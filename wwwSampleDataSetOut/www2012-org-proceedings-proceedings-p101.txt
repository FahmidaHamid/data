Targeting Converters for New Campaigns Through Factor

Models

Deepak Agarwal
Yahoo! Research

dagarwal@yahoo-inc.com

Sandeep Pandey
Yahoo! Research

spandey@yahoo-inc.com

Vanja Josifovski
Yahoo! Research

vanjaj@yahoo-inc.com

ABSTRACT
In performance based display advertising, campaign eﬀec-
tiveness is often measured in terms of conversions that rep-
resent some desired user actions like purchases and product
information requests on advertisers’ website. Hence, iden-
tifying and targeting potential converters is of vital impor-
tance to boost campaign performance. This is often accom-
plished by marketers who deﬁne the user base of campaigns
based on behavioral, demographic, search, social, purchase,
and other characteristics. Such a process is manual and sub-
jective, it often fails to utilize the full potential of targeting.
In this paper we show that by using past converted users
of campaigns and campaign meta-data (e.g., ad creatives,
landing pages), we can combine disparate user information
in a principled way to eﬀectively and automatically target
converters for new/existing campaigns. At the heart of our
approach is a factor model that estimates the aﬃnity of each
user feature to a campaign using historical conversion data.
In fact, our approach allows building a conversion model for
a brand new campaign through campaign meta-data alone,
and hence targets potential converters even before the cam-
paign is run. Through extensive experiments, we show the
superiority of our factor model approach relative to sev-
eral other baselines. Moreover, we show that the perfor-
mance of our approach at the beginning of a campaign’s life
is typically better than the other models even when they
are trained using all conversion data after the campaign has
completed. This clearly shows the importance and value of
using historical campaign data in constructing an eﬀective
audience selection strategy for display advertising.
Categories and Subject Descriptors
H.4.m [Information Systems]: Miscellaneous
General Terms
Algorithms, Performance, Experimentation
Keywords
conversions, factor, targeting

1.

INTRODUCTION

Users engage in online activities like search, consuming
content on websites, interacting with friends and colleagues
on social media, buying products online, and so on. This

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2012, April 16–20, 2012, Lyon, France.
ACM 978-1-4503-1229-5/12/04.

provides opportunities for businesses to advertise their prod-
ucts online and attract user attention in diﬀerent contexts,
creating a lucrative and rapidly growing online advertising
industry. Variety of ads are served to the users such as
those including text, logo, pictures, rich media (a combina-
tion of text, audio and video), and interactive content for
active user participation. Such online advertising is heav-
ily focused on targeting users that are of “high value,” and is
often tracked and measured in terms of conversions that rep-
resent some desired user actions like purchases, form ﬁllings,
product information requests. Targeting converters ensures
good advertiser ROI and publisher revenue, however this
involves pinpointing appropriate users amid the chaos and
huge volumes of online user activity data.

Matching the “right” users to campaigns is a complex pro-
cess that is critical to the performance of an advertising
campaign. At a fundamental level it requires eﬀective in-
ference of user interests and campaign requirements. Not
surprisingly, this has attracted wide attention from the re-
search community and sophisticated models have been built
for addressing this problem [6, 8, 23]. These models work
by learning from the past users targeted for a campaign, to
identify potential future converters. However, they do not
apply for new campaigns for which no prior targeting in-
formation is available. One can imagine dealing with this
by launching a new campaign on random users and waiting
until enough conversions are obtained for the above tech-
niques to kick in. However, this delay can result in signif-
icant monetary loss to the advertiser and the publisher for
several reasons. First, conversions are very rare events. Very
few users click on the ad and even fewer convert. Second,
learning models to target users is known to be a challenging
and high-dimensional problem that requires large number of
conversions for reliable estimation. Third, campaigns have
short lifetimes and are monitored closely. Below par perfor-
mance at the beginning can force the advertiser to stop the
campaign altogether.

In practice, optimization for new campaigns typically in-
volves marketers working with advertisers to understand the
goals and nature of their ad campaigns, and matching them
to users based on information like demographics, behavioral,
social, geographical, and others. Often this is a trial and
error process whereby marketers target speciﬁc user dimen-
sions. Although statistical and visualization tools adept at
summarizing user information in an eﬀective fashion are at
the disposal of marketers, the decision of what to target
is mostly subjective and depends on the expertise of the
marketers involved. Hypotheses are tested by running trial

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France101campaigns, new hypotheses are generated, tested, and the
process repeats. Such an unsupervised process not aimed at
optimizing a readily measurable proxy may fail to extract
optimal value for both advertisers and publishers.

In this paper we provide methods that learn user aﬃn-
ity to campaigns from combining (a) user proﬁle data based
on behavior, demographics, etc., (b) campaign meta-data in
terms of associated ad creatives, landing pages, and (c) the
user-campaign targeting interactions collected on historical
campaigns. We show such a combination is potent and can
signiﬁcantly enhance targeting performance. Our method
allows us to build targeting model for a new campaign solely
using the campaign meta-data, even before running the cam-
paign. Moreover, as the campaign starts running and addi-
tional conversion data is procured, we are able to adapt the
initial model over time.

Our approach can have signiﬁcant implications for dis-
play advertising. For instance, recent advances in tech-
nology (such as real-time bidder, ad exchanges like Dou-
bleClick/RightMedia [2]) have revolutionized display adver-
tising and given rise to a complex ecosystem of intermedi-
aries like demand side platforms, ad-networks, and others.
Several entities in this complex advertising ecosystem have
access to both user behavioral and past campaign perfor-
mance data. Hence, any of these entities can potentially use
our approach to enhance targeting for new/existing cam-
paigns. For instance, a publisher like Yahoo! can combine
user conversion information on campaigns obtained through
RightMedia with user behavioral data based on online ac-
tivities like visits to various Yahoo! pages, web searches and
vertical searches. Similarly, an ad-network can buy user be-
havioral data through data exchanges like BlueKai [1] and
combine it with partial transactional data available through
real-time bidder and advertiser-side conversion logs.

Our Approach. Campaign performance can be measured
either through ad clicks or conversions. While clicks serve
as a proxy for user’s interest in the advertised product, they
can often be misleading, e.g., click fraud, bounce clicks [17].
Hence, in this paper we use conversions as our performance
metric as it is closer to the advertisers’ real goals.

Based on data from historical campaigns that were run
for targeting conversions, we extract information and build
models to predict conversion propensity as a function of user
proﬁle and campaign meta-data information. The modeling
strategy is such that given a user proﬁle and a new campaign
with meta-data, we are able to predict conversion propen-
sity even before running the campaign, as shown in Fig-
ure 1(a). The campaign metadata helps in understanding
what the advertising campaign is about and thus identify-
ing the potential targeting set. As we run the campaign and
collect additional transactional data, our conversion model
adapts and becomes more accurate in predicting conversion
propensity. This supervised targeting approach that com-
bines user proﬁle data to optimally predict conversion rates
is markedly diﬀerent from the usual unsupervised targeting
approach practiced by marketers.

Although the supervised approach looks promising at ﬁrst
blush, it is extremely challenging for several reasons such as
low conversion rates, high dimensional user proﬁles, user
cookie churn, variability in user interests and other tem-
poral eﬀects. In fact, even the conversion deﬁnition across
campaigns is diﬀerent and depends on the advertiser and

campaign type. We deal with these challenges and make
the following contributions in this paper.

Contributions. We provide a novel modeling solution
called FACTOR that pools data across campaigns to mit-
In fact, FACTOR is able to
igate the eﬀect of sparsity.
predict user-aﬃnity to a new campaign by only using the
campaign meta-data to begin with; the predictions improve
as the campaign runs and obtains more conversion infor-
mation. The main idea is to tie the campaign speciﬁc user
feature coeﬃcients in multiple logistic regression classiﬁers
(one per campaign) through a factor model. Our model
not only learns separate factors for each user feature and
campaign, it also simultaneously learns a function that pre-
dicts campaign factors based on campaign meta-data. This
allows generalization to brand new campaigns. We run ex-
periments on more than 100 real-world ad campaigns and
report impressive gains relative to other strong baselines.
Our approach is amenable to distributed computing in a
map-reduce paradigm and scales gracefully to large adver-
tising applications.

2. PROBLEM SETUP AND CHALLENGES
Our problem setup is as follows. We are given the target-
ing data for historical campaigns that were run in the past,
we call them the train campaigns. For each train campaign,
we have a list of users who were targeted and the ones who
converted (i.e., user-campaign interaction data). Also, we
are given a representation of the users and the campaigns
whereby (see Figure 1(a)):

• User: A user is represented in terms of her past online
activities. These activities are tracked by the adver-
tisers, publishers and third parties through browser
cookies that uniquely identify the user. This includes
the history of page visits, ad views, and search queries.
Based on the content of these events, a user proﬁle is
composed in terms of a feature vector representing a
user for modeling purposes (more details in Section 5).
• Campaign: A campaign is characterized in terms of
the meta-data associated with it such as ad creatives
and landing pages. An ad creative is an image or text
snippet that is displayed to the user. Upon a click on
the ad, the user is taken to a web page associated with
this creative, called the landing page. We construct a
campaign feature vector using the creative and land-
ing page content. The metadata helps in understand-
ing what the advertising campaign is about and thus
identifying the potential targeting set.

Given this training data (user-campaign interactions, user
proﬁles and the campaign meta-data), our goal is to learn a
model that can be used to estimate conversion propensity of
a user for a brand new campaign (called test campaign) by
merely using the campaign meta-data. As the new campaign
is run and additional conversion data ﬂows in, the initial
model should adapt and get better (see Figure 1(a)). Before
proceeding to our learning strategy, we ﬁrst describe the
technical challenges that we face.
2.1 Challenges

Learning models for targeting converters is challenging for
several reasons. First, the number of conversions for each

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France102campaign is small relative to the number of user features
(rarity). We have hundreds of thousands of user features
per campaign but the number of conversions range from few
hundreds to few thousands.
(Our dataset is described in
details in Section 5.) Also, as shown in Figure 1(b), a large
fraction of user features in a campaign occurs only a few
times, making the data sparser. Hence it is diﬃcult to use
the campaign-speciﬁc data for identifying converters for a
new campaign. Pooling data across campaigns in a proper
way is an attractive approach to mitigate such sparsity. Such
data pooling is technically challenging though.

Multi-tasking has been widely used in the literature for
pooling data across multiple learning tasks. However, most
of the existing work assumes the same user features occur
across diﬀerent campaigns, while this is not true in our case
as seen in Figure 1(c) where we plot the distribution of user
feature occurrences across campaigns (sparsity). Around
15% of features occur in a few campaigns followed by a long
tail distribution. This presents additional challenges which
we shall address. Another important aspect of our problem
is that when a new campaign arrives, we want to be able
to build its targeting model using its meta-data. Moreover,
we want to ensure that with the availability of additional
conversion data procured once the campaign starts running,
we are able to adapt the initial model over time.

While pooling data across campaigns, we must realize that
campaigns come from diﬀerent advertisers and have diﬀer-
ent characteristics (heterogeneity). They span a diverse
set of domains like travel, sports goods, movie rentals, online
shopping, etc. The number of conversions across campaigns
also show wide variation. In fact, the deﬁnition of conversion
itself is diﬀerent across campaigns. In some campaigns for
instance, ﬁlling a form may be a conversion, while for some
others the user may have to subscribe to a service, and so on.
Hence, any approach that pools data across campaigns has
to be learned in an unbiased fashion after adjusting for such
heterogeneity. For instance, campaigns with large number of
conversions should not exert too much inﬂuence on the mod-
eling framework, in such cases the modeling technique will
not work well on new campaigns that are of diﬀerent kind.
Such unbiased estimation has to be conducted carefully.

3. OUR APPROACH

Our approach works by pooling data across campaigns
using the three sources of information: user-campaign inter-
actions, user proﬁles and the campaign metadata, as shown
in Figure 1(a). First, we describe how, for a single campaign,
we use the past user-campaign interactions and user proﬁles
to identify its potential future converters. We show that
this works reasonably well (in our experiments) but suﬀers
from rarity of conversions and sparsity of features. Then, in
Section 3.2 we describe how we generalize this by pooling
data across campaigns using the campaign metadata and
Hierarchical Bayesian framework.

Notations:. We introduce some notations ﬁrst. Let zj
denote the feature vector for campaign j. We note that
campaign feature vector is the only information available
for a new campaign. Let Uj denote the set of users that
are exposed to campaign j. Let ((Iij)) be a feature inci-
dence matrix where rows form the user feature and columns
are the campaign features, a 1 in the (i, j)th cell indicates
th user feature is present in campaign j, while 0 indi-
the i

cates feature absence. We denote by Xk,j the feature vector
associated with an arbitrary user k ∈ Uj, the feature ids
occurring in Xk,js obviously correspond to the 1s in the j
column of the feature incidence matrix I.
3.1 Learning from a Single Campaign

th

We begin by describing our conversion modeling for a sin-
gle campaign j. This can be framed as a binary classiﬁca-
tion task where each user proﬁle makes an instance. The
converted users are the positive instances, while the rest
make the negatives. A widely used classiﬁer for such binary
classiﬁcation tasks is logistic regression [20]. Indeed, com-
parison to other classiﬁers like SVM and Naive Bayes on
our data showed that SVM had similar performance, while
Naive Bayes performed poorly. Classiﬁers like decision trees
and random forests are not suited to our task due to sparse
occurrence frequencies of features in campaigns as shown in
Figure 1(b). Hence we use logistic regression as our base
model to develop data-pooling solutions across campaigns.
Mathematically speaking, let ykj denote the binary con-
version indicator for user k ∈ Uj on campaign j. Thus,
ykj = 1 implies user k converted on campaign j while ykj = 0
means she did not. As mentioned earlier, Xk,j denotes the
corresponding user feature vector. We will sometimes use Yj
th campaign.
to denote the entire response vector for the j
The logistic regression model for campaign j in the training
data is given as follows.

ykj ∼ Bernoulli(pkj); k ∈ Uj
log pkj

(cid:2)
k,jβj

1−pkj = X

The unknown coeﬃcient vector βj is estimated by using a
maximum likelihood (MLE) approach using the data from
past users exposed to j, i.e., for users in Uj. Let Nj de-
note the total number of users exposed to campaign j, i.e.,
Nj = |Uj|, Mj denote the total number of unique features,
i.e., Mj = length(Xk,j), and nj denote the total number of
k ykj. The log-likelihood (cid:2)j under a
converters, i.e., nj =
Bernoulli model is
X

P

(cid:2)j =

(ykjlog pkj
1 − pkj

k

+ log(1 − pkj)),

and plugging-in the expression of pkj as a function of un-
known βj, we get

X

(cid:2)j =

(ykjX

(cid:2)

k,jβj − log(1 + exp(X

(cid:2)
k,jβj)).

k

The unknown βj is obtained by maximizing the function (cid:2)j,
this problem has a rich literature dating back to the 70s and
is referred to as logistic regression [18].
In our application, it is routine to observe small number
of converters but large number of features, i.e., nj (cid:4) Mj.
For instance, in our data nj’s range from a few hundreds
to few thousands, while Mj’s are in hundreds of thousands.
With such extreme imbalance in the number of positives
relative to the dimension of unknown coeﬃcient vector βj,
the estimates are unstable and have high variance.

To get a sense of the diﬃculty involved, consider one bi-
nary user feature. The MLE then has a closed form solution
given by the log-odds ratio between the binary variables ykj
and the only binary feature Xkj. It is clear that the estimate
diverges to the boundaries {−∞, +∞} when either y’s and
X’s do not co-occur together or the X’s occur only when y’s

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France103s
e
r
u

t

i

 

a
e
F
n
g
a
p
m
a
C
%

0
6

0
4

0
2

0

1−5

6−10

11−50

51−100

>100

#Occurences

n
o

i
t
c
a
r
F

 0.16

 0.14

 0.12

 0.1

 0.08

 0.06

 0.04

 0.02

 0

 0

 20

 10
 80
Degree (in terms of number of campaigns)

 30

 40

 70

 50

 60

 90

(a) Approach overview

(b) Per-campaign feature distri-
bution

(c) Across campaigns feature dis-
tribution

Figure 1: (a) Flow of our approach. (b) Feature occurrence distribution within a campaign (for 89 campaigns).
(c) Distribution of feature occurrence across 89 campaigns.

occur. In other words, we need feature overlap with both
label types, i.e., X’s have to co-occur with both kinds of
labels. More precisely, if the cone spanned by the columns
of feature rows corresponding to converters have no overlap
with the corresponding cone for non-converters, MLE for
logistic regression does not exist! For a complete technical
characterization of this issue, we refer the reader to [14].

To ensure better behavior in high dimensional setting such
as ours, constraints (regularization) on the unknown coeﬃ-
cients βj or borrowing information across campaigns (data
pooling) is important. Proper ways to borrow information
across campaigns is the crux of our problem, as described
next.
3.2 Pooling Data Across Campaigns

We now discuss various data pooling strategies. Recall
that our goal is not to merely ﬁt logistic regression reliably
to training campaigns, we want to estimate the conversion
propensity of users to a new campaign using the campaign
speciﬁc meta-data, before even running the campaign. Such
a process can simultaneously utilize all rich sources of data
and provide more ﬁne grained user targeting compared to
the human supervised procedures whereby marketers design
targeting strategy through broad segment behavior.

We perform data pooling by working in a hierarchical
Bayesian modeling framework. Appealing again to the fea-
ture incidence matrix I, let βij denote the coeﬃcient associ-
ated with feature id i in campaign j corresponding to pairs
(i, j) for which Iij = 1. Our Bayesian framework assumes
independent Gaussian priors on βijs, i.e.,

βij ∼ N(βij0, σ

2
ij)

(1)

∗

P

We combine the prior in Equation 1 with the logistic log-
j (cid:2)j to obtain the posterior distribution of βs.
likelihood
The posterior mean provides estimated values of the coef-
ﬁcients βijs. Note that for a new campaign j
, we use the
prior mean βij∗0 as the initial targeting model, since no
to begin with.
conversion data is available on campaign j
Hence, modeling the prior means βij0s properly is crucial
for an eﬀective generalization to new campaigns.

2
ijs are the prior variance parameters and generally
harder to estimate than the mean, we choose two parameter-
izations: (a) Per-campaign variance component model, i.e.,
2
2
ij = σ
j for all i, and (b) global variance component model,
σ

Since σ

∗

−3

, 10

2s in the range [10

2
2 for all (i, j). To give some intuition on the scale
ij = σ
i.e., σ
2s, note that the interval (βij0 − 3σij, βij0 + 3σij) repre-
of σ
sents the range within which we restrict the magnitude of βij
with high probability a-priori. With hundreds of thousands
of features and small number of conversions, it is important
to keep this range to be small. Based on extensive exper-
−1]
iments, we found restricting σ
works well in our problem settings. Larger values are too
ﬂexible and lead to high posterior variance and unreliable
posterior mean estimates, while smaller values tend to re-
strict posterior means of βijs too close to βij0s and restricts
the scope of learning from the available user-campaign in-
teraction data.
3.2.1 Modeling Prior Mean
As evident, the main component of our data pooling ap-
proach in a hierarchical Bayesian framework is in estimat-
ing the prior distribution; most importantly the prior means
βij0s. We discuss three possibilities.
ZEROMEAN. This assumes βij0 = 0 and is commonly
used to impose regularization when ﬁtting a single ill-conditioned
logistic regression. The prior variance restricts the range of
coeﬃcients and the posterior mean does not diverge even
when feature cones have low overlap. As evident, this does
not generalize to brand new campaigns. However, once a
campaign is launched and it obtains some conversions, we
can use the zero prior to combine with log-likelihood and ob-
tain posterior mean for coeﬃcients. This is commonly used
in the current conversion-based advertising systems [6] and
serves as the baseline in our framework (we shall refer to
this as ZEROMEAN).
Linear Regression Prior. A natural approach is to model
the prior mean as a function of campaign features zj.
In
other words, we assume βij0 = gi(zj), where gi is an un-
known function for user feature i. Although one can use
diﬀerent kinds of non-linear functions, we conﬁne ourselves
(cid:2)
izj, where the coeﬃcient vectors gis
to a linear function g
are unknown. Such a model generalize to new campaigns if
we can estimate the unknown coeﬃcients gi for each user
feature i from the training data. To avoid over-ﬁtting, we
constrain the gis by imposing an L2 penalty term. We per-
form such an estimation through an EM algorithm as de-
scribed in section 4. For the sake of easy reference, we shall

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France104refer to this model as REG; the parameter vectors gi across
th
diﬀerent features will be denoted by a matrix G whose i
row is gi.

(cid:2)
izj for each
Factor Model. Training a global function g
user feature in REG involves estimating a large number of
parameters G. For instance, if there are 100K user features
and 30 campaign features, we have to estimate 3M parame-
ters to predict the prior mean βij0s! This could be daunting
and may require a large number of historical campaigns that
may not be always available.

To reduce the number of unknown parameters, we take re-
course to a factor model that is used in collaborative ﬁltering
applications to model user aﬃnity to items. However, in our
scenario, we do not apply it to the original user-campaign in-
teraction data, instead we use it to model the prior mean of
a coeﬃcient matrix of user features for diﬀerent campaigns.
The factor model assumes

βij0 = u

(cid:2)
ivj

where ui and vj are r-dimensional unknown latent factors
for user featurei and campaign j respectively.

We note that if the coeﬃcient matrix was complete, this is
equivalent to assuming a probabilistic PCA [21] prior on the
coeﬃcients βijs. But since the matrix is not complete, such
an interpretation is not precise, thinking as a matrix com-
pletion problem is more germane. Two issues remain. To
estimate the factors reliably when the matrix is incomplete,
some constraints need to be imposed on the factors. Also
the campaign factors vj should be computable for a new
campaign. We address both issues by putting appropriate
priors on the feature and campaign factors. More precisely,

where D is an unknown matrix with r rows, each row cor-
responds to coeﬃcients of a linear regression that predicts
the corresponding campaign factor; scalars au and av are
variance components that determine the range within which
we should constrain the factors. All unknown quantities in
Equation 2 are estimated from data as we discuss in Sec-
tion 4. For easy reference, we shall refer to this model as
FACTOR. We note that the total number of unknown pa-
rameters to estimate prior means βij0 is now r times the
total number of campaign features. If r = 5 and we have 30
campaign features, this reduces to estimating 150 parame-
ters as opposed to 3M with REG.

Some Remarks on FACTOR.
marize some important facts about FACTOR.

It is worthwhile to sum-

• Fewer Unknown Parameters: We assume the coeﬃ-
cient matrix can be well approximated a-priori through
a low-rank matrix decomposition. A linear regression
is then used to estimate the campaign factors as op-
posed to predicting each user feature coeﬃcient. This
is key in reducing the number of unknown parameters
required to estimate the prior mean.

• Dealing with Campaign Size Variation: Assuming βijs
(cid:2)
to be centered around u
ivj with some prior variance
is a crucial relaxation that allows the posterior mean
of some βijs to deviate away from the estimated prior

ui ∼ M V N(0, a u)
vj ∼ M V N(Dz j, av)

(2)

2

(cid:2)
mean u
ivj. This prevents campaigns with large num-
ber of conversions from having excessive inﬂuence on
the factor estimates.

∗

• Building and Adapting Models for New Campaigns:
, one uses the campaign features
For a new campaign j
zj∗ to predict the campaign factor as Dzj∗. Since the
factors for user features are already known from the
training phase, we can compute the prior mean βij∗0
(cid:2)
iDzj∗ . This serves as the initial model
eﬃciently as u
for the campaign. Also, due to the aforementioned re-
laxation via prior variance, the model can be adapted
over time as the number of conversions obtained on the
campaign increases. Without this relaxation, adapta-
tion would not be possible.

4. MODEL FITTING

We now describe our model ﬁtting procedures for REG
and FACTOR. For both, we use an EM algorithm [9] to
estimate the unknown parameters in the prior of βijs.

2

Parameters for EM:. Denoting the unknown parameters
in the prior distribution by Θ, our goal is to maximize the
marginal log-posterior of observed data. The marginaliza-
tion (integration) is performed with respect to latent vari-
ables (unobserved random variables) Δ. In the case of REG
for instance, Δ = {βij}∀(i,j), the set of all unknown coef-
ﬁcients corresponding to pairs (i, j) that are present in the
j}∀j) wherei runs over
incidence matrix I, andΘ = (G,{σ
all user feature ids observed in the training data, and j runs
over campaigns. For a global variance components model,
Θ = ({G, σ
For FACTOR, the latent variables are Δ = ({βij},{ui},
{vj})∀(i,j); Θ = ({σ
, D, au, av) for
the campaign-speciﬁc and global variance component mod-
els respectively. A crucial parameter here is D, the regres-
sion coeﬃcient matrix, that helps predicting factors vj for
new campaigns.

j}∀j, D, au, av) and (σ

2).

ij N(βij; βij0, σ

Q
ing the integral of product of likelihood exp(

We note that the marginal distribution involves comput-
k (cid:2)k) and prior
2
ij) with respect to Δ; this cannot be com-
puted in closed form, it is also diﬃcult to compute this using
numerical integration techniques due to the high dimension-
ality of the integral. Hence we use the EM algorithm by
working with the log-posterior of complete data ({ykj}, Δ)
conditional on Θ.

2

P

4.1 EM Algorithm

Starting from some initial estimate Θinit, the EM al-
gorithm maximizes the marginal log-posterior by iterating
through the expectation (E) and maximization (M) steps un-
til the solution converges. Each sweep of the E and M steps
are guaranteed not to reduce the marginal log-posterior. Let
Θcurr be the current estimate of Θ in the iterative process.
In the E-step, we compute the expected log-posterior of com-
plete data with respect to the conditional distribution of
[Δ|{yij}, Θcurr]. In the M-step, we maximize the expected
log-posterior (from E-step) with respect to Θ and obtain a
new estimate. To ensure convergence, it is suﬃcient to use
any hill climbing method in the M-step that provides a new
improved value of Θ; such variants are called generalized
EM (GEM) [15].

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France105Monte Carlo E-step:. The E-step in our model cannot be
computed in closed form for both REG and FACTOR since
the posterior distribution [Δ|{yij}∀(i,j), Θ] is non-standard.
However, it is possible to draw samples from this high di-
mensional distribution by using modern sampling methods
based on Markov Chain Monte Carlo (MCMC) [22]. We use
MCMC sampling procedures to approximate the expected
complete log-posterior by using a Monte-Carlo mean com-
puted from samples drawn from [Δ|{yij}, Θcurr].
In the
M-step, we maximize the Monte-Carlo mean for obtaining a
new value Θ. This is called MCEM algorithm in the litera-
ture and have been widely used in various applications (see
[7] and references therein.)

Next we provide details of sampling algorithms and M-

step computations for both REG and FACTOR.
4.2 Estimating the REG MODEL
We describe the sampling procedure ﬁrst.

Sampling for REG:. We use a Gibbs sampler [10] to sam-
ple from [Δ = {βij}∀(i,j)|{ykj}∀(i,j), Θcurr]. Each sweep in
a Gibbs sampler cycles through the individual co-ordinates
(blocks of co-ordinates) in Δ sequentially drawing a sam-
ple from lower dimensional full conditional distributions.
This idea of taming the curse of dimensionality by sampling
sequentially through lower-dimensional distribution to ob-
tain samples from very high-dimensional distribution makes
Gibbs sampling a powerful computing tool. In this case, the
full conditional distributions being sampled are univariate:
[βij|Rest,{yij}, Θcurr], where Rest denotes all co-ordinates
except the one being sampled that are ﬁxed at their latest
sampled values. The process is repeated several times, the
samples obtained are realizations from a Markov chain with
stationary distribution [Δ = {βij}∀(i,j)|{yij}∀(i,j), Θcurr].
We discard the ﬁrst few samples (called burnin), and take
the rest as our samples to compute the Monte Carlo mean.
Each univariate distribution is a one dimensional density
that is non-standard but log-concave, it is sampled by us-
ing an adaptive rejection sampling algorithm as described
in [11].

Scalability:. We note that the coeﬃcient vectors of dif-
Q
ferent campaigns are independent of each other a-posteriori,
i.e., [Δ = {βij}|{ykj}, Θcurr] =
j[Δj = βj|Yj, Θcurr].
This has important implications. It means sampling of la-
tent variables can be done separately for each campaign, i.e.,
we can run independent Gibbs sampler for each campaign
and decouple the sampling in the E-step across campaigns.
We exploit this structure to achieve scalability by paralleliz-
ing the E-step across campaigns in a map-reduce framework,
the mapper splits the data by campaigns and the reducer
runs the Gibbs sampler for each campaign using adaptive
rejection sampling.

M-step for REG:.
minimizing

X

E

(i,j):Iij =1

In the M-step, we estimate Θ by

((βij − g

(cid:2)
izj)2

2
j + log(σ

2
j ))

/σ

where the expectation is with respect to the posterior of la-
2
tent variables at the latest Θ value. If ¯βij and τ
ij denote the
mean and variance computed from the monte-carlo samples

drawn in the E-step, this reduces to minimizing

((( ¯βij − g

(cid:2)
izj)2 + τ

2
ij)/σ

2
j + log(σ

2
j ))

X

(i,j):Iij =1

For a given user feature i, we estimate gi as ˆgi through a lin-
ear regression of ¯βijs on zj. Denoting by RSSj the residual
(cid:2)
izj)2, the esti-
sum-of-squares deﬁned as
mated σ

2
j is given as

i:Iij =1( ¯βij − ˆg
X

P

2

ij)/|i : Iij = 1|

ˆσ2
j = (RSSj +

τ

i:Iij =1

For the global variance components model that assumes
2
j = σ
σ

2, the estimated σ
ˆσ2 = (

RSSj +

X

2 is given by
2

X

ij)/|(i, j) :I ij = 1|

τ

j

(i,j):Iij =1

All above expressions can be derived through simple calcu-
lus.
4.3 Estimating the FACTOR Model

Next we describe the exact sampling procedure for FAC-
TOR, followed by a more scalable but approximate estima-
tion method.

Sampling for FACTOR. For this model, the βijs are aug-
mented with latent factors ui and vj. Since the latent factors
are shared across campaigns, the posterior independence
that helped us decouple the sampling across campaigns is
no longer valid. Each sweep of the Gibbs sampler would
sample the βijs conditional on the latent variables and then
sample the latent variables conditional on the sampled βijs.
It is easy to show that conditional distributions of ui given
Rest and that of vj given Rest are Gaussian [3]. In fact, the
conditional Gaussian distributions for uis are independent
across user features and hence can be sampled in parallel.
The same logic applies to vjs.

Each sweep of the Gibbs sampler can be parallelized as fol-
lows: sample βijs given the latent factors by sampling blocks
βjs across campaigns in parallel, then sample uis across user
features in parallel followed by a parallel sampling of vjs.

Approximate E-step and M-step for FACTOR:. The
parallelized sampling scheme described above is not amenable
to parallelization in a map-reduce framework using com-
monly available software framework like Hadoop, since run-
ning a separate map-reduce job per Gibbs iteration is time
consuming and ineﬃcient. Hence we make the following ap-
proximation: we assume the latest latent factors and D are
ﬁxed parameters that are estimated as part of the M-step,
i.e., as part of Θ, and we sample the βijs in a map-reduce
framework as in REG. We then ﬁt the latent factor model
described below in Equation 3 to the Monte-Carlo mean ¯βij
computed from MCMC samples by using the algorithm de-
scribed in [3]. The latent factor model we ﬁt in the M-step
is as follows.

(cid:2)
ivj, σ

¯βij ∼ N(u
2
ij)
ui ∼ M V N(0, a u)
vj ∼ M V N(D zj, av)

(3)

We note that from the model ﬁt in Equation 3, we only
use the ﬁtted uis, vjs, and D, and regard them as estimates

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France106of the ﬁxed parameters. The approximation is a valid gener-
alized EM algorithm if the solution of (ui, vj, D) obtained
by ﬁtting the model in Equation 3 improves the marginal
log-posterior. This is indeed true if au and av are ﬁxed and
do not change over iterations since we are then performing
constrained optimization with the same constraints over EM
iterations. In our ﬁtting process, we found these parameters
to vary little across iterations.

We adopt this approximation that works in a map-reduce
framework, since most modern advertising systems store
their data on the cloud and map-reduce framework is an
attractive way to perform distributed computing in such sce-
narios.

2
j s and σ

2 are estimated as in the M-step for REG
(cid:2)
ivj as ﬁtted prior mean in the RSSj

by using estimated u
computations, all other computations are the same.

The σ

5. EXPERIMENTS

We begin by describing our dataset.

5.1 Data

We constructed a dataset consisting of 114 display adver-
tising campaigns registered on a large US advertising net-
work. All selected campaigns are performance-based, i.e.,
advertisers pay for actual conversions. The deﬁnition of con-
version diﬀers across campaigns. For each campaign we col-
lected a sample of 30,000 users who were targeted during the
four weeks period from mid March to mid April, 2011. Con-
version information for the users targeted during this period
was collected by looking ahead if necessary, due to the lag
in obtaining data for certain kinds of conversions. Overall,
we ended up with more than 3 million users to conduct our
experiments.

Each campaign serves as a dataset for our scenario whereby
each user targeted for the campaign is an instance. Users
who converted are the positive instances, while the rest are
negative examples. Our goal is to learn targeting models
that can identify potential converters for a campaign, i.e.,
distinguish between positive and negative instances.

Next we describe how the users and campaigns are repre-

sented in our data.

User Representation. For each user we construct a pro-
ﬁle based on her online activities preceding the time she was
impressed with an ad. Any potentially personally identiﬁ-
able was removed and all the data was anonymized. The
user activities include past page visits, search queries, ad
views and clicks. These activities have associated textual
content that were used to construct the features for the user
proﬁle, e.g., the text of issued search queries, the content of
pages viewed, etc. The weight for each feature was set to be
binary in our experiments. Note that while predicting for a
user during the evaluation, say on day t, we allow the pre-
diction models to access user history up to day t− 1. Hence,
the prediction method is not using any future information.

Campaign Representation. For the campaign we have
two sources of data: (a) past users who have been targeted
for the campaign and of those who converted, (b) meta-data
in the form of ad creatives (details below). If the campaign
is brand new, then the former information is not available.
An ad creative is an image or text snippet for the ad that
is displayed to the user. Upon a click on the ad, the user is

taken to a web page associated with this creative, also called
a landing page. The creative and the landing page give a suc-
cinct characterization of the ad campaign, and they can be
useful to infer the domain of the campaign. For our experi-
ments we crawled each landing page, parsed, and attributed
the extracted content to its corresponding campaign. Then
we constructed feature vectors for each campaign based on
word unigrams from the associated content. To reduce noise
when using these feature vectors in our models, we projected
them into a 30-dimensional linear subspace using PCA.

Simulating past, new and existing campaigns. We
randomly partition the 114 campaigns into a training set
of 89 campaigns and a test set with the remaining 25 cam-
paigns. The training set simulates the past campaigns for
which the advertising network has served ads and is aware
of the converters and non-converters. The test set simulates
the new/existing campaigns. We use the campaigns in the
training set to learn our models, and then build targeting
models for the campaigns in the test set (see Figure 1(a)).
To evaluate the performance on the test set, we compute the
evaluation metric (described later) from 2-fold cross valida-
tion. In other words, we randomly create three folds for each
campaign in the test set. All simulations are done on two
folds and the evaluation metric is computed on the third
fold. Sometimes, we shall refer to the two folds of a test
campaign as training data for the test campaign.

To simulate a test campaign in diﬀerent stages of its life,
we make a sample of its training data (from two folds) avail-
able to the modeling approach for training. For example,
when the sampling percentage, say P ,
is 0, no informa-
tion about converted/non-converted users for this campaign
is available while model training. This simulates a brand
new campaign and our approach would build model for this
campaign using its meta-data only. As the campaign gets
older, some converters/non-converters for it become known
to the advertising network. We simulate this by gradu-
ally increasing the value of P and allowing our approach to
use converted/non-converted user information in conjunc-
tion with the meta-data.

Evaluation Metric. For evaluating the models produced
for test campaigns, we use the area under the ROC curve.
The AUC gives the probability with which the targeting
method assigns a higher score to a random positive example
than a random negative example (i.e., probability of concor-
dance) [12]. So, a purely random method will have an area
under the curve of exactly 0.5.

An alternative metric could be to measure precision/recall
at a certain rank in the list. However, diﬀerent campaigns
may have diﬀerent requirements in terms of precision and
recall

Next we evaluate our approaches on this dataset. We start

by describing the diﬀerent methods that are compared.
5.2 Baseline and Our Approaches

The current state-of-the art for targeting converters is to
learn a targeting model for each campaign using the past
data for the campaign [6]. This is an instance of our pro-
posed approach (in Section 3) when the prior mean for each
feature is set to 0, i.e., ZEROMEAN. This would serve as
baseline for our experiments. We compare it against the
other two instantiations of our approach, REG and FAC-
TOR. The parameters for each method are tuned using

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France1072-fold cross validation and the performance numbers on the
third fold from the best setting are reported, unless stated
otherwise.
5.3 Performance Evaluation of ZEROMEAN

We start by investigating model ZEROMEAN which is
the predominant approach used in current advertising sys-
tems [6, 8, 23]. It learns a targeting model for each campaign
using the past campaign data. The approach has several
shortcomings. First, clearly, this approach is unable to pro-
duce models for brand new campaigns which do not have
any past data. Second, for campaigns with small amount of
historical data either due to their scope, scale or age, ZE-
ROMEAN struggles due to lack of positive examples.

We illustrate this by conducting experiments on the 25
test campaigns. We simulate the diﬀerent stages of a cam-
paign and compute our evaluation metric as discussed be-
fore. The performance results for ZEROMEAN are shown
in Figure 2(a). We tuned the value of prior variance and
found 0.001 provides the most stable and best results. On
the x-axis we plot the number of positives examples available
for training (on the log scale with base 10), and on the y-axis
we show the AUC value for each of the 25 test campaigns.
Also, we plot curves denoting for a given number of posi-
tives, the average AUC and the weighted average AUC over
test campaigns (weighted by the number of conversions).

Both the unweighted and weighted average show the same
trend: when the number of positive examples, P , is small,
the models produced by ZEROMEAN are not good (result-
ing in AUC close to 0.55). In fact, some campaigns get an
AUC of 0.5 (or below) which is what the RANDOM ap-
proach would do. This relates to the point we made earlier
in Section 3 that learning conversion models for targeting
is very challenging due to the sparsity of features and lack
of positives. Until 100 or more conversions are obtained for
training, the performance stays below 0.6. However, ob-
taining 100 conversions in a real world setting with several
advertisers competing for the same user segments can take
a signiﬁcant amount of time (several weeks for small cam-
paigns). Advertisers often desire fast turnaround and good
ROI. Hence it is important to deal with the cold-start issue
in an eﬀective manner, as demonstrated by our proposed
approach in the next section.

It is worth noting that the unweighted average is slightly
higher than the weighted average in Figure 2(a). On further
investigation, we found that small-scale campaigns are more
targeted in terms of their desired users. Hence, they are
relatively easier to model and perform better, which makes
the unweighted average better than weighted average. Given
that the trends exhibited by both the metrics are similar, we
only report the weighted average in the subsequent experi-
ments to avoid clutter in plots.

5.4 Using Past Campaigns to Build Models for

New Campaigns

In this section we describe how our approach from Sec-
tion 3 can be used to build models for campaigns which are
brand new or have little historical data. Then we compare
the ZEROMEAN approach against REG and FACTOR on
test campaigns.
TRAIN. We ﬁrst train REG and FACTOR over 89 train
campaigns to estimate the G matrix used by REG and the

D matrix and user factors {ui}∀i used in FACTOR using
the EM framework described in Section 3. We use map-
reduce to scale the training procedure, as described before.
After training, we perform inference to build models for the
campaigns in the test set, described below.

In the inference task we are given the
INFERENCE.
meta-data of a campaign, say c, in the test set. Using this
metadata and the estimated parameters (e.g., G, D), we
compute the prior mean (βij0) for the user feature weights.
With this prior and the available training data for campaign
c, we compute the posterior model. To simulate the test
campaign c at diﬀerent stages of its life, we vary the number
of positive examples (P ) available for training data in the
test phase as described before. When the campaign is brand
new, P is 0, and as it gets older, the value of P is increased.

RESULTS. In Figure 2(b) we show the performance of the
three methods (ZEROMEAN, REG and FACTOR). We
ran FACTOR with 5 factors for this experiment (we study
the eﬀect of using diﬀerent factors later in this section). On
the x-axis we vary the number of positive examples and on
the y-axis we denote the weighted average AUC over the 25
test campaigns. (When P is 0, the logarithm is not deﬁned
and we refer to this point as ZERO in the ﬁgures.) As
expected, all approaches improve their performance as more
positive examples trickle in.

Note that the average AUC for ZEROMEAN is 0.5 when
P = 0 since the approach is unable to produce any model for
a brand new campaign. More importantly, we see that REG
and FACTOR provide good AUC numbers even without
any training data for these new campaigns. In fact, FAC-
TOR gives AUC of about 0.65 without any training data
which is higher than the performance of ZEROMEAN with
all training data. This is a great news since it means that
using FACTOR we can bootstrap a new campaign with a
good model and start targeting the right users at the out-
set. Moreover, as more users convert, we incorporate this
knowledge to reﬁne the model (through the posterior) and
improve the AUC further.

In order to investigate this further, in Figure 3 we show
the performance over individual campaigns (along with the
weighted average). It is worth noting that the variation in
performance across campaigns is reduced using REG and
FACTOR. For example, we see that ZEROMEAN suﬀers
when there is little training data and so it has many cam-
paigns below 0.6 AUC in the left region. On the other
hand, REG performs quite well in this region by leverag-
ing the knowledge extracted from existing campaigns. But
due to high-dimensionality of G and campaign heterogene-
ity, REG can produce inaccurate models for some campaigns
(even when all training data is made available, as shown to-
wards the right in the ﬁgure). In theory, this problem can
be avoided by increasing the prior variance and allowing the
data to dominate rather than the prior mean. However,
such ﬁne tuning over individual models can be expensive
and diﬃcult to perform in a large advertising system. Our
ﬁnal approach, FACTOR, performs well for any amount of
training data (P ), it produces models which perform well
uniformly across campaigns. This is encouraging since it
shows that the improvement of FACTOR in average AUC
is not coming at the cost of hurting some campaigns for the
beneﬁt of others, instead it is by uniformly improving the
model for each campaign.

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France108 0.85

 0.8

 0.75

 0.7

 0.65

 0.6

 0.55

 0.5

e
v
r
u
c
 
C
O
R
e
h

 

t
 
r
e
d
n
u

 

a
e
r
A

 

C
U
A
e
g
a
r
e
v
A
d
e

 

weighted avg
unweighted avg

t

i

h
g
e
W

 0.45

1

1.5

ALL
# positives examples in training (log scale)
(a) Performance analysis of ZEROMEAN.

2.5

2

 0.7
 0.68
 0.66
 0.64
 0.62
 0.6
 0.58
 0.56
 0.54
 0.52
 0.5

ZeroMean
REGR
FACTOR

ZERO

1.5

ALL
# positives examples in training (log scale)

2.5

2

(b) Comparison of the three approaches (in terms of the
weighted average AUC).

Figure 2: Performance comparison of our proposed approaches on the test campaigns for diﬀerent number
of positives made available for training. ZERO refers to the setting when the campaign is brand new.

e
v
r
u
c
 
C
O
R
e
h

 

t
 
r
e
d
n
u
 
a
e
r
A

 0.85

 0.8

 0.75

 0.7

 0.65

 0.6

 0.55

 0.5

 0.45

ZERO

2

1.5

ALL
# positives examples in training (log scale)
(a) ZEROMEAN

2.5

e
v
r
u
c
 
C
O
R
e
h

 

t
 
r
e
d
n
u
 
a
e
r
A

 0.85

 0.8

 0.75

 0.7

 0.65

 0.6

 0.55

 0.5

 0.45

e
v
r
u
c
 
C
O
R
e
h

 

t
 
r
e
d
n
u
 
a
e
r
A

 0.85

 0.8

 0.75

 0.7

 0.65

 0.6

 0.55

 0.5

 0.45

ZERO

1.5

ALL
# positives examples in training (log scale)

2.5

2

ZERO

1.5

ALL
# positives examples in training (log scale)

2.5

2

(b) REG

(c) FACTOR

Figure 3: Performance variations over individual campaigns.

5.5 Effect of Parameters on FACTOR

In this section we investigate the eﬀect of several parame-
ters involved in training/testing of our FACTOR approach.

First we study the con-
Number of EM Iterations.
vergence behavior of the EM approach proposed for FAC-
TOR in Section 4. In Figure 4 we show the performance of
FACTOR on the test campaigns after diﬀerent number of
EM iterations (for P = 0). Each EM iteration takes about
1 hour of runtime for training over 89 campaigns (and 2
million users), with the help of the approximation and the
map-reduce framework described before. As expected, the
performance goes up with more iterations. However, we note
that most of the improvement is achieved within the ﬁrst 10-
15 iterations. This is quite attractive since it implies that
the model can be learned without much delay, in practice,
and also updated frequently as the underlying data changes.

In the previous sec-
Eﬀect of the number of factors.
tions we had shown the results for FACTOR for 5 factors.
In Figure 4 we vary the number of factors and plot the av-
erage weighted AUC over test campaigns after 5 iterations
of the EM algorithm. We note that the performance of our
approach is not very sensitive to the number of factors.

Eﬀect of Initialization. We initialize the EM algorithm
for FACTOR approach with zero mean and a constant value

2, for each campaign. Then in each it-
of variance, say σ
eration of the EM algorithm we update the per-campaign
variance and the global variance estimates, as described in
Section 3. Figure 4 shows that FACTOR is not sensitive
to the initial variance value. In other words, the approach
does not need too much ﬁne tuning and works well for a
large range of settings. We also observed that results with
per-campaign and global variance components are similar
for both REG and FACTOR.

6. RELATED WORK

Our multi-tasking model FACTOR is related to a rich
literature on multi-task learning [16] that learns multiple
related tasks simultaneously to take advantage of similarities
across tasks. In particular, we are related to approaches that
uncover the common (latent) features that can beneﬁt each
individual task/domain [5, 13, 19].

More recently [4] proposed a method that learnt multiple
logistic regressions across diﬀerent articles in a news rec-
ommendation system by using a low-rank projection, i.e.,
βj = U vj, where the matrix U is shared across all regres-
sions. Although this formulation is closest to our FACTOR,
it has several diﬀerences. First, both this work and most
others described above assume the presence of same fea-
tures across all tasks. This is not true in our scenario where
a feature id may only occur in a few tasks. But the most

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France109e
v
r
u
c
 
C
O
R
e
h

 

t
 
r
e
d
n
u
a
e
r
A

 

 0.65

 0.645

 0.64

 0.635

 0.63

1

 5

 10

 15

 20

Number of iterations

e
v
r
u
c
 
C
O
R
e
h

 

t
 
r
e
d
n
u
a
e
r
A

 

 0.72

 0.7

 0.68

 0.66

 0.64

 0.62

 0.6

 0.58

 0.56

 0.54

1

3
5
Number of factors

10

e
v
r
u
c
 
C
O
R
e
h

 

t
 
r
e
d
n
u

 

a
e
r
A

 0.65

 0.645

 0.64

 0.635

 0.63

per-campaign

global

0.01
Initial value of sigma

0.001

Figure 4: Eﬀect of various parameters.

important diﬀerence is that FACTOR assumes βijs are cen-
(cid:2)
tered around u
ivj and not equal to it, this relaxation is
important to obtain good performance in both cold-start
and warm start scenarios (campaigns with large number of
conversions); the model proposed in [4] does not have this
property.

As mentioned before, the factor model we use to model
the prior is borrowed from the collaborative ﬁltering litera-
ture [3] where it is used to directly model the data. Instead,
we model the original data through logistic regression and
push the factor model one level up to estimate the prior
means of the feature weights.

7. DISCUSSION

Ad exchanges and recent technologies like real-time bidder
that enable cherry-picking of impressions by ad-intermediaries
have revolutionized display advertising. It provides an ecosys-
tem where owners of rich user data can target valued user to
ensure good revenue for publishers and better ROI for ad-
vertisers. The real challenge is in building statistical mod-
els that can laser in on appropriate users: we have shown
combining historical campaign data with rich user proﬁle in-
formation and campaign metadata through our new model
FACTOR is a promising step in this direction. We showed
promising oﬄine results in this paper, and are in the process
of “productizing” and testing the method on a live advertis-
ing system.

8. REFERENCES
[1] Bluekai. www.bluekai.com/.
[2] Rightmedia. http://rightmedia.com/.
[3] D. Agarwal and B.-C. Chen. Regression-based latent
factor models. In KDD, KDD ’09, pages 19–28, New
York, NY, USA, 2009. ACM.

[4] D. Agarwal, B.-C. Chen, and P. Elango. Fast online

learning through oﬄine initialization for time-sensitive
recommendation. In KDD, pages 703–712, 2010.

[5] A. Argyriou, C. Micchelli, M. Pontil, and Y. Ying. A

spectral regularization framework for multi-task
structure learning. NIPS, 2008.

[6] A. Bagherjeiran, A. O. Hatch, A. Ratnaparkhi, and

R. Parekh. Large-scale customized models for
advertisers. In ICDM Workshops, 2010.

[7] J. Booth and J. Hobert. Maximizing generalized linear

mixed model likelihoods with an automated monte
carlo EM algorithm. J.R.Statist. Soc. B, 1999.

[8] Y. Chen, D. Pavlov, and J. Canny. Large-scale

behavioral targeting. In KDD, pages 209–218, 2009.

[9] A. P. Dempster, N. M. Laird, and D. B. Rubin.

Maximum likelihood from incomplete data via the EM
algorithm. J. of the Royal Statistical Society, Series B,
1977.

[10] A. E. Gelfand. Gibbs sampling. Journal of the

American Statistical Association, 95:1300–1304, 2000.
[11] W. Gilks and P.Wild. Adaptive rejection sampling for

gibbs sampling. 41:337–348, 1992.

[12] M. Greiner, D. Pfeiﬀer, and R. D. Smith. Receiver

operating characteristic (roc) curves. Preventive
Veterinary Medicine, 45:23–41, 2000.

[13] S. Lee, V. Chatalbashev, D. Vickrey, and D. Koller.

Learning a meta-level prior for feature relevance from
multiple related tasks. In ICML, 2007.

[14] M.J.Silvapulle. On the existence of maximum

likelihood estimates for the binomial response models.
Journal of the Royal Statistical Society, Series B,
43:310–313, 1981.

[15] R. Neal and G. Hinton. A view of the EM algorithm
that justiﬁes incremental, sparse, and other variants.
In Learning in Graphical Models, 1998.

[16] S. J. Pan and Q. Yang. A survey on transfer learning.

Technical Report HKUST-CS08-08, Hong Kong
University of Science and Technology, 2008.

[17] Y. Peng, L. Zhang, M. Chang, and Y. Guan. An
eﬀective method for combating malicious scripts
clickbots. In ESORICS, 2009.

[18] S. Press and S. Wilson. Choosing between logistic

regression and discriminant analysis. Journal of the
American Statistical Association, 73:699–705, 1978.

[19] A. P. Singh and G. J. Gordon. Relational learning via

collective matrix factorization. In KDD, 2008.

[20] T.Hastie, R.Tibshirani, and J.Friedman. The Elements

of Statistical Learning. Springer, 2009.

[21] M. E. Tipping and C. M. Bishop. Probabilistic

principal components analysis. Journal of the Royal
Statistical Socienty, Series B, 61:611–622, 1999.
[22] W.R.Gilks, S.Richardson, and D.J.Spiegelhalter.

Markov Chain Monte Carlo in Practice. Chapman and
Hall, 1996.

[23] J. Yan, N. Liu, G. Wang, W. Zhang, Y. Jiang, and
Z. Chen. How much can behavioral targeting help
online advertising? In WWW, pages 261–270, 2009.

WWW 2012 – Session: Advertising on the Web 1April 16–20, 2012, Lyon, France110