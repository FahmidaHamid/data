Investigating the Distribution of Password Choices

Hamilton Institute, National University of Ireland

Hamilton Institute, National University of Ireland

David Malone

Maynooth

David.Malone@nuim.ie

Kevin Maher

Maynooth

Kevin.J.Maher@nuim.ie

ABSTRACT
The distribution of passwords chosen by users has impli-
cations for site security, password-handling algorithms and
even how users are permitted to select passwords. Using
password lists from four diﬀerent web sites, we investigate if
Zipf’s law is a good description of the frequency with which
passwords are chosen. We use a number of standard statis-
tics, which measure the security of password distributions,
to see if modelling the data using a simple distribution is
eﬀective. We then consider how much the password dis-
tributions from each site have in common, using password
cracking as a metric. This shows that these distributions
have enough high-frequency passwords in common to pro-
vide eﬀective speed-ups for cracking passwords. Finally, as
an alternative to a deterministic banned list, we will show
how to stochastically shape the distribution of passwords,
by occasionally asking users to choose a diﬀerent password.

Categories and Subject Descriptors
K.6.5 [Computing Milieux]: Security and Protection

General Terms
Security, Human Factors, Algorithms

Keywords
passwords, distribution, Zipf, dictionary attack

1.

INTRODUCTION

Passwords are one of the most common forms of authenti-
cation that users encounter, particularly on the web. While
there is a large literature of advice on how to choose pass-
words (e.g. [11]), there are many reasons not to follow it. It
has even been argued that in general, the cost of following
such advice is greater than the cost of losing the information
being protected [7]. Consequently, rather than a theoreti-
cally desirable uniform distribution, we see that some pass-
words are signiﬁcantly more common than others. In this
paper we investigate frequency distributions that passwords
are chosen with. We consider abstract issues, such as how to
model the distribution and practical problems, such as the
password cracking and how to improve users’ choices.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2012, April 16–20, 2012, Lyon, France.
ACM 978-1-4503-1229-5/12/04.

One interesting candidate to model this distribution is
Zipf’s Law. Zipf’s Law is a probability distribution where
the frequency of an event is inversely proportional to its rank
on the frequency table. Here the rank of the most common
event is 1, the rank of the second most common is 2, and
so on. Zipf’s Law has been observed in the frequencies with
which words are used in natural language. While there are a
number of substantial diﬀerences between the choice of pass-
words and the use of words in natural language, Zipf’s Law
has the potential to capture the skewed nature of the pass-
word distribution. We expect that rather than uniformly
choosing from a list of non-dictionary words, the average
user is likely to choose a password which they can easily re-
member (their name, city, favourite team, . . . ) which leads
to certain passwords being used more frequently than others.
To study this, we use lists of users and passwords from
hotmail.com, ﬂirtlife.de, computerbits.ie and rockyou.com,
which are described in Section 2. In each case, the list of
usernames and passwords were made public after a security
incident. Our Zipf model has frequencies proportional to
r−s, where r is the rank of a password and s is a parameter
close to one. In Section 3 we analyse our datasets and ﬁt
a value for s. We will see that, while a Zipf distribution
does not fully describe our data, it provides a reasonable
model, particularly of the long tail of password choices. To
our knowledge, this is the ﬁrst paper to study if Zipf’s Law
applies to the choice of passwords.

Seeing Zipf’s Law, or any other distribution that is indeed
skewed in favour of a subset of passwords, has implications
for security.
If the right distribution of passwords can be
identiﬁed, the cost of guessing a password can be reduced.
One expects that, say, the demographic of users of a site
could be used to target an attack; a website with a .ie domain
is more likely to have Irish themed passwords than a site
with a .fr domain. A heavy-tailed distribution of password
choices could be exploited by algorithm designers to more
eﬃciently deal with passwords (e.g. algorithms in [15]).

To establish if models such as a Zipf distribution can pro-
vide useful predictions, in Section 4 we use metrics such as
guesswork [13] and Shannon entropy. We calculate these
metrics for both the ﬁtted model and the actual data, and
compare the results. We ﬁnd that the actual metrics are
within a factor of two of those predicted by the Zipf dis-
tribution, and that the Zipf model usually provides better
predictions than a simple uniform model.

In Section 5 we study a more important question: how
much does one set of password choices tells us about general
password choices. We compare the similarity of our data sets

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France301Site

#users

#pass

hotmail
ﬂirtlife
computerbits
rockyou

7300
98930
1795
32603043

6670
43936
1656
14344386

#pass
#users
0.91
0.44
0.92
0.44

1: Number of users and distinct passwords for each site.

using guessing as a metric. We show that by using common
passwords from one list, an attacker can obtain a speed up
when guessing passwords from another list, in some cases an
order of magnitude faster than techniques assessed in [4].

Finally, in Section 6, we introduce a defensive technique
for making the passwords in use more uniform. When a user
sets or resets a password, the technique probabilistically asks
them to choose a diﬀerent password. This technique uses
the Metropolis-Hastings algorithm [6, 12] and produces a
more uniform distribution of used password by stochastically
limiting their frequency, rather than imposing hard limits as
discussed in [15].

2. OVERVIEW OF DATASETS

We collected sets of passwords belonging to sites which
were compromised and the lists of passwords subsequently
publicly leaked. Since the sets were gathered by diﬀer-
ent methods (e.g. key-logging, network sniﬃng or database
dumps) the lists may only contain a random, and possibly
biased, sample of users. Our lists are from hotmail.com in
2009, ﬂirtlife.de in 2006, computerbits.ie in 2009 and rock-
you.com in 2009.

Some of the lists also give multiple passwords for a small
number of users.
In this case, we cleaned up the sets by
taking the user’s password as the last entry seen for that
user, which would hopefully correspond to a user initially
typing the wrong password and then typing the correct one,
or in the case that the password was changed, the most re-
cent password. We also omitted any user with a whitespace
password. After the data was cleaned up, we produced a
table ranking passwords in order of decreasing frequency of
use by users. Table 1 shows the number of users and the
number of distinct passwords for each set of data. As is
obvious from the table, for smaller lists there are relatively
more unique passwords.

Table 2 summarises the top 10 passwords in each list. We
see that passwords such as 123456 and password are very
common. The most common password, “123456” accounts
for 0.7% of the total passwords in the hotmail data, 3.3%
in the ﬂirtlife list and 2.0% in the rockyou list; “password”
accounts for 1.2% of the total passwords of the computerbits
list. This indicates that the password distribution is skewed
in favour of some common passwords.

The demographic of the users from each list is evident in
the ﬁrst 10 passwords of the lists with each ccTLD. Note that
the hotmail.com data is believed to have been collected with
phishing targeted at the Latino community. The ﬂirtlife list
shows clear signs of users speaking German and Turkish, and
the computerbits list contains place names of Irish interest.
If we look at the data from computerbits and rockyou we
see that the name of the website appears in the top ten of
each list.
It seems likely that this method for choosing a
password will also be used on other sites.

hotmail
0.16

ﬂirtlife
0.64

c-bits
0.15

rockyou
0.51

0.44

2.46

3.07

3.27

0.69

0.45

1.72

2.56

2.32

3.10

2.45

3.22

0.78

1.37

2.23

2.28

s
raw
s
binned
−m
raw−m

binned
1 + 1/s
binned

3: Parameters for Zipf distribution, estimated by least
squares ﬁts to frequency and nk vs. k graphs.

Knowing the demographic of the users of a site, one could
build a dictionary covering the most likely common pass-
words in use. This implies that users, if they are concerned
about their accounts being hacked, should use less common
passwords. Advice such as changing some of the charac-
ters to upper-case or writing the word in ‘leet speak’, aims
to move the password out of the most-common list. These
results also conﬁrms something that system administrators
have observed empirically, that including a localised dictio-
nary when checking password hashes with crack will usually
increase the number of recovered passwords.

3. DISTRIBUTION OF PASSWORDS

In this section we look at how passwords are distributed in
our lists, and see how well these distributions match a Zipf
model. We will be interested in the frequency fi with which
we see the ith
most popular password. Where passwords are
seen equal numbers of times, we break the tie randomly.

It turns out to be not that helpful to plot the rank vs.
frequency of our data on a linear scale. There are a small
number of passwords with a high frequency, and many pass-
words with a frequency of 1 or 2, which makes the graphs
illegible. Instead, we plot the frequency versus rank on a log-
log scale in Figure 1. These graphs certainly show evidence
of heavy-tailed behaviour, with the frequency dropping more
slowly than exponentially. A Zipf distribution would appear
as a straight line on a log-log plot, where the parameter s is
the negative of the slope.

If we ﬁt a least-squares line to this data, as shown in
Figure 1, we get a slope which is too shallow because a large
fraction of the points have frequency 1 or 2, which biases the
slope towards 0. To account for this, we follow the method in
[1] and bin the data logarithmically, as shown in Figure 2.
Here, we sum the frequency of all ranks between 2n and
2n+1 − 1. We see that this gives us a slope which better ﬁts
our data, and that the line appears a relatively good ﬁt. We
use this binned slope as a basis for modelling our data with
a Zipf distribution.

An alternate way to view the data is to look at the number
of passwords nk that are each used by exactly k users. We
plot this in Figure 3 on a log-log scale. As explained in [1], if
the data is Zipf-distributed, we expect this graph to also be
a straight line with slope −(1 + 1/s). As we can see, we also
need to bin this data before ﬁtting a line. If we do this, we
see a line is a relatively good ﬁt, with the largest discrepancy
appearing for computerbits, the smallest list. The resulting
slopes are summarised in Table 3.

We can also build a maximum liklihood estimator (MLE)

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France302least squares s=0.16

 100

 10

 1

y
c
n
e
u
q
e
r
F

 0.1

 1

 10

 100
Rank

 1000

 10000

(a) hotmail

least squares s=0.15

 100

 10

 1

y
c
n
e
u
q
e
r
F

 0.1

 1

 10

 100
Rank

 1000

 10000

(c) computerbits

y
c
n
e
u
q
e
r
F

y
c
n
e
u
q
e
r
F

 10000

 1000

 100

 10

 1

 0.1

 1

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0.1

least squares s=0.64

 10

 100

 1000

 10000

 100000

Rank
(b) ﬂirtlife

least squares s=0.51

 1

 10

 100  1000  10000 100000 1e+06 1e+07 1e+08

Rank
(d) rockyou

1: Plot of plot rank vs. frequency on log-log scale

least squares s=0.44

 100

 10

 1

y
c
n
e
u
q
e
r
F

 0.1

 1

 10

 100

 1000

 10000

Rank (binned)

(a) hotmail

least squares s=0.45

 100

 10

 1

y
c
n
e
u
q
e
r
F

y
c
n
e
u
q
e
r
F

y
c
n
e
u
q
e
r
F

 0.1

 1

 10

 100

 1000

 10000

Rank (binned)

(c) computerbits

least squares s=0.69

 10000

 1000

 100

 10

 1

 0.1

 1

 10

 100
 1000
Rank (binned)

 10000

 100000

(b) ﬂirtlife

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0.1

least squares s=0.78

 1

 10

 100  1000  10000 100000 1e+06 1e+07 1e+08

Rank (binned)

(d) rockyou

2: Exponentially binned plot of Figure 1

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France303Rank
1
2
3
4
5
6
7
8
9
10

hotmail
123456
123456789
111111
12345678
tequiero
000000
alejandro
sebastian
estrella
1234567

#users
48
15
10
9
8
7
7
6
6
6

ﬂirtlife
123456
ﬁcken
12345
hallo
123456789
schatz
12345678
daniel
1234
askim

#users
computerbits #users
1432
20
password
407
10
computerbits
365
123456
7
348
6
dublin
258
5
letmein
230
4
qwerty
223
4
ireland
3
185
1234567
175
liverpool
3
3
171 munster

rockyou
123456
12345
123456789
password
iloveyou
princess
1234567
rockyou
12345678
abc123

#users
290729
79076
76789
59462
49952
33291
21725
20901
20553
16648

2: Top 10 Passwords for each list

 10000

 1000

 100

k
n

 10

 1

 0.1

 0.01

 1

 10000

 1000

 100

k
n

 10

 1

 0.1

 1

least squares m=-1.72

 100000

 10000

 1000

 100

 10

 1

 0.1

k
n

 100

 0.01

 1

 10

 100

 1000

 10000

least squares m=-2.46

 10
k

(a) hotmail

least squares m=-2.56

k
n

 1e+08
 1e+07
 1e+06
 100000
 10000
 1000
 100
 10
 1
 0.1
 0.01
 0.001

k
(b) ﬂirtlife

least squares m=-1.37

 1

 10

 100

 1000

 10000  100000  1e+06

k

(d) rockyou

 10
k

 100

(c) computerbits

3: Plot of k vs. nk on log-log scale.

for a truncated Zipf distribution, which assigns probability
proportional to r−s to passwords with rank r = 1 . . . N . The
MLE for N is just the number of passwords with non-zero
frequency and the MLE for s can be constructed using stan-
dard techniques as described in [3]. This has the advantage
of providing both estimates of the standard error in s and a
p-value1. The results are shown in Table 4.

We see that the estimates for s provided by the MLE
for the ﬂirtlife and rockyou data are quite close to those
provided by least-squares estimate. The MLE estimates for
s for the smaller data sets are between the binned values
(around 0.45) and the raw values (around 0.15). We see
that the p-values indicate that the hotmail, computerbits
and rockyou data are unlikely to actually be Zipf distributed.
However, for the hotmail and computerbits data the largest

1P-values are calculated by generating samples using a Zipf
with the estimated parameters, applying the same sorting
and estimation. We then calculate the fraction which exceed
the Anderson-Darling statistic of our actual data.

s
MLE
s
stderr
p-value

hotmail
0.246

ﬂirtlife
0.695

c-bits
0.23

rockyou
0.7878

0.009

0.001

0.02 < 0.0001

< 0.01

0.57 < 0.01

< 0.01

4: Parameters for Zipf distribution, estimated by MLE.

discrepancy between the Zipf’s Law and the data is for the
ﬁrst few passwords, indicating that the tail of the data could
pass for Zipf with a higher p-value.

To summarise, we have seen that the password frequency
data has heavy-tailed characteristics by plotting it on a log-
log plot. Both least-squares and maximum-liklihood esti-
mates indicate that if Zipf distributed, the s parameter is
small. However, p-values indicate the data is unlikely to be
drawn exactly from Zipf’s Law.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France3044. PASSWORD STATISTICS

In this section we will look at a number of statistics rele-
vant to passwords that can be derived from the distribution
of how passwords are chosen. We will look at these statistics
when calculated directly from our lists, and compare the re-
sults when they are calculated using two models: Uniform
and Zipf. For the real lists, we calculate our statistics as-
suming the probability of the password of rank i appearing is
fi/N , where fi is the frequency with which we observed that
password and N is the total number of passwords observed.
The ﬁrst model assumes password choices are uniform over
all passwords seen, i.e., if the number of passwords is N
then a password is chosen with probability 1/N . The second
model assumes that password choices are distributed with a
Zipf distribution, i.e., the probability of password with rank
i being used is Pi = Ki−s, where s is the parameter found
in Section 3 and K is a normalising constant.

Now let us describe the statistics of interest. The ﬁrst
statistic is the guesswork, which is the mean number of
guesses needed to correctly guess the password [13], when
the ranked list of passwords is known, but the exact pass-
word is not. Guesswork is given by, G =
i=1 iPi, where Pi
is the probability of the password of rank i. This statistic
places considerable emphasis on the tail of the distribution,
and can be sensitive to relatively small gaps between the
model and the data.

PN

Another strategy for guessing passwords, given the distri-
bution, is to try the common passwords, but to give up when
some fraction α of the distribution has been covered. The
Prα
mean number of guesses associated with this is known as the
α-guesswork, Gα [13]. Its value is given by, Gα =
i=1 iPi,
where rα is the rank of the password when the cumulative
probability of being successful is at least α. We will work
with α = 0.85, so that we cover most of the distribution,
but avoid the tail.

The Shannon Entropy, H = −P

Pi log2 Pi, is a common
measure of the number of bits of uncertainty associated with
a random variable. While Shannon Entropy has been used
as a measure of security of password and key distributions, it
does not relate directly to how easy it is to guess a password
[10, 8]. R´enyi entropy, which is a generalisation of Shannon
Pi)2. It is asymptoti-
entropy, is given by R = log2(
cally related to the guessability of a password [2, 9]. The
min-Entropy is also used as a conservative measure of pass-
word/key security [5].

P√

Figure 4 compares the guesswork statistics for the uniform
model, the real data and the Zipf model. The three bars on
the left show the guesswork and the three on the right show
the 0.85-guesswork. As expected, the guesswork estimates
for the uniform model overestimate the required number of
guesses. A relatively small percentage of the total number
of passwords in the hotmail.com and computerbits.ie lists
are shared. This seems to be reﬂected in the predictions for
guesswork, where the uniform distribution provides a rela-
tively good prediction for hotmail and computerbits, while
the Zipf model underestimates. For ﬂirtlife and rockyou,
shared passwords make up a larger percentage of the total
passwords, and the guesswork is far lower than the uniform
guesswork, but the Zipf model provides better predictions,
though it still underestimates.

Figure 5 shows the Entropy values for the actual data and
models. Shannon Entropy is shown on the left, min-Entropy
in the middle and R´enyi Entropy on the right. The Uniform

model, again as expected, tends to overestimate the Entropy.
However, for the R´enyi Entropy both models and the data
seem to give results that are close together. The Zipf model
seems to provide relatively good approximations in all cases.

5. RELATION BETWEEN DISTRIBUTIONS
While the popular passwords in our lists have things in
common (e.g., the password 123456), they also show fea-
tures speciﬁc to the website or service. In Section 3 we also
saw that all lists have a number of relatively frequently used
passwords followed by a long tail of uncommon passwords.
In this section, we would like to quantify how much in com-
mon there is between the passwords in these lists.

Pt

Consider the problem of guessing the password of a ran-
domly selected user from one of our lists. If we guess the
passwords in the order from most popular to least popular
in that list, then after t guesses we will have guessed the
passwords used by C(t) =
i=1 fi users. If we guess one
password at each trial, guessing in this order recovers users’
passwords as quickly as possible, and is in this sense optimal.
Figure 6 shows C(t) as a solid line for each of our datasets.
The right-hand axis is scaled to show C(t)/N , which we
can interpret as the probability of successfully guessing in t
guesses or the fraction of users whose passwords have been
guessed. For example, after 100 guesses using the hotmail
data, we have recovered around 400 users’ passwords, which
is a 5% probability of success against a particular user. Since
we guess in the optimal order, other orderings recover fewer
users and have a lower probability of success.

Pt

If we do not know the optimal order in which to guess the
passwords, we may instead guess them in the optimal order
for another reference data set. Suppose we have a password
of rank i in the reference data set, and it has rank σ(i) in the
data set being guessed. If we guess in the order given by the
reference data set, after t guesses, we will have guessed the
passwords of C(t||σ) =
i=1 fσ(i) users, where we assume
fσ(i) is zero if password i is not in the list we are guessing.
If the ordering of the passwords by popularity is the same
for both lists, then this function will be C(t||σ) =C (t),
otherwise C(t||σ) ≤ C(t).
Figure 6 shows C(t||σ) for each of our lists, when using
each of the other lists as a reference. Consider the situation
after 1000 trial guesses. The number of users whose pass-
words match one of these 1000 guesses, C(1000||σ), can be
seen to vary by almost an order of magnitude, depending
on the list used as a reference. Thus, to guess passwords
quickly, we would like a good reference list.

Observe that for any list, once we have made more than
10–100 guesses, the larger reference lists lead to more suc-
cesses than smaller lists. This suggests that beyond the most
popular passwords, there may be a more general ordering of
passwords that is more apparent from the larger data sets.
The top one million rockyou passwords cover close to 40%
of users in the other lists.

In practice, the number of guesses that can be made de-
pends on the details of the attack. An attacker targeting a
single online account from one IP, might ﬁnd the account
locked after a small number of guesses. However, if the
attacker is cycling through many users from a number of
vantage points, the number of guesses could be considerably
higher: the attempts may only be limited by the amount of
CPU time available to the attacker.

We can apply this directly to a password cracking prob-

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France305s
e
s
s
e
u
G

s
e
s
s
e
u
G

s
t
i

B

s
t
i

B

 3500

 3000

 2500

 2000

 1500

 1000

 500

 0

 900

 800

 700

 600

 500

 400

 300

 200

 100

 0

 14

 12

 10

 8

 6

 4

 2

 0

 12

 10

 8

 6

 4

 2

 0

Uniform model Guesswork
Real data Guesswork
Zipf model Guesswork
Uniform model 0.85 Guesswork
Real data 0.85 Guesswork
Zipf model 0.85 Guesswork

(b) ﬂirtlife

Uniform model Guesswork
Real data Guesswork
Zipf model Guesswork
Uniform model 0.85 Guesswork
Real data 0.85 Guesswork
Zipf model 0.85 Guesswork

Uniform model Guesswork
Real data Guesswork
Zipf model Guesswork
Uniform model 0.85 Guesswork
Real data 0.85 Guesswork
Zipf model 0.85 Guesswork

(a) hotmail

Uniform model Guesswork
Real data Guesswork
Zipf model Guesswork
Uniform model 0.85 Guesswork
Real data 0.85 Guesswork
Zipf model 0.85 Guesswork

s
e
s
s
e
u
G

s
e
s
s
e
u
G

 25000

 20000

 15000

 10000

 5000

 0

 8e+06

 7e+06

 6e+06

 5e+06

 4e+06

 3e+06

 2e+06

 1e+06

 0

(c) computerbits

(d) rockyou

4: Guesswork statistics for Uniform model, Real data and Zipf model.

Uniform model Entropy
Real data Entropy
Zipf model Entropy
Uniform model Min Entropy
Real data Min Entropy
Zipf model Min Entropy
Uniform model Renyi
Real data Renyi
Zipf model Renyi

(b) ﬂirtlife

Uniform model Entropy
Real data Entropy
Zipf model Entropy
Uniform model Min Entropy
Real data Min Entropy
Zipf model Min Entropy
Uniform model Renyi
Real data Renyi
Zipf model Renyi

Uniform model Entropy
Real data Entropy
Zipf model Entropy
Uniform model Min Entropy
Real data Min Entropy
Zipf model Min Entropy
Uniform model Renyi
Real data Renyi
Zipf model Renyi

(a) hotmail

Uniform model Entropy
Real data Entropy
Zipf model Entropy
Uniform model Min Entropy
Real data Min Entropy
Zipf model Min Entropy
Uniform model Renyi
Real data Renyi
Zipf model Renyi

s
t
i

B

s
t
i

B

 16

 14

 12

 10

 8

 6

 4

 2

 0

 25

 20

 15

 10

 5

 0

(c) computerbits

(d) rockyou

5: Entropy values for Uniform model, Real data and Zipf model.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France306optimal guessing
guesses from rockyou
guesses from flirtlife
guesses from computerbits
40%

optimal guessing
guesses from rockyou
guesses from hotmail
guesses from computerbits
40%

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

guesses

(a) hotmail

guesses

(b) ﬂirtlife

1e+03

1e+02

s
r
e
s
u

1e+01

1e+00

1e+03

1e+02

s
r
e
s
u

1e+01

1e+00

1e+00

1e+05

1e-01

1e-02

1e-03

s
r
e
s
u
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

s
r
e
s
u

1e+04

1e+03

1e+02

1e+01

1e+00

1e+00

1e-01

1e-02

1e-03

s
r
e
s
u
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

1e+07

1e+06

1e+05

1e+04

1e+03

1e+02

1e+01

s
r
e
s
u

1e+00

1e+00

1e-01

1e-02

1e-03

1e-04

s
r
e
s
u
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

1e-05

1e+00

1e-01

1e-02

1e-03

1e-04

1e-05

1e-06

1e-07

s
r
e
s
u
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

optimal guessing
guesses from flirtlife
guesses from hotmail
guesses from computerbits
40%

optimal guessing
guesses from rockyou
guesses from flirtlife
guesses from hotmail
40%

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

guesses

(c) computerbits

guesses

(d) rockyou

6: Number of users whose passwords are recovered by using the password ordering from one distribution to guess another.

1e+05

1e+04

s
r
e
s
u

1e+03

1e+02

1e+01

1e+00

1e+00

1e-01

1e-02

1e-03

1e-04

1e-05

s
r
e
s
u

 
f

o

 

n
o

i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

guesses from rockyou
guesses from flirtlife
guesses from hotmail
guesses from computerbits
guesses from dictionary
40%

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

guesses

7: Number of users whose passwords are cracked by us-
ing the password ordering from diﬀerent distribution on the
Gawker.com password hashes.

lem. In December 2010, the password database from Gawker.com
was leaked. This database did not contain plaintext pass-
words, but instead contained hashes of passwords using the
well-known DES and Blowﬁsh password hashing schemes.
We can use the words in our list as guesses in an oﬀ-line
cracking attack against the Gawker hashes.

The Gawker dataset contained 748,090 users potentially
valid (i.e. 13 character) DES hashes. The hashes use 3844
diﬀerent salts. A simple perl script can attempt password
guesses at a rate of approximately 80,000 trials per hour
per core on a modern CPU. As the DES hash truncates
passwords to 8 characters, we truncate long passwords and
reaggregate our previous lists. The number of users whose
passwords were cracked after t trials is shown in Figure 7.

Again, the large lists provide the fastest recovery of pass-
words, and recovers 40% of users in less than one million
trials. Even our smaller lists do well, recovering the pass-
words of more than 10,000 users in around 1,000 trials (less
than one minute of CPU time).

For comparison, in Figure 7 we show the results of using
a dictionary in lexical order as list of guesses. The dictio-
nary is based on the contents of /usr/share/dict/ on Mac
OS X, truncated to 8 characters and sorted using the Unix
sort command. This results in a return on eﬀort that is
substantially lower than with ranked password lists.

Up to now, we have measured the eﬀectiveness of guessing
passwords by counting the number of distinct users whose
passwords would have been correctly guessed after t guesses.
An alternative metric counts the number of distinct pass-
words that have been correctly guessed after t guesses. Note,
we recover either zero or one password at each guess.

Figure 8 shows results for our main lists. The optimal
rate at which we can recover passwords is 1 per guess, so
we plot the optimal line y = x. We see that with about
500,000–5,000,0000 guesses we obtain about 40% of the pass-
words, except when guessing rockyou passwords, when the
other lists simply do not have enough guesses to reach 40%.
Despite this, when guessing passwords from the rockyou
dataset, the curves for the other lists stay close to the opti-
mal line, showing that there is a good return for each guess.
Figure 9 shows the results for guessing the Gawker pass-
words, in terms of fraction of passwords recovered. As not
all hashes have been cracked and the hashes are salted, we
do not know the total number of distinct passwords. How-
ever, we can upper bound the number by assuming that all
uncracked passwords are unique.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France307optimal guessing
guesses from rockyou
guesses from flirtlife
guesses from computerbits
40%

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

guesses

(a) hotmail

guesses

(b) ﬂirtlife

1e+03

1e+02

s
d
r
o
w
s
s
a
p

1e+01

1e+00

1e+03

1e+02

1e+01

s
d
r
o
w
s
s
a
p

1e+00

1e+00

1e-01

1e-02

1e-03

s
d
r
o
w
s
s
a
p
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

1e+04

1e+03

1e+02

1e+01

s
d
r
o
w
s
s
a
p

1e+00

1e+00

1e-01

1e-02

1e-03

s
d
r
o
w
s
s
a
p
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

1e+07

1e+06

1e+05

1e+04

1e+03

1e+02

1e+01

s
d
r
o
w
s
s
a
p

1e+00

1e+00

1e-01

1e-02

1e-03

1e-04

optimal guessing
guesses from rockyou
guesses from hotmail
guesses from computerbits
40%

1e+00

1e-01

1e-02

1e-03

1e-04

1e-05

1e-06

1e-07

optimal guessing
guesses from flirtlife
guesses from hotmail
guesses from computerbits
40%

s
d
r
o
w
s
s
a
p
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

s
d
r
o
w
s
s
a
p
 
f
o
 
n
o
i
t
c
a
r
f
 
/
 
y
t
i
l
i

b
a
b
o
r
p

optimal guessing
guesses from rockyou
guesses from flirtlife
guesses from hotmail
40%

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

1e+00 1e+01 1e+02 1e+03 1e+04 1e+05 1e+06 1e+07 1e+08

guesses

(c) computerbits

guesses

(d) rockyou

8: Number of passwords recovered by using the password ordering from one distribution to guess another.

s
d
r
o
w
s
s
a
p

1e+05

1e+04

1e+03

1e+02

1e+01

1e+00

1e+00

1e+01

1e+02

1e+03

optimal
guesses from rockyou
guesses from flirtlife
guesses from hotmail
guesses from computerbits
guesses from dictionary
upper limit on 40%

1e+04
guesses

1e+05

1e+06

1e+07

1e+08

9: Using orderings from each list to crack Gawker hashes.

First we note that using other password lists to guess still
provides signiﬁcantly better return than using a dictionary.
Indeed, the curves stay relatively close to the optimal line for
guesses based on the rockyou data set for between 10 and
10,000 guesses, indicating a success rate of almost 100%.
After using all 14 million passwords in this list, we have
cracked close to 40% of the passwords. The curve for dic-
tionary words stays a signiﬁcant distance from the optimal
line, suggesting less than 10% of dictionary words are actu-
ally used as passwords in the Gawker data set.

In [4], the authors consider various techniques for generat-
ing candidate passwords for guessing/cracking. These tech-
niques include dictionary attacks, mangled dictionaries and
Markov generators, which can be trained on sample pass-
words. They assess these techniques using the fraction of
passwords recovered in three data sets. They show that

in order to recover a substantial fraction of passwords, say
40%, the number of required guesses is over 100 million, un-
less the candidate-password-generating technique is trained
on a similar dataset. Our results show that the use of a large
set of passwords as a source of guesses seems to oﬀer con-
siderably better returns than these techniques, being able to
recover 40% of passwords in a less than 10 million guesses.
Of course, once exhausted, a list provides no more candidate
guesses, whereas the mangling and Markov techniques can
theoretically yield unbounded candidate sets.

6. MAKING CHOICES MORE UNIFORM
We have seen that people’s choice of passwords is non-
uniform, leading to some passwords appearing with a high
frequency. The previous section demonstrated one conse-
quence of this: a relatively small number of words can have
a high probability of matching a user’s password. To combat
this, sites often ban dictionary words or common passwords
(e.g. the Twitter banned password list [16]), in an eﬀort to
drive users away from more common passwords.

If password choices were uniform (over a large set of pass-
words) some attacks based on the existence of common pass-
words become ineﬀective. With this in mind, a scheme was
suggested in [15] which prevents users from choosing par-
ticular passwords when they become relatively too popular,
to reduce the non-uniformity of the password distribution.
We consider an alternative way to address this problem, by
treating users as biased random password generators.

There are well-known schemes that take the output from
a random generator and manipulate it to achieve a diﬀerent
distribution. For example, the Metropolis-Hastings scheme
[6, 12] allows the generation of a desired distribution P (.) by

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France308probabilistically accepting/rejecting the steps of a Markov
chain Q(., .).
It has the property that the density of the
desired distribution does not need to be known, as long as
a function proportional to the density is known.

The basic Metropolis-Hastings scheme is as follows:
1. Set t ← 0, choose any xt.
2. Generate x(cid:2)

with distribution Q(x(cid:2), xt).
”
Q(xt,x(cid:2))
Q(x(cid:2),xt)

1, P (x(cid:2))

“

3. With probability min

P (x)

go to step 4

(accept), otherwise return to step 2 (reject).

4. t ← t + 1, xt ← x(cid:2)

.

where the terms of the sequence xt are the output. Usu-
ally, the initial outputs are discarded, to wash out the initial
choice of x0 and allow the sequence to approach its station-
ary behaviour. This is sometimes referred to as burn in.

We can apply this scheme to produce a more uniform
choice of passwords. Our desired distribution P (.) will be
uniform over all passwords that users are willing to use, so
P (x(cid:2)
)/P (x) = 1. Suppose that if a user is asked to choose
a password that they choose it independently of previous
choices with probability Q(.). Though we do not know Q(.),
we make an online estimate of it, by tracking the frequency
F (.) with which users attempt to use particular passwords.
This suggests the following scheme that could be applied
when users select a password as part of a password set/reset
procedure:

1. Uniformly choose x from all previously seen passwords.
2. Ask user for a new password x(cid:2)
3. Generate a uniform real number u in the range [0, F (x(cid:2)
)]
). If u ≤ F (x) go to step 4

and then increment F (x(cid:2)
(accept), otherwise return to step 2 (reject).

.

4. Accept use of x(cid:2)

as password.

This scheme aims to generate a uniform distribution via
users’ choices using a Metropolis-Hastings scheme. There
are a few things to note. First, by choosing x uniformly over
all seen passwords, we aim to avoid the need for a burn-in
period, because we begin with a choice drawn from the dis-
tribution we want. Second, the password x is never actually
used, only its frequency F (x), so we can use 0 for F (x) if the
scheme has seen no previous passwords. Finally, the scheme
learns F (.) on-line, so the more password choices it sees, the
better we expect it will be at making choices uniform.

We implemented this scheme and tested it by choosing
passwords from the rockyou dataset, where the probability
a password was selected was proportional to its frequency
in the dataset. We generated passwords for 1,000,000 users,
with the Metropolis-Hastings scheme and, for comparison,
when users were free to choose any password or when there
was a hard relative frequency limit on passwords.

The results are shown in Figure 10. We see that with the
Metropolis-Hastings scheme, the distribution is much more
uniform, and the frequencies of the most common passwords
have been reduced from over 1,000 to just over 10, a reduc-
tion of more than two orders of magnitude. One concern
with this scheme is that is may reject a user’s choice of
password many times, and frustrate the user. However, over
these trials, users are asked on average for 1.28 passwords

First Choice
Metropolis-Hastings Scheme
Hard limit 1/1000000

 10000

 1000

 100

 10

y
c
n
e
u
q
e
r
F

 1

 1

 10

 100

 10000  100000  1e+06

 1000
Rank

10: Plot of rank vs.
frequency for users generated from
rockyou dataset, with free choices, the Metropolis-Hastings
scheme and a hard relative frequency limit (similar to [15]).

with a variance of 0.61 (compared to 1.36 and 0.72 respec-
tively for a ﬁxed relative frequency limit of 1/1, 000, 000).

We note that the Metropolis-Hastings scheme has some
similarities to the scheme in [15]. Both schemes store fre-
quency information about passwords and guide users’ choices.
To avoid storing passwords in plain text, one could store the
frequency of hashed passwords. Our scheme, however, stores
the frequency with which users choose a password rather
than the frequency of passwords in use. This has some ad-
vantages if the frequency table is stolen by an attacker, as
even if the hashes can be cracked, frequent choices are not so
commonly used because of the Metropolis-Hastings scheme.
Rather than using a simple frequency table, both these
schemes can be implemented with count-min sketches. This
is an eﬃcient data structure that stores estimates of frequen-
cies. As described in [15], there are advantages to storing the
information in a sketch, particularly if the sketch is stolen by
an attacker. This is because it uses multiple hash functions
with a smaller output space, leading to false-positives if an
attacker tries to identify high-frequency passwords.

One diﬀerence in these schemes is that the Metropolis-
Hastings algorithm aims to make the whole distribution more
uniform, rather than limit the frequency of the most popular
passwords. As we saw in Section 5 mid-ranked passwords,
say from rank 10–1,000, are important for increasing the
success rate when guessing a user’s password; these guesses
increase the success probability from a fraction of a percent
up to a few percent. By moderating the frequency of these
passwords, we may reduce the eﬀectiveness of attacks that
use both high- and mid-ranked passwords.

We also note that while this scheme learns the password
frequency distribution on-line, it could also be initialised
using a known list of password frequencies. While we chose
to target a uniform distribution, this scheme could also be
combined with a list of banned passwords (by setting the
desired frequency P (x) to be zero) or implement a soft-ban
on some passwords (by reducing P (x) for those passwords).

7. DISCUSSION

We have seen that while Zipf’s law is not an exact match,
it seems to provide a passable description of the frequencies
with which passwords are chosen. Estimates of the param-
eter s are considerably less than one. While this might be
interpreted as indicating a strongly heavy tailed behaviour,
another interpretation is that as s → 0 the distribution be-

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France309comes uniform, which is actually desirable for passwords.
These observations may be of use to algorithm designers,
for dimensioning data structures or even taking advantage
of the relatively heavy-tailed nature of users’ choices.

We also see that ﬁtting a distribution provides relatively
good approximations of the Shannon Entropy, guesswork
and other statistics that are of interest when assessing a
password distribution. Using a uniform model, where all
passwords are equally likely, provides reasonable approxima-
tions for the data sets with smaller s, but provides a poor
estimate of min-Entropy.

We have seen that demography of the userbase choosing
the passwords can be evident in the most popular passwords,
and even the name of the website is a likely password. Some
sites, for example Twitter, have noticed this and implement
banned password lists [16], which includes many of the more
common passwords, including the name of the site. This
gives weight to the advice that site administrators checking
the security using password cracking software should include
custom dictionaries including locally used terms.

The Zipf distribution decays relatively slowly, so we expect
there to be a large number of relatively commonly chosen
passwords. We investigated if these passwords vary signiﬁ-
cantly from site to site. We see that the lists of passwords
from each site have quite a lot in common. While they
do not provide the optimal order for guessing, the larger
lists provide good guidance about the ranking of passwords
in other lists. We’ve demonstrated that this can provide a
signiﬁcant speedup in guessing or cracking passwords using
moderate numbers of guesses, particularly over simple dic-
tionary attack, but also over a range of the guess-generating
techniques described in [4].

An attacker can gain a useful starting point for cracking
passwords if they collect leaked passwords. If a hashed pass-
word is exposed, the time for an attacker to hash, say, 20 mil-
lion passwords is relatively small, even on a single CPU. We
note that this adds extra weight to the advice that reusing
passwords between websites is a risk, even if there is no way
for an attacker to identify which pairs of users are common
to the websites. This is because if just one site stores the
password in plaintext format and that password is leaked,
then it facilitates the subsequent cracking of that password
on systems where the passwords are hashed.

Banning more commonly chosen passwords may result in
a more even spread of password in use.
Interestingly, we
saw that most English dictionary words are not necessar-
ily common passwords: out of more than 220,000 dictionary
words, less than 15,000 appeared as passwords in the Gawker
data set. We proposed a scheme based on the Metropolis-
Hastings algorithm that aims to generate more uniform pass-
word choices, without having to know a list of common
passwords in advance. A basic implementation of this is
relatively straight forward, and could be easily incorporated
into a password management system or PAM module [14].

8. CONCLUSION

We have seen that a Zipf distribution is a relatively good
match for the frequencies with which users choose pass-
words. We have also seen that the passwords found in the
lists that we have studied have relatively similar orderings.
Consequently, passwords from one list provide good can-
didates when guessing or cracking passwords from another

list. Finally, we presented a scheme that can guide users to
distribute their passwords more uniformly.

Acknowledgment: We thank Ken Duﬀy and Niall Murphy
for thought-provoking comments and Dermot Frost for an
oﬀer of CPU cycles. The authors were supported by NUIM
SPUR, SFI 07/SK/I1216a and 08/SRC/I1403.

9. REFERENCES
[1] L. A. Adamic. Zipf, power-laws, and pareto-a ranking

tutorial. Xerox Palo Alto Research Center,
http://www.hpl.hp.com/research/idl/papers/
ranking/ranking.html, 2000.

[2] E. Arikan. An inequality on guessing and its

application to sequential decoding. IEEE Transactions
on Information Theory, 42, Janurary 1996.

[3] A. Clauset, C. Shalizi, and M. Newman. Power-law

distributions in empirical data. SIAM review,
51(4):661–703, 2009.

[4] M. Dell’Amico, P. Michiardi, and Y. Roudier.
Password strength: An empirical analysis. In
INFOCOM, pages 1–9, 2010.

[5] D. E. Eastlake, J. I. Schiller, and S. Crocker. RFC
4086: Randomness requirements for security. pages
1–47, 2005.

[6] W. Hastings. Monte carlo sampling methods using
markov chains and their applications. Biometrika,
57(1):97, 1970.

[7] C. Herley. So long, and no thanks for the externalities:

the rational rejection of security advice by users. In
Proceedings of the 2009 workshop on New security
paradigms, pages 133–144. ACM, 2009.

[8] D. Malone and W. Sullivan. Guesswork is not a

substitute for entropy. In Proceedings of the
Information Technology and Telecommunications
Conference, 2005.

[9] D. Malone and W. G. Sullivan. Guesswork and

entropy. IEEE Transactions on Information Theory,
50(3):525–526, 2004.

[10] J. L. Massey. Guessing and entropy. In In Proceedings

of the 1994 IEEE International Symposium on
Information Theory, page 204, 1994.

[11] M. McDowell, J. Rafail, and S. Hernan. Cyber

security tip.
http://www.us-cert.gov/cas/tips/ST04-002.html,
2009.

[12] N. Metropolis, A. Rosenbluth, M. Rosenbluth,

A. Teller, and E. Teller. Equation of state calculations
by fast computing machines. The journal of chemical
physics, 21(6):1087, 1953.

[13] J. O. Pliam. The disparity between work and entropy

in cryptology. Theory of Cryptography Library:
Record, pages 98–24, 1998.

[14] V. Samar. Uniﬁed login with pluggable authentication

modules (PAM). In Proc. CCS’96, pages 1–10, 1996.

[15] S. Schechter, C. Herley, and M. Mitzenmacher.

Popularity is everything: a new approach to
protecting passwords from statistical-guessing attacks.
In Proc. HotSec’10, pages 1–6, 2010.

[16] twitter.com. Source code from twitter registration
page. view-source:https://twitter.com/signup
(search for twttr.BANNED PASSWORDS), 2010.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France310