Is this App Safe? A Large Scale Study on Application

Permissions and Risk Signals

Pern Hui Chia
Q2S NTNU∗

Trondheim, Norway
chia@q2s.ntnu.no

Yusuke Yamamoto

Kyoto University
Kyoto, Japan

yamamoto@dl.kuis.

kyoto-u.ac.jp

N. Asokan

Nokia Research Center

Helsinki, Finland

n.asokan@nokia.com

ABSTRACT
Third-party applications (apps) drive the attractiveness of
web and mobile application platforms. Many of these plat-
forms adopt a decentralized control strategy, relying on ex-
plicit user consent for granting permissions that the apps
request. Users have to rely primarily on community rat-
ings as the signals to identify the potentially harmful and
inappropriate apps even though community ratings typi-
cally reﬂect opinions about perceived functionality or perfor-
mance rather than about risks. With the arrival of HTML5
web apps, such user-consent permission systems will become
more widespread. We study the eﬀectiveness of user-consent
permission systems through a large scale data collection of
Facebook apps, Chrome extensions and Android apps.

Our analysis conﬁrms that the current forms of commu-
nity ratings used in app markets today are not reliable in-
dicators of privacy risks of an app. We ﬁnd some evidence
indicating attempts to mislead or entice users into grant-
ing permissions: free applications and applications with ma-
ture content request more permissions than is typical; “look-
alike” applications which have names similar to popular ap-
plications also request more permissions than is typical. We
also ﬁnd that across all three platforms popular applications
request more permissions than average.

Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—Ac-
cess Controls; H.5.m [Information interfaces and pre-
sentation (e.g., HCI)]: Miscellaneous

General Terms
Security, Human Factors, Measurement

Keywords
Android Apps, Chrome Extensions, Facebook Apps, Appli-
cation Permissions, Privacy
∗

Centre for Quantiﬁable Quality of Service in Communi-
cation Systems (Q2S), Centre of Excellence, appointed by
the Research Council of Norway, is funded by the Research
Council, Norwegian University of Science and Technology
(NTNU) and UNINETT.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2012, April 16–20, 2012, Lyon, France.
ACM 978-1-4503-1229-5/12/04.

1.

INTRODUCTION

Ever since the personal computer changed the lives of
people around the world, we have become accustomed to
the notion of software applications. The personal computer
world started out with completely open platforms where all
applications (apps) ran with the same complete set of priv-
ileges available to the user. This quickly gave rise to the
phenomenon of malicious and inappropriate software [10].

Operating system and runtime platform security schemes
can be used to apply the principle of least authority to ap-
plications. Although various platform security schemes were
developed since the 1960s, they saw widespread deployment
only when they were incorporated into Java Security Archi-
tecture and into mobile device platforms [21]. All modern
mobile device application platforms incorporate permission-
based platform security schemes. Web application platforms
like Facebook and browser extension runtimes like Google
Chrome extensions also use permission-based platform secu-
rity. Some of these platforms such as Apple’s iOS rely on a
central authority to decide what permissions can be granted
to a given application. Others rely on the user making the
authorization decisions. We will call the former category
centralized permission systems and the latter user-consent
permission systems.

In the smartphone arena, centralized permission systems
are currently dominant, with the exception of the Android
platform. However several HTML5 APIs (e.g., the geoloca-
tion API) support a user-consent permission system. The
availability of comprehensive APIs including oﬄine caching
makes it possible for HTML5 web apps to oﬀer similar func-
tionality as native applications.
If HTML5 web apps be-
come dominant [23], their decentralized nature will also im-
ply that user-consent permission systems will become more
widespread.

Centralized permission systems take the burden of judg-
ment away from users. While this is a beneﬁt in terms of
usability, it is problematic if the judgment in question is sub-
jective. People and organizations may disagree on whether
a certain application is privacy-invasive or oﬀensive [8]. The
biggest problem in user-consent permission systems is that
users may become habituated to permission queries and may
carelessly click through them. Even careful users have to
make access control decisions based only on a few signals
such as the average numerical rating given by other users,
number of ratings and downloads. Users who care about
their privacy [7, 1], may not have the ability to protect it in
user-consent permission systems if the signals are unreliable
or can be manipulated by developers of malicious apps.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France311In this paper, we investigate the current state of risk sig-
naling on privacy intrusiveness of apps, and if there is any ev-
idence of attempts to mislead or entice users of user-consent
permission systems into compromising their privacy. Specif-
ically we ask:

1. Do popular apps ask for more permissions than is typ-

ical for apps in general?

2. Are currently available signals about an application
reliable in indicating privacy risks associated with that
application?

3. Do developers of free apps and those with mature con-

tent ask for more permissions than is typical?

4. Do apps with “look-alike names” (i.e., names similar to
popular apps) ask for more permissions than is typical?

Our paper is structured as follows. We start with a sur-
vey of related work in Section 2 and describing the data
collection processes in Section 3. We present a basic analy-
sis on app popularity, ratings and permissions in Section 4
before proceeding to evaluate the eﬀectiveness of current
risk signals (Section 5) and potential trends of enticements
and tricks (Section 6). We conclude by revisiting the above
four questions and discussing the implications and mitiga-
tion measures in Section 7.

2. RELATED WORK

With the growing popularity of Android, there have been
a number of publications on Android OS security and its
permission system. Enck et al. [12] proposed Kirin cer-
tiﬁcation to help identifying Android apps that request a
suspicious permission combination using a set of predeﬁned
rules. Barrera et al. [6] studied the relationship between
the permissions requested by 1,100 most popular and free
Android apps by machine learning and proposed a method-
ology to improve the expressiveness of app permissions with-
out increasing its overall complexity. Our study diﬀers from
theirs in that we do not look into the patterns of permis-
sion requests in details but we study the how the number of
permissions requested by apps correlate with several signals
(e.g., community ratings) that the users receive.

Felt et al. [17] studied the eﬀectiveness of permission sys-
tems on Android and Chrome platforms. Using 1,000 most
popular Chrome extensions, they pointed out that the ﬁrst
500 most popular extensions have requested signiﬁcantly
more permissions than the second 500 extensions. However,
they observed no diﬀerences between the 756 most popu-
lar and 100 most recent Android apps. With a much larger
dataset, our study shows that there is a positive correla-
tion between the number of installations and the number
of permissions requested by the app on all three web and
mobile application platforms: Facebook, Chrome and An-
droid.
In addition, we look into whether speciﬁc types of
apps, including those with mature content, those ﬂagged by
external ratings and those with suspicious look-alike names,
request for more permissions than is typical.

In comparison, fewer studies have investigated the Face-
book permissions. King et al. [20] conducted a survey on the
privacy knowledge, behaviors and concerns of Facebook app
users. Our study diﬀers from theirs in two ways. First our
analysis relies on a large scale data collection rather than

a self-reported survey. Second while they focused on the
interaction between user’s understanding, concerns and be-
haviors when using Facebook apps, we look at the availabil-
ity of reliable risk signals on Facebook (as well as Chrome
and Android) and how the absence of them may have been
exploited by some developers to entice or trick the users with
questionable apps.

Moore and Edelman [24] studied the ecosystem of the
typo-squatting fraud – the intentional registration of mis-
spellings of popular website addresses. They estimated that
at least 938,000 typo domains targeted the 3,264 popular
.com sites they studied. They also found that 80% of the
typo-squatting domains were supported through proﬁts from
advertising, typically from the pay-per-click advertisements.
Our study is one of the ﬁrst to analyze the naming exploita-
tions in apps. While we have not conducted an in-depth
analysis on the motivation and proﬁtability of such naming
tricks, we analyzed whether apps with look-alike names re-
quest for more permissions than is typical. A related work
is by Barrera et al. [5] which studied the problem of a non-
global app ID system for Android apps. They proposed
Stratus to standardize the app IDs across diﬀerent Android
marketplaces. Our analysis in this paper focuses on look-
alike names rather than look-alike app IDs. We expect the
users to pay less attention to app IDs especially on Facebook
and Chrome where the app IDs are in the form of a string
of random digits or characters.

3. DATA COLLECTION

We detail the data collection processes for Android apps,
Chrome extensions and Facebook apps in the following. We
share our datasets on our project site [25].

3.1 Android Apps

Prior studies on Android OS security (e.g., [6, 12, 16, 17])
have mainly focused on the most popular apps on Android
Market. In order to broaden the scope we used both the of-
ﬁcial Android Market [3] and AppBrain.com [4] to construct
two datasets Android (pop) and Android (new).

Android (pop) consists of popular Android apps selected
randomly from the top-selling-free and top-selling-paid list-
ings of Android Market, as well as the list of the most popu-
lar apps according to AppBrain.com on 15 June 2011. After
removing duplicates, it contains 650 unique apps (323 paid
and 327 free). Android (new) consists of 1210 new apps
(610 paid and 600 free) which ﬁrst appeared on the most-
recent-apps section of AppBrain.com in mid June 2011 and
were still available in early October. We kept track of these
new apps and updated our database accordingly for changes
in app details.

In addition to the above, to investigate the behavior of
apps with look-alike names, we collected also a separate
much larger dataset Android (mr). The dataset consists
of 20,500 new Android apps (11,095 free and 9,405 paid)
constructed from the list of 20 most recent apps according
to AppBrain.com on an hourly basis from mid August to
early October 2011.

The application information page on Android Market pro-
vides a number of details that we use in this paper, includ-
ing app installation count, average community rating, rat-
ing count, developer URL, price, content maturity level, and
permissions requested by the app.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France3123.2 Facebook Apps

We constructed the Facebook dataset by downloading the
entire list of 34,370 Facebook apps (app names, IDs, and
developer IDs) from SocialBakers [26], a portal providing
the usage statistics of various social media. We then at-
tempted to access the Facebook application page of each of
these (using the Watir [28] library to login to Facebook).
We excluded apps that have become unavailable or other-
wise invalid or redirected to a page outside Facebook. Out of
the remaining 27,029 Facebook apps, 18,205 request at least
one permission from the user. For each of the 27,029 apps,
we downloaded details including the number of monthly ac-
tive users, the average rating, rating count, description and
category. This constitutes the Facebook (all) dataset.

3.3 Chrome Extensions

Chrome Web Store [19] lists up to 1,000 most popular ex-
tensions in 12 diﬀerent categories. As some of the categories
such as ‘Sports’ and ‘Shopping’ have far less than 1,000 ex-
tensions, even the more recent extensions such as those with
less than 10 users, were present on the lists. We constructed
our dataset by downloading all 12 lists. Removing duplicates
and extensions that became unavailable during data collec-
tion, the resulting Chrome (all) dataset consists of 5,943
extensions.
It contains details from the information page
of each extension, including the installation count, average
community rating, rating count, developer URL, version of
extension, supported languages, as well as the permission
warnings associated with the extension.

4. BASIC ANALYSIS

We ﬁrst study the link between app popularity and user

ratings, and the statistics of permissions in the following.

4.1 App Popularity and User Ratings

We deﬁne the popularity of an app as the number of in-
stallations (in the case of Android apps and Chrome ex-
tensions) or the number of monthly active users (in the
case of Facebook apps). Figure 1 shows log-log plots of
app popularity versus the number of user ratings the app
has received. While we did not test if both the distribu-
tions of app popularity and the number of ratings per app
follow a speciﬁc heavy-tailed distribution (e.g., Power-Law,
Log-normal), they appear to be highly skewed visually. All
four app popularity distributions curve in the log-log plot.
On the other hand, other than the Android (pop) dataset
where no apps have less than 30 ratings, the rating contribu-
tion patterns appear to be straight lines in the log-log plot,
suggesting that they could be a Power Law. Indeed, many
online peer production systems can be characterized by a
Power Law contribution pattern that is explainable by the
participation momentum rule [31]. The skewed nature of the
app popularity and the number of ratings per app prompted
us to use the logarithmic values, i.e., log(#installation) and
log(#rating) for popularity and rating count respectively in
subsequent analysis.

We found a strong (Pearson) correlation between app pop-
ularity and the number of ratings of the app has received
(with r ranging from 0.67 to 0.90, p<.001, see Figure 2).
Indeed, users are more likely to rate an app that they have
installed. However, somewhat counter-intuitively, the aver-
age rating of an app, avgr, does not positively correlate with

app popularity. In fact, avgr is negatively and weakly cor-
related to the app popularity (r=−0.15, p<.001) among the
new Android apps. We ﬁgure that the average user rating
can indeed be misleading without factoring in its conﬁdence
level. Considering the conﬁdence of an average rating to be
proportional to the number of ratings that it has received,
we thus measure the adjusted average rating to be:

avgra = (avgr − 3) ∗ log(#rating)

(1)

The –3 transformation is necessary as user ratings range
from 1 to 5 across the diﬀerent app platforms. As also shown
on Figure 2, there is a strong correlation between the app
popularity and the adjusted average rating (with r ranging
from 0.45 to 0.72, and p<.001). We evaluate if avgra serves
as an eﬀective risk signal against potentially intrusive or
inappropriate apps in Section 5.

4.2 Permission Statistics

Understanding the complex permission models of web and
mobile apps can be a daunting task for many ordinary users.
We brieﬂy describe the permission systems from the most
granular (Android) to the least (Chrome) below.
In each
case, we identify three sets: the set of all permissions P ,
the set of dangerous permissions Pdanger, and the set
of dangerous and information relevant permissions
Pdinf o. Pdanger consists of permissions for actions that can
be potentially harmful to the user while Pdinf o is the subset
of Pdanger consisting of permissions that permit access to
sensitive personal information of the user.

Android: Android permissions are categorized into 4 cat-
egories, namely Signature-or-System, Signature, Normal and
Dangerous. The ﬁrst two categories, Signature-or-System
and Signature permissions protect the most sensitive opera-
tions on the Android devices. These permissions can only be
granted to apps pre-installed into the device’s /system/root
folder and/or apps signed with the device manufacturer’s
private key. Requests to use these permissions by other
apps without the right keys will be ignored [17]. On the
other hand, the Normal permissions govern the functionali-
ties which can be annoying (e.g., vibrating the phone), while
the Dangerous permissions protect the user from operations
that can be potentially harmful including those that cost
money or potentially privacy intrusive [17]. The details of
individual Android permissions can be found on [2].

We observed 137 diﬀerent permissions in our dataset, out
of which 65 are dangerous permissions. Following [15], we
classiﬁed 34 of the 65 permissions in Pdanger as belonging to
Pdinf o. Table 1 shows the most frequently requested danger-
ous permissions among the popular and new Android apps.
The full list is available on our project site [25].

Facebook: The Facebook permissions have evolved as
the platform and its user base grows. Each of the permis-
sions protects a speciﬁc piece of personal information or a
speciﬁc functionality on the platform (e.g., to login to Face-
book chat system, publish user’s activity on his wall). We
consider all Facebook permissions to be dangerous. There
are in total 62 Facebook permissions [13], which are grouped
and presented to the users in 23 diﬀerent categories. Each
category is highlighted in bold and visualized with a unique
icon on the permission request screen, while the individual
permissions are described in gray text with a smaller font
size under their respective category. The individual permis-
sions requested can also be found on the URL of the per-

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France313p
p
a

 
r
e
p

 

n
o

i
t

a

l
l

a
t
s
n

i
 

#

8
0
+
e
1

6
0
+
e
1

4
0
+
e
1

2
0
+
e
1

0
0
+
e
1

Android−pop
Android−new
Facebook
Chrome

1

10

1000

10000

100
# apps

p
p
a

 
r
e
p

 

g
n

i
t

a
r
 

#

6
0
+
e
1

4
0
+
e
1

2
0
+
e
1

0
0
+
e
1

Android−pop
Android−new
Facebook
Chrome

1

10

1000

10000

100
# apps

Figure 1: Distribution of the number of installations and number of ratings per app.

Android (pop)

3

5

7

Android (new)

1 3 5

Facebook (all)

0

4

8

Chrome (all)

0 2 4 6

log_rcnt

0.90

0.75

7

5

3

log_icnt

0.57

avgr_a

6

4

2

4

2
−

4

1

log_rcnt

0.77

0.71

log_icnt

0.45

avgr_a

4

2

0

8

4

0

8

4

0

log_rcnt

0.67

0.62

log_mau

0.47

avgr_a

6

3

0

5

5
−

6

3

0

log_rcnt

0.87

0.84

log_icnt

0.72

avgr_a

4

2

0

4

2
−

2

4

6

−2

4 8

0

2

4

0

4

8

0 2 4 6

−5

5

0

2

4

−2

4 8

Figure 2: Scatter-plot matrices showing the pairwise correlation coeﬃcients (upper right triangular panel)
and the scatter-plots (lower left) of any given pairs of three variables: log of installation count, log_icnt (or
monthly active users, log_mau), log of rating count, log_rcnt, and adjusted average rating, avgr_a. The scales
of the variables are depicted on the borders of individual matrices. All correlation values are statistically
signiﬁcant with p<.001.

INTERNET
WRITE EXTERNAL STORAGE†
READ PHONE STATE†
WAKE LOCK (5)
ACCESS FINE LOCATION† (4)
ACCESS COARSE LOCATION†
READ CONTACTS† (8)
CAMERA† (11)
READ LOGS† (17)
RECORD AUDIO† (20)
GET TASKS† (10)
CALL PHONE (7)

pop
77
51
45
23
14
10
7
6
6
6
6
5

new
67
34
29
13
14
5
5
3
1
1
4
5

Table 1: Top 12 most requested dan-
gerous permissions w.r.t. Android (pop),
and percentage of apps requesting them.
Numbers in brackets show the diﬀerent
rankings w.r.t. Android (new).

†

†

Access my basic info.
Post to Facebook as me.
Send me email.
†
Access my proﬁle info.
Access my data any time.
Access my photos.
Access information people
†

†

share with me.

†

Publish games and app

activity.

Access posts in my news feed.
Access my videos.

†

†

%
67
23
14
5
2
2
2

2

1
1

† indicates a dangerous and
info. relevant permission

Your tabs & browsing activity.
Your data on <some>

†

websites.

†

†

Your data on all websites.
Your bookmarks.
Your browsing history.
Your list of installed apps,
extensions, and themes.

†

†

Your physical location.
All data on your computer

†

and the websites you visit.

†

%
58
41

35
2
2
1

1
1

Table 2: Top 10 most requested
permissions, and percentage of
Facebook apps requesting them.

Table 3: Percentage of Chrome
extensions requesting a speciﬁc
permission.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France314Perm.
type
P
Pdanger
Pdinf o
Rp (%)

Android (pop)

Android (new)

Facebook (all)

Chrome (all)

µ M max
15
10
7

4
3
1

4.5
3.0
1.6

total

137
65
34
91

µ M max
20
11
5

2
2
1

3.0
2.1
1.0

total

137
65
34
74

µ M max
13
13
11

1
1
1

1.2
1.2
0.9

total

23
23
14
67

µ M max
6
5
5

2
1
1

1.4
0.8
0.8

total

8
7
7
85

Table 4: Mean (µ), median (M) and maximum (max) number of P , Pdanger and Pdinf o requested per app, as
well as the total number of permissions on diﬀerent platforms. Rp measures the percentage of apps requesting
at least one permission.

mission request screen but we do not expect the ordinary
users to notice them. For these reasons, in this study, we
have focused on the permission categories as opposed to the
individual permissions. For simplicity, we refer to Facebook
permission categories as permissions interchangeably.

14 out of the 23 permission categories are information rel-
evant. Table 2 shows the most frequently requested per-
mission categories. Notice all apps requesting a permission
must also request for the ‘Access my basic information’ per-
mission. The most dangerous permission is perhaps ‘Access
my data any time’ which allows an app to access the user’s
information even when he is not online. Another interest-
ing permission is ‘Access information people share with me’
which allows the app to access not information about the
user himself, but the personal information of his friends.

Chrome: Among the three platforms, Chrome permis-
sions are the least granular. There are only 9 permission
warnings in total as detailed on [18]. Inline with the catego-
rization of Android and Facebook permissions, we regard all
Chrome permissions to be both dangerous and dangerous-
and-information-relevant, except the permission ‘Your tabs
and browsing activity’ which was unnecessarily required for
creating a new tab in earlier versions of Chrome browser [18].
The most dangerous is the permission to access ‘All data
on your computer and the websites you visit’ which is re-
quested by the plugin-type extensions. These plugin exten-
sions are basically native executables that run with full priv-
ileges on the user’s machine. They are manually reviewed
by Chrome before being accepted to appear on the Chrome
Web Store [18]. We found only 47 plugin extensions in our
dataset. Among the extensions that request for the per-
mission to access ‘Your data on <some> websites’, the top
10 most frequently requested sites are: google.com, face-
book.com, tiny-url.info, plus.google.com, twitter.com,
youtube.com, mail.google.com, g2me.cn, api.flickr.com,
and reddit.com.

Summary: Table 4 shows the mean, median and maxi-
mum number of P , Pdanger, and Pdinf o that an app requests
in the diﬀerent datasets. The ratio of apps requesting at
least a permission is high across all four datasets: Android
(pop) (91%), Android (new) (74%), Facebook (all) (67%)
and Chrome (all) (85%). Another trend that holds across
the diﬀerent platforms is that most apps request only a
small fraction of the total available permissions. On aver-
age (medium), Facebook and Android apps request for only
1/23 = 4% and 3/65 = 5% (3% among the new apps) of the
total available dangerous permissions respectively. In addi-
tion, there is a noticeable trend that some permissions are
more frequently requested than the others (see Table 1, 2,
3). These reinforce the ﬁndings by Felt et al. [17] that an
application permission system has the beneﬁts of allowing

Perm.
type
P
Pdanger
Pdinf o

Correlation with log(#installation)
FB Chrome
Android Android
(all)
(all)
(new)
0.15
0.28
0.12
0.11
0.28
0.12
0.12
0.28
0.10

(pop)
0.26
0.26
0.22

Table 5: Correlation between app popularity and
the number of P , Pdanger and Pdinf o requested. All
values are statistically signiﬁcant with p<.001

the platform owners (i) to avoid granting the full privileges
to third party apps, and (ii) to possibly recognize apps with
anomalous permission request patterns for triaging the man-
ual review process.

However, as it is with other security problems, the permis-
sion systems will not be eﬀective if users do not comprehend
how they work, or if the permission systems contradict other
signals the users receive. One can easily exploit the lack of
understanding and the absence of reliable risk signals for
questionable or malicious purposes.

5. EFFECTIVENESS OF RISK SIGNALS

We look into the availability of reliable and intuitive risk
signals during the process of app installation in the following.
5.1 App Popularity

Table 5 shows that there is a weak positive correlation
between app popularity and the number of permissions re-
quested. The trend holds true not only for our Chrome
extension dataset (which is much larger than the dataset
used by Felt et al. [17]), but also for Android and Facebook
apps. Also, the correlation is stronger in popular Android
apps than in new Android apps. As Felt et al. [17] hypothe-
sized, a possible explanation is that popular apps need more
permissions in order to oﬀer more functionality that makes
them more interesting or useful and hence popular. While
this phenomenon is perhaps not surprising, it underlines the
fact that careful users concerned about their privacy have to
make a tradeoﬀ between the functionality oﬀered by an app
and its potential for compromising their privacy. Although
popularity of an app is an easily available and understand-
able signal to users of app marketplaces, it is not necessarily
a reliable signal for privacy risk – a user cannot conclude
that a popular app is a safe one.
5.2 Community Rating

Community rating reﬂects how the users perceive an app.
As with the popularity measure, it is a meaningful signal
that is also widely available in app marketplaces.
If it is

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France315Correlation with avgra

Perm.
type
P
Pdanger
Pdinf o

Android Android
(new)
0.08*
◦
0.06
◦
0.04

(pop)
0.15
0.14
0.11

FB Chrome
(all)
(all)
0.18
0.11
0.16
0.11
0.12
0.16

Perm.
type
P
Pdanger
Pdinf o
# apps

Android Android
(new)
3.0
2.2
1.2
11

(pop)
6.0
3.6
2.0
5

FB Chrome
(all)
(all)
3.4
1.8
1.0
3.4
1.0
2.6
88
65

Table 6: Correlation between the adjusted aver-
age rating avgra and the number of P , Pdanger and
Pdinf o requested. All values are statistically signiﬁ-
cant with p<.001, except for the case of new Android
apps where * indicates p<0.1 and
indicates p>0.1.

◦

to be an eﬀective signal for enabling the user to detect pri-
vacy risks, it would exhibit a negative correlation with the
number of permissions requested. We found no such neg-
ative correlation between the adjusted average rating and
number of permissions (Table 6). In fact there was a weak
positive correlation in all cases except for the case of the
new Android apps, where the correlation was not statisti-
cally signiﬁcant. Again, the likely explanation is that user
ratings in app marketplaces are based on functional aspects
like features and performance rather than privacy risks.

5.3 External Ratings

Next, we studied how ratings from sources external to the
marketplaces relate to the number of permissions. We con-
sidered two sources. First is the Web of Trust (WOT) [29]
service. WOT is a community rating system which allows
users to rate a website in four dimensions: trustworthiness,
vendor reliability, privacy and child safety.
It aggregates
user ratings as well as information from other sources into
a rating along each of the dimensions as well as a combined
score. WOT ratings are usually given at the granularity of
fully qualiﬁed domain names, unless a subdomain has re-
ceived enough input ratings on its own. Websites where
multiple users control their own subsections thus typically
share a common rating inherited from the parent domain.
Second is AppBrain.com which is a website for discovering
Android apps. It provides a number of useful listings includ-
ing the most popular Android apps in diﬀerent countries and
age groups, as well as the latest apps that appear in Android
Market. To help its users, AppBrain.com labels apps cre-
ated by developers who have made a high fraction of apps
without any rating or with below average ratings, as spam.
We studied how WOT rating of the website of the app
developer (where available) relates to the permissions re-
quested by it. Table 7 shows the average number of per-
missions requested by apps whose developer websites are
deemed suspect (bad or caution) by WOT. We classiﬁed a
WOT rating into bad, caution, good or unknown following
the default risk signaling strategy of WOT as detailed in [9].
We ignored the good ratings from WOT as many developers
use a shared domain as their website and WOT’s verdicts
will not be accurate in these cases. Contrasting with the
mean values in Table 4, we see that that the suspect apps
consistently request more permissions than on average in all
cases. The diﬀerences in the average number of P , Pdanger
and Pdinf o between suspect Facebook apps and Facebook
apps in general are statistically signiﬁcant with p<.001. The
sample size is too small in the case of Android apps (see
Table 7). As for Chrome extensions, the diﬀerences are sta-

Table 7: Average number of P , Pdanger and Pdinf o
requested by apps whose developer website has been
labelled as bad or caution by WOT.

tistical signiﬁcant with p<.05 for P , while p<.1 for Pdanger
and Pdinf o. Further, we found no correlation between the
WOT’s suspect rating and community rating.

New Android apps which have been regarded as spam by
AppBrain.com also request for a higher number of permis-
sions on average with P , Pdanger and Pdinf o equal 3.3, 2.2,
and 1.2 respectively (as compared to 3.0, 2.1 and 1.0 typi-
cally, as shown in Table 4). The diﬀerences in the average
number of P and Pdinf o are signiﬁcant with p<.1.

5.4 Signals from the Developer

So far we have looked at aggregated signals available in
the marketplace (popularity and community rating) and sig-
nals from external sources. Now we turn our attention to
signals that originate from the developers themselves. We
considered three diﬀerent signals:

Availability of a developer website: The availability
of a developer website of Android apps and Chrome exten-
sions correlates positively with the number of permissions
requested by an app. Thus, the presence of a developer
website (developer identity) does not imply a less intrusive
app; in fact the reverse was observed. We have not measured
the same eﬀect for Facebook apps as the developer website
is not shown on the user-consent permission dialogs. One
may be able to obtain the developer website in the Contact
Developer link on the app information page. However, we
found that, in many cases, the link provides a means to con-
tact the developer via Facebook’s messaging system, rather
than a valid developer website.

Availability of a privacy policy: The availability of
a privacy policy with a Facebook app correlates negatively,
albeit weakly, with Pdanger (r=–0.12, p<.001) and Pdinf o
(r=–0.14, p<.001). In other words, there is some weak evi-
dence that Facebook apps accompanied by a privacy policy
are more likely to request fewer permissions. Note that the
privacy policy URLs were obtained from the user-consent
permission dialogs. We have not looked for the privacy pol-
icy URLs of Android apps and Chrome extensions as they
are not readily available.

Multiple apps from the same developer: Surpris-
ingly, the number of apps a developer has published is nega-
tively correlated to both log(#installation) and avgra among
Facebook apps, Chrome extensions and new Android apps.
The more apps a developer publishes, the more likely his
apps have a lower popularity and community rating. This
could be due to that proliﬁc developers actually make low
quality apps, or that users actually cast a higher expectation
on regular developers; it may be worth further investigation.
The number of apps a developer makes has no correlation
with the number of permissions their apps request except
for the case of new Android apps, where there is a very

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France316Perm.
type
P
Pdanger
Pdinf o

Corr. with maturity Corr. with price=free
Android Android

Android

Android

(pop)

(new)

(pop)

(new)

0.30
0.33
0.30

0.27
0.30
0.32

0.22
0.23
0.19

0.43
0.41
0.35

Table 8: Correlation between the number of P ,
Pdanger and Pdinf o requested by Android apps, the
content maturity level and whether an app is free.
All values are statistically signiﬁcant with p<.001.

Perm.
type
P
Pdanger
Pdinf o
Rp (%)

Android (pop) Android (new)
free
paid
4.1
3.9
2.8
2.6
1.4
1.4
92
86

paid
1.6
1.1
0.5
56

free
5.2
3.5
1.9
96

Table 9: Average number of P , Pdanger and Pdinf o
requested by the free and paid Android apps. Rp
measures the percentage of apps requesting at least
one permission.

weak link (r=–0.09, p<.01) between the number of apps the
developer has made and the number of permissions. Thus,
one cannot judge the potential privacy intrusiveness of an
developer based on the number of apps he has published.

6. ENTICEMENTS AND TRICKS

We investigated if there is any evidence of attempts to en-
tice or mislead the user into granting sensitive permissions.
In Section 6.1 we study if free apps or those containing ma-
ture content require more privileges than average. In Sec-
tion 6.2 we study the permission request patterns of apps
whose names look similar to the popular ones.
6.1 Free and Mature Apps

Android Market requires the developer of an app to rate
its content maturity by selecting one of four labels describ-
ing the age of the target audience: everyone, low, medium
or high maturity. Table 8 shows that there is a positive
correlation between the content maturity rating and the
number of permissions required. There is also a positive
correlation between the requested permissions and whether
the app is free. Table 9 shows the diﬀerence between paid
and free apps in terms of the average number of permis-
sions they request: free apps consistently request more per-
missions than paid apps. Note that also there is a bigger
proportion of free apps requiring at least one permission
than the paid apps; this is particularly evident among the
new Android apps. Previous studies [6, 17] found that more
free apps request for the INTERNET permission, possibly only
to load advertisements.
It is interesting to note that the
INTERNET permission is not part of Pdinf o in our analy-
sis. The consistently higher number of Pdinf o of free apps
among both popular and new Android apps suggests some
suspicious enticement. We further compared between free
and paid apps excluding permissions that are commonly re-
quired due to third party advertisement libraries. Not count-
ing ACCESS_COARSE_LOCATION, ACCESS_FINE_LOCATION, AC-
CESS_NETWORK_STATE, READ_PHONE_STATE, WAKE_LOCK as well

i

i

s
n
o
s
s
m
r
e
p
 
#
 
e
g
a
r
e
v
a

7

6

5

4

3

2

1

0

Child−unsafe site
Bad/caution site
All

P

P_danger
Facebook

P_dinfo

i

i

s
n
o
s
s
m
r
e
p
 
#
 
e
g
a
r
e
v
a

7

6

5

4

3

2

1

0

Child−unsafe site
Bad/caution site
All

P

P_danger
Chrome

P_dinfo

Figure 3: Average number of P , Pdanger and Pdinf o
requested by Chrome extensions and Facebook
apps whose developer site has been identiﬁed as
bad/caution or child-unsafe by WOT.

as INTERNET, we found that free apps still request for a higher
number of P , Pdanger and Pdinf o on average. The diﬀerences
are statistical signiﬁcant with p<.01 in all cases (except for
Pdinf o of popular Android apps where p<.05).

Facebook apps and Chrome extensions are always free.
There is also no content rating systems for these. We di-
vided these apps into three sets in terms of the WOT rat-
ings of the developer: those labeled as child-unsafe, those
labeled as suspect (bad or caution) (as we have discussed in
Section 5.3), as well as the set of all apps. The ﬁrst cat-
egory (child-unsafe) consisted of 34 chrome extensions and
70 Facebook apps. The second category (suspect sites) con-
sisted of 65 chrome extensions and 88 Facebook apps (also
shown in Table 7). Figure 3 shows the results. Suspect apps
and apps with potentially child-unsafe content request more
permissions than is typical. This eﬀect is particularly pro-
nounced in the case of Facebook apps where all diﬀerences
are signiﬁcant with p<.001. Meanwhile, the diﬀerences in
the average number of Pdanger and Pdinf o between the set of
Chrome extensions whose developer website has been iden-
tiﬁed as child-unsafe by WOT and the set of all extensions
are signiﬁcant with p<0.1.
6.2 Look-Alike App Names

Apps are uniquely identiﬁable on the respective applica-
tion platforms through unique strings, such as 102452128776
for FarmVille on Facebook, com.rovio.angrybirds for An-
gry Birds on Android, and bbncpldmanoknoahidbgmkgob-
gmhnafh for Last.fm extension on Chrome. However, unique
identiﬁers are typically long and unintuitive. One would
thus expect the users to recall or discover an app through
its name or other visually distinctive features, rather than
the IDs. On the application platforms, developers are free
to choose his preferred app name; the app names need not
be unique even on individual platforms. This creates oppor-
tunities for exploitation, for example, to create “look-alike”
apps with names exactly the same or similar to the popu-
lar ones, so to free ride on their success or as a means to
distribute potentially malicious apps.

We looked into the problem of name look-alike apps on
Android, Chrome and Facebook. To measure name simi-
larity, we have used the popular Damerau-Levenshtein edit
distance [11, 22]. Given two strings s1 and s2, we deﬁne the
normalized edit distance as follows:

distn(s1, s2) =

distDL(s1, s2)

max(len(s1), len(s2))

(2)

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France317Android
Facebook
Chrome

)

%

(
 
s
e
m
a
n
 
p
p
a
 
e
k

i
l

a
−
k
o
o
l
 
f
o
 
o
i
t
a
R

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

0−0.05

0.05−0.1 0.1−0.15 0.15−0.2 0.2−0.25 0.25−0.3

Normalized edit distance

Figure 4: Ratio of look-alike app names in speciﬁc
ranges of normalized edit distance, distn

where distDL(s1, s2) is the Damerau-Levenshtein distance
between s1 and s2, len(s) is the length of string s in terms
of the number of characters, and max(a, b) returns the larger
value between a and b.

We outlined the top 200 most popular apps on Facebook,
Chrome and Android respectively, and calculated the nor-
malized name edit distance between them and the rest of the
apps. We ignored the name pairs where both apps are pub-
lished by the same developers. We also omitted apps with
non-Latin based names in this study. Together, we have in-
vestigated 19,344 Android apps, 13,181 Facebook apps, and
5,322 Chrome extensions.

Figure 4 shows the ratios of apps whose normalized edit
distance to any of the popular counterparts falls in a speciﬁc
range. As shown by the ﬁrst three bars (i.e., distn ≤ 0.05),
there is a higher ratio of extremely look-alike apps on Face-
book than on Android and Chrome platforms. Using a sim-
ilarity threshold of distn=0.30, we found 1.15% of the An-
droid apps, 1.20% of the Facebook apps, and 1.47% of the
Chrome extensions have either intentionally or unintention-
ally used a look-alike name to a popular app.

Next, we manually categorized the look-alike app names

into the following ﬁve classes:

• Same: Exact same name of the original counterpart
• Letter change: Some letters of a term of the original

counterpart is changed

• Term change: Some terms of the original counterpart

is substituted with new terms

• Term addition/deletion: Some terms are added

into or deleted from the original counterpart

• Serialization: Special terms indicating a diﬀerent

version (e.g., 2, Free) are added to the original

Table 10 lists some examples of look-alike names we have
found, while Table 11 gives the percentage breakdown of
the diﬀerent classes of look-alike names. We found a total
of 223, 158 and 78 look-alike names on Android, Facebook
and Chrome respectively. Going through the list manually,
we observed that the look-alike names in the Same, Letter
change and Serialization classes are created with a higher
level of questionable intention. We delved into look-alike
apps of these three classes in the following.

Popular App

Look-alike App

TapFish
WChess free
SarmVille
Pho.to Mania
Facebook Notiﬁcation

Advanced Task Manager

Letter change:
A Tap Fish
A Chess Free
F
FarmVille
F
PhotoMania
C Facebook Notiﬁcations
Term change:
A Advanced Task Killer
A Blue Skies Live Wallpaper Blue Wave Live Wallpaper
F Angry birds
F
C Google +1 Button
Term addition/deletion:
A Yahoo! Mail
A Ringtone Maker
F Yearbook
C Facebook Notiﬁcations
C Reader Plus
Serialization:
A Advanced Task Killer
F
F Daily Horoscope
C Reader Plus
C Speed Dial 2

Advanced Task Killer Pro
Pool Master
Free Daily Horoscopes
ReaderPlus+
Speed Dial 2 (ru)

My Yahoo! Mail
MP3 Ringtone Maker
myYearbook
Facebook Chat Notiﬁcation
Reader to Plus

Angry bears
FameTown
Google Plus Button

FarmTown

Pool Master 2

Table 10: Example look-alike app names of diﬀerent
classes on Android (A), Facebook (F ) and Chrome
(C ). Pairs of exactly the same names are not shown.

Similarity class
Same
Letter change
Term change
Term addition/deletion
Serialization

Android Facebook Chrome
7.7
11.5
65.4
9.0
6.4

19.6
23.4
47.5
5.7
3.8

6.7
2.7
78.9
4.0
7.6

Table 11: Percentage breakdown (%) of look-alike
names in diﬀerent similarity classes.

Table 12 compares the characteristics of suspect look-alike
apps (Same, Letter change and Serialization) to the set of
targeted original counterparts, and the set of all apps in gen-
eral. As shown on the ﬁrst three rows, the average number
of P , Pdanger and Pdinf o requested by the look-alike apps
are in general lower than the original counterparts. How-
ever, the diﬀerences are not statistically signiﬁcant (except
for Pdinf o of Facebook). While this suggests that the look-
alike apps are not more privacy-intrusive than the original
counterparts (i.e., the popular apps), we cannot rule out the
potential risks of these look-alike apps immediately. Indeed,
the average number of permissions requested by the look-
alike apps are higher that is typical (i.e., comparing with
the set of all apps). The increase in the average number of
permissions is statistically signiﬁcant for both Android and
Facebook look-alike apps. This suggests some level of sus-
picious activities among the look-alike apps on Android and
Facebook platforms.

We further analyzed how community ratings respond to
look-alike apps currently. First, we found that the adjusted
average rating, avgra of the targeted counterparts is signif-
icantly higher than that of the look-alike apps across three
platforms. However, we should not assume that community
ratings are warning against look-alike apps adequately. The

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France318Perm.
type
P
Pdanger
Pdinf o
avgra
avgr

look-alike
3.9
2.6
1.3
2.2
3.8

Android

original
4.2
2.7
1.5
7.4***
4.5

all

3.0***
2.1**
1.0**
2.3
4.4

Chrome

look-alike
1.8
1.2
1.2
1.7
4.1

original
2.3
1.6
1.6
3.3***
4.2

all
1.4
0.8
0.8
1.2
4.4

look-alike
2.1
2.1
1.5
1.8
3.9

Facebook
original
2.5
2.5
1.9*
4.2***
4.0

all

1.2***
1.2***
0.9***
1.1***
3.8

Table 12: Comparing the look-alike apps to (i) the original counterparts, and (ii) all apps as a whole. Rows
1–3 compare the average number of P , Pdanger and Pdinf o requested. Rows 4–5 compare the adjusted average
rating avgra, and the average rating avgr. ***p<.01, **p<.05, and *p<.1 indicate if a measurement given by
the original counterparts, and the set of all apps, is signiﬁcantly diﬀerent from that of given by the look-alikes.

higher avgra value of the targeted apps can be likely due to
the higher number of user ratings the apps have received,
following their popularity. Indeed, we found no signiﬁcant
diﬀerences between the average rating, avgr of the look-alike
apps and the targeted counterparts. Also, the average rat-
ing of the look-alike apps are not low, ranging from 3.8 to
4.1.
In addition, the adjusted average rating of the look-
alike Facebook apps is signiﬁcantly higher than that of all
Facebook apps in general. These suggest the lack of the
current community rating systems in signaling against the
look-alike apps, especially on Facebook. Facebook does not
even present the number of user ratings nor app popularity
on the user-consent permission dialogs.

7. DISCUSSION AND CONCLUSIONS

Revisiting the questions we started with in Section 1, we
summarize and discuss the implications of our ﬁndings, and
provide recommendations in the following:

1. Popular apps request more permissions: Dissect-
ing the API calls of 940 apps, Felt et al. [16] found that one
third of them request for unused permissions, attributable
to errors and confusion over the insuﬃcient API documen-
tation. Without a source- or binary-code analysis, we have
not singled out the cases where apps request for more per-
missions due to developer errors rather than questionable
intentions. Yet, does not matter the causes (errors or bad
intentions), unfortunately, there appears to be no disincen-
tives for developers who over privilege their apps currently.
There is in fact a positive correlation between app popu-
larity and the number of permissions the app requests on
all three platforms, even when considering information sen-
sitive permissions only. More worrying is that the trend
holds true despite the diﬀerent UI designs and permission
granularities of Facebook, Chrome and Android. Ongoing
research in improving risk communication (e.g., [27]) must
take into account the high permission request frequency by
popular apps to be eﬀective.

2. No reliable app risk signals currently: As users
are ‘trained’ to accept the requests from popular apps, per-
mission systems can become more ineﬀective over time. The
problem is compounded by the fact that the currently avail-
able signals about an app are unreliable in indicating the pri-
vacy risks associated with that app. We investigated several
such signals including the adjusted community rating, the
availability of a developer website and the number of apps
published by the developer. If they are to be reliable signals
for helping users detect privacy intrusive apps, they should
exhibit negative correlation with the number of dangerous
permissions requested (and hence with potential privacy in-

trusiveness of the app). None of the above signals exhibit
the expected negative correlation. The only exception we
found is the presence of a privacy policy on the permission
request screen of Facebook apps that weakly correlates with
a lower number of requested permissions. However, if users
start relying on this as a signal, it could lead to adverse se-
lection as malicious developers can easily put up a ‘privacy
policy’ that they do not adhere to.

On the other hand, we found some external services that
show potential in signaling app risks. One is the website
reputation scores from the Web of Trust (WOT) and another
is the ﬂagging of spam Android apps by AppBrain.com. App
marketplaces can prominently display signals from similar
sources to help users recognize potentially intrusive apps.
Facebook is already receiving the website reputation scores
from WOT to protect against malicious URLs posted onto
the users’ wall [14]. It will not be too diﬃcult to adapt the
scores to warn against suspicious apps and developers.

3. Enticement of free and mature apps: We found
evidence indicating attempts to mislead or entice users into
granting permissions with free apps and mature content.
The trend holds even when focusing on information rele-
vant permissions only. Particularly, excluding the INTERNET
permission necessary for advertisement revenue (and a few
others commonly required by third party ad libraries), free
apps still request for more permissions than the paid apps.
4. Look-alike name trick: We also found “look-alike”
apps to request more permissions than is typical. While the
fraction of look-alike apps is small, there is an underlying
problem of ‘cheap identity’ with app names (and IDs) cur-
rently. Charging for a developer ID or for publishing an app
may help, but platform owners may be reluctant to do so in
the competitive market to attract developers and apps.

An option is to leverage on community inputs for reputa-
tion scores on app security and privacy. WhatApp.org [30] is
a website which collates user and expert reviews on the pri-
vacy, security and openness of web and mobile apps. How-
ever, it is still in its beta version and has not attracted much
reviews to date. Indeed there are many challenges in crowd-
sourcing of security and privacy inputs. As we found in this
paper, the number of ratings is highly correlated to the pop-
ularity of an app. This gives rise to the question of who will
review suspicious apps or grayware? There is probably no
one size that ﬁts all. We see that a successful model will need
to combine community inputs with automated evaluations.
Limitations and future work: One limitation of our
analysis is that we have not done any source- or binary-code
analysis of the apps. While we pointed out the trends that
free, mature and look-alike apps request more permissions

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France319than is typical, we cannot directly infer the maliciousness of
a particular app judging from the permissions it requests.
Secondly, while our analysis conﬁrms the higher risk with
free and mature apps, and that there is a lack of reliable
signals, we are not sure if users (in particular mature app
users) are actually aware of the privacy risks and making the
tradeoﬀ willingly. Studies to examine the privacy tradeoﬀ of
users will be interesting. Leveraging on large datasets, we
also plan to explore the use of machine learning methods for
automatic classiﬁcation of app privacy intrusiveness.

8. ACKNOWLEDGMENTS

This work has beneﬁted from initial discussions with Adri-
enne Porter Felt and David Barrera. We are also grateful
to Adrienne and the anonymous reviewers for their valuable
comments on earlier drafts.

9. REFERENCES
[1] A. Acquisti and R. Gross. Imagined communities:

Awareness, information sharing, and privacy on the
facebook. In G. Danezis and P. Golle, editors, Privacy
Enhancing Technologies, volume 4258 of Lecture Notes
in Computer Science, pages 36–58. Springer, 2006.
[2] Android Developer’s Guide – Manifest Permissions.

http://developer.android.com/reference/
android/Manifest.permission.html.

[3] Android Market. https://market.android.com.
[4] AppBrain. http://www.appbrain.com.
[5] D. Barrera, W. Enck, and P. C. van Oorschot. Seeding

a Security-Enhancing Infrastructure for Multi-market
Application Ecosystems. Technical report, Carleton
University, April 2011. TR-11-06.

[6] D. Barrera, P. C. van Oorschot, and A. Somayaji. A

Methodology for Empirical Analysis of
Permission-Based Security Models and its Application
to Android Categories and Subject Descriptors. In
Proc. of the 17th ACM conf. on Computer and
Communications Security, CCS ’10, pages 73–84.
ACM, 2010.

[7] J. Bonneau, J. Anderson, and L. Church. Privacy

suites: shared privacy for social networks. In Proc. of
the 5th Symposium on Usable Privacy and Security,
SOUPS ’09. ACM, 2009.

[8] P. H. Chia, A. P. Heiner, and N. Asokan. Use of

ratings from personalized communities for trustworthy
application installation. In Proc. of the 15th Nordic
conf. in Secure IT Systems, NordSec ’10, 2010.

[9] P. H. Chia and S. J. Knapskog. Re-evaluating the

wisdom of crowds in assessing web security. In
G. Danezis, editor, Financial Cryptography and Data
Security, FC ’11, volume 7035 of Lecture Notes in
Computer Science, pages 299–314. Springer, 2012.

[10] F. Cohen. Computational aspects of computer viruses.

Computers & Security, 8(4):297–298, 1989.

[11] F. J. Damerau. A technique for computer detection
and correction of spelling errors. Communications of
the ACM, 7:171–176, March 1964.

[12] W. Enck, M. Ongtang, and P. McDaniel. On

lightweight mobile phone application certiﬁcation. In
Proc. of the 16th ACM conf. on Computer and
Communications Security, CCS ’09, pages 235–245.
ACM, 2009.

[13] Facebook Developers – Permissions.

https://developers.facebook.com/docs/
reference/api/permissions/.

[14] Facebook partners with WOT. Article on

ArcticStartup website, May 2011.
http://www.arcticstartup.com/2011/05/12/
facebook-partners-with-wot-to-protect-its-700-
million-users.

[15] A. P. Felt. Personal Communication.
[16] A. P. Felt, E. Chin, S. Hanna, D. Song, and

D. Wagner. Android permissions demystiﬁed. In Proc.
of the 18th ACM conf. on Computer and
Communications Security, CCS ’11, pages 627–638.
ACM, 2011.

[17] A. P. Felt, K. Greenwood, and D. Wagner. The

eﬀectiveness of application permissions. In Proc. of the
2nd USENIX conf. on Web application development,
WebApps ’11. USENIX Association, 2011.

[18] Google Chrome Extensions – Permission Warnings.

http://code.google.com/chrome/extensions/
permission_warnings.html.

[19] Google Chrome Web Store – Extensions. https:
//chrome.google.com/webstore?category=ext.

[20] J. King, A. Lampinen, and A. Smolen. Privacy: Is

there an app for that? In Proc. of the 7th Symposium
on Usable Privacy and Security, SOUPS ’11, pages
12:1–12:20. ACM, 2011.

[21] K. Kostiainen, E. Reshetova, J.-E. Ekberg, and

N. Asokan. Old, new, borrowed, blue –: a perspective
on the evolution of mobile platform security
architectures. In Proc. of the 1st ACM conf. on Data
and Application Security and Privacy, CODASPY ’11,
pages 13–24. ACM, 2011.

[22] V. I. Levenshtein. Binary codes capable of correcting

deletions, insertions, and reversals. Soviet Physics
Doklady, 10(8):707–710, 1966.

[23] M. Marsall. How HTML5 will kill the native app.

Article on VentureBeat website, April 2011.
http://venturebeat.com/2011/04/07/how-html5-
will-kill-the-native-app/.

[24] T. Moore and B. Edelman. Measuring the

perpetrators and funders of typosquatting. In R. Sion,
editor, Financial Cryptography and Data Security, FC
’10, volume 6052 of Lecture Notes in Computer
Science, pages 175–191. Springer, 2010.

[25] Our project site. http://aurora.q2s.ntnu.no/app.
[26] Socialbakers – Applications on Facebook. http:

//www.socialbakers.com/facebook-applications.

[27] J. Tam, R. W. Reeder, and S. Schechter. I’m Allowing

What? Disclosing the authority applications demand
of users as a condition of installation. Technical
report, Microsoft Research, 2010. MSR-TR-2010-54.

[28] Watir – Web Application Testing in Ruby.

http://watir.com.

[29] Web of Trust (WOT). http://www.mywot.com.
[30] WhatApp? A Stanford Center for Internet and

Society website. https://whatapp.org/.

[31] D. M. Wilkinson. Strong regularities in online peer

production. In Proc. of the 9th ACM conf. on
Electronic commerce, EC ’08, pages 302–309. ACM,
2008.

WWW 2012 – Session: Security 1April 16–20, 2012, Lyon, France320