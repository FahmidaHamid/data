Using Content and Interactions for Discovering

Communities in Social Networks

Mrinmaya Sachan Danish Contractor Tanveer A. Faruquie L. Venkata Subramaniam

{mrsachan, dcontrac, ftanveer, lvsubram}@in.ibm.com

IBM Research India

New Delhi, India

ABSTRACT
In recent years, social networking sites have not only enabled
people to connect with each other using social links but have
also allowed them to share, communicate and interact over
diverse geographical regions. Social network provide a rich
source of heterogeneous data which can be exploited to dis-
cover previously unknown relationships and interests among
groups of people. In this paper, we address the problem of
discovering topically meaningful communities from a social
network. We assume that a persons’ membership in a com-
munity is conditioned on its social relationship, the type of
interaction and the information communicated with other
members of that community. We propose generative models
that can discover communities based on the discussed topics,
interaction types and the social connections among people.
In our models a person can belong to multiple communities
and a community can participate in multiple topics. This
allows us to discover both community interests and user in-
terests based on the information and linked associations. We
demonstrate the eﬀectiveness of our model on two real word
data sets and show that it performs better than existing
community discovery models.

Categories and Subject Descriptors
H.2.8 [Information Systems]: Database ApplicationsData
mining; G.3 [Probability and Statistics]: Probabilistic
algorithms

General Terms
Algorithms

Keywords
Community Detection, Social Networks, Probabilistic meth-
ods

1.

INTRODUCTION

Social networking websites provide a unique ability of al-
lowing people in geographically disperse locations to connect
socially over the internet. They provide multiple modes of
communication, enable diverse interaction types and allow
sharing of information with single or multiple people. Col-
leagues, acquaintances, family, friends, fans, activists, etc.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2012, April 16–20, 2012, Lyon, France.
ACM 978-1-4503-1229-5/12/04.

utilize social networks to update each other, communicate
their likes, dislikes, views and share personal and public in-
formation. This ability of rich social interactions has lead to
a substantial increase in the popularity of these sites. Their
popularity can be gauged from the fact that Facebook1, a
popular social networking website started in 2004, has nearly
500 million users while Twitter2, another popular website,
has nearly 125 million users. According to the 2010 Inter-
net and Social Media Consumer Insights report by Nielsen
company, internet users spend nearly 22% of their time on-
line, on social networking websites3. The navigable network
structure, the rich data produced by the users and the aﬃn-
ity of people to these websites has attracted the attention
of academia and businesses alike. They want to use this in-
formation to discover previously unknown relationships and
interests among people. For example, companies want to use
the discovered information to create smarter advertisements,
devise targeted marketing campaigns and exploit cross sell
opportunities. The 2010 Edelman Trust Barometer Report4
found that 44% of the users are likely to respond to online
marketing if there are “similar” users in their peer group who
have responded to the advertisements.

One important problem associated with discovering re-
lationships among people that has received widespread at-
tention is automated discovery of community. A commu-
nity is a collection of users as a group such that there is
high relatedness among people within the group. Discover-
ing communities consisting of “similar” users is an impor-
tant problem and ﬁnds application in areas as diverse as
sociology, biology, marketing and computer science. Orga-
nization of people into communities gives important insights
into group dynamics which can be used for online marketing,
information dissemination and understanding the formation
of clubs, committees and action groups in real world.

This notion of ‘similarity’ between users based on which
people are grouped into communities has been addressed dif-
ferently in previous works. One common approach used is to
treat communities as group of nodes in social network that
are more densely connected among themselves than with the
rest of the network. This essentially makes community dis-
covery a graph clustering problem. However, recently com-
munities are considered as interest groups providing people
interested in similar topics a common forum. For our work,

1http://www.facebook.com
2http://www.twitter.com
3http://blog.nielsen.com/nielsenwire/
4http://www.edelman.co.uk/trustbarometer/ﬁles/edelman-
trust-barometer-2010.pdf

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France331we consider communities as “groups of users (nodes) who
are interconnected and communicate on shared topics”.

In this paper, we propose generative Bayesian models for
extracting latent communities from a social network. The
models assume that community memberships are dependent
on the topics of interest amongst users and their link rela-
tionships in the social graph. Users can belong to multiple
communities and a community can be related to multiple
topics. These relationships are modeled using multinomial
probability distributions. Further, a user may be interested
in multiple topics based on his interest. This is useful in
modeling user interests or roles they play in the network.
We can also determine key topics prevailing in a commu-
nity. This can be useful in locating/searching communities
on given themes and interests.

We also utilize the “type” of interactions between users
to emphasize their interest in topics, and thus community
membership. The type of interaction provides useful infor-
mation to determine the level of participation of a user in
a community. For example, two users engaging in conversa-
tions related to politics (posting replies to each other) are
more likely to be members of a community on politics than
someone who has occasionally broadcasted posts on politics
(for example, during elections in a country).

Finally, we observe that in some social networks there
is a concept of ‘walls’ and ‘user proﬁles’ where users post
messages driven purely by their own interests. Such posts
are broadcasted to his/her neighbors by default. At the
same time, other social networks (like Email networks) have
a philosophy of personalized posts. Users can only send
directed posts to one or few other users. Here, the posts
can be assumed to be of mutual-interest to the sender and
the recipient. We model interest through topics. Hence,
we propose the Topic User Community Model (TUCM) and
Topic User Recipient Community Models (TURCM-1 and
2) for both kinds of social networks. Herein, we make an
assumption that posts in general discuss one topic only. This
reduces the model training times and allows them to scale
better on large data sizes. However, we acknowledge that
this assumption can be weak in some cases, especially when
post sizes are large. Hence, we also give a full TURCM
model that relaxes this assumption.

To the best of our knowledge we are the ﬁrst to use all
three: topics, social graph topology and nature of user inter-
actions to discover latent communities in social graphs. We
evaluated our models on one representative real word social
network of both kinds-Twitter and Enron Email corpus.

In the next section we review some prior work on latent
community discovery in social graphs. The rest of the pa-
per is structured as follows: In Section 3, we incrementally
describe the models and present a Gibbs sampling based
algorithm to infer their parameters.
In Section 4 we give
details about the data sets and experiments to validate our
models. Finally, in Section 5 we conclude our work.

2. PRIOR WORK

Most previous approaches in community discovery use
only the social structure among people to discover commu-
nities. These methods are based on agglomerative cluster-
ing, min-cut based graph partitioning, centrality based and
Clique percolation methods (CPM) [12][2]. As these mod-
els only consider links they fail to account for other node
properties and user interactions in the social graph besides

the graph, such as user interests. Another drawback is that
all of these methods with the exception of CPM perform a
hard-partitioning of nodes in the graph and do not allow
users to have membership in multiple communities.

To overcome this problem associated with hard partition-
ing of users into communities, researchers have proposed
Bayesian probabilistic models for community discovery. Here
extensions of the Latent Dirichlet Allocation (LDA) model
like Simple Social Network LDA (SSN-LDA) [17], Generic
Weighted network LDA (GWN-LDA) [16], Hybrid Commu-
nity Discovery Framework (HCDF) [5] and Hierarchical So-
cial Network-Pachinko Allocation Model (HSN-PAM) [15]
are popular. Although these models allow for mixed com-
munity memberships, they too rely primarily on the link
structure in a social graph to learn communities. For ex-
ample, SSN-LDA [17] introduces a binary relation between
each pair of users. Each user (ui) is characterized by a social
interaction proﬁle (Document in LDA) representing all its
Ii social links (words in that document):
SIP (ui) = {X1 . . . XIi}

The social interaction proﬁle of users is represented as ran-
dom mixtures over latent community variables (Topics in
LDA). Each community is in turn deﬁned as a distribution
over the social link space.

Another class of approaches have tried to utilize the se-
mantic content of social graphs to discover communities. In
[18] the authors propose the CUT (Community-User-Topic)
model which discover communities using the semantic con-
tent of the social graph. Communities are modeled as ran-
dom mixtures over users who in turn have a topical distribu-
tion (interest) associated with them. The model, however,
does not utilize the link information in a graph while dis-
covering communities.

While models like CUT assume that community members
that actively talk about certain topics are connected with
each other, models like SSN assume that users that are inter-
connected share similar interests. Neither is always true in
real world scenarios. In real world social networks, there are
users who are members of communities but do not actively
contribute in them. Also, there are members who may be
vocal about certain topics but may not be connected at all.
Thus, both the graph structure and the interactions between
users should be used to model the formation of communities.
Recently, researchers have started investigating methods
that combine both content and link information available in
social networks. The Community-Author-Recipient-Topic
(CART) model [11], was one of the ﬁrst attempts to combine
previous link based community discovery methods with con-
tent based community discovery. Though, both the CART
model and our models use topics and social graph topol-
ogy to model communities, the generative process in both is
signiﬁcantly diﬀerent. While our models assume that com-
munities are generated based on users, recipients, topics and
links connecting them, the CART model generates authors
(users) and recipients of a post from latent communities.
Since, CART takes into account recipients for every post, it
is impractical for discovering communities in social networks
such as Twitter which allow broadcasts. Practically, the
number of recipients for a message can run into thousands.
Our proposed models scale well to such social networks.

Since CART, there have been few more attempts at com-
bining content and link to obtain community structures more

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France332eﬀectively. The Topic-Link LDA model [8] and Relational
Topic Models [1] draw latent topical and community distri-
butions for every node in document networks. Further, they
generate link between documents based on topical similarity
of the documents and community membership similarities
of their authors. However, the models assume links as bi-
nary. On the other hand, our model utilizes the nature of
interactions between users while modeling communities. In-
tuitively, this is synonymous to using weights in a graph for
community discovery. We presented this idea in [13] where
we introduced a graphical model to account for all three
- Link, Content and Nature of Interaction and established
their supremacy over all previous methods. In this paper,
we provide interesting variations of the graphical model and
provide additional insights on how the choice of social graph
aﬀects the choice of graphical model.

3. COMMUNITY DISCOVERY MODELS

We often observe networks in which posts are broadcasted,
i.e. sent to each neighbor (follower) of the user. In this case,
one can intuitively observe that the post is on a topic of the
users interest and does not account for the interest of the
recipient. Hence, recipient information can safely be ignored
while gauging user interests. A few popular examples of such
networks are Twitter and Facebook. On the other hand, in
other networks like Email networks and Blogger networks,
these message broadcasts might be controlled. In such cases,
post topics characterize a mutual topic of interest between
the sender and the recipient. We propose two generative
models to account for both these kinds of networks.

The notation used by our models is as follows:
Notation: Let U be the set of users in the social network
under consideration. Let Ri be the set of neighbors (recip-
ients) of user (sender) ui ∈ U. For a given user (sender)
ui ∈ U and its neighbor (recipient) uj ∈ Ri, let Pij be the
Pij

set of posts (messages) sent by ui to uj. Let Pi = (cid:83)
P =(cid:83)

uj∈Ri

i

be the set of posts (messages) sent by user(sender) ui and
Pi be the set of posts overall. Let Np be the number
of words in a given post p, p ∈ P. Also let the cardinality
of all these sets (in boldface) be represented by their corre-
sponding capitalized symbols. The sender ui, recipient uj,
the set of words Wp for each post p and the type of posts
Xp are observable variables, while the communities, c, and
topics, z, are considered as latent variables.
3.1 Topic User Community Model

In this section, we describe our ﬁrst generative model
(TUCM) for latent community discovery in such networks.
TUCM discovers communities using the content being dis-
cussed by users in the form of latent topics and the type of
posts generated by them. In the TUCM model, we assume
that a user can belong to multiple communities and have an
interest in multiple topics. We also use the “type” of commu-
nication to improve community discovery. The idea being
that two users who share a series of posts (messages) with
each other, are likely to communicate on certain common
topics, indicating similar interests and therefore, should be
members of the same community. The type of communica-
tion indicates the strength of association between two users
and their interest in a topic. The type of interaction varies
from one social graph to another. User uploads/downloads,

comments, wall posts, shared photographs, tags, etc can be
considered as interactions in social networks. For example,
in Twitter, there are three types of interactions - a conven-
tional tweet (broadcast tweet), a reply tweet and a re-tweet.
For a conventional tweet, all the “followers” of the user are re-
cipients. A reply post is one where a user has been “tagged”
and replied to (Twitter denotes this as “@recipient” followed
by the message). Finally, a retweet is one when a user de-
cides to forward a post of another user. (Twitter denotes
this as “RT@orginal sender name”). A reply tweet or a re-
tweet clearly indicates a greater association between users
and mutual interest in the underlying topic being discussed.
In case of an email social graph, the types of posts ﬁt the
traditional model of email; that is replies, forwarded emails
and mailing lists subscriptions.

A typical social network G(U, E), where U is the set of
users (nodes) and E is the set of edges connecting them.
On top of this graph we have a collection of posts (interac-
tions) authored and exchanged among the set of users U.
Interactions are typed as described above.

Motivated by SSN-LDA [17], we represent every user as a
combination of his interaction space. Each user (ui) is char-
acterized by a social interaction proﬁle representing all its
Pi interactions (post types): SIP (ui) = {X1 . . . XPi}. The
social interaction proﬁle of users is represented as random
mixtures over latent community variables. Each community
is in turn deﬁned as a distribution over the interaction space.
This idea is analogous to LDA, where the social interaction
proﬁle is a document, interactions are words in that docu-
ment and communities are latent topics.

The number of topics Z and the number of communities C
to be discovered are speciﬁed apriori as model parameters.
Let the size of the vocabulary from which the communica-
tions between users are composed be V . This vocabulary is
constructed using the words that are used in the communi-
cations. The number of diﬀerent type of communications is
X. Let DirY (α) denote a Y-dimensional symmetric Dirich-
let with scalar parameter α and M ult(.) denote the discrete
multinomial distribution.

Using plate notation TUCM model is shown in ﬁgure 1a

and has the following generative scheme:

1. For each of the topics, 1 ≤ z ≤ Z, sample a V dimen-
sional multinomial, (cid:126)λz ∼ DirV (δ). This distribution
represents the topic as distributions over words.

2. For each of the communities, 1 ≤ c ≤ C sample a X
dimensional social interaction mixture (cid:126)φc ∼ DirX (β).

3. For the ith user ui, 1 ≤ ui ≤ U :

(a) Sample a Z dimensional vector of topic propor-

tions, (cid:126)ηui ∼ DirZ (ν).

(b) For each topic z ∈ Z, sample a C dimensional
multinomial, (cid:126)θui,z ∼ DirC (α), representing the
community proportions for that topic and sender.
(c) For each post p (1 ≤ p ≤ Pi) generated by the

sender ui having Np words:
i. Choose a topic assignment zp ∼ M ult((cid:126)ηui )

zp ∈ [1 : Z] for the post.

ii. Choose a community assignment cp.

cp ∼ M ult((cid:126)θui,zp ), cp ∈ [1 : C] for the post.

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France333Figure 1: Plate notations of (a) TUCM (b) TURCM-1 (c) TURCM-2 (d) Full TURCM

iii. Choose a social interaction type Xp ∼ M ult((cid:126)φcp ),
iv. For every slot j, 1 ≤ j ≤ Np in p, choose a

Xp ∈ [1 : X] for the post.
word wj ∼ M ult((cid:126)λzp ).

In the above generative process we assume that every
sender(ui) has a multinomial distribution over topics, (cid:126)ηui
that represents his interest for each topic. Assuming that
the user ui posts based on his inherent interest, the topic
for each post p ∈ Pi generated by him is sampled from this
user dependent topic distribution. The community assign-
ment, cp, of the post is dependent on the user and the topic
of the post. Since, social interaction proﬁles were assumed
to be random mixtures over latent communities, the inter-
action type is ﬁnally generated from the community speciﬁc
distribution.

Let W be the set of words in the corpus, X be the set of
interaction types observed on the social graph among the U
set of users (senders). Let Z and C be the set of latent topic
and community assignments for every post. The joint prob-
ability distribution of users, posts, interaction types, topic
and community assignments given by the TUCM model is

L = P (W, X, U, Z, C, θ, φ, η, λ|α, β, ν, δ)

Using the graphical model, this can be factorized as:

L =

P (W|Z; λ)P (X|C; φ)P (Z|U; η)
P (C|Z, U; θ)P (θ|α)P (φ|β)P (η|ν)P (λ|δ)

3.1.1 Parameter Estimation
Due to parameter couplings in the models, calculating ex-
act posterior probabilities over all the hyper-parameters is
intractable. However, the conditional distribution of each
variable is much easier to sample from. Hence we use a
Block-Gibbs sampling based approximate inference. We sam-
ple the topic assignment and community assignment for each
post from a conditional distribution for this assignment given
the observation and other assignments. This leads to a
Markov chain where state transitions are simulated by re-
peatedly sampling from the conditional distributions given
below.
Inspired by the mixture of unigrams, the model
makes only one topic draw for each post, and subsequently
samples as many words as in the post from the topic-word
distribution corresponding to it. We represent Wp as the set
of words in a given post p, Np as the number of words in the
post and N p
w as the number of times a given word w occurs
in p. Let C−p, X−p, Z−p and W−p represent the commu-
nity, post type, topic assignments and the set of words ex-
cept post p. Gibbs sampling is carried out by starting with

a random assignment to all the latent variables, using the
update equations to compute fresh latent assignments over
a large burn-in period. When this distribution stabilizes,
suﬃcient number of samples are taken at regular intervals
to avoid correlation. The Gibbs update equations for the
TUCM model are:

P (cp = c|C−p, Z, U) =

n

−p
c(uz) + α
−p
n
c(cid:48)(uz) + Cα

n−p
xc + β
−p
n
x(cid:48)c + Xβ

n−p
zu + ν
−p
n
z(cid:48)u + Zν

c(cid:48)

x(cid:48)

(cid:80)
(cid:80)
(cid:80)
w(cid:81)
(cid:81)
((cid:80)
Np−1(cid:81)

w∈Wp

N p

z(cid:48)

i=0

w(cid:48)

(n−p

wz + i + δ)

i=0

−p
w(cid:48)z + i + V δ))

(n

P (xp = x|X−p, C) =

P (zp = z|Z−p, U) =

P (Wp = w|W−p, Z) =

where n

a(b1...bv ) represents the number of times a,(1 ≤
−p
a ≤ A) is generated from the combination of variables b1 . . . bv
in the model, (1 ≤ bi ≤ Bi, 1 ≤ i ≤ v) excluding post p.
The procedure for the Gibbs Inference is given below:

Assign a random community, topic and type to p

Algorithm 1 Gibbs Inference for TUCM
1: /* Initialization */
2: for all posts p ∈ P do
3:
4: end for
5: /* Markov chain convergence */
6: i ← 0
7: I ← Desired Number of Iterations
8: while i < I do
9:
10:
11:
12:
13:
14:
15:
16: end while

for all posts p ∈ P do

end for
i++

Estimate P (cp, zp, xp, Wp|C−p, Z−p, X−p, W−p)
(c, z, x) ∼ P (cp, zp, xp, Wp|C−p, Z−p, X−p, W−p)
Assign community c, topic z and type x to p
record assignment (c; z; x; Wp)

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France334and ‘I ×(cid:80)

An I iteration Gibbs sampling does ‘IP CXZ’ computa-
tions for assigning topic, community and types to each post
p∈P Wp = IW ’ computations for drawing each
word in the posts. Hence, the algorithm has the worst time
complexity O(IP CXZ + IW ).

Topics can be computed using the approximation :

P (w|z) =

(cid:80)

w(cid:48)

n−p
wz + δ
−p
n
w(cid:48)z + V δ

Another approach is to ﬁnd the maximum likelihood esti-
mate for P (w|z) using P (W|z).

P (wi|z) =

P (wi|Wj)P (Wj|z)

P(cid:88)

j=1

N p
wi
Np

where, P (wi|Wj) =

and P is the number of posts in
the corpus. We observed that the results are similar in both
approaches. For the sake of simplicity, we choose the MLE
approach.
The community memberships P (u|c) and topic proportions
for a community P (z|c) are also estimated in a similar man-
ner. The P (u|c) computation gives us the community as
a distribution over users while P (z|c) gives us the topical
interest in each community.
3.2 Topic User Recipient Community Model 1
Now, we describe the model to capture user interests in the
second kind of networks which do not allow mass messaging.
In such networks, the sender typically sends out messages
to his/her acquaintances. Consequently, the posts are on
a topic of interest to both the sender and the recipient of
the post. Figure 1b shows the TURCM-1 model where the
post topics and communities are generated corresponding to
sender-recipient pair for the post.

The generative scheme for TURCM-1 closely follows that
of the TUCM described above. Multinomials (cid:126)ηui,uj and
(cid:126)θui,uj are drawn for every sender-recipient pair and the post
topic and community assignments are drawn from them re-
spectively using appropriate sender-recipient indices.

The Gibbs Sampling updates for TURCM-1 are similar
with user u replaced by a user-recipient pair ur. Since the
recipient information is only used as an index (to signify
mutual interest:there are no extra draws) the worst case time
complexity continues to be O(IP CXZ + IW ) as for TUCM.
3.3 Topic User Recipient Community Model 2
TURCM -1 accounted for recipient information of posts
by ensuring that topic and community assignments for posts
are not only based on users but user-recipient pairs of posts.
However, this is not the same as accounting for links in a
social graph as it does not in any way ensure formation of
closely knit communities as closeness in the the link struc-
ture is not explicitly captured.

Next, we describe another variation which models recip-
ients diﬀerently. Network neighborhood is modeled as an
interaction. We again go back to the Social interaction pro-
ﬁle (SIP) formulation described earlier and generate post
recipients corresponding to the community drawn. This is
the same as representing each user in the social graph as a
document with user indices of its neighbors as words. Com-
munities will cluster nodes with similar neighborhood in one

P (Rp = r|R−p, C) =

(cid:81)
Rpi−1(cid:81)
((cid:80)

r∈Rpi

j=0

r(cid:48)

(n−j
crpi

+ )

−j
r(cid:48)c + i + U ))

(n

community just as LDA clusters similar words as topics! Fig-
ure 1c shows the TURCM-2 model.

The generative scheme for TURCM-2 is also on the lines
of TUCM. Multinomials (cid:126)ηui and (cid:126)θui are drawn for every
user. The recipients in the set of recipients Rp of post p are
drawn from the multinomial (cid:126)ψcp based on the community
assignment drawn for the post.

The Gibbs Sampling updates to infer TURCM 2’s param-

eters contain an additional update for the recipient draw.

overhead of ‘I ×(cid:80)

where Pi is the post under consideration.

The additional draws for recipients have an additional
p∈P Rp = IR’ computations over TUCM,
where R is the sum of number of recipients for all the posts
in the corpora. Hence, the worst case time complexity for
Full TURCM becomes O(IP CXZ + IW + IR).
3.4 Full TURCM

In this section we describe the Full TURCM model which
is another modiﬁcation to the earlier models. In previous
models we have assumed that each post generated by a user
is based on a single topic. This assumption may not hold
true for networks which have large post sizes - for Example,
the Enron email network data set. The Full TURCM model
removes this assumption by generating a topic for each word
in a post (instead of generating a topic per post). Further,
as a result of this modiﬁcation we now, generate posts based
on the community that an author belongs to. The generative
model shown in ﬁgure 1d is explained below in detail:

1. For each of the topics, 1 ≤ z ≤ Z, sample a V dimen-
sional multinomial, (cid:126)λz ∼ DirV (δ). This distribution
represents the topic as distributions over words.

2. For each of the communities, 1 ≤ c ≤ C sample a
X dimensional social type interaction mixture (cid:126)φc ∼
DirX (β).

3. For each of the communities, 1 ≤ c ≤ C sample a U
dimensional social recipient interaction mixture (cid:126)ψc ∼
DirU ().

4. For the ith user ui, 1 ≤ ui ≤ U :

(a) Sample a C dimensional multinomial, (cid:126)θui ∼ DirC (α),

representing the community proportions for that
sender.
(b) For each community c ∈ C, sample a Z dimen-
sional multinomial, (cid:126)ηui,c ∼ DirZ (ν), representing
the topic proportions for community and sender.
(c) For each post p (1 ≤ p ≤ Pi) generated by the

sender ui: having Np words:
i. Choose a community assignment cp ∼ M ult((cid:126)θui )
ii. For each recipient slot i, 1 ≤ i ≤ Rp of the

cp ∈ [1 : C] for the post.

post p:
A. Choose a recipient rp ∼ M ult( (cid:126)ψcp )

rpi ∈ [1 : Rp] for the post.

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France335iii. Choose a social interaction type Xp ∼ M ult((cid:126)φcp ),
iv. For each word slot j, 1 ≤ j ≤ Np in p:

Xp ∈ [1 : X] for the post.

z ∈ [1 : Z].

A. Choose a topic assignment z ∼ M ult((cid:126)ηui,cp ),
B. Choose a word wj ∼ M ult((cid:126)λzwj

).

3.4.1 Parameter Estimation
The Gibbs sampling update equations for the Full TURCM

cu + α
−p
n
cu + Cα

(cid:80)

x(cid:48)

n−p
xc + β
−p
n
xc + Xβ

×

model are attained as:

(cid:80)
P (cp = c|C−p, U, R, X, Z) ∝ n−p
Z(cid:81)
Z(cid:80)

nr(cid:48)c + i + Rpi 

(cid:89)

(cid:80)

ncr + 

z=1

c(cid:48)

r∈Rp

r(cid:48)

Internet

H1N1

Stock Markets

Travel
arrive

free

monday

download

pm

friday
midday

msn

explorer
internet

inﬂuenza
symptom
america
chicken

cure

curve
shift
daily

market
numbers

Table 1: Topics extracted from Twitter dataset

California Power Gas Transportation Trading

power

transmission

energy
calpx

california

gas

energy
enron
transco

chris

price

market
dollar
nymex
trade

Deals
meeting
contract

report
enron
deal

Γ(ep,zu + n

−p
z(cpup) + β)

Table 2: Topics extracted from Enron

ep,zu + n

−p
z(cpup) + Zβ)

Γ(

z=1

where, ep,zu is the number of times topic z was generated
from user u other than post p.

(cid:80)
−(p,i)
z(cu) + ν
P (z(p,i) = z|Z−(p,i), C, U, ¯W) ∝ n
−(p,i)
n
z(cid:48)(cu) + Zν
z(cid:48)

(cid:80)

w(cid:48)

n

−(p,i)
wz + δ
−(p,i)
n
w(cid:48)z + Zδ

The Full TURCM model, by relaxing the assumption that
a post is always on a single topic incurs the overhead of
drawing the topic assignment for each word (and not each
post) in the corpus. The number of computations for as-
signing topics to each word grows to IZW , and the overall
complexity to O(IP CX + IZW ). However this computa-
tional overhead is compensated by improvements in quality
of community discovery, especially when posts are too long
and hence on more than one topic.

4. EXPERIMENTS

In this section, we evaluate our models on two real world
data sets and compare them with the CUT and CART mod-
els. Most well known deﬁnitions of communities lay empha-
sis on two things: How tightly users in a community are
inter-connected, and how strongly the users in a community
share interests?
Our models discover shared interests from content produced
by the users. To begin with, we give a qualitative evaluation
of the communities obtained and try to argue how topics,
links and types combine to produce communities eﬀectively.
We evaluate the strength of inter-connections in the com-
munity structure by computing the fuzzy modularity [7] of
the communities obtained. Modularity is a popular measure
used to quantify the quality of division of a network into
modules or communities. Finally, we show learning time
improvements over the two models.
4.1 Datasets

We use two diﬀerent datasets for our experiments, one is
the freely available collections of tweets crawled from Twit-
ter over a period of six months in 2009 [14] [6] and the
other is the Enron Email corpus5. Twitter is a social net-
working and micro blogging service where users communi-
cate by short text messages (up to 140 characters) called

5http://www.cs.cmu.edu/ enron/

‘tweets’. Tweets are publicly visible by default. However
senders can restrict message delivery. Users may subscribe
to other users’ tweets by following them. These follower
relationships impose an underlying graph structure. On
the other hand, the Enron dataset contains email exchanges
from about 150 employees, mostly senior management. We
choose these two datasets for the diversity and challenges
they bring along with them. While Twitter imposes a re-
striction on the length of posts, the number of followers of
a user can run into millions. In a social graph, these nodes
(users) are sometimes called ‘star nodes’. This is a case
when the graph is dense but the associated content is much
smaller. On the other hand, while the Enron dataset has
fewer nodes, emails can be arbitrarily long; case of a sparse
graph but rich content. Scaling a technique that integrates
both content and link to such diverse datasets is an impor-
tant challenge. Probabilistic techniques like those employed
by us that work on word frequencies have the added advan-
tage that they are less susceptible to noise. We do not have
to undergo extensive data cleansing or data preparation.

We crawled a sub-graph from Twitter for our analysis us-
ing a simple heuristic approach. We began from a set of
inﬂuential seed nodes and grew the graph by using follower
relationships. The Twitter dataset used for our experiments
has 5405 nodes, 13214 edges and 23043 posts. The link
types as described in section 3 are retained and the posts
are preprocessed to remove stop words on both datasets.
4.2 Results

In all the models presented above, Z and C, the number
of topics and the bumber of communities respectively are
free parameters. This requires some sensitivity analysis and
introduction of quality functions (such the modularity) in
order to ﬁx the best values. We will describe our strategy
for optimal parameter setting later.

For all our simulations, we set the number of communities
C at 10 and topics Z at 20 unless stated otherwise. These
choices are later proved to be close to the optimal in Sec-
tions 4.2.2 and 4.2.3 We ran 1000 iterations to burn in and
took 250 samples (every fourth sample) in the next 1000
iterations.
4.2.1 Qualitative Analysis
In Table 2 and 3, we list a few topics ((cid:126)λz) discovered by
TUCM over both datasets. We give top 5 words to visualize

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France336Management Engineering

Analyst

contract
agreement

meeting

corporation

budget

Power

Transmission

Electric

epsa
calpx

price
dollar
cash

database
meeting

Table 3: Role discovery for users

each topic. Here “calpx” is the California Power Corpora-
tion, “transco” is a gas transportation company and “nymex”
is the New York Mercantile Exchange. We see that TUCM
is able to discover meaningful topics, thus validating the as-
sumption that each post is associated with a single topic.
This is particularly true for the Twitter corpus (where post
lengths are constrained) and generally true for the Enron
corpus as seen in later experiments. Topic visualization was
similar in other models, with only minor changes.

Next, in ﬁgure 2 we illustrate the probability density over
topics ((cid:126)ηui ) for a particular Twitter user (user 93). It shows
that this user is primarily interested in topic 14 (Stock Mar-
kets) and also likes topics 4 (Internet). This analysis is useful
in ﬁnding individual user’s interests and tastes. [9] showed
how one can discover social roles of people by associating
words with users (i.e. P (w|u)) through their topical inter-
ests.
In Table 3 we give top words for a few roles using
the Enron corpus. From these words we can see that so-
cial roles are nothing but work proﬁles for people working
in Enron, like management, engineering and analyst. These
social roles were conﬁrmed against their true roles in Enron.
It is also possible to uncover community membership pro-
portions (i.e. P (c|u)) for every user. For instance, in ﬁgure
3, user 93 has a membership in community 4 to a high de-
gree. Besides, the model suggests that the user also partici-
pates in community 6 to some extent. This analysis gives us
an insight to the extent of participation of a user in various
social groups. This probabilistic notion of membership has
clear advantages in modeling user tastes and preferences to
the hard clustering approach taken in previous non proba-
bilistic approaches for community discovery.

Now that we know how to estimate user interests and
community memberships, we can also compute the topical
interest of the communities formed by those users. With
this analysis we can corroborate the intuition that commu-
nities are formed when users with similar interests aggregate
together. In Figure 4, we show the topic distributions for
diﬀerent communities. Topical peaks for a community indi-
cate the dominant topics for that particular community (i.e.
P (z|c)). For example, after looking at the topic proportions
for community 4 (see ﬁgure 5), which is the primary commu-
nity for user 93, it was found that topics 14(Stock Markets)
is the dominant topic in this community. Also topic 4 (In-
ternet) is the dominant topic in community 6 (recall that
user 93 also has a high membership in community 6). This
kind of analysis supports our hypothesis that users tend to
communicate frequently over certain topics (based on inter-
ests) and form communities which discusses them to varying
degrees. Similar visualization is possible for all four models.

4.2.2 Community Analysis
Next, we evaluate the quality of communities discovered
by these models against communities discovered by the CUT
and the CART models.

Figure 2: Topic proportions for a user

Figure 3: Community proportions for a user

Newman [10] proposed modularity, a measure of goodness
for community structure. It assumes that a good division
of the network is not merely one in which the number of
edges running between groups is small. Rather, it is one in
which the number of edges between groups is smaller than
expected. Modularity, Q is deﬁned as:

Q =

(number of edges within communities)
−(expected number of such edges)

While the application of modularity has been questioned
from time to time (like in [3] and [4]), it continues to be the
most popular and widely accepted measure of the goodness
of community structure. Since the output of all our prob-
abilistic models is a fuzzy community structure, in which
each node has a certain probability of belonging to a certain
community; we use a fuzzy variant of modularity Qf pro-
posed in [7]. Hence, Fuzzy Modularity provides a measure
of goodness for the fuzzy community structure in networks.
For a particular fuzzy partition of a graph with n nodes
and m edges where {ρk(x)}n
k=1 is the fuzzy membership of
n nodes in the k communities (S1 . . . Sk), the approach is
to classify nodes according to the majority rule, i.e. if k =
argmaxlρl(x) for a given node x then we set x ∈ Sk. Then
the fuzzy modularity Qf is deﬁned as:

(

ρk(x) + ρk(y)

2

e(x, y) − pE

f (x, y))

n(cid:88)

(cid:88)

Qf =

1
2m

k=1

x,y∈Sk

where pE
f (x, y) is the expected probabilistic number of edge
; x, y ∈ Sk and
e(x, y) with the form pE
df (x) is the extended degree of node x in community Sk
under the probabilistic setting and given by

f (x, y) = df (x)df (y)

2m

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France337Number of

Communities

6

8

10

12

14

TUCM

TURCM-1
TURCM-2

0.167
0.168
0.166
Full TURCM 0.171
0.157
0.159

CART
CUT

0.263
0.261
0.265
0.272
0.227
0.244

0.321
0.309
0.324
0.332
0.243
0.299

0.313
0.287
0.309
0.316
0.235
0.285

0.262
0.241
0.261
0.267
0.196
0.237

Figure 4: Distribution of topics within communities

Number of

Communities

6

8

10

12

14

Table 4: Fuzzy modularity on the Twitter dataset

TUCM

TURCM-1
TURCM-2

0.148
0.198
0.203
Full TURCM 0.215
0.152
0.133

CART
CUT

0.243
0.271
0.278
0.294
0.249
0.231

0.291
0.339
0.346
0.363
0.302
0.266

0.287
0.331
0.337
0.350
0.294
0.278

0.246
0.283
0.289
0.299
0.255
0.227

Table 5: Fuzzy modularity on the Enron dataset

give interesting insights on how important role the choice of
model plays. While models like TURCM-1 and TURCM-2
and CART are less suitable for sparse datasets like Twit-
ter where link information is not dominant, they become
increasingly important when the social graph information is
rich. Similar trends are also observed in perplexity compar-
isons that are provided next.
4.2.3 Perplexity Analysis
Perplexity is one of the most important measures used
to evaluate language models, especially topic models. Intu-
itively, it measures the log likelihood of generating unseen
data after learning from a fraction of data. A higher value
of perplexity implies a lesser model likelihood and hence
lesser generative power of the model. As against most topic
models where data is just the set of words, we compute the
perplexity of observing both link types and words.

We analyze and compare the perplexity of our models for
the two datasets with the CUT and CART models. We
divided the data into training and test portions randomly
in diﬀerent proportions and investigated how perplexity be-
haves as more and more data is used for training. Let Ntotal
be the size of the corpus. Let p1 . . . pN be the posts used for
training and pN +1 . . . pNtotal be used for testing.

− log P (pN +1 . . . pNtotal|p1 . . . pN )

Perplexity = exp

Ntotal − N
Since each post is generated independently,

(cid:18)

(cid:19)

test(cid:89)

i=N +1

P (pN +1 . . . pNtotal|p1 . . . pN ) =
(cid:88)

(cid:88)

For the TUCM model, post likelihood can be computed as:
P (pi|p1 . . . pN ) =

λwz

θcupi zφcxpi

ηzupi

P (pi|p1 . . . pN )

(cid:89)

w∈Wpi

z∈Z

c∈C

For the rest, the likelihoods can be computed accordingly.

First, we explore the perplexity of our models on the
two datasets. We also compare our models with CUT and

Figure 5: Distribution of topics in community 4

df (x) =

(cid:88)
(cid:88)

z∈Sk

+

ρk(x) + ρk(z)

e(x, z)

2

ρk(x) + (1 − ρk(z))

z /∈Sk

2

e(x, z)

Tables 4 and 5 compares the fuzzy modularity of our mod-
els with their peers (CUT and CART). Full TURCM ﬁnds
most meaningful communities as it not only integrates all
three links, post types and content but also does not force
every post to be on one topic. TUCM does well on the Twit-
ter dataset as it can better model the short messages, poor
content and noise present in Twitter data. On the other
hand, in the Enron email dataset broadcasting is not al-
lowed. Since users post directed messages to other users,
the topic is of interest to both the user and the recipi-
ent. Consequently, recipient information becomes very rele-
vant. Hence, TURCM-1 and TURCM-2 do well on Enron.
TURCM-2 outperforms TRUCM-1 in both datasets due to
better modeling of recipients.

Finally, the high modularity values support our assump-
tion that people who share common interests and are inter-
connected with each other in the social graph often form
communities. Modularity is an important measure in our
claim as one is always interested in strong-knit communities
where people know each other as well as share common in-
terests for reasons such as networking and task assignment.
Methods that form communities purely on interest can end
up with disparate people (who do not know each other and
are disconnected in the graph) in one community. This is
shown by much weaker numbers for the CUT model in Ta-
bles 4 and 5 . The number of topics was set to 20 for these
experiments as we vary the number of communities.

These results not only establish better community model-
ing by our models than its peers (CUT and CART) but also

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France338Figure 6: Perplexity on Enron vs (a) Percentage of data seen (b) No. of Topics (c) No. of Communities

Figure 7: Perplexity on Twitter vs (a) Percentage of data seen (b) No. of Topics (c) No. of Communities

CART in terms of perplexity. Figures 6 and 7 give the com-
parison. As expected perplexities fall with the amount of
data seen, suggesting an improvement in model tuning as
more and more data is encountered. Again, Full TURCM
does the best on both datasets which can be accredited
to its better modeling of topics. TUCM does a better on
the Twitter dataset than Enron. This is because the post
length constraint in Twitter better suits the mixture of uni-
grams assumption. Also, we can observe TUCM outperform
TURCM-1 and TURCM-2 for the Twitter dataset. This is
because the large volume of broadcast tweets in the Twitter
data set makes the recipient interest in a topic less relevant.
However, TURCM-1 has an edge over TUCM in the Enron
dataset due to the absence of broadcast messages. Consis-
tently good values for perplexity on the two diverse datasets
for all the models indicates the generalization ability of the
models despite variability in graph density, link types, noise
and post lengths. The results also establish signiﬁcant im-
provements by the models over the CUT and CART models.
This is because our models not only generate topic based
communities but also account for graph topology and link
types which are important descriptors of the strength of re-
lationship between users. The results also conﬁrm to our
intuition that in some cases (like Twitter), the post topics
model user’s (author’s) interests alone, while in other cases
they model joint interest of the sender and the recipient.
For these reasons, CART doesn’t perform too well on the
Twitter dataset and CUT doesn’t perform well on ENRON.
Finally, in order to comment on optimal model parame-
ter settings (number of topics and communities), we analyze
how model perplexities behave as the model parameters are
changed. Figures 6 (b) and 7 (b) plot the perplexities against

the number of topics. The number of communities was set
to 10 for this experiment. In both datasets for all the mod-
els, it can be roughly concluded that the peplexities attain
their minimum at around 20-25 topics. Figures 6 (c) and
7 (c) plot the perplexities against the number of communi-
ties. The number of topics was set to 10 for this experiment.
Again, for both the datasets, it can be concluded that the
perplexities attain their minimum at around 10-12 commu-
nities. Similar insights were obtained about the number of
communities from Tables 4 and 5 where the fuzzy modulari-
ties optimize around 10 communities for both datasets. This
analysis not only helps us in concluding that our models out-
perform the two baselines (CUT and CART) independent of
model parameter settings (Number of Topics and Number of
Communities) but also in obtaining an estimate on optimal
model parameter settings for both datasets.
4.2.4 Runtime Analysis
One major bottleneck with probabilistic models for so-
cial networks is their scalability. Social networks like Twit-
ter and Facebook run into millions of nodes and probabilis-
tic models due to an involved inference mechanism cannot
scale to these sizes. Next, we compare the training time
of the TUCM model against CUT and CART models. Ta-
ble 6 gives the speed-ups: proportional increase in train-
ing times (the ratio of training times of the models over
that of TUCM) against the number of nodes in the net-
work. All simulations have been done on the same archi-
tecture and platform. In all models, training is assumed to
ﬁnish when the model likelihoods converge (change in likeli-
hood over consecutive iterations falls below 1% of the likeli-
hood recorded in the previous iteration). The improvements

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France339Number of Nodes CUT CART TURCM1 TURCM2 Full TURCM

152
351
1049
2558
5405
8486

1.10
1.21
1.49
1.63
1.81
2.37

1.22
1.35
1.64
1.77
1.99
2.73

1.02
1.04
1.13
1.19
1.23
1.34

1.07
1.16
1.29
1.34
1.52
1.86

1.29
1.42
1.95
2.97
4.23
8.12

Table 6: Training time speed up of TUCM over other models

are primarily because of the mixture of unigrams approach
adopted in TUCM where we draw one topic for each post un-
like CUT and CART models which encounter the overhead
for each word in the post. CUT model does marginally bet-
ter than CART. This is because the recipient information is
less relevant community modeling in Twitter.

Among the four models presented in this paper; although
TURCM-1 has the same worst case complexity as TUCM,
it has a slightly greater overhead of accounting for recipi-
ent indices. TURCM-2 makes additional computations in
drawing recipients of the posts. More importantly, due to
the overhead of topic generation for each word, Full TURCM
takes signiﬁcantly longer for the likelihood to converge. This
speedup over models which do not make a unigram assump-
tion continues to grow with data sizes rendering such mod-
els practically unusable in real size social networks. Conse-
quently, the value of models like TUCM which model type
information intelligently and eﬃciently can be realized.

5. CONCLUSION

We began by positing that communities are formed by
users who communicate on topics of mutual interest, are
connected to each other in the social graph and share fre-
quent personal communication. We discriminated between
datasets where posts modeled author interests alone or mu-
tual interest between the author and the recipient. To cover
both cases, we proposed probabilistic schemes that incorpo-
rate topics, social relationships and nature of posts for more
eﬀective community discovery. We argued that interaction
types are important indicators of the strength of association
between users. Our models give us the capability of visual-
izing the topics a community is interested in besides oﬀering
topic modeling capabilities and discovering topics of interest
for a user. Finally, we show superior community discovery
results in the form of fuzzy-modularity and perplexity im-
provements. Our models also show signiﬁcant reduction in
training time over their closest peers making them scalable
to large real-life social networks.

6. REFERENCES
[1] J. Chang and D. Blei. Relational topic models for

document networks. In AIStats, 2009.

[2] S. Fortunato. Community detection in graphs. Physics

Reports, 486(3-5):75 – 174, 2010.

[3] S. Fortunato and M. Barthelemy. Resolution limit in

community detection. Proceedings of the National
Academy of Sciences, 104(1):36–41, 2007.

[4] B. H. Good, Y.-A. de Montjoye, and A. Clauset.

Performance of modularity maximization in practical
contexts. Phys. Rev. E, 81:046106, Apr 2010.

[5] K. Henderson, T. Eliassi-Rad, S. Papadimitriou, and

C. Faloutsos. Hcdf: A hybrid community discovery
framework. In SDM 10, 2010.

[6] H. Kwak, C. Lee, H. Park, and S. Moon. What is

Twitter, a social network or a news media? In
Proceedings of the International Conference on World
Wide Web, 2010.

[7] J. Liu. Fuzzy modularity and fuzzy community

structure in networks. The European Physical Journal
B - Condensed Matter and Complex Systems,
77:547–557, 2010. 10.1140/epjb/e2010-00290-3.

[8] Y. Liu, A. Niculescu-Mizil, and W. Gryc. Topic-link
lda: joint models of topic and author community. In
Proceedings of the 26th Annual International
Conference on Machine Learning, ICML ’09, pages
665–672, New York, NY, USA, 2009. ACM.

[9] A. Mccallum, A. Corrada-emmanuel, and X. Wang.

Topic and role discovery in social networks. In In
IJCAI, pages 786–791, 2005.

[10] M. E. J. Newman. Modularity and community

structure in networks. Proceedings of the National
Academy of Sciences, 103(23):8577–8582, 2006.

[11] N. Pathak, C. DeLong, A. Banerjee, and K. Erickson.

Social topics models for community extraction. In
Proceedings of the 2nd SNA-KDD Workshop, 2008.

[12] M. A. Porter, J.-P. Onnela, and P. J. Mucha.

Communities in networks. Notices of the American
Mathematical Society, 56(9):1082 – 1097, 2009.

[13] M. Sachan, D. Contractor, T. A. Faruquie, and L. V.

Subramaniam. Probabilistic model for discovering
topic based communities in social networks. In CIKM,
pages 2349–2352, 2011.

[14] J. Yang and J. Leskovec. Patterns of temporal

variation in online media. In ACM Conference on Web
Search and Data Mining, 2010.

[15] H. Zhang. Hsn-pam: Finding hierarchical probabilistic

groups from large-scale networks, 2010.

[16] H. Zhang, C. L. Giles, H. C. Foley, and J. Yen.

Probabilistic community discovery using hierarchical
latent gaussian mixture model. In Proceedings of the
Conference on Artiﬁcial intelligence, 2007.

[17] H. Zhang, B. Qiu, C. L. Giles, H. C. Foley, and

J. Yen. An lda-based community structure discovery
approach for large-scale social networks. In In IEEE
Conference on Intelligence and Security Informatics,
pages 200–207, 2007.

[18] D. Zhou, E. Manavoglu, J. Li, C. L. Giles, and

H. Zha. Probabilistic models for discovering
e-communities. In Proceedings of the International
Conference on World Wide Web, 2006.

WWW 2012 – Session: Community Detection in Social NetworksApril 16–20, 2012, Lyon, France340