Strategic Formation of Credit Networks

Pranav Dandekar
Stanford University

ppd@stanford.edu

Ashish Goel

Stanford University

ashishg@stanford.edu

Michael P. Wellman
University of Michigan
wellman@umich.edu

Bryce Wiedenbeck
University of Michigan
btwied@umich.edu

ABSTRACT
Credit networks are an abstraction for modeling trust between agents
in a network. Agents who do not directly trust each other can trans-
act through exchange of IOUs (obligations) along a chain of trust
in the network. Credit networks are robust to intrusion, can enable
transactions between strangers in exchange economies, and have
the liquidity to support a high rate of transactions. We study the
formation of such networks when agents strategically decide how
much credit to extend each other. When each agent trusts a ﬁxed
set of other agents, and transacts directly only with those it trusts,
the formation game is a potential game and all Nash equilibria are
social optima. Moreover, the Nash equilibria of this game are equiv-
alent in a very strong sense: the sequences of transactions that can
be supported from each equilibrium credit network are identical.
When we allow transactions over longer paths, the game may not
admit a Nash equilibrium, and even when it does, the price of anar-
chy may be unbounded. Hence, we study two special cases. First,
when agents have a shared belief about the trustworthiness of each
agent, the networks formed in equilibrium have a star-like structure.
Though the price of anarchy is unbounded, myopic best response
quickly converges to a social optimum. Similar star-like structures
are found in equilibria of heuristic strategies found via simulation.
In addition, we simulate a second case where agents may have vary-
ing information about each others’ trustworthiness based on their
distance in a social network. Empirical game analysis of these sce-
narios suggests that star structures arise only when defaults are rela-
tively rare, and otherwise, credit tends to be issued over short social
distances conforming to the locality of information.

Categories and Subject Descriptors
K.4.4 [Computing Milieux]: Electronic Commerce; J.4 [Computer
Applications]: Social and Behavioral Sciences—Economics

General Terms
Theory, Economics

Keywords
trust, credit networks, strategic network formation, empirical game-
theoretic analysis

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2012, April 16–20, 2012, Lyon, France.
ACM 978-1-4503-1229-5/12/04.

1.

INTRODUCTION

The study of strategic network formation seeks to understand the
emergent behavior and properties of a network when self-interested
agents establish connections to other agents based on their local in-
formation. In general, establishing a connection incurs a cost but
also yields some beneﬁt to agents connected through that edge. The
agents are deemed to be utility-maximizing, that is, they make de-
cisions in order to maximize the difference between their total ben-
eﬁt and their total cost. This problem has been studied in many
different settings [11, 2, 8, 5, 1]. One can ask interesting questions
about the emergent properties of the networks formed in each set-
ting: What network topologies are feasible in equilibrium? How
do equilibrium networks differ from socially optimal ones? How
does this depend upon the cost of forming an edge and the beneﬁt
derived from having a connection? If there are multiple equilibria,
can agents select among them through some kind of iterated better-
response dynamics?

This paper is an investigation into some of these questions in
the context of credit networks, an abstraction for modeling trust
among autonomous agents. A credit network represents trust rela-
tionships through a directed graph with edge capacities. Nodes in
this graph correspond to agents, and edges correspond to credit re-
lationships between them. An edge of capacity c from node u to
node v indicates that agent u extends c units of credit to agent v, or
equivalently, u is committed to accept IOUs (obligations) issued by
v up to value c. The capacity of this edge can be viewed as a mea-
sure of u’s trust in v. Nodes pay for goods and services by issuing
their own IOUs, instead of using a common currency. Credit com-
mitments between trusting nodes also enable remote transactions,
as illustrated in Fig. 1. Say node w wants to buy a good worth p
units from node u. Nodes u and w can transact—even though u
does not directly trust w—via the trusted intermediary v. Assum-
ing p ≤ min{c1, c2}, the payment proceeds by w issuing an IOU
to v worth p units, and v issuing an IOU to u worth p units. If,
however, p > min{c1, c2}, the transaction fails. As a result of a
successful transaction, the credit capacities cuv and cvw decrease
by p, representing the remaining credit commitments. In addition,
the capacities cvu and cwv both increase to p from zero, since v and
w will both accept the return of their own IOUs as payment. Thus
arbitrary payments can be routed through a credit network by pass-
ing IOUs along a chain of trusting agents, obviating the need for
a common currency. Observe that routing payments in credit net-
works is identical to routing residual ﬂows in general ﬂow networks.
Also note that payment ﬂows in the opposite direction of credit, so
a payment merely results in a redistribution of credit: buyers ex-
pend credit and sellers gain it while intermediaries exchange credit
between their neighbors, but the total credit in the network remains
unchanged.

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France559u

u

w

w

c1

v

c2

(a) Before the transaction

p

p

v

c1 − p
c2 − p
(b) After the transaction

Figure 1: Updating credit to process a transaction between u and w
worth p units.

The credit network model was introduced independently by De-
Figueiredo and Barr [7], Ghosh et al. [9], and Karlan et al. [13] as
a mechanism for enabling transactions among untrusting agents in
a network. This model is particularly well-suited for transactions
in exchange economies such as P2P networks where it has been
shown to improve inefﬁciencies resulting from asynchronous de-
mand and bilateral trading [14]. It has been used to thwart spam in
e-mail and content-sharing systems such as YouTube [16]. It can
also be used in settings such as packet routing in mobile ad-hoc net-
works and combating spam in viral marketing over social networks.
There is a large body of work in economics and sociology on so-
cial capital and favor exchanges in networks [10]. This model not
only provides a rigorous way of keeping track of favors owed to
and by each individual in a network, but also facilitates exchange
of favors, via trusted intermediaries, between individuals who do
not know each other directly.

Prior research shows that liquidity (ability to route payments)
in many credit network topologies is comparable to that in equiva-
lent centralized currency systems [6]. Whereas that work takes the
credit network to be exogenously deﬁned, here we address the ques-
tion of how credit networks may be formed in the ﬁrst place. We
endogenize network formation by explicitly modeling the decision
by each agent to issue credit to others. Issuing credit entails risk (a
counterparty may violate the trust extended), as well as beneﬁts (it
increases the probability that proﬁtable transactions may be com-
pleted). A natural question is whether agents who rationally weigh
these risks and beneﬁts will actually form viable credit networks.
Network formation in the presence of risk was recently studied by
Blume et al. [4] in a model motivated by ﬁnancial contagion and
epidemic diseases. In their setting, nodes derive utility only from di-
rect edges, whereas risk is contagious (i.e., failure of distant nodes
is also a source of risk). Our model ﬂips this: nodes derive beneﬁt
from transactions along direct as well as multi-hop paths, whereas
only direct edges are sources of risk.
1.1 Our Setting

In our model, each agent has a credit budget representing the to-
tal credit that agent can extend others. Agents play a one-shot game
where they determine how much credit to extend other agents, and
then engage in repeated probabilistic transactions over the formed
credit network. Agents derive utility from successful transactions.
Extending credit to other agents increases transaction success prob-
ability, thus contributing to utility. On the other hand, when agent u
extends credit to agent v, u risks a potential loss of utility resulting
from violation of the trust it placed in v. Thus, an agent’s net utility
is its total utility from successful transactions minus the utility loss
from extending credit to untrustworthy agents.

We analyze the formation of credit networks under various mod-
els of risk. We start with a model of dichotomous risk: agents are
embedded in a social network represented by an undirected graph.

Agents trust their neighbors in the social network and may extend
credit to them. However, they associate a very high loss of utility
with extending credit to non-neighbors, and consequently, never ex-
tend credit to them. This setting captures situations illustrated by
the following examples where directly transacting with a stranger
may have grave consequences.
• During a disease epidemic within a human population, high-
risk groups will limit their interactions to those who belong
to similar social circles. Evidence of this has been found, for
example, in the setting of HIV/AIDS [12, 3].
• Users trying to circumvent Internet censorship and evade net-
work surveillance in repressive regimes make use of Internet
proxies [15]. If caught, penalties may be severe. Thus, users
rely on their friends and acquaintances to distribute proxy
addresses.
• Members of covert organizations face the prospect of severe
harm at the hands of the enemy if their identity is compro-
mised. As a result, they may rely on longstanding relation-
ships and assets built over time to conduct their business.

We also study a model of global risk, which represents the other
extreme with respect to the dichotomous risk model. In this model,
each node has a publicly known risk of default. This corresponds
to situations involving small, densely interacting social groups, or
where there are organizations such as credit-reporting agents that
systematically gather and disseminate relevant risk information.

Finally, we study a model of graded risk that helps bridge the
gap between global and dichotomous risk. Under this model, each
agent has a private default probability. Agents receive noisy signals
about each other’s probability of defaulting, and these signals are
more informative for neighbors in the social network.
1.2 Results

Dichotomous Risk Under dichotomous risk, when we allow only
bilateral transactions (i.e., transactions only between adjacent nodes
in the social network, and payments routed only along the direct
edge between nodes), we show that the formation game is a poten-
tial game (Theorem 3.1). This implies that best-response dynamics
always converge to a Nash equilibrium1. Moreover, for a large, nat-
ural class of transaction size distributions, we show that agents’ util-
ities are concave in their credit allocations. This allows us to prove
that every Nash equilibrium of the game maximizes social welfare
(Theorem 3.4). More interestingly, we show that the Nash equilib-
ria are equivalent in a much stronger sense: any two Nash equilibria
are cycle-reachable from each other (Theorem 3.6), which means
that it is possible to transform one equilibrium into another by rout-
ing a sequence of payments from a node to itself along a feasible
path. The signiﬁcance of this structural property follows from [6]:
for any two Nash equilibria s and s
of the game, if an arbitrary
sequence of transactions is feasible starting from s, that sequence
is also feasible starting from s

(cid:2)

(cid:2)

.

With non-bilateral transactions, the game becomes signiﬁcantly
less well-behaved:
the game may not admit a Nash equilibrium
(Theorem 3.8), and even when it does, the price of anarchy in this
setting can be unbounded (Theorem 3.9).

Global Risk Under global risk, we analyze the price of anarchy
and the structure of equilibria when each agent is limited to extend
credit to at most one other agent. We prove if we disallow the empty
network as an outcome, the price of anarchy of the formation game

1In this paper, the term Nash Equilibrium always refers to a pure
Nash equilibrium, except when we explicitly consider mixed strat-
egy equilibria of simulated games in Section 4.2.

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France560is unbounded (Theorem 4.4), even though all Nash equilibria have
a star-like structure (Theorem 4.3). Instead we focus on the struc-
ture of equilibria under two simple dynamics: sequential arrival
and myopic best response. When nodes arrive sequentially and cre-
ate a single link, we show that a node u always extends credit to
either the node v that arrived immediately before u or to the node
that v extends credit to (Theorem 4.6). Thus the resulting network
has a comb-like structure. Under myopic best response, nodes ex-
tend their entire credit budget to the node that has the lowest risk
of default. If the default risks are unique, this results in a star-like
network structure which is also the optimal structure in terms of so-
cial welfare (Theorem 4.5). Thus, even though the price of anarchy
can be unbounded, nodes can easily ﬁnd the optimal network using
myopic best response.

Simulations We use empirical game simulation to study a more
general formulation of the global risk model, ﬁnding that non-empty
equilibrium networks tend to have a centralized, star-like structure
due to use of default probability as a primary credit-issuing crite-
rion. We also analyze several graded risk settings, and ﬁnd that
centralized networks only arise when defaults are relatively rare,
and otherwise, credit links tend to be issued over short social dis-
tances conforming to the locality of information.

2. MODEL AND DEFINITIONS
Let V denote the set of n agents. Each agent u ∈ V has a
budget Bu ≥ 0 representing the total credit that u can extend to
other agents in V . Agents play a one-shot game where they choose
credit allocations to form an initial network s. Agents represent
nodes of the formed network. An edge from node u to node v of
(cid:2)
capacity cuv(s) represents the credit extended by agent u to agent
v in the network s. A strategy for agent u is a set of feasible credit
allocations {cuv(s), v ∈ V : cuv(s) ≥ 0 and
v∈V cuv(s) ≤
Bu}.

2.1 Transaction Model

u,v λuv = 1.

Once a network s is formed, agents engage in repeated proba-
bilistic transactions with each other. At each time step t = 1, 2, . . . ,
a pair of transacting agents (cid:5)u, v(cid:6), with u being the payer (buyer)
and v the payee (seller), is chosen with probability λuv. The trans-
action rate matrix Λ = {λuv : u, v ∈ V } is public, and sat-
(cid:2)
isﬁes the following properties: (i) λuu = 0, (ii) λuv ≥ 0, and
(iii)
Suppose agents (cid:5)u, v(cid:6) are chosen to transact at time t. Then the
transaction size, xt
uv, between u and v is drawn from a transac-
tion size distribution over [0, ∞) with a probability density func-
tion (pdf) guv(·) and a corresponding cumulative distribution func-
tion (cdf) Guv(·). We assume that the pdfs guv(·) are public. Let
G := {guv(·) : u, v ∈ V } be the pdf matrix.
Given a transaction size x, a feasible path in the network s from
node v to node u is a set of directed edges P = {(v, u1), (u1, u2), . . . ,
(uk−1, uk), (uk, u)} such that for all (w, y) ∈ P, cwy(s) ≥ x.
We route payments along the shortest feasible path in the network.
Let P t
vu be the shortest feasible path in the credit network from
v to u at time t. A successful transaction of size xt
uv results in
a change of credit capacities along edges in P t
vu as follows. Let
st := {cuv(st) : u, v ∈ V } denote the state of the network s at
time t = 0, 1, 2, . . ., where s0 = s. Then, for w, y ∈ V and for
t >0 ,

⎧⎨
⎩ cwy(st−1) − xt
uv,
cwy(st−1) + xt
uv,
cwy(st−1),

cwy(s

t

) =

if (w, y) ∈ P t−1
if (y, w) ∈ P t−1
otherwise

vu

vu

So, in order for a payment xt
uv from u to v to succeed, there must
exist a feasible path in the credit network from the payee v to the
payer u. If no such path exists, the transaction fails, in which case
all credit capacities remain unchanged. Thus, for all t >0 , and for
all u, v ∈ V, cuv(st) + cvu(st) = cuv(s) + cvu(s).
The repeated probabilistic transactions induce a Markov chain
over the states of the network, which we denote by M(s, Λ,G). A
transaction regime is deﬁned as the tuple (cid:5)Λ,G(cid:6). We say a transac-
tion regime (cid:5)Λ, G(cid:6) is symmetric if the transaction rate matrix Λ is
symmetric: for all nodes u, v ∈ V, λuv = λvu, and the transaction
size pdfs are symmetric: for all u, v ∈ V, guv(·) = gvu(·).

We are interested in the success probabilities of transactions in
the steady-state of this Markov chain, which are difﬁcult to char-
acterize for arbitrary networks and transaction regimes. However,
we can do so in some simple cases, including the unit transaction
regime.
DEFINITION 2.1. A unit transaction regime over credit network
s is a transaction regime (cid:5)Λ,G(cid:6) where, for all u, v ∈ V and for all
t >0 , the transaction size xt
uv = 1, the transaction rate matrix Λ
is symmetric and the Markov chain M(s, Λ,G) is ergodic.
When the network s is acyclic (ignoring directionality), Dandekar
et al. [6] characterize the steady-state success probabilities under a
unit transaction regime.
([6]). Consider a credit network s. Assume that
s is acyclic if we ignore the directions of the edges in s. Let Puv
be the set of (undirected) edges along the path between nodes u
and v. Then, in a unit transaction regime over s, the steady-state
transaction success probability, fuv(s), between two nodes u, v ∈
V is given by

LEMMA 2.1

(cid:6)

(cid:8)cwy(s)(cid:9) + (cid:8)cyw(s)(cid:9)
(cid:8)cwy(s)(cid:9) + (cid:8)cyw(s)(cid:9) + 1

fuv(s) = λuv

e=(w,y)∈Puv

2.2 Utility

Agents choose credit allocations to maximize their utility. Suc-
cessful transactions contribute to agents’ utility, but agents risk
loss of utility when they extend credit to potentially untrustworthy
agents. We model this risk in several ways, but denote the expected
loss of utility to u associated with the prospect of default by v by
Δuv(s), with the constraints that Δuv(s) ≥ 0 and Δuv(s) > 0
only if cuv(s) > 0. Let fuv(s) be the steady-state success proba-
bility of the transactions from u to v when the initial network is s.
Then, the total utility of an agent u when the initial network is s is
given by

(cid:7)

(cid:7)

Uu(s) = γ

w∈V

fuw(s) −

Δuv(s)

(1)

v∈V :cuv (s)>0

where γ is a constant that converts transaction success probabil-
ity into equivalent utility units. The overall social welfare in net-
work s is simply the sum of utilities of all nodes in s: U (s) =

(cid:2)

u∈V Uu(s).

2.3 Risk Model

In order to model variation in Δuv(s), we assume that the agents
are embedded in an exogenously-deﬁned social network represented
by a simple undirected graph H = (V, E). The social network
H inﬂuences the how Δuv(s) for an agent u varies across agents
v ∈ V . We consider three speciﬁc models of how risk changes as
a function of distance between u and v in H.

Dichotomous Risk.

In this model, an agent u partitions the
set of agents V into two sets using H: neighbors in H and non-
neighbors in H. For any network s, agent u estimates risk exposure

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France561to be:

(cid:8)

Δuv(s) =

if (u, v) ∈ E
otherwise

0,
∞,

(2)

This model assumes agents are willing to interact only with their
neighbors in H. For any credit network s formed under this model,
cuv(s) = 0 if (u, v) /∈ E.
Global Risk. In this model, we assume that each agent v has
a default probability δv ∈ (0, 1] which is public. If v defaults, a
node u that extended credit cuv(s) to v loses cuv(s) units. Thus,
Δuv(s) = δvcuv(s).

Graded Risk. Here, as in the Global Risk model, each agent
v has default probability δv, but this information is not publicly
known. Instead, each agent u receives a signal δuv about the default
probability of each other agent v. These signals are decreasingly
informative with distance in H, so agents know much more about
the default probabilities of their neighbors in the social network
than about distant nodes. In our simulations, we implement this by
drawing agents’ default probabilities from a beta distribution: δv ∼
Beta(α, β). Agent u then receives a signal in the form of some
number of samples Suv drawn from the binomial distribution on δv,
where Suv decreases exponentially with social network distance.

3. NETWORK FORMATION UNDER

DICHOTOMOUS RISK

Recall that under dichotomous risk, Δuv(s) is deﬁned by (2), as

a result nodes only extend credit to their neighbors in H.
3.1 Symmetric Bilateral Transactions

We call a transaction between nodes u and v bilateral if (u, v) ∈
E and the payment is routed along the edge (u, v). Here we allow
only bilateral transactions: if a payment between adjacent nodes
u and v cannot be routed along the direct edge (u, v), we fail the
transaction. As a result, if (u, v) /∈ E, the steady-state success
probability fuv(s) = fvu(s) = 0. Moreover, the steady-state trans-
action success probabilities along an edge e = (u, v) in a network
s are governed only by the credit allocations, cuv(s), cvu(s), along
e in s. We also assume that the transaction regime (cid:5)Λ, G(cid:6) is sym-
metric and that λuv > 0 if (u, v) ∈ E. As a result, for all nodes u
and v, fuv(s) = fvu(s).
In our analysis of the symmetric bilateral transaction regime, for
an edge e = (u, v) ∈ E, we will use λe, ge(·), Ge(·) and fe(·) to
denote λuv, guv(·), Guv(·), and fuv(·), respectively.

We ﬁrst show that in this setting, the network formation game is

a potential game.

THEOREM 3.1. The network formation game under a symmet-

ric bilateral transaction regime is a potential game.

PROOF. Consider the function Φ(s) deﬁned as

(cid:7)

(cid:7)

(cid:7)

Φ(s) :=

U (s)

2

=

1
2

Uu(s) =

u∈V

fuv(s)

u∈V

v∈V

γ
2

Since we are in a symmetric bilateral transaction regime, fuv(s) =
fvu(s) for all (u, v) ∈ E, and fuv(s) = 0 if (u, v) /∈ E. There-
fore,

(cid:7)

This implies Φ(s) = γ
e∈E fe(s). We will show that Φ(s) is a
potential function. Fix a node u ∈ V . Consider a network s
which
differs from s only in the credit allocation of u. Formally, for all

(cid:2)

(cid:7)

u∈V

(cid:7)
(cid:2)

v∈V

fuv(s) = 2

fe(s)

e∈E

w, y ∈ V ,

(cid:8)

(cid:2)

cwy(s),
(cid:2)
c
wy,

if w (cid:11)= u
if w = u and (u, y) ∈ E

) =

cwy(s
where {c
uy : (u, y) ∈ E} is any feasible allocation of u’s credit.
(cid:2)
Let Eu ⊆ E be the set of edges incident upon u in E. Note that
(cid:2)
(cid:2)
for all e
). As a result,
= (u
(cid:2)
fe(cid:2) (s) = fe(cid:2) (s
Φ(s) − Φ(s
(cid:2)

) /∈ Eu, cu(cid:2)v(cid:2) (s) = cu(cid:2)v(cid:2) (s
(cid:7)

, v
). It follows that

= Uu(s) − Uu(s

) = γ

fe(s) − fe(s

(cid:2)

)

(cid:9)

(cid:10)

(cid:2)

)

(cid:2)

(cid:2)

e∈Eu

(cid:11)

(cid:12) ce(s)

0

Thus the network formation game is a potential game with Φ(s) as
the potential function.

Theorem 3.1 implies that in this setting, a Nash equilibrium al-
ways exists, best-response dynamics always converge to a Nash
equilibrium, and ﬁnally, because the potential function is given by
Φ(s) = U (s)/2, the price of stability is 1. Next we will show that
for a large, natural class of transaction size distributions, agents’
utilities are concave, and consequently, the price of anarchy is also
1, i.e., every Nash equilibrium of the formation game maximizes
social welfare.

3.1.1 Nash Equilibria Maximize Social Welfare
Consider an edge e = (u, v) ∈ E. Assume that ge(·) has sup-
port over [0, ∞). Also, let Ge(·) be twice differentiable. First we
derive an expression for fe(s) in terms of the credit allocations
cuv(s) and cvu(s) along edge e.

LEMMA 3.2. Consider a credit network s. For nodes u, v ∈ V
such that e = (u, v) ∈ E, the steady-state transaction success
probability, fe(s), under a symmetric bilateral transaction regime
is given by

fe(s) = fe(ce(s)) =

λe

ce(s)

Ge(y)dy,
0,

if ce(s) > 0
if ce(s) = 0

(3)
where ce(s) = cuv(s) + cvu(s) is the total credit allocated along
edge e in s.

The proof is omitted due to space constraints.2 Observe from (3)
that fe(s) depends only on the total credit capacity ce(s) along the
edge e = (u, v). Therefore, for the rest of this section, instead of
thinking of fe as a function of cuv(s) and cvu(s), we will think
of fe as the function fe : R+ → [0, 1]. That is, fe(x) is the
steady-state transaction success probability along edge e when the
total credit allocated along it is x. We will write fe(s) to mean
fe(ce(s)) when there is no ambiguity. Next we prove some prop-
erties of the functions fe(·) that enable us to establish that every
Nash equilibrium maximizes social welfare.

LEMMA 3.3. Consider a credit network s under a symmetric

bilateral transaction regime. For an edge e ∈ E,

1. The transaction success probability, fe(·), is continuously

differentiable and strictly increasing.

2. If ge(·) is non-increasing, fe(·) is concave.

As a corollary, if ge(·) is strictly decreasing, fe(·) is strictly con-
cave. Many natural distributions have strictly decreasing density

2Proofs of all results are included in the full version of this paper,
available at http://www.stanford.edu/~ppd/papers/
cn-formation.pdf.

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France562functions over [0, ∞). Examples include the exponential distribu-
tion, the normal distribution N (0, σ2), and the power-law distri-
bution. Next we show that if the transaction success probabilities,
fe(·), are concave, every Nash equilibrium maximizes social wel-
fare.

THEOREM 3.4. Let s be a Nash equilibrium of the network for-
mation game under a symmetric bilateral transaction regime. If the
transaction success probabilities, fe(·), e ∈ E, are concave, then
s maximizes social welfare U (s).

(cid:2)

PROOF. Recall from Theorem 3.1 that the formation game un-
der a symmetric bilateral transaction regime is a potential game and
e∈E fe(s) is a potential function. Recall
Φ(s) = U (s)/2 = γ
from Lemma 3.3, that fe(·), e ∈ E, are continuously differentiable,
which implies Φ(·) is continuously differentiable. Since fe(·) are
concave (by assumption), Φ(·) is also concave. It was shown by
Neyman [17] that any Nash equilibrium of a potential game with
a concave and continuously differentiable potential is also a po-
tential maximizer. Therefore, s maximizes Φ(s), or equivalently,
U (s).

3.1.2 Nash Equilibria are Cycle-Reachable

(cid:2)

(cid:2)

Theorem 3.4 implies an equivalence between the Nash equilibria
of the game; any two Nash equilibria s and s
have the same social
). Next we show that if fe(·), e ∈ E, are
welfare, U (s) = U (s
strictly concave, the Nash equilibria of this game are equivalent in
a much stronger sense: any two Nash equilibria s and s
are cycle-
reachable, which, as shown by Dandekar et al. [6], implies that the
sequences of transactions that succeed starting from s and starting
from s

are identical.

(cid:2)

(cid:2)

We ﬁrst show that the total credit capacity of any edge in E is

identical in any Nash equilibrium.

LEMMA 3.5. Let fe(·), e ∈ E, be strictly concave. Let s and
be two Nash equilibria of the network formation game. Then for

(cid:2)
s
all edges e ∈ E, ce(s) = ce(s

PROOF. First, let us deﬁne the marginal utility of an edge e ∈

).

(cid:2)

E.

DEFINITION 3.1. The marginal utility of an edge e ∈ E is the

function re : R+ → R+ given by
(cid:2)
e(x) =

re(x) = f

dfe(x)

dx

(cid:2)

We show that for any edge e ∈ E, re(s) = re(s
). The lemma
follows as a direct consequence.
Since fe(·) is strictly concave (by assumption), strictly increas-
ing and continuously differentiable (by Lemma 3.3), re(·) is con-
tinuous, strictly decreasing and strictly positive. In network s, the
marginal utility on an edge e ∈ E is given by re(ce(s)). We denote
it by re(s) when there is no ambiguity. Let Eu be the set of edges
in E incident upon node u.

DEFINITION 3.2. For a node u ∈ V and a network s, we deﬁne
u(s) ⊆ Eu as the set of edges
∗

ρu(s) := maxe∈Eu re(s) and E
e ∈ Eu such that re(s) = ρu(s).
∗
u(s) is the set of edges incident on node u that have the
In words, E
highest marginal utility in network s among all edges in Eu. We
show that in any Nash equilibrium s, each node u exhausts its entire
budget and allocates non-zero credit only along edges in E

∗
u(s).

PROPOSITION 1. Let s be a Nash equilibrium. Then, for all

nodes u ∈ V , both (1) and (2) are true:

(cid:2)
1.
2. For each e = (u, v) ∈ E, if e /∈ E

v:(u,v)∈E cuv(s) = Bu.

Next we deﬁne a slack edge.

∗
u(s) then cuv(s) = 0.

DEFINITION 3.3. Let s be a Nash equilibrium. We call an edge
∗
v (s) or

e = (u, v) ∈ E a slack edge in s if e /∈ E
both.

u(s) or e /∈ E
∗

Note that by Proposition 1, if edge e = (u, v) is a slack edge in
Nash equilibrium s, either cuv(s) = 0 or cvu(s) = 0 or both
cuv(s) = cvu(s) = 0.

DEFINITION 3.4. Let s be a credit network. We deﬁne
1. rmin

:= mine∈E re(s) to be the minimum marginal utility

s

of any edge e ∈ E in s,

:= {e ∈ E | re(s) = rmin
:= {u ∈ V | u is incident on some edge in Emin

},

s

s

},

2. the set Emin
3. the set V min

s

s

and

4. the set V X

s ⊆ V min
:={u ∈ V | u is incident upon some edge in E

as

s

min
s

X
s

V

and upon some edge in E − E

min
s

}

The minimum marginal utility in any two Nash equilibria is iden-

tical.

PROPOSITION 2. Let s and s

rmin
s = rmin

s(cid:2)

.

(cid:2)

be two Nash equilibria. Then

Moreover, in any two Nash equilibria s and s

(cid:2)

, the set of edges

(cid:2)

with the minimum marginal utility in s is identical to that in s

.

PROPOSITION 3. Let s and s
s = Emin

Emin

.

s(cid:2)

(cid:2)

be two Nash equilibria. Then

COROLLARY 3.1. Let s and s
V min
s = V min

s = V X
s(cid:2) .

and V X

s(cid:2)

(cid:2)

be two Nash equilibria. Then

s

(cid:2)

(cid:2)

Thus, we have established that for any two Nash equilibria s and
, re(s) = re(s
. We show using an

) for all edges e ∈ Emin

s
inductive argument that this is true of all edges in E.

DEFINITION 3.5. Given an instance I : G = (V, E); fe, e ∈
E; Bu, u ∈ V of the network formation game under a symmetric
bilateral transaction regime, a network s, and an arbitrary set of
edges F ⊆ E, we deﬁne the (s, F )-restriction of I, denoted I(s,F ),
as follows: G(F ) := (V, E \ F ), f

:= fe, e ∈ E \ F , and

(F )
e

(s,F )
B
u

if Eu ⊆ F
(u,w)∈F cuw(s) otherwise
Note that for a node u, if Eu ⊆ F , then the value of B
is
immaterial since u has no incident edges in I(s,F ) along which to
allocate its budget.

(s,F )
u

Bu −(cid:2)

(cid:8)

:=

0

DEFINITION 3.6. Given a network s and an arbitrary set of
edges F ⊆ E, we deﬁne an F -restriction of s, denoted, s(F ), as
follows: for all edges e = (u, v) ∈ E \ F, cuv(s(F )) = cuv(s)
and cvu(s(F )) = cvu(s).

PROPOSITION 4. If s is a Nash equilibrium for instance I of the
network formation game in the bilateral transaction setting, then
s(F ) is a Nash equilibrium for I(s,F ) for any set F ⊆ E.

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France563(cid:2)

PROPOSITION 5. Let s and s

be two Nash equilibria for in-
stance I of the network formation game under a symmetric bilat-
eral transaction regime. Then for all edges e ∈ E, re(s) = re(s
(cid:2)
).
Observe that since fe(·) is strictly concave, re(·) is strictly de-
creasing. Therefore, Proposition 5 implies that for all e ∈ E, ce(s) =
(cid:2)
ce(s

).

Lemma 3.5 allows us to show that any two Nash equilibria are

cycle-reachable.

(cid:2)

(cid:2)

DEFINITION 3.7

([6]). Let s and s

be two credit networks.
(cid:2)
is cycle-reachable from s if s can transformed into s
We say that s
by routing a sequence of payments along feasible cycles (i.e., from
a node to itself along a feasible path).

THEOREM 3.6. Let fe(·), e ∈ E, be strictly concave. Let s
be two Nash equilibria of the network formation game under
are cycle-

and s
the symmetric bilateral transaction regime. Then s and s
reachable from each other.

(cid:2)

(cid:2)

PROOF. First we deﬁne the generalized score vector of a credit

DEFINITION 3.8

network s.
([6]). Given a credit network s of n nodes,
the generalized score vector of s is the vector D(s) = (cid:5)du(s) : u ∈
V (cid:6) ∈ R
Next we show that any two Nash equilibria have the same general-
ized score vector.

+ where for all u ∈ V, du(s) :=

v∈V cvu(s).

(cid:2)

n

PROPOSITION 6. Let s and s

be two Nash equilibria. Then,

(cid:2)

(cid:7)

(cid:2)

).

(cid:7)

D(s) = D(s

PROOF. Fix a node u ∈ V . Recall from Proposition 1 that

cuv(s) =

v:(u,v)∈E

v:(u,v)∈E

(cid:2)

cuv(s

) = Bu

Also, from Lemma 3.5, we know that for all edges e ∈ E,

(4)

(5)

Let Eu be the set of edges in E incident upon u. It follows from
(4) and (5) that

3.2 Symmetric Transactions

Here we lift the restriction that transactions be bilateral, allowing
transactions between nodes that are not neighbors in H. We also al-
low payments between neighboring nodes to be routed along paths
other than the direct edge between them.

1

x

1

y

a

1 − x

b

1 − y

d

e

h

1

1

j

Figure 2: Example of a formation game that does not admit a Nash
equilibrium.

THEOREM 3.8. There exists an instance of the network forma-
tion game under a symmetric transaction regime that does not ad-
mit a Nash equilibrium.

PROOF. We will construct an instance of network formation game
and show that it does not admit a Nash equilibrium. Consider a
game with six agents: V = {a, b, d, e, h, j}. The graph H is a line
graph over nodes in V with edges (a, b), (b, d), (d, e) and so on.
For each node u ∈ V, Bu = 1. The non-zero transaction rates are
given by: λab = λba = λde = λed = λhj = λjh = 0.001, λae =
λea = λbj = λjb = 0.2435, λej = λje = 0.01. All other en-
tries in the transaction rate matrix Λ are zero. All transactions are
of size one. Observe that this is a unit transaction regime, so we
can use Lemma 2.1 to compute the steady-state transaction success
probabilities between nodes.

Let s be a Nash equilibrium. Then, it must be that cab(s) =
cde(s) = chj (s) = cjh(s) = 1. Let cbd(s) = x and cba(s) =
1 − x. Similarly, let ceh(s) = y and ced(s) = 1 − y. Observe that
since all transactions are of size one, and s is a Nash equilibrium, it
must be that x, y ∈ {0, 1} (i.e., x and y cannot be strictly between
0 and 1). Verify that for each of the four combinations of (x, y),
namely, (0, 0), (0, 1), (1, 0) and (1, 1), either b or e has an improv-
ing unilateral deviation. In fact, the four combinations form a best-
response cycle. Hence, there is no assignment of x, y ∈ [0, 1] that
will ensure that s is a Nash equilibrium.

ce(s) = ce(s

)

(cid:2)

(cid:7)

v:(u,v)∈E

(cid:7)

e∈Eu

(cid:7)
(ce(s) − cuv(s))
(cid:7)

e∈Eu

(cid:2)

) = du(s

cuv(s

e∈Eu

du(s) =

cvu(s) =

cvu(s) =

ce(s) − Bu =

(cid:2)

ce(s

) −

(cid:7)
(cid:7)

v∈V

=

e∈Eu

Next we show that even if agents reach a Nash equilibrium, it
may be arbitrarily bad in terms of social welfare compared to a
social optimum.

(cid:2)

)

PROPOSITION 7

([6]). Two credit networks s and s

reachable if and only if D(s) = D(s

).

(cid:2)

are cycle-

Proposition 6 along with Proposition 7 complete the proof.

(cid:2)

THEOREM 3.7

are cycle-reachable,

The signiﬁcance of this result is that if s and s
they support the same set of feasible transactions.
([6]). Let s1 and s2 be two cycle-reachable
networks. If a transaction θ = (cid:5)u, v, p(cid:6) (i.e., routing p units from
node u to node v) is feasible in s1, it is also feasible in s2. Further,
(cid:2)
if transaction θ in network s1 results in a network s
1, and the same
(cid:2)
(cid:2)
transaction in network s2 results in a network s
1 and s
2
are cycle-reachable.

(cid:2)
2, then s

Thus, for two Nash equilibria s and s
of the game, if a sequence of
transactions succeeds starting from s it also succeeds starting from
(cid:2)
. Observe that this equivalence between Nash equilibria implied
s
by Theorem 3.6 is stronger than that implied by Theorem 3.4.

(cid:2)

(cid:2)

1

1

1

1

b

c

(a) An equilibrium network s

1

b

1
1
∗
(b) An optimal network s

1

c

a

a

d

d

Figure 3: Example of a game with an unbounded price of anarchy.

THEOREM 3.9. The price of anarchy of the network formation

game under a symmetric transaction regime is unbounded.

PROOF. We will construct an instance of the game and show
that it has an unbounded price of anarchy. Consider a game with
four agents: V = {a, b, c, d}. The graph H is a line graph over

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France564(cid:7)

(cid:7)

u∈V
2
3

v∈V
8
3

= λ1

∗

nodes in V with edges (a, b), (b, c) and (c, d). For each node u ∈
V, Bu = 1. The non-zero transaction rates are given by: λab =
λba = λcd = λdc = λ1 > 0, λad = λda = λ2 (cid:14) λ1. All other
entries in the transaction rate matrix Λ are zero. All transactions
are of size one.

Consider the network s shown in Fig. 3a. Observe that we can
use Lemma 2.1 to compute the steady-state transaction success
probabilities between nodes in s. Verify that s is a Nash equilib-
rium. The overall social welfare, U (s), in network s is given by

Uu(s) =

fuv(s) = 2fab(s) + 2fcd(s)

(cid:7)

U (s) =

u∈V

= 2λ1

2
3

+ 2λ1

(cid:7)

∗

Now consider the network s
optimum. The overall social welfare U (s

in Fig. 3b. Verify that s
) is given by

∗

(cid:13)

) =

U (s

Uu(s
As λ1 → 0, the ratio U (s

u∈V

∗

∗

2
λ1
) = 2
3
)/U (s) → ∞.

+ λ1

1
2

+ λ2

1
6

∗

is a social

(cid:14)

4. NETWORK FORMATION UNDER

GLOBAL RISK

Recall that in the global risk model, each agent v has a public
default probability δv ∈ (0, 1]. If v defaults, a node u that extended
credit cuv(s) to v loses cuv(s) units. Thus, Δuv(s) = δvcuv(s).
4.1 Single-Minded Agents

We analyze the setting where agents may issue credit to at most

one counterpart.

DEFINITION 4.1. We say that agent u ∈ V is single-minded if
in any credit network s, either cuv(s) = 0 for all v ∈ V , or there
exists a single agent w ∈ V such that cuw(s) = Bu.
Further, we assume that (i) the transaction rate matrix Λ is uniform:
for all u, v ∈ V, λuv = λ = 1/(n(n− 1)), (ii) all transactions are
size one: for all u, v ∈ V , and for all t >0 , xt
uv = 1, and (iii) for
all agents u ∈ V , the credit budget Bu = c > 0, where c is an
integer.

First we illustrate using a simple example that if the default prob-
abilities are in a certain range, the empty network is a Nash equilib-
rium, and the price of anarchy is ∞.
Example 1: Consider a set of n agents. Further suppose that
for all u ∈ V, γλ(h + h2) > δuc > γλh, where h = c/(c + 1).
Let s be the empty network. Observe that, Lemma 2.1, the utility
to a node u from extending to any node v in s is γλh, which by
assumption is less than δvc. Thus s is a Nash equilibrium. On the
other hand, since γλ(h + h2) > δuc for all u ∈ V , the social
optimum is a star network where every node extends credit to the
root, while the root extends no credit. As a result, the price of
anarchy is ∞.

For the rest of this section, we assume that extending zero credit
is not part of the agents’ strategy set. This assumption, coupled
with the fact that agents are single-minded, implies that any credit
network formed in this setting will have exactly n directed edges
each of capacity c, where n is the number of agents playing the
game. Since an agent extends credit to exactly one agent in any
network, we deﬁne the following notation to denote the agent that
has been extended credit by an agent u in network s: for a network
s, we deﬁne τs : V → V to be the “trustee function": τs(u) = v
implies cuv(s) = c.

LEMMA 4.1

We use the following observation to prove our results; the ob-
servation follows from the analysis by Dandekar et al. [6] of the
steady-state success probability in trees under a unit transaction
regime.
([6]). Consider a network s. Let u ∈ V be a
node such that no node extends credit to u in s and let τs(u) = v.
Assume the transaction rate matrix Λ is uniform and s is under a
unit transaction regime. Then, for any node w ∈ V \{u, v}, fuw(s) =
hfvw(s), where h = c/(c + 1).
4.1.1 Price of Anarchy and Structure of Equilibria

LEMMA 4.2. Let v

It is easy to see that any socially optimal network will have a star-
like structure where the root is a node with the minimum default
probability.
∗ ∈ arg minv∈V δv be a node with the mini-
∗ ∈ arg minv∈V \{v∗} δv be a node
mum default probability. Let u
∗
with the minimum default probability among nodes other than v
.
∗}, τs∗ (u) =
∗
Consider a network s
∗
∗
maximizes social welfare. More-
v
) = u
over, s
Next we show that all Nash equilibria have a star-like structure.

such that for all nodes u ∈ V \{v
. Then, s

is also a Nash equilibrium.

, and τs∗ (v

∗

∗

∗

THEOREM 4.3. For a sufﬁciently large n, in any Nash equilib-
such that for all nodes v ∈ V \
∗}, τs(v) = u
∗

∗
rium s there exists a node u
{u
Next we show that despite ruling out the empty network as a Nash
equilibrium, the price of anarchy in this setting can be unbounded.
THEOREM 4.4. The price of anarchy of the network formation

.

game with single-minded agents is unbounded.
PROOF. Consider a set of n agents. Assume, without loss of
generality, that for nodes u1, . . . , un ∈ V, δu1 ≤ . . . ≤ δun . Let
δu1 c = γλ(n− 3)h22c/(2c + 1), and δu2 = δu3 = γλ(n− 3)h2,
where recall that h = c/(c+1). Consider the network s
in Fig. 4a.
It follows from Lemma 4.2 that s
is a socially optimal network.
Consider the network s1 in Fig. 4b. Observe that Lemma 2.1 can be
used to compute the steady-state transaction success probabilities
and, hence, the utilities, of all nodes in s1. Since c(δu3 − δu1 ) ≤
(n − 3)γλ h2
2c+1 , nodes in s1 cannot beneﬁt from extending credit
to u1 or u2 instead of u3. Thus, s1 is a Nash equilibrium. Note that
since s

and s1 are structurally identical

∗

∗

∗

(cid:7)

(cid:7)

(cid:14)

+ 2h

+ 2λ

2c

2c + 1

fuv(s1)

∗

u,v

u,v

) =

fuv(s

(cid:13)
= λ(n − 2)
(n − 3)h
= λ(n − 2)(n − 3)h

2

2

+ 2h

2c

2c + 1

+ Θ(n)

∗

∗

U (s

Thus, the total social welfare in s

) = γ

fuv(s

u,v

= γλ(n − 3)h

2

∗

is given by
) − (n − 1)δu1 c − δu2 c
(cid:13)
(n − 2) − (n − 1)

(cid:14)

2
+ Θ(n) = Θ(n

)

2c

2c + 1

(cid:7)

(cid:7)
(cid:7)

u,v

= γ

u,v

On the other hand,

U (s1) = γ

fuv(s1) − (n − 1)δu3 c − δu1 c
fuv(s1) − γλ(n − 1)(n − 3)h

2 − δu1 c = Θ(n)

Since the price of anarchy is lower-bounded by U (s
have that PoA = Ω(n).

∗

)/U (s1), we

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France565u1

c

u3

c

c

c

c

c

c

c

c

c

u2

u4

u3
(a) Socially optimal network s

∗

.

un

u2

u1
un
(b) Nash equilibrium s1; node u3 is the root node.

u4

Figure 4: Example of a game under the global risk model with an unbounded price of anarchy.

4.1.2 Dynamics of Network Formation

Despite the fact that the price of anarchy in this setting can be ar-
bitrarily high, we demonstrate that myopic best-response dynamics
can quickly converge to a socially optimal network.

Myopic Best Response For network s, and an agent u, we deﬁne
∗ ∈ arg minv∈V \{u} δv
myopic best-response by u as follows: let v
be a node with the lowest default probability among all nodes ex-
∗
,
cept u. Then, u’s myopic best response is to extend credit to v
) : u, v ∈ V } deﬁned below
i.e., τs(cid:2) (u) = v
is the network resulting from u’s myopic best-response in s. For
nodes w, y ∈ V ,

= {cuv(s

, where s

∗

(cid:2)

(cid:2)

if w (cid:11)= u
if w = u and y (cid:11)= v
if w = u and y = v

∗
∗

⎧⎨
⎩ cwy(s),

0,
c,

(cid:2)

) :=

cwy(s

THEOREM 4.5. Assume that the default probabilities, δv, v ∈
V , are all distinct. Consider a network s. Let s
be the network ob-
tained after all agents have played myopic best response, starting
from s. Then s

maximizes social welfare.

∗

∗

∗

PROOF. Since the default probabilities are all distinct, there ex-
, with the lowest default probability, and
with the second lowest default probability. Then,
∗
.
) = u

ists a unique node, say v
∗
another node u
observe that for all u ∈ V \{v
The optimality of s

∗}, τs∗(u) = v
follows from Lemma 4.2.

and τs∗ (v

∗

∗

∗

Sequential Arrival We consider a model where agents arrive
sequentially, and strategically decide which one of the agents in the
network to extend credit to. Let s0 be a network of two agents,
say u0 and v0, such that τs0 (u0) = v0 and τs0 (v0) = u0. At
each time t = 1, 2, . . . , an agent ut arrives and extends credit to
one of agents in the network st−1 in order to maximize Uut (st)
where st is the resulting network. We denote by Vt the set of agents
that have arrived up to and including time t. We show that the
agent ut arriving at time t always extends credit either to ut−1 or
to τst−1 (ut−1).

THEOREM 4.6. For all t ≥ 1, τst (ut) ∈ {ut−1, τst−1 (ut−1)}.
Since the node ut arriving at time t always extends credit to either
ut−1 or τst−1 (ut−1), the resulting network has a comb-like struc-
ture, i.e., there is a chain of nodes forming the spine of the network,
and each node in that chain is trusted by a number of leaf nodes.
4.2 Simulations on Global and Graded Risk

To address a more general case, we turn to empirical game anal-
ysis methods. In this approach, we choose a small set of heuristic
strategies for agents to follow, and apply hierarchical reduction [18]
to limit the number of players. We repeatedly simulate strategy pro-
ﬁles in this restricted game to estimate their payoffs. Evaluating the
resulting empirical game yields insight on general strategic issues
as exhibited by the heuristic strategies. This methodology allows us
to generalize the setting in several ways: non-uniform transaction

rates and values, issuing credit to multiple counterparts, and graded
risk based on incomplete information.

In the experiments reported here, we simulate 60-agent credit
networks and construct 6-player hierarchically reduced games in
which a multiple of 10 agents plays each strategy. In each simula-
tion run, agents are ﬁrst assigned strategies, after which the random
parameters H (social network), Δ (default probabilities), Λ (trans-
action rates), and G (transaction sizes) are realized. Then agents
issue credit according to their strategies, defaults occur according
to Δ, and 10,000 transactions are attempted according to Λ. Each
successful transaction in which agent u buys from agent v adds xuv
to u’s payoff and subtracts 1 from v’s, while transferring 1 unit of
credit through the network. Each agent also loses cuv for each de-
faulter v to which it had issued credit. We calculate the payoff to a
strategy s as the average payoff to agents playing s. Strategy pay-
offs are averaged over 250 to 3500 simulation runs as necessary to
statistically distinguish empirical game equilibria.

In all simulation environments, the transaction rate λuv for each
pair of agents is drawn uniformly and then normalized. The trans-
action size distribution guv(·) = xuv is a singleton for each pair of
agents, but the value is drawn from one of two distributions: xuv ∼
U [1, 1.2] or xuv ∼ U [1, 2]. Note that we are using xuv ∼ G here to
indicate the value to the buyer u, whereas the seller’s cost, and the
amount of credit transferred are ﬁxed at one. Default probabilities
δv for each agent are drawn from one of three Beta distributions:
Beta(1, 1), Beta(1, 2), or Beta(1, 9).

Our experiments consider two risk models: global risk, with
no social network, and graded risk, where H is an Erdös-Rényi
graph. Under global risk, all agents are fully informed about trans-
action rates (Λ), transaction values (G), and default probabilities
(Δ). Under graded risk, agents still know Λ and G, but information
about Δ comes in the form of signals whose informativeness de-
creases exponentially with social network distance. If we call the
length of the shortest path between u and v in the social network
|SP uv|, then the number of samples u receives from Binom(δv)
is Suv = (cid:8)103−|SP uv|(cid:9), meaning that agents receive 100 samples
for their neighbors, 10 for nodes at distance 2, 1 at distance 3, and
none at greater distances.
If agent u receives a signal with Suv
samples including Sd
uv defaults, its posterior belief about v’s de-
fault probability is Δuv = Beta(α + Sd
4.2.1 Strategies

uv, β + Suv − Sd

uv).

We are particularly interested in what criteria agents might use to
allocate credit. We therefore focus on heuristic strategies that create
a ﬁxed number of credit links (either 0 or 5), and allocate the same
amount of credit (5 units) on all links. An agent’s strategic decision
is then whether to allocate any credit, and if so, what criteria to
employ in picking the ﬁve nodes to which they connect.

We test eight heuristic strategies under which agent u could issue
the following sets of credit links, where the pair (v, cuv) indicates
that u issues cuv units of credit to agent v:
• ZE (zero credit): ∅

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France566(a) Social network distance between all
pairs of agents. G(n = 60, p = 1

12 ).

(b) Social network distances for credit
links under DP. DT is similar.

(c) Social network distance for credit links
under TD. IX, TV, TP, and EU are similar.

Figure 5: Distributions of social network distances: (a) between pairs of agents; (b) over credit links produced by strategy DP with; (c) over
credit links produced by strategy TD. Parameter settings: graded risk; δv ∼ Beta(1, 2); xuv ∼ U [1, 2].
• IX (index): {(v, 5) : v ∈ {v1, . . . , v5}}
• {(v, 5) : v is among the 5 best agents according to . . .}

are shown in the top half of Fig. 6. Strategies appearing in a cell
are supported in some symmetric mixed-strategy Nash equilibrium
of the corresponding game. Each circled strategy is a symmetric
pure-strategy Nash equilibrium.

– DP (estimated default probability): Δuv
– TV (myopic trade value): λuvxuv
– TP (net trade proﬁt): λuvxuv − λvu
– EU (expected utility): 104(1− Δuv)(λuvxuv − λvu)− 5Δuv
– TD (trade then default): 104(1 − Δuv)λuvxuv − 5Δuv
– DT (default then trade): λuvxuv − 5Δuv
Some of these strategies warrant further explanation: DP, which
chooses the agents least likely to default, has very different results
under global and graded risk. In the former case, δv is common
knowledge for all agents, so all agents playing DP coordinate their
credit issuance. Under graded risk, agents’ beliefs Δuv depend
on their position in the social network, hence different DP agents
make varying choices. By always issuing credit to agents 1 to 5,
IX provides a way for agents to coordinate in either the global or
graded risk settings.

EU estimates the expected utility attributable to each agent, as-
suming that all attempted transactions succeed. TD does the same,
but excludes the cost from selling to other agents. These strate-
gies both tend to weight λuvxuv much more heavily than Δuv, so
the strategy DT also considers both transactions and defaults, but
switches the relative weights.

Fig. 5a illustrates the distribution of social network distances for
all agents in the Erdös-Rényi graph under graded risk. The distribu-
tion over distances in the social network for credit links produced
by strategy DP is shown in Fig. 5b. Comparing these two his-
tograms, we can see that preferring low-default counterparts results
in issuing credit to agents nearby in the social network. Although
neighbors in the network have the same prior probabilities of de-
fault as distant agents, the superiority of information about them
means that nearby agents are much more prevalent among those
with lowest posterior probabilities. The strategy DT produces a
similar histogram to DP, as it also relies heavily on beliefs about de-
fault probability, adding just a small factor for trade value that acts
as a tie-breaker. The remaining six strategies are inﬂuenced only
slightly or not at all by the social network, and therefore exhibit
histograms (Fig. 5c) much like the underlying distance distribution
shown in Fig. 5a.

4.2.2 Global Risk Model

The results of equilibrium analysis under global risk for each
combination of default probability distribution, and buyer surplus

Default probability is clearly the most relevant criterion in the
global risk setting. At least one of DP and DT, and often both, is
supported in an equilibrium of all settings except the bottom left,
which has the lowest transaction values and highest default proba-
bilities (where the empty network is the unique equilibrium). That
the empty network is among the equilibria in all three environments
with low transaction values is an indication of the importance of
network effects: it is much more proﬁtable to participate in a credit
network if many other agents do so as well. We also observe the
importance of coordinating on a centralized, star-like network, in
that DP and IX both appear as symmetric pure strategy equilibria.
This point is reinforced by the poor performance of the strategies
relying primarily on transaction value: TV, TP, and TD.

l

s
u
p
r
u
s
r
e
y
u
b

.

g
v
a

0.5

0.1

DP

DT

DT

ZE

DT

DT

DP

DP
ZE

global risk model
(complete info)

1/2

1/3

avg. default probability

DP

DP
ZE

IX

1/10

l

s
u
p
r
u
s
r
e
y
u
b
.
g
v
a

0.5

0.1

graded risk model
(incomplete info)

DT

DT

EU IX DP
DT TD
ZE

ZE

ZE

1/2

1/3

prior default probability

IX

1/10

ZE

Figure 6: Strategies appearing in symmetric Nash equilibria in six
global risk environments (top), and six graded risk environments
(bottom). Circled strategies in a cell constitute pure symmetric
equilibria of the associated game.

4.2.3 Graded Risk Model

The bottom half of Fig. 6 shows equilibrium analysis under graded
risk. DP, which appears in equilibria of nearly all global risk set-
tings is less prevalent in graded risk equilibria, indicating that it
owes much of its success to its function as a coordination device.
TD, on the other hand, continues to perform well, making clear

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France567that default probability is still a relevant criterion to consider. In
the low-value settings, it is unsurprising that the empty network is
more likely to arise, because agents have less information available.
When defaults are sufﬁciently rare, a centralized network from all
agents playing IX is again an equilibrium. The case of high value
and low default probability shows a multiplicity of equilibria, in-
cluding the only appearance of one of the strategies focused on
trades: TD.

The clear messages from our empirical game simulations are
twofold. First, coordinating on a centralized, star-like network can
be very beneﬁcial, when such coordination is feasible. Second, net-
work effects are very strong: none of the strategies that rely heavily
on transaction-related criteria perform well; instead agents tend to
play strategies like TD, IX, and DP that result in a high likelihood
of remaining connected to most of the network in equilibrium.

5. CONCLUSION

Our investigation of strategic issues in the formation of credit net-
works characterizes, in various settings, the nature and efﬁciency of
credit networks that are formed by self-interested agents autonomously
choosing how to issue credit among available counterparts. The
analysis employs game-theoretic solution concepts, employed in
theoretical examination of analytic models, as well as simulation-
based exploration of extended environments.

Under dichotomous risk, if only bilateral transactions are allowed,
we show that the formation game is a potential game. Moreover,
for many transaction size distributions, we show that agents’ utili-
ties are concave, and consequently, every Nash equilibrium of the
game maximizes social welfare. More interestingly, we showed
that the Nash equilibria are equivalent in a much stronger sense:
all Nash equilibria are cycle-reachable [6] from each other, which
implies that the sequences of transactions that can be supported
from each equilibrium network are identical. However, when we
allow transactions over longer paths, best-response dynamics may
not converge, and the price of anarchy is unbounded.

Under a model of global risk, if agents are limited to extend
credit to at most one other agent, we prove that the networks formed
in equilibrium have a star-like structure. Although the price of an-
archy is unbounded, myopic best response quickly converges to a
social optimum. Even when agents are allowed to extend credit
to multiple agents, we show using empirical game simulation that
non-empty equilibria tend to be star-like. We also analyze several
graded risk settings, and ﬁnd that agents coordinate in a star-like
structure only when defaults are relatively unlikely, and otherwise,
credit links tend to be issued over short social distances conforming
to the locality of information.

6. ACKNOWLEDGMENTS

This research was supported in part by NSF award IIS-0904325.
Part of the research was also sponsored by the Army Research Lab-
oratory and was accomplished under Cooperative Agreement Num-
ber W911NF-09-2-0053. The views and conclusions contained in
this document are those of the authors and should not be interpreted
as representing the ofﬁcial policies of the Army Research Labora-
tory or the U.S. Government. The U.S. Government is authorized to
reproduce and distribute reprints for Government purposes notwith-
standing any copyright notation here on.

7. REFERENCES
[1] E. Anshelevich and M. Hoefer. Contribution games in

networks. Algorithmica, pages 1–40, 2011.
10.1007/s00453-011-9520-7.

[2] V. Bala and S. Goyal. A noncooperative model of network

formation. Econometrica, 68:1181–1229, 2000.

[3] M. A. Barnard. Needle sharing in context: Patterns of

sharing among men and women injectors and HIV risks.
Addiction, 88:805–812, 1993.

[4] L. Blume, D. Easley, J. Kleinberg, R. Kleinberg, and

E. Tardos. Network formation in the presence of contagious
risk. In 12th ACM Conference on Electronic Commerce,
pages 1–10, San Jose, CA, 2011.

[5] J. Corbo, A. Calvó-Armengol, and D. Parkes. A study of
Nash equilibrium in contribution games for peer-to-peer
networks. SIGOPS Operating Systems Review, 40:61–66,
2006.

[6] P. Dandekar, A. Goel, R. Govindan, and I. Post. Liquidity in
credit networks: A little trust goes a long way. In 12th ACM
Conference on Electronic Commerce, pages 147–156, San
Jose, CA, 2011.

[7] D. B. DeFigueiredo and E. T. Barr. TrustDavis: A

non-exploitable online reputation system. In 7th IEEE
International Conference on E-Commerce Technology, pages
274–283, Washington, DC, 2005.

[8] A. Fabrikant, A. Luthra, E. N. Maneva, C. H. Papadimitriou,
and S. Shenker. On a network creation game. In 22nd ACM
Symposium on Principles of Distributed Computing, pages
347–351, 2003.

[9] A. Ghosh, M. Mahdian, D. M. Reeves, D. M. Pennock, and

R. Fugger. Mechanism design on trust networks. In 3rd
International Workshop on Internet and Network Economics,
pages 257–268, 2007.

[10] M. O. Jackson, T. Rodríguez Barraquer, and X. Tan. Social

capital and social quilts: Network patterns of favor exchange.
American Economic Review, pages 1–52, 2011.

[11] M. O. Jackson and A. Wolinsky. A strategic model of social

and economic networks. Journal of Economic Theory,
71(1):44–74, 1996.

[12] J. A. Jacquez, C. P. Simon, J. Koopman, L. Sattenspiel, and

T. Perry. Modeling and analyzing HIV transmission: The
effect of contact patterns. Mathematical Biosciences,
92(2):119 – 199, 1988.

[13] D. Karlan, M. Mobius, T. Rosenblat, and A. Szeidl. Trust

and social collateral. Quarterly Journal of Economics,
124(3):1307–1361, 2009.

[14] Z. Liu, H. Hu, Y. Liu, K. W. Ross, Y. Wang, and M. Mobius.

P2P trading in social networks: The value of staying
connected. In 29th IEEE International Conference on
Computer Communications, pages 1–9, 2010.

[15] M. Mahdian. Fighting censorship with algorithms. In 5th
International Conference on Fun with Algorithms, pages
296–306, Iscia, Italy, 2010.

[16] A. Mislove, A. Post, P. Druschel, and K. P. Gummadi. Ostra:
Leveraging trust to thwart unwanted communication. In 5th
Usenix Symposium on Networked Systems Design and
Implementation, pages 15–30, San Francisco, 2008.

[17] A. Neyman. Correlated equilibrium and potential games.

International Journal of Game Theory, 26:223–227, 1997.
[18] M. P. Wellman, D. M. Reeves, K. M. Lochner, S.-F. Cheng,

and R. Suri. Approximate strategic reasoning through
hierarchical reduction of large symmetric games. In 20th
National Conference on Artiﬁcial Intelligence, pages
502–508, Pittsburgh, 2005.

WWW 2012 – Session: Game Theory and the WebApril 16–20, 2012, Lyon, France568