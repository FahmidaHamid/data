Modeling and Predicting Behavioral Dynamics on the Web

Kira Radinsky‡∗, Krysta Svore†, Susan Dumais†,
Jaime Teevan†, Alex Bocharov†, Eric Horvitz†

‡ CS Department, Technion—Israel Institute of Technology, 32000 Haifa, Israel

† Microsoft Research, Redmond, WA 98052

‡ kirar@cs.technion.ac.il

† {ksvore|sdumais|teevan|alexeib|horvitz}@microsoft.com

ABSTRACT
User behavior on the Web changes over time. For exam-
ple, the queries that people issue to search engines, and the
underlying informational goals behind the queries vary over
time. In this paper, we examine how to model and predict
this temporal user behavior. We develop a temporal mod-
eling framework adapted from physics and signal processing
that can be used to predict time-varying user behavior us-
ing smoothing and trends. We also explore other dynamics
of Web behaviors, such as the detection of periodicities and
surprises. We develop a learning procedure that can be used
to construct models of users’ activities based on features of
current and historical behaviors. The results of experiments
indicate that by using our framework to predict user behav-
ior, we can achieve signiﬁcant improvements in prediction
compared to baseline models that weight historical evidence
the same for all queries. We also develop a novel learning
algorithm that explicitly learns when to apply a given pre-
diction model among a set of such models. Our improved
temporal modeling of user behavior can be used to enhance
query suggestions, crawling policies, and result ranking.
Categories and Subject Descriptors
H.3.7 [Information Storage and Retrieval]: Digital Li-
braries; I.5.4 [Pattern Recognition]: Applications
General Terms
Algorithms, Experimentation
Keywords
Behavioral Analysis, Predictive Behavioral Models
1.

INTRODUCTION

Numerous aspects of the Web change over time, from such
salient changes as the addition and evolution of content, to
more subtle but important dynamics. We explore the tem-
poral dynamics of user behavior, investigating how we can
model and predict changes in the queries that people issue,
the informational goals behind the queries, and the search
results they click on during Web search sessions. In informa-
tion retrieval, models of user behavior have been employed
in the past as static sources of evidence for enhancing access;
user behavior has been aggregated over time and also used
identically for all types of queries. We explore opportunities
∗Part of the research was performed while the author was
at Microsoft Research.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2012, April 16–20, 2012, Lyon, France.
ACM 978-1-4503-1229-5/12/04.

Figure 1: A time series (2/14–5/25, 2011) for the query
japan (normalized by overall #clicks logged on each day).

for learning about how the behavior of users changes over
time and then using predictive models to enhance retrieval.
As an example, for a population of users, the frequency that
a query is issued and the number of times that a search result
is clicked on for that query can change over time. We model
such dynamics in the behavior as a time series, focusing on
queries, URLs, and query-URL pairs as the behaviors.

In Figure 1, we show the query-click behavior of the query
japan over time, i.e., number of clicks on any URL shown for
the query. We can see a dramatic change in behaviors as-
sociated with this query following the Japanese earthquake
on March 11th, 2011. The number of clicks surges for the
query for a period of time, and then slowly decays. Both
the frequency with which a URL is returned for a query and
the frequency that speciﬁc URLs are clicked on can change
over time. We explore the changing behavior of a popu-
lation of searchers via changes in the frequency of query-
URL pairs over time. For the japan query example, the
frequencies of access of some URLs change over time be-
cause of changes in query frequency, while others do not
change (see Figure 2). We can also examine temporal pat-
terns in how often a URL is presented and clicked, aver-
aged over all queries where it is returned. In Figure 3, we
provide an illustration of the number of clicks on the URL
http://en.wikipedia.org/wiki/Japan over time.

These diﬀerent kinds of dynamics, based in changing be-
haviors among a population of users, can be modeled sys-
tematically and predicted. Although the timing of the ini-
tial peak for the query japan may be hard to predict, there
are many other cases in which search behaviors are easier
to predict. Consider the queries presented in Figures 4 —
6. Figure 4 is a good example of a query showing a steady
decrease in click frequency. Figure 5 shows a query under-
going a steady increase in click frequency. Figure 6 presents
a query with periodic changes in frequency of clicks. Using

 Japan query time series Query time series: Japan Normalized #Clicks (10^-6) WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France599gregations of queries over time to understand changes in the
popularity [21] and uniqueness of topics at diﬀerent times
of day [3]. Vlachos et al. [20] were among the ﬁrst to ex-
amine and model periodicities and bursts in Web queries
using methods from Fourier analysis. They also developed a
method to discover important periods and to identify query
bursts. Jones and Diaz [10] identiﬁed three general types of
temporal query proﬁles: atemporal (no periodicities), tem-
porally unambiguous (contain a single spike), and tempo-
rally ambiguous (contain more than one spike). They fur-
ther showed that query proﬁles were related to search perfor-
mance, with atemporal queries being associated with lower
average precision. Some studies [5, 16] used temporal pat-
terns of queries to identify similar queries or words. Shok-
ouhi [18] identiﬁed seasonal queries using time-series anal-
ysis. Kulkarni et al. [14] explored how queries, their as-
sociated documents, and the intentions behind the queries
change over time. The authors identify several features by
which changes to query popularity can be classiﬁed, and
show that presence of these features, when accompanied by
changes in result content, can be a good indicator of change
in the intention behind queries. Kleinberg [11, 12] developed
general techniques for summarizing the temporal dynamics
of textual content and for identifying bursts of terms within
content.

Researchers have also examined the relationship between
query behavior and events. Radinsky et al. [17] showed
that queries reﬂect real-world news events, and Ginsberg
et al. [8] used queries for predicting H1N1 inﬂuenza out-
break. Similarly, Adar et al. [2] identiﬁed when changes in
query frequencies lead or lag behind mentions in both tra-
ditional media and blogs. From a Web search perspective,
breaking news events are a particularly interesting type of
evolving content. Diaz [7] and Dong et al. [1] developed al-
gorithms for identifying queries that are related to breaking
news and for blending relevant news results into core search
results. Yang and Leskovec [22] studied temporal patterns
associated with online content via a time series clustering
approach that uses a similarity metric that is invariant to
scaling and shifting.
Information about time-varying user
behavior was also explored by Koren et al. [13], who used
matrix factorization to model user biases, item biases, and
user preferences over time.

Although much has been done in the investigation of user
behavior over time on the Web, few have pursued the con-
struction of underlying models of this behavior, and then
used these models for prediction of future behavior. We
present methods for modeling behaviors over time that ex-
plain observed changes in the frequency of queries, clicked
URLs, and clicked query-URL pairs.
3. TEMPORAL MODELING OF POPULA-

TION BEHAVIOR ON THE WEB

In this section we present a modeling technique that can
be used to capture the dynamic nature of web behavior.
Of special importance in modeling web search behavior are
global and local trends, periodicities, and surprises. We
present the general theory behind this model (Section 3.1),
the modeling techniques (Section 3.2), the learning proce-
dure for these models from real-world data (Section 3.4),
and how forecasting is performed using these models (Sec-
tion 3.3).
3.1 State-Space Model

The state-space model (SSM) is a mathematical formu-
lation used frequently in work on systems control [9] to

Figure 2: Time series (2/14–5/25, 2011) for sam-
ple clicked URLs for query Japan (normalized by total
#clicks on each day).

Figure 3: A Wikipedia article time series (2/14–5/25,
2011) for Japan (normalized by total #clicks on each day
and position of the URL).

time series modeling, we can estimate these trends and peri-
odicities and predict future values of the frequency of clicks.
More accurate predictions of search behavior can be used to
improve crawling policy and the ranking of search results.

The key contributions described in this paper are as fol-
lows: (1) We highlight the rich opportunities to study hu-
man behavior on the web and explore several models based
on time series to represent and predict diﬀerent aspects of
search behavior over time. We discuss how these models
can be learned from historical user-behavior data, and de-
velop algorithms tailored to address several properties seen
in the dynamics of population behavior on the web, includ-
ing trend, periodicity, noise, surprise, and seasonality detec-
tion. (2) We present a novel learning algorithm which we re-
fer to as dynamics model learner (DML), that determines the
right model for every behavior based on features extracted
from logs of web behavior. We show that DML is superior
to more traditional model selection techniques. (3) Finally,
we perform empirical evaluation of our approaches over real-
world user behavior, providing evidence for the value of our
modeling techniques for capturing the dynamics of user be-
havior on the Web.

2. RELATED WORK

In this paper we examine how to model and predict peo-
ples’ Web search behavior. Of particular interest are changes
in query frequency and clicked URLs over time. Researchers
have examined previously how query volume changes over
time. For example, some researchers have investigated ag-

 Japan query-URL time series Query-URL time series: Japan Normalized #Clicks (10^-6) URL time series: en.wikipedia.org/wiki/Japan Normalized #Clicks (10^-6) WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France600represent a physical system as a set of input, output, and
state variables related by ﬁrst-order diﬀerential equations. It
provides an easy and compact approach for analyzing sys-
tems with multiple inputs and outputs. The model mimics
the optimal control ﬂow of a dynamic system, using some
knowledge about its state variables. These models allow for
great ﬂexibility in the speciﬁcation of the parameters and
the structure of the problem based on some knowledge of
the problem domain, that provides information about the
relations (e.g., linear) among the parameters. Using upper
case letters for matrices and lower case for scalars, the linear
space state model (with additive single-source error) deﬁnes
a system behavior by the following two equations:

Yt = W (θ)Xt + t,
X(t+1) = F (θ)Xt + G(θ)t,

(1)
(2)

Figure 4: Query exhibiting behavior where historical
data has little relevance for prediction (normalized by
overall #clicks on each day).

where Yt is the observation at time t, Xt is the state vector,
t is a noise series, and W (θ), F (θ), G(θ) are matrices of pa-
rameters of the model. For a longer prediction range h, it
is usually assumed that Yt+h = Yt. In our work we assume
(as commonly assumed in natural systems representations)
that t is a Gaussian process with variance σ2. Equations
(1) and (2) are called the measurement and transition equa-
tions, respectively. To build a speciﬁc SSM, a structure for
the matrices W (θ), F (θ), G(θ) is selected, and the optimal
parameters θ and σ and an initial state X0 are estimated.
3.2 Population Behavior as a State Space Model

The SSM representation encompasses all linear time-series
models used in practice. We show in this section how the
SSM can be applied to model the search behavior of a pop-
ulation of people searching on the Web. We model the
state Xt using a trend and seasonal component, as is of-
ten done for modeling time-series [15]. The trend represents
the long-term direction of the time series. The seasonal (or
periodicity) component is a pattern that repeats itself with a
known periodicity, such as every week or every year. We now
present models for user search behavior without trend and
periodicity (using just historical smoothing), models with
only trend or periodicity, and models that combine period-
icity and trend. Each such combination will be represented
by setting the scalars of the matrices W (θ), F (θ), G(θ).
3.2.1 Modeling with Smoothing
Figure 4 displays the click behavior of a population of
users for the query justin bieber. The click popularity de-
creases with time, therefore models that simply average his-
torical data, and then extrapolate a constant value as a pre-
diction, can be poor models of the future. The Simple Holt-
Winters model is a technique for producing an exponentially
decaying average of all past examples, thus giving higher
weights to more recent events. The model is represented by
the equation

yt+1 = α · xt + (1 − α) · yt.

Intuitively, for y = x0, solving the recursive equation as
follows
yt+1 = αxt + . . . + α(1 − α)k−1xt−k + . . . + (1 − α)tx0
produces a prediction yt+1 that weights historical data based
on exponentially decay according to the time distance in
the past. The parameter α is estimated from the data (see
Section 3.4). Converting to SSM notation, let lt = yt+1
where lt is the level of the time series at time t and t =
xt − yt. The measurement and transition equations can be

deﬁned as:

Yt = yt = lt−1,
Xt = lt = lt−1 + αt.

(3)

In this case, W = (1), F = (1), G = (α).
3.2.2 Modeling with Local Trend
In many cases, using only one coeﬃcient to decay previous
data is not expressive enough to capture the dynamics of
the system. One such case is a time series that exhibits a
local trend. Figure 5 shows the query-click behavior for the
query harold camping, who predicted that the end of the
world would commence on May 21st, 2011. The growing
interest in this prediction around this date shows a clear
local growth trend in the time series. Simple smoothing of
historical data would underestimate the dynamics of interest
in this topic. A solution to this problem is the addition of a
trend component to the simple Holt-Winters model:

yt = lt−1 + d · bt−1 + t,
lt = lt−1 + bt−1 + αt,
(lt − lt−1 − bt−1),

∗

bt = bt−1 + β

(4)

where lt is the level of the time series at time t, d is the
damping factor, and bt is an estimation of the growth of the
series at time t, which also can be written as

bt = bt−1 + αβ

∗

t = bt−1 + βt = bt−1 + βt.

Converting to SSM notation, let Xt = (lt, bt)(cid:48), then:

(cid:18)1 1

Yt =(cid:0)1 d(cid:1) Xt−1,
(cid:19)
(cid:18)α
(cid:19)
(cid:18)1 1
(cid:19)

Xt−1 +

β

t.

Xt =

In this case, W =(cid:0)1 d(cid:1) , F =

0 1

(cid:18)α

(cid:19)

β

.

, G =

0 1

3.2.3 Modeling with Periodicity
Figure 6 shows query-click behavior for the query con-
sumer report that exhibits weekly periodicity. Predictions
based only on local trends or smoothing of the data will
perform badly during the peaks. A solution is the addition
of a periodic or seasonal component st to the Simple Holt-
Winters model,

yt = lt−1 + st−m + t,
lt = lt−1 + αt,
)st−m,

∗ · (yt − lt−1) + (1 − γ

∗

st = γ

  Smoothing: Justin Bieber Normalized #Clicks (10^-6) WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France601Figure 5: Query exhibiting behavior with local trend.

Figure 6: Query exhibiting a periodic behavior (nor-
malized by overall #clicks on each day).

where m is the periodicity parameter that is estimated based
on the data along with other parameters.

In SSM notation, the equation system can be written as:

yt = lt−1 + st−m + t,
lt = lt−1 + αt,
st−i = st−i+1,
. . . ,
st = st−m + γt,

(5)

and for Xt = (lt, s1, . . . , sm), we can represent the param-
eters F, G, W in a form of matrices similar to the Trend
Holt-Winters model formulation.
3.2.4 Modeling with Local Trend and Periodicity
In the previous models, the trend and periodicity were
considered separately. However, for many queries, like the
query vampire diaries shown in Figure 7, the trend and
periodicity components are mixed together. The addition
of trend and periodicity parameters produces the following
model:

yt = lt−1 + d · bt−1 + st−m + mt + t,
lt = lt−1 + bt−1 + αt,
bt = bt−1 + βt,
st = st−m + γt,
. . . ,
st−i = st−i+1.

(6)

3.2.5 Modeling Surprises
The Holt-Winters models assume the conversion of a set
of parameters to a single forecast variable Yt. However, in

Figure 7: Query exhibiting periodic behavior with local
trend (normalized by overall #clicks on each day).

many real-world time series, the model itself changes over
time and is aﬀected by external disturbances caused by non-
modeled processes in the open world. For example, in Figure
8, we see a periodic query fda with a disturbance on March
4th, due to an external event concerning the announcement
that some prescription cold products are unsafe. Inclusion
of such outliers might have a strong eﬀect on the forecast
and parameter estimation of a model. We want to identify
characteristics in the temporal patterns which are not ad-
equately explained by the ﬁtted model, and try to model
them for a better estimation of Yt. If these characteristics
take the form of sudden or unexpected movements in the se-
ries we can model them by the addition of disturbances that
capture the occurrences of surprises from the perspective of
the model.

A disturbance or a surprise is an event which takes place
at a particular point in the series, deﬁned by its location and
magnitude. In a time series, the eﬀect of a disturbance is not
limited to the point at which it occurs, but also propagates
and creates subsequent eﬀects that manifest themselves in
subsequent observations.

We augment the standard Holt-Winters model with the
addition of two surprise parameters: mt, which is a surprise
measurement at time t, and kt, which is the surprise trend
at time t:

yt = lt−1 + d · bt−1 + st−m + mt + t,
lt = lt−1 + d · bt−1 + αt,
bt = bt−1 + kt + βt,
st = st−m + γt,
. . . ,
st−i = st−i+1.

(7)

We discuss in Section 4.4 methods for identifying the sur-
prises kt in a time series.
3.3 Forecasting

Once this structure is speciﬁed, the distribution of the fu-
ture values of the time series can be evaluated, given past
history. That is, we learn an SSM for time series Y1, . . . , Yn
jointly with the internal states X0, . . . , Xn, and residuals
0, . . . , n. During prediction, future states Xn+1 are gener-
ated using the state transition equation (2), and based on
these, a distribution of the future values Yn+1 is generated
using the measurement equation (1). The ﬁnal prediction
can be generated by simply using the expected value of this
distribution.

Local Trend: Harold Camping Normalized #Clicks (10^-6)  Periodic: Consumer Reports Normalized #Clicks (10^-6)  Local Trend & Periodicity: Vampire Diaries Normalized #Clicks (10^-6) WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France602search behavior. For example, we know what query was is-
sued, the number of clicks on a given URL for that query,
and so on. In this section, we discuss how to use domain
knowledge to further improve behavior prediction. We fo-
cus on learning which of the trained temporal SSM models
is most appropriate for each object of interest, and then es-
timating parameters for the chosen model.
4.2.1 Learning Problem Deﬁnition
We start by motivating the algorithm formally and deﬁn-
ing the learning problem. Let T be the discrete representa-
tion of time and O be the set of objects and let fi : O× T →
Image(fi) be a set of features. For example, O can be the
URLs, f1(o, t) can be the number of times URL o was clicked
at time t, and f2(o, t) can be the dwell time on the URL at
time t.

In time-series analysis, the learner is given examples of a
single object o over some period t0, . . . , tn, and produces a
classiﬁer C : T → R based on those examples. In its use for
prediction, the classiﬁer is provided with an example of the
object seen at training time ti, and produces the prediction
of its class at time ti+1 (for example, how many times the
URL o is clicked tomorrow).
In regression learning, the learner is given examples of
multiple objects O(cid:48) ⊂ O and produces a classiﬁer C : O → R
based on those examples. During prediction, the classiﬁer
is given an example of an object oi, that has not been seen
before and produces the prediction of its class.

The time-series approach is capable of making speciﬁc pre-
dictions about a speciﬁc object at a certain time, but does
not consider information about other objects in the system
and therefore cannot generalize based on their joint behav-
iors. Regression learning, on the other hand, generalizes over
multiple objects, but does not use the speciﬁc information
about the object it receives during prediction, and therefore
does not use the information about how this speciﬁc object
behaves over time.

We combine the two approaches into a uniﬁed methodol-
ogy that ﬁrst considers generalized information about other
objects to choose a model of prediction and then uses the
speciﬁc knowledge of the predicted object to learn the spe-
ciﬁc parameters of the model for the object. Formally, given
a set of objects O(cid:48) ⊂ O over some period of time t0, . . . , tn,
we produce a classiﬁer C that receives an object o ∈ O (not
necessarily o ∈ O(cid:48)) over some period t0, . . . , tn, and produces
the prediction of its class at time tn+1.
4.2.2 Learning Algorithm
In this section we present a new learning algorithm, dy-
learner (DML), for learning from multiple
namics model
objects with historical data. Let O(cid:48) ⊂ O be a set of ob-
jects given as examples for training the learning model. Let
t1, . . . , tn+σ be the times dedicated for training the model.
For example, O(cid:48) can be a set of queries for which we have
user behavior for the period of time t1, . . . , tn+σ. We divide
the objects into two sets — the learning set, t1, . . . , tn, and
the validation set tn+1, . . . , tn+σ. For every temporal model
described in Section 3, we train a model Yi on the learning
period. We then check for mean square error (MSE) over
the validation period. Formally, let o(t) be the behavior of
object o at time t (e.g., how many times the query o was
searched), then

(o(t) −(cid:98)o(t))2
where(cid:98)o(t) is the model m estimation at time t.

M SE(o, t1, . . . , tn+σ, m) =

σ

(cid:80)tn+σ

t=tn+1

,

Figure 8: Query exhibiting behavior with surprises.

3.4 Parameter Estimation

The SSM family provides a predeﬁned structure for fore-
casting, where the speciﬁc parameters of the model need to
be evaluated from the data. We apply gradient descent [19]
to optimize the model parameters based on training data.
We assume here the following loss function, which is a com-
mon criteria for measuring forecast error:

T(cid:88)

F =

2
t .

(8)

t=1

We deﬁne this to be the likelihood that the residual  =
(0, . . . , T ) is zero. The initial values of X0 are set heuris-
tically, and reﬁned along with the other parameters. The
seasonal component m is estimated from the data by auto-
correlation analysis (see Section 4.3).

4. LEARNING TO PREDICT THE BEHAV-

IOR OF A POPULATION OF SEARCHERS

As described in Section 3, diﬀerent temporal models can
be employed to represent user behaviors over time. We now
present a known method for model selection based on the in-
formation criteria of the time series (Section 4.1), and then
provide a novel method for inferring the model based on
extended and domain-speciﬁc characteristics of the Web be-
haviors (Section 4.2). We conclude with models to detect
periodicity (Section 4.3) and surprise (Section 4.4).
4.1 Information Criteria

We employ training data to select the best predictive
model. A common practice in model selection is to opti-
mize the Bayesian information criterion (BIC),

BIC = −2 · log(L) + q · log(n),

(9)

where q is the number of parameters, n is the length of the
time series, and L is the maximized likelihood function. For
a Gaussian likelihood, this can be expressed as

BIC = n · log(σ2

e ) + q · log(n),

(10)

where σe is the variance of the residual in the testing period
(estimated from the test data). The model with the lowest
BIC is selected to represent the time series and to issue point
forecasts.
4.2 Learning Temporal Behaviors

The criteria mentioned in Section 4.1 takes into account
only the model behavior on the time-series values. However,
in our domain we have access to richer knowledge about

 Surprise: FDA Normalized #Clicks (10^-6) WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France603Let m(i, o) be the model index with the lowest MSE on
the test period for the object o. We construct a set of ex-
amples E = {(cid:104)f1(o), . . . , fn(o)(cid:105), m(i, o)|o ∈ O(cid:48)} — a vector
representing an object and labeled with the best-performing
model for that object. We then use a learner (in our ex-
periments, a decision-tree learner) along with the examples
E to produce a classiﬁer C. During prediction, C is ap-
plied on the object we wish to predict, otarget. The output
m(i, otarget) = C(otarget) represents the most appropriate
model for the object otarget. We train model i using the be-
havior of otarget during t1, . . . , tn+σ. A detailed algorithm
is illustrated in Figure 9. An example of a learned decision
tree is shown in Figure 10. In this ﬁgure, we see that the
periodic model should be applied only on queries considered
periodic (as deﬁned in Section 4.3), along with other char-
acteristics. If the query is not periodic, either the trend or
smoothing model should be applied, depending on the query
shape (quefrencies values) (see Section 4.2.3). Thus by us-
ing the DML model we learn to apply the correct model for
every query, URL or query-URL pair.

Procedure Dynamics Model Learner(O(cid:48), Learner)
Train:
Train temporal models m1(o), . . . , mM (o) for every o ∈ O(cid:48)
E = { (cid:104)f1(o, ti), . . . , fn(o, ti)(cid:105),

arg mini M SE(o, t1, . . . , tn+m, mi)|o ∈ O(cid:48)}

Call Learner with E, and receive the

hypothesis classiﬁer C

Prediction: Given unlabeled instance otarget at time t
chosenModel ← Evaluate C on
learntModel ← Learn chosenModel parameters

(cid:104)f1(otarget, t), . . . , fn(otarget, ti)(cid:105)

using otarget(t1), . . . , tn+m

Return Evaluate learntModel on otarget(t)

Figure 9: The procedure estimates the model type to
learn based on past examples and their features. The
model parameters are estimated and a prediction for the
new object is performed.

4.2.3 Temporal Features
DML uses a set of features fi about each object o. In this
section, we discuss the speciﬁc features we use to train the
DML model used in our experiments. We devise a total of
973 features (partial description of the features is available
on 1), and group them into three groups: aggregate features
of the time series o, shape feature of the time series o, and
other domain-speciﬁc features such as the query class.

Aggregate Features. Features such as the average, min-
imum, maximum, and period of the time series, e.g., the
average of the query volume. Other features consider the
dynamics of the series, e.g., the time series periodicity (see
Section 4.3) and number of surprises (see Section 4.4). We
also consider the size of the spikes during the surprises (the
magnitude of the disturbance).

Shape Features. Shape features represent the shape of
the time series. Our goal is to produce a representation that
is not sensitive to shifts in time or the magnitude of the
diﬀerences. Formally, for a time series y[n] = x[n], we are
looking for a representation that will be equivalent to series
of the form y[n] = x[n−h] and y[n] = A·x[n], for any shift h

Figure 10: A part of the learned dynamic model.

and any scalar A. Homomorphic signal processing is a solu-
tion that satisﬁes these conditions. Intuitively, application
of the Finite Fourier transform (FFT) operator

N−1(cid:88)

xk =

−i2πk n

N

xne

n=0

on a time series transforms it to what is called the spectral
domain, i.e., produces a vector x of size k, where every xk
represents the k-th frequency of the time series. Application
of a log function on the resulting frequency vector and an
additional FFT operator transforms it to what is called the
cepstral domain [6], and the values of x in this product are
called quefrencies. We consider these features to represent
the shape of the series.

Domain-Speciﬁc Features. We also consider a set of
temporal and static features that are domain speciﬁc. For
the query-click time series we consider the total number of
clicked URLs, and the query-click entropy at time t, which
is deﬁned as:

QueryClickEntropy(q, t) = − n(cid:88)

click(ui, q) log p(click(ui, q))

i=1

where u1, . . . , un are the clicked URLs at time t, and click(ui, q)
is the number of clicks on ui for a query q at time t. We
consider an aggregated version of query-click entropy as the
average of the last k = 7 days before the prediction. For
both the query and URL click time series, we consider the
topical distribution of the URL or query. We used a standard
topical classiﬁer which classiﬁes queries into topics based on
categories from the Open Directory Project (ODP) [4]. We
chose to classify into approximately 40 overlapping topics,
such as travel, health, and so on.
4.3 Learning To Detect Periodicity

Detecting the periodicity size of a time series is crucial for
periodic models. For this process we use a signal processing
method called autocorrelation that provides a signal’s corre-
lation value with itself. This method can be used to detect
repeating patterns with noise, and is deﬁned as

Autocorrelation(f, h) =

f (t + h)f (t) dt,

(11)

(cid:90) ∞

−∞

where h is the shift of the series, i.e., the periodicity. Sev-
eral h values are experimented, and the highest value of the
autocorrelation for those values is used. A query is classiﬁed
as periodic based on a certain threshold ω:

1http://www.technion.ac.il/ kirar/Datasets.html

Autocorrelation(f, h) > ω,

(12)

Is Query Periodic? urlImpression_quefrancy1 <= 29.66 queryurlAVG <= 0.04 urlImpression quefrancy10 <= 13.72 Query Period <= 130 URL Peaks AVG<= 0 Query Period <= 126: Smoothing (Eq. 3) Query Period > 126: Periodic (Eq. 5) queryurlImpression_LastValue <= 6 urlImpression_quefrancy_3 <= 5.12 urlImpression quefrancy5 <= 5.76: Local Trend (Eq. 4) urlImpression quefrancy_5 > 5.76: Smoothing (Eq. 3) NO YES WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France604Speciﬁcally in the web domain, we found it beneﬁcial to limit
the possible h values to common web-periodic intervals, such
as weekly, monthly, and yearly (see Section 6.2).
4.4 Learning To Detect Surprises

Queries can be modeled using one of the SSM models in-
troduced previously but, as we discussed earlier, sometimes
areas of the time series exhibit “surprising” behavior that is
not well-ﬁt by the model. We conjecture that, when a tem-
poral model encounters a surprise in the data, the model’s
residual error stops behaving linearly.
Intuitively, in the
beginning of a spike the model “under-predicts” the data
since the previous data did not include any indication of a
spike. After the spike, the model tends to “over-predict”
the data, as it still considers the spike’s data. We intro-
duce surprises as signiﬁcant changes in the residual during
the period of an event. Let r = r1, . . . , rn be the resid-
uals of the temporal model for the times t1, . . . , tn, where
time t. Let t(cid:48)
m be surprise candidates time points,
< 0 for each t(cid:48) ∈ {t(cid:48)
m}, i.e., lo-
such that rt(cid:48)
cations in the time series where the residual changes signs.
Let rt1 and rt2 be two neighboring sign-change points, such
that rt1−1 · rt1 < 0, rt2+1 · rt2 < 0, rt · rt1 > 0, t1 ≤ t ≤ t2.
We deﬁne an impact of an event as

rt = o(t) −(cid:98)o(t), and (cid:98)o(t) is the prediction of the model for

1, . . . , t(cid:48)
1−1 · rt(cid:48)

1, . . . , t(cid:48)

1

Impact(t1, t2) = M SE(o, t1, t2, m) =

Intuitively, only surprises that have long impact on the
model should be considered as a surprise. We propose a
greedy procedure that adds the surprise locations starting
from highest to lowest impact to the model and measures
the improvement of the model (using BIC criteria). When
the model stops improving, we output the surprises. The
full surprise detection algorithm is given in Figure 11.

Procedure Surprise Detector(o(t1), . . . , o(tn),m)

(cid:80)t2

t=t1

r2
t
t2 − t1

.

BICi−1 ← ∞
BICi ← ∞
EventCandidates = {t(cid:48)
Events = {}
Do

1, . . . , t(cid:48)

m|rt(cid:48)

· rt(cid:48)

i

< 0}

i−1

i

Impact(t(cid:48)
i)

curEvent ← arg maxt(cid:48)
EventCandidates ← EventCandidates/{curEvent}
mi ← Build model m with events Events
BICi ← BIC(mi)
If BICi > BICi−1
Events ← Events ∪ {curEvent}
BICi−1 ← BICi

using training data o(t1), . . . , o(tn)

Else Return Events

While EventCandidates (cid:54)= {}
Return Events

Figure 11: Detecting surprises in time series.

5. EXPERIMENTAL SETUP

We now outline the experimental methodology we em-
ployed to test the temporal models that we have presented.
We ﬁrst describe the setup for the prediction experiments,
and then for the periodicity and surprise detection experi-
ments.

5.1 Prediction Experiments
5.1.1 Empirical Methodology
We perform several prediction experiments, namely pre-
dicting query, URL, and query-URL click frequencies. We
also modeled and predicted query, URL and query-URL im-
pressions. Because of space limitations, we present results
only for click behavior. In every experiment, a time series is
created for the behavior for 5 SSM models (Section 3), 2 se-
lection models (BIC (Section 4.1), DML (Section 4.2)), and
4 baseline models (Section 5.1.3). The prediction results are
shown for a variant of the M SE to avoid numerical errors:
M SE(predicted) = E[(predicted − real)0.5]. The above er-
ror is averaged over 12 consecutive prediction days (to avoid
overﬁtting of a speciﬁc day).
5.1.2 Data
For the experiments, we use a dataset containing query
and URL user visit activity obtained from Bing during the
period December 15th, 2010 to April 25th, 2011. The data
contains information about a query’s daily click counts, a
URL’s daily click counts, and, for each query, all of the
URLs presented along with their corresponding daily rank
positions and daily click counts. We ﬁlter the data and con-
sider only queries and URLs that have more than 5 clicks
per day. For each query, we consider the ﬁrst 4 top URLs
by click frequency. We normalize every activity time series
by the total number of activities on that day, to known sea-
sonality of high searches over weekends. For query and URL
pairs, we also normalize by the number of clicks on the URL
at the position at which it was displayed in the displayed
ranked results for the query, producing a value which is not
dependent on the position.

We focus on several types of queries:

1. General Queries We ﬁrst present prediction over a
general sample of queries issued to Bing. For this pur-
pose we use 10000 queries randomly sampled without
repetition on a given day, and 35,862 clicked URLs.

2. Temporal Queries Time series modeling is especially
interesting in cases where the behavior of the popula-
tion of users changes over time. To study such changes,
we identiﬁed three types of queries that we believe will
beneﬁt from temporal modeling.

(a) Dynamic Queries Queries like the japan query
described earlier arise because of external events and
require fresh content to satisfy users’ needs. Trained
judges labeled queries that required fresh results at
speciﬁc points in time. We say that a query q is Dy-
namic if a human labeled it at time t as a query re-
quiring fresh results. In the experiments, a total of 504
dynamic queries and 1512 URLs were used.

(b) Temporal-Reformulation Queries Another way
of identifying queries associated with time-sensitive in-
formational goals is to examine queries that explicitly
refer to a period of time. We focused on queries that
were reformulated to include an explicit temporal ref-
erent (e.g., an initial query world cup might be later
reformulated as world cup 2011 or world cup latest re-
sults). We say that a query q was reformulated to a
query q(cid:48) = q + w, if a user issuing a query q at time t
issued the query q with an additional word w at time
t + 1 in the same session. We say that a query q was
temporally reformulated if w is of type year, day of
week, or if w is one of the following words: current,

WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France605latest, today, this week. Reformulation data was ob-
tained for queries issued in the years 2007-2010. In the
experiments, a total of 330 and 1320 URLs were used.

method that detects peaks as events. This is a reasonable
baseline, as many of the events can be seen as peaks in the
query stream.

(c) Alternating Queries Queries that exhibit inter-
esting temporal behavior often show changes in the
URLs that are presented and clicked on over time. We
focus on a subset of queries, whose most frequently
clicked URLs alternate over time. We say that a query
q is alternating if ∃t1, t2 ∈ T, i, j ∈ N : Click(ui, t1|q) >
Click(uj, t1|q), Click(ui, t2|q) < Click(uj, t2|q), where
u1, . . . , un are the matching URLs to the query q, and
Click(u, t|q) is the number of clicks on u at time t for
the query q. In the experiments, a total of 1836 and
7344 URLs were used.
5.1.3 Baseline Methods
The most commonly used baseline for representing user
search behavior is the averaging of activity over some period
of time. Generally speaking, we consider baselines that per-
form some kind of uniform or non-uniform mapping of the
data, and output the average of the mapping as the predic-
tion. We call these diﬀerent mappings Temporal Weighting
Functions. The modeling in this case is of the form

t−1(cid:88)

i=0

yt =

(cid:80)t−1

w(i, yi)yi
j=0 w(j, yj)

,

where w(i, yi) is a temporal weighting function. In this work,
we consider the following baseline functions:

1. AVG: A simple average of the time series: w(i, yi) = 1.

2. LIN: The linear weighting function: w(i, yi) = i.

3. POW: The power weighting function (in the experi-

ments we set p = 2): w(i, yi) = ip.

4. YES: The yesterday weighting function that only con-
siders the last value of the time series (“what happened
yesterday is what will happen tomorrow”): The YES

(cid:40)

weighting function: w(i, yi) =

1 i = t − 1
0 otherwise.

5.2 Periodicity Detection Experiment

We performed experiments to evaluate the periodicity de-
tection algorithms. This component is crucial for initializing
the SSM seasonal models. To capture long as well as short
periodicity, search logs for query-click data for the period
2006–2011 were obtained, and a daily time series was gen-
erated for every query. We used the seasonality dataset [18]
that contained 259 queries, each annotated as seasonal or
not by several judges. We compare our method for periodic-
ity detection against the method described in Shokouhi [18],
which was applied to perform seasonal-trend decomposition
on the time series, comparing the seasonal component to
that of the time series before the decomposition.
5.3 Surprise Detection Experiment

We performed experiments to evaluate our surprise detec-
tion algorithm. We obtained a set of 24 queries judged by
humans as news-related queries. Judges were also asked to
provide a label (event or not) for every week in the series
(a total of 313 data points for queries behavior for the years
2006-2011 ). A total of 61 events were detected. For every
query we trained the surprise detection model and a baseline
method, and compare their results. The baseline model is a

6. EXPERIMENTAL RESULTS

We now summarize the results for prediction for diﬀerent
temporal models, and also provide results of experiments on
detecting periodicity and surprise.
6.1 Prediction Experiments

We ﬁrst summarize the diﬀerent prediction results for

query, URL, and query-URL click behavior.
6.1.1 Query Prediction
Query click prediction results are shown in Table 1. The
table reports prediction errors, so the smaller the number
the better the prediction accuracy. The best performing
model for each query type is shown in bold. For all of the
query types, we observe that the DML method performs the
best. DML always outperforms the well-known BIC method
for model selection as well as all of the SSM models and
baselines. This shows that learning which model to apply
based on the diﬀerent query features is extremely useful for
query-click prediction.

Comparing the temporal SSM models versus the baselines,
we observe that for the General class of queries the model
that smooths surprises performs the best. This result in-
dicates that most queries are noisy and strongly inﬂuenced
by external events that tend to interfere with model ﬁtting.
For the Dynamic class, temporal models that only take into
account the trend or learn to decay historical data correctly
perform the best. This result aligns with the intuition that
queries which require new results need the most relevant
new information. Thus, old data interferes with prediction.
Most of those queries exhibited a trend in the end of the
period. Few disturbances (surprises) were detected, there-
fore the Surprise model was not useful for this set. A sim-
ilar pattern is shown for the Alternating queries. For the
Temporal-reformulations query class, the baseline that per-
forms simple averaging of historical data yields the best re-
sults. In this category, the best performing temporal models
are those that take into account the periodicity of the query.
Overall, predictions were the most accurate for the Gen-
eral class of queries, indicating that many queries are pre-
dictable. The Temporal Reformulation class of queries pro-
vides the most diﬃcult challenge for predictive models, show-
ing prediction errors of 0.52 (best prediction model error).
Most errors result from queries that are seasonal with a pe-
riodicity of more than a year, e.g., holiday related queries
(sears black Friday) or other annual informational goals as
exempliﬁed by the query 2007 irs tax. As we only had data
for a period of 5 months, such longer-term periodicities were
not detected.
6.1.2 URL Prediction
URL click prediction results are given in Table 2. We see
again that the DML procedure has the best prediction accu-
racy for Dynamic and Temporal Reformulation queries. For
these classes of queries, models that learn to weight histori-
cal behavior and trend models achieve the best performance.
For Alternating queries, we observe that the clicked URL
behavior beneﬁts from seasonality modeling. For Temporal
Reformulation queries, the baseline and DML models show
the best prediction performance. Interestingly, the Periodic,
Trend+Periodic and Surprise models perform poorly. Simi-
lar to what we observed for query prediction, here again the

WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France606Baselines

Temporal SSM Models

Model Selection

Query Type

AVG LIN POW YES

SMOOTH TREND PERIODIC

General
Dynamic

0.17
0.54
Temp Reform 0.56
0.30

Alternating

0.40
0.68
0.67
0.34

0.40
0.68
0.65
0.33

0.18
0.56
0.78
0.33

0.19
0.49
0.76
0.30

0.18
0.49
0.77
0.30

0.17
0.58
0.59
0.44

TREND+
PERIODIC

0.16
0.59
0.62
0.45

SURPRISE DML

BIC

0.15
0.60
0.63
0.45

0.14
0.44
0.52
0.29

0.19
0.48
0.73
0.33

Table 1: Query number of click prediction Error (lower numbers indicate higher performance). Statistically signiﬁcant
results are shown in bold.

tion for regular web periodicity (h = 7, 28, . . . , 31, 360 . . . 365)
is important.
6.3 Surprise Detection Experiment

Table 4 shows results of our surprise detection algorithm
compared to the baseline peak detection algorithm. We see
the surprise detector has high precision and low recall. On
the other hand, the peak detector identiﬁes all surprises but
with very low precision. As most peaks in queries are usually
noise, and not real events, we prefer the Surprise Detector
over the peak detection method. For example, the query
credit rating has some seasonal peaks after S&P declara-
tions, which should not be considered a surprise. However,
the peak detector identiﬁes them as such, while the surprise
detector does not recognize it as an event. On Aug 8th,
when U.S. credit rating was downgraded, the query volume
exhibited an unusual peak, which was identiﬁed by the sur-
prise detector.

Surprises Detector Peak Detector

Precision

Recall

96.42%
59.92%

46.66%
100%

Table 4: Recall and precision of the diﬀerent surprises
detectors. Statistically signiﬁcant results are shown in
bold.

7. CONCLUSIONS

We developed methods for modeling the dynamics of the
query and click behaviors seen in a large population of Web
searchers. We modeled temporal characteristics that are
often observed in query and URL click behavior, including
trend, periodicity, and surprise disruptions. We presented
diﬀerent temporal representations and learning procedures
and showed how we can construct models that predict future
behaviors from historical data.

Temporal models performed better than the baseline mod-
els that use the same weighting of historical data for all
queries in almost all cases. We also found that diﬀerent tem-
poral models are appropriate for diﬀerent types of queries.
Query click behavior tends to be rife with disturbances (sur-
prises). Thus, models that identify and smooth out such dis-
turbances tend to predict well. For speciﬁc types of queries,
such as Dynamic and Alternating queries, trend models are
more appropriate. URL click behavior tends to exhibit dif-
ferent temporal behavior showing fewer disturbances (as we
did not see much gain with using the surprise temporal
model). Thus, models that understand trend and smooth
historical data using learned models tend to perform bet-
ter for these predictions. For Alternating queries, periodic
modeling tends to work better. We found the dynamics
seen in query-URL click behavior to be interesting sources
of insight into changes in users’ intentions over time. We ob-
served that, in general, the application of correct smoothing
or incorporating trend is the best methodology.

Figure 12: Comparison of STL method with Autocor-
relation method for seasonality detection by precision (y
axis) and recall (x axis).

errors stem from URLs that have periodic content with an
annual periodicity lag, which is bigger than the 5 months of
data obtained for training the models. The models incor-
rectly estimate the lag, which is outside of the scope of the
data, and therefore the prediction accuracy is poor.

For URL prediction, the best accuracy is achieved for the
General query set. The most diﬃcult prediction challenge
came from the Dynamic set.
6.1.3 Query-URL Prediction
Query-URL pair click prediction results are shown in Ta-
ble 3. We ﬁrst observe the DML has the best performance
for the General and Temporal Reformulation queries. The
temporal model which smooths across surprises (Surprise)
is especially useful for the Dynamic query type.

Across Tables 1–3, there appear to be two groups of SSM

models: (1) Smooth and Trend models (2) Periodic,
Trend+Periodic and Surprise models. Smooth and Trend
models show very similar performance to each other. Simi-
larly the Periodic, Trend+Periodic and Surprise model be-
have similarly. Sometimes one group performs better than
the other, but the groupings are consistent across the three
tables and four query types.
6.2 Periodicity Detection Experiment

To evaluate our periodicity model, we evaluate perfor-
mance for diﬀerent autocorrelation thresholds, ω. Figure
12 shows the precision-recall results for our autocorrelation
model (Autocorrelation) compared to the baseline model
(STL). The Autocorrelation method proposed in this work
reaches the same maximum recall as the state-of-the-art STL
autocorrelation method (around 0.85), and outperforms it in
precision for every recall level by up to 15 percent. We also
performed experiments for applying autocorrelation without
any lag limiting. The result yields a recall of about 0.25–0.27
with precision of 0.5–0.6. We conclude that the lag limita-

WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France607Baselines

Temporal SSM Models

Model Selection

Query Type

AVG LIN POW YES

SMOOTH TREND PERIODIC

General
Dynamic

0.02
0.77
Temp Reform 0.31
0.49

Alternating

0.02
0.75
0.30
0.49

0.02
0.71
0.27
0.48

0.02
0.72
0.27
0.47

0.01
0.73
0.32
0.51

0.02
0.72
0.29
0.51

0.01
0.74
0.78
0.41

TREND+
PERIODIC

0.01
0.76
0.72
0.42

SURPRISE DML

BIC

0.01
0.76
0.72
0.42

0.02
0.72
0.27
0.48

0.02
0.73
0.28
0.51

Table 2: URL number of click prediction Error (lower numbers indicate higher performance). Statistically signiﬁcant
results are shown in bold.

Baselines

Temporal SSM Models

Model Selection

Query Type

AVG LIN POW YES

SMOOTH TREND PERIODIC

General
Dynamic

0.16
0.28
Temp Reform 0.53
0.08

Alternating

0.20
0.40
0.68
0.12

0.20
0.39
0.67
0.11

0.16
0.41
0.69
0.13

0.12
0.29
0.66
0.13

0.14
0.28
0.69
0.13

0.42
0.20
0.58
0.17

TREND+
PERIODIC

0.23
0.20
0.58
0.16

SURPRISE DML

BIC

0.23
0.19
0.59
0.16

0.10
0.25
0.48
0.09

0.12
0.28
0.63
0.12

Table 3: Query-URL number of click prediction Error (lower numbers indicate higher performance). Statistically
signiﬁcant results are shown in bold.

We introduced a novel Dynamics Model Learner (DML)
algorithm, that learns the correct model to apply for every
query, URL or query-URL pair that it is presented with,
without a priori categorization of queries into groups. We
compared the predictive performance of this method with
static baselines, temporal models, and a standard model
selection algorithm (BIC), and found that it has superior
performance in all groups. We believe this result paves the
way for incorporating multiple types of models for better
time-aware search procedures.

The kinds of time-aware modeling of user behavior that
we introduced in this paper can be incorporated in many
search-related applications. Query click prediction can be
used to improve query suggestions to present the most ap-
propriate suggestions at the time the query is issued. URL
click prediction can be used to improve re-crawling strate-
gies, by focusing crawling eﬀorts on URLs that are likely to
be clicked. And, Query-URL prediction can induce better
ranking that is more aware of the user query-URL tempo-
ral intent. Additionally, the models we have presented in
this work can also be used at diﬀerent time granularities
and applied on diﬀerent types of objects (Query, URL and
Query-URL), either aggregated for all users or applied on
speciﬁc user behavior, thus creating time-aware personalized
retrieval, where the temporal intent is modiﬁed to accom-
modate individual searchers.
8. ACKNOWLEDGMENTS

We thank Dan Liebling for help with obtaining the user behav-
ior data, and Chris Meek and Kuansan Wang for fruitful discus-
sions. We also thank Milad Shokouhi for providing the labeled
seasonal queries.

9. REFERENCES
[1] Z. Zheng G. Mishne J. Bai R. Zhang K. Bichner C. Liao

A. Dong, Y. Chang and F. Diaz. Towards recency ranking
in web search. In WSDM, 2010.

[2] E. Adar, D. S. Weld, B. N. Bershad, and S. D. Gribble.

Why we search: visualizing and predicting user behavior. In
WWW, 2007.

[3] S. M. Beitzel, E. C. Jensen, A. Chowdhury, D. Grossman,

and O. Frieder. Hourly analysis of a very large topically
categorized web query log. In SIGIR, 2004.
[4] P. N. Bennett, K. Svore, and S. T. Dumais.

Classiﬁcation-enhanced ranking. In WWW, 2010.

[5] S. Chien and N. Immorlica. Semantic similarity between

search engine queries using temporal correlation. In WWW,
2005.

[6] D. P. Skinner D. G. Childers and R. C. Kemerait. The
cepstrum: A guide to processing. IEEE, 65:1428–1443,
1977.

[7] F. Diaz. Integration of news content into web results. In

WSDM, 2009.

[8] J. Ginsberg, M. Mohebbi, R. Patel, L. Brammer,

M. Smolinski, and L. Brilliant. Detecting inﬂuenza
epidemics using search engine query data. Nature,
457(7232):1012–4, 2009.

[9] J.Durbin and S.Koopman. Time Series Analysis by State

Space Methods. Oxford University Press, 2008.

[10] R. Jones and F. Diaz. Temporal proﬁles of queries. ACM

Trans. Inf. Syst, 2004.

[11] J. Kleinberg. Bursty and hierarchical structure in streams.

In KDD, 2002.

[12] J. Kleinberg. Temporal dynamics of on-line information

systems. Data Stream Management: Processing High-Speed
Data Streams. Springer, 2006.

[13] Y. Koren. Collaborative ﬁltering with temporal dynamics.

In KDD, 2009.

[14] A. Kulkarni, J. Teevan, K. M. Svore, and S. T. Dumais.

Understanding temporal query dynamics.

[15] J.Ord R. Hyndman, A.Koehler and R.Snyder. Forecasting
with Exponential Smoothing (The State Space Approach).
Springer, 2008.

[16] K. Radinsky, E. Agichtein, E. Gabrilovich, and

S. Markovitch. A word at a time: Computing word
relatedness using temporal semantic analysis. In WWW,
2011.

[17] K. Radinsky, S. Davidovich, and S. Markovitch. Predicting
the news of tomorrow using patterns in web search queries.
In WI, 2008.

[18] M. Shokouhi. Detecting seasonal queries by time-series

analysis. In SIGIR, 2011.

[19] Jan A. Snyman. Practical Mathematical Optimization: An

Introduction to Basic Optimization Theory and Classical
and New Gradient-Based Algorithms. Springer, 2005.
[20] M. Vlachos, C. Meek, Z. Vagena, and D. Gunopulos.

Identifying similarities, periodicities and bursts for online
search queries. In SIGMOD, 2004.

[21] P. Wang, M. W. Berry, and Y. Yang. Mining longitudinal

web queries: trends and patterns. JASIST, 54:743–758,
2003.

[22] J. Yang and J. Leskovec. Patterns of temporal variation in

online media. In WSDM, 2011.

WWW 2012 – Session: Web User Behavioral Analysis and ModelingApril 16–20, 2012, Lyon, France608