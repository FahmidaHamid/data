Spectral Analysis of Communication Networks Using

Dirichlet Eigenvalues

∗
Alexander Tsiatas

9500 Gilman Drive

La Jolla, CA 92093-0404
atsiatas@cs.ucsd.edu

Onuttom Narayan
Department of Physics

Department of Computer Science and Engineering

University of California, San Diego

University of California, Santa Cruz

1156 High Street

Santa Cruz, CA 95064

narayan@physics.ucsc.edu

Iraj Saniee

Mathematics of Networks
Alcatel-Lucent Bell Labs
600 Mountain Avenue
Murray Hill, NJ 07974

iis@research.bell-labs.com

Matthew Andrews

Mathematics of Networks
Alcatel-Lucent Bell Labs
600 Mountain Avenue
Murray Hill, NJ 07974

andrews@research.bell-labs.com

ABSTRACT
Good clustering can provide critical insight into potential
locations where congestion in a network may occur. A nat-
ural measure of congestion for a collection of nodes in a
graph is its Cheeger ratio, deﬁned as the ratio of the size
of its boundary to its volume. Spectral methods provide
eﬀective means to estimate the smallest Cheeger ratio via
the spectral gap of the graph Laplacian. Here, we compute
the spectral gap of the truncated graph Laplacian, with the
so-called Dirichlet boundary condition, for the graphs of a
dozen communication networks at the IP-layer, which are
subgraphs of the much larger global IP-layer network. We
show that i) the Dirichlet spectral gap of these networks is
substantially larger than the standard spectral gap and is
therefore a better indicator of the true expansion proper-
ties of the graph, ii) unlike the standard spectral gap, the
Dirichlet spectral gaps of progressively larger subgraphs con-
verge to that of the global network, thus allowing proper-
ties of the global network to be eﬃciently obtained from
them, and (iii) the (ﬁrst two) eigenvectors of the Dirichlet
graph Laplacian can be used for spectral clustering with ar-
guably better results than standard spectral clustering. We
ﬁrst demonstrate these results analytically for ﬁnite regular
trees. We then perform spectral clustering on the IP-layer
networks using Dirichlet eigenvectors and show that it yields
cuts near the network core, thus creating genuine single-
component clusters. This is much better than traditional
spectral clustering where several disjoint fragments near the
network periphery are liable to be misleadingly classiﬁed as a
single cluster. Since congestion in communication networks
is known to peak at the core due to large-scale curvature
and geometry, identiﬁcation of core congestion and its local-
ization are important steps in analysis and improved engi-
∗
Pkwy, Mountain View, CA 94043.

At time of publication, at Google Inc., 1600 Amphitheatre

Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW’13, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

neering of networks. Thus, spectral clustering with Dirichlet
boundary condition is seen to be more eﬀective at ﬁnding
bona-ﬁde bottlenecks and congestion than standard spectral
clustering.

Categories and Subject Descriptors
G.2.2 [Discrete Mathematics]: Graph Theory—network
problems; C.2.1 [Computer-Communication Networks]:
Network Architecture and Design—network topology

Keywords
Spectral clustering, Dirichlet eigenvalues, Communication
networks, Cheeger ratio

1.

INTRODUCTION

An important problem in network analysis is partition-
ing nodes, also sometimes known as ﬁnding communities.
This requires ﬁnding clusters of nodes that are inherently
well-connected within themselves with sparser connections
between clusters; when the clusters do not overlap, they de-
ﬁne a partitioning of the graph. This problem is also closely
related to ﬁnding network bottlenecks; if a graph has bot-
tlenecks, then a good partition is often found by dividing
the graph at its bottlenecks. Many real-world networks are
truly vast, encompassing hundreds of thousands to billions
of nodes and edges; for example, communication, social and
biological networks. This scale produces serious computa-
tional challenges for detection of bottlenecks and communi-
ties: the large majority of algorithms are computationally
too intensive to use at this scale on such graphs. Instead,
one can study smaller sub-graphs of these networks; for ex-
ample, the portion of a social network corresponding to one
university or the portion of a communication network corre-
sponding to one Internet service provider, and hope to derive
properties of the larger graph from those of the smaller sub-
graphs. In this paper, we show how to deﬁne key properties
of a graph, its Dirichlet spectral gap and eigenvectors which
aid in clustering, and show how these closely relate to the

1297spectral gaps and eigenvectors of its sub-graphs thus making
identiﬁcation of bottlenecks and points of congestion both
more eﬀective and scalable.

More precisely, spectral graph theory [3], the study of
eigenvalues and eigenvectors of graph-theoretic matrices, is
often used to analyze various graph properties. One might
hope that the properties of a large sub-graph of a network
will be representative of the properties of the entire net-
work. Unfortunately, the properties of an expander graph
depend on the conditions imposed at its (large) boundary.
For example, the spectral gap of the graph Laplacian on a
ﬁnite truncation of an inﬁnite regular tree approaches zero
as the size of the truncation is increased, even though the
spectral gap of its inﬁnite counterpart is non-zero. In this
paper we show that, by contrast, if the spectral gap is cal-
culated with Dirichlet boundary conditions, it approaches
the inﬁnite graph limit as the size of truncation is increased.
Computation of a better spectral gap makes it possible to do
spectral clustering more eﬀectively thus making identiﬁca-
tion of bottlenecks and points of congestion more eﬀective.
Motivated by this result, we compute the Dirichlet spec-
tral gap for ten IP-layer communication networks as mea-
sured and documented by previous researchers in the Rock-
etfuel database [18]. We ﬁnd that the Dirichlet spectral gap
is much larger than the traditional spectral gap for these
graphs. (Traditional spectral clustering uses the normalized
Laplacian matrix L or some similar matrix; we use the ma-
trix LD: the Laplacian restricted to the rows and columns
corresponding to non-boundary nodes.) Moreover, unlike
the traditional spectral gap, it does not trend downwards
for larger networks. This indicates that the spectral gap for
these networks viewed as sub-graphs of a much larger graph
is away from zero.

There are precedents for treating networks essentially as
subsets of an an overarching (inﬁnite) graph; many net-
work generation models [2, 6, 21] exhibit unique convergence
properties (to power-law degree distributions or otherwise)
as the size of the network grows to inﬁnity. We also note that
Dirichlet boundary conditions have been shown to be suc-
cessful at mitigating other boundary-related issues in graph
vertex ranking [5].

There is a direct connection between the spectral gap
and clustering in networks, through the Cheeger inequality.
Spectral graph theory has led to many eﬀective algorithms
for ﬁnding cuts that result in a small Cheeger ratio, includ-
ing spectral clustering [15, 17, 16, 20] and local graph par-
titioning algorithms [1]. These algorithms have been well-
studied, both empirically [15, 17] and theoretically [15, 20].
Unfortunately, these algorithms can also exhibit some unde-
sirable behavior. It has been shown empirically [12] that the
“best” partitionings of many networks, as measured by the
Cheeger ratio, result in cutting oﬀ nodes or subtrees near
the boundary of the network. The resulting ‘clusters’ near
the boundary actually consist of several disjoint fragments.
Especially when viewed as subsets of larger networks, this
kind of clustering is not particularly meaningful.

In this paper, we use Dirichlet spectral clustering to iden-
tify good cuts in the networks in the Rocketfuel database.
We use the top two eigenvectors of LD, the normalized graph
Laplacian with Dirichlet boundary conditions, to cut the
network into two sections. We demonstrate that, compared
to traditional spectral clustering, there is a substantial re-
duction in the average number of components resulting from

the cut, without a signiﬁcant increase in the Cheeger ratio.
Instead of ﬁnding cuts near the boundaries of the networks,
Dirichlet spectral clustering obtains cuts in the network core.
The Cheeger ratio of a cut is a well known indicator of the
congestion across the cut; small Cheeger ratios are likely to
be associated with bottlenecks. The emphasis on identify-
ing core bottlenecks becomes more critical in the light of
the recent observation that many real-world graphs exhibit
large-scale curvature [10, 14]. It has been shown [10, 14] that
such global network curvature leads to core bottlenecks with
load (or betweenness) asymptotically much worse than ﬂat
networks, where “load” means the the maximum total ﬂow
through a node assuming unit traﬃc between every node-
pair along shortest paths [14]. As such, it is important to
ﬁnd and characterize bottlenecks at the core rather than
the fringes, where they do not matter as much. Our ob-
servations, suggest that Dirichlet spectral clustering may be
more useful in this regard.

The rest of this paper is structured as follows: in Section 2,
we give the theoretical justiﬁcation for using Dirichlet eigen-
values [4] instead of the traditional spectrum for analyzing
and clustering ﬁnite portions of much larger graphs. In Sec-
tion 3, we then compare the spectral gap using Dirichlet
eigenvalues to the traditional spectral gap on real, publicly-
determined network topologies [18] that represent smaller
portions of the wider telecommunications grid. In Section
4, we demonstrate how Dirichlet spectral clustering ﬁnds
graph partitions that are more indicative of bottlenecks in
the network core rather than the fringes.

2. SPECTRUM OF FINITE TREES: MOTI-
VATION FOR DIRICHLET SPECTRAL
CLUSTERING

Throughout this paper, we analyze general undirected
connected graphs G by using the normalized graph Lapla-
cian L, deﬁned as in [3]. For two vertices x and y, the
corresponding matrix entry is:

⎧⎪⎨
1
− 1√
⎪⎩

0

Lxy =

dxdy

if x = y,
if x and y are adjacent, and

otherwise,

where dx and dy are the degrees of x and y. We denote
by λ the spectral gap, which is simply the smallest nonzero
eigenvalue of L.
For any graph G and ﬁnite subgraph S ⊂ G, the Cheeger

ratio h(S) is a measure of the cut induced by S:

h(S) =

e(S, ¯S)

min(vol(S), vol( ¯S))

.

We use e(S, ¯S) to denote the number of edges crossing from S
to its complement, and the volume vol(S) is simply the sum
of the degrees of all nodes in S. The Cheeger constant h is the
minimum h(S) over all subsets S. The Cheeger constant and
spectral gap are related by the following Cheeger inequality
[3]:

2h ≥ λ ≥ h2
2

.

Both λ and h are often used to characterize expansion or
bottlenecks in graphs. This inequality shows that they are

1298both good candidates and gives the ability to estimate one
based on the other.

For the inﬁnite d-regular tree, the spectral gap and Cheeger
constant have both been analytically determined [7, 13]. Us-
ing L, the spectral gap is

λ = 1 − 2
d

√

d − 1,

(1)
and the Cheeger constant is h = d− 2 [9]. Both of these val-
ues are nonzero, indicating good expansion. However, the
Cheeger ratio for truncated d-regular trees (T dT) – those
with all branches of the inﬁnite tree cut oﬀ beyond some
radius r from the center – approaches zero as the tree gets
deeper. By cutting oﬀ any one subtree S from the root,
there is only one edge connecting S to ¯S, and as the tree gets
deeper, this ratio gets arbitrarily small. Using the Cheeger
inequality, it follows that the λT dT → 0 as r → ∞. Thus, the
standard spectral properties of ﬁnite trees do not approach
the inﬁnite case as they get larger; in fact, they suggest the
opposite. This is problematic when making qualitative ob-
servations about networks and their expansion, necessitating
another tool for spectral analysis of networks.

The main reason why the traditional spectral gap does not
capture expansion well in large, ﬁnite trees is the existence
of a boundary. This is also problematic in network parti-
tioning algorithms; often times the “best” partition is a bag
of whiskers or combination of several smaller cuts near the
boundary [12]. In this paper, we will use Dirichlet eigenval-
ues to eliminate this problem.

Dirichlet eigenvalues are the eigenvalues of a truncated
matrix, eliminating the rows and columns that are associ-
ated with nodes on the graph boundary. We will use a trun-
cated normalized graph Laplacian, LD, a submatrix of L.
This is diﬀerent from simply taking the normalized Lapla-
cian of an induced subgraph, as the edges leading to the
boundary nodes are still taken into account; it is only the
boundary nodes themselves that are ignored. We deﬁne the
Dirichlet spectral gap to be the smallest eigenvalue of LD.
This version of the graph Laplacian was ﬁrst introduced in
[4] to analyze local cuts on graphs.

Using Dirichlet eigenvalues, it is also possible to obtain a
local Cheeger inequality [4] for the sub-graph S. First, the
local Cheeger ratio is deﬁned [4] for a set of nodes T ⊂ S as

H(T ) =

e(T, ¯T )
vol(T )

;

because the boundary nodes are excluded from S in the deﬁ-
nition of [4], the set T cannot contain any boundary nodes of
S. The local Cheeger ratio H(T ) is the appropriate quantity
when S is a sub-graph of a larger graph. Note that there is
no min in the denominator; this is because the local Cheeger
ratio is speciﬁc to a subgraph, and it does not make sense to
take into account the rest of the graph beyond the bound-
ary of that subgraph. The local Cheeger constant hS for S is
then deﬁned as the minimum of H(T ) for all T ⊂ S \ ∂(S).
The local Cheeger inequality obtained in [4] is

hS ≥ λS ≥ h2
S
2

,

where λS is the Dirichlet eigenvalue of the normalized Lapla-
cian restricted to the rows and columns corresponding to
nodes in S. This inequality indicates a relationship between
local expansion and bottlenecks.

Figure 1: Dirichlet spectral gap for successively
larger 3-regular trees, showing convergence to a
nonzero value. The limit, as estimated by the
Cheeger inequality, is λ ≈ 0.057.

The use of Dirichlet eigenvalues requires that the bound-
ary of the graph S be deﬁned. If S is a tree, the leaf nodes
are a natural choice. When S is actually a ﬁnite trunca-
tion of a larger graph, the boundary can be deﬁned as the
set of nodes that connect directly to other nodes outside
the truncation; for the Rocketfuel data [18], we will use the
nodes with degree 1 which presumably connect outside of
the subnetwork.

We ﬁrst use Dirichlet eigenvalues on d-regular trees as pro-
totypical evidence for their eﬀectiveness in capturing true
spectral properties on real-world networks. There is empiri-
cal evidence in Figure 1, showing that the Dirichlet spectral
gap for 3-regular trees indeed converges to a nonzero value as
tree depth increases, contrasting with the traditional spec-
tral gap which converges to zero. This is made rigorous in
the following theorem:

Theorem 1. For ﬁnite d-regular trees of depth L, the
Dirichlet spectral gap converges to the true spectral gap (1)
of the inﬁnite tree as L approaches inﬁnity.

Proof. To derive the Dirichlet spectral gap for ﬁnite
trees using the leaves as the boundary, we will solve a recur-
rence that arises from the tree structure and the standard
eigenvalue equation

Ld(cid:4)x = λ(cid:4)x.

(2)

Let T be a d-regular tree of depth L + 1; the (L + 1)st
level is the boundary. We ﬁrst consider eigenvectors (cid:4)x which
have the same value at every node at the same depth within
T ; these eigenvectors are azimuthally symmetric. We can
represent each such eigenvector (cid:4)x as a sequence of values
(x0, x1, . . . , xL), where xi is the uniform value at all nodes
at depth i, similar to the analysis of the inﬁnite-tree spectral
gap appearing in [7]. Using this eigenvector form for (cid:4)x in
(2) leads to the recurrence:

xi − 1
d

xi−1 − d − 1

d

xi+1 = λxi, 2 ≤ i ≤ L.

(3)

1299At the leaves of the tree, we have the Dirichlet boundary
condition:

xL+1 = 0,

(4)

and at the root of the tree we have the boundary condition

x0 − x1 = λx0.

We can solve (3) using the characteristic equation:

d − 1
d

r2 − (1 − λ)r +

1
d = 0,

whose roots can be written as
1√
d − 1

r1,2 =

e±iα

with

λ = 1 − 2
d

√

d − 1 cos α.

(5)

(6)

(7)

Since λ has to be real, either the real or imaginary part of α
must be zero. Substituting the ﬁrst boundary condition (4)
yields a solution to (3) with the form

Figure 2: Comparison of traditional and Dirichlet
spectral gaps in Rocketfuel data as well as the 2-
dimensional Euclidean grid.

3. SPECTRUM OF ROCKETFUEL

xn = A(rn−L−1

1

− rn−L−1

2

).

(8)

NETWORKS

for some constant A and r1,2 given in (6). Using (5), the
condition for eigenvalues is

tan α

tan(L + 1)α = − d − 2

d

0 < α < π.

(9)

Since tanh x/ tanh(L + 1)x >0 for all real x, there are no
imaginary solutions to Eq.(9). Therefore all the L + 1 solu-
tions are real. From Eq.(7), the corresponding L + 1 eigen-
values are all outside the inﬁnite-tree spectral gap.
We now consider eigenvectors which are zero at all nodes
up to the k’th level with L > k ≥ 0. The eigenvector is
non-zero at two daughters of some k’th level node and the
descendants thereof. We assume azimuthal symmetry in-
side both these two sectors. The eigenvalue condition for
the parent node at the k’th level forces the eigenvector to
be opposite in the two sectors. Inside each sector, (3), (6),
(7) (4) and (8) are still valid. However, (5) is replaced by
the condition xk = 0, from which sin(L + 1− k)α = 0.
There are L − k real solutions to this equation, correspond-
ing to eigenvalues that lie outside the inﬁnite-tree spectral
gap, each with degeneracy dk(d − 1). The total number of
eigenvalues we have found so far is

L + 1 +

L−1(cid:6)

k=0

(d − 1)(L − k) =

dk

dL+1 − 1
d − 1

(10)

i.e. we have found all the eigenvalues. As L gets larger, the
smallest α approaches 0, showing that the Dirichlet spectral
gap converges to the spectral gap of the inﬁnite tree (1) as
the depth approaches inﬁnity.

This derivation shows that Dirichlet eigenvalues capture
the expansion properties of trees much better than the tra-
ditional spectral gap which has been shown to approach zero
for large ﬁnite trees. This behavior on trees suggests that
Dirichlet eigenvalues are a good candidate for use in analyz-
ing real-world networks. Such analysis appears in Section
3.

Our work is motivated by derivation of scalable meth-
ods for clustering of large graphs. As an example, we study
clustering of a series of datasets representing portions of net-
work topologies using Rocketfuel [18]. Rocketfuel datasets
are publicly-available, created using traceroute and other
networking tools to determine portions of network topol-
ogy corresponding to individual Internet service providers.
Even though like most measured datasets, the Rocketfuel
networks are not free of errors (see for example [19]), they
provide valuable connectivity information at the IP-layer of
service provider networks across the globe. Because the
datasets were created in this manner, they represent only
subsets of the much larger Internet; it becomes impossible
to determine network topology at certain points. For exam-
ple, corporate intranets, home networks, other ISP’s, and
network-address translation cannot be explored. The net-
works used range in size from 121 to 10,152 nodes.

Because of the method of data collection, the Rocketfuel
datasets contain many degree-1 nodes that appear at the
edge of the topology. In actuality, the network extends be-
yond this point, but the datasets are limited to one ISP
at a time. As such, for these networks, it makes sense to
view these degree-1 nodes as the boundary of a ﬁnite subset
of a much larger network. Using this boundary deﬁnition,
we compute the Dirichlet spectral gaps of these graphs and
compare with their standard counterparts, as shown in Ta-
ble 1 and Figure 2. It is apparent that the Dirichlet spectral
gaps are much larger than the traditional spectral gaps for
all the networks, implying a much higher degree of expan-
sion than one would traditionally obtain. The spectral gaps
for a two-dimensional square Euclidean grid are also shown;
the grid is known to be a poor expander, and accordingly
even the Dirichlet spectral gap is very small.

Figure 3 shows the same data, plotted as a function of
the number of nodes N in each network. We see that the
traditional spectral gap keeps decreasing as N is increased,
whereas the Dirichlet spectral gap does not.

Since Figure 3 compares diﬀerent networks, possibly with
diﬀerent properties, we conﬁrm the result by computing the

1300Table 1: Structural and spectral properties of Rocketfuel datasets.

Dataset ID Nodes Edges Traditional spectral gap Dirichlet spectral gap

1221
1239
1755
2914
3257
3356
3967
4755
6461
7018
Grid

2998
8341
605
7102
855
3447
895
121
2720
10152
10000

3806
14025
1035
12291
1173
9390
2070
228
3824
14319
19800

0.00386
0.01593
0.00896
0.00118
0.01045
0.00449
0.00799
0.03570
0.00639
0.00029
0.00025

0.07616
0.03585
0.09585
0.04621
0.04738
0.05083
0.03365
0.06300
0.11036
0.09531
0.00050

Figure 3: Comparison of traditional and Dirichlet
spectral gaps across Rocketfuel networks.

Figure 4: Comparison of traditional and Dirich-
let spectral gaps in successively larger subgraphs,
grown from the center of mass of dataset 7018.

spectral gap for subgraphs of diﬀerent sizes drawn from a
single network. All the nodes that are within a distance r
of the center of mass of a network are included in a sub-
graph, with r varying between 1 and the maximum possible
value for the network. In Fig. 4 shows the results for the
largest of the Rocketfuel networks, dataset 7018 containing
over 10,000 nodes. For a subgraph of radius r, the bound-
ary is deﬁned as all the nodes which i) have edges connecting
them to nodes in the graph that are outside the subgraph or
ii) connect to the outside world, i.e. that have degree 1 in
the full dataset. As in Fig. 3, in Fig. 4, the traditional spec-
tral gap keeps decreasing as r is increased, but the Dirichlet
spectral gap does not.

4. SPECTRAL DECOMPOSITION

One important application of the eigendecomposition of
a graph is spectral clustering or partitioning [15, 17]. The
problem is to group the nodes into partitions, clusters, or
communities that are inherently well-connected within them-
selves, with sparser connections between clusters. This is
closely related to ﬁnding bottlenecks; if a graph has a bot-
tleneck, then a good partition is often found by dividing the
graph at the bottleneck. See [16] for a general survey of
graph clustering.

It is often desirable for a network partition to be balanced,
and ﬁnding bottlenecks near the core or center of mass of a
network is often more useful than simply clipping small sub-
sets of nodes near the boundary. But according to [12], using

the Cheeger ratio as a metric on real-world data, the “best”
cuts larger than a certain critical size are actually “bags of
whiskers” or combinations of numerous smaller cuts. Be-
cause many graph clustering algorithms, including spectral
clustering, try to optimize for this metric, the resulting par-
titions often slice numerous smaller cuts oﬀ the graph, which
is not always useful. For our Rocketfuel data, we know that
the boundary of the network is imposed by the method of
data collection. Thus, by eliminating the boundary from
graph clustering, we can more easily ﬁnd partitions that are
more evenly balanced, and bottlenecks that are closer to the
core of the network.

To do this, we use standard spectral clustering techniques
from [15], but instead of using the normalized graph Lapla-
cian L, we use the truncated Dirichlet version LD. The
eigenvectors used for clustering will therefore not include
components for the degree-1 boundary nodes, but we can
assign them to the same side of the partition as their non-
boundary neighbor nodes. Speciﬁcally, we compute the ﬁrst
two eigenvectors of LD and cluster the nodes based on their
components in these eigenvectors using k-means. For each
node, we compute the distance to both centers and sort the
nodes based on the diﬀerence. For a partition of size k, we
take the top k nodes.

We follow the experiments of Leskovec et al. in [12] by us-
ing both traditional spectral clustering and Dirichlet spec-
tral clustering to ﬁnd cuts of diﬀerent sizes. Speciﬁcally, we
ﬁnd Dirichlet cuts of all possible sizes, and then we ﬁnd cuts

1301using traditional spectral clustering for those same sizes af-
ter adding boundary nodes back in. Thus, for each network
of N nodes, we calculate N − B cuts, where B is the number
of boundary nodes.

For each cut, we measure the Cheeger ratio h and the
number of components c. Ideally, a logical cut would split
the network into exactly c = 2 components, but as Leskovec
et al. demonstrated, as cut size increases, spectral clustering
and other algorithms that optimize for h yield cuts with
many components. This is precisely the problem we are
trying to avoid using Dirichlet clustering, and our results
show that Dirichlet clustering is eﬀective in ﬁnding cuts with
fewer components. Furthermore, even though our algorithm
is not speciﬁcally optimizing for h, it does not ﬁnd cuts that
have signiﬁcantly worse values for h while ﬁnding cuts with
far fewer components.

We outline some aggregate data in Table 2. For several
datasets, we count the number of cuts in four diﬀerent cate-
gories, comparing the Dirichlet Cheeger ratio and number of
components (hD and cD) with traditional spectral clustering
(hT and cT ). It is evident that Dirichlet clustering ﬁnds cuts
with fewer components than traditional spectral clustering
(cD ≤ cT ) for most cut sizes, indicating that while spectral
clustering optimizes for Cheeger ratio, it often “cheats” by
collecting whiskers as one cut. In addition, despite the use of
Cheeger ratio optimization, Dirichlet clustering sometimes
ﬁnds cuts with better Cheeger ratio as well. In the last two
columns for each dataset, we give the diﬀerence in h and c
averaged out over all cut sizes. It turns out that the Cheeger
ratios, on average, are not drastically diﬀerent between the
two methods, and Dirichlet clustering gives cuts with far
fewer components.

Along with our aggregate data, we illustrate each indi-
vidual cut for several of our Rocketfuel datasets in Fig. 5.
(A few of the datasets were too large for accurate numerical
computation and are therefore not shown.) For each cut size,
we plot a point corresponding to the diﬀerence in Cheeger
ratio h and the number of components c between Dirich-
let and traditional spectral clustering.
It should be clear
that for the majority of cut sizes, Dirichlet clustering ﬁnds
cuts with far fewer components, but there is generally little
change in Cheeger ratio. This can be seen in the large vari-
ation on the c-axis with much smaller discrepancies on the
h-axis.
In other words, Dirichlet clustering avoids ﬁnding
“bags of whiskers” while still maintaining good separation in
terms of h, despite not explicitly optimizing for h.

We further visualize Dirichlet spectral clustering for two
Rocketfuel data sets, shown in Figures 6 and 7.
In both
cases, one side of the partition is colored blue, and the other
side is colored red. Notice that for these graphs, Dirichlet
spectral clustering separates red and blue nodes much better
than traditional spectral clustering as expected.

It is clear that using Dirichlet eigenvalues improves the
partition by ignoring the boundary, alleviating the tendency
to ﬁnd “bags of whiskers” without drastically changing the
Cheeger ratio. Although traditional spectral clustering does
not always fail, there is clear evidence that Dirichlet spectral
properties are an important tool in the analysis of real-world
networks.

5. DISCUSSION

Our results show evidence that eigenvalues of the nor-
malized graph Laplacian can provide rich information about

real-world networks when Dirichlet boundary conditions are
applied. We ﬁnd that the Dirichlet spectral gap computed
for several IP-layer networks is much larger than the tradi-
tional spectral gap, and is likely to go to a ﬁnite limit as
the size of the network is increased. Rigorous analysis for
inﬁnite d-regular trees suggests that this may be the same
as the spectral gap of a communication network that is a
smaller section of something much larger. Spectral cluster-
ing using Dirichlet eigenvalues yields much better clustering
than traditional methods.

The spectral decomposition using Dirichlet eigenvalues
also suggests a connection to large-scale negative curvature
[10, 11, 14] in the Rocketfuel data. Traditional negatively
curved graphs such as trees and hyperbolic grids generally
exhibit poor connectivity and core congestion. Standard
clustering often yields combinations of smaller cuts near the
periphery of the graph, but using Dirichlet clustering, we
can see that there tend to be bad larger-scale cuts as well in
the Rocketfuel datasets, in the graph interior. The presence
of these larger-scale cuts is a hallmark of negative curvature
or hyperbolicity [8], suggesting that Dirichlet spectral clus-
tering may yield diﬀerent behavior for hyperbolic and ﬂat
networks. The hyperbolic grids themselves are also suitable
for further analysis, building from our study of regular trees.
Many properties such as the spectral gap remain open ques-
tions.

With some evidence of a connection between global nega-
tive curvature, the spectral gap, and expansion, it would be
interesting to empirically compare the hyperbolicity δ, the
Cheeger constant h, and the traditional and Dirichlet spec-
tral gaps of Rocketfuel and other real-world networks as well
as well-known network models. From this, it could be pos-
sible to classify various networks based on these properties.

6. ACKNOWLEDGMENTS

This work was performed during an internship of A.T.
at Bell Labs, Murray Hill, New Jersey and was supported
by AFOSR Grants Nos. FA9550-08-1-0064 (for O.N., as a
consultant with Bell Labs) and FA9550-11-1-0278.

7. REFERENCES
[1] R. Andersen, F. Chung, and K. Lang. Local graph

partitioning using PageRank vectors. In Proc. IEEE
Symposium on Foundations of Computer Science
(FOCS’06), pages 475–486, Berkeley, California, Oct.
2006.

[2] A.-L. Barab´asi and R. Albert. Emergence of scaling in

random networks. Science, 286(5439):509–512, Oct.
1999.

[3] F. Chung. Spectral Graph Theory. AMS Press,

Providence, RI, 1997.

[4] F. Chung. Random walks and local cuts in graphs.

Linear Algebra Appl., 423(1):22–32, May 2007.

[5] F. Chung, A. Tsiatas, and W. Xu. Dirichlet PageRank

and trust-based ranking algorithms. In Proc.
Workshop on Algorithms and Models for the Web
Graph (WAW’11), pages 103–114, Atlanta, Georgia,
May 2011.

[6] P. Erd¨os and A. R´enyi. On the evolution of random
graphs. Publ. Math. Inst. Hung. Acad. Sci., Ser. A,
5:17–61, 1960.

1302Table 2: Average Cheeger ratios (h) and number of components (c) for Dirichlet and traditional spectral
clustering of several Rocketfuel datasets. Extreme values are visible in Fig. 5.

cD ≤ cT
hD ≤ hT

cD ≤ cT
hD > hT

Number of cuts in each category:

cD > cT
hD ≤ hT

cD > cT
hD > hT

49
538
32
224
49
182
24
15
111
157

197
362
91
819
67
315
137

6

199
465

0
0
0
0
0
3
3
0
0
12

6
30
14
323
35
41
129

6
73
273

Dataset

1221
1239
1755
2914
3257
3356
3967
4755
6461
7018

Avg
cD − cT
-28.9
-75.1
-4.5
-107.3
-12.3
-34.6
-3.2
-12.3
-13.4
-54.3

Avg
hD − hT
0.0506
0.0127
0.0545
0.0565
0.0370
0.0388
0.1423
-0.0970
0.0148
0.0403

Avg
cT
36.8
83.4
7.9
125.8
20.0
45.6
9.2
15.4
19.7
81.4

Avg
hT
0.0829
0.1326
0.1210
0.1639
0.1386
0.1895
0.1215
0.3460
0.0999
0.0735

[7] J. Friedman. The spectra of inﬁnite hypertrees. SIAM

[14] O. Narayan and I. Saniee. Large-scale curvature of

J. Comput., 20(5):951–961, Oct. 1991.

networks. Phys. Rev. E, 84(6), Dec. 2011.

[8] M. Gromov. Hyperbolic groups. In S. Gersten, editor,
Essays in Group Theory, pages 75–263. Springer, New
York, 1987.

[9] O. H¨aggstr¨om, J. Jonasson, and R. Lyons. Explicit
isoperimetric constants and phase transitions in the
random-cluster model. Ann. Probab., 30(1):443–473,
Jan. 2002.

[15] A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral

clustering: Analysis and an algorithm. In Advances in
Neural Information Processing Systems (NIPS’02),
pages 849–856, Vancouver, Canada, Dec. 2002.

[16] S. E. Schaeﬀer. Graph clustering. Computer Science

Review, 1(1):27–64, Aug. 2007.

[17] J. Shi and J. Malik. Normalized cuts and image

[10] E. Jonckheere, P. Lohsoonthorn, and F. Bonahon.

segmentation. 22(8):888–905, Aug. 2000.

Scaled Gromov hyperbolic graphs. J. Graph Theory,
30(2):157–180, Feb. 2008.

[11] E. Jonckheere, M. Lou, F. Bonahon, and

Y. Baryshnikov. Euclidean versus hyperbolic
congestion in idealized versus experimental networks.
Internet Math., 7(1):1–27, 2011.

[12] J. Leskovec, K. Lang, A. Dasgupta, and M. W.

Mahoney. Statistical properties of community
structure in large social and information networks. In
Proc. International Conference on the World Wide
Web (WWW’08), pages 695–704, Beijing, China, Apr.
2008.

[13] B. D. McKay. The expected eigenvalue distribution of

a large regular graph. Linear Algebra Appl.,
40:203–216, Oct. 1981.

[18] N. Spring, R. Mahajan, and D. Wetherall. Measuring

ISP topologies with Rocketfuel. In Proc. ACM
SIGCOMM Conference (SIGCOMM’02), pages
133–145, Pittsburgh, Pennsylvania, Aug. 2002.
[19] R. Teixeira, K. Marzullo, S. Savage, and G. M.

Voelker. In search of path diversity in ISP networks.
In Proc. Internet Measurement Conference (IMC’03),
pages 313–318, Miami, Florida, Oct. 2003.

[20] U. von Luxburg. A tutorial on spectral clustering.

Statist. Comput., 17(4):395–416, Dec. 2007.

[21] D. Watts and S. Strogatz. Collective dynamics of
‘small-world’ networks. Nature, 393:440–442, June
1998.

1303(a) Dataset 1221

(b) Dataset 1755

(c) Dataset 3257

(d) Dataset 3356

(e) Dataset 3967

(f) Dataset 6461

Figure 5: Comparison of Cheeger ratio h and number of components c for cuts for various datasets using
Dirichlet (D) and traditional (T ) spectral clustering. Each point represents one possible cut size; in general,
Dirichlet clustering yields many fewer components without sacriﬁcing much in Cheeger ratio.

1304Figure 6: Partition of Rocketfuel dataset 3356 using standard (left) and Dirichlet (right) spectral clustering.

Figure 7: Partition of Rocketfuel dataset 1755 using standard (left) and Dirichlet (right) spectral clustering.

1305