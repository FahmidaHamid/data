Whom to Mention: Expand the Diffusion of Tweets by

@ Recommendation on Micro-blogging Systems

Beidou Wang†, Can Wang†, Jiajun Bu†, Chun Chen†, Wei Vivian Zhang(cid:2), Deng Cai‡, Xiaofei He‡
†Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University, China

(cid:2)Microsoft Corporation, Redmond, WA, USA

‡State Key Lab of CAD&CG, College of Computer Science, Zhejiang University, China

†{beidou,wcan,bjj,chenc}@zju.edu.cn, (cid:2)wzha@microsoft.com,

‡{dengcai,xiaofeihe}@cad.zju.edu.cn

ABSTRACT
Nowadays, micro-blogging systems like Twitter have become
one of the most important ways for information sharing. In
Twitter, a user posts a message (tweet) and the others can
forward the message (retweet). Mention is a new feature in
micro-blogging systems. By mentioning users in a tweet,
they will receive notiﬁcations and their possible retweets
may help to initiate large cascade diﬀusion of the tweet.
To enhance a tweet’s diﬀusion by ﬁnding the right persons
to mention, we propose in this paper a novel recommenda-
tion scheme named as whom-to-mention. Speciﬁcally, we
present an in-depth study of mention mechanism and pro-
pose a recommendation scheme to solve the essential ques-
tion of whom to mention in a tweet. In this paper, whom-to-
mention is formulated as a ranking problem and we try to
address several new challenges which are not well studied in
the traditional information retrieval tasks. By adopting fea-
tures including user interest match, content-dependent user
relationship and user inﬂuence, a machine learned ranking
function is trained based on newly deﬁned information dif-
fusion based relevance. The extensive evaluation using data
gathered from real users demonstrates the advantage of our
proposed algorithm compared with the traditional recom-
mendation methods.

Categories and Subject Descriptors
H.3.5 [Online Information Services]: Web-based services

General Terms
Theory

Keywords
Micro-blogging Systems; Twitter; Mention; Recommenda-
tion; Information Diﬀusion; Information Retrieval

1.

INTRODUCTION

With more than 140 million active users and over 340 mil-
lion messages posted per day, Twitter has become one of the
most inﬂuential media for spreading and sharing breaking

Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW 2013, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

news, personal updates and spontaneous ideas.
In Micro-
blogging systems like Twitter, users tweet about any top-
ics within the 140-character limit and follow others to re-
ceive their tweets. Furthermore, with retweeting (forward
a tweet), information can be eﬀectively relayed beyond ad-
jacent neighbors, virtually giving every user the power to
spread information broadly.

However, recent studies [2][31][37] show that the diﬀusion
power of tweets from diﬀerent users varies signiﬁcantly: 0.05
percent of Twitter users attract almost 50 percent of all
attention within Twitter and the spread of a tweet from
an ordinary user is rather limited, with an average retweet
rate of 0.11. This suggests a very limited diﬀusion for most
tweets.

Fortunately, as a new feature in Micro-blogging systems,
Mention can help ordinary users to improve the visibility
of their tweets and go beyond their immediate reach in so-
cial interactions. Mention is enabled in a tweet by adding
”@username”. All the users mentioned by a tweet will re-
ceive a mention notiﬁcation (e.g. by an e-mail ) and are
able to retrieve the tweet from their personal mention tab.
By using Mention, one can draw attention from a speciﬁc
user, or highlight a place or organization anytime. Properly
using mention can quickly help an ordinary user spreading
his tweets:

1. By mentioning a non-follower of the tweet author, the
non-follower may retweet it to his followers and spread
the tweet to a new group of users, which usually leads
to further cascade diﬀusion.

2. By mentioning a follower of the author, the mention
serves as a useful notiﬁcation, especially when the fol-
lower follows a large number of other users and a tweet
can be easily swamped in the enormous number of
tweets. It’s also critical for a tweet to be viewed prompt-
ly as 25% replies to a tweet happen within 67 seconds,
75% within 17 minutes and 75% message ﬂow lasts less
than an hour [35]. So, without proper notiﬁcation, a
tweet may easily be neglected as one’s followers fail to
read it in time.

Despite the signiﬁcance of the mention feature, to the best of
our knowledge, Mention Recommendation is seldom studied
in previous works. To better help an ordinary user spreading
their thought in Micro-blogging systems, we propose in this
paper a novel Mention Recommendation algorithm named
whom-to-mention, in which we help a tweet to reach more

1331people by recommending proper users to be mentioned be-
fore publishing it.

The recommendation task can be formulated as a rank-
ing problem. Traditionally, one can rank users based on the
similarity between a tweet and a user’s proﬁle (e.g. the ag-
gregation of all the tweets posted by a user) and recommend
the top ranked users to be mentioned. However, there are
several challenges which make the traditional recommenda-
tion methods fail:

Information Diﬀusion Based Relevance: In classic in-
formation retrieval tasks (e.g. TREC adhoc retrieval
tasks), relevance is usually interpreted as topical rel-
evance, which stands for to what extent the topic of
a result matches the topic of the query. However, the
goal of mention recommendation is to ﬁnd candidates
who can help spread a tweet. Instead of topical rele-
vance, the information diﬀusion power should be con-
sidered in the relevance judgement.

Content-dependent User Relationship Model: In tra-
ditional social network recommendation, user relation-
ship is usually modeled as a weighted graph with edges
indicating the bonds between two users based on ex-
plicit social relationship. The interactive functions
(e.g. retweet, reply, mention) in micro-blogging sys-
tems allow us to adopt the implicit network derived
from user’s interactive behaviors to achieve more pre-
cise user relationship predictions. Moreover, it brings
in new features for modeling user relationship, as users’
interactions are usually content (topic) related, which
makes the user relationship model content-dependent.
For instance, a user may selectively retweet sport news
from another user while ignoring other contents such
as movie comments from the same user. Modeling the
content-dependent user relationship based on the im-
plicit network of user interactions thus remains as a
challenge.

Recommendation Length Restriction: Due to the stric-
t length restriction of a tweet, only a small number
of users can be mentioned in a tweet. Moreover, a
tweet mentioning a lot of users is likely to be treated
as a spam tweet, which will decrease others’ interest in
retweeting it. Thus, to accomplish the mention recom-
mendation task, the algorithm needs to be optimized
for mentioning only a small number of users.

Recommendation Overload Problem: Traditional rec-
ommendation systems such as those used in Amazon
may recommend one item to large numbers of users,
which results in popular products. However, in the
mention recommendation system, a user being recom-
mended too many times will suﬀer from the severe
mention overload problems. Tons of mention notiﬁ-
cations will not only interrupt user‘s daily use of mi-
croblogs, but also result in frustration and decrease
user’s interest in retweeting.

To cope with all the above mentioned challenges, whom-
to-mention is proposed in this paper. We use a machine
learning approach to train a ranking model which consists
of three parts: ranking features, relevance and a ranking
function [10]:

We adopt a series of new features to deliver more precise
mention recommendation, including: the match of the given
tweet and interest proﬁles of the recommended users, the
user relationship between the recommended users and the
author of the tweet, and the inﬂuence of the recommended
users. Furthermore, we manage to model user relationship
based on the implicit network derived from user retweet in-
teractions, which we name as user social ties model. We
take advantage of the content-dependent feature of user so-
cial ties and make use of the content feature of the tweets
one user has retweeted from another in a user social tie.

Instead of the classic topical relevance model, the rele-
vance in whom-to-mention is redeﬁned as the potential d-
iﬀusion a user may bring to a tweet, estimating by the ex-
pectation user coverage, which will be further explained in
section 4.2.

A Support Vector Regression (SVR) based ranking func-
tion is then trained to calculate the relevance of a candidate
user to a tweet and ranks the most relevant candidates on
the top of the recommendation list. Constraints are carefully
designed in the ranking process to avoid the recommenda-
tion overload problem.

It is worthwhile to highlight the following three aspect-
s of our whom-to-mention recommendation scheme in this
paper.

1. We present the ﬁrst in-depth study of mention fea-
ture in microblogs by resolving the most essential prob-
lem of whom to mention. Instead of passively waiting
to be retweeted by others, our novel recommendation
scheme allows users to improve the diﬀusion of their
tweets by reaching out to the right person with the
help of mention recommendation.

2. We formulate the mention recommendation as a rank-
ing problem and to ﬁnd the most proper users to be
mentioned, a ranking function is learned with a nov-
el information diﬀusion based relevance, incorporating
with new features including user interest match, user
social ties and user inﬂuence. We model user rela-
tionship based on the implicit network derived from
user’s retweet interactions and take fully exploit of its
content-dependent features.

3. Our method is thoroughly evaluated on a real life dataset.

Whom-to-mention algorithm is proved highly eﬀective
compared against a large number of baselines. We an-
alyze how diﬀerent features aﬀect the recommenda-
tion performance with aborative designed comparison
experiment. New issues like recommendation length
restriction and recommendation overload problem is
careful evaluated and discussed.

2. RELATED WORK

2.1 Recommendation Approaches

Using information retrieval approaches to recommend doc-
uments, users or items has been a fertile area of research.
Content-based recommendation systems like [25][27], recom-
mend items similar to those that a user liked in the past.
Though the use of information retrieval on recommendation
has been studied for a long time, new studies keep emerging
to solve all kinds of new challenges [33]. For instance, Diaz
et al. make the ﬁrst in-depth study of information retrieval

1332approaches applied to match-making systems and study u-
nique problems like two-sided and subjective relevance[10].
In our work, the information diﬀusion based relevance, new
features like user social ties , new challenges like the recom-
mendation length restriction and overload problem all make
our whom-to-mention diﬀerent from previous information
retrieval approaches.

Most of the prior work on social network recommenda-
tion mainly focuses on recommending interesting users or
contents [11]. Hsu et al. address the problem of link recom-
mendation in weblogs and similar social networks by propos-
ing an approach based on collaborative recommendation us-
ing the link structure of a social network and content-based
recommendation using mutual declared interests [17]. Chen
et al. study people recommendations designed to help users
ﬁnd known, oﬄine contacts and discover new friends on so-
cial networking sites [7]. Guy et al. study personalized rec-
ommendation of social software items and make a compari-
son between recommendations that are based on the user’s
familiarity network and his similarity network[13]. None of
previous works can be directly applied to whom-to-mention
task and solve all the new challenges.

2.2 Learning to Rank

Learning to rank has been a popular research area. Exist-
ing approaches can be roughly divided into three categories:
pointwise approaches[21][26] in which the learning-to-rank
problem can be approximated by predicting the score of a
single query-document pair and various regression and or-
dinal regression algorithms can be adopted in this kind of
approaches; pairwise approaches [4][5], in which the ranking
problem is reduced to pairwise classiﬁcation and the goal
is to minimize average number of inversions in ranking; list-
wise approaches [28][36], in which the value of the evaluation
measures is optimized directly, averaged over all queries in
the training data. The ranking algorithm from our work
belongs to the pointwise approaches.

2.3 Studies on Micro-blogging Systems

With the launch of Twitter in 2007, microblogs become
highly popular and large numbers of researches have been
done. Our research is involved with structure and user rela-
tionship analysis of microblogs, user interest modeling, rec-
ommendation, information diﬀusion and inﬂuential users i-
dentiﬁcation on micro-blogging systems.

The characteristics of network structure and user rela-
tionship of microblogs have attracted much attention in the
past few years. Kwak et al. make the ﬁrst quantitative s-
tudy on the information diﬀusion on Twitter by studying
the topological characteristics of Twitter and provide lots of
statistic details of Twitter[20]. Besides the network based
on user’s explicit following network of Twitter, analysis of
the users’ interactions in the implicit network of Twitter
has been an emerging area [30][18]. Sousa et al. analyze
replies of a speciﬁc Twitter dataset and a slight tendency
for people selectively choosing whom to reply based on the
topic of the tweets is found [30]. Jang et al. propose an
egocentric semantic social network based on user reply in-
teractions on Twitter, but the strength of user relationship
is not considered and user bonds from diﬀerent user pairs
are incomparable[18].

A lot of works have been done on user interest model-
ing, Michelson et al. discover users’ topics of Twitter by

categorizing the entities in the tweets and developing a us-
er proﬁle by adopting the categorization result[23]. Hong
et al. evaluate how the restricted length of the tweets can
limit the potential of traditional topic models and the au-
thors also show that training a topic model on aggregated
messages can help to signiﬁcantly enhance the experiment
performance[16].

Information diﬀusion and inﬂuential user identiﬁcation on
Twitter have been extensively studied. Ye et al. ﬁrst explore
the propagation patterns of general messages on Twitter and
how to measure social inﬂuence on Twitter [35]. Bakshy et
al. study the attributes most relevant to the inﬂuence of
Twitter users [3]. Cha et al. make an in-depth comparison
of three measures of inﬂuence: indegree, retweets, and men-
tions and investigate the dynamics of user inﬂuence across
topics and time [6]. Bakshy et al. ﬁnd that predictions of
which particular user will generate large cascades are rel-
atively unreliable and word-of-mouth diﬀusion can only be
harnessed reliably by targeting large numbers of potential
inﬂuencers [2]. Romero et al. model the global inﬂuence of
a node on the rate of diﬀusion through the network based
on a Linear Inﬂuence Model [34].

Several researches have focused on recommending who to
follow or what to read on Twitter. Hannon et al. recom-
mend Twitter users to follow using content and collaborative
ﬁltering approaches [15] and Chen et al. recommend interest-
ing content from information streams on Twitter considering
features including content sources, topic interest models for
users, and social voting [8]. To the best of our knowledge,
recommendation on whom to mention in Twitter has never
been studied in previous work.

3. PROBLEM DEFINITION

We formalize whom-to-mention into a retrieval scenario
consisting of a set of users, U , each of whom maintains a user
interest proﬁle and a user inﬂuence proﬁle. For a user u ∈
U , a user interest proﬁle ru, consists of a set of descriptive
attributes and tf-idf features extracted from a modiﬁed bag
of words model used on u’s recent tweets. A user inﬂuence
proﬁle su is made up of attributes related to user’s inﬂuence
on Twitter. For users u, v ∈ U , there exists a social tie
tieu,v based on the retweeting interactions between u and
v, which includes a scalar attribute indicating the strength
of bonds between u and v and tf-idf features extracted from
the tweets u retweets from v. A query q consists of tf-idf
features extracted from a speciﬁc tweet.
For each query (tweet) q from user u, we would like to rank
all the other users v ∈ U −u based on features including user
interest match, user social ties and user’s inﬂuence, so that
the relevant candidates occur above non-relevant candidates.

4. RECOMMENDING WHOM TO MENTION

BY LEARNING A RANKING MODEL

The key of whom-to-mention is to rank the candidate user-
s given a speciﬁc tweet and we use a machine learning ap-
proach to train a ranking model for our recommendation
task, which is made up of three parts: ranking features, rel-
evance and a ranking function[10]. Ranking features include
all the attributes which may inﬂuence the score of a candi-
date match. Based on our recommendation task, relevance
refers to the potential diﬀusion a user could bring to a spe-
ciﬁc tweet. A ranking function is a machine learning model

1333which predicts the relevance given observable ranking fea-
tures. We will discuss the details of the three parts in this
section.

4.1 Ranking Features

4.1.1 User Interest Match

The match of a tweet and the candidate’s interest is an
intuitively important feature for whom-to-mention. When
mentioning a candidate in a tweet, a candidate interested in
it is more likely to retweet it.

To calculate the match, the largest challenge is to gener-
ate the user interest model on micro-blogging systems, which
diﬀers from traditional user interest models because users’
tweets are limited to only 140 characters in length, cover-
ing a wide variety of topics, as well as often presented with
shorthands and special formats such as hash tags. Moreover,
the nature of our recommendation task requires capturing
more detailed aspects of interest. For instance, a footbal-
l fan may be assumed interested in sports based on topic
modeling technics like LDA. However, it is not a good inter-
est match, if we mention the football fan in a tweet talking
about a basketball match (because the tweet is also con-
sidered talking about sports, which makes a match for the
tweet and the candidate).

Based on previous studies [16] , topic modeling techniques
like LDA may not ﬁt the short-length, ambiguous, noisy data
feature in Twitter. Consequently, we use a modiﬁed bag-of-
words model to generate the user interest model.

To begin with, we aggregate a user’s recent tweets. For
a candidate user u, we deﬁne du as the set of recent tweets
for u; in this work, we will assume that du is u’s 1000 most
recent tweets. We also extract the words from the hash
tag topics, which we name as hu and they are important
because they are usually used to identify a topic or an event.
Besides the tweets, we also consider all the attributes from
the user proﬁle page, including user’s full name, the location,
a short biography and tags. For a user u, we choose the short
biography feature fu and tag feature tagu for the interest
modeling. A user interest proﬁle ru is then deﬁned as ru =
{du, hu, fu, tagu} and R = {ru|u ∈ U}.
In this way, R
provides us the basis for user interest modeling.

To cope with the short noisy text , we ﬁrst analyze around
50,000 hot short queries (popular words or phrases) based
on a latest search engine query log covering a lot of new
words and words in short-hand format and we denote these
words as Dict. In this way, popular phrase like ”Big Bang
Theory” is considered as a word in Dict. We ﬁlter the text
in R, eliminating all the stop words, only keeping a word if
it’s either identiﬁed as a noun or a word from Dict.

The name entity recognition for tweets is conducted with
the help of ICTCLAS 1 (a toolkit used for word split and
name entity recognition) and the query log is provided by
Sogou 2 (a leading search engine company in China).

Given a query (tweet) qu from user u, we apply the same
word parsing strategy as mentioned above and represent qu
and R as tf.idf-based term vectors, which are further used to
estimate the user interest match. With the help of Lucene,
a proven, robust and scalable indexing and retrieval platfor-

1

2

http://ictclas.org/
http://www.sogou.com/labs/dl/w.html

m, the match score between a query qu and a user interest
proﬁle rv can thus be deﬁned as:

iscore(qu, rv) = coord(qu, rv) · queryN orm(qu)·

(tf (t ∈ rv) · idf (t)

2 · norm(t, rv))

(cid:2)

t∈qu

The tf (t ∈ rv) correlates to the term’s frequency :

tf (t ∈ rv) =

√

nt,rv

(1)

(2)

where nt,rv is the frequency of term t in rv and normalization
of the document length is deﬁned in norm(t, rv) for eﬃciency
consideration.

idf (t) stands for the Inverse Documentary Frequency de-

ﬁned as:

idf (t) = 1 + log(

|R|

|r : t ∈ r| )

norm(t, rv) is a normalization factor deﬁned as:
norm(t, rv) = lengthN orm(rv) · boost(t)

(3)

(4)

where lengthN orm is a length normalization factor which
ensures short document contributes more to the score. We
also consider boost factors that terms from diﬀerent sources
own diﬀerent weights (e.g. a term from tagu is more impor-
tant than one from du). According to evaluation on training
data, we set the boost boost(t) as:

(cid:3)

boost(t) =

2
1

if t ∈ hu, fu, tagu
if t /∈ hu, fu, tagu

(5)

coord(qu, rv) is a score factor based on how many query
terms are found in document rv and queryN orm(q) is a
normalization factor used to make scores between queries
comparable. They are implemented using Lucene’s function
which details can be found here 3.

4.1.2 User Social Tie Modeling

User relationship plays an important role in whom-to-

mention task, an acquaintance is usually more likely to retweet
compared with a total stranger. Previous studies [20][19]
mainly study explicit social connections based on the fol-
low relationship of Twitter. However, according to a study
of Facebook [1], people only communicate with a few of
their explicit declared friends. So modeling user relationship
based on some implicit networks can be better indicators of
the actual social relationships between users.

In our work, user relationship model is based on implicit
connections derived from users’ retweet activities in micro-
blogging systems, which we name as user social tie model.
Though lots of work on retweet behaviors have been done,
they are usually in the information diﬀusion perspective in-
stead of modeling user relationships [2][3][6].

We make two assumptions in modeling user social ties.
First, user social ties can be derived from the retweet inter-
actions between two users and frequency of interaction can
be used to quantify the strength of a social tie. Second, the
social tie between two users is content-dependent. Thus in
our model, a user social tie consists of three parts: nodes

3

http://lucene.apache.org/core/old_versioned_docs/

versions/3_0_0/api/core/org/apache/lucene/search/
Similarity.html

1334Table 1: Statistical Indicators on Modeling User Inﬂuence

Denotation
Follower(u)

(6)

(7)

Avg retweet(u)

Avg reply(u)

Avg coverage(u)

Explanation
The number of followers of user u, one of
the most popular metrics on estimating a
user’s inﬂuence.
The average number of retweets for each
tweet from u.
The average number of replies for each
tweet from u.
The average number of users a tweet from
u can reach. The coverage of a tweet is
deﬁned in details in section 4.2.

including the two users of a tie, a strength score indicating
how strong two users are bonded in a tie and a content vec-
tor indicating topics the user interested in retweeting. The
details are explained as follows.

For users u, v ∈ U , we deﬁne tweet set rtu,v as:

rtu,v = {tw|tw is a tweet u retweets from v}

We deﬁne the social tie strength as stru,v

stru,v = |rtu,v|

We ﬁlter rtu,v with the same method mentioned in section

4.1.1 and deﬁne user social tie between user u and v as:

tieu,v = {rtu,v, stru,v}

(8)
It is important to notice that tieu,v (cid:4)= tiev,u. Given a
query qu from user u, we can calculate the user relationship
score by multiplying the strength of the social tie with the
similarity between qu and rtu,v:
tscore(qu, rtu,v) = stru,v · coord(qu, rtu,v) · queryN orm(qu)

·

(tf (t ∈ rtu,v) · idf (t)

2 · norm(t, rtu,v))

(cid:2)

t∈qu

(9)

All the factors in formula (9) are deﬁned the same as in

formula (1).

4.1.3 User Inﬂuence Modeling

Intuitvely, user inﬂuence is also important to the perfor-
mance of our recommendation task. If two users are both
likely to retweet the tweet, the more inﬂuential one could
help it reach more people by initiating a larger cascade of
retweet. Given a user u, we summarize a series of statistical
indicators which may indicate his inﬂuence in Tabel 1.

We can deﬁne u’s inﬂuence proﬁle su as:
su = {Follower(u),Avg retweet(u),

Avg reply(u), Avg coverage(u)}

(10)

4.2 Relevance

In traditional text retrieval tasks (e.g. search engine re-
trieval tasks), relevance always refers to the topical match
between the query and the document[10]. When interpret-
ed in this way, we can always rely on editors to manually
assess the relevance based on their experience and exper-
tise. However, when it comes to our recommendation task,
editors have to compare a query (tweet) with user proﬁles
made up of thousands of tweets and analyze hundreds of
content-based user relationship bonds, which makes the pro-
cess time-consuming and result inaccurate.

Instead, we can calculate the relevance based on user be-
havioral information. Our recommendation scheme aims to
spread a tweet to more people by mentioning proper users in
it. So we can deﬁne the relevance between a query (tweet)
and a user as the diﬀusion the user brings to it. Intuitively,
the diﬀusion can be easily estimated by how many retweets a
user initiates by retweeting the tweet. However, for ordinary
users, the retweet cascades of their tweets are usually very
small. For instance, given a tweet, if one user can results
in 3 retweets each by a user with 100 followers and another
user brings it 2 retweets each by a user with 1000 followers,
the latter user obviously helps it to reach more people (2000

vs. 300). Thus, it’s more accurate to estimate the relevance
based on the number of users a candidate helps the tweet to
reach, which we name as coverage. We denote the relevance
of query q and user v as rel(q, v) and deﬁne it as:

(cid:2)
u ∈ the retweet cascades initiate by v} (11)

rel(q, v) = {

Follower(u)|

4.3 Ranking Function

Many machine learning models can be used as a rank-
ing function for our whom-to-mention recommendation task.
We adopt a machine learned ranking function based on sup-
port vector regression (SVR) , because it is a sophisticated
proven regression algorithm which is adaptive to complex
systems, robust in dealing with corrupted data and with a
good generalization ability [32].

Given a query qu from user u and a candidate match v,
we use SVR to compute a score to serve as the relevance
rel(qu, v). We deﬁne xqu,v as the feature vector correspond-
ing to the pair (qu, v).

xqu,v = {iscore(qu, rv), tscore(qu, rtv), sv}

(12)
The set of training data is as {(x1, y1), ..., (xn, yn)}, where
xi ⊂ Rm stands for the feature vector for a pair of query and
candidate in which m is the number of feature dimensions,
and yi ⊂ R stands for the corresponding relevance value.
A generic SVR estimating function is with the form as:

f (x) = (w · φ(x)) + b

(13)
w ⊂ Rm,b ⊂ R and φ stands for a nonlinear transforma-
tion from Rm to high-dimensional space. The core goal of
SVR is to learn the value of w and b to minimize risk of
regression.

1
2

L(f (xi) − yi) +

||w||2

i=0

Risk(f ) = C

(14)
L(·) is a loss function and C is a constant used to de-
termine penalties to estimation errors which is determined
with grids search and cross-validation techniques. We ex-
periment the performance of diﬀerent kernel functions and
choose kernel function with best performance (RBF kernel).
Details of SVR can be found in [29].
4.4 Recommendation Overload Problem

One new issue of our whom-to-mention task is that the
recommendation may concentrate on a few popular users,
which causes mention overload (users get too many mention
notiﬁcations from the recommendation system). Moreover,
diﬀerent users may respond diﬀerently to the overload. For

n(cid:2)

1335instance, some users may not want to receive any mention
notiﬁcation from the recommender at all, while some others
may feel okay even if mentioned 100 times in a day.

In our recommendation framework, we carefully cope with
this problem by allowing users to freely set an up-limit of
recommended times per day. After ranking phase, all the
candidates with recommended times up-limit reached are e-
liminated and the top k of the remaining candidates are then
recommended.
In real application, within a day, our rec-
ommendation scheme follows a ﬁrst publish, ﬁrst to choose
policy and recommend the next best candidate once a user’s
recommendation up-limit is reached.

In our evaluation, since our test tweets are published over
a period of time, we set the up-limit for mentioning at 25,
which as a matter of fact, is a quite strict constraint.

5. EXPERIMENT SETTING

We design the experiment with 4 goals:(1) To evaluate
how our proposed algorithm performs compared with oth-
er base-line algorithms;(2)To test how diﬀerent features we
considered aﬀect the recommendation performance;(3) To
examine how diﬀerent ranking functions aﬀect the result-
s;(4) To consider how new challenges like the recommenda-
tion length restriction and recommendation overload aﬀect
the performance of our algorithm.

The key challenge of the experiment design lies in evalu-
ating the information diﬀusion (coverage of users) resulted
by mentioning a user in a tweet. Instead, we make an ap-
proximate estimation using the user’s retweet behavior. For
example, if user A retweets a tweet t and helps t reach 500
people, it’s reasonable to assume that A will retweet it if we
mention A in t. So in our evaluation, by mentioning A in t,
the user coverage A brings to t is 500. If user B has never
retweeted t, we assume B will not retweet t when mention-
ing him in t and the user coverage B brings to t thus is
considered to be 0.

5.1 Data Collection

We collected data from Sina Weibo, a Twitter-like micro-
blogging system in China with more than 400 million reg-
istered users and over 100 million messages posted per day.
Diﬀerent from Twitter’s API, which is restricted in retriev-
ing mention and retweet timelines, Weibo’s API allows us to
get all the tweets from a user’s diﬀerent timelines. Moreover,
we obtained authorizations from over 5000 real Weibo users,
who grant us full access to all the authentication-protected
user data, including user proﬁles, tweets, the retweet time-
line, the reply and mention timeline, and accurate reply and
retweet number for each tweet. We parse 48,000 tweets pub-
lished by the authorized users, only keeping tweets being
retweeted more than 5 times, which leaves us 132,796 retweet
records and 7800 tweets to serve as the training and testing
tweets.

Based on the retweet records, 52,468 users participate in
retweeting and are considered as our recommendation can-
didates. We collect the most recent 1000 tweets from these
users (around 46 million in total) and record their personal
information including the full name, the location, user biog-
raphy etc. Average retweet rate and relpy rate for each user
are calculated based on the most recent 200 tweets (around
11 million in total). 97,164 user social ties are established
based on retweet interactions. In our experiment, we split

the parsed tweets into training and testing data set with an
80/20 proportion and cross-validation is used.

5.2 Evaluation Metrics

We evaluate the results using both standard information
retrieval metrics[14][9] and metrics featuring on measuring
information propogation[35]. In particular, we use the fol-
lowing metrics: precision (P ), average precision at K (AP @K),
retweet times (RT ), user coverage (Cov) and normalized us-
er coverage (Cov N ), which are deﬁned as,

P =

Nhit
m

(cid:4)K

i=1(P (i))
Nhit

AP @K =

|t| |t ∈ Tt,u}

(cid:2)
RT = {
(cid:2)
(cid:2)
u∈R
f ollower(v)|v ∈ Ut,u}
(cid:2)
(cid:2)

Cov = {

u∈R
Cov N = {arctan(

(f ollower(v)))|v ∈ Ut,u}

u∈R

(15)

(16)

(17)

(18)

(19)

where m is the size of the recommendation list, Nhit is
the number of users in the recommendation list belonging
to the top m relevant matches and P (k) means the precision
at cut-oﬀ k in the recommendation list. For a user u, a tweet
t and the recommendation list R, we deﬁne Tt,u as all the
retweets from the retweet cascades initiated by u retweeting
t and Ut,u as all the users from the retweet cascades initiated
by u retweeting t.

Retweet times stands for the number of hops in a tweet
propagation and each hop increases the chance for the tweet
to reach more users. User coverage is a more intuitional
metric which is the cumulative number of users that a tweet
has reached due to the mention recommendation.
In the
normalized user coverage, we normalize the coverage with
an arctan() function, to make the coverage number from
diﬀerent algorithms more comparable.

Due to the length restriction, only a limited number of
users can be mentioned in a tweet and thus we set the length
of recommendation list as 5 in our evaluations. We also test
how the algorithm performs when we only recommend 1∼4
users to mention.
5.3 Comparison Algorithms

To the best of our knowledge, no previous studies have
been done on the whom-to-mention task. Though the task is
with lots of new challenges, we try our best to adapt several
classic recommendation algorithms to this new problem to
serve as baseline comparison algorithms.

• Content-based Recommendation (CR). A content based
recommendation algorithm similar to [12] is careful-
ly designed. User proﬁle are based on the content of
tweets and attributes from user proﬁle page. A spe-
ciﬁc tweet is considered as an item, illustrated by its
content. Both the user proﬁle and item are modeled as
tf.idf-based vectors and we recommend users by rank-
ing the cosine similarity scores of user proﬁle and item.

1336• Content-boosted Collaborative Filtering Recommen-
dation (CCFR). For our task, recommendation is con-
ducted before a tweet is published and there thus exist
no user interaction behaviors like retweet and reply to
serve as ratings, so the recommender is always in a
cold start state. We choose Content-boosted Collabo-
rative Filtering Recommendation[22] which copes with
the cold start problem of traditional Collaborative Fil-
tering. A tweet is viewed as an item and a candidate
is regarded as a user. When a new item (tweet) need-
s recommendation, we ﬁnd 5 most similar items from
training data based on content similarity and recom-
mend users by combining the recommendation results
from the similar items.

• Bonds-based Recommendation (BR). In BR, we rec-
ommend candidates to a tweet based on the social
bonds between candidates and the tweet author, which
means the closer a candidate is linked to the author,
the more likely he will be recommended. The social
bond is modeled based on users’ retweet interactions.
• Inﬂuence-based Recommendation (INFR). In INFR,
we recommend candidates based on their inﬂuence,
which is a linear combination of inﬂuence features men-
tioned in section 4.1.3. We try to recommend the most
inﬂuential users to mention given a tweet.

• Random Recommendation (RR). In RR, 5 users are
randomly chosen from the candidates to generate the
recommendation list.

• Whom-to-mention with diﬀerent Ranking function. To
evaluate how diﬀerent ranking functions aﬀect the rec-
ommendation result, we compare the performance of
WTM by using three diﬀerent ranking algorithms as
the ranking function,
including using Support Vec-
tor Regression (WTMSV R), using Linear Regression
(WTMLR) and using Gradient Boosted Decision Trees
[24](WTMGBDT ).

• Twitter and Weibo. Based on statistics from previ-
ous studies[2] [37], we get the average retweet rate and
coverage of a tweet in Twitter. With the help of the
data we collect for user inﬂuence modeling (11 million
tweets from Weibo), we calculate the average retweet
rate and coverage for a tweet from Weibo. These num-
bers show the general average diﬀusion of a tweet in a
Micro-blogging system.

6. RESULTS AND ANALYSIS

6.1 Algorithm Performance Evaluation

As shown in table 2 and ﬁgure 1, our whom-to-mention
approach (WTM) signiﬁcantly improves the diﬀusion of a
tweet in all the metrics. We draw the following conclusions
from these results.

First, Random Recommendation (RR) barely shows any
eﬀect, which makes it clear that simply mentioning some
users has little eﬀect in improving the diﬀusion of a tweet.
Second, the poor performance of Inﬂuence-based Recom-
mendation (INFR) is because inﬂuential users may be nei-
ther interested in the tweet, nor share any social ties with

0.2

0.15

0.1

0.05

0

 

3.5

3

2.5

2

1.5

1

0.5

0

 

 

 

WTM
CCFR
BR
CR
INFR
RR

WTM
CCFR
BR
CR
INFR
RR

Precision

AP@K

Retweet Times

Normalized Coverage

Figure 1: Performance Comparison of WTM and Baseline
Algorithms

the author. Moreover, mention notiﬁcations may be easily
neglected by the inﬂuential users since they usually receive
thousands of mention notiﬁcations per day. Third, Content-
based Recommendation (CR), although eﬀective, is not as
good as those based on user relationships like BR and C-
CFR; this is partly attributed to the noise and ambiguity
existing in the tweet-based user proﬁles and item proﬁles.
Fourth, the performance of Bonds-based Recommendation
(BR) shows users who share strong social ties with the au-
thor are more likely to help him retweet the tweet and it
is in accordance with our daily experience. Furthermore,
Content-boosted Collaborative Filtering Recommendation
(CCFR) shows the best performance in all of our comparison
algorithms, owing to both its adoption of sophisticated CF
recommendation scheme based on the implicit retweeting
interaction network and the incorporation of content-based
features during the recommendation.

Finally, our SVR based whom-to-mention recommenda-
tion (WTM) outperforms all the comparison algorithms.
Even comparing with CCFR, it shows 70% increase in pre-
cision, a 94% increase in AP @5, an 72% increase in retweet
rate and a 51% increase in normalized coverage of users.
Our algorithm beneﬁts from the exploitation of all the new
features, a careful design of relevance model and a rank-
ing function based on machine learning techniques. More-
over, our algorithms results in a 2821% and 389% increase of
retweet rate and a 338% and 523% increase of coverage com-
pared with an ordinary tweet from Twitter and Sina Weibo,

1337Table 2: Result Comparison of WTM and Baseline Algorithms

Precision

AP@5

Retweet Times

Normalized Coverage

WTM
0.1343
0.1005
3.1026
0.8525

CR

0.0309
0.0207
0.9395
0.2649

CCFR
0.079
0.0515
1.8058
0.5640

BR

0.0492
0.0416
1.1990
0.2349

INFR
0.0279
0.0178
1.0147
0.1969

RR

Twitter Weibo

1.47E-04
4.91E-05

0.0015
0.0023

-
-

-
-

0.110

0.798

-

-

Table 3: Comparison on How Diﬀerent Features Aﬀect the Performance of WTM

ALL

NO Interest No Inﬂuence No Ties No ContentInTie Twitter Weibo

Precision

AP@5

Retweet Times

Coverage

0.1342
0.1005
3.1026
3716

0.1328
0.0985
3.0559
3643

0.1319
0.1129
3.0359
3592

0.0658
0.0410
1.7540
2185

0.1171
0.0869
2.6770
3239

-
-

-
-

0.110
1100

0.798
711

which further conﬁrms the eﬀectiveness of our algorithm on
boosting the diﬀusion of a tweet.
6.2 Feature Importance Evaluation

To analyze how features used in our proposed algorithm
contribute to the learned model, we design this contrast ex-
periment by eliminating one feature at a time and observe
how the performance of our model changes. Furthermore,
since we assume user social ties in micro-blogging systems
are content-dependent, we design a contrast algorithm by
eliminating all the content information from our user social
ties, leaving only the number of interaction times to indicate
the strength of social ties. All the results are listed in Table
3.

We note that when eliminating user interest match score
(No Interest), AP @5 suﬀers from a 2.0% decline and the
coverage of users suﬀers from a 2.0% decline. Similar to user
interest, the coverage of users decreases 3.4% after exclud-
ing user inﬂuence features (No Inﬂuence) from our model.
When we eliminate the user social ties feature (No Ties),
the model suﬀers a 60% decline of AP @5 and a 41% decline
of coverage. This result is in accordance with the results in
section 6.1, which shows although user interest match and
user inﬂuence help to improve the recommendation result,
content-dependent user social ties play a much more signif-
icant role in the recommendation.
It’s worth noting that
AP@5 exhibits the best performance after eliminating the
inﬂuence features, indicating that not all inﬂuential user-
s are interested in the tweet and many pay little attention
to mentions since they may receive hundreds, or even thou-
sands per day. However, the inﬂuence features do help to
expand the retweet rate and user coverage because the in-
ﬂuence brought by inﬂuential users outweighs the precision
loss.

Furthermore, after removing all the content feature from
the social ties (No ContentInTie), a 14% decline in AP @5
and a 13% decline in coverage prove that content feature in
social ties plays an important part in the recommendation
and user social ties are content-dependent.
6.3 Ranking Function Evaluation

Various machine learning models can be used as ranking
functions for our task and we explore three most commonly
used ones. The result is listed in Table 4. We can see that
our SVR based model(WTMSV R) outperforms the linear re-
gression (WTMLR) and GBDT (WTMGBDT ) based models

Table 4: WTM with Diﬀerent Ranking Functions

WTMSV R WTMLR WTMGBDT

Precision

AP@5

Retweet Times

Normalized Coverage

0.1343
0.1005
3.1026
0.8525

0.0877
0.0613
2.2342
0.5837

0.0769
0.0492
0.8997
0.7986

Table 5: WTM and CCFR with 1 or 3 Users Recommended

Precision

AP@k (k=1 or 3)

Retweet Times

Normalized Coverage

WTM 1 CCFR 1 WTM 3 CCFR 3
0.0988
0.0988
1.1313
0.5003

0.1263
0.1021
2.3307
0.7224

0.0358
0.0368
0.4945
0.2569

0.0718
0.0509
1.2913
0.4587

1

0.8

0.6

0.4

0.2

0
 
5

WTM_Precision
WTM_Normalize_Coverage
CCFR_Precision
CCFR_Normalize_Coverage

4

3

2

The Number of Recommended Users

 

1

Figure 2: Results with Limited Recommended Users

and we attribute it to the kernel function feature used in
SVR which helps us to map the data from the input space
into a higher dimensional space.
6.4 Limited Recommended Users

The tweet-length limitation makes it hard to mention many
users at the same time and moreover, mention too many
users may results in the tweet looking suspicious as a spam
tweet. We choose to recommend 5 users in our evaluation

1338i

s
e
m
T
 
d
e
n
o
i
t
n
e
M

300

250

200

150

100

50

0
 
0

 

WTM
CCFR

50

100

150

200

Figure 3: Recommendation Density Comparison Between
WTM and CCFR (200 most recommended users)

because we believe 5 is the up-limit of mentioning users in
one tweet and in practice use, a user can choose a subset of
the 5 users to mention. We also test the performance of our
algorithm when only mention 1∼4 users in a tweet and com-
pares it with our best comparison algorithm CCFR, which
are shown in table 5 and ﬁgure 2.

Our algorithm outperforms CCFR based on all metrics.
For instance, when only mentioning one user, our algorith-
m shows a more than 200% remarkable improvement on all
the metrics. Furthermore, compared with CCFR, the per-
formance decline rate of our algorithm is much less than
CCFR’s when reducing the number of recommended users.
For instance based on normalized coverage user metric, the
average decline rate of our WTM is 31%, while the average
decline rate of CCFR is 51%, which conﬁrms our WTM per-
forms much better when only a few users are recommended.
The precision drops slightly when recommending fewer
users, showing that expanding the retweet is a quite diﬃcult
task and recommending only few users will incur higher miss
rate, leading to the slight precision drop.
6.5 Recommendation Overload Evaluation

If everyone uses the whom-to-mention system, recommen-
dation overload may occur and a popular user may receive
tons of mention notiﬁcation from the recommendation sys-
tem which will result in a severe interruption. We show how
many times a user is recommended in our evaluation in a
descending order in ﬁgure 3. From the ﬁgure the recom-
mendation distribution of WTM is more smooth compared
with our best comparison algorithm CCFR. It is also worth
noting that in CCFR, there exist users recommended hun-
dreds of times which may lead to potential mention overload
while our algorithm avoids the overload problem by setting
the constraints based on user’s free will.

fect recommendation match in real world may be regarded
as a miss in the evaluation as a result of lack of retweet log
given the tweet. However, by comparing our algorithm with
a set of carefully designed comparison algorithms, we be-
lieve our algorithm performs well based on the remarkable
improvement on all metrics. On the other hand, attracting
others to retweet is not an easy job and comparing with the
average retweet rate 0.11 on twitter (0.78 on Weibo), our
average 3.1 retweet rate shows a notable improvement.

Based on our comparison evaluation, it shows the content-
dependent user social tie feature plays a much more impor-
tant role compared with user interest match and user inﬂu-
ence. We proposes 3 reasons for this phenomenon: First,
though with careful pre-processing, the ambiguity and noise
in the tweets still decrease the accuracy of user interest
match. As a matter of fact, even though both are content
features derived from user‘s tweets to model user‘s inter-
est, the content feature from user‘s social ties shows more
eﬀectiveness compared with content feature from user‘s in-
terest model, because the former feature is with less noise
(users usually prefer to choose a well written tweet with a
clear topic to retweet). Second, though intuitively inﬂuen-
tial users can lead to a larger diﬀusion of the tweet, they
are usually mentioned by large numbers of people everyday,
which makes them more easily to ignore the mention noti-
ﬁcations. Third, the content-dependent retweet social tie is
a strong indication. A user retweeting another user‘s tweet
usually indicates a close user relationship and people who
are close are more likely to retweet a tweet from each other.
Moreover, retweet shows a strong interest on the topic of
the tweet, so the user will be very likely to retweet the tweet
with the same topic again in the future.

8. CONCLUSIONS

We oﬀer the ﬁrst in-depth study on Mention Recommen-
dation and propose a new recommendation scheme to ex-
pand the diﬀusion of tweets by recommending proper users
to mention. We formulate this new problem as a ranking
problem and use new features, new relevance and a machine
learned ranking function to solve it.

We ﬁnd that the best performance of the algorithm is
achieved when all the new features, including user interest
match, user social ties and user inﬂuence, are used. A rel-
evance deﬁned by the coverage of users and an SVR based
ranking function also help to improve the performance. Based
on our comparison experiment, we also ﬁnd that user rela-
tionship based features play a more important role than the
content based features. Furthermore, we conﬁrm that the
content-dependent feature in user relationships is of high
eﬀectiveness in our recommendation model.

Many future works can be further explored. For instance,
we use a post-processing step to solve the recommenda-
tion overload problem while constrained optimization can
be tried to address this issue in the future. It’s also interest-
ing to study on how the proportion of strangers and friends
in the recommendation list aﬀect the tweet diﬀusion.

7. DISCUSSION

9. ACKNOWLEDGMENTS

The experiment results may seem a bit low, which is in ac-
cordance with our expectation. On one hand we ascribe it to
we performing an oﬀ-line evaluation by using user‘s retweet
log to estimate the possible information cascade and a per-

This work was supported by the National Basic Research

Program of China (973 Program) under Grant 2013CB336500,
National Nature Science Foundation of China (Grant Nos:
61173185, 61173186, 61125203, 61222207), National Key Tech-

1339nology R&D Program (Grant Nos: 2012BAI34B01, 2008BAH26B00),
Zhejiang Province Key S&T Innovation Group Project (Grant
No.2009R50009), Program for New Century Excellent Tal-
ents in University (NCET-09-0685).

An explorative study. In Sixth International AAAI
Conference on Weblogs and Social Media, 2012.

[19] A. Java, X. Song, T. Finin, and B. Tseng. Why we twitter:

understanding microblogging usage and communities. In
Proceedings of the 9th WebKDD, pages 56–65, 2007.

10. REFERENCES

[1] F. Abel, Q. Gao, G. Houben, and K. Tao. Analyzing user

modeling on twitter for personalized news
recommendations. User Modeling, Adaption and
Personalization, pages 1–12, 2011.

[2] E. Bakshy, J. Hofman, W. Mason, and D. Watts.

Everyone’s an inﬂuencer: quantifying inﬂuence on twitter.
In Proceedings of WSDM 2011, pages 65–74, 2011.

[3] E. Bakshy, J. Hofman, W. Mason, and D. Watts.

Identifying inﬂuencers on twitter. In WSDM 2011, 2011.

[4] B. Bartell, G. W. Cottrell, and R. Belew. Learning to

retrieve information. In Proceedings of the Swedish
Conference on Connectionism, 1995.

[5] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang, and H.-W. Hon.

Adapting ranking svm to document retrieval. In
Proceedings of SIGIR 2006, pages 186–193, 2006.

[6] M. Cha, H. Haddadi, F. Benevenuto, and K. Gummadi.
Measuring user inﬂuence in twitter: The million follower
fallacy. In 4th International AAAI Conference on Weblogs
and Social Media (ICWSM), pages 10–17, 2010.

[7] J. Chen, W. Geyer, C. Dugan, M. Muller, and I. Guy. Make

new friends, but keep the old: recommending people on
social networking sites. In Proceedings of the 27th
international conference on Human factors in computing
systems, pages 201–210, 2009.

[8] J. Chen, R. Nairn, L. Nelson, M. Bernstein, and E. Chi.
Short and tweet: experiments on recommending content
from information streams. In Proceedings of the 28th
international conference on Human factors in computing
systems, pages 1185–1194, 2010.

[9] M. Chen, J. Han, and P. Yu. Data mining: an overview

from a database perspective. Knowledge and data
Engineering, IEEE Transactions on, pages 866–883, 1996.

[10] F. Diaz, D. Metzler, and S. Amer-Yahia. Relevance and

ranking in online dating systems. In Proceeding of
SIGIR2010, pages 66–73, 2010.

[11] Z. Guan, C. Wang, J. Bu, C. Chen, K. Yang, D. Cai, and

X. He. Document recommendation in social tagging
services. In Proceedings of the 19th International
Conference on World Wide Web, pages 391–400, 2010.

[12] I. Guy, I. Ronen, and E. Wilcox. Do you know?:

recommending people to invite into your social network. In
Proceedings of the 14th international conference on
Intelligent user interfaces, pages 77–86, 2009.

[13] I. Guy, N. Zwerdling, D. Carmel, I. Ronen, E. Uziel,

S. Yogev, and S. Ofek-Koifman. Personalized
recommendation of social software items based on social
relations. In Proceedings of the third ACM conference on
Recommender systems, pages 53–60. ACM, 2009.

[14] D. Hand, H. Mannila, and P. Smyth. Principles of data

mining. The MIT press, 2001.

[15] J. Hannon, M. Bennett, and B. Smyth. Recommending

twitter users to follow using content and collaborative
ﬁltering approaches. In Proceedings of the fourth ACM
conference on Recommender systems, pages 199–206, 2010.
[16] L. Hong and B. Davison. Empirical study of topic modeling

in twitter. In Proceedings of the First Workshop on Social
Media Analytics, pages 80–88, 2010.

[17] W. Hsu, A. King, M. Paradesi, T. Pydimarri, and

T. Weninger. Collaborative and structural recommendation
of friends using weblog-based social network analysis. In
AAAI Spring Symposium Series, 2006.

[18] J. Jang, J. Choi, G. Jang, and S. Myaeng. Semantic social

networks constructed by topical aspects of conversations:

[20] H. Kwak, C. Lee, H. Park, and S. Moon. What is twitter, a

social network or a news media? In Proceedings of
WWW2010, pages 591–600, 2010.

[21] P. Li, C. J. C. Burges, and Q. Wu. Mcrank: Learning to

rank using multiple classiﬁcation and gradient boosting. In
NIPS’07, 2007.

[22] P. Melville, R. Mooney, and R. Nagarajan.

Content-boosted collaborative ﬁltering for improved
recommendations. In Proceedings of the National
Conference on Artiﬁcial Intelligence, pages 187–192, 2002.

[23] M. Michelson and S. Macskassy. Discovering users’ topics of
interest on twitter: a ﬁrst look. In Proceedings of the fourth
workshop on Analytics for noisy unstructured text data,
pages 73–80, 2010.

[24] A. Mohan, Z. Chen, and K. Q. Weinberger. Web-search

ranking with initialized gradient boosted regression trees.
Journal of Machine Learning Research, Workshop and
Conference Proceedings, 14:77–89, 2011.

[25] R. Mooney and L. Roy. Content-based book recommending
using learning for text categorization. In Proceedings of the
ﬁfth ACM conference on Digital libraries, pages 195–204,
2000.

[26] R. Nallapati. Discriminative models for information

retrieval. In Proceedings of SIGIR 2004, pages 64–71, 2004.

[27] M. Pazzani and D. Billsus. Learning and revising user

proﬁles: The identiﬁcation of interesting web sites. Machine
learning, 27(3):313–331, 1997.

[28] T. Qin, X.-D. Zhang, M.-F. Tsai, D.-S. Wang, T.-Y. Liu,

and H. Li. Query-level loss functions for information
retrieval. Information Processing and Management,
44(2):838–855, 2008.

[29] A. Smola and B. Sch¨olkopf. A tutorial on support vector
regression. Statistics and computing, 14(3):199–222, 2004.

[30] D. Sousa, L. Sarmento, and E. Mendes Rodrigues.

Characterization of the twitter@ replies network: are user
ties social or topical? In Proceedings of SMUC 2010, pages
63–70, 2010.

[31] S. Wu, J. Hofman, W. Mason, and D. Watts. Who says

what to whom on twitter. In Proceedings of WWW 2011,
pages 705–714, 2011.

[32] X. Wu, V. Kumar, J. Ross Quinlan, J. Ghosh, Q. Yang,

H. Motoda, G. McLachlan, A. Ng, B. Liu, P. Yu, et al. Top
10 algorithms in data mining. Knowledge and Information
Systems, 14:1–37, 2008.

[33] B. Xu, J. Bu, C. Chen, and D. Cai. An exploration of

improving collaborative recommender systems via user-item
subgroups. In Proceedings of the 21st international
conference on World Wide Web, 2012.

[34] J. Yang and J. Leskovec. Modeling information diﬀusion in

implicit networks. In Data Mining , 2010 IEEE 10th
International Conference on, pages 599–608, 2010.

[35] S. Ye and S. Wu. Measuring message propagation and

social inﬂuence on twitter. com. Social Informatics, pages
216–231, 2010.

[36] Y. Yue, T. Finley, F. Radlinski, and T. Joachims. A

support vector method for optimizing average precision. In
Proceedings of SIGIR 2007, pages 271–278, 2007.

[37] W. Zhao, J. Jiang, J. Weng, J. He, E. Lim, H. Yan, and

X. Li. Comparing twitter and traditional media using topic
models. Advances in Information Retrieval, pages 338–349,
2011.

1340