TopRec: Domain-Speciﬁc Recommendation through

Community Topic Mining in Social Network

∗
Xi Zhang, Jian Cheng

{xi.zhang, jcheng, tyuan, bniu, luhq}@nlpr.ia.ac.cn

Beijing, China

, Ting Yuan, Biao Niu, Hanqing Lu

National Laboratory of Pattern Recognition

Institute of Automation, Chinese Academy of Sciences

ABSTRACT
Traditionally, Collaborative Filtering assumes that similar
users have similar responses to similar items. However, hu-
man activities exhibit heterogenous features across multiple
domains such that users own similar tastes in one domain
may behave quite diﬀerently in other domains. Moreover,
highly sparse data presents crucial challenge in preference
prediction. Intuitively, if users’ interested domains are cap-
tured ﬁrst, the recommender system is more likely to provide
the enjoyed items while ﬁlter out those uninterested ones.
Therefore, it is necessary to learn preference proﬁles from
the correlated domains instead of the entire user-item ma-
trix. In this paper, we propose a uniﬁed framework, TopRec,
which detects topical communities to construct interpretable
domains for domain-speciﬁc collaborative ﬁltering. In order
to mine communities as well as the corresponding topics, a
semi-supervised probabilistic topic model is utilized by in-
tegrating user guidance with social network. Experimental
results on real-world data from Epinions and Ciao demon-
strate the eﬀectiveness of the proposed framework.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information
ﬁltering; H.3.5 [Online Information Services]: Web-based
services

General Terms
Algorithms, Experimentation

Keywords
Recommender Systems, Collaborative Filtering, Social Net-
work, Probabilistic Topic Modeling

1.

INTRODUCTION

As electronic commerce becomes increasingly popular, large

amounts of available information for products are ﬂooding
the Web. To avoid customers inundated with choices, nowa-
days recommender systems take a central role by selecting
the potential enjoyed products and ﬁltering out uninterest-
ed ones. Through taking personalized recommendations for
∗

corresponding author

Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW 2013, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

products, some famous online shopping websites such as A-
mazon and Netﬂix have expanded their marketing success-
fully [7, 15].

Most of these commercial systems are based on Collabo-
rative Filtering(CF), which is an eﬀective recommendation
approach with fundamental assumption that two users have
similar tastes on one item if they have rated other items
similarly [29, 24]. Due to the collaboration eﬀects, CF only
relies on users’ history behaviors without collecting content
information for all users and items. Another beneﬁt of CF
is that unexpected products could be recommended to user-
s by mining user-product interactions. Those products are
diﬃcult to be discovered by merely analyzing the contents.
Although CF approaches have superior characteristics and
have been applied to many real-world systems, there stil-
l exist drawbacks which limit their performance. On the
one hand, traditional CF considers collaboration eﬀects a-
mong users but ignores the variety across diﬀerent domain-
s. Generally, customers have similar tastes in one domain
could not infer that they have similar tastes in other do-
mains. An impressive example is involving Epinions1, which
is one of the largest product review websites with several
less-correlated domains such as “Movies”, “Music”, “Home
& Garden”, and so on. On the site, two users who love
movies of the same type are probably to have totally diﬀer-
ent preference in “Home & Garden” domain. In this sense,
users show heterogenous features across multiple domains.
As a consequence, training domain-speciﬁc recommendation
model is more reasonable than training a model on the entire
user-item matrix.

On the other hand, recommender systems in practice have
to face a main challenge of data sparsity. Typically, there
are usually thousands of products on e-commerce websites
but most of them are long-tailed. In this case, recommenda-
tion based on CF methods is inclined to suggest well-known
products rather than those cold ones [19]. Hence, it is quite
diﬃcult to predict user preference accurately from the whole
item set. To alleviate this problem, an intuitive scheme is
to take users’ interested topic into account. Considering a
scenario that if a user’s attitude toward domains is captured
ﬁrst, one who expresses great interest in “Music” would prob-
ably receive a recommendation list with more music-related
products than popular products in other domains. Com-
pared to prediction in the whole item set, a user’s preferred
long-tailed items are more likely to be dug out via prediction
in the interested domains.

1http://www.epinions.com

1501Nevertheless, the information of users’ interested topics
is absent in most existing consumer review sites. One s-
traightforward solution is to count how many times a user
purchased or clicked products in one domain, then whether
the user is interested in a domain or not would be inferred
by her statistical history reviews. However, users without
interest interactions but with social relations in the domain
might probably be ignored. Also, since the distribution of
review number over users is quite imbalanced, it is unclear
how to deﬁne a uniﬁed criterion to partition users into diﬀer-
ent domains. Instead, we change our perspective to mining
interpretable topics for communities. The process is equiv-
alent to ﬁnding user clusters meanwhile align them into the
predeﬁned domains, and therefore can be viewed as commu-
nity topic mining.

With all the concerns aforementioned, we develop a nov-
el recommendation framework integrating community top-
ic mining with domain-speciﬁc recommendation, which is
called TopRec for short. As we known, social community
detection itself is a very important research task with great
challenges in data mining [4, 30]. The crucial diﬀerence is,
in our TopRec framework, we not only focus on communi-
ty detection algorithm, but also investigate:(1) how to align
these extracted user communities without explicit topic to the
known domains, and (2) how to take advantage of the natu-
ral social network structure to assist user clustering. To the
best of our knowledge, these issues have not been studied in
recommender systems before.

To address above two issues, we propose a uniﬁed prob-
abilistic topic model in the context of social network in
this paper, by combining semi-supervised methods of user-
guided and structure-constrained clustering. Then the ac-
curacy of the top-n recommendation task can be improved
by domain-speciﬁc CF algorithm. The main contributions
of this work are summarized below:
• Proposing a novel recommendation framework, TopRec,
for multi-category datasets with trust connections to
deal with the limitations of conventional CF methods.
• Introducing user guidance as a sort of prior knowledge
in the probabilistic topic model to detect communi-
ties and align them with existing domains at the same
time.

• Embedding social links as complementary data resource
in the probabilistic topic model to satisfy connectivity
coherency.

• Employing domain-speciﬁc CF approach to formulate
heterogenous latent features corresponding to the in-
terested domains for user.

The rest of the paper is organized as follows. A new rec-
ommendation framework, TopRec, is introduced in Section
2. A uniﬁed probabilistic model for community topic min-
ing is described in Section 3 and a domain-speciﬁc CF model
for recommendation is presented in Section 4. Then we ana-
lyze experimental results on benchmark datasets in Section
5. Finally, we discuss the related work in Section 6 and
conclude this work in Section 7.

2. A NEW FRAMEWORK - TOPREC

Domain1

Domain2

Domain3

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:19)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:24)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:19)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:24)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:19)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:24)(cid:24)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:24)(cid:19)(cid:19)(cid:19)(cid:19)(cid:8)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:24)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:24)(cid:19)(cid:19)(cid:19)(cid:19)(cid:8)(cid:8)

(cid:24)(cid:19)(cid:8)
(cid:24)(cid:24)(cid:24)(cid:24)(cid:19)(cid:19)(cid:8)(cid:8)

item

user

social link

interest

Figure 1: A simple illustration of interest interac-
tions and social network within domains. The larger
nodes represent experts in domains.

2.1 Framework Overview

There are three types of data in our framework: the review
records and the social network for all users, as well as the
category information for all items. Without loss of general-
ity, Figure 1 depicts a typical topology of a heterogeneous
graph containing both interest interactions and social net-
work. The essential of our goal is to construct domains by
the given data and community topic mining, then conduct
domain-speciﬁc recommendation, which consists of following
two stages:

Stage 1: Community Topic Mining. In this study,
we tackle this step with probabilistic topic model for three
main considerations. First, individuals in real life are usually
multi-faceted. As their interests cannot be captured by one
topic, discrete mixed membership models like Probabilistic
Latent Semantic Analysis(PLSA) [10] and Latent Dirichlet
Allocation(LDA) [1], which can represent objects as distri-
bution over topics, are suitable in our scenario. Second, in
consumer review sites such as Epinions, we can always ﬁnd
active users in each domain(the larger node in Figure 1),
who can supply prior knowledge of the probabilistic model
for topic alignment. Third, probabilistic topic model allows
to connect similar users in social relations to enhance com-
munity meanwhile indicates why we connect them.

Stage 2: Domain-Speciﬁc Collaborative Filtering.
After extracting topical communities, users are divided in-
to domains according to their interested topics. To predict
user preference, we exploit normal CF in each domain and
then return a rank list according to the predicted rating s-
cores. In our case, the particular algorithm utilized is Prob-
abilistic Matrix Factorization(PMF) [21], a state-of-the-art
CF approach with promising recommendation results. As a
matter of fact, the TopRec is a general framework and has
potential to combine other CF methods in practice.

One similar problem has been formulated in Multiclass

Co-Clustering(MCoC) model recently [27], which groups user-
s and items into topical subsets to achieve better recommen-
dation results. However, TopRec boosts performance by ex-
ploring interpretable domains while the topics in MCoC are
implicit.
2.2 Problem Deﬁnition

In this section, we introduce an overview of our recommen-
dation framework, TopRec, and give the problem deﬁnition
formally.

Here we present the notations and deﬁnitions to be used
in this paper. Suppose there are N users and M item-
s in the given dataset, U = {u1,··· , uN} denote the us-

1502er set and V = {v1,·· · , vM} denote the item set. Let
R = (r1,··· , rN )T ∈ R
N×M represent rating matrix, where
ri is column vector including ratings from user ui toward-
s item set V. Note that rating vector ri can be viewed as
feature representation for user ui. Then a user ui in col-
lection U can be denoted by a series of items {vj}M
j=1. Let
T = (t1,··· , tN )T ∈ R
N×N denote a binary trust matrix,
where ti is column vector indicating whether user ui trust
others in user set U. We also model this user-user relation-
ship as a graph G with adjacency matrix W to encode this
trust relations into community mining model.
Deﬁnition 1. Domain. Suppose the number of domains
is K, a domain Dk is composed of item subset Vk and user
subset Uk, where k = 1,··· , K, then we have Nk users and
Mk items in each domain. Thus, a set of domain can be
represented as D = {D1,··· ,DK}.
Deﬁnition 2. Problem Deﬁnition. Given review ma-
trix R, social context T and item-domain information Vk =
{v1,··· , vMk}, our goal is:
In stage 1, discover domain-
s Dk = {Uk,Vk} by mining Uk = {u1,··· , uNk}, where
k = 1,··· , K.
In stage 2, for each domain Dk, we train
PMF model using the observed ratings of user-item pairs
(ui, vj ), where ui ∈ Uk and vj ∈ Vk. Finally, by utilizing
the learnt domain-speciﬁc latent features in prediction, the
personalized rank lists for users in set U towards the whole
item set V are returned.

3. COMMUNITY TOPIC MINING

In this section, we propose a semi-supervised probabilis-
tic topic model with expert guidance and network structure.
By modeling the generative process of user set, the model
could explicitly mine their interest topics from both histor-
ical ratings and social relationships.
3.1 Basic Idea

Probabilistic generative models such as PLSA have been
widely used in many text mining tasks [10, 3, 16], and al-
so play a signiﬁcant role in recommendation tasks due to
their ability in dealing with dyadic data [11, 26]. Follow-
ing the previous works on probabilistic models, we treat
user as a mixture of topics, where each topic is a multi-
nomial distribution over all the items. For instance, a dis-
tribution that assigns high probabilities to items such as
“iPhone”,“iPad”,“Kindle” would suggest that the user loves
“Electronics” topic.
In order to identify multiple interest
topics for user, we model users in a mixture model with K
topics and estimate the model parameters so that the like-
lihood of user collection U is maximized. In this way, the
statistical topic model could capture the co-occurences of
items and encourage to group users into communities.

Intuitively, user communities grouped by basic PLSA mod-
el can represent interest topics towards item categories. How-
ever, these extracted topics are latent variables without ex-
plicit meaning and cannot be regarded as the given cate-
gories. Thus, simply using PLSA cannot ensure the obtained
topic is well-aligned to the speciﬁc domains. To overcome
this limitation, we introduce user guidance as a priori into
the generative clustering process. In reality, most users in
consumer review sites are extremely cold. That is, there
is little useful information could guide community mining.
Fortunately, there exit a few representative and trustable
users in each domain, who review and comment frequently
meanwhile own a large number of trustors. In this study, we

regard these users as experts of each community and their
rating distribution over items as prior knowledge for clus-
tering.

Another problem is that the social network structure might
be neglected. Generally, people not only make interactions
with online products but also have trusts relation with other
users. Thus only using rating data cannot guarantee that
well-connected users are clustered in the same topical com-
munity. Besides, more information about cold users can be
analyzed from the perspective of their local trusting neigh-
bors. For example, one might do not have enough reviews,
while has more trust relations such that mining her interest
topic from social view is possible. Accordingly, these linked
structures are quite useful in community topic mining.
3.2 Experts-Guided Topic Modeling
To model the user clustering procedure with experts guid-
ance, we introduce a topic variable zk ∈ {z1,··· , zK} with
each observation of a item vj ∈ {v1,··· , vM} is rated by a
particular user ui ∈ {u1,··· , uN}. Each topic zk is corre-
sponding to the k-th domain. Let c(ui, vj ) = Rij denote the
rating of user ui giving item vj to express how much the
user like the item.
Given a user collection U, experts-guided topic modeling
is to discover topical communities meanwhile label them the
known domains, and then users and items with a similar
topic could be mapped into the same subgroup. To this end,
we take the rating vectors of experts as prior knowledge for
each user cluster. To make sure the eﬀect of the guidance,
the experts are manually chosen by two criteria:

• Informative. The experts should be the persons who
contribute a large quantity of reviews in one particular
item category, so that their attitude can cover items
in the category as more as possible.

• Reliable. The experts would better have a great num-
ber of followers, which implies their reviews and com-
ments are trustable to some certain extent.

Once the experts are selected, we model such prior as a
Dirichlet distribution to enforce the topics to be as close as
possible to the predeﬁned domains. Speciﬁcally, for each giv-
en topic zk, its probabilistic distribution over items p(vj|zk)
is assumed to be a multinomial distribution, which is gener-
ated from some Dirichlet distribution. We deﬁne this Dirich-
let prior as zk : Dir({σkp(vj|¯uk) + 1}vj∈V ), where σk is con-
ﬁdence parameter of the prior distribution for topic k, and
¯uk ∈ U denote expert corresponding to the topic k.
Similar to PLSA, parameters in our model are {p(vj|zk),
p(zk|ui)}. We set all the parameters as Θ for succinct in the
following paragraph. In general, the prior on the parameters
can be presented as

p(vj|zk)

σkp(vj| ¯uk)

(1)
where the prior p(vj|¯uk) involves the rating distribution

of experts over the item set V, and can be obtained by

k=1

j=1

P (Θ) ∝ K(cid:2)

M(cid:2)

p(vj|¯uk) =

(cid:3)M

c(¯uk, vj )
j(cid:2)=1 c(¯uk, vj(cid:2) )

(2)

A large σk equals to high conﬁdence on prior of topic k.
When σk = 0, the prior of p(vj|zk) boils down to a uniform

1503In fundamental PLSA model, the log-likelihood of user

distribution, which means that no guidance is introduced in
the clustering process.
collection U is
L(U) = log p(U|Θ) =

p(vj|zk)p(zk|ui)

c(ui, vj ) log

N(cid:4)

M(cid:4)

K(cid:4)

i=1

j=1

k=1

(3)
We may use Bayesian estimation, so the parameter Θ can

be estimated by maximizing Eq.(3), which is

ˆΘ = arg max

Θ

log p(U|Θ)

(4)

With the prior incorporated, Maximum A Posterior (MAP)
estimator is used instead of Maximum Likelihood estimator.
That is, L(U) = log(p(U|Θ)p(Θ)). Therefore, Θ is obtained
by

ˆΘ = arg max

Θ

log(p(U|Θ)p(Θ))

M(cid:4)

{ N(cid:4)

i=1

j=1

c(ui, vj ) log

K(cid:4)

k=1

p(vj|zk)p(zk|ui)

= arg max

K(cid:4)

Θ

M(cid:4)

+

k=1

j=1

σkp(vj|¯uk) log p(vj|zk)}

3.3 Network-Constrained Topic Modeling

Furthermore, we propose to regularize the user-speciﬁc
feature space by social network during clustering process.
Given a binary trust matrix T = (t1,··· , tN )T ∈ R
N×N ,
a social graph G = (U,E , T) could be constructed, where
U is a set of N vertices representing users, E ⊆ U × U is
a set of edges representing trust similarity between users in
neighborhood, and T can be regarded as a matrix in which
each row corresponds to a vector of feature values of a user.
In particular, user relationships are embodied by deﬁning
adjacency matrix W on user graph as

W (ui, ui(cid:2) ) =

sim(ui, ui(cid:2) ),
0,

if ui(cid:2) ∈ N (ui) or ui ∈ N (ui(cid:2) )
otherwise.

(cid:5)

(6)
where N (ui) is the k-nearest neighbor of ui, and sim(ui, ui(cid:2) )
represents the trust similarity measurement. For simplic-
ity, we use cosine distance between vectors {ti}N
i=1 here.
Though above equation, we transform the original directed
trust graph T to an undirected trust similarity graph W,
which is able to formulate into topic model as regularization
term directly.

The essential idea of network-constrained user clustering
is on the basis of one simple assumption: users who have a
strong connection with each other in social network should
have similar preference on topics. Inspired by this fact, we
adopt the following formulation as a constraint for topic
model
R(U,G) =

(p(zk|ui) − p(zk|ui(cid:2) ))

W (ui, ui(cid:2) )

(cid:4)

K(cid:4)

2

1
2

(cid:3)ui,ui(cid:2)(cid:4)∈E

k=1

(7)
Therefore, our aim is to minimize Eq.(7). Then we uti-
lize this constraint into log-likelihood function generated by
PLSA, which means to maximize

J (U,G) = L(U) − λR(U,G)

(8)

(5)

3.5 Parameter Estimation

where λ is a regularization parameter which controls the
inﬂuence of smoothness on topic distribution over network.
3.4 The Uniﬁed Model

Combining above two parts of topic modeling, we have a
joint objective function with concerning both topical con-
sistency and connectivity coherency at the same time. By
substituting the posterior probability formula in Eq.(5) and
the regularizer in Eq.(7) into Eq.(8), the ﬁnal objective func-
tion can be written as
J (U,G) =

p(vj|zk)p(zk|ui)

K(cid:4)

N(cid:4)
K(cid:4)

i=1

j=1

c(ui, vj ) log

M(cid:4)
M(cid:4)
σkp(vj|¯uk) log p(vj|zk)
(cid:4)

K(cid:4)

k=1

j=1

+

k=1

− λ
2

(cid:3)ui,ui(cid:2)(cid:4)∈E

W (ui, ui(cid:2) )

(p(zk|ui) − p(zk|ui(cid:2) ))

2

k=1

(9)

For Maximum Likelihood Estimation (MLE) procedure,
the Expectation Maximization (EM) algorithms is common-
ly used. However, in our MAP case with the combination of
regularizer, parameter estimation becomes diﬃcult to han-
dle by the standard EM. Hence, we apply the Generalized
Expectation Maximization algorithm (GEM) to estimate the
parameter Θ. Parameter in n-th iteration are denoted as Θn.
Formally, we conduct a two-step iterative algorithm. In
E-step, given all the users’ reviews data and parameter Θn,
the distribution of the topics can be computed simply by the
same formula as PLSA
p(zk|ui, vj , Θn) =

(cid:3)K
pn(vj|zk)pn(zk|ui)
k(cid:2)=1 pn(vj|zk(cid:2) )pn(zk(cid:2)|ui)

(10)

In M-step, the algorithm searches better parameters through
optimizing Q-function: Θn+1 = arg maxΘ Q(Θ; Θn), which
is present by

N(cid:4)
Q(Θ; Θn) = J (Θn) +
M(cid:4)

K(cid:4)

i=1

K(cid:4)

k=1

αi(

p(zk|ui) − 1)

(11)

+

j=1

k=1

αk(

p(vj|zk) − 1)
(cid:3)
(cid:3)
where αi and αk are Lagrange multipliers of the constraints
k p(zk|ui) = 1 for all users and
j p(vj|zk) = 1 for all
topics, respectively.
Computation of pn(vj|zk) To optimize Eq.(11) with
respect to pn(vj|zk), we need to consider the original PLSA
likelihood function and the user guidance term. By taking
partial derivative of pn(vj|zk) to Eq.(11), its updating can
be got as
pn+1(vj|zk) =

(cid:3)N
(cid:3)M
(cid:3)N
i=1 c(ui, vj )p(zk|ui, vj , Θn) + σkp(vj|¯uk)
i(cid:2)=1 c(ui(cid:2) , vj(cid:2) )p(zk|ui(cid:2) , vj(cid:2) , Θn) + σk
j(cid:2)=1

(12)
This formulation can be understood easily. In addition to
the data of user collection, the opinions of experts on item
distribution over topics are also imposed. Then parameter
updating are decided by collaboration of the both factors,
which is also consistent with our intuition.

1504Computation of pn(zk|ui) Optimizing Eq.(11) with re-
spect to pn(zk|ui) directly is more complicated even though
it is only related with the terms of data likelihood and net-
work regularization. Similar to [3], we take the strategy in
GEM to satisfy Q(Θn+1) ≥ Q(Θn) in each step, which ﬁnds
a better Θ rather than ﬁnds a globally optimal solution. We
apply the normal updating method in standard PLSA to
maximize L(U) in Eq.(8) which can ﬁnd a start value Θ1
n+1.
Then R(U,G) is increased by

n+1(zk|ui) = τ pt
pt+1

n+1(zk|ui) + (1 − τ )

(cid:2)N

i(cid:2)=1 W (ui, ui(cid:2) )pt

(cid:2)N

i(cid:2)=1 W (ui, ui(cid:2) )

n+1(zk|ui(cid:2) )

M(cid:4)

(13)
where τ is Newton step parameter to limit the eﬀect of s-
moothness by R(U,G). We repeat this iteration until the
Q-function is beginning to drop. Also, we judge the out-
n+1) ≥ Q(Θn), we adopt the proposal of
put Θt
Θt
n+1, otherwise, reject it. The E-step and M-step equa-
tions are alternated until achieving some termination con-
ditions.
In this way, we obtain the estimated parameters
{p(vj|zk), p(zk|ui)}.

n+1. If Q(Θt

Now, to group each user into more than one topical com-
munities, we set a natural clustering criterion as: a user ui
is interested in a meaningful topic zk, if and only if func-
tion f (zk, ui) is satisﬁed by f (zk, ui) > ε. Thus, given a
user, the function f (·) measures attractiveness of a domain
on her, which is deﬁned as

f (zk, ui) =

c(ui, vj )p(vj|zk)

(14)

j=1

Clearly, Eq.(14) could be viewed as a kind of similarity mea-
surement between users and topics.

4. DOMAIN-SPECIFIC COLLABORATIVE

FILTERING

In this section, we illustrate domain-speciﬁc collaborative
ﬁltering in detail. The overall procedure consists of two
steps, which are model training and top-n recommendation.
4.1 Model Training
After community topic mining, the observed user-item
pairs are allocated into diﬀerent domains. Let Rk ∈ R
Nk×Mk
denote the rating matrix for the k-th domain, where k =
1, . . . , K. Mk and Nk are the number of items and users
in each domain respectively. Let Pk ∈ R
d×Nk and Qk ∈
d×Mk denote the latent feature matrices in k-th domain,
R
with column pk
j represent the latent feature vectors
of users and items respectively, where d denotes the dimen-
sion of latent feature. Adopting PMF model in diﬀerent
domains, the model is trained on rating data by minimizing
the square error

i and qk

I k
ij(Rk

ij − (p
k
i )

T

2

k
j )

q

+

β

2

(

(cid:7)p

k

i (cid:7)2

+

(cid:7)q

k

j (cid:7)2

)

i=1

j=1

(15)
where I k
ij indicates the training data of user-item pairs be-
longed to domain k, (cid:7) · (cid:7)2 denotes the Frobenius norm to
make the solution more robust, and β is the regularization
coeﬃcient. One important diﬀerence between the PMF and
our model is that we consider the training process across
each domain. Therefore, we have K objective functions in

Nk(cid:4)

Mk(cid:4)

Nk(cid:4)

Mk(cid:4)

i=1

j=1

1
2

Mk(cid:4)

Nk(cid:4)

i=1

Mk(cid:4)

Nk(cid:4)

i=1

total. The parameters pk
j in Eq.(15) can be min-
imized by Alternating Least Square(ALS) method, which
performs the following two updates alternatively.

i and qk

First, optimizing Eq.(15) with respect to pk

i for i = 1, 2, . . . ,

Nk in domain k and ﬁxing all qk

j leads to

k
p
i = (

I k
ijq

k
j (q

k
j )

T

+ βId)

−1

(

I k
ijRk

ij q

k
j )

(16)

j=1

j=1

Then, optimizing with respect to qk
domain k and ﬁxing all pk
i leads to

j for j = 1, 2, . . . , Mk in

k
j = (

q

k
k
I k
ijp
i (p
i )

T

+ βId)

−1

(

I k
ijRk

k
ij p
i )

(17)

(cid:3)Mk

(cid:3)Nk

(cid:7)qk

j=1 mk
vj

j(cid:7)2 and

In order to avoid overﬁtting on test data, we use the
i (cid:7)2
weighted-regularization
instead of the original regularization terms in Eq.(15) in ex-
periment, where mk
ui denote the number of ratings
of item vj and user ui in Dk, respectively.
4.2 Recommendation with Domains

vj and nk

i=1 nk
ui

(cid:7)pk

Since top-n recommendation is to produce a ranking list
of items with high to low preference, it is necessary to pre-
dict ratings for users towards items in each domain ﬁrst.
Corresponding to training process, we consider a two-step
ﬁltering to recommend items in the framework of TopRec.
Given a user-item pair (ui, vj ), the ﬁrst step is to judge
whether the user ui is interested in the speciﬁc domain Dk
If she is interested in Dk,
where the item vj belongs to.
the following rating prediction step is implemented using
the learnt domain-speciﬁc user and item latent feature pa-
rameters pk
j . Otherwise, we do not predict rating
for the user-item pair. In detail, the whole process can be
summarized in a uniﬁed form

i and qk

ˆRij =

i )T qk

j + rk

(pk
0

if ui ∈ Dk ∩ vj ∈ Dk
otherwise

(18)

(cid:5)

where rk ∈ R denotes the global oﬀset of Dk by averaging
observed ratings in the domain. For each node, we sort the
predicted rating ˆRij of all the K domains with a decreasing
order and then the top-n item list is eventually generated.
Basically, TopRec can ﬁlter out lots of items for users ac-
cording to their uninterested domains and then recommend
items with high predicted rating score in their interested
domains.

5. EXPERIMENTS

In this section, we investigate the performance of TopRec
in top-n recommendation task compared to other state-of-
the-art algorithms on two real-world datasets. Also, we re-
port the results for diﬀerent settings of model parameters.
5.1 Datasets

We examine how the TopRec behaves on two multi-domain
product review datasets with trust networks: Epinions and
Ciao2. Both of them are well-known consumer opinion web-
sites where users not only provide reviews to their familiar
products but also maintain trust lists of their trusting users.

2http://www.ciao.co.uk

1505Table 1: Statistics of the Datasets
Epinions Ciao
4,137
7,475
72,198
140,434
194,278
343,789
85,877
143,066
8
10
46.96
45.99
2.69
2.45
20.75
19.14
99.93%
99.97%
99.74%
99.50%

# of Users
# of Items
# of Ratings
# of Trust Links
# of Domains
Ave Ratings per User
Ave Ratings per Item
Ave Trusts per User
Rating Sparsity
Trust Network Sparsity

103

102

101

)
s
r
e
s
u
#
(
y
t
i
s
n
e
d

100

101

103

102

degree(#interests)
(a) Epinions

102

101

)
s
r
e
s
u
#
(
y
t
i
s
n
e
d

100

101

102

degree(#interests)
(b) Ciao

103

Figure 2: Degree distribution of Epinions and Ciao.

The version of the two datasets3 used in this study are
published by the authors of
[25] including data records un-
til May 2011. To evaluate the eﬀects of social network, we
ﬁrst remove users without trust relations. For the purpose
of taking each user’s top-n recommendation performance in-
to account, we also prune users with fewer than ten reviews
to ensure suﬃcient test data for each user. Then we use
eight and ten top popular categories to deﬁne the domains
for Epinions and Ciao respectively. The detailed statistics of
the two datasets are showed in Table 1. Compared to Ciao,
Epinions owns more users and products in their most repre-
sentative categories, which results in more review data and
trust links. While the scale of Epinions and Ciao are diﬀer-
ent, the sparsity of both datasets are comparable. Based on
the presented statistics, the high sparsity is fairly noticeable
in user-item interaction as well as trust relation. Especially,
as we do not sift cold products from the original published
datasets, the averaging rating per item is extremely small.
Figure 2 shows the degree distribution of the two dataset-
s. As we can see, the datasets are very sparse and suggest
power law distribution.

In experiments, we randomly pick 80% of the review data
to form the training set and the rest for the test set, and
run ten times in each conﬁguration.
5.2 Performance Measures

Because recommender systems in reality normally con-
cerns about personalized ranking of entities but not rating
prediction to all products, we analyze performance of each
model by comparing the top suggestions in our experiments.
For a consistent evaluation with the top-n recommenda-
tion literature, three classical measures commonly used are
employed: MAP(Mean Average Precision), F-measure, and
nDCG(normalized Discounted Cumulative Gain).

For each user, given a ranked list with n items, we denote
prec(j) as the precision at ranked position j, pref(j) as a
binary preference indicator at position j. AP is deﬁned as

AP(u) =

(cid:2)n

j=1 prec(j) × pref(j)

# of preferred items

(cid:2)

u∈U AP(u)

|U|

MAP =

To compute F-measure, let precision and recall denote
the user-oriented averaging precision and recall with top-n
list.

2 × precision × recall

F1 =

precision + recall

3http://www.public.asu.edu/ jtang20/

(19)

(20)

(21)

To obtain nDCG, the preference indicator pref(j) is also
used.

nDCG =

1

IDCG

× n(cid:3)

j=1

2pref(j)−1
log2(j + 1)

(22)

where IDCG is produced by a perfect ranking algorithm.
By this deﬁnition, nDCG gives larger credit to top-ranked
entities. Higher MAP, F1 and nDCG implies better recom-
mendation result.
5.3 Comparisons

Here we compare three variant methods on the basis of
TopRec framework with four baseline methods to demon-
strate the eﬀectiveness of each part of our model.

• TopRec with Single Class (TopRec-S) In this single
class model, we change user clustering criteria as: a
user ui is interested in topic zk if and only if ∀zk(cid:2) ,
s.t.f (zk, ui) > f (zk(cid:2) , ui). Thus user membership hy-
pothesis becomes that a user only interested in one
topical domain. We set the model as a comparison of
users’ multi-faceted features assumption. f (zk, ui) is
still computed by Eq.(14) here.

• TopRec with Multiple Class (TopRec-M) The multi-
class model based on TopRec framework believes that
users are interested in multiple topical domain. Note
that both of TopRec-S and TopRec-M are not added
social networks.

• TopRec with Network (TopRec-Net) As to evaluate
the contribution of social network, we embed network-
constrained term on the basis of TopRec-M. This mod-
el is the uniﬁed model described in section 3.4.

• Probabilistic Matrix Factorization (PMF) [21]. PM-
F virtually is a low rank matrix factorization mod-
el and assumes that a user generates a rating for an
item by adding Gaussian noise to the inner product
d and qj ∈ R
Rij = (pi)T qj, where pi ∈ R
d associate
with latent factor vector of user and item.

• PMF with Domains (PMF-D). This model takes mul-
tiple domains information of items into consideration,
so the PMF-D treats diﬀerent domains independently
but has N users in all domains.

• Multiclass Co-Clustering (MCoC) [27]. This method
proposes a framework to extend traditional CF by di-
viding users and items into multiple subgroups. D-
iﬀerent with our framework, it views this allocation
procedure as a Multiclass Co-Clustering problem.

1506Table 2: Performance comparisons of top-n recommendation on Epinions in terms of MAP, F1 and nDCG.

Methods

n=5

F1

MAP

n=10

n=15

n=20

nDCG MAP

F1

nDCG MAP

F1

nDCG MAP

F1

nDCG

RANDOM 0.2275

0.1156

0.1357

0.2248

0.1160

0.1109

0.2201

0.1072

0.0957

0.2162

0.0994

0.0855

PMF

PMF-D

MCoC

0.2896

0.1714

0.1857

0.2911

0.2038

0.1709

0.2835

0.2010

0.1551

0.2759

0.1904

0.1418

0.3666

0.2045

0.2249

0.3593

0.2157

0.1919

0.3467

0.2032

0.1689

0.3360

0.1885

0.1520

0.3736

0.1961

0.2492

0.3667

0.1990

0.2017

0.3628

0.1847

0.1714

0.3598

0.1726

0.1518

TopRec-S

0.2951

0.1569

0.1814

0.2904

0.1582

0.1487

0.2844

0.1555

0.1325

0.2779

0.1549

0.1234

TopRec-M

0.3953

0.2169

0.2485

0.3847

0.2206

0.2058

0.3739

0.2041

0.1781

0.3651

0.1882

0.1591

TopRec-Net 0.4236 0.2386 0.2710 0.4111 0.2400 0.2235 0.3991 0.2200 0.1927 0.3896 0.2001 0.1709

• Random Group Model (RANDOM) TopRec divides
users into groups with sizes of {N1, . . . , NK}, so we
randomly sample users into K groups with the same
sizes of TopRec. The random group model is to cre-
ate comparison with the process of community topic
mining.

To make a fair comparison, we use PMF as the basic CF
method either training on user-item domains or entire user-
item matrix in all the experiments. For PMF, the latent
dimensionality of low rank features is set to be d = 10, and
the regularization coeﬃcient is set as β = 0.1.
5.4 Experimental Protocol

To all the comparisons, we utilize the following experi-

mental protocol.

We ﬁrst notice that both of Epinions and Ciao are em-
ployed 5-star rating systems, which refers to user-item in-
teraction are explicit. However, we also ﬁnd that more than
70% ratings are 4 or 5, which means the rating distribution
are fairly imbalanced. This positive ratings phenomenon al-
so appears in many other online consumer rating datasets
so that it is inevitably to train overly optimistic estimators
by using the observed ratings directly. To address this phe-
nomenon, we adopt a bias correction procedure mentioned
in [28]. That is to draw uniformly from the set of the unob-
served user-item pairs for each user as pseudo-negatives to
balance the original training set. The assumption under bias
correction is that the unobserved samples are less interested
by users compared with observed rating data.

For the evaluation protocol, we follow the evaluation mech-
anism described in [28, 6]. For each user, as the total number
of items is huge in the datasets, while the number of true
preferred items is much smaller, it is prohibitive to take all
the items as candidates and generate a total ordering of the
whole item set. Our test methodology for top-n measure is:
for each user, we randomly select S additional items that
are not reviewed and mix them with the test data to con-
struct a probe set. Thus we compute the predicted ratings
over probe sets to ﬁnd top-n products. The size of random
probes per user is set as S = 500 in experiments.
5.5 Results and Analysis

Performance on Epinions. Table 2 shows the experi-
mental results on the Epinions dataset with three diﬀerent
evaluation metrics: MAP, F-measure, nDCG, when we vary
the number of returned items n = 5, 10, 15, 20. For the three
variants of TopRec methods, we pick conﬁdence parameter

TopRec−Net
TopRec−M
TopRec−S

 

0.45

0.4

0.35

0.3

0.25

5
@
P
A
M

0.2

 

1000

2000

3000

5000 10000 50000

4000
σ
k

Figure 3: Impact of expert guidance conﬁdence pa-
rameter σk on MAP@5 performance of Epinions.

σk = 10000, the number of experts 3 for each domain, and
the value of regularization parameter λ = 100. Then we em-
pirically set the number of nearest neighbors as 5, the value
of Newton step parameter τ as 0.01.

From Table 2, TopRec-Net yields the best performance
under all of the evaluation conditions. By looking at the
trend along with the number of returned list n, we can see
that all of the performance drops when the returned list n
is increasing. This is mainly because that more than half of
users only have less than ﬁve true interested items in test
set. When n becomes large, recall improves while precision
declines severely.

Compare models concerned about domain-speciﬁc CF (i.e.
TopRec variants and PMF-D)with the original PMF, it is
clear to conclude that the multiple domains do beneﬁts on
recommendation task. TopRec, which allocates users into
their interested domains by user clustering and topic min-
ing, outperforms PMF-D, which simply assumes that users
are belonged to all the domains. By comparing the three
variants of TopRec, we show that TopRec-M and TopRec-
Net perform better than TopRec-S, which demonstrates the
multi-faceted assumption for online users. Another phe-
nomenon is that TopRec-Net outperforms TopRec-M consis-
tently, which infers that network-constrained topic modeling
can bring about performance improvement.

To illustrate the eﬀectiveness of our community topic min-
ing stage, we compare our methods with the state-of-the-art
approach MCoC. Both of TopRec and MCoC aim to map
users and items into subgroups, but we take advantage of the

1507Table 3: Performance comparisons of top-n recommendation on Ciao in terms of MAP, F1 and nDCG.

Methods

n=5

F1

MAP

n=10

n=15

n=20

nDCG MAP

F1

nDCG MAP

F1

nDCG MAP

F1

nDCG

RANDOM 0.1915

0.0832

0.1139

0.1917

0.0781

0.0872

0.1891

0.0699

0.0727

0.1867

0.0642

0.0638

PMF

PMF-D

MCoC

0.2296

0.1127

0.1415

0.2357

0.1484

0.1327

0.2312

0.1555

0.1246

0.2258 0.1534 0.1169

0.3002

0.1434

0.1760

0.3004

0.1567

0.1508

0.2943

0.1538

0.1339

0.2854

0.1483

0.1224

0.3029

0.1265

0.1960

0.2999

0.1418

0.1619

0.2971

0.1329

0.1364

0.2930

0.1233

0.1197

TopRec-S

0.3277

0.1456

0.2011

0.3230

0.1282

0.1488

0.3173

0.1137

0.1231

0.3103

0.1052

0.1083

TopRec-M

0.3839

0.1732

0.2359

0.3787

0.1629

0.1811

0.3706

0.1468

0.1515

0.3634

0.1332

0.1325

TopRec-Net 0.4025 0.1843 0.2501 0.3963 0.1766 0.1946 0.3878 0.1613 0.1641 0.3878 0.1479 0.1431

TopRec−Net
TopRec−M
TopRec−S

 

0.45

0.4

0.35

0.3

0.25

5
@
P
A
M

0.2

 

1000

2000

3000

5000 10000 50000

Figure 4: Impact of expert guidance conﬁdence pa-
rameter σk on MAP@5 performance of Ciao.

4000
σ
k

category relations and employ semi-supervised topic model
for user clustering instead of user-item Co-Clustering. The
experimental results illustrate that our model works bet-
ter than MCoC. The reason is as follows. MCoC conduct-
s Co-Clustering only by ratings. However, the user-item
rating matrix we faced with is highly sparse, few observed
interactions are available for MCoC model. To compensate
this, our model combines rating matrix with complementary
knowledge of item categories and social networks. At last,
we show that user clustering and topic alignment are pivotal
for overall recommendation performance by the comparison
of TopRec and RANDOM.

Performance on Ciao. Ciao is a smaller dataset with
few ratings. We select expert conﬁdence parameter σk =
5000 according to the quantities of observed ratings. Other
parameters mentioned above are set the same as Epinions.
Experimental results on Ciao are reported in Table 3.
It
is evident that TopRec-Net outperforms the other methods
in almost all cases on this dataset. Diﬀerent from Epinion-
s data, TopRec-S behaves better than MCoC and PMF-D
this time. This is because more users are interested in one
domain in the dataset. Similar to Epinions, the number of
interested products for majorities is still less than ﬁve in
test set, which leads to the performance getting worse as
the recommended lists expending.

Parameter Study. The TopRec model mainly has two
important parameters. We ﬁrstly study the eﬀect of con-
ﬁdence parameter σk for expert guidance on Epinions and
Ciao. The conﬁdence weight of each domain is set from 1000
to 50000. The larger σk means the model has more conﬁ-

5
@
P
A
M

0.45

0.4

0.35

0.3

0.25

0.2

 

 

5
@
P
A
M

0.45

0.4

0.35

0.3

0.25

0.2

0.15

 

 

TopRec−Net
TopRec−M
TopRec−S
MCoC
PMF−D
PMF
RANDOM

10

100

λ

1000

10000

(b) Ciao

TopRec−Net
TopRec−M
TopRec−S
MCoC
PMF−D
PMF
RANDOM

10

100

λ

1000

10000

(a) Epinions

Figure 5: Impact of regularization parameter λ on
MAP@5 performance

dence on experts. In Figure 3 and 4, MAP of the top 5 list
are plotted as a function of σk for Epinions and Ciao respec-
tively. As we increase σk, the performance in both Figure
ﬁrst increases and thereafter declines slightly. This obser-
vation coincides with the interpretation of experts-guided
topic modeling: besides user collection U, we adding a pseu-
do counts σkp(vj|¯uk) for item vj , therefore it would be bet-
ter that σk is equivalent to sample size. Yet, if we give a
much higher conﬁdence weight to experts, experimental re-
sults show that the performance would not raise any more.
From the ﬁgures, we can see that the trends are quite similar
on both of the datasets. According to their sample size, the
optimal conﬁdence weight is σk = 10000 for Epinions, and
around σk = 5000 for Ciao.

Now, we discuss the second essential parameter of TopRec,
λ. Figure 5 shows how the social regularization parame-
ter λ impacts the performance of TopRec-Net. We vary
λ ∈ {10, 100, 1000, 1000} where larger λ enhance penalty
of the disagreement of interest distribution between social
neighbors. When λ is small, the uniﬁed model TopRec-Net
behaves like TopRec-M which does not consider social link.
When λ increase, the social regularization term becomes
more inﬂuential on the model and brings the network infor-
mation into the community mining. For Epinions and Ciao,
the performance reaches the peaks at λ = 100. Nevertheless,
if λ becomes increasingly large, the social smoothness term
would overwhelm the rating information which is responsi-
ble for community mining, as well as prior knowledge which
is in charge of topic alignment. As a result, the performance
drops dramatically on the two datasets.

Further Probing on Topic Mining. A key reason for
the performance improvement of TopRec is to utilize semi-
supervised topic model to mine meaningful topics and align

1508e
r
u
s
a
e
m
-
F

e
r
u
s
a
e
m
-
F

number of expert in each domain

(a) Epinions

number of expert in each domain

(b) Ciao

Figure 6: Topic mining results of TopRec-Net under
expert guidance.

them with communities. Here we would like to probe further
how the topic mining works.

In our framework, community topic mining is posed as
an intermediate step and resulting topical communities are
used in domain-speciﬁc recommendation. The ultimate goal
of topic mining for communities is to discover interpretable
topics for each user. Yet, it is rather diﬃcult to get a good
topical summary for community by a pure unsupervised top-
ic model. Hence, we resort to semi-supervised topic model-
ing, in which expert guidance is the critical component de-
ciding whether the model can derive desired user clustering
results.

To analyze the performance of topic mining, the great-
est challenge is we do not know the true topics interested by
users. However, the topics in our model could be interpreted
by item categories. That is to say, for us ers, the categories of
preferred items in test set are capable to represent their true
labels. After topic mining, a series of predicted topics are
obtained for users. Then we could evaluate mining results
by combining precision and recall with respect to topics. In
Figure 6, F-measure on Epinions and Ciao of TopRec-Net is
presented as a function of the number of expert. Particular-
ly, the number of experts for each domain is chosen from the
range {1, 2, 3, 5, 10}. In implementation, when there is more
than one expert in each domain, their rating distributions
over items are added into the vector c(¯uk, vj ) of Eq.(2). By
viewing the tendency of clustering accuracy along with the
number of experts in each domain, we can see that, more
expert guidance leads to better clustering results.

6. RELATED WORK

In this section, we review related works for recommender
systems with collaborative ﬁltering, especially for model-
based CF approaches. CF can be classiﬁed into two diﬀerent
approaches: memory-based algorithms and model-based al-
gorithms. Memory-based CF algorithm usually search for
the similar users or items to produce a prediction or top-n
recommendation [22, 9]. Although memory-based approach-
es are easy implemented and commonly used in reality, they
are normally limited by highly sparse data [24], since the
similarity cannot be estimated accurately in this case.

In model-based approaches, a compact model employed
machine learning and statistical techniques is trained from
the known ratings. There are many model-based algorithm-

s proposed, such as latent factor models [11, 23], graphical
models [13], clustering models [5, 8], and Bayesian mod-
el [2].One popular latent factor model is low-rank matrix
factorization whose premise is that users’ preferences are
only inﬂuenced by a small number of factors, so it uses low-
rank latent factors to approximate rating data [21, 14, 20].
From the view of matrix completion, the low-rank factor-
ization models are competent in tasks with a large amount
of missing entries. Many evidence have shown that matrix
factorization models outperform other CF approaches.

Recently, several approaches resort to trust-aware collabo-
rative ﬁltering [25, 17, 12] where users are no longer treated
as independent and identically distributed. All these meth-
ods based on common rationale that users are likely to have
similar tastes with their trusted friends in social network-
s. Previous studies manifest that social relations as another
form of user information could alleviate sparsity problem
and improve recommendation accuracy. Most of the exist-
ing social recommendation methods focus on encoding so-
cial network in user proﬁle learning. However, many other
web mining tasks show that when it comes to mining topics
and relationships among objects, network structure are help-
ful [18, 3]. Our work employ the network-regularized topic
modeling into a novel use for user clustering in recommender
systems.

Apart from social relations, other relations such as item-
category could also been incorporated into recommender
systems to make up the lack of rating information. In [32],
an extension of the probabilistic matrix factorization to multi-
domain case is proposed. Through learning a covariance ma-
trix, rating knowledge is transferred across domains adap-
tively. Yang et al. [31] model category-speciﬁc trust cir-
cle from ratings and trust links and formulate multi-faceted
trust network into social matrix factorization. Diﬀerent
with [32], they evaluate the model in each domain without
given the overall performance.

Clearly, we could take advantage of external information
such as user’s trust network and item’s category to compen-
sate the sparse data. On the other hand, there are more
dense patterns or groups in the original rating matrix which
can be uncovered though clustering methods. Traditional
clustering CF models cluster users based on the items they
rated or cluster items based on the users that rated them [5,
24]. However, these models overlook the user-item similari-
ty during clustering procedure. To avoid the shortcomings,
co-clustering models are proposed to map user and item into
clusters simultaneously, and thus each cluster becomes more
dense than the entire rating matrix [8, 27].

In this study, the proposed TopRec model leverages the
power of clustering method and external relations to obtain
domains with explicit topics. In experiments, we have shown
that this combination works well on highly sparse datasets.

7. CONCLUSION

Eﬀectively modeling interest topics for users and accord-
ingly recommending their preferred items are fundamental
issues to all recommender systems. In this paper, we propose
a novel framework, TopRec, jointly exploiting community
topic mining and domain-speciﬁc collaborative ﬁltering for
top-n recommendation task. To construct domains, we inte-
grate expert guidance with social network to establish a u-
niﬁed probabilistic topic model for community topic mining.
Then we utilize the observed user-item ratings across diﬀer-

1509ent domains for collaborative ﬁltering. Experimental results
on two datasets from real-world consumer review websites
have demonstrated that the proposed method produces more
accurate recommendation than other competitors.

8. ACKNOWLEDGEMENT

This work was supported in part by the 973 Program un-
der Project 2010CB327905, by the National Natural Sci-
ence Foundation of China under Grant No. 61170127 and
61070104.

9. REFERENCES

[1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet

allocation. J. Mach. Learn. Res., 3:993–1022, 2003.

[2] J. S. Breese, D. Heckerman, and C. Kadie. Empirical

analysis of predictive algorithms for collaborative ﬁltering.
In Proceedings of the Fourteenth conference on Uncertainty
in artiﬁcial intelligence, pages 43–52, 1998.

[3] D. Cai, Q. Mei, J. Han, and C. Zhai. Modeling hidden

topics on document manifold. In Proceedings of the 17th
ACM conference on Information and knowledge
management, pages 911–920, 2008.

[4] A. Clauset, M. Newman, and C. Moore. Finding

community structure in very large networks. Physical
review E, 70(6), 2004.

[5] M. Connor and J. Herlocker. Clustering items for

collaborative ﬁltering. In SIGIR 2001 Workshop on
Recommender Systems, 2001.

[6] P. Cremonesi, Y. Koren, and R. Turrin. Performance of

recommender algorithms on top-n recommendation tasks.
In Proceedings of the fourth ACM conference on
Recommender systems, 2010.

[7] D. M. Fleder and K. Hosanagar. Recommender systems
and their impact on sales diversity. In Proceedings of the
8th ACM conference on Electronic commerce, pages
192–199, 2007.

[8] T. George and S. Merugu. A scalable collaborative ﬁltering

framework based on co-clustering. In Proceedings of the
Fifth IEEE International Conference on Data Mining,
2005.

[9] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl.

An algorithmic framework for performing collaborative
ﬁltering. In Proceedings of the 22nd annual international
ACM SIGIR conference on Research and development in
information retrieval, pages 230–237, 1999.

[10] T. Hofmann. Probabilistic latent semantic indexing. In

Proceedings of the 22nd annual international ACM SIGIR
conference on Research and development in information
retrieval, pages 50–57, 1999.

[11] T. Hofmann. Latent semantic models for collaborative

ﬁltering. 22(1):89–115, 2004.

[12] M. Jamali and M. Ester. A matrix factorization technique

with trust propagation for recommendation in social
networks. In Proceedings of the fourth ACM conference on
Recommender systems, pages 135–142, 2010.

[13] R. Jin, L. Si, and C. Zhai. Preference-based graphic models
for collaborative ﬁltering. In Proceedings of the Nineteenth
conference on Uncertainty in Artiﬁcial Intelligence,
UAI’03, pages 329–336, 2003.

[14] Y. Koren. Factorization meets the neighborhood: a

multifaceted collaborative ﬁltering model. In Proceedings of
the 14th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 426–434, 2008.

[15] G. Linden, B. Smith, and J. York. Amazon.com

recommendations: item-to-item collaborative ﬁltering.
Internet Computing, IEEE, 7:76 – 80, 2003.

[16] Y. Lu and C. Zhai. Opinion integration through

semi-supervised topic modeling. In Proceedings of the 17th

international conference on World Wide Web, pages
121–130, 2008.

[17] H. Ma, H. Yang, M. R. Lyu, and I. King. Sorec: social

recommendation using probabilistic matrix factorization. In
Proceedings of the 17th ACM conference on Information
and knowledge management, pages 931–940, 2008.

[18] Q. Mei, D. Cai, D. Zhang, and C. Zhai. Topic modeling
with network regularization. In Proceedings of the 17th
international conference on World Wide Web, pages
101–110, 2008.

[19] K. Onuma, H. Tong, and C. Faloutsos. Tangent: a novel,

’surprise me’, recommendation algorithm. In Proceedings of
the 15th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 657–666, 2009.

[20] J. D. M. Rennie and N. Srebro. Fast maximum margin

matrix factorization for collaborative prediction. In
Proceedings of the 22nd international conference on
Machine learning, pages 713–719, 2005.

[21] R. Salakhutdinov and A. Mnih. Probabilistic matrix

factorization. In Advances in Neural Information
Processing Systems, 2008.

[22] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl.

Item-based collaborative ﬁltering recommendation
algorithms. In Proceedings of the 10th international
conference on World Wide Web, pages 285–295, 2001.

[23] L. Si and R. Jin. Flexible mixture model for collaborative

ﬁltering. In Proceedingins of the 20th international
Conference on Machine Learning, pages 704–711, 2003.

[24] X. Su and T. M. Khoshgoftaar. A survey of collaborative

ﬁltering techniques. Advance in Artiﬁcial Intelligence,
pages 4:2–4:2, 2009.

[25] J. Tang, H. Gao, and H. Liu. mtrust: discerning

multi-faceted trust in a connected world. In Proceedings of
the ﬁfth ACM international conference on Web search and
data mining, pages 93–102, 2012.

[26] R. Wetzker, W. Umbrath, and A. Said. A hybrid approach
to item recommendation in folksonomies. In Proceedings of
the WSDM ’09 Workshop on Exploiting Semantic
Annotations in Information Retrieval, pages 25–29, 2009.

[27] B. Xu, J. Bu, C. Chen, and D. Cai. An exploration of

improving collaborative recommender systems via user-item
subgroups. In Proceedings of the 21st international
conference on World Wide Web, pages 21–30, 2012.

[28] S.-H. Yang, B. Long, A. Smola, N. Sadagopan, Z. Zheng,
and H. Zha. Like like alike: joint friendship and interest
propagation in social networks. In Proceedings of the 20th
international conference on World wide web, pages
537–546, 2011.

[29] S.-H. Yang, B. Long, A. J. Smola, H. Zha, and Z. Zheng.
Collaborative competitive ﬁltering: learning recommender
using context of user choice. In Proceedings of the 34th
international ACM SIGIR conference on Research and
development in Information Retrieval, pages 295–304, 2011.

[30] T. Yang, R. Jin, Y. Chi, and S. Zhu. Combining link and

content for community detection: a discriminative
approach. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data
mining, pages 927–936, 2009.

[31] X. Yang, H. Steck, and Y. Liu. Circle-based

recommendation in online social networks. In Proceedings
of the 18th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 1267–1275,
2012.

[32] Y. Zhang, B. Cao, and D.-Y. Yeung. Multi-domain

collaborative ﬁltering. In Proceedings of the Twenty-Sixth
conference on Uncertainty in artiﬁcial intelligence, pages
725–732, 2010.

1510