The Cost of Annoying Ads

Daniel G. Goldstein
Microsoft Research, NYC

102 Madison Ave., 12th Floor

New York, NY 10016

dgg@microsoft.com

R. Preston McAfee

Google Strategic Technologies
1600 Amphitheatre Parkway
Mountain View, CA 94043
preston@mcafee.cc

Siddharth Suri

Microsoft Research, NYC

102 Madison Ave., 12th Floor

New York, NY 10016
suri@microsoft.com

ABSTRACT
Display advertisements vary in the extent to which they an-
noy users. While publishers know the payment they receive
to run annoying ads, little is known about the cost such
ads incur due to user abandonment. We conducted a two-
experiment investigation to analyze ad features that relate
to annoyingness and to put a monetary value on the cost
of annoying ads. The ﬁrst experiment asked users to rate
and comment on a large number of ads taken from the Web.
This allowed us to establish sets of annoying and innocuous
ads for use in the second experiment, in which users were
given the opportunity to categorize emails for a per-message
wage and quit at any time. Participants were randomly as-
signed to one of three diﬀerent pay rates and also randomly
assigned to categorize the emails in the presence of no ads,
annoying ads, or innocuous ads. Since each email catego-
rization constituted an impression, this design, inspired by
Toomim et al. [18], allowed us to determine how much more
one must pay a person to generate the same number of im-
pressions in the presence of annoying ads compared to no
ads or innocuous ads. We conclude by proposing a theo-
retical model which relates ad quality to publisher market
share, illustrating how our empirical ﬁndings could aﬀect the
economics of Internet advertising.

Categories and Subject Descriptors
J.4 [Social and Behavioral Sciences]: Economics

General Terms
Economics, Experimentation

Keywords
display, advertising, quality, compensating diﬀerential

1.

INTRODUCTION

Display advertising is the prevalent way for publishers to
monetize content on the Web. Publishers receive payment
from advertisers for placing ads near their content or in their
applications. Payments can be determined by a contract or
a real-time auction. In either arrangement, publishers are
typically paid by the number of impressions they can deliver.
Thus, they have an incentive to attract and retain users with

Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW 2013, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

valuable content, experiences, and applications, and have a
disincentive to lose users due to annoyances.

Display ads vary in the extent to which they annoy users.
Annoying ads are a source of tension for publishers since
they both make money, through payments from advertisers,
and cost money, through a decrease in page views due to
users abandoning the site. This tension has led to conﬂict
within publishing organizations between salespeople, who
have an incentive in the form of commission to sell any ads,
and management, who are concerned with long-term growth
of users and traﬃc. The continued long-term display of an-
noying ads may exert negative eﬀects on the publisher, the
user, and the advertiser, which we discuss in turn.

First, annoying ads can exert negative eﬀects on publish-
ers. Apart from the user abandonment eﬀects we investigate
in this paper, annoying ads might signal that the website on
which the ad is placed on lacks stability (“Why should I
trust my email to a site that is so desperate for cash it ac-
cepts ads of such poor quality?”), reputability (“Why should
I trust the objectivity of a site that is so in the pocket of
advertisers it won’t refuse any of them?”), or safety (“Why
would I trust this publisher to protect me from phishing
attacks, scams, malware, etc. if they are so indiscriminate
about who they let advertise?”).

Second, annoying ads can exert a negative impact on users.
Ads with excessive animation can get in the way of the user
consuming the publisher’s content, undermining the very
reason that brought them to the site. In what follows, we
document users reporting that annoying ads distract them.
Furthermore, we provide experimental evidence that annoy-
ing ads impair accuracy on a cognitive task.

Finally, annoying ads may harm the advertiser that cre-
ated them. As will be shown, annoying ads are often charac-
terized by exaggerated attempts to capture visual attention
such as through fast-moving animation or bizarre imagery.
While these manipulations do capture attention, they may
also signal that the advertiser is desperate for business or
low on resources, undermining the classical signal of quality
that advertising is theorized to bring [15]. Furthermore, ex-
periments have shown that too much animation can result
in lower ad recognition rates compared to ads with moder-
ate or no animation [21, 2].
In these ways, annoying ads
may actually lower brand reputation and recall, two metrics
advertisers typically strive to increase.

If annoying ads exhibit so many negative eﬀects for pub-
lishers, users and advertisers, one may wonder why a pub-
lisher would run annoying ads at all. The answer may be
that it is has been historically diﬃcult to measure the mon-

459etary cost of annoying ads. The ﬁrst and main contribution
of this work is that we measure the compensating wage dif-
ferential of annoying ads. That is, we measure how much
more one must pay a user to do the same amount of work
in the presence of annoying ads compared to innocuous ads
or no ads. The compensating diﬀerential is important to
measure because it captures some of the negative eﬀects of
advertising, which publishers need to heed as a lower bound
when setting the price to run an ad.

In a two-experiment investigation, we compute the com-
pensating diﬀerential for annoying ads. In the ﬁrst exper-
iment users randomly rated either an animated ad or its
static counterpart. This design shows that animation has a
negative impact on user ratings. For those ads that users
rate as annoying we ask them to explain their thinking. An
analysis of the ratings and comments yields a better of un-
derstanding of what users ﬁnd annoying about these ads.
This analysis will also exhibit how annoying ads negatively
aﬀect user perceptions of advertisers. These analyses are
additional contributions of this work.

In the second experiment, we use those ads identiﬁed as
more or less annoying, along with the recent methodolog-
ical innovation of Toomim et al. [18], to estimate the pay
rate increase necessary to generate an equal number of page
views in the presence of annoying ads, compared to innocu-
ous ads or no ads. This estimate is the cost of annoying
ads in our experiment. We chose categorizing emails as the
task to proxy for using a publisher’s site because users ei-
ther implicitly or explicitly need to categorize their emails
as spam or not spam in the presence of ads when using free
web-based email services such as Yahoo! Mail, GMail, and
Mail.com. Finally, we provide a theoretical model of how
our empirical ﬁndings could aﬀect the display advertising
industry, which is the third contribution of this work.

2. RELATED WORK

As mentioned in Section 1, we use the methodological in-
novation of Toomim et al. [18] for computing compensating
diﬀerentials. Toomim et al. conducted a Mechanical Turk
experiment in which participants randomly experienced an
easy, medium, or hard version of a task at a randomly as-
signed pay rate. This allowed the authors to compute how
much more one would have to pay a worker to do the hard
task over the medium and easy tasks. The authors also ex-
hibited this technique in an experiment in which participants
were randomly assigned to use either an “ugly” or a “pretty”
interface to do a task. We will use this technique to isolate
the eﬀect of the ad quality on user abandonment. Next, we
describe prior experimental work which studies the impact
of ad quality on behavior.

Dreze and Hussherr [4] conducted an experiment on the ef-
fectiveness of display advertisements using eye-tracking tech-
nology. Their conclusion, that users rarely focus directly on
banner ads, is often referred to as banner blindness, a term
coined by Benway [1]. Burke et al. [2] had participants per-
form visual search tasks in the presence of no ads, a static
display ad, or an animated display ad. They found that ads
did reduce search time, however, there was no signiﬁcant
diﬀerence between animated and static ads. Perhaps even
more surprisingly, they did a post hoc test which found that
animated ads were remembered less frequently than static
ads.

Yoo and Kim [21] asked a similar research question. They
conducted a larger-scale laboratory experiment in which par-
ticipants were randomly exposed to web pages with ads with
no animation, slow-moving animation or fast-moving anima-
tion. They found that more animation did increase attention
to ads. Moreover, moderate animation increased ad recogni-
tion rates and brand attitudes. Highly animated ads, how-
ever, decreased recognition rates and brand attitudes. This
result complements the results of Burke et al. [2]. Yoo and
Kim [21] conclude that, “Web advertisers should be aware of
the possibility that excessive animation can backﬁre against
the original intention of eﬀective communication.”

Goldfarb and Tucker [5] conducted a ﬁeld experiment in
which they found that ads that matched the site’s content or
ads that were intrusive increased participant’s self-reported
intent to purchase. However, ads that were both intru-
sive and matched the website’s content reduced intent to
purchase. Ads were considered intrusive if, for example,
they produced a popup window, took over the whole screen,
played music, or obscured the web page text. The authors
suggest that the reason for this interaction eﬀect is that
users are more sensitive to targeted and intrusive ads when
the product advertised is privacy sensitive. In the context
of sponsored search, Buscher et al. [3] found that ads that
are relevant to the search terms received more visual atten-
tion than ads that were less relevant. This complements the
results of Goldfarb and Tucker [5] which were found in the
domain of display advertising.

Taken as a whole, these studies suggest there may be ben-
eﬁts to a small degree of animation or intrusiveness in ad-
vertising, but that too much animation or intrusiveness can
have a detrimental impact on the ad eﬀectiveness.

3. RATING THE QUALITY OF ADS

We next describe our experiments, both of which were
conducted on Amazon’s Mechanical Turk1, an online labor
market. Since it was originally built for jobs that are dif-
ﬁcult for computers but are easy for humans (e.g., image
recognition), jobs on Mechanical Turk are called Human In-
telligence Tasks or HITs. There are two types of people
on Mechanical Turk: requesters and workers. Requesters
can post HITs and workers can choose which HITs to do
for pay. After a worker submits a HIT, the requester can
either accept or reject the work based on its quality. The
fraction of HITs that a worker submits which are accepted
is that worker’s approval rating. This functions as a rep-
utation mechanism. The Amazon API gives each worker
account a unique, anonymous identiﬁer. By tracking the
IDs of the workers who accepted our HITs, we could enforce
that participants were only allowed to participate in one of
the two experiments, and they were only allowed to do that
experiment one time.

There is a burgeoning literature on conducting behavioral
experiments on Mechanical Turk [12, 11, 16, 6, 7, 20, 13, 9,
17]. In this setting, the experimenter takes on the role of the
requester and the workers are the paid participants of the
experiment. Mason and Suri [10] provide a how-to guide for
conducting behavioral experiments on Mechanical Turk. We
now describe the design and results of our ﬁrst experiment,
which served to identify sets of more and less annoying ads

1http://www.mturk.com

460(henceforth “bad ads” and “good ads” for brevity) for use in
the second experiment.
3.1 Method

The goal of this experiment is to rank a set of actual
display ads in terms of annoyingness and to collect reasons
why people ﬁnd certain ads annoying. The preview page of
the HIT explained that workers would ﬁrst browse through
all of the ads in the experiment and then rate them one by
one. After accepting the HIT, participants were shown 9
pages of ads, with 4 ads per page, and instructions to take
a quick look at each page. This was done to familiarize
respondents with the items they would ultimately rate to
reduce random order eﬀects in their later use of a rating
scale. This was also done so that participants could calibrate
their use of the rating scale [14]. Next, users were shown
each ad individually, again in random order, and asked to
rate each ad on a 5-point scale with the following levels:

1. Much less annoying than the average ad in this exper-

iment

2. A bit less annoying than the average ad in this exper-

iment

3. Average for this experiment

4. A bit more annoying than the average ad in this ex-

periment

5. Much more annoying than the average ad in this ex-

periment

After rating every ad on this scale, participants were then
shown only the ads they rated as annoying (i.e., “A bit more
annoying than the average ad in this experiment” or “Much
more annoying than the average ad in this experiment”) and
asked to write a few words as to why they found the ad
annoying.

We used a pool of 144 ads, 72 of which were skyscrapers
(either 120 or 160 pixels wide by 600 pixels high) and 72 of
which were medium rectangles (300 pixels wide by 250 pix-
els high). The ads primarily came from Adverlicious2, an
online display advertising archive. A worker was randomly
assigned to either see all skyscrapers or all medium rectan-
gles. The 144 ads used in the experiment were created from
72 animated ads, from which we created an additional 72
static variants by taking a screenshot of each animated ad’s
ﬁnal frame. The animation in display ads typically lasts
only a few seconds and then settles into a ﬁnal frame which
serves as a static ad for the rest of the time the ad is in view.
The ﬁnal frame is usually a good representation of the ad
since it often shows the advertiser name with the same gen-
eral design, creative, and color scheme as the animated part.
This technique, which resulted in 72 animated/static pairs,
allowed us to study the eﬀect of animation on annoyance,
holding all other properties of the ads constant. For each
ad pair, workers were randomly assigned to see either the
static or animated variant. Since this random assignment
was done per pair, each participant saw a mixture of both
animated and static ads.

We paid each worker a $0.25 ﬂat rate and a bonus of
$0.02 per ad rated. Since we had users input free text, we
2http://adverlicio.us

Category
Animation
Attentional Impact
Aesthetics
Reputation
Logic

Example Words
move, motion, animate
annoy, distract, attention
ugly, busy, loud, cheap
scam, spam, fake
sense, weird, stupid

Count
771
558
435
122
107

Table 1: Categorization of words found in the par-
ticipants’ comments on the ads they found annoying

used the Amazon API to restrict to U.S. workers to help
ensure a good grasp of the English language. We also used
the Amazon API to require workers have at least a 95%
approval rating.

3.2 Results

The experiment ran for 18 hours and collected responses
from 163 participants. We excluded participants who skipped
more than one question, leaving 141 participants. Though
this exclusion makes little diﬀerence in the results, we felt
it best to only compare the ratings of people who rated a
similar number of items, as ratings may change as a function
of the number of items previously rated. The distribution
was rather symmetric with an average rating of 2.9 on the
ﬁve point scale. Since a rating of 3 corresponds to “Aver-
age for this experiment”, the participants’ ratings were well
calibrated to our instructions.

Recall that we started with 72 ads and created static vari-
ants of each, resulting in the 144 ads in this experiment.
Figure 1 (top) shows the average rating of each ad sorted
from most annoying to least annoying. This plot shows the
quite striking eﬀect of animation on annoyance: the 21 most
annoying ads were all animated, and the 24 least annoying
ads were all static. This is further exempliﬁed in Figure 1
(bottom) in which each animated ad is compared to its static
variant. Here, the pairs are sorted by the annoyingness of
the animated variant and the static version is placed at the
same x-coordinate as its animated counterpart. The static
versions tend to fall below the animated versions, often by
several standard errors or more than one rating point. Put
another way, we did not observe a case where animation sig-
niﬁcantly improved an ad on this annoyingness scale. Since
the advertisers and products are held constant within each
pair, it seems that animation alone is a cause of annoyance.
As mentioned, the 10 most and least annoying ads iden-
tiﬁed in this experiment will serve as the sets of “bad” and
“good” ads in the next experiment which is described in Sec-
tion 4. Figures 2 and 3 show examples from these two sets.
Recall that each participant who rated an ad as either “A
bit more annoying than the average ad in this experiment”
or “Much more annoying than the average ad in this experi-
ment”, was asked to write a few words as to why they found
that ad annoying.
In all there were 1846 such responses
from the 141 respondents. First, we manually constructed
a set of categories to characterize these reasons based on a
5% sample of the comments. We then analyzed the entire
corpus treating each response as a bag of words. We looked
at all words that occurred at least 10 times (excluding “stop
words”), and assigned them to a relevant category. Then,
for each category, we totaled up the number of times the
words in that category appeared in the bag. The results are
shown in Table 1.

4615

4

3

2

5

4

3

2

g
n

i
t

a
r
 
s
s
e
n
g
n
y
o
n
n
a

i

 

n
a
e
M

g
n

i
t

a
r
 
s
s
e
n
g
n
y
o
n
n
a

i

 

n
a
e
M

0

0

50
Ads ranked by annoyingness

100

Ad Type

animated
static

Ad Type

animated
static

Ad pairs ranked by annoyingness of the animated variant in each pair

60

20

40

Figure 1: The top panel ranks ads by annoyingness and shows that the 21 most annoying ads were animated
and the 24 least annoying ads were static. The bottom panel ranks pairs of ads by the annoyingness of the
animated variant. The static variants tend to fall below their animated versions, suggesting that animation
increases annoyingness, even when the advertiser and product are held constant. Error bars are ± 1 standard
error.

462(a)

(a)

(b)

(b)

Figure 2: Two examples of “bad” ads. Figure 2(a)
is a medium rectangle whereas Figure 2(b) is a
skyscraper. In the animated version of Figure 2(a)
the woman’s arm rapidly moves up and down. Sim-
ilarly, in Figure 2(b) the snake writhes wildly, sticks
its tongue out, and pulses its eyes red.

This rudimentary text analysis shows that the most fre-
quent topic was the animation of the ad, e.g., “too much
movement”. The next most common topic was the ad’s dele-
terious eﬀect on user attention, e.g., “it diverts my attention
from what is important; the content on the page”. The third
most common topic was the aesthetic of the ad, e.g., “an-
other cheap looking ad that I would never click.” This leads
to the fourth most common complaint. These poor aesthet-
ics would often lead people to believe the ad is a scam, e.g.,
“seems like a scam with a cheap design”. Finally, many of the
ads had a graphic that did not logically relate to the product
such as a dancing wizard in an ad for online classes. This
type of non sequitur also bothered users, e.g., “A dancing
wizard has nothing to do with going to school.”

We list here two observations from this analysis. First, the
reasons listed above span the costs to the user, publisher and
advertiser mentioned previously. Complaints about move-
ment or animation and how they distract from the content
show there is a cost to users and publishers. In addition,
users were skeptical of aesthetically unappealing or illogical
creatives, suggesting that annoying ads also have a cost for
advertisers. Second, the chief complaint was about anima-
tion, which corroborates our ﬁnding that animation exerts
a causal inﬂuence on annoyance.

4. MEASURING THE COST OF ADS

As seen in the previous section there might be a variety
of attributes of an ad that a user might ﬁnd annoying. If
we view attributes of an ad as residing in a multidimen-
sional space, the average ratings of the previous section are
how users project of that multidimensional space onto a one-
dimensional annoyingness scale. Thus, we use the method of
Toomim et al. [18] along with ads from each end of this an-
noyingness scale as sets of “bad” and “good ads” to measure
the cost of annoying ads.

Figure 3: Two examples of “good” ads.

4.1 Method

The participants were 1223 Mechanical Turk workers with
at least a 90% approval rating who participated for a base
pay of 25 cents and a bonus, which was not disclosed before
the HIT was accepted to prevent selection eﬀects. The ex-
periment was advertised as an email classiﬁcation task and
ran for a period of two weeks. Upon accepting the HIT,
participants were randomly assigned to one of nine condi-
tions: three pay conditions and three ad conditions. The
pay conditions oﬀered a bonus of one, two, or three cents
per ﬁve emails classiﬁed (i.e., .2, .4, or .6 cents per email),
and the ad conditions varied whether “bad ads”, “good ads”,
or no ads were displayed in the margin as the task was com-
pleted. No mention was made of pay conditions, ad con-
ditions or random assignment, and a search on turkerna-
tion.com, a discussion forum for Mechanical Turk workers,
found no mention of either experiment. A chi-squared test
found no signiﬁcant diﬀerence in the number of participants
beginning work across the nine conditions.

In all conditions, the task consisted of classifying the con-
tent of emails as “spam”, “personal”, “work” or “e-commerce”
related. Emails were drawn from the public-domain Enron
email dataset3 with one email presented per page, along with
accompanying ads, if any. In the “bad ads” condition, two
ads randomly drawn from the 10 most annoying ads in our
ﬁrst experiment were displayed in the margins around the
email being classiﬁed. Figure 4 is a screenshot of the bad ads
condition. The “good ads” condition was the same, except
the ads were drawn from the 10 least annoying ads. In both
conditions, ads were drawn randomly from their respective
pools with each page load, and the urls for the ads were such
that ad blocking software would not ﬁlter them out. The “no
ads” condition simply had whitespace in the margin. The
width of the page and text area was held constant across
conditions and chosen so that it would be visible to the vast
majority of Web browsers.

3http://www.cs.cmu.edu/~enron/ Identifying information
such as email addresses, phone numbers and the name “En-
ron” were removed.

463464465(Intercept)

Impressions

Good ads

No ads

Pay rate

Good ads or no ads

Model 1 Model 2
∗∗∗

∗∗∗

0.90
(0.01)
∗∗∗−7.8e−5
(0.00)

∗∗∗

0.90
(0.01)
−7.8e−5
(0.00)
∗∗
0.02
(0.01)
0.03
(0.01)
0.14
(0.43)

∗∗∗

0.14
(0.43)
0.02
(0.01)

∗∗∗

Number of observations
***
p <0 .05, *

p < 0.01, **

1057

1057

p < 0.1

Table 3: Linear regression of classiﬁcation accuracy
on impressions, ad condition, and pay rate. Ex-
cludes participants who classiﬁed no emails, as their
accuracy is undeﬁned. Pay rate is in dollars per ﬁve
impressions. Standard errors are in parentheses.

the function R would be:

R(A) = max

S

(cid:2)

i∈S

(cid:2)

i∈S

ai ≤ A.

ri subject to

This function is poorly behaved since it has ﬂat spots and
jumps. Moreover, the selection of ads is equivalent to the
knapsack problem and thus NP-hard. Nevertheless, since it
is very unlikely that showing a single ad would maximize
the revenue of the advertiser, the greedy algorithm (which
displays the ads from highest to lowest by the ratio of ri/ai
until the user cost approaches A) involves at worst the per-
centage loss in ﬁlling A, and thus is small when A is large
relative to the individual ads, as in our context. This ap-
proximate solution has the property that R is non-decreasing
and approximately concave, as assumed.

We simplify the problem by considering a diﬀerentiable R,
which may be thought of as the consequence of an inﬁnite
number of very small ads. In our setting, the assumption
of many small ads is more plausible than in many economic
settings simply because ad space per user generally sells for
less than a U.S. penny.

Without loss of generality we can model the publisher as
selecting A and u, with v = u+A determining v. Let c(v) be
the cost of content to the publisher; it is assumed increasing
and convex. Then the publisher’s net proﬁt for a given value
of u is,

π(u) = max

A

R(A) − c(u + A)

∗
The ﬁrst order condition for the optimal value A

is,

(cid:4)

0 =R

(A

∗

) − c

(cid:4)

∗
(u + A

).

The concavity of R and assumed convexity of c ensure that
the function R(A) − c(u + A) is concave in A, and thus any
interior solution of the ﬁrst order conditions is a global max-
imum4. Moreover, diﬀerentiating the ﬁrst order conditions
4We will focus only on interior solutions, but the analysis
= 0 or u +
readily generalizes to the border cases when A

∗

gives,

∗

dA
du

=

R

(cid:4)(cid:4)
∗
(u + A
c
∗) − c
(cid:4)(cid:4)(A

(cid:4)(cid:4)(u + A

)

∗)

∈ (−1, 0)

The function π has the following property by the envelope
theorem,

(cid:4)

π

(u) = −c
(cid:3)

(cid:4)

∗
(u + A

) < 0.

(cid:4)

∗

Diﬀerentiating this gives,
∗
(u + A

(u) =c

π

(cid:4)(cid:4)

(cid:4)(cid:4)

)

(cid:4)

(cid:3)
1 + dA
du
(cid:3)

1 +

(cid:4)(cid:4)(A

R

)

(cid:4)
(cid:4)(cid:4)(u + A
∗)

(cid:4)(cid:4)
∗
(u + A
c
∗) − c
(cid:4)(cid:4)(A
R
∗
(cid:4)(cid:4)
(A
)
R
∗) − c
(cid:4)(cid:4)(u + A

∗)

(cid:4)(cid:4)

∗
(u + A

)

(cid:4)(cid:4)

∗
(u + A

)

= −c
= −c
< 0

∗

Thus π is decreasing and concave. Provided there is no
upper bound on advertising or on content value, any u can
be accommodated.
Let x(t) ∈ [0, 1] be the publisher’s market share at time t.
We will suppress the time dependence for clarity but note
be a reference
that x and u are both time dependent. Let u
utility level—think of it as the utility oﬀered by imperfect
substitute products. If there is only one rival oﬀering a com-
petitive product it would certainly react to changes in u. In
this case we are modeling the beneﬁt the publisher would
receive before the competitor has time to react. If the sub-
stitute is competitively supplied, however, then we can take
∗
as a given, since the competition has already been forced
u
it to its optimum value. We suppose that the process deter-
mining consumers switching to alternative services depends
on the net utility oﬀered, according to the logistic equation
(1)
This equation is commonly used in population growth be-
cause population growth depends on the existing population
x (in our context, this might be the word of mouth of ex-
isting users inﬂuencing adoption), the fraction of non-users
1 − x who can be converted, the speed λ at which they con-
vert, and the diﬀerence in net utility u− u
. This functional
form also arises through the replicator dynamics [8].

(t) =λ (u − u
∗

)x(1 − x).

x

∗

(cid:4)

Rewriting Equation 1, we can think of the publisher as

(cid:4)
choosing the share growth x

, which dictates user utility

u = u

∗

+

(cid:4)

x

λx(1 − x) .

The publisher’s ﬂow revenue is xπ(u). Let r be the interest
rate facing the publisher. The publisher maximizes present
discounted which is

(cid:4)

(cid:5) ∞

(cid:3)

(cid:5) ∞

−rt

0

e

xπ(u)dt =
Theorem 1. If − r
λ
∗
share converges to x
ket share is given by

(cid:4)

x

−rt

e

xπ

∗

u

+

λx(1 − x)

dt.

0
π(u∗) ≥ 1, the publisher’s market
π(cid:2)(u∗)
= 0. Otherwise, the terminal mar-

∗

x

= 1 + r
λ

(cid:4)

∗
(u
)
π
∗) .
π(u

∗

= 0. Indeed, the only properties used of π are that it is
A
decreasing and concave, both of which are preserved in the
border cases.

466of complaints about annoying ads providing a ﬁrst pass at
identifying undesirable features. We used the good and bad
ads from this study to measure the compensating wage dif-
ferential in the second study. The main result of this pa-
per is that annoying ads lead to site abandonment and thus
fewer impressions than good ads or no ads. In what might
be seen as good news for publishers, good ads and no ads
led to roughly equal numbers of impressions. Annoying ads
impaired people’s ability to carry out an email classiﬁcation
task, suggesting that annoying ads have a real cost to users
beyond mere annoyance. Finally, we provided a theoretical
model that computes a dynamic equilibrium, which permits
studying not only properties of the steady state, but the ad-
justment to that state as well. This model can be used to
understand the behavior of legacy publishers, who inherited
a large market share, in the face of competition from new
entrants.

We calculated the compensating wage diﬀerential in our
experiment of bad ads to no ads to be $1.53 CPM, bad
ads to good ads to be $1.15, and good ads to no ads to be
$.38 CPM. Some care must be taken in interpreting these
numbers. While we picked a task—classifying emails—that
should be familiar and common for most internet users, this
task may not be representative of other internet tasks like
reading news stories or searching for products to purchase.
Abandonment rates may diﬀer with diﬀerent tasks and the
eﬀects of advertising may vary as well. While virtually ev-
ery web service features competition, the switching costs
vary from very low in consuming news to relatively high in
changing email services. Because our users on Mechanical
Turk have an outside option of working on an alternative
HIT, we expect our results to be most applicable to sit-
uations involving lower switching costs. Nevertheless, we
expect that our ﬁnding that annoying ads cost the user at
least $1 CPM over more pleasant ads will be obtained in
some other environments.

For these reasons, we suggest further studies be done on
Mechanical Turk, as ﬁeld experiments, and in laboratories
to measure this diﬀerential on similar and diﬀerent tasks. If
studies across various domains with a variety of tasks and
outside options arrive at similar diﬀerentials, more credence
can be placed on these numbers. We view this work as a
ﬁrst step in this direction. If future work arrives at similar
estimates across a variety of publishers, such estimates could
serve as a useful lower bound for what a publisher should
charge to run these ads. Moreover, it will be valuable to use
the compensating diﬀerentials approach to price the various
bad aspects of ads, including animation and poor aesthetics.
This work also suggests a variety of policy recommenda-
tions. Most directly, the $1 CPM user cost of bad ads has
practical consequences for publishers, especially as bad ads
often command lower CPMs. It is a reason that publishers
should insist on a substantial premium for annoying adver-
tisements. Moreover, a publisher could randomize which
users see which ads and track both time spent on the page
and the frequency with which users return to the site. This
type of experimentation would capture longer term eﬀects of
annoying ads than those studied here. Also, publishers could
give users an option to close or replace an ad. A replace-
ment event would allow the publisher to infer that a user
would prefer a random ad over the ad currently shown. Ad-
vertisers with a high closure rate should be charged more.
Furthermore, it would be reasonable to assume that more

Figure 7: Phase diagram relating market share to
user utility as described by Theorem 1

∗

∗

In addition, if x < x
creasing over time. If x > x
time.

∗

, then user utility u > u

∗

and is de-
and is increasing over

, u < u

∗

, u

The proof of this theorem is given the in Appendix. The
solution is illustrated in the phase diagram given in Figure 7.
The equilibrium for any starting market share x involves the
∗
). The value of u adjusts to put
path pointing toward (x
the publisher on this path. Starting with a low market share,
the publisher sets a high user utility which is a combination
of low advertising and high content quality, and then gradu-
ally degrades user utility and increases advertising intensity.
In contrast, a publisher who starts with a high market share
will set a very low content quality and high advertising in-
tensity, and then gradually improve the user experience. An
, the asymptotic
increase in the interest rate decreases x
in-
market share. An increase in the competitive level u
creases x

when π is log-convex and vice-versa.

∗

∗

∗

There are several conclusions one can draw from this model.
First, since the terminal market share predicted in Theo-
rem 1 depends on π, which depends on A and u, the model
justiﬁes the ratio of the revenue to user cost as the key metric
for advertising selection. Second, in a competitive advertis-
ing market, all ads will sell for a constant times the user cost.
Annoying ads will run only when their revenue is very high
or the publisher is extremely willing to sacriﬁce user expe-
rience for revenue. Third, a legacy publisher, whose market
share is large because they initially faced little competition,
will start with a lower user experience involving both more
ads and worse content than an entrant. This will result in
the legacy publisher seeing a fast decline in user base. The
legacy publishers content will gradually improve until a sta-
ble point is reached. Finally, if consumers react suﬃciently
slowly to changes in content (that is, λ is small), a legacy
publisher will gradually go extinct rather than oﬀer a better
user experience.
6. CONCLUSION

The ﬁrst study reported here showed that people ﬁnd ani-
mated advertisements more annoying than static ones, hold-
ing all else constant. This study also identiﬁed ﬁve categories

467annoying ads would be closed or replaced faster than less
annoying ads. Ad replacement would help the user by re-
moving the annoying ad and the publisher by making it pos-
sible to charge for two impressions.

7. ACKNOWLEDGMENTS

We thank Randall A. Lewis, Justin M. Rao, and David H.

Reiley for helpful conversations.

APPENDIX
In this section we give the proof of Theorem 1.

(cid:6)

(cid:7)

(cid:4)

x
1−x

Proof. Deﬁne y = log
x(cid:2)

. Note, y
1+ey . Furthermore, 1 + e

1−x =
x(1−x) , and x = ey
1−x =
1
1−x . Thus we can reformulate the publisher’s optimization
dt.
problem as that of maximizing
1+ey π
∗
, t) = e
. The Euler equation
Let F (y, y
u
for this problem is

x + x(cid:2)
= x(cid:2)
y = 1 + x
(cid:9)
(cid:4)(cid:10)

0 e
+ 1
λ y

(cid:8) ∞

+ 1
λ y

−rt ey

−rt ey

1+ey π

(cid:4)(cid:10)

(cid:9)

u

∗

(cid:4)

(cid:4)

(cid:4)

0 = ∂F
∂y
−rt

= e

− d
dt
e

∂F
(cid:4)
∂y
y

(cid:3)

(cid:4)

∗

+

(cid:3)

1
λ
∗

(cid:4)

y

e

y

u

−rt

(1 + ey)2 π
− 1
d
e
+
u
λ
dt
−rt[λ(1 − x)π (u) +rπ
(cid:4)
)(1 − x) − π
(u) λ(u − u
∗

1
λ
(u)

1 +e y π

−π

y

e

(cid:4)

(cid:4)

= x
λ

(cid:4)(cid:4)

(u) u

(cid:4)

]

Thus,
(cid:4)(cid:4)
(cid:4)
(u)u

(cid:4)

= λ(1 − x)π(u) +rπ
and 0 = λ(1− x

(u) − λ(u − u
π
A steady state of the system holds when x
u = u
to

∗
)π(u

) + rπ

)(1 − x)π
= u

(u).
= 0, or
). This is equivalent

(u

∗

∗

∗

∗

(cid:4)

(cid:4)

(cid:4)

(cid:4)

1 − x

∗

= − r
λ

(cid:4)

∗
(u
)
π
∗) .
π(u

λ

If − r

π(cid:2)(u∗)
π(u∗) ≥ 1, all optimal paths involve x → 0 as there
π(cid:2)(u∗)
π(u∗) < 1, there is
= 0 curve occurs when
)(1 − x)π
(u) . Thus,

is no internal steady state. When − r
an interior steady state. The u
(u) − λ(u − u
0 = λ(1 − x)π (u) + rπ
∗
near (x

, u

),

∗

∗

λ

(cid:4)

(cid:4)

(cid:4)

u(cid:2)=0 =
=

λπ(u)−λ(u−u∗)π(cid:2)(u)

λ(1−x)π(cid:2)(u)+rπ(cid:2)(cid:2)(u)−λ(1−x)π(cid:2)(u)−λ(u−u∗)(1−x)π(cid:2)(cid:2)(cid:2)(u)
+rπ(cid:2)(cid:2)(u)−λ(u−u∗)(1−x)π(cid:2)(cid:2)(cid:2)(u) ≈ λπ(u∗)

λπ(u)−λ(u−u∗)π(cid:2)(u)

rπ(cid:2)(cid:2)(u∗) < 0.

(cid:11)(cid:11)

du
dx

We can obtain insight about the paths near this solution
by a ﬁrst order Taylor approximation. The strategy looks
like this. Write

λ(1 − x) π(u)

π(cid:2)(cid:2)(u) + r

)x(1 − x)
λ(u − u
∗
π(cid:2)(cid:2)(u) − λ(u − u
π(cid:2)(u)

∗

)(1 − x) π(cid:2)(u)
π(cid:2)(cid:2)(u)

(cid:13)

(cid:11)(cid:11)

1
t

∂Ψ
∂Δ

(cid:12)
(cid:3)
(cid:12)

(cid:4)

=

(cid:4)

=

≈

(cid:3)

(cid:3)

(cid:4)
x
(cid:4)
u

(cid:4)
x
(cid:4)
u

(cid:4)

.

g(x, u)
h(x, u)

∂g/∂x
∂h/∂x

∂g/∂u
∂h/∂u

(cid:13)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)

(x,u)=(x∗,u∗)

(cid:3)

(cid:4)

.

x − x
∗
u − u
∗

Thus, it pays to increase a convergent x if and only if x < 1−
π(cid:2)(u∗)
π(u∗) , implying that this is only candidate for convergent
paths when − r

π(cid:2)(u∗)
π(u∗) < 1.

r
λ

λ

Locally the behavior of the general system is approximated
by the behavior of the linear system. The only challenging
term in the matrix is

(cid:11)(cid:11)(cid:11)(cid:11)

∂h
∂u

u=u∗,x=x∗

λ(1 − x) π (u)
(cid:4)(cid:4) (u)

∗

= ∂
∂u
−λ(u − u
(cid:3)

= −λ(1 − x
1 − π

+r

∗

= r

(cid:4)
(u)
(cid:11)(cid:11)(cid:11)(cid:11)
π
+ r
(cid:4)(cid:4) (u)
π
π
(cid:4)
)(1 − x) π
(u)
(cid:4)(cid:4) (u)
π
(cid:4)(cid:4)(cid:4)
∗
∗
) π (u
)
(u
) π
(cid:4)
∗)2
(cid:4)(cid:4) (u
π
(cid:4)
∗
(cid:4)(cid:4)(cid:4)
∗
) π
(u
∗)2
(cid:4)(cid:4) (u
(cid:4)(cid:3)

(u
π

)

0
π(u)
π(cid:2)(cid:2)(u)

∗
λx

∗

)

(1 − x
r

u=u∗,x=x∗

(cid:4)

x − x
∗
u − u
∗
(cid:4)

Thus,(cid:3)

(cid:4)

(cid:3)

≈

(cid:4)
(cid:4)

x
u

−λ
(cid:3)

The eigenvalues of the linear system are determined by so-
lutions μ to

0 = det

−μ
π(u)
π(cid:2)(cid:2)(u)

−λ

λx

∗

)

(1 − x
∗
r − μ

solving for μ gives,

μ =

r ±

r2 − 4λ2x

∗(1 − x

2 − rμ + λ
(cid:14)

0 =μ

(cid:12)

∗

1
2
(cid:4)(cid:4)

2

∗

(1 − x

∗

x

∗
) π (u
)
∗)
(cid:4)(cid:4) (u
π

(cid:13)

∗)
∗) π (u
∗)
(cid:4)(cid:4) (u

π

λ

(u

Because π

) < 0, there is one positive and one negative
eigenvalue and both are real. Thus, the behavior of the
system is a saddle, as illustrated in Figure 7. There are
inﬁnitely many paths consistent with equilibrium given by
the diﬀerential equations. Which one is the right one? In
π(cid:2)(u∗)
π(u∗) ≥ 1, all paths that don’t violate
the case when − r
transversality lead to x = 0. Suppose x is a candidate limit.
+ Δ for t units of time. The ﬁrm
Consider setting u = u
(cid:3)(cid:5) t
earns
(cid:3)(cid:5) t
(cid:9)

∗
xπ(u
(x + λx(1 − x)Δt) π(u
∗
∗

Ψ ≈

+ Δ)

(cid:4)

(cid:4)

−rs

−rs

)y

ds

+

∗

e

0

=

1
r
+

0

e

ds

xπ(u

+ Δ)

−rt(cid:10)
e
1 − e
−rt (x + λx(1 − x)Δt) π(u
∗
1
(cid:9) 1
(cid:9)
r
(cid:6)
(cid:6)
1 − e
−rt
−rt
(cid:4)
) + λ
(u
(cid:6)
r e
−rt(1 − x)
π(cid:2)(u∗)
1−e−rt
π(u∗) + e
λ
t
π(u∗) + (1 − x)
π(cid:2)(u∗)
λ
r

(cid:7)

(cid:7)

(cid:10)

xπ

∗

)

t

Δ=0 = 1
r
∗
= λ
)
r xπ(u
∗
= λ
)
r xπ(u

x(1 − x)tπ(u
∗

(cid:7)

(cid:10)

)

468A. REFERENCES
[1] Jan P. Benway. Banner blindness: The irony of

attention grabbing on the world wide web. In
Proceedings of the Human Factors and Ergonomics
Society 42nd Annual Meeting, volume 1, pages
463–467, October 1998.

[2] Moira Burke, Anthony Hornof, Erik Nilsen, and

Nicholas Gorman. High-cost banner blindness: Ads
increase perceived workload, hinder visual search, and
are forgotten. ACM Transactions on
Computer-Human Interaction, 12(4):423–445,
December 2005.

[3] Georg Buscher, Susan T. Dumais, and Edward

Cutrell. The good, the bad, and the random: an
eye-tracking study of ad quality in web search. In
Proceedings of the 33rd international ACM SIGIR
conference on Research and development in
information retrieval, SIGIR ’10, pages 42–49, New
York, NY, USA, 2010. ACM.

[4] Xavier Dr`eze and Fran¸cois-Xavier Hussherr. Internet

advertising: Is anybody watching? Journal of
Interactive Marketing, 17(4), 2003.

[5] Avi Goldfarb and Catherine Tucker. Online display
advertising: Targeting and obtrusiveness. Marketing
Science, 30(3):389–404, May–June 2011.

[6] Daniel G. Goldstein, R. Preston McAfee, and

Siddharth Suri. The eﬀects of exposure time on
memory of display advertisements. In Proceedings of
the 12th ACM conference on Electronic commerce, EC
’11, pages 49–58, New York, NY, USA, 2011. ACM.

[7] Daniel G. Goldstein, R. Preston McAfee, and
Siddharth Suri. Improving the eﬀectiveness of
time-based display advertising. In Proceedings of the
13th ACM conference on Electronic commerce, EC
’12, 2012.

[8] Ed Hopkins. Two competing models of how people

learn in games. Econometrica, 70(6):2141–2166,
November 2002.

[9] John J. Horton, David G. Rand, and Richard J.
Zeckhauser. The online laboratory: Conducting
experiments in a real labor market. Experimental
Economics, 14(3):399–425, 2011.

[10] Winter Mason and Siddharth Suri. Conducting

behavioral research on Amazon’s Mechanical Turk.
Behavior Research Methods, 44(1):1–23, March 2012.

[11] Winter Mason and Duncan J. Watts. Collaborative

learning in networks. Proceedings of the National
Academy of Sciences, December 2011.

[12] Winter A. Mason and Duncan J. Watts. Financial
incentives and the performance of crowds. In Paul
Bennett, Raman Chandrasekar, and Luis von Ahn,
editors, Proceedings of the ACM SIGKDD Workshop
on Human Computation, pages 77–85. ACM, 2009.

[13] Gabriele Paolacci, Jesse Chandler, and Panagiotis G.

Ipeirotis. Running experiments on Amazon
Mechanical Turk. Judgment and Decision Making,
5:411–419, 2010.

[14] Allen Parducci and Linda F. Perrett. Category rating

scales: Eﬀects of relative spacing and frequency of
stimulus values. Journal of Experimental Psychology,
89(2):427–452, 1971.

[15] John G. Riley. Silver signals: Twenty-ﬁve years of

screening and signaling. Journal of Economic
Literature, XXXIX:432–478, 2001.

[16] Aaron D. Shaw, John J. Horton, and Daniel L. Chen.

Designing incentives for inexpert human raters. In
Proceedings of the ACM 2011 conference on Computer
supported cooperative work, CSCW ’11, pages 275–284,
New York, NY, USA, 2011. ACM.

[17] Siddharth Suri and Duncan J. Watts. Cooperation

and contagion in web-based, networked public goods
experiments. PLoS One, 6(3), 2011.

[18] Michael Toomim, Travis Kriplean, Claus P¨ortner, and

James A. Landay. Utility of human-computer
interactions: Toward a science of preference
measurement. In Proceedings of CHI 2011: ACM
Conference on Human Factors in Computing Systems,
2011.

[19] W. N. Venables and B. D. Ripley. Modern Applied

Statistics with S. Springer, New York, 2002.

[20] Jing Wang, Siddharth Suri, and Duncan Watts.

Cooperation and assortativity with dynamic partner
updating. Proceedings of the National Academy of
Sciences, 109(36):14363–14368, Septemeber 2012.

[21] Chan Yun Yoo and Kihan Kim. Processing of

animation in online banner advertising: The roles of
cognitive and emotional responses. Journal of
Interactive Marketing, 19(4):18–34, 2005.

469