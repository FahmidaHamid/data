Unsupervised Sentiment Analysis with Emotional Signals

Xia Hu, Jiliang Tang, Huiji Gao, and Huan Liu

Computer Science and Engineering

Arizona State University
Tempe, AZ 85287, USA

{xia.hu, jiliang.tang, huiji.gao, huan.liu}@asu.edu

ABSTRACT
The explosion of social media services presents a great op-
portunity to understand the sentiment of the public via ana-
lyzing its large-scale and opinion-rich data. In social media,
it is easy to amass vast quantities of unlabeled data, but
very costly to obtain sentiment labels, which makes unsuper-
vised sentiment analysis essential for various applications.
It is challenging for traditional lexicon-based unsupervised
methods due to the fact that expressions in social media
are unstructured, informal, and fast-evolving. Emoticons
and product ratings are examples of emotional signals that
are associated with sentiments expressed in posts or words.
Inspired by the wide availability of emotional signals in so-
cial media, we propose to study the problem of unsupervised
sentiment analysis with emotional signals. In particular, we
investigate whether the signals can potentially help senti-
ment analysis by providing a uniﬁed way to model two main
categories of emotional signals, i.e., emotion indication and
emotion correlation. We further incorporate the signals into
an unsupervised learning framework for sentiment analysis.
In the experiment, we compare the proposed framework with
the state-of-the-art methods on two Twitter datasets and
empirically evaluate our proposed framework to gain a deep
understanding of the eﬀects of emotional signals.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Informa-
tion Search and Retrieval—Classiﬁcation; I.2.7 [Artiﬁcial
Intelligence]: Natural Language Processing

General Terms
Algorithm, Performance, Experimentation

Keywords
Emotional Signals, Sentiment Analysis, Twitter, Emoticon,
Social Correlation, Social Media

1.

INTRODUCTION

Social media services such as Twitter1 and Facebook2 are
increasingly used to communicate and exchange opinions

1

2

https://twitter.com/
http://www.facebook.com/

Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW’13, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

about celebrities, politicians, products, companies, stocks
and events [17, 24]. These opinion-rich resources attract
attention from disciplines to understand the opinions of so-
cial media users. For example, the aggregated sentiments of
tweets about politicians are used to predict poll ratings [24].
Asur and Huberman [3] exploit Twitter sentiment and con-
tent to forecast box-oﬃce revenues of movies, outperforming
traditional market-based predictors. Various applications
demonstrate the eﬀectiveness of sentiment analysis in un-
derstanding opinions contained in social media.

Methods for automatically classifying sentiments expressed
in product and movie reviews have been extensively studied
for years [13, 20], and can roughly be divided into supervised
and unsupervised sentiment analysis [25]. The supervised
methods train a robust sentiment classiﬁer from manually
labeled training data. In social media, it is time and labor
consuming to obtain sentiment labels, which are essential for
supervised sentiment analysis algorithms. Given large-scale
unlabeled data which can be easily collected in social media,
we propose to study unsupervised sentiment analysis.

A traditional way to perform unsupervised sentiment anal-
ysis is the lexicon-based method [24, 36, 37]. These methods
employ a sentiment lexicon to determine overall sentiment
polarity of a document. Lexicon-based unsupervised senti-
ment analysis becomes diﬃcult due to the distinct features
of social media data. First, texts in social media are short,
thus we lack suﬃcient aggregated information to measure
overall sentiment of a post [14]. Second, new expressions,
like “it’s coooool” and “good 9t :)”, are frequently used and
fast-evolving in social media. They are not standard, but
are more acceptable in social media. Third, users may use
diﬀerent words to express their opinions in distinct domains.
It is diﬃcult to deﬁne a universally optimal sentiment lex-
icon to cover words from diﬀerent domains [23]. Thus it is
challenging for lexicon-based methods to accurately identify
the overall sentiment polarity of social media posts, which
are short, unstructured, fast-evolving, and domain-speciﬁc,
though they provide convenience in instant communications
for human beings.

Abundant emotional signals are observed in social media.
Emotional signals are any information that could be corre-
lated with sentiment polarity of a document or the words
in the document. For example, when communicating in the
physical world, it is common for people to supplement vocal
interaction with gestures and facial expressions. Similarly,
in social media, users develop visual cues that are strongly
associated with their emotional states. These cues, known
as emoticons (or facial expressions), are widely used to show

607the emotion that a user’s post represents. When the authors
use emoticons, they are eﬀectively marking up the text with
an emotional state [22]. In this case, an emoticon is consid-
ered as an emotional signal. Another example of emotional
signals is the consistency theory [1], which is well-established
in social sciences and was introduced to model people’s emo-
tions [20]. Emotion consistency theory suggests that words
that often co-occur show the same sentiment orientation,
especially when the posts are short. Although manually la-
beling data is costly, massing vast quantities of unlabeled
data is easy in social media.

In this paper, we exploit emotional signals contained in
social media data for eﬀective sentiment analysis in an un-
supervised manner. Speciﬁcally, we investigate the following
problems: Are the emotional signals available in social me-
dia potentially useful for sentiment analysis? How can the
emotional signals be explicitly represented and incorporated
into an unsupervised sentiment analysis framework? Is the
integration of emotional signals helpful for real-world senti-
ment analysis applications? The main contributions of this
paper are summarized as follows:

• Formally deﬁne the problem of unsupervised sentiment

analysis with emotional signals;

• Verify the existence of representative emotional signals
with statistical hypothesis testing, and propose a uni-
ﬁed way to model the emotional signals;

• Present a novel framework to incorporate the emo-
tional signals into unsupervised sentiment analysis; and
• Empirically evaluate the proposed framework on real-
world Twitter datasets and elaborate the eﬀects of the
emotional signals on sentiment analysis.

The remainder of this paper is organized as follows.

In
Section 2, we review existing literature related to our work.
In Section 3, we formally deﬁne the problem we study. In
Section 4, we conduct an exploratory study to examine the
potential impacts of emotional signals with social media
datasets. In Section 5, we propose an unsupervised senti-
ment analysis framework which considers diﬀerent types of
emotional signals in a uniﬁed way. In Section 6, we report
empirical results on real-world datasets.
In Section 7, we
conclude and present the future work.

2. RELATED WORK

Sentiment analysis has been a hot topic for quite a few
years [20]. Recently, as an eﬀective tool to understand opin-
ions of the public, sentiment analysis is widely used in vari-
ous social media applications [27], including poll rating pre-
diction [24], stock market prediction [4], event analysis [18],
behavioral targeting [38], etc. Similar to conventional senti-
ment analysis on product and movie reviews, most existing
methods in social media can fall into supervised learning
methods [10, 15] and unsupervised learning methods [4, 18,
24]. Due to the lack of label information and the large-scale
data produced by social media services, unsupervised learn-
ing becomes more and more important in real-world social
media applications.

The most representative way to perform unsupervised sen-
timent analysis is the lexicon-based method. The methods
rely on a pre-deﬁned sentiment lexicon to determine the gen-
eral sentiment polarity of a given document. The existing

methods can be generally divided into three categories. The
ﬁrst is to employ a group of human annotators to man-
ually label a set of words to build the sentiment lexicon,
e.g., General Inquirer [31] and MPQA [37]. The second is
dictionary-based methods [2, 26], which employ a dictionary,
e.g., WordNet, to learn sentiment orientation of a word from
its semantically/linguistically related words mined from the
dictionary. The third is called corpus-based methods [23,
34, 39], which infer sentiment orientation of the words from
a given corpus by exploring the relation between the words
and some observed seed sentiment words/information, and
then build a domain-dependent sentiment lexicon. Diﬀerent
from traditional lexicon-based methods, we perform unsu-
pervised sentiment analysis from a novel perspective. The
proposed framework considers both post- and word-level
sentiment-related contextual information, i.e., emotional sig-
nals, in a uniﬁed framework. The proposed framework makes
use of the valuable emotional signals to compensate the
problem of lack of label information in social media.

Some eﬀorts have been made to explore the eﬀects of emo-
tional signals on sentiment analysis. Zhao et al. [40] em-
ployed the emoticon related tweets to train a naive Bayes
classiﬁer for sentiment classiﬁcation. Bordy and Diakopou-
los [6] showed that the lengthening of a word is strongly as-
sociated with its sentiment. Li et al. [19] used the sentiment
knowledge learned from one domain to facilitate sentiment
analysis on another domain. However, the proposed meth-
ods rely on one domain-dependent emotional signal to some
extent. As we discussed in the experiment, performance of
some emotional signals, e.g., emoticons, is not stable when
used on datasets from diﬀerent domains. Diﬀerent from pre-
vious methods, we present the ﬁrst quantitative study ana-
lyzing the impacts of emotional signals that are ubiquitous
in social media. We further provide a novel unsupervised
sentiment analysis framework to make use of the interpreted
emotional signals in a uniﬁed way.

3. PROBLEM STATEMENT

One distinct feature of social media data is that it often
provides additional information other than text. An exam-
ple of social media data is illustrated in Figure 1. Traditional
sentiment analysis methods work with “ﬂat” attribute-value
data in the form of a post-word matrix, as shown in the left
part of the ﬁgure. They assume that posts are independent
and identically distributed (i.i.d.). This assumption does
not hold true in social media. Unlike traditional platforms,
social media contains emotional signals that are highly cor-
related with the sentiment polarity of posts and words, as
shown in the right part of the ﬁgure.

We study social media data that consists of a collection
of posts with emotional signals. This is a general setting
in social media. The posts can be a set of tweets, Facebook
updates, Yelp comments, Amazon product reviews, etc. The
emotional signals could be any information correlated with
sentiment of a post or words in the post. The emotional
signals can roughly be divided into two categories, emotion
indication and emotion correlation, as deﬁned below.

Deﬁnition 1 (Emotion Indication): Emotion indica-
tion is deﬁned by the emotional signals that strongly re-
ﬂect the sentiment polarity of a post or a word and can be
easily collected from social media. For example, emoticons
correspond to sentiments expressed in posts, and they are
frequently used on diﬀerent social media platforms. The in-

608w1 w2

…

…

wj

…     …

wn

p1
p2
p3
…

pi

…

pm

Post – Word Matrix

p

p

p

p

post-level

p

w

w

w

w

w
word-level

Emotion Correlation

(cid:45) (cid:47) LOL

post-level

Sentiment 
Lexicon     

word-level

Emotion  Indication

Figure 1: An Example of Social Media Data

tuition is that it is unlikely for a user to include a negative
emoticon in a post expressing something positive. As shown
in the bottom right corner of Figure 1, we have post-level
emotion indication, including emoticons, product ratings,
restaurant stars, etc., and word-level emotion indication, in-
cluding some publicly available sentiment lexicons.

Deﬁnition 2 (Emotion Correlation): Emotion corre-
lation is deﬁned by the emotional signals that reﬂect the
correlation between posts or words. For example, we can
build a connection between two words in a post with emo-
tion consistency theory [1]. The theory suggests that two
frequently co-occurring words should have similar sentiment
polarity. The intuition is that it is unlikely that people will
mix negative and positive words together in a short post.
As shown in the top right corner of Figure 1, we have post-
level emotion correlation, like a post-post social network,
text similarity between two posts, etc., and word-level emo-
tion correlation, like consistency theory, synonym relation
in WordNet, co-occurrence information in Wikipedia, etc.
m×n be the post-word content
matrix, where m is the number of posts and n is the number
of distinct words in the posts. The entry at the ith row and
jth column of a matrix A is denoted as A(i, j). A(i,∗) and
A(∗, j) denote the ith row and jth column of a matrix A,
respectively. (cid:4)A(cid:4)F is the Frobenius norm of a matrix A,
and (cid:4)A(cid:4)F =

Notations: Let X ∈ R

(cid:2)(cid:3)m

(cid:3)n

i=1

j=1 A(i, j)

2

.

Generally, as stated by Speriosu et al. [30], sentiment anal-
ysis requires three stages: (1) topic-based message retrieval;
(2) subjectivity classiﬁcation; (3) polarity sentiment classi-
ﬁcation. This paper, like most previous work in sentiment
analysis [10, 21, 30], focuses on the last stage of the process
— polarity sentiment classiﬁcation.

With the terminologies deﬁned above, we now formally

deﬁne our task as following:

Given a corpus of social media posts X and available emo-
tional signals, including post- and word-level emotion indica-
tion, and post- and word-level emotion correlation, our task
is to automatically infer the sentiment labels of the posts.

4. DATA ANALYSIS

A motivation for this work is that emotional signals could
be strongly correlated with the sentiment in a post or a word.

Table 1: List of Emoticons

:D =)

:-)
:-(

Positive
Negative

:)
:(

: )
: (

Before proceeding, we ﬁrst introduce real-world data used in
this work and investigate whether the observed emotional
signals have any potential impact on sentiment analysis.
4.1 Datasets

Two publicly available tweet datasets are used in our study,
i.e., Stanford Twitter Sentiment and Obama-McCain De-
bate. Now we introduce the two datasets in detail.

The ﬁrst dataset used in the experiment is Stanford Twit-
ter Sentiment (STS).3 Go et al. [10] created a collection of
40,216 tweets with polarity sentiment labels to train a sen-
timent classiﬁer. The tweets in the dataset are crawled be-
tween April 6, 2009 and June 25, 2009 via Twitter API.4
We include all the tweets and their corresponding sentiment
labels in the dataset for experiment.

The second data set is Obama-McCain Debate (OMD).5
This dataset consists of 3,269 tweets posted during the presi-
dential debate on September 26, 2008 between Barack Obama
and John McCain [29]. The sentiment label of each tweet
was annotated through Amazon Mechanical Turk6. Each
tweet was manually labeled by at least three Turkers. The
majority of votes for a tweet is taken as a gold standard.

We follow a standard procedure for data preprocessing.
The unigram model is employed to construct the feature
space, term presence is used as the feature weight. No stem-
ming or removing stop-words is performed for both datasets.
Next we introduce a sentiment lexicon used in our study.

Sentiment Lexicon: A widely used manually labeled
sentiment lexicon, i.e., MPQA Opinion Corpus7 (MPQA),
is used in this study. There are 2718 positive and 4902
negative words in the sentiment lexicon.
4.2 Verifying Emotional Signals

We study the potential impact of two representative emo-
tional signals, emoticon and emotion consistency, on the sen-
timents via statistical hypothesis testing.

4.2.1 Verifying Emotion Indication

Emotion indication suggests that the sentiment of a post
is likely to be consistent with its indication information. We
use the emoticons listed in Table 1 to validate whether this
hypothesis holds in the two datasets.

For each of the two datasets, two groups of tweets with
equal size are selected. One group is the tweets with positive
emoticons, the other is tweets randomly selected from the
whole dataset. We construct two vectors sp and sr, which
represent the sentiment polarity of the tweets in the two
groups, respectively. We form a two-sample one-tail t-test
to validate the existence of positive emotion indication. We
test whether or not there is suﬃcient statistical evidence to
support the hypothesis that the sentiment polarity of the

3

4

5

http://www.stanford.edu/~alecmgo/cs224n/
http://apiwiki.twitter.com/
https://bitbucket.org/speriosu/updown/src/

5de483437466/data/
6

7

https://www.mturk.com/
http://www.cs.pitt.edu/mpqa/opinionfinder_1.html

609Table 2: Hypothesis Testing Results (P-Values) to
Verify Emotion Indication and Emotion Correlation

Emotional Signal
Positive Emoticon
Negative Emoticon

Emotion Consistency

STS

OMD

5.2464e-008
1.7909e-007
9.0032e-008

2.5338e-004
1.2558e-003
3.0698e-008

ﬁrst group is larger than that of the second. The null hy-
pothesis is H0 : μp − μr ≤ 0, and the alternative hypothesis
is H1 : μp−μr > 0. In the formulations, μp and μr represent
the sample mean of sentiment polarity of the tweets in the
two groups, respectively.

Similarly, for each of the two datasets, we construct two
vectors sn and sr in terms of negative emoticons. One group
is the tweets with negative emoticons, the other is tweets
randomly selected from the whole dataset. The null is H0 :
μn − μr ≥ 0, and alternative hypotheses is H1 : μn − μr < 0,
where μn and μr represent the sample mean of sentiment
polarity of the tweets in the two groups, respectively.

The t-test results, p-values, are summarized in the middle
two rows of Table 2. The results show that there is strong
statistical evidence, with signiﬁcance level α = 0.01, to re-
ject the null hypothesis in both tests on the two datasets. In
other words, the results validate the hypothesis that emotion
indication is clearly correlated with the sentiments expressed
in social media data.

4.2.2 Verifying Emotion Correlation

Emotion consistency theory suggests that the sentiments
of two co-occurring words have higher probability to be con-
sistent than those of two random words. We use hypothesis
testing to validate whether this social theory still holds in
the two datasets.

We ﬁrst deﬁne the sentiment diﬀerence score between two

words as

Dij = ||wi − wj||2,

(1)

where wi and wj represent sentiment polarity of the words,
which are determined by the MPQA sentiment lexicon.

Then, we construct two vectors sc and sr with an equal
number of elements. Each element of the ﬁrst vector sc
is calculated by Eq. (1), where wi and wj are words co-
occurring in the same post. Each element of the second
vector represents the sentiment diﬀerence score between wi
and another randomly selected word wr. We form a two-
sample one-tail t-test to validate the existence of emotion
consistency. We test whether there is suﬃcient evidence to
support the hypothesis that sentiment diﬀerence of the ﬁrst
group is less than that of the second. The null hypothesis
is H0 : μc − μr ≥ 0, and the alternative hypothesis is H1 :
μc − μr < 0, where μc and μr represent the sample means of
sentiment diﬀerence scores in the two groups, respectively.
The t-test results, p-values, are summarized in the last
row of Table 2. The results show that there is strong ev-
idence, with signiﬁcance level α = 0.01, to reject the null
hypothesis on the two datasets. In other words, we validate
the existence of emotion correlation in social media data.
By verifying the existence of the emotional signals in social
media data, it paves the way for our next study of modeling
the emotional signals for sentiment classiﬁcation.

5. ESSA: AN UNSUPERVISED SENTIMENT

ANALYSIS FRAMEWORK

In this section, we ﬁrst discuss how to explicitly model
the two categories of emotional signals and propose a novel
framework to make use of the Emotional Signals for unsu-
pervised Sentiment Analysis (ESSA).

5.1 Modeling Emotion Indication

Post-level Emotion Indication: As we discussed, post-
level emotion indication strongly reﬂects the sentiment po-
larity of a post. The key idea of modeling post-level emotion
indication is to make the sentiment polarity of a post as close
as possible to the emotion indication of the post. It can be
formulated as minimizing the following loss function:

(cid:4)U(i,∗) − U0(i,∗)(cid:4)2
2,

m×c is the post-sentiment matrix, U0 ∈ R

(2)
where U ∈ R
m×c
represents the emotion indication matrix, and c is the num-
ber of sentiment classes for posts. Our task is polarity senti-
ment classiﬁcation, i.e., c = 2. For example, U0(i,∗) = (1, 0)
represents that the post contains positive emotion indica-
tion, and U0(i,∗) = (0, 1) negative indication. U0(i,∗) =
(0, 0) represents unknown, i.e., there is no emotion indica-
tion in the post.

To avoid impacts brought by unknown elements of U0,

the loss function for all the posts can be formulated as

Ru
I = (cid:4)G

u

(U − U0)(cid:4)2
F ,

(3)
where Gu ∈ {0, 1}m×m is a diagonal indicator matrix for
post-level emotion indication, i.e., Gu(i, i) = 1 represents
that the i-th post contains emotion indication, Gu(i, i) = 0
otherwise. This loss function incurs a penalty if the learned
sentiment polarity is inconsistent with the emotion indica-
tion contained in the data.

Word-level Emotion Indication: It has been validated
in [35] that the overall sentiment of a post is positively cor-
related with the sentiments of the words in that post. By
modeling word-level emotional signals, we have the potential
to utilize the valuable information in the sentiment analysis
framework to infer sentiment polarity of a post.

Similar to modeling the post-level emotion indication, we
propose to make the sentiment polarity of a word as close
as possible to the word-level emotion indication. It can be
formulated by minimizing the following loss function:

(cid:4)V(i, ∗) − V0(i, ∗)(cid:4)2
2,

(4)

and considering all the words, it can be formulated as

Rv
I = (cid:4)G

v

(V − V0)(cid:4)2
F ,

(5)
where Gv ∈ {0, 1}n×n is a diagonal indicator matrix to rep-
resent whether the word contains word-level emotion indi-
cation or not, V ∈ R
n×c is the word-sentiment matrix, and
V0 ∈ R
5.2 Modeling Emotion Correlation

n×c is the word-level emotion indication matrix.

This category of emotional signals reﬂect correlation be-
tween data points, i.e., posts or words. We propose to con-
struct a graph to represent geometric structure of the data.
In the graph, nodes represent data points, and edges repre-
sent correlation between the data points. Now we introduce
how to model the emotion correlation in detail.

610Post-level Emotion Correlation: In order to model
post-level emotion correlation, we construct a post-post graph
Gu. In the graph, nodes represent posts in the corpus and
edges represent the aﬃnity between the posts. The adja-
(cid:4)
cency matrix Wu ∈ R

m×m of the graph Gu is deﬁned as

if ui ∈ N (uj) or uj ∈ N (ui)
otherwise .

W

(6)
where uj is a post in the corpus, and N (uj ) represents the
k-nearest neighbors of the post. Many metrics, e.g., textual
similarity and social network information, can be adopted
to obtain nearest neighbors of a post, and further deﬁne the
adjacency matrix.

(i, j) =

1
0

u

The key idea is that if two nodes are close in the graph,
their labels are also close to each other. This intuition is
consistent with traditional supervised sentiment analysis, in
which it is assumed that sentiment labels of two posts are
more likely to be consistent when their textual similarity is
high [25]. It can be mathematically formulated as minimiz-
ing the following loss function:

m(cid:5)

m(cid:5)

(cid:4)

1
0

Ru

C =

1
2

=

(cid:4)U(i, ∗) − U(j,∗)(cid:4)2
u − W
U),

)U)

u

i=1

j=1

T
T r(U
T r(U

(D
TLu

2W

u

(i, j)

=

(7)
where T r(·) is the trace of a matrix, Lu = Du − Wu is the
Laplacian matrix [11] of the constructed graph Gu, and Du ∈
m×m is a diagonal matrix where Du(i, i) =
j=1 Wu(i, j).
R
This loss function will incur a penalty if two posts are close
in the graph but have diﬀerent sentiment labels.

(cid:3)m

Word-level Emotion Correlation: Similar to the in-
terpretation of the post-level emotion correlation, we con-
struct a word-word graph Gv. In the graph, nodes represent
distinct words in the corpus and edges represent the aﬃn-
ity between words. Adjacency matrix Wv ∈ R
n×n of the
constructed graph Gv is deﬁned as

v

(i, j) =

if vi ∈ N (vj ) or vj ∈ N (vi)
otherwise .

W

(8)
where vj is a word in the corpus, and N (vj ) represents the k-
nearest neighbor of the word. This matrix can also be formu-
lated according to various metrics, like co-occurrence infor-
mation, semantic similarity computed by WordNet, Wikipedia,
or search engine, which have been extensively studied in Na-
ture Language Processing literature [14].

The basic idea here is to build a latent connection to make
sentiment labels of two words as close as possible if they are
close in the graph Gv, and this goal can be achieved by
minimizing the following loss function:

Rv

C = T r(V

TLv

V),

(9)

where Lv = Dv − Wv is the Laplacian matrix of Gv.
5.3 Exploiting Emotional Signals for Unsuper-

vised Sentiment Analysis

Supervised learning methods have been widely used for
sentiment analysis [25]. They treat sentiment classiﬁcation
as a two-topic (positive and negative sentiment) classiﬁca-
tion problem, and learn a classiﬁer based on manually la-
beled data. To avoid the time-consuming and expensive la-

beling work, emotional signals are employed in the proposed
unsupervised framework to guide the learning process.

Under this scenario, with the interpretation of the two cat-
egories of emotional signals, we propose a matrix factoriza-
tion based framework for unsupervised sentiment analysis.
The proposed method is built on the orthogonal nonnega-
tive matrix tri-factorization model [8] (ONMTF). The basic
idea of the ONMTF model is that data instances can be
clustered based on the distribution of features, and features
can be clustered according to their distribution of data in-
stances. The principle of ONMTF is consistent with topic
modeling in text mining, e.g., PLSI [12], in which each doc-
ument can be represented as a mixture of the latent topics,
and each word can be generated from the latent topics.

The ONMTF model is to approximate the input post-
word matrix with three factor matrices that assign cluster
labels to posts and words simultaneously by solving the fol-
lowing optimization problem:

min

U,H,V≥0

O = (cid:4)X − UHV

T(cid:4)2
F ,

s.t. U

T

U = I, V

T

V = I.

(10)

n×c
+

and V ∈ R

where X is the input post-word content matrix, and U ∈
m×c
are orthogonal nonnegative matri-
R
+
ces indicating low-dimensional representations of posts and
words, respectively. The orthogonal and nonnegative condi-
tions of the two matrices U and V enforce the model to pro-
vide a hard assignment of cluster label for posts and words.
H ∈ R

c×c
+ provides a condensed view of X.

While supervised sentiment analysis methods use man-
ually labeled information to train a classiﬁer, motivated
by [26], we treat unsupervised sentiment analysis as a clus-
tering problem, and employ emotional signals as prior knowl-
edge to guide the learning process. In particular, to ensure
the learned latent topic space to be sentiment space, we
introduce emotional signals to constrain the matrix factor-
ization based framework from both post and word sides.
Our proposed unsupervised sentiment analysis framework
can be mathematically formulated as solving the following
optimization problem:

min

U,H,V≥0
+ λv

I(cid:4)G

J = (cid:4)X − UHV
(V − V0)(cid:4)2
F + λu
s.t. U
U = I, V

T

v

T(cid:4)2

F + λu

C T r(U
T

V = I.

I (cid:4)G
TLu

u

(U − U0)(cid:4)2
U) + λv

C T r(V

F

TLv

V),

I , λv

I , λu

C, λv

(11)
where λu
C are all positive regularization parame-
ters which control contributions of post- and word-level emo-
tion indication, and post- and word-level emotion correla-
tion, respectively. Note that we focus on studying the eﬀects
of emotional signals on sentiment analysis performance, but
not ways to combine them. We can simply combine these
emotional signals with equal weight in the general frame-
work. The orthogonal and nonnegative conditions of U and
V provide a hard assignment of sentiment polarity to posts
and words simultaneously.

With the optimization results, the sentiment polarity of a
post ui can be inferred by f (ui) = arg maxj∈{p,n} U(i, j).
The optimization problem in Eq. (11) is not convex with
respect to the three variables U, H and V together. There is
no closed-form solution for the problem. Next, we introduce
an alternative scheme to solve the optimization problem.

6115.4 Optimization Algorithm for ESSA

It is diﬃcult to give a closed-form solution for the opti-
mization problem in Eq. (11). Motivated by [8], we now
introduce an alternative algorithm to ﬁnd optimal solutions
for the three variables U, H, and V. The key idea is to opti-
mize the objective with respect to one variable, while ﬁxing
others. The algorithm will keep updating the variables until
convergence. Now we introduce the algorithm in detail.

5.4.1 Computation of H

Optimizing the objective function in Eq. (11) with respect

to H is equivalent to solving

JH = (cid:4)X − UHV

T(cid:4)2
F .

min
H≥0

(12)
Let ΛH be the Lagrange multiplier for constraint H ≥ 0,

the Lagrange function L(H) is deﬁned as follows:

L(H) = (cid:4)X − UHV

F − T r(ΛH H
).
By setting the derivative ∇HL(H) = 0, we get
V.

ΛH = −2U

XV + 2U

UHV

T(cid:4)2

T

T

T

T

(13)

(14)

The Karush-Kuhn-Tucker complementary condition [5] for

the nonnegativity constraint of H gives

ΛH (i, j)H(i, j) = 0 ;

(15)

thus, we obtain

[−U

T

XV + U

T

T

UHV

V](i, j)H(i, j) = 0.

(16)

Similar to [8], it leads to the updating rule of H,

(cid:6)

H(i, j) ← H(i, j)

[UT XV](i, j)

[UT UHVT V](i, j)

.

(17)

5.4.2 Computation of U

Similar to the computation of H, optimizing the objective
function in Eq. (11) with respect to U leads to the updating
rule of U,

(cid:7)(cid:8)(cid:8)(cid:9) [XVHT + λu

U(i, j) ← U(i, j)

I GuU0 + λu

[UHVT VHT + λu

I GuU + λu

CWuU + UΓ−
C DuU + UΓ+

U ](i, j)

U ](i, j)
(18)

The details are given in Appendix A.

5.4.3 Computation of V

Similarly, optimizing the objective function in Eq.( 11)

with respect to V leads to the updating rule of V,

V(i, j) ← V(i, j)

(cid:7)(cid:8)(cid:8)(cid:9) [XT UH + λv

I Gv V0 + λv

[VHT UT UH + λv

I GvV + λv

CWv V + VΓ−
C DvV + VΓ+

V ](i, j)

V ](i, j)
(19)

The details are given in Appendix B.

In summary, we present the computational algorithm of
optimizing Eq. (11) in Algorithm 1. In the algorithm, we
conduct initialization for indicator matrix, Laplacian ma-
trix, and the three matrices to be inferred from line 1 to 3.
T is the number of maximum iterations. The three matrices
are updated with the updating rules until convergence or
reaching the number of maximum iterations. The correct-
ness and convergence of the updating rules can be proved
with the standard auxiliary function approach [28].

I , λv

I , λu

C , λv

C, T }

Algorithm 1: ESSA: Exploring Slang Sentiment Words
for Sentiment Analysis
Input: {X, U0, V0, λu
Output: V
1: Construct matrices Gu and Gv in Eq. (3) and (4)
2: Construct matrices Lu and Lv in Eq. (7) and (9)
3: Initialize U = U0, V = V0, H ≥ 0
4: while Not convergent and t ≤ T do
5:
6:

Update H(i, j) ← H(i, j)

[UT UHVT V](i,j)

[UT XV](i,j)

(cid:10)

[XVHT +λu
I

GuU0+λu
C

[UHVT VHT +λu
I

GuU+λu
C

WuU+UΓ−
Du U+UΓ+
U

U

](i,j)

](i,j)

[XT UH+λv
I

Gv V0+λv
C

[VHT UT UH+λv
I

Gv V+λv
C

Wv V+VΓ−
Dv V+VΓ+
V

V

](i,j)

](i,j)

(cid:6)
Update
U(i, j) ← U(i, j)
(cid:6)

Update
V(i, j) ← V(i, j)

7:

8:

t = t + 1
9:
10: end while

5.5 Extensions

In some social media applications, it is possible that more
emotional signals from multiple sources are available. For
example, product ratings from Amazon, restaurant ratings
in Yelp, etc. are potentially correlated with the sentiment
polarity of the posts. These sources could be useful to be
included in the proposed framework as post-level emotion
indication information. Also, as we discussed, for word-level
emotional signals, WordNet, Wikipedia or other Web re-
sources could be useful to build the word-word graph as
word-level emotion correlation.

The proposed framework can be easily extended to incor-
porate multiple emotional signals by solving the following
optimization problem:
J1 = O +
(cid:5)

λs1Ru

λs2Rv

(cid:5)

(cid:5)

(cid:5)

U,H,V≥0

I,s1 +

min

I,s2

s1∈SI,U
λs3Ru

C,s3 +

s2∈SI,V
λs4Rv

C,s4 ,

+

s3∈SC,U

s4∈SC,V

.

.

s.t. U

T

U = I, V

T

V = I.

(20)
where O is the objective function deﬁned in Eq. (10). The
second term is to introduce post-level emotion indication
information from multiple sources SI,U , where s1 represents
an emotional signal from the sources, Ru
I,s1 represents the
loss function deﬁned in Eq. (3) for the signal s1, and λs1 is
the corresponding positive parameter to control contribution
from the emotional signal. Similarly, we deﬁne the other
three loss terms in the formulation to integrate word-level
emotion indication, post- and word-level emotion correlation
from multiple information sources, respectively.

The optimization problems in Eq. (20) can be solved with
a similar algorithm as that we introduced in Section 5.4. We
do not discuss the details since that our focus is to illustrate
how to make use of the emotional signals in this paper.

6. EXPERIMENTS

In this section, we conduct extensive experiments to eval-
uate the proposed framework ESSA and the factors that
could aﬀect the framework. Through the experiments, we
aim to answer the following two questions,

6121. How eﬀective is the proposed framework compared with

other unsupervised sentiment analysis methods?

2. What are the eﬀects of the emotional signals in terms

of sentiment analysis performance?

We begin by introducing the experimental setup, and then
compare the performance of diﬀerent unsupervised senti-
ment analysis methods. Finally, we study the eﬀects of the
emotional signals on the proposed framework.
6.1 Experimental Setup

We follow the standard experiment settings [20] to evalu-
ate the performance of sentiment analysis methods. In par-
ticular, we apply diﬀerent methods to perform unsupervised
sentiment classiﬁcation8 on social media datasets. Senti-
ment classiﬁcation accuracy is used as the performance met-
ric. To avoid bias brought by diﬀerent corpora, STS and
OMD introduced in Section 4.1 are used in the experiments.
The manually annotated sentiment polarity is considered as
the gold standard.

For general experiment purposes, we choose emoticons,
sentiment lexicon, textual similarity and word co-occurrence
as post-level emotion indication, word-level emotion indica-
tion, post-level emotion correlation and word-level emotion
correlation, respectively. Emoticons are the ones listed in
Table 1, and sentiment lexicon is the MPQA introduced in
Section 4.1. The latter two emotional signals are discussed
in Section 5.2, and we empirically set k = 20 for k-nearest
neighbor deﬁned in Eq. (6) and (8). There are four parame-
ters involved in the experiments, including λu
C in
Eq. (11). All the parameters are positive. They control the
contributions of diﬀerent emotional signals to the general
model. For general experiment purposes, we empirically set
λu
I = λv
C = 1, which means the emotional signals
are simply combined with equal weight. The impacts of the
parameters on the learning model will be further discussed
in Section 6.4.
6.2 Performance Evaluation

C = λv

I = λu

I , λv

I , λu

C, λv

We now study the beneﬁts of utilizing emotional signals
over other unsupervised methods, accordingly answering the
ﬁrst question above. We compare our proposed method
ESSA with the following three categories of methods,

• Traditional Lexicon-Based Methods: These methods
employ a word-matching scheme to perform unsuper-
vised sentiment classiﬁcation. In particular, sentiment
polarity of a word is obtained from the pre-deﬁned sen-
timent lexicon, i.e., +1 for positive, and -1 for nega-
tive. The overall sentiment score of a post is computed
as the summation of sentiment scores of the words in
the post. We employ two widely used manually la-
beled sentiment lexicons in the experiment. The ﬁrst
is General Inquirer9 (GI), and the second is MPQA
introduced in Section 4.2. According to diﬀerent lexi-
cons used, we denote the two methods as GI-Label and

8In machine learning, classiﬁcation is often considered as
a supervised learning method. Following the terminology
used in sentiment analysis literature [20], we consider the
task of determining sentiment polarity of a post without
extra human eﬀorts during learning process as unsupervised
sentiment classiﬁcation.
9

http://www.wjh.harvard.edu/~inquirer/

Table 3: Sentiment Classiﬁcation Accuracy of the
Unsupervised Methods on the Datasets

Method
GI-Label

MPQA-Label

LBM

K-Means
ONMTF
MoodLens

CSMF
ESSA

STS (gain)

OMD (gain)

0.615

0.602

0.630 (+2.40%)
0.663 (+7.70%)
0.550 (-10.66%)
0.567 (-7.93%)
0.680 (+10.46%)
0.657 (+6.81%)
0.726 (+17.96%)

0.629 (+4.53%)
0.636 (+5.56%)
0.568 (-5.65%)
0.565 (-6.21%)
0.583 (-3.11%)
0.657 (+9.08%)
0.692 (+14.96%)

MPQA-Label. In addition, Taboada et al. [32] propose
LBM to incorporate intensiﬁcation and negation to re-
ﬁne the sentiment score for each document. This is the
state-of-the-art lexicon-based method for unsupervised
sentiment analysis.

• Document Clustering Methods: Unsupervised learning
has been extensively used in text mining. We choose
the most representative clustering method, K-Means,
as a baseline method in this study.
In addition, we
test the clustering performance of a basic ONMTF [8]
method, which is a variant of our proposed method
without any emotional signals. We set the number of
clusters as two in both methods. As a common ini-
tialization for clustering methods, we randomly assign
initial centroids and initial class indicator matrix for
K-Means and ONMTF, respectively.

• Methods Incorporating Emotional Signals: Although
we ﬁrst present a quantitative study of emotional sig-
nals and provide a uniﬁed model to incorporate emo-
tional signals, some eﬀorts have been made to use some
speciﬁc emotional signals,
i.e., emoticons and senti-
ment lexicons. We denote the methods as MoodLens
and CSMF in the experiment. MoodLens [40] utilizes
available emoticons in a corpus as noisy label infor-
mation to train a naive Bayes classiﬁer, and apply the
trained classiﬁer to infer sentiment polarity of other
posts. CSMF [26] proposes to learn from lexical prior
knowledge from domain-independent sentiment terms
and domain-dependent unlabeled data.

The experimental results of the methods are presented in
Table 3. In the table, “gain” represents the percentage im-
provement of the methods as compared to our ﬁrst baseline
method GI-Label. In the experiment, each result denotes an
average of 10 test runs. By comparing the results of diﬀerent
methods, we draw the following observations:

(1) From the results in Table 3, we can observe that our
proposed framework ESSA consistently outperforms other
baseline methods on both datasets. Our method can gen-
erate better results than the state-of-the-art methods LBM,
MoodLens, and CSMF. We apply two-sample one-tail t-tests
to compare ESSA to the best baselines LBM, MoodLens, and
CSMF. The experiment results demonstrate that the pro-
posed model performs signiﬁcantly better (with signiﬁcance
level α = 0.01) than the three methods.

(2) The performance of ESSA is better than the ﬁrst and
second categories of methods, which are based on text in-

613formation alone. This demonstrates that the integration of
emotional signals positively helps improve sentiment classi-
ﬁcation performance. ESSA outperforms the third category
of methods, which also make use of emotional signals. This
validates the excellent use of emotional signals in the pro-
posed framework for sentiment analysis.

(3) Generally, among all the three categories of baseline
methods, the document clustering methods achieve the worst
performance. This demonstrates that, without any prior
knowledge in the learning process, pure text clustering meth-
ods cannot achieve good performance for sentiment analysis.
(4) The methods that incorporate emotional signals show
superior performance in the experiment. However, it is also
noted that the baseline GI-Label achieves even better perfor-
mance than MoodLens on OMD dataset. This demonstrates
that the performance of sentiment analysis, which relies on
only one speciﬁc emotional signal as prior knowledge, is not
stable on all the datasets.

In summary, with the help of emotional signals, our pro-
posed framework always outperforms the lexicon-based meth-
ods, traditional text clustering methods, and the methods
incorporating emotional signals. In the next subsection, we
investigate the eﬀects of diﬀerent emotional signals on the
sentiment analysis framework.

6.3 Effects of Emotional Signals

In this subsection, we study the eﬀects of the emotional
signals on our proposed framework, accordingly answering
the second question asked in the beginning of Section 6.

We ﬁrst compare the performance of the proposed frame-
work with only one emotional signal on the two datasets.
The results are plotted in Figure 2. In the ﬁgure, the ﬁrst
four methods represent performance of the proposed frame-
work with one emotional signal, i.e., post- and word-level
emotion indication, post- and word-level emotion correla-
tion, respectively. The last is our proposed method with
four emotional signals.

From the ﬁgure, we observe that, with the integration of
all the four diﬀerent emotional signals in a uniﬁed way, the
proposed framework ESSA achieves better performance than
those with only one emotional signal. Among the emotional
signals, word-level emotion indication achieves good perfor-
mance on both datasets. This observation is consistent with
traditional unsupervised methods, which consider that the
quality of the sentiment lexicon is the most important factor
for sentiment analysis. The post- and word-level emotion
correlations have comparable performance. The post-level
emotion indication performs diﬀerently on the two datasets.
To further explore the eﬀects of diﬀerent emotional signals
on unsupervised sentiment analysis, we employ a “knockout”
technique in the experiment. Knockout-based methods have
been widely used in many areas, like gene function anal-
ysis [9], to test the overall performance variance brought
by one process or one component when it is made inopera-
tive in the framework. We conduct experiments to compare
the diﬀerences brought by knocking out one and two emo-
tional signals from the framework. Note that knocking out
three terms is the same as the ﬁrst set of experiments we
conducted in this subsection. Our proposed framework is
general. We can knock out some of the emotional signals
from the framework by setting the corresponding parame-
ters λu
C to zero. The results are sum-
marized in Table 4. In the table, “loss” indicates the per-

C, and λv

I , λu

I , λv

y
c
a
r
u
c
c
A
n
o

 

i
t

a
c
i
f
i
s
s
a
C

l

0.8

0.75

0.7

0.65

0.6

0.55

0.5

 

 

Post−Indication
Word−Indication
Post−Correlation
Word−Correlation
ESSA

STS

Dataset

OMD

Figure 2:
ESSA on the Datasets

Sentiment Classiﬁcation Accuracy of

centage decrease of the methods as compared to the frame-
work “Default” with all the emotional signals. The middle
four columns are the parameter settings, and the last two
columns are the classiﬁcation results on the two datasets.

From the table, we can draw the following observations:
(1) After knocking out any of the emotional signals, perfor-
mance of the proposed framework decreases. This demon-
strates that all the emotional signals we study are useful
for the proposed framework.
(2) Generally, knocking out
emotion indication incurs more performance decrease than
knocking out emotion correlation. This suggests that emo-
tion indication might be more important than emotion cor-
relation information. Among the two signals, knocking out
word-level emotion indication incurs consistently signiﬁcant
performance decreases on both datasets.
6.4 Parameter Analysis

In this subsection, we study the eﬀects of the important

parameters on the proposed framework.

Parameters of the Four Signals: In previous subsec-
tions, for general experiment purposes, we empirically set
equal weights for the emotional signals. Now we take a closer
look at the eﬀects of the parameters λu
C, and λv
C
on the framework. We consider one emotional signal at a
time, and vary the corresponding parameter, denoted as λ,
to adjust its contribution to the general framework. The
experiment results on the two datasets are plotted in Fig-
ure 3(a) and 3(b), respectively.

I , λu

I , λv

From the ﬁgures, it can be seen that: (1) The general
trends of the performance of the emotional signals are sim-
ilar with the variation of parameter settings. Generally, we
can set the parameters between 0.1 and 1 to achieve a rela-
tively good performance. (2) With diﬀerent parameter set-
tings, word-level indication achieves relatively good results
on both datasets, and post-level indication performs diﬀer-
ently on the two datasets. This observation is consistent
with our discussion in Section 6.3.

Parameters of the Two Categories of Signals: We
now examine the parameters to control emotion indication
and emotion correlation information. In particular, we set
equal weights to the signals in the same category, i.e., λu
I =
λv
I = λI , λu
C = λC. The classiﬁcation accuracy of

C = λv

614Table 4: Sentiment Classiﬁcation Accuracy with Diﬀerent Signals on the two Datasets

λu
C

1
1
1
0
1
1
0
1
0
1
0

λv
C
1
1
1
1
0
1
1
0
1
0
0

STS (loss)

OMD (loss)

0.7259

0.6922

0.6729 (-7.30%)
0.6911 (-4.79%)
0.719 (-0.95%)
0.7165 (-1.30%)
0.6187 (-14.77%)
0.6459 (-11.02%)
0.6589 (-9.23%)
0.6815 (-6.11%)
0.6882 (-5.19%)
0.7113 (-2.01%)

0.6882 (-0.58%)
0.6416 (-7.31%)
0.6825 (-1.40%)
0.6798 (-1.79%)
0.6282 (-9.25%)
0.6781 (-2.04%)
0.6646 (-8.32%)
0.6388 (-7.72%)
0.6229 (-10.01%)
0.6725 (-2.85%)

y
c
a
r
u
c
c
A
n
o

 

i
t

a
c
i
f
i
s
s
a
C

l

0.74

0.72

0.7

0.68

0.66

0.64

0.62

0.6

0.58

10

5

1

0.1

Correlation −− λ
C

 0.01

1e−3

1e−3

 0.01

10

5

1

0.1

Indication −− λ
I

Figure 4:
ESSA on STS Dataset

Sentiment Classiﬁcation Accuracy of

Default

Knock Out
One Term

Knock Out
Two Terms

λu
I
1
0
1
1
1
0
0
0
1
1
1

λv
I
1
1
0
1
1
0
1
1
0
0
1

 

Post−Indication
Word−Indication
Post−Correlation
Word−Correlation

0.8

0.75

0.7

0.65

0.6

0.55

y
c
a
r
u
c
c
A
n
o
i
t

 

a
c
i
f
i
s
s
a
C

l

 
t

n
e
m

i
t

n
e
S

0.5
 
0

1e−4

1e−3

1e−2
0.1
Parameter λ

1

10

100

(a) STS Dataset

 

Post−Indication
Word−Indication
Post−Correlation
Word−Correlation

0.8

0.75

0.7

0.65

0.6

0.55

y
c
a
r
u
c
c
A
n
o

 

i
t

a
c
i
f
i
s
s
a
C

l

 
t

n
e
m

i
t

n
e
S

0.5
 
0

1e−4

1e−3

0.01
0.1
Parameter λ

1

10

100

Table 5: Optimal Sentiment Classiﬁcation Results
on the two Datasets

(b) OMD Dataset

Figure 3: Performance Variation of the Emotional
Signals with Diﬀerent Parameters

ESSA on the two datasets with diﬀerent settings of λI and
λC are plotted in Figure 4.

In Figure 4, performance of ESSA improves as λI and λC
increase, and reaches a peak at λI = 1 and λC = 0.1. When
λI > 1 or λC > 0.1, the performance of ESSA declines.
Generally, the performance is not sensitive to λC. The re-
sults further demonstrate that the proposed framework can
achieve a relatively good performance when setting the pa-
rameters in the range of 0.1 to 1. Similar results have been
observed on the OMD dataset; we omit the results owing to
lack of space.

Optimal Results: As emotion indication appears to be
more important than emotion correlation information, we

Method
GI-Label
ESSA

ESSA-opt

STS (gain)

OMD (gain)

0.615

0.602

0.726 (+17.96%)
0.7471 (+21.40%)

0.692 (+14.96%)
0.7097 (+17.87%)

try to place higher weights on the two emotion indication
signals. In Table 5, we summarize the performance of GI-
Label, our proposed method ESSA, and ESSA with optimal
parameters (1, 1, 0.3, 0.3) on STS and (1, 0.3, 0.5, 0.5)
on OMD. As compared to GI-Label, we can achieve 21.40%
and 17.87% improvement on the two datasets, respectively.
The performance of ESSA-opt is better than that of ESSA.
This implies that although the performance of our method is
relatively good, it can be further improved by analyzing the
importance of emotional signals, and place higher weights
on the relatively more important signals.

6157. CONCLUSION

where

Texts in social media are short, fast-evolving, and infor-
mal, which presents challenges to sentiment analysis. Mean-
while, we show that there are emotional signals available in
social media data. In this paper, we investigate a novel prob-
lem of interpreting emotional signals for unsupervised sen-
timent analysis. In particular, we ﬁrst conduct exploratory
study on two Twitter datasets to verify the existence of emo-
tional signals. The post- and word-level emotion indication
and emotion correlation are then employed as regularizers
to a matrix tri-factorization based unsupervised sentiment
analysis framework. Extensive experiments are conducted,
and the results demonstrate the eﬀectiveness of the proposed
framework as well as the roles of diﬀerent emotional signals
in sentiment analysis.

There are many potential future extensions of this work.
It is interesting to investigate the contributions of other emo-
tion indication information available in social media, like
product ratings and restaurant reviews.
It is also inter-
esting to study other emotion correlation information, like
spatial patterns and homophily eﬀect [33], to measure the
sentiment orientation of social media posts as well. In addi-
tion, utilizing such models for real-world applications, e.g.,
analyzing sentiments of crowd’s responses in a hyperlocal
community [16], is also a promising direction.

Acknowledgments
We truly thank the anonymous reviewers for their perti-
nent comments. This work is, in part, supported by ONR
(N000141110527) and (N000141010091).

APPENDIX
A. COMPUTATION OF U

Optimizing the objective function in Eq. (11) with respect

to U is equivalent to solving
JU = (cid:4)X − UHV
+ λu

min
U≥0

CT r(U
T
s.t. U

TLu
U).
U = I.

Let ΛU and ΓU be the Lagrange multipliers for constraints
U ≥ 0 and UT U = I, respectively; the Lagrange function
L(U) is deﬁned as follows:
T(cid:4)2
F + λu
U) − T r(ΛU U

L(U) = (cid:4)X − UHV
TLu

(U − U0)(cid:4)2

) + T r(ΓU (U

CT r(U

I (cid:4)G

+ λu

F

u

T

T

By setting the derivative ∇UL(U) = 0, we get

ΛU = −2XVH

T

+ 2λu

C(D

+ 2UHV

T

T
VH
)U + 2UΓU .

u − W

u

+ 2λu

u
I G

(U − U0)

(23)
With the KKT complementary condition for the nonneg-

ativity constraint of U, we have

ΛU (i, j)U(i, j) = 0 ;

thus, we obtain
[−XVH
+ λu
C(D

T

+ UHV
u − W

u

T

T
VH

(U − U0)
)U + UΓU ](i, j)U(i, j) = 0,

+ λu

u
I G

(24)

(25)

T(cid:4)2

F + λu

I (cid:4)G

u

(U − U0)(cid:4)2

F

(31)
With the KKT complementary condition for the nonneg-

T − HV
u
G

T

T
VH

(U − U0) − λu

C(D

u − W

u

)U.

(26)

ΓU =U

T

XVH
T

I U

− λu
U−Γ

Let ΓU = Γ+

−
U , where Γ+

U (i, j) = (|ΓU (i, j)|+ΓU (i, j))/2

U (i, j) = (|ΓU (i, j)| − ΓU (i, j))/2 [7], we get
−

and Γ
[−(XVH
+ (UHV

T

T

+ λu

u
I G
T
VH

U0 + λu

u

CW
U + λu

C D

+ λu

u
I G

U + UΓ

−
U )

u

U + UΓ

+
U )](i, j)U(i, j) = 0.

(27)

which leads to the updating rule of U,

(cid:7)(cid:8)(cid:8)(cid:9) [XVHT + λu

I GuU0 + λu

[UHVT VHT + λu

I GuU + λu

U(i, j) ← U(i, j)

U ](i, j)

CWuU + UΓ−
C DuU + UΓ+
(28)

U ](i, j)

.

B. COMPUTATION OF V

Optimizing the objective function in Eq.( 11) with respect

min
V≥0

to V is equivalent to solving
JV = (cid:4)X − UHV
+ λv
s.t. V

TLv
V = I.

C T r(V

V).

T

T(cid:4)2

F + λv

I(cid:4)G

v

(V − V0)(cid:4)2

F

(29)

We introduce two Lagrange multipliers ΛV and ΓV for the

constraints; the Lagrange function is deﬁned as follows:

L(V) = (cid:4)X − UHV
TLv

CT r(V

+ λv

I(cid:4)G

T(cid:4)2
F + λv
V) − T r(ΛV V

v

(V − V0)(cid:4)2

F

T

) + T r(ΓV (V

T

By setting the gradient ∇VL(V) = 0, we get

V − I)).
(30)

ΛV = −2X
+ 2λv
C (D

T

T
UH + 2VH
v − W

v

)V + 2VΓV .

T

UH + 2λv

v
I G

U

(V − V0)

(21)

ativity constraint of U, we have

ΛV (i, j)V(i, j) = 0

thus, we obtain

[−X
+ λv

T

T
UH + VH
v − W
v

C (D

T

U

UH + λv

(V − V0)
)V + VΓV ](i, j)V (i, j) = 0,

v
I G

(32)

(33)

U − I))
(22)

where

ΓV =V

T

T

X
− λv
V −Γ

I V

T

UH − H
v
G

U

UH
(V − V0) − λv

T

T

v − W

v

)V.

(34)

C (D

Let ΓV = Γ+

−
V , where Γ+

V (i, j) = (|ΓV (i, j)|+ΓV (i, j))/2

V (i, j) = (|ΓV (i, j)| − ΓV (i, j))/2, we get
−
UH + λv

V0 + λv

V + VΓ

v
I G

−
V )

v

T

UH + λv

v
I G

U

CW
V + λv

CD

and Γ
[−(X
T
+ (VH

T

v

V + VΓ

+
V )](i, j)V (i, j) = 0.

(35)

which leads to the updating rule of V,

V(i, j) ← V(i, j)

(cid:7)(cid:8)(cid:8)(cid:9) [XT UH + λv

I GvV0 + λv

[VHT UT UH + λv

I GvV + λv

V ](i, j)

CWvV + VΓ−
C DvV + VΓ+
(36)

V ](i, j)

.

6168. REFERENCES

[1] R. Abelson. Whatever became of consistency theory?

Personality and Social Psychology Bulletin, 1983.

[2] A. Andreevskaia and S. Bergler. Mining wordnet for

fuzzy sentiment: Sentiment tag extraction from
wordnet glosses. In Proceedings of EACL, 2006.

[3] S. Asur and B. Huberman. Predicting the future with

social media. In WI-IAT, pages 492–499, 2010.
[4] J. Bollen, H. Mao, and X. Zeng. Twitter mood

predicts the stock market. Journal of Computational
Science, 2011.

[5] S. Boyd and L. Vandenberghe. Convex optimization.

Cambridge university press, 2004.

[6] S. Brody and N. Diakopoulos.

Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!: using word
lengthening to detect sentiment in microblogs. In
Proceedings of EMNLP, pages 562–570, 2011.

[7] C. Ding, T. Li, and M. Jordan. Convex and

semi-nonnegative matrix factorizations. IEEE TPAMI,
32:45–55, 2010.

[8] C. Ding, T. Li, W. Peng, and H. Park. Orthogonal

nonnegative matrix t-factorizations for clustering. In
Proceedings of SIGKDD, pages 126–135, 2006.
[9] T. Egener, J. Granado, and M. Guitton. High

frequency of phenotypic deviations in physcomitrella
patens plants transformed with a gene-disruption
library. BMC Plant Biology, 2:6, 2002.

[10] A. Go, R. Bhayani, and L. Huang. Twitter sentiment

classiﬁcation using distant supervision. Technical
Report, Stanford, pages 1–12, 2009.

[11] Q. Gu and J. Zhou. Co-clustering on manifolds. In

Proceedings of SIGKDD, pages 359–368, 2009.

[12] T. Hofmann. Probabilistic latent semantic indexing. In

Proceedings of SIGIR, pages 50–57, 1999.

[13] M. Hu and B. Liu. Mining and summarizing customer

reviews. In Proceedings of SIGKDD, 2004.

[14] X. Hu, N. Sun, C. Zhang, and T.-S. Chua. Exploiting

internal and external semantics for the clustering of
short texts using world knowledge. In Proceedings of
CIKM, pages 919–928, 2009.

[15] X. Hu, L. Tang, J. Tang, and H. Liu. Exploiting social

relations for sentiment analysis in microblogging. In
Proceedings of WSDM, 2013.

[16] Y. Hu, S. D. Farnham, and A. Monroy-Hern´andez.

Whoo. ly: Facilitating information seeking for
hyperlocal communities using social media. In
Proceedings of CHI, 2013.

[17] Y. Hu, A. John, D. Seligmann, and F. Wang. What
were the tweets about? topical associations between
public events and twitter feeds. ICWSM, 2012.
[18] E. Kim, S. Gilbert, M. Edwards, and E. Graeﬀ.
Detecting sadness in 140 characters: Sentiment
analysis of mourning michael jackson on twitter. 2009.
[19] T. Li, V. Sindhwani, C. Ding, and Y. Zhang. Bridging

domains with words: Opinion analysis with matrix
tri-factorizations. In Proceedings of SDM, 2010.

[20] B. Liu. Sentiment analysis and subjectivity. Handbook

of Natural Language Processing, 2010.

[21] B. Liu and L. Zhang. A survey of opinion mining and

sentiment analysis. Mining Text Data, 2012.

[22] K.-L. Liu, W.-J. Li, and M. Guo. Emoticon smoothed

language models for twitter sentiment analysis. In
Proceedings of AAAI, 2012.

[23] Y. Lu, M. Castellanos, U. Dayal, and C. Zhai.

Automatic construction of a context-aware sentiment
lexicon: an optimization approach. In Proceedings of
WWW, pages 347–356, 2011.

[24] B. O Connor, R. Balasubramanyan, B. Routledge, and

N. Smith. From tweets to polls: Linking text
sentiment to public opinion time series. In Proceedings
of ICWSM, 2010.

[25] B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?:

sentiment classiﬁcation using machine learning
techniques. In Proceedings of ACL, pages 79–86, 2002.

[26] W. Peng and D. H. Park. Generate adjective

sentiment dictionary for social media sentiment
analysis using constrained nonnegative matrix
factorization. In ICWSM, 2011.

[27] S. Prentice and E. Huﬀman. Social medias new role in

emergency management. Idaho National Laboratory,
pages 1–5, 2008.

[28] D. Seung and L. Lee. Algorithms for non-negative

matrix factorization. NIPS, pages 556–562, 2001.

[29] D. Shamma, L. Kennedy, and E. Churchill. Tweet the

debates: understanding community annotation of
uncollected sources. In Proceedings of WSM, 2009.

[30] M. Speriosu, N. Sudan, S. Upadhyay, and

J. Baldridge. Twitter polarity classiﬁcation with label
propagation over lexical links and the follower graph.
In Proceedings of the First Workshop on Unsupervised
Learning in NLP, 2011.

[31] P. Stone, D. Dunphy, and M. Smith. The general

inquirer: A computer approach to content analysis.
1966.

[32] M. Taboada, J. Brooke, M. Toﬁloski, K. Voll, and

M. Stede. Lexicon-based methods for sentiment
analysis. Computational Linguistics, 2011.

[33] J. Tang, H. Gao, X. Hu, and H. Liu. Exploiting

homophily eﬀect for trust prediction. In WSDM, 2013.

[34] P. Turney. Thumbs up or thumbs down?: semantic
orientation applied to unsupervised classiﬁcation of
reviews. In Proceedings of ACL, pages 417–424, 2002.

[35] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating

analysis on review text data: a rating regression
approach. In Proceedings of SIGKDD, 2010.

[36] J. Wiebe, T. Wilson, and C. Cardie. Annotating
expressions of opinions and emotions in language.
Language Resources and Evaluation, 39:165–210, 2005.

[37] T. Wilson, J. Wiebe, and P. Hoﬀmann. Recognizing

contextual polarity in phrase-level sentiment analysis.
In Proceedings of HLT and EMNLP, 2005.

[38] Y. Xie, Z. Chen, K. Zhang, M. M. A. Patwary,

Y. Cheng, H. Liu, A. Agrawal, and A. Choudhary.
Graphical modeling of macro behavioral targeting in
social networks. In Proceedings of SDM, 2013.

[39] L. Zhang and B. Liu. Identifying noun product
features that imply opinions. In Proceedings of
ACL:HLT, pages 575–580, 2011.

[40] J. Zhao, L. Dong, J. Wu, and K. Xu. Moodlens: an

emoticon-based sentiment analysis system for chinese
tweets. In Proceedings of SIGKDD, 2012.

617