HeteroMF: Recommendation in Heterogeneous Information

Networks using Context Dependent Factor Models

Mohsen Jamali

Department of Computing Science

University of British Columbia

Vancouver, Canada

jamalim@cs.ubc.ca

Laks V.S. Lakshmanan

Department of Computing Science

University of British Columbia

Vancouver, Canada
laks@cs.ubc.ca

ABSTRACT
With the growing amount of information available online, recom-
mender systems are starting to provide a viable alternative and
complement to search engines, in helping users to ﬁnd objects of
interest. Methods based on Matrix Factorization (MF) models are
the state-of-the-art in recommender systems. The input to MF is
user feedback, in the form of a rating matrix. However, users can
be engaged in interactions with multiple types of entities across
different contexts, leading to multiple rating matrices.
In other
words, users can have interactions in a heterogeneous information
network. Generally, in a heterogeneous network, entities from any
two entity types can have interactions with a weight (rating) indi-
cating the level of endorsement. Collective Matrix Factorization
(CMF) has been proposed to address the recommendation problem
in heterogeneous networks. However, a main issue with CMF is
that entities share the same latent factor across different contexts.
This is particularly problematic in two cases: Latent factors for en-
tities that are cold-start in a context will be learnt mainly based on
the data from other contexts where these entities are not cold-start,
and therefore the factors are not properly learned for the cold-start
context. Also, if a context has more data compared to another con-
text, then the dominant context will dominate the learning process
for the latent factors for entities shared in these two contexts. In this
paper, we propose a context-dependent matrix factorization model,
HETEROMF, that considers a general latent factor for entities of ev-
ery entity type and context-dependent latent factors for every con-
text in which the entities are involved. We learn a general latent fac-
tor for every entity and transfer matrices for every context to con-
vert the general latent factors into a context-dependent latent factor.
Experiments on two real life datasets from Epinions and Flixster
demonstrate that HETEROMF substantially outperforms CMF, par-
ticularly for cold-start entities and for contexts where interactions
in one contexts are dominated by other contexts.

Categories and Subject Descriptors
H.2.8.d [Information Technology and Systems]: Database Appli-
cations - Data Mining

General Terms
Algorithms, Measurement, Experimentation

Keywords
Recommendation, Matrix Factorization, Multi-Context, Cold Start
Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW 2013, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

1.

INTRODUCTION

With the rapidly growing amount of information available on
the WWW, it becomes necessary to have tools to help users to se-
lect the relevant part of online information. To satisfy this need,
recommender systems have emerged, e.g., there are popular rec-
ommenders for movies1, books2, music3, etc. Recommender are
becoming a viable alternative and complement to search engines
in helping users to ﬁnd objects of interest. Typically, in a recom-
mender system, a set of users interact with a set of items. The inter-
actions vary, e.g., from users providing explicit scores for movies
or books, to users listening to songs multiple times, to joining a
community or favoriting a photo. We generically refer to all types
of interactions in which users endorse items as ratings. The ratings
expressed by users on items are stored in a rating matrix, which
is typically extremely sparse [1, 10]. The classical task of a rec-
ommender is to predict the rating for user u on a non-rated item i
based on the known ratings.

Matrix Factorization (MF) [13, 8] based models are the state-
of-the-art methods for recommender systems. MF factors the rat-
ing matrix into two low rank matrices that represent latent fac-
tors for users and items. The model based on these factor ma-
trices is then used for rating predictions. The typical setting in
recommender systems is based on interactions between two types
of entities. However, increasingly, there are social eco-systems
where multiple entity types co-exist and interact with each other
and across a variety of contexts, leading to multiple rating matri-
ces. In other words, entities can have interactions in a Heteroge-
neous Information Network (HIN). Generally, in a heterogeneous
network, entities from any two entity types can have interactions,
with a weight (rating) indicating the level of endorsement. For ex-
ample, in a social media service like LinkedIn4, there are entities
of types user, company, university, etc., and there are interactions
in the form of user-user, user-company, company-university, etc.
The recommendation problem we study in this paper is how to
recommend entities of one type to those of another, e.g., users to
users (contacts), universities to companies (hiring), or professors to
companies (expertise), leveraging the feedback data from the var-
ious interactions to predict the weight (rating) on interactions that
have yet to happen. Recommendations in heterogeneous informa-
tion networks can be valuable for applications like feed ranking.
For instance, consider personalizing the news feeds in Facebook,
Google+ or LinkedIn, where any entity can have news updates and
entities from different types can get engaged in interactions, includ-

1www.netﬂix.com
2www.amazon.com
3www.last.fm
4www.linkedin.com

643ing the consumption of news feeds. This can make use of not just
ranking based on content but also the predicted importance of the
appropriate entity. E.g., if a student is more interested in certain
companies, this can be factored in the way news feeds from various
entities are ranked, for that student. Here, predicting the impor-
tance of one entity for another requires a recommendation model
that can work on heterogeneous networks. Figure 1 illustrates the
“schema” of a sample heterogeneous information network.

Figure 1: Schema of a sample Heterogeneous Information Net-
work.

Collective Matrix Factorization (CMF) [17, 9] has been pro-
posed to address the recommendation problem in heterogeneous
networks. In CMF, every entity has a latent factor and interactions
between two entities are governed by their corresponding latent
factors. The latent factor of an entity is learnt based on the ob-
served interaction data from all the contexts in which this entity is
involved in interactions. However, a main issue with CMF is that
entities share the same latent factor across different contexts. This
is particularly problematic in two cases. First, suppose an entity
e is cold-start in one context c. That is, e participates in very few
interactions (ratings) in context c. Latent factors for entity e will be
learnt mainly based on the interaction data from other contexts c(cid:48)
where e is not cold-start, and therefore the factors are not properly
learned for the cold start entities in the context c. Second, suppose a
context has signiﬁcantly more interaction data compared to another
context. Then the dominant context will dominate the learning pro-
cess for the latent factors for entities shared in these two contexts.
In this case, the latent factors for the shared entities are not learnt
properly for the dominated context, even for non cold start entities
in the dominated context.

Recall that we use rating as a general term to include the real
valued item ratings in Epinions5 and Flixster6 and binary rating
values such as joining a community in Facebook7 and LiveJournal8
or adding a photo to your favorite list in Flickr9. Also, visit counts
on a Web page or the number of interactions among two entities are
also indicators of ratings (weights) on these interactions. In other
words, any type of user behavior demonstrating her evaluation (or
5www.epinions.com
6www.ﬂixster.com
7www.facebook.com
8www.livejournal.com
9www.ﬂickr.com

endorsement) of an entity can be regarded as a rating (binary or real
values).

In this paper, we propose a context-dependent matrix factoriza-
tion model, HETEROMF, that extends CMF and considers a gen-
eral latent factor for every entity type and a context-dependent la-
tent factor for every context in which the entity is involved. HET-
EROMF learns a general latent factor for every entity and transfer
matrices for every context, to convert the general latent factors into
context-dependent latent factors.

To test the effectiveness of our proposed method, we conduct a
detailed set of experiments on two real life datasets from Epinions
and Flixster. Our results demonstrate that HETEROMF substan-
tially outperforms CMF, particularly for cold-start entities and for
contexts where the size of the interaction data is dominated by other
contexts.

There has been a large body of recent work on link prediction
in heterogeneous information networks [21, 19]. We review these
works in detail in Section 3, but note here that their main focus is
analyzing how topological structures in heterogeneous networks af-
fect link (relationship) formation and using this to predict whether
(and, in some cases, when) an entity will form a relationship with
another. As such our goal and methodology are different from
theirs. The main goal of this paper is to learn the latent factors
governing the behavior of entities in different contexts (rather than
using topological structures), and address the issues mentioned for
the state-of-the-art CMF methods.

In this paper, we make the following contributions:
• We introduce the novel HETEROMF model, a generalized
CMF based model that considers general latent factors for
entities as well as context speciﬁc latent factors for the con-
texts in which entities are involved in interactions.

• We use a transfer matrix to convert base latent factors into
context speciﬁc latent factors. Transfer matrices are learnt
per context.

• HETEROMF is particularly helpful for cold start entities, and
for the contexts that are dominated by the interactions from
other contexts.

• We perform experiments on two real life data sets from Epin-
ions and Flixster. Experimental results show that HETEROMF
achieves substantial RMSE gain compared to CMF, particu-
larly for cold start entities, and for the contexts dominated by
other contexts.

The rest of the paper is organized as follows: Preliminaries and
problem deﬁnition are discussed in Section 2, followed by some of
more recent related works in Section 3. Our proposed HETEROMF
model is introduced in Section 4. Also we discuss the inference
algorithm for HETEROMF in Section 4. In Section 5, we present
our experimental results on real life datasets. Finally, we conclude
the paper and discuss some future work in Section 6.

2. PRELIMINARIES

In this section, we review some preliminaries and formally state

the problem studied in this paper.
A heterogeneous information network (HIN) G consists of N
entity types denoted by U = {U1, ..., UN} and τ contexts de-
noted by L = {L1, .., Lτ}. Each context Ll consists of interac-
tions among entities from two participating entity types Un and
Um, where Un, Um ∈ U. For example movie ratings is an instance
of a context in which entities of type user interact with entities of

644type movie and the interactions result in interaction weights that we
generically call ratings. Note that the two participating entity types
of a context can be the same: e.g., in the context of social networks
both entity types are user. Similarly, more than one context can
bring about interactions between the same pair of entity types: e.g.,
a social network (with explicit links) as well as a co-authorship net-
work (based on common published papers) are two contexts which
relate users with users.

The observed interactions in a context Ll are stored in a context-
speciﬁc rating matrix Rl. Rl is typically a very sparse matrix. Ev-
ery cell in this matrix, rl
u,v, denotes the rating (interaction weight)
observed from entity u ∈ Un on entity v ∈ Um. Here Un and Um
are the entity types participating in the context Ll. The set of all
rating matrices corresponding to the various contexts is denoted R.

We next formally state the problem we study in this paper.

DEFINITION 1

(PROBLEM STUDIED). Given a heterogeneous
information network G = (cid:104)U,L,R(cid:105) , a context Ll ∈ L consisting
of interactions among Un ∈ U and Um ∈ U, and entities u ∈ Un
and v ∈ Um such that rl
u,v using the
observed ratings in R.

u,v is unknown, predict rl

Figure 2: Graphical model representing MF.

3. RELATED WORK

Matrix Factorization (MF) is one of the common techniques for
model-based recommendation. MF has been proposed in order to
perform predictions for a single user-item rating matrix, for a single
context, unlike the setting in this paper. In MF, each user and each
item is associated with a K dimensional latent factor vector [6]: the
latent factor of user u is denoted Uu and stored as the uth row of
user factor matrix U. The latent factor of item i is denoted Vi and
stored as the ith row of item factor matrix V .

In order to learn the latent factors of users and items, [13] em-
ploys probabilistic matrix factorization to factor the user-item ma-
trix into the product of user and item latent factors. The conditional
probability of the observed ratings is deﬁned as:

N(cid:89)

M(cid:89)

(cid:104)N(cid:16)

u=1

i=1

(cid:17)(cid:105)IR

u,i

p(R|U, V, σ2

R) =

Ru,i|U T

u Vi, σ2
r

(1)

where N (x|µ, σ2) is the normal distribution with mean µ and
u,i is the indicator function that is equal to 1 if
variance σ2, and I R
u has rated i and equal to 0 otherwise. Also, zero mean Gaussian
priors are assumed for user and item factors:

M(cid:89)

i=1

N(cid:89)

u=1

p(U|σ2

U ) =

N (Uu|0, σ2

UI), p(V |σ2

V ) =

N (Vi|0, σ2

V I)

(2)
Figure 2 presents the graphical model representing matrix fac-
torization. The latent factors of users and items are learnt in MF
using the observed rating matrix. To predict the rating of user v on
item j in the test phase, the inner product of learnt latent factors Uv
and Vj is computed as the predicted rating.

The matrix factorization based method, essentially considered
the state-of-the-art method for recommendation, has been recently
extended to incorporate other factors in the factorization of the rat-
ing matrix: these include modeling at multiple scales [3], incorpo-
rating users with similar rating patterns [6], and taking the times-
tamps into account [7]. The last approach [7] won the Netﬂix grand
$1M prize10. Matrix factorization is the basis for building extended
models such as collective matrix factorization, and our proposed
model, HETEROMF.

10http://www.netﬂixprize.com/

In this section, we review some related work on matrix factoriza-
tion, collective matrix factorization and recommendation and link
prediction in heterogeneous information networks.

As discussed in the previous section, matrix factorization is pro-
posed for single context domains, where there is only one rating
matrix. However, users can be involved in interactions across mul-
tiple contexts. In this case, one could ﬁt the rating matrix in each
context separately. However, this approach would not take advan-
tage of any correlations between contexts. In other words, informa-
tion from one context does not propagate to another context. This
approach is called separate matrix factorization (SMF) and we use
SMF as one of our baseline models in our experiments.

Singh and Gordon [17] proposed Collective Matrix Factorization
(CMF) for learning in multi-context domains. CMF decomposes
the rating matrix in every context into a product of latent factor ma-
trices of the entities from the two participating entity types of the
context. Whenever an entity type participates in more than one con-
text, the latent factors for that entity type are shared among the con-
texts in which this entity participates. Figure 3 shows an example
graphical model representing a CMF model. In this model, there
are two contexts (with observed ratings R and O) and three entity
types (U, V, Z). E.g., it could represent users (U) rating movies
(V ) and books (Z). The graphical model representing CMF for
more than two contexts is simply a generalization of the one shown
in Figure 3.

Figure 3: Graphical model representing a simple Collective
Matrix Factorization (CMF), with only two contexts.

645In CMF, the latent factor of an entity from a speciﬁc entity type
is learned based on the observed ratings from the contexts in which
this entity type participates. However, a main issue with CMF is
that entities share the same latent factor across different contexts.
We conjecture that this is particularly problematic in two cases.
First, latent factors for entities that are cold-start in a context will
be learned mainly based on the data from other contexts where it
is not cold-start, and therefore the factors are not properly learned
for the cold-start context. In practice, cold start entities are entities
that have very few (normally less than 5) observed ratings that they
participate in.

Second, if a context has more interaction data compared to an-
other context, then the dominant context will dominate the learning
process for the latent factors for entities shared in these two con-
texts. In other words, the latent factors for all entities in the shared
entity type are learnt mainly based on the dominating context and
the dominated context has very little effect on the learned latent
factors. Therefore, the latent factors are not properly learned for
representing the dominated context. In this paper, we address these
issues by introducing context-dependent latent factors besides hav-
ing general factors for entities in different entity types. CMF is our
main competitor in the experiments and we show that our proposed
model addresses the above issues with CMF and substantially out-
performs it.

Collective matrix factorization has also been used in [9]. Lippert
et al. [9] consider user attributes (e.g., gender, age, etc.) as differ-
ent contexts. However, in recent papers [24, 2, 4] user attributes
(features) are considered as the prior for user latent factors, and a
transfer matrix [24] is used to generate a latent factor using user at-
tributes. In our research, we do not assume we have access to entity
attributes. However, we use the same idea as in [24, 2, 4] to gener-
ate context-speciﬁc latent factor using the general latent factor for
the entity and a context-dependent transfer matrix.

Recently, Yang et al. [22] employed collective matrix factoriza-
tion for recommendation in social rating networks where there is a
rating matrix between users and items and a social network among
users. The proposed model in this paper considers the social net-
work and user ratings as two contexts and decomposes each context
into the product of latent factors of the entities corresponding to
the participating entity types of that context. The model proposed
in [22] can be represented by the graphical model demonstrated in
Figure 3 by setting Z = U and letting O denote social relations.
Note that the social network in this paper is considered to be undi-
rected. Among other things, the authors showed that their approach
leads to better prediction accuracy than using the ratings alone or
using the soial network alone.

There is an important body of research on link prediction in het-
erogeneous information networks [21, 23, 19, 14, 18]. These works
particularly focus on how topological structures in heterogeneous
networks affect the relationship building and whether an entity en-
gages in an interaction with another entity or not. Yu et al. [23]
and Sun et al.
[18] used the concept of “meta-path”, ﬁrst intro-
duced in [20], to deﬁne features for a potential interaction between
entities a and b, and further used these features to learn a regres-
sion function to compute the probability of a link (interaction). In
the meta-path based approach, a set of path patterns from entity a
to b is selected and the number of such paths is computed to de-
termine the path-speciﬁc features. Computation of paths between
two entities is performed on the ﬂy (memory-based) which requires
exploring the HIN and makes the meta-path based methods slower
in prediction compared to model-based approaches such as CMF
that do not require to access the raw data after the learning phase.
Meta-path based methods also have a training phase to learn the

regression weights to combine the various topological features to
compute the probability of an interaction.

Shi et al. [16, 15] proposed a model to use the labeled data from
other related (heterogeneous) sources to help in predicting the tar-
get task even if they have different feature spaces and distributions.
This paper proposes a solution and discusses the conditions where
this is possible and highly likely to produce better results. This
model uses spectral embedding to unify the different feature spaces
of the target and source data sets, even when they have completely
different feature spaces. The principle is to cast into an optimiza-
tion objective that preserves the original structure of the data, while
at the same time, maximizes the similarity between the two [16].
Next, a sample selection strategy is applied to select only those
related source examples. Finally, a Bayesian-based approach is
applied to model the relationship between different output spaces.
While these works are very interesting, they mainly deal with trans-
ferring feature spaces from a domain to another domain, rather than
learning from interactions in other contexts which is our main fo-
cus.

4. PROPOSED HETEROMF

In this section we introduce our proposed model, HETEROMF,
that extends collective matrix factorization and incorporates con-
text dependent latent factors for entities, in their interactions in dif-
ferent contexts. As discussed before, the main problem with CMF
models is that the latent factors for entities of an entity type are
shared among all the contexts that this entity type participates in.
Recall that this is particularly problematic for cold-start entities,
and for contexts dominated by other contexts.

To address these issues, we propose HETEROMF, a generalized
context dependent collective matrix factorization based approach.
In our proposed model, each entity of every entity type has a base
latent factor. For each context in which this entity type partici-
pates, entities of that type have a context speciﬁc latent factor. To
elaborate on the intuition,suppose that in a domain, users can rate
movies and books. In this example, users have some general fac-
tors representing their general rating behavior. However, the factors
governing users’ behavior in the context of movies is different from
her factors in the context of books. Context speciﬁc factors depend
on the base factors and can be derived from the base factors of an
entity. In HETEROMF, a transfer matrix is used to transfer the base
factors to the context speciﬁc factors in each context. The following
is the list of latent factors used in HETEROMF:

• Latent factors for entities of type Un are denoted by Un, n ∈
[1, N ]. The latent factor for an entity u ∈ Un is denoted by
Un,u.

• Entities of an entity type have their own context speciﬁc la-
tent factors in the contexts Ll this entity type participates in
n. In
and the context speciﬁc latent factors are denoted by U l
HETEROMF, context speciﬁc latent factors U l
n are generated
using the base latent factors Un and a context speciﬁc trans-
fer matrix M l
n. The context speciﬁc latent factor for an entity
u ∈ Un and for context Ll is denoted by U l

n,u.

n and U l

• Every context Ll has two entity types. Therefore every con-
text Ll is associated with two context-dependent entity latent
factors U l
m. In some cases such as social relations,
we can have n = m. Note that for each context, there are
two separate transfer matrices M l
m, unless the con-
text is an undirected network (n = m). It should be noted
that if a network is undirected, then M l

n and M l

n = M l

m.

646In our proposed HETEROMF model, the observed ratings for a
context Ll are generated using the context speciﬁc latent factors
for the entities whose entity types participate in that context, as
follows:

u,v ∼ N (U
Rl

(cid:48)l
n,uU l

r,l)

m,v, σ2

(3)
In this equation and in what follows, we use M(cid:48) to denote the
transpose of matrix M. Context speciﬁc latent factors U l
n are gen-
erated using the product of the base latent factors Un and a context
n,u is a k1-dimensional column
speciﬁc transfer matrix M l
vector and Un,u is a k2-dimensional column vector, then M l
n is
a k2 × k1 matrix that converts the base latent factor to a context
speciﬁc latent factor. M l
n should be learned in the training phase.

n. If U l

n,u ∼ N (M l
U l

l,nI)

nUn,u, σ2

(4)
In the above Equation, I is the identity matrix. Similar to regular
MF, every base latent factor has a zero-mean normal prior. Note
that, if the attributes for different entity types (e.g., age and gender
for users or location for companies) were available, we could use
them as the mean of the normal distribution for prior, instead of a
zero mean normal prior.

Un,u ∼ N (

−→
0 , σ2

nI)

(5)
Figure 4 demonstrates the graphical model representing the HET-
EROMF model. In this graphical model, σn denotes the variance
for the distribution of base latent factors Un, σl,n is the variance
for context speciﬁc latent factors U l
n, and σr,l is the variance for
the observed ratings in the context Ll.

be dominated. Although the base factors for the shared entity type
can be dominated, notice that the transfer matrices are learned per
context, leading to a proper learning of the context speciﬁc latent
factors and resolving the shared latent factors’ issues in CMF.

Using the graphical model demonstrated in Figure 4 , the com-
plete data likelihood (joint likelihood) in HETEROMF is computed
as follows:

(cid:89)
(cid:0)P (U l

l

×(cid:89)

l

P (R, θ|η) =

P (Rl|U l

n, U l

m, σr,l)

n|Un, M l

n, σl,n) × P (U l

m|Um, M l

m, σl,m)(cid:1)

P (Un|σn)

(6)

×(cid:89)

n

In the above equations, we have:

η = {∪nσn,∪lσl,n,∪lσl,m,∪lσr,l, M = ∪l{M l

n, M l

m}}

θ = {∪lU l

n,∪lU l

m,∪nUn}, R = ∪l{Rl}

It should be noted that if Rl is an undirected network, then M l
m and therefore U l

n =
m,u. Using Equations (3)-(6), the log-

M l
likelihood of the complete data is computed as follows:

n,u = U l

(cid:19)IR,l

u,v

(cid:0)rl

u,v−U

L = − 1
2

− 1
2

− 1
2

σ2
r,l

l

n

m

v∈U l

u∈U l

(cid:18) 1
(cid:88)
(cid:88)
(cid:88)
(cid:18) 1
(cid:88)
(cid:88)
(cid:0)U l
(cid:18) 1
(cid:88)
(cid:88)
(cid:0)U l
(cid:88)
(cid:88)

u∈Um

u∈Un

σ2

σ2

l,m

l,n

l

l

− 1
2

n,u − M l

nUn,u

m,u − M l

(cid:18) 1

mUm,u

(cid:0)Un,u

r,l

m,v

(cid:48)l
n,uU l

(cid:1)2+log σ2
(cid:19)
(cid:1)2 + kl log σ2
(cid:19)
(cid:1)2 + kl log σ2
(cid:19)
(cid:1)2 + kn log σ2

l,m

l,n

n

(7)

n

u∈Un

σ2
n

In the above equations, I R,l

u,v is an indicator that returns 1 if entity
u has a relation with entity v in the context Ll, and returns 0 other-
wise. Also, kl is the dimensionality of latent factors in context Ll,
and kn is the dimensionality of factors for entity type Un.

Figure 4: The graphical model representing HETEROMF.

HETEROMF is particularly helpful for entities that are cold-start
in a context but are active in other contexts. HETEROMF uses the
base factors of those entities and transfers them to the context spe-
ciﬁc latent factors using the transfer matrix for that context, without
being dominated by the latent factors from the contexts in which
these entities are not cold-start. Also, even if a context is domi-
nated by another context, the context speciﬁc latent factors will not

4.1 Inference in HeteroMF

We use expectation maximization (EM) to ﬁt HETEROMF and
learn the latent factors and model parameters. In the E step, we
compute the expected log-likelihood with respect to the latent vari-
ables (Eθ|R,η(L)). In the M step, we maximize the expected like-
lihood with respect to the model parameters (η) to compute the
model parameters. The EM iterations are repeated until conver-
gence.

The expected log-likelihood is computed as follows:

647(8)

σ2
r,l =

Eθ|R,η(L) =
(cid:88)
(cid:88)
(cid:88)

(cid:18)

l

u∈U l

n

v∈U l

m

− 1
2

(cid:18)

(cid:80)

t

− 1
2

Eθ|R,η

(cid:1)2 + V ar[Sl

u,v]

(cid:0)rl
u,v − (cid:91)
Sl
(cid:32)
σ2
r,l

u,v

kl log σ2

l,n+

n[t, ]Un,u)2(cid:1)(cid:19)

(cid:33)

log σ2

r,l +

l

(cid:88)

(cid:88)
(cid:0)(U l
u∈Un
n,u[t] − M l
(cid:32)
(cid:88)
(cid:88)
(cid:0)(U l

u∈Um
m,u[t] − M l

σ2

l,n

l

− 1
2

Eθ|R,η

(cid:18)

(cid:80)
(cid:88)
(cid:88)

t

n

u∈Un

− 1
2

(cid:18)

σ2

l,m

(cid:80)

t

kn log σ2

n +

(cid:33)

l,m+

kl log σ2

m[t, ]Um,u)2(cid:1)(cid:19)
(cid:0) (cid:92)Un,u[t]

2

(cid:19)

+ V ar(cid:2)Un,u[t](cid:3)(cid:1)
m,v, (cid:100)Sl

σ2
n

In the above equation, Sl

u,v = U

(cid:48)l
n,uU l

u,v is the sample
u,v. Also
11.

u,v, V ar[Sl

u,v] is the sample variance of Sl
mean of Sl
Un,u[t] is the tth element in the vector representing Un,u
4.1.1 E Step
We use Gibbs sampling in the E step. We draw T samples for
all the latent variables and compute the sufﬁcient statistics (Monte
Carlo means and variances of the latent variables) to be used in the
M step.

In the E step, we sample the latent variables from their distri-
butions given the rest of random variables. For example, to sam-
ple Un,u, we sample from P (Un,u|rest). This probability is em-
bedded in the complete data likelihood and since all distributions
are normal, P (Un,u|rest) is also normal. Generally, if f (x) is a
multivariate normal density function with mean µ and variance-
covariance matrix Σ. Then, we have:

(cid:18) d

dx

(cid:19)

µ = Σ

log f (x)

|x=0 and Σ = −

(cid:18) d2

dx2 log f (x)

(cid:19)−1

Now, for latent variables Un and U l

n we use the above lemma to
compute the mean and variance of the normal density functions to
sample these latent variables from:

V ar[Un,u|rest] =

E[Un,u|rest] = V ar[Un,u|rest]

(cid:18) 1

I +

σ2
n

(cid:19)−1
(cid:19)

n,u

(cid:88)
(cid:18) (cid:88)

l∈Cn

l∈Cn

M

(cid:48)l
n M l
n
σ2

l,n

M

(cid:48)l
n U l
σ2

l,n

(9)

(10)

In the above equations, Cn is the set of contexts in which entity
type Un is involved. Similarly, the mean and the covariance matrix
for U l

n,u is computed as follows:

11Note that
Eθ|R,η ((U l
M l

to improve readability in Eq.
n [t, ](cid:92)Un,u
(cid:3).

n[t, ]Un,u )2) = (cid:0) (cid:92)
n [t, ]Cov(cid:2)U l

n,u [t]−M l
(cid:48) l
n [t, ] − 2M l

n,u [t]−M l
U l

n,u [t], Un,u

n [t, ]V ar[Un,u ]M

(cid:1)2 +V ar[U l
(8), we used
n,u [t]]+

(cid:19)IR,l

u,v

V ar[U l

n,u|rest] =

(cid:18) 1

σ2

l,n

I +

(cid:19)−1

(11)

(cid:48)l
m,v

U l

m,vU
σ2
r,l

(cid:88)
(cid:18) (cid:88)

v∈U R,l

u

v∈U R,l

u

(cid:19)

(12)
m) that

E[U l

n,u|rest] = V ar[U l

n,u|rest]

m,v

rl
u,vU l
σ2
r,l

+

M l

nUn,u
σ2

l,n

In the above equations, U R,l

denotes the entities (from U l

u

have relation with u in the context l.
4.1.2 M Step
In the M step, we maximize the expected likelihood, Eθ|R,η(L),
with respect to model parameters (η) to compute the updated val-
ues for the model parameters. To do so, we set the derivative of
Eθ|R,η(L) with respect to every model parameter to zero and com-
pute the model parameters as follows:

(cid:80)

(cid:80)

u∈U l

n

v∈U l

(cid:80)

σ2
n =

(cid:80)

u∈Un

u∈Un

(cid:80)

t

u,v

m

|Rl|

(cid:18)(cid:0)rl
u,v − (cid:100)Sl
(cid:0) (cid:92)Un,u[t]
(cid:80)
(cid:18)

kn|Un|

2

t

Eθ|R,η((U l

kl|Un|

(cid:1)2 + V ar[Sl

u,v]

(cid:19)IR,l

u,v

+ V ar(cid:2)Un,u[t](cid:3)(cid:1)

(13)

(14)

(cid:19)

n,u[t] − M l

n[t, ]Un,u)2)

n,u[t](cid:91)Un,u + Cov[U l

(cid:18) (cid:88)

(cid:0) (cid:92)U l
(cid:18) (cid:88)
(cid:0)(cid:91)Un,u

u∈Un
×

u∈Un

(cid:48)

(cid:91)Un,u

n,u[t], Un,u](cid:1)(cid:19)(cid:48)
+ V ar[Un,u](cid:1)(cid:19)−1

(15)

(16)

σ2
l,n =

M l

n[t, ] =

Now, we continue to the next EM iteration using the updated
model parameters. We continue performing E and M steps until
convergence of the learned parameters.

5. EXPERIMENTS

In this section, we ﬁrst describe the datasets used in our exper-
iments and our experimental setting and design, and then present
the experimental results.
5.1 Datasets

One of the bottlenecks to research in heterogeneous network
analysis has been the lack of publicly available datasets featuring
a large number of entity types, numerous contexts, and rich inter-
action data. Many previous papers on heterogeneous information
networks have tended to use bibliographic datasets [19, 23]. These
datasets contain the entity types, authors, institutions, publications,
and venues, to name a few. However, there are no explicit ratings
in these datasets, and the contexts in bibliographic networks are not
real context where entities interact. Ideal datasets for this research,
particularly for recommendations research, would be the real het-
erogeneous networks from online social media services such as

648Facebook, Google+, or LinkedIn where there are multiple entity
types such as users, universities, companies, etc. and these entities
interact in several contexts. However, due to lack of public data
available for such heterogeneous networks featuring many entity
types and multiple contexts, we use two publicly available data sets
from Epinions.com and Flixster.com. These two datasets are in fact
social rating networks [5] and each one consists of two contexts: a
social network among users, and an item rating matrix. In this sub-
section we brieﬂy introduce these two datasets.

Epinions.com is a product reviewing website in which users can
express trust on other users besides writing reviews on various prod-
ucts. We used the version of the Epinions dataset12 published by
Richardson and Domingos [12]. The social relations in Epinions
are in fact trust relations, which are directed. Flixster.com is a so-
cial networking service in which users can rate movies and create
a social network. The social relations in Flixster are friendship re-
lations and undirected. The Flixster data set has been crawled by
Jamali and Ester [5] and has been made publicly available for the
research community13. Ratings in Flixster and Epinions are real
values in the range [1,5]. The social relations in both data sets are
binary, indicating whether or not a social relation exists. General
statistics of the Flixster dataset and the Epinions data set are shown
in Table 1. Between these two datasets, we capture both directed
and undirected social networks and two contexts, one involving bi-
nary ratings and the other real ratings.

Table 1: General statistics of the Flixster and Epinions

Social Relations

Statistics

Users

Ratings
Items

Flixster

Epinions

1M

26.7M
8.2M
49K

71K
508K
575K
104K

5.2 Experimental Setups

We implemented the algorithms in R and in C: R scripts are used
to handle the input matrices and high level routines, and C is mainly
used for more complex processing. Our experiments were run on a
single core of a multi-core machine with an Intel Xeon CPU X5570
2.93GHz and 8M cache. While the machine had 64GB memory,
our implementation of HETEROMF consumed only 1GB memory
on the largest dataset (Flixster).

We perform 5-fold cross validation in our experiments. In each
fold we have 80% of data as the training set and the remaining 20%
as the test set.

The evaluation metric we use in our experiments is RMSE, de-

ﬁned as follows:

(cid:115)(cid:80)

(ru,v −(cid:98)ru,v)2

(u,i)|Rtest

|Rtest|

RM SE =

(17)

where Rtest is the set of all entity pairs (u, v) in the test data.
Note that RMSE values for different contexts are computed sepa-
rately and Rtest in the above equation is the test data for a speciﬁc
context. We report the results for different contexts in both Epin-
ions and Flixster separately.

To evaluate the performance of our proposed model, we consider

three comparison partners, i.e., competing approaches:

12http://alchemy.cs.washington.edu/data/epinions/
13www.sfu.ca/∼sja25/datasets/

• HeteroMF: The context-speciﬁc factorization based model

proposed in this paper.

• CMF: The collective matrix factorization method [9].
• SMF: Separate matrix factorization, where different contexts
are learned separately using separate latent factors. No infor-
mation is propagated across contexts.

In the datasets used in our experiments, we only have entity types
of user, product, and movie. Entity type user is the only entity type
that is shared among two contexts. To perform a comprehensive
set of experiments and evaluate the strength of our model in all the
aspects and issues that we identiﬁed for CMF, we design and per-
form different sets of experiments. We report experimental results
on three kinds of users:

• AllUsers: All the users in the system.
• Cold Start: Cold-start users for a speciﬁc context who are
users that have rated less than 5 (but more than zero) items
in one context, and 5 or more ratings in the other context.

• Inactive: Users who have no ratings in a context, but have 5
or more ratings in the other context. These users are particu-
larly important for the case that the latent factors of a user are
properly learned in a context and now this user wants to start
expressing ratings in a new context. Transferring the learnt
factors across contexts to model the rating behavior for these
users is very important.

The three kinds of users above cover key settings which we be-
lieve should both highlight the advantage of our proposed model
and expose its limitations, if any. In both datasets, as such none of
the ratings or the social relations dominate each other. To overcome
this, we simulate a dataset where one context dominates another
one, by selecting a subset of the ratings in each dataset to represent
a context. In Epinions, if we only consider the category of “online-
store", then the ratings (22K) will be dominated by the social rela-
tions (508K). Similarly in Flixster, if we only consider the movies
from the “Horror" genre, then the ratings (245K) will be dominated
by the social relations (26M). In our experimental results we refer
to these data sets as Epinions-dominant and Flixster-dominant.
5.3 Experimental Results

In this subsection, we report our experimental results on the dif-
ferent sets of experiments introduced in the previous subsection for
both Flixster and Epinions.
Epinions.

Figure 5 compares the RMSE of the comparison partners for
different sets of users in both the contexts – rating and trust, for
Epinions. In both contexts, HeteroMF outperforms the compari-
son partners. Notice that HeteroMF’s improvement over CMF is
substantially more than the latter’s improvement over SMF. Fig-
ure 6 shows RMSE improvement of HeteroMF over CMF for vari-
ous kinds of users. It can be easily seen that HeteroMF achieves a
substantial RMSE improvement over CMF for cold start users and
inactive users, compared with all users. In the rating context, the
RMSE gain for cold-start users (4.9%) is more than 2.5 times the
RMSE gain for all users, and the RMSE gain for inactive users is
more than 1.6 times the RMSE gain for cold-start users. Similar
behavior is exhibited in the trust context. The absolute value of the
RMSE gain of HeteroMF for each kind of users is more than for
the rating context. But the increase in the RMSE gain when we go
from all users to cold-start users to inactive users is more modest
compared to the rating context.

649(a) Rating

Figure 6: Comparison of RMSE improvement for cold start
users, all users, and inactive users in Epinions.

(b) Trust

Figure 5: RMSE results for comparison partners in different
contexts for Epinions.

Flixster.

Figure 7 shows the results for the Flixster dataset. As shown
in this ﬁgure HeteroMF outperforms all the comparison partners
for all three sets of users in both contexts. Unlike Epinions, Het-
eroMF’s RMSE gain over CMF is comparable to the latter’s RMSE
gain over SMF. Figure 8 depicts how the RMSE gain of HeteroMF
over CMF varies depending on the kind of users. It clearly shows
that similar to the case for Epinions, HeteroMF archieves substan-
tial RMSE gain for cold start users and inactive users, compared
with all users.
Analysis.

Experimental results on cold start users and inactive users show
that CMF can not properly learn the latent factors for entities that
have not expressed enough ratings in one context, but have many
ratings in another context. This is mainly due to the fact that the
latent factors for users are shared across different contexts in CMF.
For cold start users in a context, their latent factors are dominated
by the other context. On the other hand, HeteroMF learns general
latent factors for users and context speciﬁc latent factors in rating
and social contexts. Transfer matrices are used to convert a general
latent factor to a context speciﬁc factor.

In other words, the main advantage of HETEROMF over CMF is
that HETEROMF decomposes the latent factors of an entity into a
general latent factor and a context dependent transfer matrix. Gen-
eral factors are learnt based on the observations in all contexts.
However, the transfer matrix is learnt for a speciﬁc context only.
In HETEROMF, even if a user has no ratings it does not matter
because his general factors are learnt based on other contexts and

to tailor this factor to a context dependent one HETEROMF uses a
transfer matrix that is properly tuned for this speciﬁc context and is
in charge of translating general factors into context speciﬁc factors.
Dominated Contexts.

Figure 9 presents the RMSE for the dominated context (rating)
in Epinions-dominant. As shown in this ﬁgure and in Figure 10,
HeteroMF achieves a substantial RMSE improvement over CMF
even for all users in Epinions-dominant on the dominated context,
namely rating. HeteroMF outperforms CMF by 11% in the rating
context which is very impressive, compared to less than 2% for
the Epinions’ complete dataset. Similar results are achieved for
Flixster-dominant (see Figures 11 and 10).
CMF vs. SMF.

There are some interesting and somewhat surprising results shown
in Figures 9 and 11 in addition to those discussed earlier. In both
datasets, SMF outperforms CMF in the rating context! This shows
that when a context dominates another context, it is beneﬁcial for
the dominated context to be learned separately from the dominating
context. Indeed, by learning the dominated context along with the
dominating context, CMF suffers on the dominated context, com-
pared with SMF. So far, all the experiments we have discussed con-
vincingly highlight the weaknesses of CMF exactly as we outlined
in the earlier sections and precisely under the settings discussed,
w.r.t. different kinds of users and different contexts.
What is a context?.

It should be noted that there are different genres in Flixster and
different product categories in Epinions which can potentially be
considered as different contexts. Syntactically, we can of course
regard them as contexts. Can we expect the same kind of behav-
ior from these “contexts” that we observed for the rating vs. so-
cial/trust contexts in our experiments above? To test this, we per-
formed experiments on these settings and the results were not strik-
ing, in that the RMSE gain of HeteroMF over CMF was not sub-
stantial (Even for some genres/categories, CMF performed slightly
better.). We believe that this is mainly due to the fact that although
different genres can potentially represent different contexts, in re-
ality users’ behavior toward them tends to be very similar. There-
fore, direct propagation of information from one context to another
one (as is done by CMF) is not going to harm cold-start users. In
other words, if a user is cold start in one genre but active in another
genre, he/she is actually not a cold-start user and his/her ratings in
the active context happen to faithfully capture his behavior in the

650(a) Rating

Figure 8: Comparison of RMSE improvement for cold start
users, all entities, and inactive users in Flixster.

(b) Social

Figure 7: RMSE results for comparison partners in different
contexts in Flixster.

so-called cold-start context, with high accuracy. E.g., there is not
a great difference in the rating behavior of “Thriller” movies com-
pared to “Comedy” movies. However, social relations and ratings
are fairly independent and are genuinely separate contexts. Indeed,
we can see the effect of multiple contexts much better in this set-
ting, as shown in our experiments. Similar remark hold for the
Epinions dataset.

5.3.1 Running Time
In our experiments, CMF converged in about 50 iterations, while
HETEROMF took about 100 iteration to converge. Table 2 com-
pares the actual average running time for an EM iteration in both
HETEROMF and CMF on all datasets. As shown in this table,
an EM iteration in CMF, on an average, runs more than 4 times
faster than a corresponding EM iteration in HETEROMF, for all
datasets used in our experiments. Slower iterations in HETEROMF
are mainly due to the fact that HETEROMF considers context-speciﬁc
factors. Also, to facilitate the propagation across contexts, in the E
step we ﬁrst sample context-speciﬁc factors, then the base factors,
and then we do one more round of sampling for context-speciﬁc
factors to propagate the information from the observed data to the
base factors and from the base factors back to the contexts.

Note that although CMF is faster than HETEROMF in the learn-
ing phase, both methods are equally fast in the prediction (test)
phase, when they simply use the learned latent factors. In real in-
dustrial strength applications, substantial accuracy improvements
for cold-start entities and dominated contexts, that are achieved by
HETEROMF compared to CMF, tend to be very important for new
user engagement and for controlling information propagation from

Figure 9: RMSE results for comparison partner in the domi-
nated context (rating) for Epinions-dominant, where a context
(rating) is dominated by another one (trust).

large contexts to much smaller sized contexts. Thus, the increased
learning time is a price that may be worth paying in practice. It
is worth noting, however, that the learning phases in both HET-
EROMF and CMF are highly parallelizable, which may allow us to
save on learning time signiﬁcantly.

6. CONCLUSIONS

Traditional recommender systems focus on interactions between
users and items in a single context and use past interactions, ex-
pressed as ratings, to make predictions about future ratings users
may give items they have not interacted with before. Methods
based on matrix factorization are the state of the art for making
these predictions. However, in heterogeneous information networks,
entities of different types interact with each other, often across a va-
riety of contexts. This leads to multiple rating matrices. Collective
matrix factorization is the state of the art for rating predictions in
such settings. We identiﬁed certain fundamental issues with the
way in which CMF models and approaches the rating prediction
problem in this setting. We proposed a context-dependent matrix
factorization model, HETEROMF, that considers a general latent
factor for entities of every entity type and context-dependent latent
factors for every context in which the entities participate. HET-
EROMF learns a general latent factor for every entity and trans-

651Table 2: Average running time of a single EM iteration in dif-
ferent datasets.

HeteroMF

34min.
18min.
220min.
116min.

CMF
7.5min.
4min.
48min.
26min.

Dataset
Epinions

Flixster

Epinions-dominant

Flixster-dominant

Figure 10: Comparison of RMSE improvement for cold start
users and all users in the dominated context (ratings). The re-
sults are for both Epinions and Flixster for the case that a con-
text (rating) is dominated by another one (social or trust).

Figure 11: RMSE results for comparison partner in the dom-
inated context (rating) for Flixster-dominant, where a context
(rating) is dominated by another one (social).

fer matrices for every context, to convert the general latent factors
into a context-dependent latent factor. HETEROMF is particularly
helpful for cold-start entities and contexts that are dominated by
other contexts. The transfer matrices in HETEROMF are learned
per context and prevent the learnt factors for a context from being
dominated by other contexts. Also, for entities that are cold start
in a context, HETEROMF uses the product of the base latent factor,
learned from observations for this entity in other contexts, and the
transfer matrix, learned from the observations for all entities in this
context, to generate a proper context-speciﬁc latent factor.

We performed comprehensive experiments on two real datasets
from Epinions and Flixster. Both data sets feature interactions be-
tween users and interactions between users and items (products or
movies) in two different contexts. Experimental results demon-
strate that HETEROMF substantially outperforms CMF, particu-
larly for cold-start entities and for contexts where interactions in
one context are dominated by those of other contexts. Additionally,
our experimental analysis convincingly highlights the weaknesses
of CMF exactly as we outlined in the technical sections, w.r.t. dif-
ferent kinds of users and different contexts.

This work suggests several interesting directions for future re-
search. All interactions considered in this paper are binary, where
a pair of entities (from the same or different types) are involved.
There are real applications where the “arity” of interactions can

be higher. As an example, in Amazon, products are reviewed by
reviewers, and both products and reviews may be rated by raters.
Here, a rating on a review is really an interaction between three en-
tity types – rater, reviewer and product. Tensor factorization models
and their extensions have been used by Moghaddam et al. [11] for
predicting helpfulness of reviews. It is interesting to enhance ten-
sor factorization models to account for multipe interaction contexts.
Another direction is incorporating entity attributes. For simplic-
ity and generality, in this paper we do not assume access to entity
attributes. However, the HETEROMF framework can take advan-
tage of user demographics, movie genres and actors, and product
specs, when available. Extending our experiments to incorporate
these is interesting. Finally, we note that the features extracted in
meta-path based approaches [20, 19] can also be used as features
in HETEROMF.

7. REFERENCES
[1] G. Adomavicius and A. Tuzhilin. Toward the next generation

of recommender systems: A survey of the state-of-the-art
and possible extensions. IEEE Transactions on Knowledge
and Data Engineering, 17(6):734–749, 2005.

[2] D. Agarwal, B.-C. Chen, and B. Pang. Personalized

recommendation of user comments via factor models. In
Proceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP’11), pages 571–582,
2011.

[3] R. M. Bell, Y. Koren, and C. Volinsky. Modeling

relationships at multiple scales to improve accuracy of large
recommender systems. In KDD’07: The 13th ACM SIGKDD
conference on Knowledge Discovery andData Mining, pages
95–104, 2007.

[4] B.-C. Chen, J. Guo, B. Tseng, and J. Yang. User reputation

in a comment rating environment. In Proceedings of the 17th
ACM SIGKDD international conference on Knowledge
discovery and data mining (KDD’11), pages 159–167, 2011.

[5] M. Jamali and M. Ester. A matrix factorization technique

with trust propagation for recommendation in social
networks. In Proceedings of the fourth ACM conference on
Recommender systems, RecSys ’10, pages 135–142, 2010.

[6] Y. Koren. Factorization meets the neighborhood a

multifaceted collaborative ﬁltering model. In Proceedings of
the 14th ACM SIGKDD international conference on
Knowledge discovery and data mining, KDD ’08, pages
426–434, 2008.

[7] Y. Koren. Collaborative ﬁltering with temporal dynamics. In

Proceedings of the 15th ACM SIGKDD international
conference on Knowledge discovery and data mining, KDD
’09, pages 447–456, 2009.

[8] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization
techniques for recommender systems. IEEE Computer,
42:30–37, 2009.

652[9] C. Lippert, S. H. Weber, Y. Huang, V. Tresp, M. Schubert,
and H.-P. Kriegel. Relation prediction in Multi-Relational
domains using matrix factorization. In NIPS 2008 Workshop
on Structured Input Structure Output, 2008.

[10] H. Ma, I. King, and M. R. Lyu. Learning to recommend with

social trust ensemble. In Proceedings of the 32nd annual
international ACM SIGIR conference on Research and
development in information retrieval, SIGIR’09, pages
203–210, 2009.

[11] S. Moghaddam, M. Jamali, and M. Ester. Etf: extended

tensor factorization model for personalizing prediction of
review helpfulness. In Proceedings of the ﬁfth ACM
international conference on Web search and data mining,
WSDM ’12, pages 163–172, 2012.

[12] M. Richardson and P. Domingos. Mining knowledge-sharing

sites for viral marketing. In Proceedings of the eighth ACM
SIGKDD international conference on Knowledge discovery
and data mining, KDD ’02, pages 61–70, 2002.

[13] R. Salakhutdinov and A. Mnih. Probabilistic matrix

factorization. In Twenty-First Annual Conference on Neural
Information Processing Systems, NIPS’07, 2007.

[14] C. Shi, X. Kong, P. S. Yu, S. Xie, and B. Wu. Relevance

search in heterogeneous networks. In Proceedings of the 15th
International Conference on Extending Database Technology
(EDBT’12), pages 180–191, 2012.

[15] X. Shi, Q. Liu, W. Fan, Q. Yang, and P. S. Yu. Predictive
modeling with heterogeneous sources. In Proceedings of
SIAM International Conference on Data Mining (SDM’10),
2010.

[16] X. Shi, Q. Liu, W. Fan, P. S. Yu, and R. Zhu. Transfer

learning on heterogenous feature spaces via spectral
transformation. In Proceedings of the 2010 IEEE
International Conference on Data Mining (ICDM’10), pages
1049–1054, 2010.

[17] A. P. Singh and G. J. Gordon. Relational learning via

collective matrix factorization. In Proceedings of the 14th
ACM SIGKDD international conference on Knowledge
discovery and data mining (KDD’08), pages 650–658, 2008.

[18] Y. Sun, R. Barber, M. Gupta, C. C. Aggarwal, and J. Han.

Co-author relationship prediction in heterogeneous
bibliographic networks. In Proceedings of the 2011
International Conference on Advances in Social Networks
Analysis and Mining (ASONAM ’11), pages 121–128, 2011.

[19] Y. Sun, J. Han, C. C. Aggarwal, and N. V. Chawla. When
will it happen?: relationship prediction in heterogeneous
information networks. In Proceedings of the ﬁfth ACM
international conference on Web search and data mining
(WSDM’12), pages 663–672, 2012.

[20] Y. Sun, J. Han, X. Yan, P. S. Yu, and T. Wu. Pathsim: Meta

path-based top-k similarity search in heterogeneous
information networks. In In 37th international conference on
Very Largse Databases (VLDB’11), 2011.

[21] C. Wang, R. Raina, D. Fong, D. Zhou, J. Han, and

G. Badros. Learning relevance from heterogeneous social
network and its application in online targeting. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Information
Retrieval (SIGIR’11), pages 655–664, 2011.

[22] S.-H. Yang, B. Long, A. Smola, N. Sadagopan, Z. Zheng,

and H. Zha. Like like alike: joint friendship and interest
propagation in social networks. In Proceedings of the 20th
international conference on World wide web, WWW ’11,
pages 537–546, 2011.

[23] X. Yu, Q. Gu, M. Zhou, and J. Han. Citation prediction in

heterogeneous bibliographic networks. In Proceeding of
SIAM international conference on Data Mining (SDM’12),
pages 1119–1130, 2012.

[24] L. Zhang, D. Agarwal, and B.-C. Chen. Generalizing matrix

factorization through ﬂexible regression priors. In
Proceedings of the ﬁfth ACM conference on Recommender
systems (Recsys’11), pages 13–20, 2011.

653