Know Your Personalization: Learning Topic level

Personalization in Online Services

Anirban Majumder

Bell Labs Research, Bangalore, India
anirban.majumder@alcatel-lucent.com

Nisheeth Shrivastava

Bell Labs Research, Bangalore, India

nisheeth.shrivastava@alcatel-lucent.com

ABSTRACT
Online service platforms (OSPs), such as search engines,
news-websites, ad-providers, etc., serve highly personalized
content to the user, based on the proﬁle extracted from her
history with the OSP. Although personalization (generally)
leads to a better user experience, it also raises privacy con-
cerns for the user—she does not know what is present in
her proﬁle and more importantly, what is being used to per-
sonalize her content. In this paper, we capture OSP’s per-
sonalization for an user in a new data structure called the
personalization vector (η), which is a weighted vector over
a set of topics, and present eﬃcient algorithms to learn it.

Our approach treats OSPs as black-boxes, and extracts
η by mining only their output, speciﬁcally, the personalized
(for an user) and vanilla (without any user information)
contents served, and the diﬀerences in these content. We
believe that such treatment of OSPs is a unique aspect of
our work, not just enabling access to (so far hidden) proﬁles
in OSPs, but also providing a novel and practical approach
for retrieving information from OSPs by mining diﬀerences
in their outputs.

We formulate a new model called Latent Topic Person-
alization (LTP) that captures the personalization vector in
a learning framework and present eﬃcient inference algo-
rithms for determining it. We perform extensive experi-
ments targeting search engine personalization, using data
from both real Google users and synthetic setup. Our results
indicate that LTP achieves high accuracy (R-pre = 84%) in
discovering personalized topics. For Google data, our qual-
itative results demonstrate that the topics determined by
LTP for a user correspond well to his ad-categories deter-
mined by Google.

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications—
Data mining

Keywords
personalization; online service providers; topic model

1.

INTRODUCTION

Personalization is being used by most on-line service plat-
forms (OSPs) such as search, advertising, shopping etc. Their

Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW 2013, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

goal is to lure users by oﬀering a better service experience
customized to their individual interests. A popular trend is
to employ proﬁle based personalization, where OSPs build
extensive proﬁles for the user (based on her past interactions
such as search queries, browsing history, links shared, etc.)
and personalize content using this proﬁle. Several popular
search1, movie
services employ such personalization, e.g.
recommendations2, etc.

While OSPs track rich user data in their histories alone,
they can infer much more information about them by mining
this raw data.
Informally speaking, OSPs can determine
a user’s interests and biases on diﬀerent categories, which
can later be used (along with the history) for personalizing
content for her. For example (see [20] for details), Google is
shown to have inferred users political aﬃliations (republican
or democratic) and use it to re-rank search results.

For a user, this raises a signiﬁcant privacy concern—she
does not know what was tracked in her history, what has
been inferred, and more importantly, is currently being used
to personalize her content. Moreover, as both the personal-
ization techniques and the data they operate on are the key
diﬀerentiators for the OSPs (their secret sauce), they do not
reveal either of them, making it even harder for an user to
understand how personalization is being done (for her).

In this paper, we aim at extracting a user’s proﬁle from
the OSP. We model this proﬁle as a weighted personalization
vector over topics, where the weight on a topic indicates her
interest in it (higher means more interested). Informally, a
topic is any concept or phenomenon that the user could be
interested in, e.g. a speciﬁc sport, preference over cuisines,
favorite author, movie genre, etc.3

Our goal is not to reverse-engineer the OSP’s inference
algorithms.
In fact, we treat the OSP as a black-box and
assume that we only have access to its output, i.e. the (per-
sonalized) content served by the OSP to a user on diﬀerent
queries4. The central idea in our approach is to get both
personalized content (served for the user) and vanilla con-
tent (served for a new/not logged in user) for the same query
and analyze their diﬀerences. Through careful inspection of

1http://privacy.microsoft.com/en-us/Bing.mspx;

http://support.google.com/websearch/bin/answer.py?answer=1710607.

2Netﬂix: http://www.netﬂixprize.com
3More speciﬁcally, we deﬁne it as a distribution over bag
of words, a common deﬁnition in the topic modeling litera-
ture (see Section 3).

4The query could point to a static page, e.g. reviews and
other information on a movie, or dynamically generated, e.g.
search results.

873these two types of content, we identify the hidden user pro-
ﬁle (summarized through a weighted set of topics) used by
the OSP to serve personalized content.

There is very little concrete information available on the
techniques the OSPs use to personalize content. Our paper
provides a novel approach to tackle this problem, giving in-
sights into the hidden user proﬁles without the knowledge
of the speciﬁc inference techniques used by the OSP or the
history of the user. We believe that this idea of comparing
the diﬀerences in output to extract the hidden personalized
topics is a unique aspect of our paper and opens a new di-
rection in privacy research that can be aimed at commercial
OSPs.

As an example, consider the case of a search engine. For
any search query, we can get the personalized and vanilla
results by making the query from a browser with and with-
out logging in, respectively. These results are basically two
ranked lists with some urls in the latter moved up or down in
the former (i.e. re-ranked ), based on the user’s proﬁle. We
study these re-rankings over multiple queries and determine
the topics of interest for the user that can best explain these
diﬀerences.

For the rest of the paper, we focus our attention on search
engine personalization. However, our techniques can easily
be extended to other services where a) we can observe both
vanilla and personalized content and b) the content is oﬀered
as ranked lists of items (e.g. urls, movies, products, etc.).
For example, we can apply it to movie recommendations by
Netﬂix based on the personalized (and vanilla) ranked list
of related movies presented when a user visits a particular
movie page.

1.1 Search Personalization and Re-ranking

Although the exact details of personalization for search
engines are not publically available, recent works in the web-
search community have thrown some light on them [8, 23,
18]. The common underlying theme for these techniques is
to ﬁrst populate the vanilla result using the semantics of
the query string and then personalize it by re-arranging the
items in this list, using the proﬁle information. Therefore,
conceptually, the vanilla and personalized contents are re-
ordering of the same set of items. We take advantage of this
re-ranking of results to determine the topics present in the
user’s proﬁle with the OSP.

It is important to observe that the assumption of vanilla
and personalized results being re-rankings of same set of
urls, does not preclude the generality of our approach. This
assumption can easily be lifted by simply adding the extra
urls in one list to the end of the other list5. The important
point is that personalization, by deﬁnition, will aﬀect the
ranks of the results shown, which is what we use in this
paper.

Note that the topics that we learn may not be explicitly
maintained by the search engine (or an OSP in general); in
fact their proﬁle data could consist of parameters completely
unrelated to, and may not even map to, our deﬁnition of top-
ics. Our paper hinges on the intuition that a user proﬁle can
be succinctly captured by a set of topics that reﬂects her in-
terests. Any search engine (or OSP) that personalizes results

5In our experiments with Google, only 15% of person-
alized results contain any extra result compared to vanilla,
and even these contain on average only 14% extra urls (or,
1.4 urls for an avg. result size of 10).

based on her interests must give higher preference to the re-
sults matching these topics. Thus our approach of ﬁnding
topic-level personalization is fairly generic—it can work with
OSPs who do not necessarily maintain topic-based proﬁles of
users and without the knowledge of the inference algorithms
they use.

An alternate approach to recreate the user proﬁle could
be via mining the inputs to the search engine (i.e. the user’s
search query logs, results clicked, browsing history etc.)[8,
23, 22]. However, this approach has several shortcomings
compared to us. First of all, it is very hard to catch up to
the commercial techniques used by OSPs that are usually
more advanced and rapidly evolving. Secondly, due to the
proprietary nature of OSPs, it is not clear what algorithm
or even what part of the history is being used by them.
Finally, in many cases the history information may not be
available publicly (i.e. while a Google user’s search history is
available, past ads served are not), limiting the eﬀectiveness
of these approaches. In contrast, our approach is agnostic
to OSP’s personalization scheme and can work even when
the history is not public.

1.2 Our Contributions

The main contributions of the paper are as follows.

• We propose a new direction in privacy research that gives
users a glimpse of their proﬁle information being used by
commercial OSPs to serve personalized content. We for-
mally capture this information as a personalization vector
over topics that provides a concise and accurate summary
of the user proﬁle.

• We propose a novel way to compute this personalization
vector based on the personalized and vanilla content served
by an OSP. This formulation treats the OSP as a black-
box and hence can work with a variety of on-line services.
We believe that this is a unique aspect of our work and
can open a new direction for privacy research by enabling
access to (so far hidden) proﬁle information in OSPs.

• We present a probabilistic model (named Latent Topic
Personalization, or LTP) that captures the intuition be-
hind our approach. LTP is both expressive and leads to
computationally eﬃcient inference algorithms (LTP-INF
and LTP-EM) that ﬁnd the personalization vector on real
data-sets.

• Our experiments with synthetic data-sets generated by
a state-of-the-art personalization engine show that LTP
can learn the personalization parameters very accurately,
achieving on average 84% precision in learning personal-
ized topics.

• We perform experiments on a novel real-life data-set con-
taining the personalized and vanilla query results collected
from 10 Google users. Our qualitative results demon-
strate that the personalized topics determined by LTP for
a user correspond well to his ad-categories determined by
Google.

2. RELATED WORK
Search personalization: A large body of work exists on
personalizing search results using user-proﬁles [8, 23, 18],
that collectively give overwhelming evidence of its bene-
ﬁts. More recently, researchers have also explored creating

874proﬁles using topic models [22] and other textual informa-
tion [25]. These works are not competitors of our paper, but
rather serve as a motivation for us, as they highlight the ex-
istence and importance of proﬁles in the state-of-the-art in
personalization.

Another body of work explores short-term and session
based personalization [1, 8], that personalize based on user’s
current intention, based on his recent history or session.
While such approaches are not aligned with our idea, there
are two important points to note—a) they do no imply
proﬁle-based personalization does not happen, rather, they
are typically used in conjunction with each other [1, 13], and
b) since they are applicable only during a session, it is easy
to remove their aﬀect by making sure no coherent session is
tracked during our data collection (by doing the queries in
a random order or adding suﬃcient delays).

Researchers have also found that personalization is not al-
ways beneﬁcial and have proposed various approaches, such
as click-entropy [26, 27], dynamic user interests [13] and
query diﬃculty [31], to ﬁlter queries that should not be per-
sonalized (irrespective of user’s proﬁle). Such ﬁltering is very
hard replicate in our approach since the output may not con-
tain any information to model them. We therefore allow for
existence of this hidden process in our model via a latent
variable deciding (randomly) if personalization happens on
a query (see Section 4.1 for details).

In a paper contemporary to ours, Hannak et al. [9], study
the parameters (location, demographics, etc.)
that eﬀect
personalization in Google search. While these parameters
give insights on what inputs inﬂuence personalization in
practice, it is very diﬀerent from the topic-based approach
we take to capture the hidden user proﬁles.
Topics Models: Although topic models are clearly a pop-
ular tool for processing textual information and have also
been used in personalization, there is no work to our knowl-
edge that models the diﬀerences in two documents (or two
ranked set of documents) as us. A recent work by Bischof
et al.
[2] comes close—they ﬁnd exclusive topics (that are
suﬃciently diﬀerent from each other) so that the documents
can be classiﬁed into a non-overlapping hierarchy. While
this also involves ﬁnding topics which are present in some
documents and not in others, it is still very diﬀerent from
our approach of ﬁnding a consistent (may not be exclusive)
set of personalized topics that can diﬀerentiate personalized
and vanilla content.
Privacy: Finally, our problem stems from the general area
of privacy of user data. Various studies have highlighted
problems of privacy in information leaks from OSPs[11, 17,
10]. Korolova et al. [10] showed how targeted ads can pin-
point individual users in Facebook, Mao et al. [17] analyzed
tweets to ﬁnd vacation plans and medical conditions for real
users, etc. However, these studies are focused on ﬁnding in-
stances of privacy leaks from the entire OSP network and
do not help users understand leaks in their own account.
Other approaches of privacy preserving personalization aim
at building systems from scratch that ensure certain norms
are preserved in the personalized output, e.g. grouping user
proﬁles [29, 30] to preserve k-anonymity or making a diﬀer-
entially private recommender system[14]. Recently, Chen et
al. [6] presented a more user centric approach that gives user
control over ﬁne grained categories (represented as a ﬁxed
hierarchical taxonomy) which they want personalization on.

These techniques, however, require the users to switch to
these new systems which is not practical.

3. PROBLEM FORMULATION

In this section, we introduce our notations and deﬁne the

technical problem that we consider in this paper.

3.1 Notation

Let I = {i1, i2, · · · } be the universe of all the items being
present at the personalization server, where, an item might
represent a url (for search engines like Google, Bing, etc.), a
product web-page (for e-commerce sites like Amazon, Net-
Flix, etc.) or an advertisement (for ad servers). For a query
q, let πq and σq denote the personalized and vanilla results.
In the following discussion, we will often drop the subscript
q, when the query is understood from the context.

As mentioned earlier, both π and σ are treated as per-
I ′ ⊂ I. Technically,
mutations over a ﬁnite set of items
a ranking/permutation6 is a bijection from a set to itself.
For any permutation π, π(i) denotes the item assigned at
rank (position) i, hence π = (π(1), π(2), · · · ). The notation
π−1(d) denotes the rank i of an item d ∈ I in π such that
π(i) = d. For any two permutations π and σ, we use the
notation σ−1(π(i)) to denote the rank of the item π(i) in σ.
Observe that π−1(π(i)) = i. We use Sn to denote the set of
all permutation over n items.

We assume that there are T topics {β1, β2, · · · , βT } in
our system where each topic βk is deﬁned as a multino-
mial distribution over a ﬁxed vocabulary V . For each word
w ∈ V , we have a parameter βk,w = Pr(w | βk) such that

Pw∈V βk,w = 1. Each item7 i ∈ I is represented by its

topic-map θi which is a multinomial distribution over the
set of topics. By inspecting the components of θi, one can
infer how related the item is to a particular topic.

We now describe our representation of topic-level user pro-
ﬁle information. For each user u and topic βk ∈ β, we as-
sociate a variable ηu,k ∈ R. It captures the importance of
βk (more relevant topics have higher values) for serving per-
sonalized content to u. The complete proﬁle information
(we name it as latent personalization vector) is denoted by
ηu = (ηu,1, ηu,2, · · · , ηu,T ). We often drop the subscript u
and refer to it simply as η whenever the user is understood
from the context.

3.2 Problem

Our strategy to learn the personalization vector η is to
repeatedly frame queries to the search engine and observe
the diﬀerence between its vanilla and personalized results.
For a given user u, we ﬁrst sign-in to her account and sub-
mit a query. This gives the search engine an opportunity to
personalize the result by using u’s proﬁle information and
through this process, we obtain the personalized result π.
Next, we submit the same query in an anonymized form, by
removing all cookies from the http request, thus removing all
account details (but keeping all other parameters same such
as IP address, User-Agent, etc.). This time the server sends
back the vanilla result σ. We expect that as this process
is repeated many times, the cumulative diﬀerence between
these two kinds of results will become statistically signiﬁ-

6We often use them interchangeably.
7Speciﬁcally, the textual content or meta-data of the

item.

875δ

τ

z

σ

π

γ

η

g

λ

Q

U

f

µ

α

θ

K

ν

W

W

I

β

T

the items and a personalization block to model the person-
alized responses (i.e. π1, π2, · · · , πm).

Topic Block The topic block follows the description of
standard topic models (c.f. LDA [3]) and we present it here
for the sake of completeness. The generative process for the
topic block is as follows

• For each topic βk, k = 1, 2 · · · , T

1. Sample βk ∼ Dirichlet(ν).

Personalization Block

Topic Block

• For each item i ∈ I

Figure 1: Graphical model representation of LTP.

cant and contain substantial evidence for η. In this paper,
we study the following problem: Given pairs of query results
(σ1, π1), (σ2, π2) · · · (σm, πm), how do we learn the latent per-
sonalization vector η, for a given user?

Non-proﬁle factors Although personalization normally
yields its beneﬁts by presenting more relevant results to the
users, it is also known to be less eﬀective and even detrimen-
tal in many cases. For example, while personalizing results
are known to work well for short and ambiguous queries [24]
where user searching same query may be looking for com-
pletely diﬀerent things, for common and speciﬁc queries two
users with very diﬀerent proﬁles are normally looking for the
same information and are satisﬁed with the same (ordering
of) results. In such cases, even though user’s proﬁle implies
re-ranking, the server may decide not to personalize. This
creates a problem for our approach as a search engine’s de-
cision whether to personalize the result of a search query
or not, is inﬂuenced not only by the topical content of the
query result, but also through other ﬁltering processes that
are hidden from us.

We take care of this in our model by introducing a la-
tent parameter that, during training phase, ﬁlters out such
inexplicable events and reduces the noise in the personaliza-
tion vector. In our experiments with the Google data-set,
we found several instances of queries with results at higher
ranks having higher “scores” (see Section 4 for deﬁnition of
scores) the ones at lower ranks, that were not personalized,
while another query with similar scores was personalized.
Without this latent parameter, these instances would have
reduced the eﬀectiveness of learning η.

4. LTP MODEL

The goal of topic-based personalization learning is to cap-
ture the following information: topics on which personaliza-
tion takes place and a weight vector corresponding to the
degree of personalization on these topics. In addition, the
approach has to scale with large number of queries. To meet
these objectives, we ﬁrst propose Latent Topical Personal-
ization model (LTP) to study the problem from a Bayesian
perspective. Following that, we develop eﬃcient variational
inference and estimation techniques for learning the param-
eters of this model.

4.1 Model Description

We now formally describe the proposed LTP model. LTP
models (Figure 1) both topics and personalization.
It in-
volves a topic block to model the topical content creation of

1. Sample its topic-map θi ∼ Gaussian(0, diag(α2)).

2. For each word position j = 1 · · · ni for item i

(a) Sample topic Ki,j with Pr(Ki,j = k) ∝ eθi,k .
(b) Sample word Wi,j ∼ Multinomial(βKi,j ).

The joint distribution for the topic-block can be written

as

p(θ, K, W, β | α, ν) = Yi∈I

ni

p(θi | α) ·

p(βk | ν)

T

Yk=1

p(Ki,j | θi) · p(Wi,j | Ki,j , β1···T )

(1)

Yi∈I

Yj=1

Personalization Block Our design of the personaliza-
tion block is little more involved. The main diﬃculty stems
from the non-proﬁle based factors, which may lead to no
re-ranking of results even when the user proﬁle (i.e. η) indi-
cates personalization should happen. In LTP, we achieve it
by introducing a latent switch variable z (refer to Figure 1).
Independently, for each query, we sample z, governed by a
prior parameter τ and based on its value decide whether
to allow topical personalization or not. The parameter τ is
user-speciﬁc and controls the rate at which topical person-
alization takes place (for that user).

Based on the value of z, we pick a probability distribu-
tion over permutations and sample π from it. Probabilistic
models on permutations have recently been applied to solve
various problems related to ranking [21]. Probability distri-
butions deﬁned over permutations can be broadly catego-
rized into two types—distance based and score based. In a
distance based model [16], the probability of a permutation
is deﬁned according to its distance from a central permuta-
tion. They have rich expressive power as they can incorpo-
rate a wide variety of distance functions over permutations
but are, in general, computationally ineﬃcient.

Score based models [12], on the other hand, are very ef-
ﬁcient as they divide permutation construction into stages
and assign scores on each stage such that the ﬁnal proba-
bility is a combination (multiplication) of stage-wise scores.
However, being deﬁned as a speciﬁc function over scores,
they have limited expressive power e.g. they can not take
into account any central permutation in the generative pro-
cess. For LTP, we have a central permutation (vanilla list σ)
and want to model π as being generated from it. Further,
as explained later, we deﬁne scores on items as a function
η. Therefore, we need a model which combines the notion
of distance with scores and is computationally eﬃcient.

The probability distribution f (Figure 1) is a process for
generating the personalized response π, and is decomposed

876σ
π

2
3

3
1

1
2

3

e−1

1

e−2
e−1

Items

1st Stage

2nd Stage

3rd Stage

2

e0
e1

1

3

3

3

π

1

1

2

f (π | σ) = 0.03

κ1, κ2

˜η, γ

φ

z

Q

τ

η

Personalization Block

U

Figure 2: An example illustrating the steps of f . We
have assumed µ = 1. At each stage, the actual out-
come is marked in blue and the most likely outcome
is marked in red.

Figure 3: Variational distribution used for inferring
personalization in LTP.

learned from the data. The overall probability of sampling
π is given by

into sequential stages. Observed that (see Figure 1) this pro-
cess is activated only if z = 0, thereby, implying no topical
personalization should happen. In the ﬁrst stage, we pick
the item π(1) with probability

exp(µ(1−σ−1π(1)))

Pj≥1 exp(µ(1−σ−1 π(j))) . Note

that this probability is maximum when the two permuta-
tions agree with the ﬁrst position i.e. π(1) = σ(1). However,
if we happen to pick some other item i.e. π(1) 6= σ(1), then
for the second stage, the most likely outcome is to bring
back the item σ(1) and put it at the second position of π
i.e. π(2) = σ(1).

In general, in the kth stage, the probability of selecting

exp(µ(k−σ−1π(k)))

π(k) is

Pj≥k exp(µ(k−σ−1π(k))) . Intuitively, at each stage k,

the model determines the items among σ(1), σ(2), · · · , σ(k −
1) which are not yet sampled by f and assigns higher proba-
bility on picking them. In Figure 2 gives an example of this
sampling process.

Considering all the stages, we obtain the overall probabil-
ity of sampling π which is given by the following expression

g(π | η; σ, λ, θ) = Yi  

exp(ληT θπ(i) + (1 − λ)(i − σ−1π(i)))

Pj≥i exp(ληT θπ(j) + (1 − λ)(i − σ−1π(j)))!

It can be veriﬁed that g is also a valid probability distribu-
tion.

The generative process for the personalization block can

be described as

• For each user u

1. Sample τ ∼ Beta(δ, δ).
2. Sample η ∼ Gaussian(0, diag(γ2))

• For each query qi, i = 1, 2, · · · , m

1. Sample zi ∼ Bernoulli(τ ) to decide whether to

allow topical personalization.

2. If zi = 1, sample πi ∼ g(· | σi, λ, θ, η).

3. Else, sample πi ∼ f (· | σi, µ).







The joint distribution for the personalization block can be

written as

(2)

p(π,z, τ, η | θ; γ, δ, µ, λ, σ) = p(η | γ) · p(τ | δ)

f (π | σ, µ) = Yi

exp(µ(i − σ−1π(i)))

exp(µ(i − σ−1π(j)))

Xj≥i

It can be shown that f is a valid probability distribution i.e.

f (π | σ, µ) ≥ 0 for all π ∈ Sn and Pπ f (π | σ, µ) = 1. The

parameter µ controls the spread of the distribution i.e.
if
µ → 0 then f converges to the uniform distribution over Sn;
otherwise, for µ > 0 the distribution is concentrated around
σ. We assume µ ≥ 1.

We now describe our next permutation model g that cap-
tures the topic-level personalization which is invoked only if
z = 1. Model g is also decomposed into sequential stages
and at each stage uses both the central permutation σ and
a set of scores, to determine π. Each item d ∈ I is assigned
a score ηT θd. In the ith stage, g selects the item π(i) with
probability

exp(ληT θπ(i) + (1 − λ)(i − σ−1π(i)))

Pj≥i exp(ληT θπ(j) + (1 − λ)(i − σ−1π(j)))

The working principle for g is similar to f , except that
it now allows for deviations from σ only if it is explained
by the scores. Parameter λ is tuned to adjust the relative
importance of the scores and the central permutation σ. For
example, if λ = 0 then the scores are ignored and if λ = 1
then the central permutation does not play any role. We
treat 0 ≤ λ ≤ 1 as a free parameter whose value needs to be

m

Yi=1

p(zi | τ ) · g(πi | σi, λ, θ, η)zi f (πi | σi, µ)1−zi

(3)

Finally, the full joint distribution for LTP can be obtained
by multiplying Equations 1 and 3. We treat the parame-
ters ν, α, δ, γ as constant and do not consider learning them.
However, the parameters µ and λ that controls the permu-
tation models need to be learned. We have assumed a Gaus-
sian prior on η. The role of this prior is to set η to zero when
we do not observe any signiﬁcant diﬀerence between π and
σ i.e πi ≈ σi.

We ﬁrst assume that λ and µ are predeﬁned constants
and describe the inference (LTP-INF) of the personalization
vector η based on these values in Section 4.2. We will then
use LTP-INF to also estimate these parameters in Section
4.3.

4.2 Inference of Personalization Vector

The key inferential problem that we study in this work is
to obtain the posterior distribution on the latent variables
i.e. to determine p(θ, K, β, z, τ, η | σ; λ, µ). As with simpler
topic models, the exact inference is intractable and there-
fore, we resort to approximate inference techniques. Given
the non-conjugacy of π and θ, sampling based techniques

877In this paper, we propose a
are unlikely to be eﬃcient.
variational approximation scheme.
In a variational infer-
ence, one deﬁnes a family of simpler distribution over the
latent variables to approximate the true posterior distribu-
tion. This family of distribution is indexed by additional
parameters (called variational parameters) which are tuned
so as to minimize the KL divergence with the true posterior.
We ﬁrst simplify the inference by breaking it into two
parts. For the ﬁrst part, we ignore the dependency be-
tween the topic and the personalization block. Therefore,
our strategy is to ﬁrst infer the topics and use the inferred
topics and the topic-maps of the items to carry out inference
for the personalization block. This will simplify the expo-
sition greatly and the ideas that we develop here will carry
over naturally to the general case of inferring the blocks
jointly. We revisit the inference for the complete model in
Section 4.4. Inference for the topic block follows standard
techniques (see e.g.
[3]) and therefore, we omit the details
here. For the rest of this sub-section we assume that the
topics have been inferred and develop an inference scheme
for the personalization block.

For the personalization block, the key inferential prob-
lem is to obtain the posterior distribution p(z, τ, η | σ; λ, µ).
This posterior is approximated with the help of a variational
distribution r. Figure 3 illustrates its graphical model rep-
resentation. The personalization vector η is assumed to be
Gaussian with the following density

r(η | ˜η) = (2πγ2)− T

2 exp(cid:18)−

1

2γ2 (η − ˜η)′ · (η − ˜η)(cid:19)

Here, the variational parameter ˜η represents the mean of the
gaussian and its variance is γ2I. For query qi we assume that
zi is sampled from a Bernoulli distribution with parameter
φi ∈ (0, 1). Finally, for user u, we assume that τ is sam-
pled from a beta distribution having the following density
function

r(τ | κ1, κ2) =

Γ(κ1 + κ2)
Γ(κ1)Γ(κ2)

τ κ1−1(1 − τ )κ2−1

where the parameters κ1, κ2 > 0 and Γ(x) is the Gamma
function. We use the notation Ψ(x) for the digamma func-
tion which is deﬁned as d

dx ln Γ(x).

The next step in our variational analysis is to learn the
particular value of the parameters (φ, κ1, κ2, ˜η) that mini-
mizes the KL divergence between r and the true posterior p.
It can be shown8 that minimizing the KL divergence has the
same eﬀect as maximizing the following objective function,

Λ(φ, κ1, κ2, ˜η) = Er [ln p] + H(r)

(4)

where H(r) is the entropy and Er denotes expectation w.r.t
the distribution r.

We use block coordinate-wise ascent to maximize the ex-
pression in Equation 4. Intuitively, we perform ﬁxed point
iterations by updating one block of parameters at a time,
keeping all other parameters ﬁxed to their most recent value.
The update rule for parameters φ1,2,··· ,m, κ1, κ2 are obtained
by setting the partial derivatives of Λ to zero. Due to our
choice of r, the update rules for φ, κ1, κ2 are particularly
simple and have closed-form expressions.

8Refer to [3] for the proof.

Algorithm 1 LTP-INF: Variational Inference Algorithm
for LTP
1: Input Training data-set

(π, σ)1,2,··· ,m;

values

for

2, ˜η′) that maximize Λ;

1 , κ(0)
2 ,

1···m, κ(0)
2 > 0;

| σj , µ) −

λ, γ, δ, µ;

1, κ′

1···m, κ′

1 , κ(0)

2 , ˜η(0));

2: Output Values (φ′
3: Initialization Randomly initialize to (φ(0)
1 , κ(0)

˜η(0)) such that 1 > φ(0)
1...m > 0 and κ(0)
4: i ← 0; ∆(0) ← Λ(φ(0)
1···m, κ(0)
5: while ∆ has not converged do
6:
7:

j=1(1 − φ(i−1)
j=1 φ(i−1)

1 ← δ +Pm
2 ← δ +Pm

i ← i + 1;
κ(i)
κ(i)
for j = 1...m do
µj ← Ψ(κ(i)
Er[ln g(πj | η; σj , θ, λ)];
φ(i)
j ← 1/(1 + eµj ); /* Update φj */

2 ) − Ψ(κ(i)

1 ) + ln f (πj

);

j
;

j

8:
9:
10:

11:
12:
13:

end for
˜η(i) ← argmax

˜η

Λ(φ(i)

1···m, κ(i)

1 , κ(i)

2 , ˜η); /* Use conju-

gate gradient to optimize this block */

14: ∆(i) ← Λ(φ(i)
15: end while
16: return (φ(i)

1···m, κ(i)

1 , κ(i)

2 , ˜η(i))

1···m, κ(i)

1 , κ(i)

2 , ˜η(i));

To maximize Λ with respect to ˜η, we use the conjugate
gradient algorithm9. The objective function for ˜η can be
written as

L(˜η) = −

1

2γ2 ˜η′ · ˜η +Xi

(1 − φi) · Er [ln g(πi | σi, θ, λ)]

It can be proved that L is concave (with respect to ˜η) and
therefore, using simple optimizers like conjugate gradient,
we will be able to obtain the global maximum [4]. Algo-
rithm 1 summarizes the inference procedure. Due to page
limits, we omit the derivations and refer to the full version
of the paper [15] for details.

4.3 Parameter Estimation

We now focus our attention at learning λ and µ. We use
Maximum Likelihood Estimators (MLE) for this, where one
ﬁnds the value of the parameters that maximizes the (log)
likelihood of the observed data i.e. the following expression

ln p(π | λ, µ; σ) =

m

Xi=1

ln p(πi | λ, µ; σi)

(5)

However, to calculate the likelihood function, we have to
marginalize over the latent variables which is diﬃcult in our
model for both real variables (η, τ ), as it leads to inte-
grals that are analytically intractable, and discrete variables
(z1···m), it involves computationally expensive sum over ex-
ponential (i.e. 2m) number of terms.

We use the variational Expectation Maximization (EM)
algorithm to circumvent this diﬃculty. In the E-step, Al-
gorithm 1 approximates the true posterior distribution over
the latent variables, using the current estimates of the pa-
rameters. The variational parameters learned in this step

9http://en.wikipedia.org

/wiki/Nonlinear conjugate gradient method

878Algorithm 2 LTP-EM: Variational EM Algorithm for LTP
1: Input Training data-set (π, σ)1,2,··· ,m
2: Output Values (λ′, µ′) that maximize Equation 5
3: Initialization Randomly initialize (λ(0), µ(0)) s.t. 0 ≤

λ(0) ≤ 1 and µ(0) > 0.

4: while (λ, µ) have not converged do
5: E-step

/* The variational inference step */

(φ′

1···m, κ′

1, κ′

2, ˜η′) ← LTP-INF(σ, π, λ(i), µ(i));

•

•

Λ(i)(λ, µ) ←

r(φ′,κ′

E
1 ,κ′

2, ˜η′)

[ln p];

5.1.1 Google Search Personalization

returned by a search engine. During the training phase, we
present these queries to LTP and let it learn the personaliza-
tion vector η. Once η is learned, the next step is to validate
it, by measuring how well it corresponds to the ground truth.
However, in practice, such validation schemes are often diﬃ-
cult to design as the search engines do not reveal the actual
user proﬁle10. We therefore perform our experiments on
both real-world data-set comprised of Google search history
of a few users, and a large scale synthetic data-set.

We collected search history data from 10 real Google users
in Nov 2012. We fetched their past search queries using
Google API that returns a sample of about 1000 web queries
from her history (it also contains other queries like map,
image, etc. that we ignored). We retrieved on average 850
distinct queries for each user.

We issued each distinct query in his history (in a ran-
domized order) to Google both with and without their login
credentials to retrieve the search results. For a given query,
both the results were fetched at the same time (within a few
seconds of each other) and using the identical connection
parameters such as user-agent (UA), IP-address, http head-
ers (except cookies), etc. This process removes non-proﬁle
based personalizations such as those based on context of
the current session (randomized order breaks any coherent
context in user’s history), IP address or location, time-of-
the-day (the whole data collection for a user took only a few
minutes), browser or OS type, etc. Hence the diﬀerences in
results should be only due to user’s proﬁle.

We then parsed the result pages and extracted the ranked
results. We ignored the paid links (at top and bottom of the
page) and any map, image, or other embedded group of re-
sults that some queries return. We then used the Mallet [19]
toolkit to extract topics from the urls11 separately for each
user. Due to privacy considerations, we then annonymized
the entire data set by mapping each url, query and topic to
(randomly generated) IDs. Our algorithms were run on this
annonymized data.

We found ample evidence of proﬁle based personalization
on Google—roughly 30% queries received personalized re-
sults, i.e. had diﬀerences in the ranks of urls in personalized
and vanilla results. We also found that the personalization
is much more subtle compared to the impression we get from
search personalization literature (and our experiments with
AlterEgo server)—most queries (≈ 70%) were not person-
alized and while there were some queries with fair amount
of personalization, on an average, we observed very little
diﬀerence between the results12.

5.1.2 AlterEgo

We use an open source search personalization engine called
AlterEgo [18] to generate the synthetic dataset. AlterEgo
contains implementation of various popular proﬁling and

10Google, however, publishes the categories of topics used
to serve personalized ads. Unfortunately, this data is not
quite helpful as the categories are very high level and do not
convey rich enough information.

11We used the snippets that Google returns along with

the search results to obtain text for the urls.

12The avg. EMD (earth mover’s distance) over queries
the EMD of moving a

with personalization was 5.9 (e.g.
single url at rank 5 to rank 1 is 4)

6: M-step /* Learn new estimates of the parameters */

•

(λ(i+1), µ(i+1)) ← argmax

Λ(i)(λ, µ)

µ>0

1≥λ≥0

7:
i ← i + 1
8: end while
9: return (λ(i), µ(i))

are used in the subsequent M-step to maximize the likeli-
hood function (over the true parameters λ and µ).

Algorithm 2 summarizes the steps of the variational EM.
It can be shown [15] that the constraint maximization prob-
lem in step 6 is a concave program and therefore, can be
solved optimally and eﬃciently [4].

4.4 Learning Topic Distributions

For inference in the topic block (Figure 1), we augment
our variational distribution with additional parameters in
the following way. Topic distribution βk is sampled from
a Dirichlet prior with parameters { ˜βk,w | w ∈ V }. The
topic assignments Ki,j are sampled from a multinomial dis-
tribution with parameters ωi,j,1···T and θi is sampled from
a normal distribution with mean ˜θi and variance α2I. Us-
ing the same recipe as in Section 4.2 (c.f. Equation 4), we
arrive at the following simple update rule for learning the
topic distributions

βk,w = ν + Xi,j

Wi,j =w

ωi,j,k

The topic assignments ωi,j also has a closed form update
rule as given by ωi,j,k ∝ exp(Er[ln θi] + Er[ln βk,wi,j ])

The main diﬃculty in learning topic-maps (i.e. θi’s) stems
from the coupling between the personalization and the topic
blocks through θ. While determining Er[ln g(π | η, θ; σ, λ)]
(step 8 of Algorithm 1), we now have to take expectation
over θ, in addition to η. However this calculation is analyt-
ically tractable due to our assumption of independence and
gaussian priors on θ and η. We use gradient descent on θ to
solve it. The rest of the calculation remains unchanged.

5. EXPERIMENTS

In this section, we describe a comprehensive set of exper-
iments designed to evaluate the accuracy and eﬀectiveness
of our techniques.

5.1 Data-sets

The input to our algorithm consists of a set of queries and
the personalized and vanilla results (i.e. π, σ pairs) for them,

879personalization techniques; we used their “unique matching”
technique for our experiments13.
In our simulation, we
used AlterEgo as a surrogate personalization engine i.e. we
obtain the vanilla result from Google and use AlterEgo to
personalize it. The beneﬁt of this approach is that we can
train AlterEgo on topics of our choice and use this infor-
mation to validate the model output η. The work-ﬂow and
details of the data generation steps are presented below.
Generating Topics We extracted a set of 500 topics by
running Mallet on approximately 420k urls obtained from
the Delicious dataset[28]. We manually select 50 topics and
label them into 10 categories (examples are health, cooking,
science, ﬁnance, etc.); these topics serve as a ground-truth
for us. The selection of these topic categories and urls (used
in the next step) is intended to simulate a typical user be-
havior, where, a user in interested in ≈ 10 categories of
topics.
Training AlterEgo For each topic, we inspect the topic-
maps of the urls and identify the ones which have signiﬁcant
(> 0.2) weight (on this topic). These urls are used to train
AlterEgo proﬁle. We generated 10 proﬁles trained on a sub-
set of 1 to 10 topics (i.e. 10 proﬁle for 1 topic, 10 proﬁle on
2 randomly selected topics, and so on), generating a total of
50 proﬁles.
Queries We generated 500 queries for each topic by ran-
domly combining the top 10 relevant words from them. This
gives us a total of 5k queries (over 10 categories). For each
query, we retrieved the vanilla results from Google. Note
that, if a query is related to a topic used for training the
proﬁle, only then AlterEgo will be able to personalize it.
Otherwise, the vanilla and personalized results will be more
or less identical.

5.2 Implementation Details

We use JOptimizer 14 - a java based open source optimiza-
tion package for solving the convex program in Algorithm 2
(step 6) All our experiments are carried out on a Intel Pen-
tium IV machine with 3.0GHz processor and 4GB of RAM.
We use the following values of the hyper-parameters : δ =
2.0, γ = 1.0. For computational eﬃciency, we used Mallet
for inference in the topic-block (see Figure 1) and do not use
the inference process described in Section 4.4.

5.3 Results with the AlterEgo data-set

In this section, we summarize the result of our experi-

ments with the AlterEgo data-set.

5.3.1 Precision-Recall

Our ﬁrst set of experiments are designed to evaluate the
accuracy of LTP in correctly learning the personalized top-
ics. On each AlterEgo proﬁle, we train LTP and learn the
personalization vector η. Next we compare it with the ac-
tual list of topics that were used to train this proﬁle (by
AlterEgo). Let Tact be the true set of personalized topics
and Tinf be the one inferred by LTP. For this experiment,
we measure the precision and recall values, where precision
is deﬁned as |Tact∩Tinf |
i.e. the fraction of reported topics
that are actually personalized and recall by |Tact∩Tinf |

|Tinf |

|Tact|

i.e.

13We also did experiments with their “matching” tech-
nique, and got very similar results which are omitted due
to lack of space.

14http://www.joptimizer.com/

the fraction of the original personalized topics that we are
able to identify.

P@1
97.80

P@3
84.02

P@5
70.60

R-pre P@+1 P@+3 MAP
84.66
97.60

70.69

54.44

Table 1: Performance (in %) of LTP in ﬁnding per-
sonalized topics (with AlterEgo data-set).

We re-order the topics based on the (decreasing) value of
η computed by LTP. For each k, we declare the top-k topics
(with maximum η values) as personalized and calculate the
precision and recall value for this decision. Table 1 sum-
marizes the precision scores obtained by LTP. Speciﬁcally,
we evaluate its performance in terms of Precision@1(P@1),
P@3, P@5, R-precision (R-pre) and mean average precision
(MAP) [5, 7]. Note that the size of actual topics was quite
diﬀerent for diﬀerent runs (varies from 1-10). Hence, along
with the top-k topics, we also study the precision at |Tact+k|
(denoted as P@+k).

0

.

1

9

.

0

8
0

.

7

.

0

6

.

0

5

.

0

l
l

a
c
e
R

0.2

0.4

0.6

0.8

1.0

Figure 4: Precision-Recall results for LTP in retriev-
ing the personalized topics (with AlterEgo data-set).

Precision

In Figure 4, we illustrate the recall performance of our
algorithm. At the expense of low precision (< 0.4), LTP is
able to retrieve all the personalized topics (recall ≥ 0.93)
and its recall performance is relatively insensitive to preci-
sion; however, if we require high precision ( > 0.8), the recall
drops to ≈ 0.5. As evident from the ﬁgure, a typical operat-
ing characteristic of LTP is precision ≈ 0.7 and recall ≈ 0.7,
which is achieved when we return top-3 topics.

5.3.2 Classiﬁcation Tests

In this section, we develop two classiﬁcation tests to evalu-
ate LTP’s predictive power. For both these experiments, we
randomly split the π, σ list into data-sets D1 (80%), used
for training LTP, and D2 (20%), used for testing. We re-
peat this split with 10 random seeds and report the average
number in all the data presented below.

Query Disambiguation In this experiment, while test-
ing on D2, we hide which result is personalized and which
one is vanilla and the task of the model is to determine the
correct labels.

We proceed with the classiﬁcation task in the following
way. Let η′ be the parameter learned by LTP during the
training. For input lists l1 and l2, LTP calculates the like-
lihood values p(l1 | l2, η′) and p(l2 | l1, η′) and whichever
likelihood is higher is assigned to the personalized result i.e.
if p(l1 | l2, η′) > p(l2 | l1, η′) then l1 is declared to be the

880#topics

Accuracy (µ ± σ)

Time (secs)

LTP-EM LTP-INF LTP-EM LTP-INF
.74 ± .09
.72 ± .06
.70 ± .05
.69 ± .04
.69 ± .05
.67 ± .04
.65 ± .04
.63 ± .04
.63 ± .05
.62 ± .02

.72 ± .09
.70 ± .09
.68 ± .06
.67 ± .05
.67 ± .05
.65 ± .05
.65 ± .05
.63 ± .04
.62 ± .05
.62 ± .02

80.7
154.3
221.6
272.2
336.1
333.2
342.5
348.2
354.4
359.2

22.7
31.5
42.4
53.7
69.8
70.7
71.1
73.6
76.4
79.5

1
2
3
4
5
6
7
8
9
10

Table 2: Summary of results with the AlterEgo
dataset

personalized result and vice versa. We name this test as P-V
disambiguation for a given proﬁle. Over all the test points
in D2, the fraction of queries that were labeled correctly is
referred to as disambiguation accuracy.

Table 2 summarizes the result of this experiment. In sum-
mary, we achieve disambiguation accuracy in the range of
62-74%. For each proﬁle, we collect the accuracy values for
the 10 diﬀerent runs and report its mean and standard devi-
ation (µ ± σ). Observe that our accuracy decreases slightly
as the AlterEgo proﬁle is trained with more and more topics.
Table 2 also reports the training time of LTP-EM . For
proﬁles trained with many topics, LTP-EM takes more time
to converge. We repeat the experiment with LTP-INF with
the parameter values ﬁxed to λ = 0.9 and µ = 10.0. As the
results show, LTP-INF is up to 5 times faster to train but
achieves slightly lower accuracy. The accuracy however, im-
proves slightly (< 3%) if we increase the amount of training
data (D1) from 80% to 90% (not shown in the table).

1 topic
3 topics
5 topics

)

%
(
y
c
a
r
u
c
c
A

0
8

0
7

0
6

0
5

0
4

0
3

0
2

2

4

6

8

10

Number of users in a group

Figure 5: Performance of LTP in user classiﬁcation
(with AlterEgo data-set).

User Classiﬁcation For this experiment, we consider
groups of users (i.e. proﬁles) and develop a classiﬁcation
test within the group members. We vary the size of the
group from 2 to 10 and for each group size, randomly pick
10 groups. For each group G, we present a (π, σ) pair to
LTP but do not reveal the user it belongs to. The task of
the model is to correctly predict the user.

We again use the likelihood test for this task. Speciﬁcally,
u)

for each user u ∈ G and input (π, σ), we calculate p(π | σ, η′

Google Category

Topic in LTP

Comics & Animation -

online read manga

Anime & Manga
Autos & Vehicles -
Vehicle Shopping

Computers -

Software Utilities
World Localities -

kyojin shingeki chapter

car india chrysler

price jaguar sport bmw
class import common
org public implement

seoul citi hotel

South Asia

location shop mall coex

η

0.60

0.42

0.15

0.13

Table 3: Correlation between personalized topics in
LTP and Google categories.

u learned during training) and output the user for which

(η′
the likelihood attains its maximum value.

In Figure 5, we summarize the result of this experiment.
There are two parameters in this experiment - the size of
the group and the number of topics used to train AlterEgo
for each proﬁle in the group. For simplicity, we present here
results for the homogeneous case, where we combine proﬁle
which are trained on the same number of topics 15. Observe
that the accuracy reported by LTP is signiﬁcantly higher
than a random guess (which is 1/g, g being the group size).
The accuracy decreases slightly if proﬁles are trained with
many topics. We believe this reduction in accuracy is also an
artifact of our data generation—proﬁles trained on multiple
topics can (and do) have topics in common, that will make
it hard to distinguish personalized response on two proﬁle
trained on the same topic.

In summary, these results, together with the precision-
recall values from last section highlight that our model ﬁts
the data well and learns the correct set of personalized topics
on synthetic data.

5.4 Results with the Google dataset

In this section we describe the results with the Google
data-set. Note that since we do not know the actual person-
alization on diﬀerent topics (ground truth) for a real Google
user, we cannot perform the precision-recall experiments as
with AlterEgo dataset, and resort to only query disambigua-
tion and user classiﬁcation test described above. However,
we also perform some qualitative tests that give ample indi-
cation that we have found a good personalization vector.

5.4.1 Qualitative Evidences for Correctness of η

We now present our analysis on ﬁnding qualitative correct-
ness of η using evidences of personalization. An evidence is
an instance of π, σ where results were re-ranked such that
the ones with η were moved up. Note that while such ev-
idence have no statistical signiﬁcance, they are much more
helpful for a user’s understanding of his proﬁle compared to
the personalization vector. Such evidences are a core feature
of the privacy toolkit we are building (see Section 6).

Figure 6 shows an example evidence of personalization
happening on a user’s account. The result for query Q (“how
to decide mixing of markov chain”) and theta values for two
relevant topics T1 (about “Algorithms” deﬁned by words al-
gorithm, design, complexity) and T2 (about “Probability”
deﬁned by words probability, distribution) are shown. For

15We also performed experiments on the general case (e.g.
by grouping proﬁles trained on 3 topics with 5 topics). The
results are similar and not repeated here.

881Topic

T1 T2
.40
η
.90
.30
Q .01
.10
.15
U1
U2
.01
.25

Figure 6: An example to illustrate the diﬀerence between personalized (left) and vanilla (right) search results
(for a real user) returned by Google.

User Id

1
2
3
4
5
6
7
8
9

15 Topics
.74±.05
.68±.05
.67±.13
.54±.08
.54±.11
.85±.07
.73±.04
.66±.03
.52±.04

20 Topics
.70±.05
.70±.04
.72±.14
.51±.06
.47±.09
.78±.05
.70±.05
.62±.03
.52±.03

50 Topics
.70±.06
.70±.04
.67±.13
.55±.06
.49±.11
.84±.04
.71±.06
.61±.04
.50±.04

100 Topics

.73±.04
.65±.03
.73±.11
.59±.07
.43±.09
.81±.07
.73±.06
.64±.03
.54±.04

Table 4: Accuracy of LTP over 9 Google users.

this user, η value for T1 is very high compared to T2. Ob-
serve that the wiki link U1 (in the box), although less rele-
vant to the query, is placed higher in the personalized results.
As our analysis shows, U2 is has a high weight on topic T1
compared to U2, which leads to this personalization. The
user can therefore see not just his inferred interests (more
in “Algorithms” compared to “Probability”), but also how it
aﬀects his results.

We next move to another qualitative analysis of η by com-
paring it directly with the categories Google itself associates
with a user16. We try to match topics with high η (top-k
such topics) with the broad categories in Google. Table 3
shows the result of such matching for 3 users. Take for
example, the “Anime and Manga” category, that was also
assigned a very high η = .6 (compared to an average value
of .004) by LTP.

Such anecdotes show that our techniques have, in fact,

learned the personalization vector correctly.
5.4.2 Quantitative Experiments

Query Disambiguation Table 4 summarizes the result
of query disambiguation on the Google dataset. We ﬁrst
study the eﬀects of number of topics (T ) chosen for the
user. We notice that only a few topics 15-50 are enough
to get good accuracy for any user. Our accuracy results
diﬀer signiﬁcantly for diﬀerent users, varying from as low

16Shown

in

Google

ads

preference manager

https://www.google.com/settings/ads/onweb/

Group

Size

Number of Topics

10

20

50

100

2
3

.59 ± .06
.48 ± .04

.61 ± .06
.53 ± .05

.65 ± .04
.60 ± .05

.58 ± .05
.50 ± .06

Table 5: User classiﬁcation accuracy on Google data.

as 54% to 85%. We believe this is because the amount of
personalization is diﬀerent for various users, and this aﬀects
the learning accuracy of our techniques.

User Classiﬁcation Table 5 show that even with 3 users,
we are able to get an accuracy of up to 60%. For this exper-
iments, we extracted η values over a common set of topics
for each user. These η values learned were also very diﬀerent
for diﬀerent users (data not shown). This shows that η is in
fact learned tailored to the personalization of each user.

6. CONCLUSIONS

In this paper we have presented a novel approach to ex-
tract user proﬁle information in the form of personalization
vector over topics from commercial OSPs (such as Google
search). Our approach treats OSPs as black-boxes, i.e. as-
sumes no knowledge of the personalization algorithms and
history of users maintained by them, and works by compar-
ing the personalized and vanilla content served by them.

To the best of our knowledge, this is the ﬁrst work that
tries to extract information based solely on mining the out-
put of OSPs. This approach is unique in not just enabling
access to (so far hidden) proﬁles in OSPs, but also in provid-
ing a novel and practical approach for retrieving information
from OSPs by mining diﬀerences in their outputs.

Our approach also has direct beneﬁts for end users, as for
the ﬁrst time, it enables them to access their (so far hidden)
proﬁle information tracked by an OSP. While being an in-
formational tool by itself, this has wider implications to the
outlook of user privacy research—it can be used to infer the
personalization happening on sensitive topics (e.g. ﬁnancial,
medical history, etc.), which a user may not be comfortable
with. We believe that this can be used to build an end-
user privacy preserving tool and are currently working on a
prototype for the same.

8827. REFERENCES
[1] P. N. Bennett, R. W. White, W. Chu, S. T. Dumais,

P. Bailey, F. Borisyuk, and X. Cui. Modeling the
impact of short-and long-term behavior on search
personalization. In SIGIR, 2012.

[2] J. Bischof and E. Airoldi. Summarizing topical content

with word frequency and exclusivity. ICML, 2012.

[3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent
dirichlet allocation. J. Mach. Learn. Res., 2003.

[4] S. Boyd and L. Vandenberghe. Convex Optimization.

Cambridge University Press, 2004.

[5] C. Buckley and E. M. Voorhees. Retrieval evaluation

with incomplete information. In SIGIR, 2004.

[6] G. Chen, H. Bai, L. Shou, K. Chen, and Y. Gao. Ups:
eﬃcient privacy protection in personalized web search.
In SIGIR, 2011.

[7] N. Craswell, A. P. de Vries, and I. Soboroﬀ. Overview

of the trec-2005 enterprise track. In TREC, 2005.

[8] Z. Dou, R. Song, and J. R. Wen. A large-scale
evaluation and analysis of personalized search
strategies. In WWW, 2007.

[9] A. Hannak, P. Sapiezynski, A. M. Kakhki,

B. Krishnamurthy, D. Lazer, A. Mislove, and
C. Wilson. Measuring personalization of web search.
In WWW, 2013.

[10] A. Korolova. Privacy violations using microtargeted

ads: A case study. In ICDMW, 2010.

[11] J. Lindamood, R. Heatherly, M. Kantarcioglu, and

B. Thuraisingham. Inferring private information using
social network data. In WWW, 2009.

[12] R. D. Luce. Individual choice behavior: A theoretical

analysis. Wiley, 1959.

[13] J. Luxenburger, S. Elbassuoni, and G. Weikum.

Matching task proﬁles and user needs in personalized
web search. In CIKM, 2008.

[14] A. Machanavajjhala, A. Korolova, and A. D. Sarma.

Personalized social recommendations: accurate or
private. VLDB Endowment, 2011.

[15] A. Majumder and N. Shrivastava. Know your

personalization: Learning topic level personalization
in online services. Arxiv, abs/1212.3390, 2012.

[16] C. L. Mallows. Non-null ranking models. Biometrika,

1957.

[17] H. Mao, X. Shuai, and A. Kapadia. Wpes. In Proc.
workshop on Privacy in the electronic society, 2011.

[18] N. Matthijs and F. Radlinski. Personalizing web search

using long term browsing history. In WSDM, 2011.

[19] A. K. McCallum. Mallet: A machine learning for

language toolkit. http://mallet.cs.umass.edu.

[20] E. Pariser. The Filter Bubble: What the Internet Is

Hiding from You. Penguin Press, 2011.

[21] T. Qin, X. Geng, and T. Y. Liu. A new probabilistic

model for rank aggregation. In NIPS, 2010.

[22] D. Sontag, K. Collins-Thompson, P. N. Bennett,

R. W. White, S. Dumais, and B. Billerbeck.
Probabilistic models for personalizing web search. In
WSDM, 2012.

[23] B. Tan, X. Shen, and C. X. Zhai. Mining long-term

search history to improve search accuracy. In
SIGKDD, 2006.

[24] J. Teevan, E. Adar, R. Jones, and M. Potts. History

repeats itself: repeat queries in yahoo’s logs. In
SIGIR, 2006.

[25] J. Teevan, S. T. Dumais, and E. Horvitz.

Personalizing search via automated analysis of
interests and activities. In SIGIR, 2005.

[26] J. Teevan, S. T. Dumais, and E. Horvitz. Potential for

personalization. TOCHI, 2010.

[27] J. Teevan, S. T. Dumais, and D. J. Liebling. To

personalize or not to personalize: modeling queries
with variation in user intent. In SIGIR, 2008.

[28] R. Wetzker, C. Zimmermann, and C. Bauckhage.

Detecting trends in social bookmarking systems: A
del.icio.us endeavor. IJDWM, 2010.

[29] Y. Xu, K. Wang, B. Zhang, and Z. Chen.

Privacy-enhancing personalized web search. In WWW,
2007.

[30] Y. Zhu, L. Xiong, and C. Verdery. Anonymizing user
proﬁles for personalized web search. In WWW, 2010.
[31] Z. A. Zhu, W. Chen, T. Wan, C. Zhu, G. Wang, and

Z. Chen. To divide and conquer search ranking by
learning query diﬃculty. In CIKM, 2009.

883