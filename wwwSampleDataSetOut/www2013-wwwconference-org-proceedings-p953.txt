Measurement and Modeling of Eye-mouse Behavior in the

Presence of Nonlinear Page Layouts

Vidhya Navalpakkam

LaDawn Jentzsch

Sujith Ravi

Amr Ahmed

Rory Sayres

Alex Smola

{vidhyan,ladawn,sayres,sravi,amra}@google.com, alex@smola.org

ABSTRACT
As search pages are becoming increasingly complex, with
images and nonlinear page layouts, understanding how users
examine the page is important. We present a lab study on
the eﬀect of a rich informational panel to the right of the
search result column, on eye and mouse behavior. Using eye
and mouse data, we show that the ﬂow of user attention
on nonlinear page layouts is diﬀerent from the widely be-
lieved top-down linear examination order of search results.
We further demonstrate that the mouse, like the eye, is sen-
sitive to two key attributes of page elements – their position
(layout), and their relevance to the user’s task. We identify
mouse measures that are strongly correlated with eye move-
ments, and develop models to predict user attention (eye
gaze) from mouse activity. These ﬁndings show that mouse
tracking can be used to infer user attention and information
ﬂow patterns on search pages. Potential applications include
ranking, search page optimization, and UI evaluation.

Categories and Subject Descriptors
H.4.m [Informations Systems Applications]: Miscella-
neous

General Terms
Design, Experimentation, Human Factors

Keywords
eye, mouse, web search, attention, measurement, prediction

1.

INTRODUCTION

A decade ago, search pages were simple, text only and
contained a linear listing of documents. Today, search pages
are increasingly complex, with interactive elements, images
and text in multiple colors, font sizes, and varying inden-
tation; they include new multi-column layouts, and contain
various page elements drawn from news, images, documents,
maps and facts. With multiple page elements competing for
the user’s attention, and attention being a limited resource,
understanding which page elements get more or less atten-

Copyright is held by the International World Wide Web Conference
Committee (IW3C2). IW3C2 reserves the right to provide a hyperlink
to the author’s site if the Material is used in electronic media.
WWW 2013, May 13–17, 2013, Rio de Janeiro, Brazil.
ACM 978-1-4503-2035-1/13/05.

tion is important, and has applications for ranking, search
page optimization, and UI evaluation.

Previous studies of attention on search pages focused on
the linear page layout (containing a single column of search
results) and showed a Golden Triangle [14] of user atten-
tion1 – where users pay most attention to the top-left of the
page, and attention decreases as we move towards the right
or bottom of the page. Related studies showed that users
tend to scan the search page sequentially from top to bot-
tom, giving rise to popular cascade models and their variants
[6, 5]. Given that the search pages have become more com-
plex since (both visually and content-wise), the question of
whether the Golden Triangle and other previous ﬁndings on
attention still hold is open.

Eye tracking has been the favored methodology for study-
ing user attention on the web [9, 8, 7, 2, 3, 20].
It oﬀers
rich details on user attention by sampling eye gaze positions
every 20ms or more frequently, and providing fairly accu-
rate estimates of user eye gaze (<0.5-1◦error, just a few pix-
els). On the ﬂip side, commercial eye trackers are expensive
($15K upwards per piece), eye tracking is not scalable (typi-
cally performed in the lab with 10-30 participants), and it is
not clear to what extent ﬁndings from eye tracking studies
in controlled lab settings can generalize to user attention in
the wild.

Recently, researchers have begun exploring whether a user’s
mouse activity can provide approximations to where the user
is looking on the search results page. Previous studies have
shown reasonable correlations between the eye and mouse
for linear page layouts2[22, 12, 15]. In this paper, we con-
duct a lab study to test whether mouse tracks can be used to
infer user attention on complex search pages with nonlinear
page layouts. In particular, we test eye-mouse sensitivity to
an element’s position on the search page, and its relevance
to the user’s task. The main contributions of this paper are
outlined below:

1. We present a lab study to test eye-mouse activity on
linear search page layouts (containing one column of
search results) and new nonlinear search page layouts

1in this paper, we use the term “user attention” to refer to
those aspects of users’ attention that can be measured by the
eye. Note that attention itself is a more complex, cognitive
process.
2We ignore ads in this study, and focus only on search re-
sults. Thus, linear layout here refers to a single column of
search results.

953(containing a rich informational panel on the top-right
of the page), and demonstrate that the mouse, like the
eye, is sensitive to the element’s position on the search
page in both layouts.

2. We demonstrate that both eye and mouse are sensitive

to the element’s relevance to the user’s task.

3. We identify mouse measures that are most correlated

with eye gaze.

4. We develop models that predict users’ eye gaze reason-
ably well from their mouse activity (67% accuracy in
predicting the ﬁxated result element, with an error of
upto one element).

5. We conclude with limitations of mouse tracking and
why it may be a weak proxy for eye tracking, but can-
not substitute it.

2. RELATED WORK
2.1 Relationship of eye and mouse signals

The relationship of eye and mouse movements have been
explored both in lab studies and at scale. Rodden and col-
leagues [22] measured eye and mouse movements of 32 users
performing search tasks in a lab setting. They identiﬁed
multiple patterns of eye-mouse coordination, including the
mouse following the eye in the x and y directions, marking
a result, and remaining stationary while the eye inspected
results. They found a general coordination between eye and
mouse position, where the distribution of eye/mouse dis-
tances centered close to 0 pixels in both x and y directions.
Huang et al [15] extended these ﬁndings by examining
variations in eye-mouse distance over time. They found that
eye-mouse distances peaked around 600 ms after page load
and decreased over time, and that the mouse tended to lag
gaze by ≈700 ms on average. They classiﬁed cursor behav-
iors into discrete patterns – Inactive, Reading, Action, and
Examining – and measured sizeable diﬀerences in mouse-
cursor position and time spent engaging in diﬀerent behav-
iors.

Because mouse-position signals can be collected at scale
more readily than eye movements, recent work has focused
on relating large-scale mouse signals to eye movements. One
approach proposed by Lagun and Agichtein (“ViewSer”; [18])
involves presenting a search result page in which all elements
are spatially blurred except the result containing the mouse
cursor. The resulting patterns of mouse movement across
results were found to correlate with eye tracking results ob-
tained in a lab setting for the same queries.

Other work from Huang, Buscher and colleagues [17, 16, 4]
compare eye and mouse tracking results from lab studies to
large-scale logs data from a search engine, deployed both in-
ternally [17] and on an external sample of users [16, 4]. This
work demonstrated that mouse-based data can be used to
evaluate search result relevance, distinguish cases of “good”
(user need-satisfying) and “bad” abandonment on web pages,
and identify clusters of distinct search task strategies.
2.2 Predictive models

Several studies have developed predictive models of user
attention, searcher behavior, or both, based on mouse data.
Guo and Agichtein [10] collected mouse-movement data from
searches at a university library, and were able to discrimi-
nate navigational from informational task intent. The au-
thors also built a binary classiﬁer to distinguish whether the

mouse was within a speciﬁed radius from the eye (varied
from 100 to 200 pixels), and showed that this model out-
performed a simple baseline model which always guessed
the majority category [12]. Huang et al [15] used eye and
mouse movement data from a lab study to ﬁt eye positions
using a linear model based on extracted mouse interaction
features. Their model demonstrated an improved eye gaze
prediction (decreased RMS error in mouse-cursor distance
in each direction, and Euclidean distance) over mouse data
alone.

Mouse behavior has been used to model patterns of user
search goals and strategies. Huang et al [16] incorporated
mouse data from search logs into a Dynamic Bayesian Net-
work model of searcher activity, using the positions of results
that were hovered over but not clicked to provide a more ro-
bust measure of which results were evaluated. The searcher
model incorporating these signals performed better (lower
click perplexity metrics, measuring unexpected click pat-
terns) than models without the signals. Guo and Agichtein
[11] used mouse movements to classify hidden states repre-
senting searchers’ search goals (researching versus conduct-
ing a purchase) or ad receptiveness (likely or unlikely to click
on a relevant ad) and tested the performance of their model
against data extracted from a user study, and user-provided
data from a library system. The authors also developed
a model of document relevance based on a combination of
mouse activity on the search result page, and on subsequent
post-search pages [13].
2.3 Differences from our work

To summarize, previous research on attention and eye-
mouse behavior in search focused on linear page layouts con-
taining a single column of search results, and demonstrated
mouse sensitivity to position on page. Our work diﬀers from
previous work in at least 3 ways: 1) In addition to linear
page layouts, we explore nonlinear 2-column results layouts,
with a rich information panel on the right hand side of the
page; 2) Apart from position on page, we test whether the
mouse is sensitive to important factors such as element’s rel-
evance to user’s task; 3) We systematically compare various
user-speciﬁc, global and hybrid models for predicting user
eye gaze based on mouse signals.

3. EXPERIMENT DESIGN

We recruited 31 participants (15 male and 16 female; age
range 18-65, with a variety of occupations and self-reported
web search expertise). Data from 5 participants was ex-
cluded due to calibration problems with the eye tracker.

Participants were given 4 warm-up tasks to familiarize
themselves with the testing procedure. They were then
asked to describe all of the elements of the search results
page to ensure they were aware of all elements on the page,
including the relatively new Knowledge Graph (KG) results
feature on the top-right of the page.3 For example, a query
on an entity such as a famous celebrity or place triggers a
result page with an informational panel (KG) on the right
hand side, containing images and facts about that entity.

Participants were provided a list of 24 search tasks. Each
task was accompanied by a link to the search results page
with a prespeciﬁed query (to ensure that all particpants saw

3http://googleblog.blogspot.com/2012/05/introducing-
knowledge-graph-things-not.html

954the same page). For consistency in results sets across users,
users could not change the queries. Blocks of images and
advertisements were suppressed on the results pages.

We used a 2 x 2 within subject design with two factors:
(1) KG present or absent, (2) KG relevant or irrelevant to
the user’s task. We varied task relevance of KG by design-
ing 2 tasks for the same query, one for which the answer
was present in KG (e.g., ”ﬁnd the names of Julia Robert’s
children”) and another for which the answer was present in
web results, but not KG (e.g. ”what does People magazine
say about Julia Roberts?”). Each user performed an equal
number of tasks with KG present and absent, as well as with
KG relevant and irrelevant. The order of tasks, KG pres-
ence, and KG task relevance were all randomized within and
across users. 4

For the purposes for this study, we injected custom javascript

in search results pages to log mouse activity on search page
as users performed their search tasks.
In particular, we
logged the browser viewport, and sampled mouse x,y posi-
tions every 20ms during mouse movements. Eye tracks were
simultaneously recorded using a Tobii TX300 eye tracker
with 300 Hz tracking frequency and an accuracy of 0.5◦ vi-
sual angle on a 23” monitor (1880 x 1000 browser size). Both
eye and mouse tracks were recorded with an origin at the
top-left of the document.

We considered data upto the ﬁrst click on the search page,
or until the user terminated the task (by clicking the back-
button to revisit the task list). Raw eye and mouse tracks
were of the form: <user, task, timestamp, x, y>. The raw
eye data was parsed to obtain a sequence of ﬁxations (brief
pauses in eye position for around 200-500ms) and saccades
(sudden jumps in eye position) using standard algorithms
[21, 23]. Eye ﬁxations and their duration are thought to in-
dicate attention and information processing [8]. Thus, our
subsequent analysis is performed using eye ﬁxations data.
We aligned eye ﬁxation and mouse data using time from
page load. Since eye ﬁxations occur every 200-500ms, while
mouse movements were logged every 20ms, we aligned them
per user, task by assigning the most recently ﬁxated eye
position to each mouse event.

4. RESULTS
4.1 Correlations in pixel space

To test eye-mouse correlations in pixel space, we extract
the following measures per user, per task: x,y positions of
eye and mouse, maximum x, maximum y, minimum x, and
minimum y. The scatter plot in ﬁgure 1 shows that the max-
imum y position shows reasonable correlation (r2=0.44).
Other pixel measures such as instantaneous x,y positions
of eye-mouse, or minimum x, maximum x, and minimum y
show poor correlation between eye and mouse (r2<0.05).
4.2 Correlations in Area-of-Interest space

The pixel-level measures described above include eye-mouse

activity in white space, and other elements that are not web
results (e.g., search bar, navigation menu). Since we mainly
care about which result element the user is looking at, we

4Another example of a query from the study, along with
tasks are: For search [hope ﬂoats]: ”Who directed the movie
’Hope Floats’” (answer in KG); ”What does the Hope Floats
wellness center do?” (answer not in KG)

Figure 1: Eye and mouse show correlations in the
maximum cursor distance along the vertical axis (y).
Each point in the scatter plot denotes a user, task
combination.

proceed to analyze the data by deﬁning meaningful areas-of-
interest on the search page. We divide the page into Knowl-
edge Graph results (KG), and divide result elements into
3 roughly equal-sized parts (so that their size is similar to
KG): Top 3 results (top), middle 3 results (mid), bottom
4 results (bot).
In addition, we consider the left naviga-
tion menu (left), and group everything else under miscella-
neous (misc). Thus, we deﬁne 6 areas-of-interest (AoI). The
bounding boxes of these AoIs are illustrated in Figure 3,
which shows a heatmap visualization of user eye gaze when
KG is present and absent.

To analyze the data quantitatively, for each AoI, we ex-
tract the following mouse measures: 1) #mouse hovers or
visits to the AoI, 2) time to ﬁrst mouse visit on the AoI
(in milliseconds), 3) dwell time (in milliseconds) per mouse
position within the AoI, 4) total mouse dwell time (in mil-
liseconds) in the AoI, 5) fraction of page dwell on AoI, 6)
fraction of tasks where the last mouse position occurs within
the AoI. We also extract corresponding measures for the eye.
Figure 2 shows eye-mouse correlations in AoI space. As
seen in the ﬁgure, the fraction of page dwell on AoI (dwell
time within AoI / total page dwell time) is strongly cor-
related between the eye and mouse (r2=0.89), followed by
dwell per AoI (in seconds, r2=0.36). We believe that the
fraction of page dwell time is a more useful measure, as it
adjusts for the pace at which users read, while raw dwell
times are sensitive to variation in user reading speeds. In-
terestingly, time-on-page after the eye/mouse visits the AoI
is also reasonably well correlated (r2=0.45). We will see
later (section 4.5) that this measure is aﬀected by the AoI’s
relevance (the user spends more time searching on the page
after visiting an AoI if the AoI is irrelevant).

We also ﬁnd strong correlations between the last AoI seen
by the eye and mouse before page click or abandonment
(r2=0.86), number of eye and mouse visits to an AoI (r2=0.83).
In comparison, there is weaker correlation between eye and
mouse time to ﬁrst noticing an AoI (r2=0.33), and no cor-
relation for time per eye/mouse pause (r2=0.07).

955Figure 2: Area of interest (AoI) measures. The measures for eye data are shown in the x axis, and mouse
data are shown in the y axis. The left panel shows the dwell time per AoI in seconds, the middle panel shows
the fraction of page dwell per AoI, and the right panel shows the time on page after visiting the AoI (in
seconds). Each data point reﬂects one user/task/AoI combination.

4.3 Information ﬂow patterns

Does the diﬀerent page layout (due to the presence of KG)
alter the way users examine the search page? The typical
information ﬂow pattern is that users examine the search
page linearly from top to bottom (the driving hypothesis
behind the popular cascade models of user click behavior on
search)[6, 5]. A Markovian analysis of eye tracks shows the
following information ﬂow pattern for our study.

• 78% ﬁxations start at the Top (14% on mid, 5.9% on
KG and near zero elsewhere), followed by nearly equal
probability of switching from top results to KG or mid-
dle results.
• majority of incoming ﬁxations on KG come from the
• majority of outgoing ﬁxations from KG go to the top

top (81%;14% from mid, and 0.7% from bottom)

(78%; 12% to mid, 9.5% to left and 0.4% to bot)

We ﬁnd strong correlations between eye and mouse-derived
transition probabilities across AoIs (r2=0.73) and the start-
ing distribution (of ﬁrst AoI visited by eye and mouse; r2=0.82).
This suggests that users’ information ﬂow on the page may
be reasonably inferred from mouse tracks as well.

4.4 Sensitivity of eye-mouse to position and page

layout

Figure 4 shows a visualization of eye and mouse patterns
(superimposed) for 2 diﬀerent experimental conditions, one
containing KG (new page layout), and another without (tra-
ditional page layout containing one column of results). Eye
patterns shown in green, mouse in blue. Each eye/mouse
pause is denoted by a circle, whose size is proportional to
the duration of the pause. The bigger blue circles and the
smaller green circles show that the mouse pause durations
are longer (e.g., mouse may be parked idle for a few seconds)
compared to eye ﬁxation durations that are typically 200-
500ms. This ﬁgure shows clearly that the eye and mouse are
sensitive to page layouts and KG presence – in this example,
both show activity in the right hand side of the page when
KG is present, and no activity when KG is absent. Over all
users, the fraction of page time spent by the eye increases
from <1% when KG is absent to 13% when KG is present.

(a) Eye dwell time

(b) Mouse dwell time

Figure 5: Fraction of page dwell in areas of interest
is similar for eye and mouse

The mouse shows a similar increase, although to a smaller
extent (from 9%5 to 15%).

Figure 5 further demonstrates sensitivity to position by
quantifying the fraction of page dwell by eye (panel a) and
mouse (panel b) for diﬀerent positions on the search page
when KG is present. Both the eye and mouse show that
the top results dominate by receiving over 60% page dwell,
followed by middle results and KG, each receiving between
10-20% page dwell, followed by the bottom results (< 5%;
others are negligible).
4.5 Sensitivity of eye-mouse to relevance

Figure 6 shows how KG relevance aﬀects eye attention.
While both irrelevant and relevant KGs get around 1s of at-

5The baseline mouse activity when KG is absent is higher
than the corresponding eye activity as some users tend to
park their mouse in the whitespace corresponding to the KG
area, while scanning nearby result elements. Due to such
noise, the magnitude of attention measures may diﬀer be-
tween the eye and mouse, however, both the eye and mouse
show the same direction of trend – an increase in activity –
due to KG presence and relevance.

956Figure 3: Eﬀect of KG presence on eye gaze heatmaps. Red hotspots indicate where the user spent most
time looking. The left panel shows a heatmap of user eye gaze when KG is absent (the shape resembles a
Golden Triangle focused on top-left of the page). The right panel shows the corresponding heatmap when
KG is present. The search pages have the page areas of interest (AoIs) outlined, and regions outside AoIs
dimmed. For the actual result pages presented to users, the AoIs were not visually marked in this way. Note
the increased activity near KG, suggesting a potential second Golden Triangle focused on KG.

tention, there are signiﬁcant diﬀerences in other measures:
irrelevant KGs slow down the user by 3.5-4s on average (time
on page and time on task increase), while relevant KGs speed
up the user by around 4s on average (users spend 2-2.5s less
on each of the top and mid as the answer is found in KG).
Thus, relevant KGs get a higher fraction of page dwell (18%)
than irrelevant KGs (8%), and search terminates faster on
average after the user visits a relevant KG compared to an
irrelevant KG (0.9 vs 2.8s). Clearly, task relevance is an
important factor aﬀecting user attention and task perfor-
mance.

We tested whether mouse activity is sensitive to changes
in relevance. We observe similar trends as the eye, but to a
smaller extent. Like the eye, the mouse shows that relevant
KGs get a higher fraction of page dwell (17%) compared to
irrelevant KGs (12%), and search terminates faster on aver-
age after the user visits a relevant KG compared to an irrele-
vant KG (2.9 vs 6.4s). Figure 7a shows sample mouse tracks
when KG is relevant – in this example, the task is “when was
the sequel to Toy Story released?”, we ﬁnd that the user ﬁnds
the answer in KG, hence search terminates soon after user
visits KG. Figure 7b shows sample mouse tracks when KG
is irrelevant – in this example, the task is “ﬁnd more about
the Let’s Move program by Michelle Obama”, we ﬁnd that
the user visits KG, and continues searching on the rest of
the page 6. Thus, mouse activity, like eye gaze, is sensitive
to relevance.

6The ﬁgure shows two diﬀerent queries to illustrate more
examples of pages with KGs. However, for analysis, we used
the same set of queries to compare KG-relevant and KG-
irrelevant conditions.

5. PREDICTING EYE FROM MOUSE
Given the observed correlations between eye and mouse ac-
tivity in some measures, we are motivated to ask the follow-
ing questions:

• How well can we predict eye gaze from mouse activity?
• Can we achieve higher accuracy by predicting elements
of interest on the screen rather than estimating the
exact eye gaze coordinates?
• To what extent is the relationship between eye gaze
and mouse position user-speciﬁc and how far can we
generalize to unseen users?

To answer these questions we developed a set of regression
and classiﬁcation models to predict the exact coordinates
of the eye gaze and the element of interest on the page,
respectively. Before describing these models in detail we
need a formal deﬁnition of our learning problem: We divided
the set of eye-mouse readings into a set of points, where each
point di = (yi, ei, vi) represents the eye gaze coordinates yi,
a corresponding element of interest on the page ei, and a
covariate vector vi comprising of a set of mouse features. We
let Du = {du
nu} be the set of nu points pertaining
to user u, and we let D = {D1,··· , DU} be the set of all
data points across all U users.
5.1 Regression to predict the eye position

1 ,··· , du

As a ﬁrst step consider the problem of estimating the y-
coordinate of eye-gaze directly from mouse activity7. This

7Predicting the y coordinate of eye gaze is more interesting
than the x coordinate, as it can reveal which result element

957Figure 4: Examples of eye (green) and mouse (blue) tracks when KG is present (left) and absent (right)

φ(vi) comprises a nonlinear mapping, we obtain a nonlinear
function in the input covariate space.

To assess the impact of a personalized model we compare
the following three models: a global model that estimates
the parameter w common for all users. Secondly we infer
a user-speciﬁc model that provides an upper bound of how
accurately the model can estimate eye positions from mouse
activity. Finally, we infer a hybrid model that combines
global and user-speciﬁc components. This allows us to dis-
sociate both parts, thus allowing us to generalize to users
where only mouse movements are available while obtaining
a more speciﬁc model whenever eye tracking is possible. We
describe these three approaches below:

Figure 6: Eﬀect of KG relevance on eye. Consider
the left panel. The x axis shows the AoIs, and the
y axis shows, for each AoI, the diﬀerence in atten-
tion (in seconds) when KG is present and relevant
vs. when KG is absent (mean ± standard error).
Right panel shows the corresponding plot for irrel-
evant KG.

is a regression problem where we seek to ﬁnd a function
f : v → y such that the discrepancy between f (v) and the
observed eye position y is minimized.

In the following we use a (generalized) linear model to rep-
resent the mapping from attributes to eye positions. That
is, we seek to learn a regression function
f (v) = (cid:104)w, φ(vi)(cid:105)

Here f is parametrized by a weight vector w that we seek
to estimate. When φ(vi) = vi we end up with a linear
regression function in the input covariate space vi. When

the user is looking at. Thus we focus on y coordinate in this
paper.

Global model: In this setup we learn a global regression
function fg parametrized by a global weight vector wg.
The learning goal is to ﬁnd wg that minimize the av-
erage prediction error on the whole dataset. More for-
mally, our learning problem for the y-coordinate is:

(cid:88)

di∈D

minimize

wg

(cid:107)yi − (cid:104)wg, φ(vi)(cid:105)(cid:107)2

2 + λ(cid:107)wg(cid:107)2

2

where λ is a regularization parameter to prevent over-
ﬁtting. This model tests the hypothesis that eye-mouse
correlation is a global phenomenon and does not de-
pend on the speciﬁc user behaviour.

User-speciﬁc models: In this setup we learn regression
functions fu independently for each user u. The learn-
ing problem for the y-coordinate is:
i )(cid:105)(cid:107)2

i − (cid:104)wu, φ(vu

2 + λ(cid:107)wu(cid:107)2

(cid:88)

(cid:107)yu

2

minimize

wu

di∈D

This model tests the hypothesis that eye-mouse corre-
lation is NOT a global phenomenon and depends on
the speciﬁc user behaviour.

Hierarchical model: In this setup we still learn a per-
user regression model, however we decompose each
user-speciﬁc regression weight additively into a user-
dependent part wu and a global part wg. More for-

958Relevant KG

Irrelevant KG

Figure 7: Eﬀect of KG relevance on mouse. Search tends to terminate soon after visiting a relevant KG. For
irrelevant KGs the user visits the KG and then continues examining the rest of the page. See footnote 6.

mally, our learning problem for the y-coordinate is:
i )(cid:105)(cid:107)2

i − (cid:104)wu + wg, φ(vu

minimize

(cid:107)yu

2 +

wg ,wu1 ,...wU

(cid:88)
(cid:88)
(cid:34)(cid:88)

u∈U

i ∈Du
du
(cid:107)wu(cid:107)2

λ

u∈U

(cid:35)

2 + (cid:107)wg(cid:107)2

2

This model tests the hypothesis that eye-mouse corre-
lation has some global patterns shared across users, as
captured by wg, in addition to user-speciﬁc patterns,
as captured by the set wu weights.

5.2 Classiﬁcation for elements of interest

Instead of estimating the absolute position of eye gaze ex-
plicitly, one might want to settle for a slightly simpler task
— that of estimating which element of interest is being in-
spected by the user. For this purpose we divide the screen
into blocks of pixels that represent special elements on the
page (e.g., result element 1,2, etc.).
In our experiments,
each page is divided into a set of 11 diﬀerent elements (10
result elements, 1 KG)8. The prediction task here involves
predicting the particular element that the eye gaze is cur-
rently focused on using information from the mouse activity.
We treat this as a multi-label classiﬁcation problem. We use
the same terminology from Section 5.1. Our goal is to learn
a classiﬁcation function h(., w) : φ(vi) → L, where L is the
label space. In analogy to Section 5.1, we are interested in
the following three cases:

Global model: In this setup we learn a global classiﬁcation
function hg parametrized by a global weight vector wg.
The learning goal is to ﬁnd wg that minimize the mis-
classiﬁcation error on the whole dataset:

I(cid:2)ei (cid:54)= h(cid:0)φ(vi), wg

(cid:1)(cid:3) + λ(cid:107)wg(cid:107)2

2

(cid:88)

minimize

wg

di∈D

8Note that the 11 elements for classiﬁcation are diﬀerent and
more ﬁne-grained than the area-of-interest classes mentioned
in section 4.

where I is the indicator function, which is 1 iﬀ its
argument is evaluated to be true.

User-speciﬁc models: In this setup we learn classiﬁcation

function hu independently for each user u:

(cid:88)

I(cid:2)eu
i (cid:54)= h(cid:0)φ(vu

i ), wu

(cid:1)(cid:3) + λ(cid:107)wu(cid:107)2

2

minimize

wu

i ∈Du
du

Hierarchical models: in this setup we still learn a per-
user regression model, however we decompose each
user-speciﬁc regression weight additively into a user-
dependent part wu and a global part wg:

minimize
wg ,wu1 ,···wU

(cid:1)(cid:3)

i ), wg + wu

(cid:88)

(cid:88)
(cid:18)

u∈U

i ∈Du
du
(cid:107)wg(cid:107)2

2 +

+ λ

i (cid:54)= h(cid:0)φ(vu
I(cid:2)eu
(cid:19)
(cid:88)

(cid:107)wu(cid:107)2

2

u∈U

Note that for optimization purposes the indicator function
for correct labels is replaced by a diﬀerentiable loss function.
Alternatively, one may use a reduction to binary approach
and solve a sequence of associated cost-sensitive learning
problems [1].
5.3 Experimental setup

To be able to test our hypothesis we divided the data
into train and test as follows. We randomly sampled 30%
of the users and reserved them for test. Then for the re-
maining 70% users, we randomly sampled 70% of their data
points to construct the training data set and added the re-
maining 30% of their data points to the test set. By that,
our test set comprises two kind of users: 1) users unseen
during the training, and 2) users partially seen via some of
their data points in the training set. This allows us to test
the generalizability of our models and test our hypothesis
of whether or not mouse-eye correlation is user-speciﬁc or
user-independent. For all the experiments below, we report
accuracy on the whole test set and break it as well into ac-

959(a)

(b)

Figure 8: Examples of eye-mouse time course in the y direction. y axis shows the vertical position of eye
(green) and mouse (blue) (0 is page-top, and increasing values represent further down the page), and x
axis shows time in centiseconds (multiply by 10 to get time in milliseconds). The size of the blue blobs is
proportional to the duration of mouse pause at that position. In the example on the left, the mouse is initially
parked for around 20 seconds, while the eye examines the nearby elements carefully. The mouse then jumps
forward, and then on, correlates better with the eye (task was “Describe the Mozart programming system”).
The example on the right shows that the mouse follows eye gaze (with a lag) as the user looks up and down
the search page (task was “Describe the koala library for facebook”).

curacy on seen user and accuracy on unseen users. 9 We
perform prediction as follows based on the model:

Global models: We use the same weight vector wg on

both seen and unseen users.

User-speciﬁc models: If the user was seen before we use
his own speciﬁc weight wu. For this model, we do not
report results over unseen users.

Hierarchical models: If the user was seen before we use

wg + wu, otherwise we use wg.

We use the following information from mouse activity as
features in our prediction models for each time point t:

1. Time from page load (t)
2. Cursor Position (xt,yt)
3. Cursor Velocity: magnitude (vxt, vyt), and direction

(sxt, syt)

4. Cursor Distance moved (dxt, dyt)
5. Area-of-interest in which cursor lies (aoit)
6. Corresponding page element (elmt)

In addition to computing these features at time t, we con-
sider past and future values of features 2-4. e.g., we consider
the future cursor positions, average future velocities, total
cursor distance moved, and number of changes in mouse
movement direction for time windows [t, t + k] where k ∈
{1, 2, 4, 8, 16}; similarly for the past. This gives us a total of
83 features by the above phase space embedding.
5.4 Eye Prediction Results

Next, we show results from various prediction models on
diﬀerent corpora under the various task settings described

9For seen users, it is possible that adjacent data points from
the same user may end up being split across the train and
test datasets. However, all the methods compared here are
provided with identical train/test distributions and therefore
this does not introduce bias for any particular method. In
addition (as mentioned earlier), we also report results when
predicting on test data from completely unseen users that
do not overlap with the train dataset.

above. Following Huang et al. [15], we use a baseline model
which predicts that the eye gaze is focused exactly at the
mouse position. We use two feature map functions φ(v):
linear where φ(v) = v and nonlinear mapping using Nys-
trom approximation for Gaussian RBF kernels [24].
Denote by k(v, v(cid:48)) = exp(−γ (cid:107)v − v(cid:48)(cid:107)2) a Gaussian RBF
kernel as it is commonly used in kernel methods. Then this
kernel can be approximated by the following feature map:

(cid:69)

where

(cid:68) ˜φ(v), ˜φ(v

(cid:48)

)

˜k(v, v

(cid:48)

) =

˜φ(v) = K

− 1
nn [k(v1, v), . . . , k(vn, v)]

2

Here v1, . . . , vn are 1,000 random observations and Knn is
an n × n matrix obtained by forming the inner products
[Knn]ij = k(vi, vj). The advantage of the mapping ˜φ(v) is
that it can be used to learn a linear function in the trans-
formed feature space that is equivalent to learning a non-
linear function in the input space. That is, in both cases we
employ the VW package [19] to solve all the optimization
problems.

Results are shown in Table 1. We draw the following

conclusions:

• The observed mouse-eye correlation function is highly
nonlinear and that is why nonlinear models outper-
formed their linear counterparts especially in classiﬁ-
cation settings. For example, the best results achieved
on unseen users using nonlinear features is 62.3% pre-
diction error compared to 80.7% error for the linear
counterpart (which amounts to 23% reduction in clas-
siﬁcation error). This is a natural consequence of the
fact that we need to specify nonlinear boundaries in
order to distinguish between diﬀerent blocks in the re-
sult set. Here nonlinear basis functions are much more
advantageous.
• Our best model (nonlinear hierarchical) provides a 24.3%
improvement over the baseline (in RMSEy for pixel
space). In comparison, the best model from Huang et

960al[15] achieved an improvement of 10.4% over the same
baseline.10
• The observed mouse-eye correlation function is clearly
user-dependent because users exhibit diﬀerent patterns
while navigating the page (for example some users tend
to align the mouse with their gaze as their attention
shifts around the page, so called mouse readers). From
our results, it is clear that the user-speciﬁc models
overwhelmingly outperform all other models.
• While building a user-speciﬁc model is advised when-
ever abundant training data is available from individ-
ual users, it is not a scalable approach. We hypothe-
sized that hierarchical models would help in general-
izing eye-gaze prediction to unseen users. As evident
from our experiments using a simple additive hierar-
chical model, the results over unseen users slightly im-
proved compared to the global models. The reason
is that additive models separate user-speciﬁc patterns
(via the wu weight vector) from global patterns shared
across users (captured via the wg vector) which are
then used in predicting eye-gaze from mouse activity
over unseen users. We believe that this is a promising
direction and we plan to investigate further into using
more advanced transfer learning approaches for trans-
ferring eye-mouse patterns from seen users to unseen
users.
• Note that at a ﬁrst glance, the total classiﬁcation error
over seen and unseen users from our best model seems
rather high (nonlinear hierarchical, 60.3% error). How-
ever, this impression is misleading: ﬁrstly, it amounts
to a 14.8% reduction over its counterpart in the base-
line (70.8%), and the error reduction is bigger (28%)
for user-speciﬁc models on seen users. Secondly, the
current method of computing error penalizes adjacent
elements as much as far away page elements, leading
to high values of error (for example, predicting that
the user is looking at search result 1 while the ground
truth is that he is looking at search result 2 would
result in the same classiﬁcation error as between re-
sults 1 and 10). A cost sensitive loss function taking
the page layout into account could be used to address
this issue.
Indeed, we ﬁnd that the result elements
were mostly confused with adjacent result elements,
and KG was confused with the ﬁrst result element. If
we ignore errors due to adjacent elements on the page,
the total classiﬁer error drops dramatically from 60.3%
to 33.1% (nearly halved). For example, the error for
the ﬁrst result element drops from 23 to 12% (91% of
this error reduction was from ignoring result 1-2 con-
fusion), the error for the second element drops from 79
to 8% (97% error reduction was from ignoring result
2-1, 2-3 confusion), the error for KG drops from 60 to
12% (75% error reduction was from ignoring KG-result
1 confusion). To summarize, these results suggest that
the nonlinear hierarchical model can predict the result

10Huang et al. report results using a slightly diﬀerent set of
features which makes a direct comparison diﬃcult for this
particular study. However, we use the same baseline method
as theirs and although the feature sets may diﬀer, our global
linear model simulates their method. The results presented
in this paper indicate that our best approach clearly outper-
forms these methods and yields a signiﬁcant improvement in
prediction performance for diﬀerent test settings.

element that the user is looking at (with an error of
upto one element) at reasonably high accuracy (67%)
from mouse tracks only.

6. DISCUSSION

In this paper, we demonstrate through carefully designed
experiments in the lab that the mouse, like the eye, is sensi-
tive to two key attributes of page elements – their position
on the page, and their relevance to the user’s task. Using a
2x2 within subject design, we systematically varied the page
layout (2 column content layout – KG present on the top-
right of the page, vs.
linear 1 column content layout with
web results only and KG absent), and relevance (KG either
relevant or not to user task). Eye and mouse tracks were
recorded simultaneously as users performed the tasks. We
discuss the key ﬁndings and potential applications.
6.1 Mouse tracking aids layout analysis

Our analysis shows that the eye and mouse are strongly
correlated in some measures such as: 1) fraction of page time
spent within the area-of-interest, 2) last area-of-interest vis-
ited before user clicks/abandons, and 3) transition proba-
bilities between areas of interest. The ﬁrst measure is par-
ticularly interesting as it is sensitive to both the position
and relevance of an AoI: comparing diﬀerent experimental
conditions, we observe that like the eye, the fraction of page
time on KG as measured by the mouse, is higher when KG
is present vs. absent, and higher when KG is relevant vs.
irrelevant.
In addition, we ﬁnd that the page time after
the mouse visits KG is shorter when KG is relevant than
when it is irrelevant, suggesting that users terminate search
faster after visiting a relevant KG. Together, these mouse
measures can provide useful signals about user attention to,
and task relevance of, page elements even in the absence of
clicks. Potential applications of tracking these mouse mea-
sures at scale include ranking, search page optimization and
UI evaluation.

The second ﬁnding of strong eye-mouse correlations in
the last area-of-interest visited before click/abandonment is
consistent with Huang et al’s ﬁnding that eye and mouse are
strongly correlated at the time of click (user’s decision) than
at the beginning of the task (where users tend to explore the
page).

As search pages become increasingly complex (visually
and content-wise), understanding how users consume the
page, or how information ﬂows through the search page is
an important question that has applications for ranking and
improving user satisfaction (by providing the high quality
answers where they are most likely to look at). For ex-
ample, in linear page layouts containing a single column of
search results, the dominant ﬂow pattern is that users scan
the page from top to bottom. The corresponding eye gaze
heatmaps resemble a Golden triangle with more attention
being paid to the top-left of the page, and decreasing atten-
tion towards the right or bottom of the page. In contrast,
in the new page layout containing 2 columns (one column of
search results, and a second column with visually attractive
content on the top right of the page corresponding to the
Knowledge Graph results), we ﬁnd that while majority of
the users start by viewing the top search results, as a next
step, they are equally likely to see the KG on the right, or
middle results below. The corresponding eye gaze heatmaps
in Figure 3 have 2 Golden triangles, one focused at the top-

961RMSEy (pixels)
Seen users

Baseline
Linear

Model

mouse position
Global
Hierarchical
User-speciﬁc

Nonlinear Global

Hierarchical
User-speciﬁc

Total
270.1
218.2
216.5

–

211.7
204.5

–

276.9
217.0
215.1
193.8
210.0
201.3
179.7

unseen users Total
70.8
77.3
76.0

263.9
219.3
218.2

–

213.2
207.5

–

–

63.9
60.3

–

Classiﬁcation Error (%)

Seen users

unseen users

72.0
72.4
71.9
55.9
64.8
58.7
51.8

69.7
81.6
80.7

–

63.0
62.3

–

Table 1: Comparison of models for predicting eye gaze from mouse activity. Size of training data mtrain = 20788,
test data mtest = 19000 (comprised of 8899 points from previously seen users and 10101 points from new users).
Our best model (nonlinear hierarchical) provides a 24.3% improvement over the baseline (in pixel space) and
14.8% improvement in element space.

left of the search results, and a new triangle focused at the
top-left of the KG. Our ﬁnding of eye-mouse correlations
for the starting distribution (ﬁrst area-of-interest visited by
the eye and mouse), and transition probabilities between
pairs of area-of-interest suggests that we may reasonably in-
fer user information ﬂow on search pages by analyzing their
mouse tracks. This could be potentially useful as search
pages evolve to new UIs, layouts, and richer results, which
may not be parsed in a conventional linear manner.

There is also reasonable eye-mouse correlation on maxi-
mum y distance on the page, which reﬂects how far down
the page did the user visit (with their eye or mouse). This
could be useful in inferring which page folds were attended
by the user, and how far down the page they read.

6.2 On mouse tracking as a proxy for eye track-

ing

While mouse tracking is gaining in popularity, it remains a
poorly understood science. Future work will involve analyz-
ing mouse usage statistics, understanding how mouse usage
behavior varies as a function of users (intent, age, gender,
reading ﬂuency), page (UI, images, result quality) and de-
vice properties (e.g., trackpad vs. traditional mouse).

In particular, there exists a rich body of statistical liter-
ature to analyze models involving partially observed data,
such as Hidden Markov Models and Conditional Random
Fields. Analysis of users’ mouse activity (even in the ab-
sence of eye data) can provide information about prototyp-
ical mouse behaviors of users (e.g., parking, reading, skim-
ming). In turn, such information can help us estimate eye
positions more accurately in spite of the paucity of eye track-
ing data.

limitations of mouse tracking. Unlike eye gaze patterns,
there is wide variability in mouse behavior between and
within users. For example, some users read with their mouse,
which as Rodden et al. [22] note is a rare event. Other users
tend to park their mouse idle while scanning the page with
their eye. Some users tend to mark interesting results with
their mouse, others simply use their mouse for scrolling and
clicking. Given the wide variability and noise in mouse usage
behavior, inferring attention from mouse is a hard problem.
Further noise in mouse behavior may be introduced depend-
ing on the type of mouse device (e.g., a trackpad may involve
more scrolling and smooth mouse movements than a linear
mouse). Due to the above reasons, we need to rely on aggre-
gate statistics of mouse behavior over several users to infer

their attention on page. In contrast, eye tracks from a single
user can already reveal a lot about their attention on page.
This leads us to the conclusion that while mouse track-
ing can oﬀer valuable signals on user attention on areas-of-
interest or page elements at an aggregate level, it cannot yet
match the millisecond temporal and pixel-level spatial reso-
lution of eye tracking on a per user, per page level. Despite
this limitation, mouse tracking has much promise as it oﬀers
a scalable methodology to infer user attention on web pages,
especially when clicks are absent or few.

7. CONCLUSIONS

We demonstrate through carefully designed lab studies
that the mouse, like the eye, is sensitive to 2 key attributes
of page elements – their position on page, and their relevance
to the user’s task – both for linear one-column page layouts
and increasingly popular two-column page layouts. Despite
the noise in mouse activity due to wide variability in mouse
usage behavior within and between users, we ﬁnd strong
eye-mouse correlations in measures such as the fraction of
page time on result elements, and transition probabilities
between elements, suggesting that one may reasonably infer
user attention and information ﬂow over elements on the
search page, using mouse tracks. This is further validated by
the reasonably high accuracy (67%) in predicting the ﬁxated
result element from mouse activity (with an error of upto
one element). Potential applications include ranking, search
page optimization, and UI evaluation both in the presence,
and absence of clicks.

8. REFERENCES
[1] N. Abe, B. Zadrozny, and J. Langford. An iterative

method for multi-class cost-sensitive learning. In
KDD, pages 3–11, 2004.

[2] G. Buscher, E. Cutrell, and M. Morris. What do you

see when you’re surﬁng?: using eye tracking to predict
salient regions of web pages. In Proceedings of the 27th
international conference on Human factors in
computing systems, pages 21–30. ACM, 2009.

[3] G. Buscher, S. Dumais, and E. Cutrell. The good, the

bad, and the random: an eye-tracking study of ad
quality in web search. In Proceeding of the 33rd
international ACM SIGIR conference on Research and
development in information retrieval, pages 42–49.
ACM, 2010.

962[4] G. Buscher, R. W. White, S. Dumais, and J. Huang.
Large-scale analysis of individual and task diﬀerences
in search result page examination strategies. In
Proceedings of the ﬁfth ACM international conference
on Web search and data mining, WSDM ’12, pages
373–382, New York, NY, USA, 2012. ACM.

[5] O. Chapelle and Y. Zhang. A dynamic bayesian
network click model for web search ranking. In
Proceedings of the 18th international conference on
World wide web, pages 1–10. ACM, 2009.

[6] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An
experimental comparison of click position-bias models.
In Proceedings of the international conference on Web
search and web data mining, pages 87–94. ACM, 2008.

[7] E. Cutrell and Z. Guan. What are you looking for?:

an eye-tracking study of information usage in web
search. In Proceedings of the SIGCHI conference on
Human factors in computing systems, pages 407–416.
ACM, 2007.

information retrieval, SIGIR ’12, pages 195–204, New
York, NY, USA, 2012. ACM.

[17] J. Huang, R. W. White, and S. Dumais. No clicks, no
problem: using cursor movements to understand and
improve search. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems,
CHI ’11, pages 1225–1234, New York, NY, USA, 2011.
ACM.

[18] D. Lagun and E. Agichtein. Viewser: enabling

large-scale remote user studies of web search
examination and interaction. In Proceedings of the
34th international ACM SIGIR conference on
Research and development in Information Retrieval,
SIGIR ’11, pages 365–374, New York, NY, USA, 2011.
ACM.

[19] J. Langford, L. Li, and A. Strehl. Vowpal Wabbit,

2007.

[20] J. Nielsen and K. Pernice. Eyetracking web usability.

New Riders Pub, 2010.

[8] A. Duchowski. Eye tracking methodology: Theory and

[21] A. Olsen. Tobii i-vt ﬁxation ﬁlter - algorithm

practice, volume 373. Springer, 2007.

[9] L. Granka, T. Joachims, and G. Gay. Eye-tracking

analysis of user behavior in www search. In
Proceedings of the 27th annual international ACM
SIGIR conference on Research and development in
information retrieval, pages 478–479. ACM, 2004.

description white paper. 2012.

[22] K. Rodden, X. Fu, A. Aula, and I. Spiro. Eye-mouse
coordination patterns on web search results pages. In
CHI ’08 Extended Abstracts on Human Factors in
Computing Systems, CHI EA ’08, pages 2997–3002,
New York, NY, USA, 2008. ACM.

[10] Q. Guo and E. Agichtein. Exploring mouse movements

[23] D. Salvucci and J. Goldberg. Identifying ﬁxations and

saccades in eye-tracking protocols. In Proceedings of
the 2000 symposium on Eye tracking research &
applications, pages 71–78. ACM, 2000.

[24] A. J. Smola and B. Sch¨olkopf. Sparse greedy matrix
approximation for machine learning. In ICML, pages
911–918, 2000.

for inferring query intent. In Proceedings of the 31st
annual international ACM SIGIR conference on
Research and development in information retrieval,
SIGIR ’08, pages 707–708, New York, NY, USA, 2008.
ACM.

[11] Q. Guo and E. Agichtein. Ready to buy or just

browsing?: detecting web searcher goals from
interaction data. In Proceedings of the 33rd
international ACM SIGIR conference on Research and
development in information retrieval, SIGIR ’10, pages
130–137, New York, NY, USA, 2010. ACM.

[12] Q. Guo and E. Agichtein. Towards predicting web

searcher gaze position from mouse movements. In CHI
’10 Extended Abstracts on Human Factors in
Computing Systems, CHI EA ’10, pages 3601–3606,
New York, NY, USA, 2010. ACM.

[13] Q. Guo and E. Agichtein. Beyond dwell time:

estimating document relevance from cursor movements
and other post-click searcher behavior. In Proceedings
of the 21st international conference on World Wide
Web, WWW ’12, pages 569–578, New York, NY, USA,
2012. ACM.

[14] G. Hotchkiss, S. Alston, and G. Edwards. Eye

tracking study. Research white paper, Enquiro Search
Solutions Inc, 2005.

[15] J. Huang, R. White, and G. Buscher. User see, user
point: gaze and cursor alignment in web search. In
Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems, CHI ’12, pages
1341–1350, New York, NY, USA, 2012. ACM.

[16] J. Huang, R. W. White, G. Buscher, and K. Wang.

Improving searcher models using mouse cursor
activity. In Proceedings of the 35th international ACM
SIGIR conference on Research and development in

963