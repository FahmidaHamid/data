LiveClassi(cid:2)er: Creating Hierarchical Text Classi(cid:2)ers

through Web Corpora

Chienâ€ºChung Huang
Institute of Information

Science

Academia Sinica
Taipei, Taiwan

Shuiâ€ºLung Chuang
Institute of Information

Science

Academia Sinica
Taipei, Taiwan

Leeâ€ºFeng Chien (cid:3)
Institute of Information

Science

Academia Sinica
Taipei, Taiwan

villars@iis.sinica.edu.tw

slchuang@iis.sinica.edu.tw

lfchien@iis.sinica.edu.tw

ABSTRACT
Many Web information services utilize techniques of information
extraction (IE) to collect important facts from the Web. To cre-
ate more advanced services, one possible method is to discover
thematic information from the collected facts through text classi-
(cid:2)cation. However, most conventional text classi(cid:2)cation techniques
rely on manual-labelled corpora and are thus ill-suited to cooperate
with Web information services with open domains. In this work,
we present a system named LiveClassi(cid:2)er that can automatically
train classi(cid:2)ers through Web corpora based on user-de(cid:2)ned topic
hierarchies. Due to its (cid:3)exibility and convenience, LiveClassi(cid:2)er
can be easily adapted for various purposes. New Web information
services can be created to fully exploit it; human users can use it
to create classi(cid:2)ers for their personal applications. The effective-
ness of classi(cid:2)ers created by LiveClassi(cid:2)er is well supported by
empirical evidence.

Categories and Subject Descriptors
H.3 [Information Storage and Retrieval]: Miscellaneous

General Terms
Algorithms, Experimentation, Performance

Keywords
Text Classi(cid:2)cation, Web Mining, Topic Hierarchy

1.

INTRODUCTION

Although the (cid:2)eld of Web information extraction (IE) has made
much progress in recent years [7, 6, 12, 22], most of the time
the information extracted is simply used to populate the databases
without any re(cid:2)ning step. If this extracted information can be pro-
cessed and more information can be discovered from it, undoubt-
edly, many new advanced information services would become pos-
sible. For example, suppose there is a Web information service
that helps users collect publication lists of researchers in a certain
area; and suppose further that there are some mechanisms to decide
the researchersâ€™ specialized (cid:2)elds based on their publication lists,
such mechanisms would be highly valuable from the perspective of
(cid:3)Lee-Feng Chien also works in Department of Information Man-
agement, National Taiwan University, Taiwan
Copyright is held by the author/owner(s).
WWW2004, May 17(cid:150)22, 2004, New York, New York, USA.
ACM 1â€º58113â€º844â€ºX/04/0005.

both commercial interests and academic inquisition. In brief, dis-
covering information hidden in the extracted information, e.g., the
information at thematic level, would open up possibilities of creat-
ing new Web applications and help researchers to conduct deeper
analysis.

Generating thematic information can be realized through text
classi(cid:2)cation (cid:150) a subject having been extensively studied for years
[21]. In the above example, one can classify the publication lists
into a set of classes representing various (cid:2)elds in computer sci-
ence, thus determining the interests of researchers. However, most
text classi(cid:2)cation techniques assume manually-labelled corpora are
handy and can be used for training (cid:150) an assumption sometimes not
quite realistic in practical experience. For one thing, labelling the
corpus is laborious and needs the assistance of professional index-
ers, and possibly suffers from the problem of subjectivity; for an-
other, the acquisition of corpora is often a non-trivial matter. There-
fore, these techniques relying on hand-labelled corpora to create
thematic metadata are ill-suited to cooperate with Web information
services.

If, on the other hand, there exists a system that can automatically
acquire necessary training corpora based on user-de(cid:2)ned topic hi-
erarchies and train the classes effectively, positively such a system
can be easily adapted to cooperate with Web information services.
Moreover, it also would give great facility to human users.

The above consideration motivates us to design a system named
LiveClassi(cid:2)er that requires limited human involvement in creating
hierarchical text classi(cid:2)ers. LiveClassi(cid:2)er was developed under the
assumption there does not exist any manually-assigned corpus, or
even if it exists, the amount is inadequate. Consider that the Web
offers inexhaustible data source for almost all subjects, the system
was designed to fully exploit the richness of Web resources. The
main features of LiveClassi(cid:2)er are: (1) using Web search-result
pages as the corpus source; (2) exploiting the structural information
inherent in the topic hierarchy to train the classi(cid:2)er; and (3) creating
key terms to amend the insuf(cid:2)ciency of the topic hierarchy. We here
sketch the key idea of LiveClassi(cid:2)er brie(cid:3)y.

Given a topic hierarchy, an intuitive idea would be to acquire
topic-related corpora from the Web to be the substitutes of manual-
labelled corpora. However, considering the heterogeneity of Web
corpus, much noises must be contained in these downloaded doc-
uments. Thankfully, there are more suitable tools to realize this
idea(cid:151)Web search engines. One may send the names of the classes
as queries to search engines and use the returned search-results
pages as the corpus. However, even so, the retrieved search-results
still may contain noises unavoidably. Our idea is that we can formu-

184late more precise queries and organize the corpus more effectively
by the concept of the classes.

The main merits of LiveClassi(cid:2)er are its wide adaptability and its
(cid:3)exibility. The needed classi(cid:2)er can be created by simply de(cid:2)ning
a topic hierarchy. Aside from generating more thematic informa-
tion for Web information service, LiveClassi(cid:2)er also gives much
convenience to human users.

The rest of the paper is structured as follows. LiveClassi(cid:2)er,
along with the approach it is based on, is presented in Section 2,
experiments are presented Section 3, the related work in Section 4,
and conclusions are drawn in Section 5.

2. LIVECLASSIFIER

In Section 2.1, we give an overview of the components of Live-
Classi(cid:2)er. A more detailed analysis of each component is presented
respectively in Sections 2.2, 2.3 and 2.4.
2.1 Overview of the System

We (cid:2)rst de(cid:2)ne the problem LiveClassi(cid:2)er is supposed to deal

with and then discuss the technical details.

Given a set of classes, C = fc1; c2:::; cng, a collection of text
objects, T O = fto1; to2:::; tomg, and also a mapping (cid:14) : T O !
2C that describes the correct classes a text object is supposed to
be classi(cid:2)ed to. LiveClassi(cid:2)er aims at (cid:2)nding a one-to-one map-
ping scheme (cid:24) : T O ! 2C such that the size of correct result set
CRS = ftoijtoi 2 T O; (cid:24)(toi) = (cid:14)(toi)g is maximal.

The architecture of the system is illustrated in Figure 1. Live-
Classi(cid:2)er was designed to interact with both human users and Web
applications. The input of LiveClassi(cid:2)er includes topic hierarchies
and texts that need to be classi(cid:2)ed, the former for the training phase
and the latter for the testing phase. We summarize each component
of the system.

(cid:15) Feature Extractor: this component interacts with search en-
gines and extracts highly-ranked search snippets as effective
feature sources. It outputs feature vectors to describe both
the topic classes and the text objects.

(cid:15) HCQF Classi(cid:2)er Generator: HCQF is the acronym of Hier-
Concept-Query-Formulation, a technique we developed to
train statistical models for topic classes. As its name sug-
gests, it emphasizes on using the concepts embedded in topic
hierarchies to train the classi(cid:2)ers. This component interacts
with the Feature Extractor to organize the class models. It
outputs class models to be operated upon by Text Classi(cid:2)er.
(cid:15) Text Classi(cid:2)er: Using trained classes output by HCQF clas-
si(cid:2)er generator, this component determines proper classes
for texts of concern.

2.2 Feature Extractor

To decide the similarity between a text object and a target class,
we need a representation model to describe them. In the case of full
articles or short documents, we can directly use its content words
as its feature source. However, if the text object of concern is a text
segment, such as a user query, a named entity, and a topic term and
so on, the problem is slightly complicated. In the former case, the
text object itself affords abundant feature terms, as it contains tens
to thousands of words, while in the later case, the few words com-
posing the text segment are obviously insuf(cid:2)cient. To overcome
this problem, we send the text segment as a query to search engines
and use the returned pages as its feature source. Note also that we
use only the snippets as the source, instead of the whole Web pages,
so as to reduce the number of page accesses.

hi

!g@BA,A

Td5,e&

*fg.

:

T-

(,U





 "!

VXW
Y[Z\^]_a``"W>bWZc

@BA
A

CEDFHG
JK
K
DI
NQ	NO
=>
?

JR

NO
SO
5,'

9;:,<,








5,'

=>
?

 

	






56

(3
7&

4"
+,

)*,+,-

*

/102

Figure 1: A diagram presenting the architecture of LiveClassi(cid:2)er.

When we train the classi(cid:2)ers in Section 2.3, a similar process is
repeated: sending the boolean expression of class names to search
engines and using the returned pages as the training corpus. Con-
sidering the heterogenous nature of the Web, one may doubt whether
it is a sound strategy to use the Web resources as the feature source.
However, thanks to the recent advances in search technology, we
think that, to a certain degree, the highly-ranked returned pages
contain quite relevant information and can be treated as an approx-
imate description of the text segment or the topic class. We shall
compare the performance of using supervised (hand-labelled) cor-
pus and that of unsupervised corpus composed of search-results in
Section 3.

We adopt the vector-space model to describe the features for both
text objects and topic classes. Speci(cid:2)cally, as we shall present in
Section 2.3, HCQF Classi(cid:2)er Generator outputs a set of class ob-
jects for each separate topic class; both these class objects and text
objects are to be converted into vectors to estimate the similarity
between them.

To (cid:2)nd enough features for text segments and to acquire the
training corpora for classes, we formulate queries based on the the
text segments or some boolean expression of class names. Suppose
that, for each query q, we collect up to Nmax search-result snip-
pets, denoted as SRSq. Each SRSq can then be converted into
a bag of feature terms by applying normal text processing tech-
niques, e.g., removing stop words and low-frequency words, to the
contents of SRSq. Let T be the feature term vocabulary, and let
ti be the i-th term in T . With simple processing, a query q can be
represented as a term vector vq in a jT j-dimensional space, where
vq;i is the weight ti in vq. The term weights in this work are de-
termined according to one of the conventional tf-idf term weighting
schemes [19], in which each term weight vq;i is de(cid:2)ned as

vq;i = (1 + log2 fq;i) (cid:2) log2(n=ni);

where fq;i is the frequency ti occurring in vqâ€™s corresponding fea-
ture term bag, n is the total number of class objects, and ni is the
number of class objects that contain ti in their corresponding bags

185






#

$

%

&
'
$
(
.
%

&
'
$
.

.
8
6
&
.
.
6
.
&


$

:
'
'
:
A
'
-
&


8
6
&
.
.
L
M
L
P
A
-
$

'
&
'
$
&


$

:
'

'
6
-
$
&

-
:
*
of feature terms. The similarity between a text segment and a class
object is computed as the cosine of the angle between the corre-
sponding vectors, i.e.,

sim(va; vb) = cos(va; vb):

If, instead of a text segment, the text object is a full article or a
short document, its content words are directly treated as SRSq and
the similar processing technique and weighting scheme is operated
upon it. We omit the repetitions.

2.3 HCQF Classi(cid:2)er Generator

For the sake of clarity, we present the technique Hier-Concept-
Query-Formulation (HCQF) in a step-by-step manner. A topic hi-
erarchy T H = (C; R) consists of two parts: a set of topic classes
C = fc1; c2:::; cng and a set of relations R = fr1; r2:::; rmg,
relating them hierarchically so that super classes conceptually sub-
sume sub classes. A topic class, whose name is an assigned key-
word, essentially represents an abstract concept and the concept is
usually embodied by a pre-arranged training set that describes its
characteristics. For each ci, if disregarding its relative position in
T H, we can send the name of ci to search engines and use the re-
turned snippets as its training set. We refer to a concept described
by such a training set as general concept G(ci) of ci ; however, in
our case, we think this kind of general concept is not the concept
that ci is really meant to represent. The reason is that a general
concept does not fully re(cid:3)ect the structural information inherent in
the topic hierarchy T H.

To remedy this problem, therefore, we de(cid:2)ne speci(cid:2)c concept
S(ci) that we think is really the concept ci represents in the context
of a hierarchy. Our idea can be illustrated by an example: suppose
Y department is a sub class of X university in some topic hierarchy
T H, G(Y ) only expresses Y but fails to indicate that Y department
is a child class of X university. Instead, the concept that Y really
represents in T H is not only about Y but also the fact that Y is a
child of X. Put another way, suppose we wish to train the class (cid:147)CS
department,(cid:148) a subclass of (cid:147)Stanford,(cid:148) most snippets gotten from
the query (cid:147)CS department(cid:148) positively contain information about
(cid:147)CS department,(cid:148) however, many of them are possibly about (cid:147)CS
department(cid:148) of some universities other than (cid:147)Stanford(cid:148). Such a
training set apparently isnâ€™t a precise description of the class we
wish to train.

Back to the (cid:2)rst example, in our research, Y â€™s speci(cid:2)c con-
cept S(Y ) should be the result of Y â€™s general concept G(Y ) con-
strained by its parent X. Following this line of reasoning, not only
X, but also all of Y â€™s ancestors should exert some in(cid:3)uence on
Y â€™s general concept. Naturally, one is led to think of the converse.
Descendant classes should also exert a reciprocal in(cid:3)uence on an-
cestor classes, i.e. descendant classes should enrich the concept of
ancestor classes so as to give a more precise description for them.
Suppose X university has three departments, Y , Y 0, and Y 00, the
concept that X represents is not only about X itself but also the fact
it is the parent of Y ,Y 0 and Y 00. As above, all descendent classes
should enrich the concept of X. Thus, to summarize, for each ci,
the content of a speci(cid:2)c concept is determined by the combination
of three factors: its ancestors, its decedents, and its own general
concept.

We now formally de(cid:2)ne what a speci(cid:2)c concept is. Given some
class c(cid:11), whose ancestors are Ac(cid:11) and whose descendants are Dc(cid:11),
its speci(cid:2)c concept, S(c(cid:11)), is the union of two separate parts: spe-
ci(cid:2)c ancestral concept, SA(c(cid:11)) and speci(cid:2)c descendant concept,
SD(c(cid:11)), the former being its general concept constrained by its
ancestors, while the latter being the uni(cid:2)cation of the speci(cid:2)c an-

cestral concepts of all its descendants 1:

SA(c(cid:11)) = G(c(cid:11)) \ fG(ai)jai 2 Ac(cid:11) g;

SD(c(cid:11)) = [fSA(dj)jdj 2 Dc(cid:11) g;

S(c(cid:11)) = SA(c(cid:11)) [ SD(c(cid:11)):

The task of preparing the training set to express SA(c(cid:11)) seems
dif(cid:2)cult, but fortunately real-world search engines relieve us much
of the trouble. One may send the query as a boolean expression c(cid:11)
and the name of its ancestors Ac(cid:11) to search engines and use the re-
turned snippets as the required training set for SA(c(cid:11)). Conversely,
when preparing the training set to express SD(c(cid:11)), one simply adds
up all the training sets for speci(cid:2)c ancestral concept of Dc(cid:11).

In more practical terms, the total training set of class c(cid:11) is then
composed of the training set (Nmax snippets) for SA(c(cid:11)) and the
training sets (Nmax (cid:3) jDc(cid:11) j) for SD(c(cid:11)). Note that each Nmax
snippets can be then converted to a class object according to the
vector space model discussed in Section 3.1. Therefore, c(cid:11) is then
presented as an array of class objects, one of them is from SA(c(cid:11))
while others are from SD(c(cid:11)).

The strength of HCQF lies exactly in this kind of rich training
set. For c(cid:11), its concept is not only speci(cid:2)ed by its ancestors and
itself, but also by all its descendants. Suppose we only consider
SA(c(cid:11)) but drop SD(c(cid:11)), we have merely Nmax snippets to train
ci; on the other hand, if we take SD(c(cid:11)) into consideration, we
may have a dramatic (1 + jDc(cid:11) j) (cid:3) Nmax snippets to train c(cid:11).
(Note that since we convert the training sets into class objects, the
above expression can be better restated as the comparison between
1 and 1 + jDc(cid:11) j objects.) Moreover, the additional jDc(cid:11) j (cid:3) Nmax
snippets ( or jDc(cid:11) j objects) donâ€™t contain as much noise as one
might expect, because they are already constrained by c(cid:11) along
with its ancestors beforehand.

It can easily be seen that one may train all the classes in T H
by traversing it by the manner of BFS twice. For each ci, the (cid:2)rst
round collects the training set for SA(ci), while the second round
adds up the training sets for SD(ci) and S(ci). Having collected
all the necessary training sets, by using the collection of the terms
in all training sets as the total feature vocabulary T , these training
sets can be converted into class objects.

So far, we have presented the overall idea of HCQF and it can
be observed that it mainly concerns about how to formulate pre-
cise queries and organize the corpus. We now are left with two
more problems. First, the leaf class cleaf , unlike internal classes,
cannot be strengthened by its descendent classes. In other words,
Sd(cleaf ) = (cid:28) and HCQF seems have a weaker descriptive power
for them. Second, suppose we are given only a non-hierarchical
tree, i.e. a (cid:3)at structure, can HCQF be generalized so as to be
applied to it too?

The answer to two above questions lies in the fact that one can
always (cid:2)nd some classes to enrich a leaf class by inserting them
as (cid:147)pseudo(cid:148) children classes. Given some leaf class cleaf , when
collecting the snippets to organize Sa(cleaf ), one can easily (cid:2)nd
some associated terms of cleaf and use some (cid:2)ltering mechanisms
to choose proper terms as child classes of cleaf
1We use the set operations to express our idea, and their meaning
will be made clear in the following discussion. Strictly speaking,
the notation we use here is not mathematically rigorous. The (cid:147)con-
cept,(cid:148) actually, isnâ€™t composed of distinct entities as a mathematical
set is.
2It is not necessary that one always (cid:2)nds the associated terms from
the Web-retrieved snippets. If the leaf class has some local training
document set, one can also extract associated terms from it.

2.

186the collection of

feature vector of of class ob-

HCQF(T H = (C; R))
C: the set of topic classes
R: relations among topic classes
SRS: the collection of training sets (search result snippets) (ini-
tially (cid:28))
CO:
jects
1: for all c 2 C, according to R, choose c by BFS do
2:
SRSc   send c [ cancestors to search engines
if c= leaf then
3:
4:
5:
6:
7: for all c 2 C, according to R, choose c by BFS do
8:
9:
10: for all srs 2 SRS do ftransform SRS into a feature vector

ATc   Associated Terms by Subsumption(c, SRSc)
for all at 2 ATc do

SRSc   SRSc [ SRScdescendents
SRS   SRS [ SRSc

SRSc   SRSc[ send (c [ at) to search engines

according to Section 3.1g

co   transform srs
CO   CO [ co

11:
12:
13: return CO

Associated Terms by Subsumption(c, SRSc)
c: topic class
SRSc: training set of c
AT : the set of associated terms (initially (cid:28))

if p(cjt) (cid:21) 0:8 and p(tjc) < 1 then

14: for all t 2 SRSc do
15:
16:
17: return AT

AT   AT [ t

Associated Terms by Co-occurrence(c, SRSc)
c: topic class
SRSc: training set of c
AT : the set of associated terms (initially (cid:28))

if DF (t; c)=DF (C) > " then fDF value can be gotten
from search enginesg

18: for all t 2 SRSc do
19:

20:
21: return AT

AT   AT [ t

Figure 2: An algorithmic procedure describing HCQF. Note that
Line 4 can be replaced by Associate Term by Co-occurrence(c, SRSc).

In our experiments, we have employed the following two tech-
niques to create the (cid:147)pseudo(cid:148) child classes. We choose either (1)
the terms subsumed by cleaf [20]; or (2) the terms having the high-
est mutual information with cleaf .

leaf is subsumed by cleaf , the documents that cd

The (cid:2)rst technique is based on the assumption that, suppose a
term cd
leaf appears
always (or almost always) contain cleaf , while the documents con-
taining cleaf do not necessarily contain cd
leaf . The formula is set
as follows:

P (cleaf jcd

leaf ) (cid:21) (cid:18);

P (cd

leaf jcleaf ) < 1:

[20] set (cid:18) to 0.8. However, in our experience, a slightly better

result can be acquired by setting (cid:18) to 0.85 for Web documents.

The second technique is based on the assumption that the con-
cept of cleaf can be enriched by its most relevant terms too. We
choose the terms that appear with cleaf above a certain threshold
of times. We denote the document frequency of some term t as
DF (t) and that of the co-occurrence of s and t as DF (t; s), then
our idea can be expressed as

DF (t; cleaf )
DF (cleaf )

> (cid:15)

Based on heuristics, we set (cid:15) to 0.45 in this work. The whole

algorithmic procedure of HCQF is presented in Figure 2.

TextClasssi(cid:2)er(to; C; CO; n)
to: the unknown text object
C: the set of classes
CO: the set of class objects returned by HCQF
n: the number of target categories

1: for all co 2 CO do
2:
3: Rk(to)   the k class objects co 2 CO with highest r(to; co)

r(to; co)   sim(vto; vco)

scores

rkN N (to; c)   0

4: for all c 2 C do
5:
6: for all co 2 Rk(to) do
7:

for all c is a class of co do fa class object co may enrich
multiple ancestor classesg

8:
9: return top-ranked n classes in C according to the decreasing

rkN N (to; c)   rkN N (to; c) + r(to; co)

order of rkN N (to; c)

Figure 3: An algorithmic procedure describing the text classi(cid:2)cation
process.

2.4 Text Classi(cid:2)er

Given a new candidate text object to, Text classi(cid:2)er determines

a set of classes that are considered as toâ€™s most relevant classes.

As discussed in Section 2.2, the candidate text object to is rep-
resented as a feature vector vto. For the classi(cid:2)cation task, we here
adopt a kNN approach.

kNN has been an effective classi(cid:2)cation approach to a broad
range of pattern recognition and text classi(cid:2)cation problems [9].
By kNN approach, a relevance score between text object to and
candidate class Ci is determined by the following formula:

rkN N (to; Ci) = X

sim(vto; vj)

vj 2Rk(to)\Ci

where Rk(to) are toâ€™s k most-similar class objects, measured by
sim function, which is the cosine angle between the two vectors,
in the whole collection. Figure 3 shows the algorithmic procedure
of this classi(cid:2)cation process.

The classes that a text object is to be assigned to are determined
by either a prede(cid:2)ned number of most-relevant clusters or a thresh-
old to pick those clusters with scores higher than the speci(cid:2)ed
threshold value. Different threshold strategies have both advan-
tages and disadvantages [26]. In this study, to evaluate the perfor-
mance, we select the (cid:2)ve most relevant classes as candidates.

3. EXPERIMENTS

Having described the overall idea of LiveClassi(cid:2)er, we now try
to justify it by empirical evidence. In designing the experiments,
we not only assessed the accuracy of LiveClassi(cid:2)e, but also ex-
plored possible applications that could be derived from it.

Throughout the experiments, we use Yahoo!â€™s topic hierarchy as
the testing bed. k is set to 5. The search engine employed was
Google.

To better evaluate how LiveClassi(cid:2)er performs when the length
of the test text object varies, we divided them into three groups:
text segments, short documents and full articles. Text segments
were directory names of lower levels classes. For example, in the
following Computer Science experiment, the directory names (cid:147)In-
telligent Software Agent(cid:148) and (cid:147)Fuzzy Logic(cid:148) could be taken as text
segments of concern and were supposed to be classi(cid:2)ed into the
higher level class (cid:147)Arti(cid:2)cial Intelligence(cid:148). For each directory in
Yahoo!, there was a list of Web sites accompanied by site descrip-
tion offered by Yahoo!â€™s indexers. We used the Web pages of the

187Table 1: Top 1-5 inclusion rates of classifying text objects into second level classes of CS-tree from Yahoo! under various circum-
stances.
Topic Hierarchy Used +
Corpora Source
Manual Hierarchy + Un-
supervised Web Corpora

Based on only second level classes (Approach 1)

Full Article

Text Type

Approach

Top-1

.3389

.3785

.6045

.6214

.6779

2

3

4

5

Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article

.8034
.6943
.7288
. 9326
.9272
.6384

.8146
.7242
.7458
.9326
.9371
.7005

.8483
.7545
.7514
.9606
.9636
.7231

Based on (cid:2)rst three level classes (Approach 2)

Augmented Hierarchy +
Unsupervised Web Cor-
pora

Based on pseudo classes generated by subsumption tech-
nique plus classes at the (cid:2)rst two levels (Approach 3)

Based on pseudo classes generated by co-occurrence
technique plus classes at (cid:2)rst two levels (Approach 4)

Not Using Topic Hierar-
chy + Supervised Corpora

Using the short documents of Yahoo! (Approach 5)

.5780
.4917
.5367
.7837
.7384
.3785

.7008
.6346
.6780
.8932
.8775
.5254

Short Document
Text Segment
Full Article

Short Document
Text Segment
Full Article

Short Document
Text Segment

.6753
.6060
.4067

.7050
.6424
.3785

.6142
.6912

.8432
.7252
.6045

.8034
.7417
.5706

.6751
.8039

.8432
.8146
.7062

.8764
.8245
.6497

.7005
.8671

.8932
.8411
.7457

.8932
.8510
.7006

.7100
.9003

.8932
.8510
.7740

.8932
.8609
.7288

.7259
.9202

sites as full articles 3 and the description of the sites as short docu-
ments.
3.1 The Overall Performance of LiveClassi(cid:2)er
We (cid:2)rst focused on how well LiveClassi(cid:2)er performs when deal-
ing with text objects of different lengths. We chose a speci(cid:2)c do-
main, computer science in Yahoo! Computer Science topic hierar-
chy to conduct this experiment. There were totally 36 second-level,
177 third-level, and 278 fourth-level classes, all rooted at the class
(cid:147)Computer Science(cid:148). We used the second-level classes, e.g., (cid:147)Arti-
(cid:2)cial Intelligence(cid:148) and (cid:147)Linguistics(cid:148) as the target classes and tried
to classify text objects into them.

For text segments, the 278 fourth-level classes were used as test
instances. Also, we chose randomly 177 full articles and their cor-
responding short documents from the fourth-level classes.

In general, we were interested in the following questions and

designate them respectively as Approaches 1-5:

1. Suppose we use only the restricted version of HCQF, i.e.
dropping SD(C) and only using SA(C), remove the root and
the third-level classes, and donâ€™t consider generating pseudo
classes, how well does HCQF do? This is equivalent to using
only a (cid:3)at structure and can be thought of as the bottom-line.
(Approach 1)

2. Suppose we take both SD(C) and SA(C) into consideration
but still donâ€™t generate pseudo classes automatically, how
well does HCQF do? (Approach 2)

3. Suppose we are not given third-level classes, how well does
HCQF do if it generates pseudo classes automatically by the
subsumption technique? (Approach 3)

4. The same situation as (3), but now HCQF generates pseudo

classes by the co-occurrence technique. (Approach 4)

5. Instead of using HCQF, the short documents of Level 2 and
Level 3 classes are used as training corpora, how well do the
classi(cid:2)ers perform? (Approach 5)

3Note that we treated the Web pages in their simplest form, i.e.
only their full content without considering any tag information.

Note that in Approaches 3 and 4, for each target class, we de-
liberately made the number of its pseudo child classes the same
with Approach 2 so as to evaluate the performance of HCQF in the
context of a manually-constructed hierarchy and an automatically-
augmented hierarchy.

Table 1 shows the result of the achieved top 1-5 inclusion rates,
the top n inclusion rate is the rate of test objects whose highly
ranked n candidate classes contain the correct class. From this
table, it can be observed that Approach 2 surpassed all other ap-
proaches. This is a hint that a well-organized topic hierarchy greatly
contributes to the high performance of HCQF. Approaches 3 and
4 also got promising results, though not as good as Approach 2.
This indicates that both subsumption technique and co-occurrence
technique could get proper pseudo classes; HCQF does not neces-
sarily rely on user-de(cid:2)ned topic hierarchies; to a certain degree, the
manual-de(cid:2)ned topic hierarchies can be approximated by HCQFâ€™s
automatic mechanisms. The worst was Approach 1, a simple (cid:3)at
structure. However, it deserves attention that, though it fell far
behind other approaches, considering that there were totally 36
classes, its overall performance was still acceptable. This not only
revealed the superiority of Web resources but also implicitly sug-
gested that, to train a classi(cid:2)er, a simple but effective method is to
simply designate a set of distinct class names.

A very interesting observation can be made about Approach 5.
Using Yahoo!â€™s short documents as the training corpora also got de-
cent results, second only to Approach 2 but superior to Approaches 3
and 4. Unlike the previous four Approaches using unsupervised
training corpora downloaded from Search engines, Approach 5 can
be deemed as using supervised hand-labelled training corpora. If
unsupervised training corpora could get comparable (Approaches 3
and 4) or even better result (Approach 2) than supervised train-
ing corpora, it implies that a topic-hierarchy composed of key-
words speci(cid:2)ed by indexers or librarians seems enough to create
the needed classi(cid:2)ers, rather than manually labelling a lot of cor-
pus.

Concerning the text type axis, it can be observed that the three
types all got satisfactory results. In general, the classi(cid:2)er we trained
could categorize text segments and short documents with promis-
ing accuracy. This con(cid:2)rmed our conjecture that Web search-result

188snippets were a proper description of the text segments and could
be used as the feature source.

Compared to short documents and text segments, the full article
experiment didnâ€™t get as good results, though the results were still
promising. The probable reason of this performance degradation
was that the content of the test Web pages was too diverse so that
they sometimes were not conceptually closely related to the target
class.
3.2 Granularity and Diversity

Having observed how HCQF performed in a speci(cid:2)c area: Com-
puter Science, we then tried to examine whether HCQF could be
applied to a topic-hierarchy of more diverse domains and of deeper
depth. We extracted parts of of Yahoo!â€™s directory about (cid:147)Science(cid:148)
and (cid:147)Social Science(cid:148) of 5 level deep. There were totally 84 text
segments and 139 short documents and their corresponding full ar-
ticles in Level 5.

Table 2: The information of Science and Social Science hierar-
chies extracted from Yahoo!â€™s directory.

Level 2
Science

Social
Science

Level 3
Mathematics
Chemistry

Astronomy
History

Sociology

Linguistics and Hu-
man Languages

Level 4
Geometry, Number Theory
Chemist, Chemical and Bio-
logical Weapons
Solar System, Cosmology
Historiology, Genealogy

Social Class and Strati(cid:2)cation,
Urban Studies
Translation and Interpretation,
Word and Wordplay

Unlike the preceding experiment, we tried to classify the various
text objects of Level 5 into Levels 2, 3, and 4 respectively. Clas-
sifying text objects into different levels of the topic hierarchy has a
consequential implication: it means whether HCQF can create the-
matic information of different degrees of re(cid:2)nement. In particular,
the depth of a class in a topic hierarchy suggests its own topicality
and speciality. And if a text object can be successfully classi(cid:2)ed
into classes of different levels, it means much more information
can be thus created.

Table 3: The Top 1 inclusion rate of classifying text objects
into different levels. Number of pseudo classes created by Ap-
proaches 3 and 4 is 6.

Approaches
Approach 1

Approach 2

Approach 3

Approach 4

Approach 5

Text Types
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment

Level 2
.5731
.4748
.4609
.8047
.8417
.9634
.6172
.5467
.6190
.5390
.5755
.5827
.6562
.5683
.8452

Level 3
.4219
.3525
.5714
.6094
.6978
.8333
.4667
.4317
.6428
.6453
.4101
.6310
.5313
.4453
.7142

Level 4
.6094
.5683
.8810
N/A
N/A
N/A
.6171
.6384
.9166
.6610
.6834
.9048
.8203
.9496
.4048

Table 2 lists the details about the Level 2 to Level 4; Table 3
lists the results. It can be observed that classifying text objects into

different levels of the topic hierarchy got roughly the same results.
Although the higher the levels, the number of classes was smaller
and it seems easier to classify text objects into them, this factor was
cancelled by another fact: the concept of higher level classes were
harder to be trained correctly due to their generality and abstraction.

3.3 Creating Thematic Metadata for Textual

Data

Recent advances in text processing technologies, such as text
pattern recognition, information extraction, metadata annotation can
extract metadata (facts) about people, place, time from texts with
high accuracy. However, the metadata created by these kinds of
technologies, is still too primitive to be used as a basis for more ad-
vanced applications, such as concept-based search. How to create
more re(cid:2)ned metadata with limited human intervention is a prob-
lem that deserves investigation. In this experiment we explored the
possibility of using LiveClassi(cid:2)er to help create more re(cid:2)ned meta-
data.

We extracted three hierarchies from Yahoo!, respectively (cid:147)Peo-
ple(cid:148) (People/Scientist), (cid:147)Place(cid:148) (Region/Europe), and (cid:147)Time(cid:148)
(History-time Period). For these three cases, we randomly selected
100, 100, and 93 class names, which could be considered as a kind
of text segment, from the bottom-level and assigned them onto the
second-level classes. And as before, we randomly selected 77, 80,
45 short documents along with the corresponding full articles from
Yahoo! to conduct the experiments.

Table 5 lists some samples of the test text segments and their
corresponding classes. Table 4 lists the classi(cid:2)cation results for
various types of text. It could be observed that in the (cid:147)People(cid:148) and
(cid:147)Place(cid:148) cases, our approach got very satisfactory results, while in
the (cid:147)Time(cid:148) case we did not get similar good results. The reason
for its performance degradation seems that the concept of a time
period, such as (cid:147)Renaissance(cid:148)and (cid:147)Middle Ages(cid:148), is too broad and
too much noise is contained in the returned snippets, thus lowering
the precision of classi(cid:2)cation.

On the contrary, the high performance of the (cid:147)People(cid:148) case and
(cid:147)Place(cid:148) case is contributed by two factors: (1) The concepts of the
classes themselves are very speci(cid:2)c. A speci(cid:2)c concept implies
that Web search results are very precise and coherent and thus have
a higher chance of training the class correctly. (2) The classes are
themselves very distinct from one another. Notice especially this
factor can partly explain why the (cid:147)People(cid:148) and the (cid:147)Place(cid:148) cases
got better results than the above CS experiment. The (cid:2)elds of CS
often overlap in subjects while peopleâ€™s jobs and the places seldom
do.

Table 5: Some samples of the test text segments and their cor-
responding classes extracted from Yahoo!.

People Curie, Marie (1867-1934)

Samples and Corresponding Second-level Classes
Physicists
Korzybski, Alfred (1879-1950)
Linguists
Fulton, Robert (1765-1815) Engineers&Inventors
Mathematicians
Cantor, Georg (1845-1918)
Greece
Piraeus
Kannus
Finland
Austria
Vorchdorf
Iceland
Grindavik
Glorious Revolution
17th Century
Ancient History
Peloponnesian War
Hanseatic League
Middle Ages
18th Century
French Revolution

Place

Time

189Table 4: Top 1-5 inclusion rates for classifying Yahoo!â€™s People, Place, and Time text objects.

Yahoo! (People)

Approach
Approach 1

Approach 2

Yahoo! (Place)

Approach 1

Approach 2

Yahoo! (Time)

Approach 1

Approach 2

Text Type
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment

Top-1
.5866
.8961
.8654
.7066
.8533
.8846
.7375
.9000
.8700
.8625
.9500
.9200
.3333

.4

.1612
.4222
.4444
.3854

2

.6933
.8961
9808
.8133
.8961
.9808
.8375
.9250
.9500
.8875
.9750
.9600
.4444
.5555
.3225
.4444
.5555
.5521

3

.7466
.8961
.9808
.8533
.8961
.9904
.85
.9500
.9700
.8875
.9750
.9700
.5555

.6

.4301
.5555
.6222
.6354

4
.8

.8961
.9904
.8533
.8961
.9904
.875
. 9750
.9700

.9

.9750
.9700
.6444
.6444
.4838
.6444
.6666
.6562

5
.8

.8961
.9904
.8533
.8961
.9904
.8875
.9750
.9800
.9125
.9750
.9800
.6444
.7333
5591
.6444
.7555
.6562

Table 6: The information of the paper data set.

# Papers Assigned Class

Conference
AAAIâ€™02
ACLâ€™02
JCDLâ€™02

SIGCOMMâ€™02

29
65
69
25

CS:Arti(cid:2)cial Intelligence
CS:Linguistics
CS:Lib. & Info. Sci.
CS:Networks

Table 7: Top 1-5 inclusion rates for classifying paper titles.

Approach
Approach 1
Approach 2

Top-1
.2021
.4628

2

.2872
.6277

3

.3457
.7181

4

.3777
.7713

5

.4255
.8085

3.4 Paper Title Classi(cid:2)cation

We mentioned in Section 1 that one could design a Web informa-
tion service that collects academic papers and use a classi(cid:2)cation
technique to determine the specialized (cid:2)elds of researchers. We
now try to use LiveClassi(cid:2)er to show that this goal is achievable.

In this experiment, we collected a data set of academic paper
titles from four computer science conferences in year 2002 and
tried to classify them into the 36 second-level CS classes again.
Each conference was assigned to the Yahoo! class to which the
conference was considered to belong, e.g., AAAIâ€™02 was assigned
to (cid:147)Computer Science/Arti(cid:2)cial Intelligence,(cid:148) and all the papers
from that conference unconditionally belonged to that category. Ta-
ble 6 lists the relevant information of this paper data set. Note that
this might not be an absolutely correct classi(cid:2)cation strategy, as
some papers in a conference may be even more related to other do-
mains than the one we assigned them. However, to simplify our
experiment, we made this straightforward assumption. Table 7 lists
the experimental results. Also, Table 8 displays some examples of
miss-classi(cid:2)ed papers. It can be observed that the contents of these
miss-classi(cid:2)ed papers were actually more related to the classes as-
signed.
4. RELATED WORK

The fundamental similarity between HCQF and automatic query
expansion techniques is not hard to be discerned. The latter tech-
nique has been studied for decades with debatable degrees of suc-
cess; for a summary article, see [23]; more recent developments
can be found in [25, 18, 3]. Query expansion was (cid:2)rst introduced
to overcome the problem of word mismatch, a problem fundamen-
tal to Information Retrieval.
In a manner of speaking, the topic

hierarchy de(cid:2)ned by users can be taken as a kind of thesaurus; but
the topic hierarchy represents the subsumption relationship among
the concept of the classes rather than some semantical relationship.
A lot of Web IE systems have been developed and met different
degrees of success. The following list we cite is bound to be incom-
plete [10, 12, 11, 16, 4, 13]. However, to the best of our knowledge,
the possibility of combining text classi(cid:2)cation technique with Web
IE techniques to create more advanced Web information services
seems seldom to get a direct treatment in the literature.

Using the Web as a super huge knowledge source to solve prob-
lems is common practice these days. There have been attempts of
using Web Mining techniques to extract templates [2], to disam-
biguate word sense [1], to resolve PP attachment [24], to translate
terms [14], to build query taxonomies [5], and to categorize docu-
ments [8].

The works most closely related to ours are [17, 15]. Both works
were devised in view of overcoming the problem of expensiveness
and scarcity of hand-labelled corpora, although their approach and
ours are quite different in methodological aspect. Their main idea
is to use a bootstrapping process to label the unlabelled documents
probabilistically, and use the newly-labelled corpus to help retrain
the classi(cid:2)er and recursively so. The assumption of both works is
that an initial data set already exists, which may be some labelled
corpus [17], or some manually-assigned keywords [15]. They fo-
cus on the training stage, i.e., how to optimize the classi(cid:2)er based
on known corpus in the training stage, while in this work we fo-
cus on how to prepare a more suitable and rich initial data set. We
think their works and ours are complementary and it is possible to
upgrade the performance of LiveClassi(cid:2)er by adopting their tech-
nique. Also, more re(cid:2)ned query expansion techniques can be in-
corporated into HCQF to creating more suitable pseudo classes.

5. CONCLUDING REMARKS

In this work, we have presented a system that can automati-
cally extract corpora from the Web to train classi(cid:2)ers. The main
merits of LiveClassi(cid:2)er are its wide adaptability and its (cid:3)exibil-
ity. The needed classi(cid:2)er can be created by de(cid:2)ning a topic hierar-
chy. The necessary corpora can be fetched and organized automat-
ically, promptly, and effectively. Furthermore, the performance of
the classi(cid:2)ers created are in general good, supported by empirical
evidence.

From the perspective of application, LiveClassi(cid:2)er can create
more information at thematic level and this information can in turn

190Table 8: Selected examples of miss-classi(cid:2)ed paper titles.

Paper Title

A New Algorithm for Optimal Bin Packing
(Im)possibility of Safe Exchange Mechanism Design
Performance Issues and Error Analysis in an Open-Domain Question Answering System
Active Learning for Statistical Natural Language Parsing
Improving Machine Learning Approaches to Coreference Resolution
A language modelling approach to relevance pro(cid:2)ling for document browsing
Structuring keyword-based queries for web databases
A multilingual, multimodal digital video library system
SOS: Secure Overlay Services

Conference

AAAI
AAAI
ACL
ACL
ACL
JCDL
JCDL
JCDL
SIGCOMM

Target
Class
AI
AI
LG
LG
LG
LIS
LIS
LIS
NET

5

4

3

2

Top-
1
MOD COLT DNA
ALG AI
MD
LG
DB
SC
NET
ALG DC
SC
LG
AI
NN
LG
AI
NN
ALG FM
AI
LG
LIS
LG
ALG
UI
AI
ALG ARC
DB
LIS
AI
ECAD NET
UI
LG
LIS
NET MC
SC
OS
DC

COLT ALG

:Arti(cid:2)cial Intelligence

AI
ALG :Algorithms
ARC :Architecture
COLT:Computational Learning Theory
DB :Databases
DC :Distributed Computing

DNA :DNA-Based Computing
ECAD:Electronic Computer Aided Design

FM :Formal Methods
LG :Linguistics
LIS :Library and Information Science
MC :Mobile Computing

MOD:Modeling
NET :Networks
NN :Neural Network
OS :Operating Systems
SC :Security
UI :User Interface

2

3

5

4

200

Table 9: Yahoo!â€™s Computer Science experiment when the cor-
pus size increases. Approach 1.
Top-1
Nmax Text Type
.3389
100
.5780
.4917
.5311
.5780
.4850
.4294
.5563
.4518
.4294
.5454
.4219
.4294
.5450
.4219

Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment
Full Article
Short Document
Text Segment

.3785
.7008
.6346
.6271
.6678
.6213
.5028
.6632
.5880
.5198
.6553
.5747
.5198
.6345
.5083

.6214
.8146
.7242
.6949
.7409
.7243
.6102
.7423
.6910
.5819
.7004
.6678
.5819
.6921
.6047

.6779
.8483
.7545
.7118
.8034
.7409
.6251
.8011
.7043
.5875
.7321
.6810
.5875
.6999
.6146

.6045
.8034
.6943
.6723
.7008
.6910
.5593
.6803
.6545
.5593
.6731
.6445
.5593
.6855
.5648

400

600

800

be used to create more value-added Web information services. For
common human users, LiveClassi(cid:2)er also bestows much conve-
nience. No longer troubled by the tedious work of preparing cor-
pora, users may effortlessly construct many classi(cid:2)ers by his/her
own preference.

The effectiveness of LiveClassi(cid:2)er deserves some remarks. As
discussed in the preceding section, downloading un-labelled Web
corpora to augment features or to enhance the size of training cor-
pora has been tried in many recent works. However, few have con-
sidered the problem of (cid:147)how(cid:148) to collect and organize the corpora.
One may entertain the idea that HCQF simply depends on the
enormous size of Web resource to train the topic-hierarchy, how-
ever, this is not the case. Table 9 lists the results of the Computer
Science experiment when training corpora increased. It can be ob-
served that the performance did not ameliorate with the size of the
training corpora, on the contrary, it is the other way around.

A probable reason of this phenomenon is that the lowly-ranked
snippets contain much more noise, thus dragging down the perfor-
mance. Obviously, downloading Web documents indiscriminately
does not ensure success in training. The reason that HCQF can
get better results is rather its exploiting structural information con-
tained in topic hierarchies. We have presented in Section 3 that sub-
trees of limited depth extracted from Yahoo!â€™s directory can achieve
satisfactory results. We have also proven in Section 3.2 that in dif-
ferent granularities and in diverse domains, HCQF can achieve ac-
ceptable results. However, designing experiments of larger scale is
still desirable.

LiveClassi(cid:2)er can be accessed online in the following URL

http://liveclassi(cid:2)er.iis.sinica.edu.tw/. Users can create and modify
classi(cid:2)ers online.

6. REFERENCES
[1] E. Agirre, O. Ansa, E. Hovy, and D. Martinez. Enriching
very large ontologies using the www. In Proceedings of
ECAI 2000 Workshop on Ontology Learning, 2000.

[2] Z. Bar-Yossef and S. Rajagopalan. Template detection via
data mining and its applications. In Proceedings of the 11st
International World Wide Web Conference, pages 26(cid:150)33,
2002.

[3] C. Carpineto, R. De Mori, G. Romano, and B. Bigi. An

information-theoretic approach to automatic query
expansion. ACM Transactions on Information Systems,
19(1):1(cid:150)27, 2001.

[4] C.-H. Chang and S.-L. Lui. Iepad: information extraction

based on pattern discovery. In Proceedings of 10th
International World Wide Web Conference, pages 681(cid:150)688,
2001.

[5] S.-L. Chuang and L.-F. Chien. Towards automatic generation

of query taxonomy: A hierarchical query clustering
approach. In Proceedings of the 2nd IEEE International
Conference on Data Mining, pages 75(cid:150)82, 2002.

[6] W. Cohen and W. Fan. Learning page-independent heuristics
for extracting data from web pages. In Proceedings of the 8th
International World Wide Web Conference, 1999.

[7] W. Cohen, M. Hurst, and L. Jensen. A (cid:3)exible learning

system for wrapping tables and lists in html documents. In
Proceedings of the 11th International World Wide Web
Conference, pages 232(cid:150)241, 2002.

[8] W. Cohen and Y. Singer. Context-sensitive learning methods
for text categorization. In H.-P. Frei, D. Harman, P. SchÂ¤auble,
and R. Wilkinson, editors, Proceedings of the 19th Annual
International ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 307(cid:150)315,
ZÂ¤urich, CH, 1996. ACM Press, New York, US.

[9] B. V. Dasarathy. Nearest Neighbor (NN) Norms: NN Pattern
Classi(cid:2)cation Techniques. McGraw-Hill Computer Science.
IEEE Computer Society Press, Las Alamitos, California,
1991.

[10] E. O. Doorenbos, R. and D. Weld. A scalable

comparison-shopping agent for the world-wide web. In
Proceedings of Autonomous Agents, pages 39(cid:150)48, 1997.

[11] C.-N. Hsu and M.-T. Dung. Generating (cid:2)nite-state

transducers for semi-structured data extraction from the web.

191Journal of Information Systems, Special Issue on
Semistructured Data, 23(8):521(cid:150)538, 1998.

[12] N. Kushmerick, D. Weld, and R. Doorenbos. Wrapper

induction for information extraction. In International. Joint
Conference on Arti(cid:2)cial Intelligence, pages 729(cid:150)737, 1997.

[13] B. Liu, R. Grossman, and Y. Zhai. Mining data records in

web pages. In Proceedings of the ACM SIGKDD
International Conference on Knowledge Discovery and Data
Mining, 2003.

[14] W.-H. Lu, L.-F. Chien, and H.-J. Lee. Anchor text mining for

translation of web queries. In Proceedings of the (cid:2)rst IEEE
International Conference on Data Mining, pages 401(cid:150)408,
2001.

[15] A. McCallum and K. Nigam. Text classi(cid:2)cation by
bootstrapping with keywords. In ACL Workshop for
Unsupervised Learning in Natural Language Processing,
1999.

[16] I. Muslea, S. Minton, and C. Knoblock. Stalker: Learning
extraction rules for semistrctured, web-based information
sources. In Workshop on AI and Information Integration, in
conjunction with the 15th National Conference on Arti(cid:2)cial
Intelligence (AAAI-98), 1998.

[17] K. Nigam, A. K. McCallum, S. Thrun, and T. M. Mitchell.
Text classi(cid:2)cation from labeled and unlabeled documents
using EM. Machine Learning, 39(2/3):103(cid:150)134, 2000.
[18] Y. Qui and H. Frei. Concept based query expansion. In

Proceedings of the 16th Annual International ACM SIGIR
Conference on Research and Development in Information
Retrieval, pages 160(cid:150)169, 1993.

[19] G. Salton and C. Buckley. Term weighting approaches in

automatic text retrieval. Information Processing and
Management, 24:513(cid:150)523, 1988.

[20] M. Sanderson and W. B. Croft. Deriving concept hierarchies

from text. In Proceedings of the 24th Annual International
ACM SIGIR Conference on Research and Development in
Information Retrieval, pages 206(cid:150)213, 1999.

[21] F. Sebastiani. Machine learning in automated text

categorization. ACM Computing Surveys, 34(1), 2002.

[22] S. Soderland. Learning to extract text-based information

from the world wide web. In Proceedings of the 3rd
International Conference on Knowledge Discovery and Data
Mining, pages 251(cid:150)254, 1997.

[23] K. Sparck-Jones. Notes and references on early classi(cid:2)cation

work. SIGIR Forum, 25(1):10(cid:150)17, 1991.

[24] M. Volk. Exploiting the www as a corpus to resolve pp

attachment ambiguities. In Proceedings of Corpus
Linguistics, 2001.

[25] J. Xu and W. Croft. Query expansion using local and global

document analysis. In Proceedings of the 19th Annual
International ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 412(cid:150)420, 1996.

[26] Y. Yang. A study on thresholding strategies for text

categorization. In Proceedings of the 24th Annual
International ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 137(cid:150)145, 2001.

192