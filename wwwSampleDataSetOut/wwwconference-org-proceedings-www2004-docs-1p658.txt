A Hierarchical Monothetic Document Clustering Algorithm

for Summarization and Browsing Search Results

Krishna Kummamuru
IBM India Research Lab
Block 1, IIT, Hauz Khas
New Delhi 110016 INDIA

kkummamu@in.ibm.com

Rohit Lotlikar

IBM India Research Lab
Block 1, IIT, Hauz Khas
New Delhi 110016 INDIA
rohitmlo@in.ibm.com

Shourya Roy

IBM India Research Lab
Block 1, IIT, Hauz Khas
New Delhi 110016 INDIA
rshourya@in.ibm.com

Karan Singal

Dept. of Computer Science

and Engg.
IIT-Guwahati

North Guwahati 781039 INDIA
karan iitg@yahoo.co.in

Raghu Krishnapuram
IBM India Research Lab
Block 1, IIT, Hauz Khas
New Delhi 110016 INDIA
kraghura@in.ibm.com

ABSTRACT
Organizing Web search results into a hierarchy of topics and sub-
topics facilitates browsing the collection and locating results of in-
terest.
In this paper, we propose a new hierarchical monothetic
clustering algorithm to build a topic hierarchy for a collection of
search results retrieved in response to a query. At every level of
the hierarchy, the new algorithm progressively identiﬁes topics in
a way that maximizes the coverage while maintaining distinctive-
ness of the topics. We refer the proposed algorithm to as DisCover.
Evaluating the quality of a topic hierarchy is a non-trivial task, the
ultimate test being user judgment. We use several objective mea-
sures such as coverage and reach time for an empirical comparison
of the proposed algorithm with two other monothetic clustering al-
gorithms to demonstrate its superiority. Even though our algorithm
is slightly more computationally intensive than one of the algo-
rithms, it generates better hierarchies. Our user studies also show
that the proposed algorithm is superior to the other algorithms as a
summarizing and browsing tool.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information Search
and Retrieval – Clustering

General Terms
Algorithms

Keywords
Automatic Taxonomy Generation, Clustering, Summarization, Data
Mining, Search

1.

INTRODUCTION

The lack of a central structure and freedom from a strict syntax
is responsible for making a vast amount of information available
on the Web, but retrieving this information is not easy. Ranked lists
Copyright is held by the author/owner(s).
WWW2004, May 17–22, 2004, New York, New York, USA.
ACM 1-58113-844-X/04/0005.

returned by search engines are still a popular way of searching and
browsing the Web today. However, this method is highly inefﬁcient
since the number of retrieved search results can be in the thousands
for a typical query. Most users just view the top ten results and
therefore might miss relevant information. Moreover, the criteria
used for ranking may not reﬂect the needs of the user. A majority
of the queries tend to be short [3], thus making them non-speciﬁc
or imprecise [19]. The inherent ambiguity in interpreting a word or
a phrase in the absence of its context means that a large percentage
of the returned results can be irrelevant to the user.

Ranked lists have been found to be fairly effective for naviga-
tional tasks such as ﬁnding the URL of an organization. However,
since the results are not summarized in terms of topics, they are not
well suited for browsing tasks. One possible solution is to create
a static hierarchical categorization of the entire Web and use these
categories to organize the search results of a particular query. For
example, the dmoz (www.dmoz.org) directory that categorizes Web
sites is manually created by about 52 thousand editors. However,
this solution is feasible only for small collections. For example,
dmoz covers less than 5% of the Web. Secondly, even if we were
to categorize the entire Web either manually or automatically, the
categories may not be useful in organizing the search results of
a particular query [18, 6]. This is so because some or all of the
sub-topics associated with the user query may not be present in the
directory.

It has been observed that post-retrieval document clustering typi-
cally produces superior results [8]. Taxonomies are generated using
document clustering algorithms which typically result in topic or
concept hierarchies. Concept hierarchies expose the different con-
cepts present in the document (or search result) collection, as top
level nodes in the hierarchy and the user can choose the concept
he is interested in and can browse it in detail. Examples of search
engines that return search results in terms of a hierarchy include
vivisimo (www.vivisimo.com) and kartoo (www.kartoo.com).

Automatic taxonomy generation (ATG) algorithms can be cate-
gorized into two classes based on how the documents are assigned
to different clusters. Monothetic algorithms are those in which a
document is assigned to a cluster based on a single feature, whereas
polythetic algorithms assign documents to the clusters based on

658multiple features. Monothetic clustering is well suited for generat-
ing hierarchies for summarization and browsing search results be-
cause each cluster is described by a single feature or a concept and
all the documents present in a cluster contain this feature. Hence,
the user can easily understand clusters generated by monothetic
clustering algorithms.

In this paper, we propose a novel algorithm for post-retrieval hi-
erarchical monothetic clustering of search results to generate con-
cept hierarchies. As the algorithm progressively identiﬁes clusters
it tries to maximize the distinctiveness of the monothetic features
describing the clusters while at the same time maximizing the num-
ber of documents that can be described or covered by the mono-
thetic features. We refer to the proposed algorithm as DisCover.
One of the challenges we address in this paper is that of evaluat-
ing the performance of the algorithms that generate concept hier-
archies. We compare the performance of DisCover with that of
two of other known monothetic algorithms. The two algorithms
are CAARD and DSP and they will be explained in the next sec-
tion. This comparison is based on certain objective measures and
it shows that DisCover results in hierarchies with superior cover-
age and reach time (explained later). DisCover takes slightly more
time (19ms) than CAARD to generate hierarchies, but it takes much
less time than DSP. In addition to comparison based on objective
measures, we have also conducted user studies evaluate the perfor-
mance of the algorithms subjectively. The user studies reveal that
the hierarchies obtained using DisCover are more meaningful than
to those obtained by CAARD and DSP.

In Section 2, we describe some of the earlier work on taxon-
omy generation. In Section 3, we present the proposed DisCover
algorithm. In Section 4, we describe the experimental setup that
was used for conducting the experiments. We will also describe the
various heuristics that we used for identifying interesting phrases
(i.e., candidates for monothetic features) in the document collec-
tion in detail. We present the comparisons in Section 5 and report
the results from our user studies in Section 6. We summarize our
contributions and propose some possible extensions in the last sec-
tion.

2. RELATED WORK

2.1 Automatic Concept Hierarchies

As mentioned in the previous section, some of the ATG algo-
rithms are monothetic in the sense that a document is assigned to
a cluster based on a single feature, while the others are polythetic.
Popular examples of polythetic document clustering algorithms are
K-means [1] and agglomerative algorithms [22].
In these algo-
rithms, each cluster is described by several words or phrases. The
grouping of documents can be done by clustering documents or
words or by simultaneously clustering both documents and words.
The last approach is called co-clustering. ATG algorithms can be
classiﬁed as either top-down or bottom-up, depending on how they
build the hierarchy. A survey of various ATG techniques can be
found in [9]. We brieﬂy describe some of the techniques below.

Zamir and Etzioni [26] present an interface (called Grouper) to
the HuskySearch meta search engine [21] that dynamically groups
the search results into clusters labeled by phrases extracted from
snippets. Grouper uses an algorithm called Sufﬁx Tree Clustering
(STC) for forming groups of “snippets” (or summaries) of Web
pages. STC is based on standard techniques from the literature that
allow the construction of “sufﬁx trees” in time that is linear in the
number of document snippets, assuming that the number of words
in each snippet is bounded by a constant.

Vaithyanathan and Dom [23, 24] deﬁne a model for ﬂat (i.e.,

one-level) clustering, and then generalize it to generate hierarchi-
cal clusters. The model assumes that the feature set T can be par-
titioned into two conditionally independent sets: a ‘useful’ set U,
and a ‘noise’ set N. They extend the noise/useful concept to hier-
archical clustering by interpreting the ‘noise’ set associated with a
particular node to be the set of features that have a common distri-
bution over child nodes of the given the node, and the ‘useful’ set
to be the set of features that can be used to discriminate among the
child nodes.

There have been some attempts to generate hierarchies using the
thesaural relationship between words and phrases.They analyze the
context (phrase) in which a term occurs to infer the relationships
between various terms [5, 7].

One of the early works in monothetic clustering is the subsump-
tion algorithm by Sanderson and Croft [20]. The subsumption
algorithm builds concept hierarchies by ﬁnding pairs of concepts
(x, y) in which x subsumes y. The algorithm computes the sub-
sumption relationships between some selected pairs of words and
phrases (x, y) from the document collection and then retains only
those pairs in which x subsumes y. The hierarchy is then built in a
bottom-up fashion.

Lawrie et al. [13] consider an approach based on a set of topic
terms and a set of vocabulary terms to generate concept hierarchies.
They propose a language model composed of all the conditional
probabilities Prx(A|B) where Prx(A|B) is the probability of oc-
currence of A in the x-neighborhood of B. Here, A is a topic
term and B is a vocabulary term. In the experiments reported in
[13], the topic terms and the vocabulary terms are the same and
are those that occur in at least two documents excluding numbers
and stopwords. The ultimate goal is to ﬁnd the set of terms that
have maximal predictive power and coverage of the vocabulary. To
achieve this goal, the language model is converted into a graph and
the problem is posed as Dominating Set Problem (DSP). Since DSP
is known to be NP complete, the authors propose a greedy approx-
imation to solve DSP. The solution provides a set of terms that can
be used as labels at the top level. To ﬁnd the sub-topics of a top-
level topic, the language model is constructed on the terms occur-
ring in the neighborhood of the topic and the corresponding DSP is
solved. The procedure can be applied recursively to obtain a hier-
archy of topics. A variation of this method has been applied to Web
searches [14].

Kummamuru and Krishnapuram [11] consider the inclusion rela-
tion between while generating concept hierarchies. A set of words
and phrases representing concepts is ﬁrst identiﬁed from the cor-
pus. The degree to which the meaning of one concept wi in an-
other concept wj is estimated from the document corpus as |wj
·
wi|/|wi| where w is a n dimensional vector in which the i-th ele-
ment is 1 if concept w is present in i-th document and is zero oth-
erwise. The goal is to ﬁnd a minimal subset of concepts whose ele-
ments are as distinct from each other as possible and each concept
not in the subset has an inclusion degree in at least one of concepts
in the subset that is greater than a predeﬁned threshold, η. The au-
thors propose a fast greedy algorithm called Clustering Algorithm
for Asymmetrically Related Data (CAARD) to ﬁnd the solution to
the problem. The concept hierarchy is built by recursively applying
CAARD to the concepts in each cluster until a terminating condi-
tion is reached. CAARD adaptively ﬁnds η at various levels so that
the algorithm results in a hierarchy of a pre-speciﬁed size.

There is another class of approaches in which keywords are clus-
tered instead of documents.
In this approach, two keywords are
considered similar if they occur in the same set of documents. This
type of clustering is known as distributional clustering [16]. Fuzzy
Co-clustering of Documents and Keywords (FCoDoK) [10], Fuzzy

659Simultaneous KeyWord Identiﬁcation and Clustering of Documents
(FSKWIC) [4], and Rowset Partitioning and Submatrix Agglomer-
ation (RPSA) [15] are examples of co-clustering.
2.2 Evaluation of Taxonomies

Evaluation of the quality of taxonomies generated by a particu-
lar algorithm is an important and non-trivial task. We brieﬂy re-
view some of the relevant evaluation measures used in the litera-
ture. In [26], Zamir and Etzioni manually determine the precision
of the clustering algorithm. In [27], Zhao and Karypis use the F-
Score to evaluate the accuracy with which the documents are as-
signed to the clusters. However, this approach requires the use of
ground truth, which is unknown for collections of documents re-
turned by a search engine. Sanderson [19] performed a user study
to evaluate the quality of the relationship between a given concept
and its child and parent concepts. In [12] (a longer version of [14]),
Lawrie and Croft used three different evaluation measures. The
summary evaluation compares the Expected Mutual Information
Measure (EMIM) of terms in the hierarchy with the EMIM of the
top TF-IDF terms. This measure only estimates the goodness of
concepts when compared to the top TF-IDF terms and does not
necessarily reﬂect the end user requirements. The reachability cri-
terion measures the ability to ﬁnd documents within the hierarchy.
The reach time criterion measures the time taken to ﬁnd a relevant
document.

3. MONOTHETIC DOCUMENT
CLUSTERING ALGORITHM

3.1 Desirable Properties of Taxonomies

The main purpose of building a taxonomy is to provide a mean-
ingful navigational and browsing mechanism by organizing large
amounts of information into a small number of hierarchical clus-
ters [27]. In particular, the taxonomy should provide an overview
of the various concepts present in the collection of documents, and
reduce the search time associated with locating documents of inter-
est.

In this section, we enumerate some desirable properties of tax-
onomies generated from a corpus of documents. The proposed al-
gorithm uses some of these desirable properties. In Section 5, we
evaluate how well the taxonomies generated by the proposed algo-
rithm satisfy these desirable properties.

Property 1: Document Coverage. Ideally, all the documents in the
collection should be covered by the taxonomy. A document
is said to be covered by a taxonomy if it lies in (or assigned
to) at least one of the clusters in the top level of the taxonomy.
This requirement means that the top level clusters should be
chosen in such a way that they cover most of the documents
in the corpus. A taxonomy generation algorithm that covers
more number of documents will be considered to be better.

Property 2: Compactness. Since the main purpose of the taxon-
omy generation is to summarize and provide a better brows-
ing experience, the taxonomy should be as compact as pos-
sible. If a taxonomy becomes too wide or too deep, then the
basic purpose of taxonomy generation may not be served. A
ranked list (which can be considered as one-level deep tax-
onomy) may have a good coverage but it is not compact.

Property 3: Sibling Node1 Distinctiveness. Each of the nodes, es-
pecially those at the top level in the taxonomy, represents a

1We use the word ‘node’ to refer to a ‘cluster’ in a taxonomy.

concept2 present in the search results. At any level of the
hierarchy, the sibling concepts should be as different as pos-
sible from each other to minimize ambiguity while browsing
the documents in the hierarchy.

Property 4: Node Label Predictiveness. A good taxonomy should
help the user ﬁnd documents of interest with minimum ef-
fort. The labels of the node guide the user in locating a doc-
ument in the taxonomy. Hence, the node labels should be
chosen such that they are good indicators of the documents
they contain.

Property 5: Reach time. The average time it takes to locate search
results of interest is also an important criterion for taxonomies.
Ideally, we should be quickly able to locate search results of
interest within the hierarchy. Reach time is quantiﬁed more
formally in Section 5.

Property 6: General to speciﬁc. The node labels in the hierarchy
are actually the concepts associated with the query. In the hi-
erarchy, the most general concepts should be associated with
the root, and the node label of any node should be more spe-
ciﬁc (less general) than that of its parent and at the same time
it should be less speciﬁc (more general) than those of its chil-
dren. The generality or speciﬁcity of the node labels needs
to be considered within the context of the query.

Among the above desirable properties, we use Properties 1, 2 and
3 for the development of the algorithm. In Section 5, we evaluate to
what extent Properties 1, 2 and 5 are satisﬁed by the taxonomies ob-
tained by DisCover, CAARD and DSP. We also compare the com-
putational complexities of the three algorithms. Since Properties 4
and 6 are difﬁcult to quantify, we evaluate them subjectively along
with other measures in Section 6.

It may be noted that compactness and document coverage could
be contradicting requirements. Coverage can be increased by adding
more top level nodes. However, when the compactness criterion is
added, the algorithm would be ﬁrst forced to capture those concepts
that are present in a large portion of the document collection.
3.2 DisCover Algorithm

We assume that each document in the collection can be repre-
sented by a set of concepts. Each node in the hierarchy is associated
with a concept (i.e., the node label) and all documents under that
node contain that concept. In general, each of these documents will
contain several other concepts as well. We refer to the union of all
these concepts as concepts under the node. Monothetic clustering
of the documents under a node involves selecting a subset of those
concepts, optimal in some sense, and associating a child node with
each of them.

For ease of browsing and speed of execution, it is desirable to
compute a compact hierarchy that initially has a limited number
of child nodes under each node, but provide the user, via the user
interface, the ability to progressively increase the number of child
nodes of any node of interest. However, addition of new child nodes
should not require re-clustering of documents under the node. Oth-
erwise the speed will be compromised. Therefore, the child nodes
need to be generated in a particular sequence that is optimal in some
sense. For these reasons, we formulate our algorithm as that of se-
quentially selecting concepts from a set of concepts in an optimal
manner. This is equivalent to saying that we wish to ﬁnd an op-
timal ordering or permutation of the set of concepts. Speciﬁcally,
2We use the word concept to also represent either a word or a
phrase.

660we would like that the next concept selected be the one that will in-
crease the coverage maximally (Property 1) and will be maximally
distinct from its existing siblings (Property 3). By providing ability
to grow the hierarchy progressively, we allow users to choose upon
a suitable trade off between coverage and compactness (Property
2) that is appropriate for the task at hand.
Let C = {c1, . . . , cn} be the complete set of ordered concepts
under a node in the taxonomy. Let C(α) = {cα(1), cα(2), . . . cα(n)},
where α is a permutation on {1, . . . , n}, denote a permuted se-
quence of concepts. Let Sα,k−1 = {cα(1), . . . , cα(k−1)} represent
(k − 1) (where ((1 ≤ k ≤ n))) concepts that have already been
chosen sequentially. Let Uα,k−1 = C−Sα,k−1 denote the remain-
ing concepts in C that have not entered the sequence. We need to
pick the next concept from Uα,k−1 add to Sα,k−1, or equivalently
we need to determine α(k). The optimality criterion to be maxi-
mized for determining α(k) is

α(k) = arg max

g(Sα,k−1, cj)

j

cj ∈ Uα,k−1,

(1)

where, g(sα,k−1, cj) is deﬁned as follows:

g(Sα,k−1, cj) ∆= w1gc(Sα,k−1, cj) + w2gd(Sα,k−1, cj).

(2)

Here, gc and gd are functions that reﬂect document coverage and
sibling distinctiveness respectively, and w1 and w2 are the weights
associated with the respective factors.

Let d(C) denote the set of all documents covered by the concept

C. We deﬁne

gc(Sα,k−1, cj) ∆= |d(cj) − d(Sα,k−1)|.

(3)

The quantity on the right is the number of documents in d(cj) that
are not in d(Sα,k−1). In other words gc(.) quantiﬁes the increase
in coverage that would result by addition of cj as a concept node.
To compute the distinctiveness of a node c from a set of nodes
S, we consider of the concepts covered under S and c or concepts
that co-occur along with the concepts S and c. Let t(S) and t(c)
denote the sets of concepts under S and c respectively. Then

gd(Sα,k−1, cj) ∆= |t(cj) − t(Sα,k−1)|.

(4)

In other words gd(.) quantiﬁes the increase in the total number of
concepts when cj is added to Sα,k−1.
To determine α(k), we need to evaluate the RHS of (1), i.e.,
evaluate g(Sα,k−1, cj), for all cj ∈ Uα,k−1. The entire process
for computing the sequence Sα,k is described in the pseudo code
in Figure 1. We refer to the proposed algorithm as the concept
Distinctiveness and document Coverage (DisCover, for short) al-
gorithm.

There are some similarities between the above formulation and
that of traditional leader clustering [2]. Suppose we require to
cluster the concepts into k clusters. Then, the ﬁrst k concepts
cα(1), . . . , cα(k) represent the leaders of k clusters. The rest of
the elements in C(α) can be assigned to one these k clusters that
minimizes its dissimilarity (g) with the leader of the cluster. Note
that a similarity threshold, η, is used in leader clustering algorithms
as well as CAARD. Increasing the threshold increases the number
clusters. Moreover, the cluster leaders result with a smaller value
of η remain as cluster leaders when the data is reclustered with a
higher value of η. This observation also motivated us to the above
formulation.

Here, we formulated the problem of taxonomy generation as the
problem of ﬁnding a permutation that optimizes an objective func-
tion. This is done having in mind the experience of the end-user
of the system. Typically, a user browsing through a taxonomy

Sα,0 = ∅
for k = 1 to n {
α(k) = arg maxj g(Sα,k−1, cj)
Sα,k = Sα,k−1 ∪ cα(k)

}

Figure 1: DisCover Algorithm - outer loop

popular queries

ambiguous queries

2 fast 2 furious, miss universe,
sars, bugbear, david beckham
jaguar, latex, panther, java, blues

Table 1: Queries used in the user study.

would like to look at the sub-concepts at various levels of gran-
ularity. Large number of sub-concepts (clusters) are needed by a
person that wants to see more detailed sub-concepts. Alternatively,
as will be explained in the experimental setup, we can gradually
show the concepts in C(α) to the user as she seeks more and more
information.

The values of the weights w1 and w2 need to be determined em-
pirically. We have chosen w1 = 0.8 and w2 = 0.2 by trial and er-
ror. In our experience, the concepts that are picked initially are the
ones that are present in a large number of documents. The “niche”
concepts begin to appear in later stages.

4. EXPERIMENTAL SETUP

4.1 Introduction

In this section, we describe the system that we built and used
for empirical evaluations and user studies. We selected the queries
shown in Table 1. Of the ten queries, ﬁve are what we call ambigu-
ous queries and the remaining ﬁve are popular. Ambiguous queries
have multiple interpretations associated with them, whereas popu-
lar queries are some of the top gaining queries reported by Google
in the month of June 2003. For each query, we requested 1000 (En-
glish only) search results from Google (http://www.google.com).
The actual number of search results returned by Google for these
ten queries varied from 564 to 910 with a mean of 818. Also, some
non-English (generally French or Spanish results) would creep in.
For each search result, we retrieve the title and snippet and con-
verted them to plain text. Next, the feature extraction module (de-
scribed in detail Section 4.2) builds an index for the collection of
snippets. The feature extraction phase is common to all three al-
gorithms. Finally, each algorithm accesses the index to generate its
hierarchy. We have developed an interface, which will be explained
below, that simultaneously displays the three hierarchies generated
by CAARD, DisCover and DSP respectively. We set the parameters
of all three algorithms to only display the top ﬁve nodes under any
parent node. The purpose of doing so is to make it simpler for users
to compare the hierarchies. We ﬁrst explain the feature extraction
module in the next section and the user interface in Section 4.3.
4.2 Feature Extraction

The purpose of feature extraction is to build an index of the var-
ious terms that occur in the collection. Once the index has been
created, the original documents are no longer required. The index
is a compact representation of the document collection. Not all of

661the terms in the document collection should be included in the in-
dex. Common words and frequent words such as ‘the’, ‘of’, ‘to’ are
poor predictors of the content of a document and have little value as
indexing terms. Also, it is preferable that morphologically and se-
mantically related terms are conﬂated into a single index term. For
example, the terms “professor”, “professorship”, and “A professor”
should be conﬂated into a single term such as “professor”.

Nouns, adjectives and noun phrases are valuable as index terms
since they are good indicators of the content of a document. Part-
of-speech determination and extraction of noun phrases were done
using a tool developed by IBM T. J. Watson Research Lab, which
is in essence similar to [25].

The index is binary, it indicates whether a term occurs or does
not occur in a document. Since we deal with short (1-3 line) snip-
pets, it does not make sense to consider a term more important if it
occurs multiple times in a document. Though feature extraction is
not the focus of this work, good feature extraction is an important
prerequisite for a good hierarchy. The following are the steps used
for this purpose.

Step 1: Term extraction. Generally noun phrases, and single
words that are either nouns or adjectives are most predictive of the
content of the document. We identify these terms while ignoring
other terms. We also ignore any single words less than 3 characters
in length.

Step 2: Adding constituent words and sub-phrases. For each
extracted phrase, we add constituent words of the phrase as well as
sub-phrases to the list of concepts.

Step 3: Stop-word elimination. We eliminate words commonly
found in Web documents (such as “page”, “site”, and “click”) that
are considered as stopwords.

Step 4: Morphological generalization. We normalize noun phrases

by removing stopwords, determiners and prepositions. Single words
and words part of noun phrases are stemmed using Porter’s stem-
mer [17]. All terms are converted to lower-case.

Step 5: Index creation. An index is created for the terms result-
ing from Steps 1 to 4. The index is further reﬁned by removing the
terms that occur in less than two percent of the documents because
they are unlikely to impact the hierarchy.

Step 6: Generating node labels and thresholding. We have rep-
resented concepts by stemmed words and phrases. However, these
are not usually very meaningful for use as node labels. Therefore,
we replace each stemmed term by the most frequently occurring
original term.

4.3 User Interface

The user interface consists of a browser window with 4 frames
as shown in Figure 2. This ﬁgure shows the GUI for the query
“Latex”. The three hierarchies in the left 3 frames from left to
right correspond to CAARD, DisCover and DSP respectively. We
hide the names of the hierarchies and call them Algorithm 1, 2
and 3 to obtain unbiased feedback from the users. When any node
label (for any of the 3 hierarchies, at any level of the hierarchy)
is clicked, the snippets contained in that node are displayed in the
right most frame. Thus the user can see the documents assigned to
any node of the hierarchies. A ‘+’ sign inside a node indicates that
the node may be expanded to show the lower-level nodes. When
this sign is clicked the node is expanded to display the child nodes,
and simultaneously the sign changes to ‘−’ indicating that the child
nodes may be collapsed. If a node contains more than 5 children,
we display the more and less hyperlinks at the bottom. The user
can click on them to see either more number of sub-concepts or
less number of sub-concepts. However, for the user study, in order
to make it easier for the hierarchies to be compared, we displayed

CPU time (ms)
Complexity

99.2
O(kn)

DisCover CAARD

DSP
80.8
421.7
O(kn) O(kn2)

Table 2: Average CPU time of algorithms in milliseconds.

only upto a maximum of 5 children for each node. Also we do
not display nodes that contain fewer than 4 documents. Documents
that do not fall into any of the displayed nodes are relegated to an
”Others” node. In Figure 2, we have expanded one of the nodes
(“rubber”) in all the three hierarchies.

5. EMPIRICAL EVALUATION
5.1 Computation Complexity

Let n be the number of concepts and k be the number of clusters
that we are interested in generating. Then, the for loop in Figure 1
needs to be executed only k times instead of n times. Hence, the
complexity of DisCover is O(kn).

CAARD visits concepts in the decreasing order of their docu-
ment frequencies and computes their inclusion with the already
selected leaders. Hence, Card’s complexity is also O(kn). As
explained in Section 2, DSP builds a language model.
It com-
putes conditional probabilities between every pair of concepts. This
makes the complexity of DSP O(kn2).

In our experiments, we have also measured the execution time
of all three algorithms. Table 2 shows the average CPU time of the
algorithms for generating the hierarchies for the queries in Table 1
along with their computational complexity. These results reﬂect the
above observations. However, DisCover takes a little longer than
CAARD. This is mainly because DisCover computes concept dis-
tinctiveness in addition to document coverage. CAARD effectively
computes document coverage only.
5.2 Coverage and Compactness

As mentioned in the Section 3, there is an implicit trade off be-
tween coverage and compactness. We analyze this behavior for the
taxonomies obtained by the three algorithms as we consider more
and more nodes. We compute the percentage of documents that has
been covered. In the case when the top level node contains a child
node with the query term as its label, we consider the sub-concepts
of this node.

DSP uses a threshold that is computed using conditional proba-
bilities. Therefore, the number of nodes returned by DSP depen-
dents on the contents of the node in the taxonomy. Since DisCover
and CAARD can generate as many nodes as required in the com-
parisons, we consider only the number of nodes generated by the
DSP. Figure 3 shows the graph of coverage versus the number of
nodes for two of the queries. Each of these graphs shows the behav-
ior of all the three algorithms. As expected from the formulations,
DisCover algorithm exhibits higher coverage than the other algo-
rithms for the same number of nodes. Even though the behavior of
DSP is quite similar to that of DisCover for small number of nodes,
its coverage reduces below that of CAARD algorithm for higher
number of nodes.
5.3 Reach Time

To quantify the reach time for a search result, we need to ﬁrst
outline an operational procedure to locate a search result of interest
and then base the reach time upon that procedure. This procedure
should mimic the procedure that a typical user of the system will
follow.

662Figure 2: The user interface.

A typical user would inspect all the top level node labels and se-
lect a node which he or she feels is most likely to contain the search
result(s) of interest. This takes a time proportional to the number
of top level nodes, lets say it takes a time θ × n0, where n0 is the
number of root level nodes and θ is a proportionality constant. The
user will expand the selected node to display it’s child nodes. Sim-
ilarly, for the consecutive levels, user will inspect the node labels
and select one that he/she feels is most likely to contain relevant
search results. The time required for this selection can be similarly
computed. The user would continue this process and drill down the
hierarchy until a leaf node is reached. By adding up the times spent
at each level, we obtain the path time tpath for this node. At this
point, the user would scan the search results under that leaf node
sequentially until the desired search result is found. If the desired
snippet is located at the pth position, then the reach time for the
snippet is given by

treach = (θs × p) + tpath(q).

(5)

If a snippet is in multiple leaf nodes, we use the least of the reach
times as the reach time for that snippet. To compute the average
reach time over all snippets, we average the reach time over all the
snippets. Snippets that do not fall into any node of the hierarchy, are
assumed to lie in the ”Others” node at the top-level of the hierarchy.
For a ranked list the reach time for the ith snippet is simply i, so
the average reach time for a ranked list of N search snippets is

N−1X

tRankedlist = 1/N

i = N/2.

(6)

Figure 3: Effect of number of clusters (nodes) on coverage.

i=0

Table 3 summarizes the reach time computed for the 2 sets of
queries. Each of the numbers shown in the table is the average
of reach times of hierarchies obtained using the queries from the
corresponding query group. It may be observed from Table 3 that
DisCover resulted in hierarchies with less reach times than the other
algorithms.

663CAARD DisCover DSP Ranked List

ambiguous

popular

196
130

161
87

181
221

424
377

Table 3: Comparison of the average reach time for different
algorithms.

Question Criterion Evaluated
number

1a
1b
1c
2a
2b
3

Summarization by top level nodes
Missing concepts in top level
Redundancy among top level nodes
Summarization by second level nodes
Redundancy among second level nodes
Overall utility for browsing and searching

Table 4: Questions used in the survey.

6. USER STUDY

Comparing and evaluating hierarchies is not easy as many of the
criteria are rather subjective in nature. The best way to evaluate the
performance on such criteria is by performing user studies. This
demonstrates whether the hierarchies generated are actually helpful
to real users for browsing a particular document collection.

We performed the study on 17 volunteers who were both tech-
nical and non-technical employees of the IBM India Research Lab.
The queries were assigned to each volunteer such that each volun-
teer evaluated 3 queries (except for one volunteer who evaluated 2
queries). This gave us 5 responses to each query, with a total of
25 responses for ambiguous queries and 25 responses for popular
queries. Users were provided with a very short introduction to ATG
and the motivation behind creating a taxonomy from a document
collection. The users were not told which hierarchy corresponded
to which algorithm.

Each user was asked to ﬁll up an online questionnaire for each
query. The questionnaire contained 6 questions. For each question,
the user was asked to rate each hierarchy on a scale of 1-10. The
6 questions can be broadly divided into 3 groups. The ﬁrst group
of 3 questions pertain to the top level nodes of the hierarchy. The
second group of 2 questions pertain to the second level nodes. In
the ﬁnal question, the user was requested to give an overall rating
to the hierarchy. The criteria evaluated by the questions are shown
in Table 4.
6.1 Analysis

Since the evaluation process is subjective, it is not meaningful
to compare the actual scores between one user and another or be-
tween one query and another. However, it is meaningful to compare
scores within a response. Thus, for each question in each of the
50 responses, we noted whether DisCover was rated “better than”,
“worse than” or “equal to” CAARD and DSP respectively. The
responses for popular and ambiguous queries were separated out.
The number of instances of each type was counted. These results
are shown in Table 5 and 6, for ambiguous and popular queries
respectively.

From Tables 5 and 6, it can be seen than DisCover is superior to
DSP in almost every respect. In comparison with CAARD, Dis-
Cover is better in terms of summarization for both popular and
ambiguous queries. However, in the redundancy aspect, for am-
biguous queries, DisCover performs comparably to CAARD. For

Question
number

relative to CAARD

relative to DSP

better

equal worse

better

equal worse

1a
1b
1c
2a
2b
3

14
10
7
15
8
16

6
12
11
8
8
3

5
3
7
2
9
6

15
8
16
14
13
19

5
7
6
10
10
3

5
10
3
1
2
3

Table 5: Performance of DisCover relative to CAARD and
DSP for ambiguous queries. The entries are the number of in-
stances.

Question
number

relative to CAARD

relative to DSP

better

equal worse

better

equal worse

1a
1b
1c
2a
2b
3

10
11
4
9
6
11

10
12
13
8
6
6

5
2
8
8
13
8

20
18
12
18
15
19

4
6
8
7
6
5

1
1
5
0
4
1

Table 6: Performance of DisCover relative to CAARD and DSP
for popular queries. The entries are the number of instances.

popular queries, CAARD outperforms DisCover in the redundancy
aspect. The response to the last question “Overall, which hierarchy
is the best in terms of summarizing the search results and ease of
browsing the results?” indicates the overall sentiment of users to-
ward the algorithms. The results show that DisCover outperforms
both CAARD and DSP. In particular, for ambiguous queries the
difference is higher. This is as expected because, since the purpose
of hierarchies is to identify the different concepts in the document
collection, the utility of a good hierarchy is more evident when the
queries are ambiguous. An alternate view of the results for ques-
tion 3 is shown in Figure 4. DisCover is ranked ﬁrst far more often
than it is ranked second or third when compared with CAARD or
DSP, particularly in the case ambiguous queries.

7. CONCLUSIONS

In this paper, we propose a new algorithm for hierarchical mono-
thetic document clustering for summarization and browsing of Web
search results. We select a monothetic clustering algorithm because
they are well suited for generating concept hierarchies. With a fo-
cus on end-user requirements, we deﬁne a set of desirable prop-
erties for such an algorithm. We quantify some of the properties
and frame an optimality criterion. Our algorithm differs from ex-
isting monothetic clustering algorithms in the optimality criterion.
We empirically evaluate the performance of our algorithm in rela-
tion to two other monothetic clustering algorithms - CAARD and
DSP based on a set of 10 queries. We also perform user studies to
evaluate the performance of the algorithms on the more subjective
criteria as well as to justify the selection of these evaluation crite-
ria. Our empirical evaluations reveal that the nodes generated by
DisCover cover documents more efﬁciently than either CAARD or
DSP. Consequently, the reach time for DisCover tends to be sig-
niﬁcantly lower than that for CAARD and DSP. User studies also
reveal that DisCover is more useful as a browsing and summarizing
tool than either CAARD or DSP.

We use only coverage, distiveness and compactness properties

664[9] R. Krishnapuram and K. Kummamuru. Automatic taxonomy
generation: Issues and possibilities. In LNCS: Proceedings of
Fuzzy Sets and Systems (IFSA), volume 2715, pages 52–63.
Springer-Verlag Heidelberg, Jan. 2003.

[10] K. Kummamuru, A. K. Dhawale, and R. Krishnapuram.

Fuzzy co-clustering of documents and keywords. In
Proceedings of FUZZIEEE, St. Louis, MO, 2003.

[11] K. Kummamuru and R. Krishnapuram. A clustering

algorithm for asymmetrically related data with its
applications to text mining. In Proceedings of CIKM, pages
571–573, Atlanta, USA, 2001.

[12] D. J. Lawnie and W. B. Croft. Generating hierarchical

summaries for web searches.
citeseer.nj.nec.com/lawrie03generating.html.

[13] D. Lawrie, W. B. Croft, and A. Rosenberg. Finding topic
words for hierarchical summarization. In Proceedings of
SIGIR, pages 349–357. ACM Press, 2001.

[14] D. J. Lawrie and W. B. Croft. Generating hierarchical

summaries for web searches. In Proceedings of SIGIR, pages
457 – 458, 2003.

[15] B. Mandhani, S. Joshi, and K. Kummamuru. A matrix

density based algorithm to hierarchically co-cluster
documents and words. In Proceedings of WWW , Budapest,
Hungary, 2003.

[16] F. C. N. Pereira, N. Tishby, and L. Lee. Distributional

clustering of English words. In Meeting of the Association
for Computational Linguistics, pages 183–190, 1993.

[17] M. F. Porter. An algorithm for sufﬁx stripping. Program,

14:130–137, 1980.

[18] G. Salton. The SMART Retrieval Systems. Prentice Hall,

Englewood Cliffs, N.J., 1971.

[19] M. Sanderson. Word sense disambiguation and information

retrieval. In Proceedings of SIGIR, pages 142–151, 1994.

[20] M. Sanderson and W.B.Croft. Deriving concept hierarchies
from text. In Proceedings of SIGIR, pages 206–213, 1999.

[21] E. Selberg and O. Etzioni. Multi-service search and

comparison using the MetaCrawler. In Proceedings of
WWW, Darmstadt, Germany, December 1995.

[22] P. H. A. Sneath and R. R. Sokal. Numerical Taxonomy - The
Principles and Practice of Numerical Classiﬁcation. W. H.
Freeman, San Francisco, CA, 1973.

[23] S. Vaithyanathan and B. Dom. Model selection in

unsupervised learning with applications to document
clustering. In The Sixth International Conference on Machine
Learning (ICML- 1999), pages 423–433, June 1999.

[24] S. Vaithyanathan and B. Dom. Model-based hierarchical

clustering. In Proceedings of Sixth Conference on
Uncertainty in Artiﬁcial Intelligence, pages 599–608, 2000.

[25] R. Weischedel, M. Meteer, R. Schwartz, L. Ramshaw, and
J. Palmucci. Coping with ambiguity and unknown words
through probabilistic models. Association for Computational
Linguistics, 19(2):359–382, 1993.

[26] O. Zamir and O. Etzioni. Web document clustering: A

feasibility demonstration. In Proceedings of SIGIR, pages
46–54, 1998.

[27] Y. Zhao and G. Karypis. Evaluation of hierarchical clustering

algorithms for document datasets. In Proceedings of CIKM,
pages 515–524. ACM Press, 2002.

Popular Queries

Ambiguous Queries

Figure 4: Rank distribution of 3 algorithms for question 5.

to design the proposed algorithm. It will be interesting to see the
effect of explicitly optimizing the reach time property on the algo-
rithm. We have used a general purpose chunking tool for feature
extraction in our experiments because the searches we performed
and the corpus are general in nature. One may need to use domain
dependent annotators or chunkers in order to apply this algorithm
when used in generating concept hierarchies from search results
obtained using domain-dependent queries on domain-speciﬁc cor-
pora. It will be interesting to explore how to use domain-speciﬁc
ontologies, if available, in generating the concept hierarchies.

8. REFERENCES
[1] G. Ball and D. A. Hall. A clustering technique for

summarizing multivariate data. Behavioral Science,
12:153–155, 1967.

[2] R. O. Duda, P. E. Hart, and D. G. Stork. Pattern

Classiﬁcation. John Wiley and Sons, Inc., New York, 2001.
[3] K. Franzen and J. Karlgren. Verbosity and interface design.
Technical Report T2000:04, Swedish Institute of Computer
Science (SICS), 2000.

[4] H. Frigui and O. Nasraoui. Simultaneous categorization of

text documents and identiﬁcation of cluster-dependent
keywords. In Proceedings of FUZZIEEE, pages 158–163,
Honolulu, Hawaii, 2002.

[5] G. Grefenstette. Explorations in Automatic Thesaurus

Discovery. Kluwer Academic Publishers, 1994.
[6] A. Grifﬁths, H. Luckhurst, and P. Willett. Using

inter-document similarity information in document retrieval
systems. Journal of the American Society for Information
Sciences, 37:3–11, 1986.

[7] M. A. Hearst. Automated discovery of WordNet relations. In

C. Fellbaum, editor, WordNet: an Electronic Lexical
Database. MIT Press, 1998.

[8] M. A. Hearst and J. O. Pedersen. Reexamining the cluster

hypothesis: Scatter/gather on retrieval results. In
Proceedings of SIGIR, pages 76–84, Z¨urich, CH, 1996.

665