Outlink Estimation For Pagerank Computation Under

Missing Data

Sreangsu Acharyya
Department of E.C.E

University of Texas, Austin.

sreangsu@ece.utexas.edu

Joydeep Ghosh
Department of E.C.E

University of Texas, Austin.
ghosh@ece.utexas.edu

ABSTRACT
The enormity and rapid growth of the web-graph forces
quantities such as its pagerank to be computed under miss-
ing information consisting of outlinks of pages that have not
yet been crawled. This paper examines the role played by
the size and distribution of this missing data in determining
the accuracy of the computed pagerank, focusing on ques-
tions such as (i) the accuracy of pageranks under missing
information, (ii) the size at which a crawl process may be
aborted while still ensuring reasonable accuracy of pager-
anks, and (iii) algorithms to estimate pageranks under such
missing information. The (cid:12)rst couple of questions are ad-
dressed on the basis of certain simple bounds relating the
expected distance between the true and computed pager-
anks and the size of the missing data. The third question
is explored by devising algorithms to predict the pageranks
when full information is not available. A key feature of the
\dangling link estimation" and \clustered link estimation"
algorithms proposed is that, they do not need to run the
pagerank iteration afresh once the outlinks have been esti-
mated.
Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Clustering

General Terms
Algorithms
1.

INTRODUCTION

Selecting and ordering query results, from over 3 billion

hyperlinked pages that now constitutes the web graph G(V; E)
is a di(cid:14)cult web mining problem of extreme importance and
one in which link analysis plays a key role. The enormity and
dynamic nature of the web-graph, and especially its rapid
rate of growth, forces link analysis based ranking schemes
like Pagerank to operate under a signi(cid:12)cant amount of out-
dated and missing data, present in the form of unknown
outlinks from uncrawled pages. This naturally raises ques-
tions on the accuracy of the pageranks under such severe
conditions, for example, how much of the web graph need
to be traversed so that enough faith can be ascribed to the
computed pagerank values, or how may one estimate the un-
known outlinks and incorporate them in the pagerank calcu-
lation without re-running the iteration from scratch again.
These are examined below.
Copyright is held by the author/owner(s).
WWW2004, May 17â€“22, 2004, New York, New York, USA.
ACM 1-58113-912-8/04/0005.

2. PAGERANK ITERATION AND INCOM-

PLETE DATA

The lack of information about the outlinks of the un-
crawled pages gets expressed in the Pagerank iterations as
incomplete rows of the transition matrix whose stationary
distribution is the Pagerank vector. Thus one either has to
remove the uncrawled but known vertices for calculation or
substitute a predicted distribution (normalized outlink vec-
tors) in its place. Here we show this lack of information
may seriously a(cid:11)ect the accuracy of the Pagerank vector.
But (cid:12)rst we de(cid:12)ne what we mean by accurate Pageranks on
a subgraph of the web.

Definition 1. Given a subset Vk of the vertices of the
web-graph G(V; E), the true pageranks of Vk are de(cid:12)ned to be
those that are calculated on the subgraph G0(Vk; Ek) induced
by the vertices Vk, i.e. G0 contains all and only those edges
xy 2 E, s.t. x; y 2 Vk.

At any stage of operation of a pageranking engine, the en-
tire set of web pages V can be divided into the crawled set
C and its complement, the uncrawled set C 0. We de(cid:12)ne for-
ward set of C as F = fp : 9(q 2 C)j(q; p) 2 Eg. Henceforth
the shorthand q ! p is used to denote (q; p) 2 E. For pages
in the set of known but uncrawled pages FC 0 = fF \ C 0g the
pageranking engine will have no knowledge of their outward
links. This constitutes missing information under which the
ranking scheme has to operate. We call the set fC [ FC 0g
the known set Vk and represent its cardinality by Nk = jVkj.
Given an incomplete
transition matrix of size N , and a distribution p((cid:1)) from
which the unspeci(cid:12)ed rows (normalized outlink vectors) have
been drawn, the resulting pageranks are called robust if the
expected distance between the calculated and true pageranks
is of order O(1).

Definition 2. Robustness:

Proposition 1. For outlinks drawn with p(:) as uniform,
the pagerank computation is robust if the size of the set of
unknown vertices of the order O(pNk).
The proof is omitted for lack of space and can be found in an
expanded version [4]. From practical standpoint, however,
the assumption of uniform distribution of outlinks is debat-
able. Web statistics suggest that outlinks are a lot sparser
than those generated from uniform sampling over the en-
tire regular unit N simplex. A closer approximation would
be that they are sampled from lower dimensional simplices
that constitute the boundary of our original N -dimensional

486simplex. This would increase the expected distance, for a
distribution uniform over the lower dimensional simplex n.
This points to the fact that careful imputations of the
unknown values in the transition matrix may be required.
One adhoc method suggested in the original Pagerank paper
[2] is to ignore the unknown rows and work with fully know
submatrix corresponding to pages in C. Once the stationary
distribution of the induced transition has been computed,
the (cid:12)nal ranks are computed by running multiple, but (cid:12)xed
number of iterations of the Pagerank algorithm applied to
vertices in FC 0 to estimate their pageranks. We show that
a single iteration su(cid:14)ces under certain assumptions. This
paper examines schemes with which one may apportion a
pagerank value to the pages in FC 0 that incorporates the
unknown outlinks.

3. DANGLING LINK ESTIMATION

Unlike the method where the unknown rows of the transi-
tion matrix are (cid:12)lled by a non-committal uniform distribu-
tion, one may use the expected distribution i.e. the distribu-
tion of the state transition events averaged over an in(cid:12)nite
time, which under mild conditions converge to the station-
ary distribution or the pagerank values. Replacing unknown
values by their expectation has been a standard method of
imputation, however in this case we can argue for it even
more strongly by drawing upon studies conducted on the
power law nature of web graphs.
It has been shown that
preferential attachment of links is crucial for explaining such
power laws. A model where web vertices link to other ver-
tices proportional to the pagerank values generate power
laws which are similar to those observed in practice [3].

One is obviously tempted to run this scheme iteratively
where the next pagerank estimates are computed by replac-
ing the unknown rows by the current pagerank values till
convergence. Thus we are looking for a vector (equivalently,
a probability distribution) r such that if we substitute it in
the place of the unknown rows we get back r as our pager-
ank, i.e. r is a (cid:12)xed point. The (cid:12)xed point can however be
computed analytically without the need for such iterative
updates.

Proposition 2. Calculating the pagerank of pages in C
followed by a single pagerank iteration on the incomplete
transition matrix provides the valid pagerank under the as-
sumption that entries in the unknown rows have the same
outlink distribution as the converged pagerank vector.

4. CLUSTERED LINK ESTIMATION

Our objective here is to estimate the unspeci(cid:12)ed rows of
the pagerank matrix T , i.e. the conditional distribution ta-
ble P (y2jy1) and its corresponding stationary distribution
r as the new pagerank vector. For that we introduce a
latent variable model, which unlike those proposed for co-
occurrence data [1] is applicable even when closed world
assumption is not made, allowing one to use in our dynamic
setup.

The probability of page y1 linking y2 is expressed through
latent variables Z. We pose the model in terms of a single
random variable Z by introducing constraints that the row
and column marginals of its joint distribution are identically
distributed. This constraint also has another signi(cid:12)cance
that unlike a general joint distribution over discrete random
variables this can mapped directly into a Markov chain on

D

 
,
e
c
n
a
t
s
i
D
1
L

 

2

1.5

1

0.5

0

0

Naive 500
Null 500
Uniform 500
Dangling 500

Figure:1Comparison of
outlink Prediction by
Dangling Link, Naive
Bayes, Null and Uni-
form distribution for a
crawl set of 500 pages.

3000

500
2500
No of Pages with distance less than D

1000

1500

2000

K states, thereby making it possible to compute the pager-
ank in the coarser representation and estimating the (cid:12)nal
pageranks from it. The model is represented as

P (y2jy1) =

1

P (y1)  

z1

z2

P (y1jz1)P (z1):P (z2jz1)P (y2jz2)

= P (y2):  

z1

z2

P (z1jy1)

P (z2; z1)

P (z1):P (z2)

:P (z2jy2)

(1)

Now except for P (y2), which is essentially the pagerank
of y2, no other term assigns probabilities over the set Y
and therefore can be modeled by a (cid:12)xed set of parameters,
irrespective of whether the set Y changes or not, this prop-
erty allows us to use the model even in a dynamic scenario.
However we do seem to have a chicken and egg problem be-
cause to estimate the pagerank P (y2) we need the transition
probabilities P (y2jy1) which in turn requires P (y2). Let us
express the equation above in a more compact matrix nota-
tion, let (cid:3)[1; 2] = P (z2;z1)
P (z1);P (z2) , U [i; j] = P (Z(yj ) = ijyj ), a
diagonal matrix R[i; i] = P (yi) = ri and r[i] = P (yi). Using
the equation (1) above and the stationarity property of the
pageranks one has

T T r = R[U T (cid:3)T U ]:r = r or; [U T (cid:3)T U ]r = R(cid:0)1r = 1 (2)

Given the matrices (cid:3) and U the linear equation above in
jY j = Nk unknowns can be solved using iterative scaling
that chooses the maximum entropy solution under the lin-
ear constraints. We have omitted the derivation of the E
step and that of the M step under row column marginal con-
straints. Full details maybe found at [4]. The L1 distance
between the true and the predicted rows of the transition
matrix is shown for a small subset of the webgraph from
utexas domain in (cid:12)gure (1), a naive Bayes classi(cid:12)er tak-
ing the inlinks as input was used as a comparison including
a predictor which always predicted an uniform distribution
and another which predicted that the page did not have any
outlinks .
5. REFERENCES
[1] T. Hofmann and J. Puzicha. Unsupervised learning

from dyadic data. Technical Report TR-98-042,
University of California, Berkeley, Berkeley, CA, 1998.
[2] L. Page, S. Brin, R. Motwani, and T. Winograd. The
pagerank citation ranking: Bringing order to the web,
1998.

[3] G. Pandurangan, P. Raghavan, and E. Upfal. Using

PageRank to Characterize Web Structure. In 8th
Annual International Computing and Combinatorics
Conference (COCOON), 2002.

[4] www.lans.ece.utexas.edu/ srean/wip/missing.pdf.

487 
 
