PageRank as a Function of the Damping Factor⁄

DSI, Università degli Studi di

DSI, Università degli Studi di

Paolo Boldi

Milano

Massimo Santini

Milano

Sebastiano Vigna

DSI, Università degli Studi di

Milano

boldi@acm.org

msantini@acm.org

vigna@acm.org

ABSTRACT
PageRank is deﬁned as the stationary state of a Markov chain. The
chain is obtained by perturbing the transition matrix induced by
a web graph with a damping factor ﬁ that spreads uniformly part
of the rank. The choice of ﬁ is eminently empirical, and in most
cases the original suggestion ﬁ D 0:85 by Brin and Page is still
used. Recently, however, the behaviour of PageRank with respect
to changes in ﬁ was discovered to be useful in link-spam detec-
tion [21]. Moreover, an analytical justiﬁcation of the value chosen
for ﬁ is still missing. In this paper, we give the ﬁrst mathemati-
cal analysis of PageRank when ﬁ changes. In particular, we show
that, contrarily to popular belief, for real-world graphs values of ﬁ
close to 1 do not give a more meaningful ranking. Then, we give
closed-form formulae for PageRank derivatives of any order, and an
extension of the Power Method that approximates them with con-

vergence O¡tk ﬁt¢ for the k-th derivative. Finally, we show a tight

connection between iterated computation and analytical behaviour
by proving that the k-th iteration of the Power Method gives ex-
actly the PageRank value obtained using a Maclaurin polynomial
of degree k. The latter result paves the way towards the application
of analytical methods to the study of PageRank.

Categories and Subject Descriptors
G.2 [Discrete Mathematics]: Graph Theory; G.3 [Probability
and Statistics]: Markov processes

General Terms
Algorithms, Experimentation, Measurement

Keywords
Web graph, PageRank, Approximation

1.

INTRODUCTION

PageRank [17] is one of the most important ranking techniques
used in today’s search engines. Not only is PageRank a simple, ro-
bust and reliable way to measure the importance of web pages [3],
but it is also computationally advantageous with respect to other

⁄This work has been partially supported by a “Finanziamento per
grandi e mega attrezzature scientiﬁche” of the Università degli
Studi di Milano and by the MIUR COFIN Project “Linguaggi for-
mali e automi”.
Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2005, May 10-14, 2005, Chiba, Japan.
ACM 1-59593-046-9/05/0005.

ranking techniques in that it is query independent, and content inde-
pendent. Otherwise said, it can be computed ofﬂine using only the
web graph1 structure and then used later, as users submit queries to
the search engine, typically aggregated with other, query-dependent
rankings [4, 12, 16].

One suggestive way to describe the idea behind PageRank is as
follows: consider a random surfer that starts from a random page,
and at every time chooses the next page by clicking on one of the
links in the current page (selected uniformly at random among the
links present in the page). As a ﬁrst approximation, we could deﬁne
the rank of a page as the fraction of time that the surfer spent on that
page on the average. Clearly, important pages (i.e., pages that hap-
pen to be linked by many other pages, or by few important ones)
will be visited more often, which justiﬁes the deﬁnition. However,
we also allow the surfer to restart with probability 1 ¡ ﬁ from an-
other node chosen randomly and uniformly, instead of following a
link.

As remarked in [5], a signiﬁcant part of the current knowledge
about PageRank is scattered through the research laboratories of
large search engines, and its analysis “has remained largely in the
realm of trade secrets and economic competition”. As the authors
of the aforementioned paper, however, we believe that a scientiﬁc
and detailed study of PageRank is essential to our understanding
of the web, and we hope this paper can be a contribution in such
program.

PageRank is deﬁned formally as the stationary distribution of a
stochastic process whose states are the nodes of the web graph. The
process itself is obtained by combining the normalised adjacency
matrix of the web graph (with some patches for nodes without out-
links that will be discussed later) with a trivial uniform process that
is needed to make the combination irreducible and aperiodic, so
that the stationary distribution is well deﬁned. The combination
depends on a damping factor ﬁ 2 T0; 1/, which will play a major
rôle in this paper. When ﬁ is 0, the web-graph part of the process
is annihilated, resulting in the trivial uniform process. As ﬁ goes to
1, the web part becomes more and more important.

The problem of choosing ﬁ was curiously overlooked in the ﬁrst
papers about PageRank: yet, not only PageRank changes signiﬁ-
cantly when ﬁ is modiﬁed [19, 18], but also the relative ordering
of nodes determined by PageRank can be radically different [14].
The original value suggested by Brin and Page (ﬁ D 0:85) is the
most common choice. Intuitively, 1 ¡ ﬁ is an amount of ranking
that we agree to give uniformly at each page. This amount will be
then funneled through the outlinks of the node. A common form of
link spamming funnels carefully this amount towards a single page,
giving it a preposterously great importance.

1The web graph is the directed graph whose nodes are URLs and
whose arcs correspond to hyperlinks.

It is natural to wonder what is the best value of the damping
factor, if such a thing exists. In a way, when ﬁ gets close to 1 the
Markov process is closer to the “ideal” one, which would somehow
suggest that ﬁ should be chosen as close to 1 as possible. This
observation is not new, but it has some naivety in it.

The ﬁrst issue is of computational nature: PageRank is tradition-
ally computed using variants of the Power Method. The number of
iterations required for this method to converge grows with ﬁ, and
moreover more and more numerical precision is required as ﬁ gets
closer to 1.

But there is an even more fundamental reason not to choose a
value of ﬁ too close to 1: we shall prove in Section 3 that when ﬁ
goes to 1 PageRank gets concentrated in the recurrent states, which
correspond essentially to the nodes whose strongly connected com-
ponents have no passage toward other components. This phenom-
enon gives a null PageRank to all the pages in the core component,
something that is difﬁcult to explain and that is contrary to com-
mon sense. In other words, in real-word web graphs the rank of
all important nodes (in particular, all nodes of the core component)
goes to 0 as ﬁ goes to 1.

Thus, PageRank oscillates between a meaningless uniform dis-
tribution (ﬁ D 0) and a meaningless distribution concentrated most-
ly in irrelevant nodes (ﬁ D 1). As a result, both for choosing the
correct damping factor and for detecting link spamming, being able
to describe the behaviour of PageRank when ﬁ changes is essential.
Recently, indeed, a sophisticated form of link-spam detection has
been based on the study of the value of PageRank with respect to
ﬁ [21].

To proceed further in this direction, it is essential that we have
at our disposal analytical tools that describe this behaviour. To this
purpose, we shall provide closed-form formulae for the derivatives
of any order of PageRank with respect to ﬁ, and an iterative algo-
rithm (an extension of the power method) that approximates them.
The most surprising consequence, easily derived from our for-
mulae, is that the vectors computed during the PageRank computa-
tion for any ﬁ 2 .0; 1/ can be used to approximate PageRank for
every other ﬁ 2 .0; 1/. This happens because the k-th coefﬁcient of
the Maclaurin series for PageRank can be easily computed during
the k-th iteration of the Power Method. This allows to study easily
the behaviour of PageRank for any node storing a minimal amount
of data.2

2. BASIC DEFINITIONS

Let G be the adjacency matrix of a directed graph of N nodes
(identiﬁed hereafter with the numbers from 0 to N ¡ 1). A node is
terminal if it does not have outlinks, except possibly for loops (or,
equivalently, if all arcs incident on the node are incoming). If we
want to be speciﬁc about the presence of a loop, we shall use the
terms looped and loopless3.

We note that usually G is preprocessed before building the cor-
responding Markov chain. Common processing includes removal
of all loops (as nodes should not give authoritativeness to them-
selves) and thresholding the number of links coming from pages of
the same domain (to reduce the effect of link spamming).

all

Java

code

the

algorithms

implementing

2Free
de-
scribed in this paper will be available for download at
http://law.dsi.unimi.it/.
3In PageRank-related literature, loopless terminal nodes are more
commonly known as dangling nodes; the same kind of node is often
called a sink in graph-theoretic literature. Our choice avoids the
usage of ambiguous terms that have been given different meanings
in different papers.

If no loopless terminal nodes are present (note that after the pre-
processing sketched above they will be the only kind of terminal
nodes), we can just normalise uniformly to 1 the row-sums of G by
multiplying it by D¡1, the inverse of the diagonal degree matrix.
However, D is not invertible if loopless terminal nodes are present.
The classical way to handle this situation consists in substituting
them with nodes that have one outgoing arc toward every node (in-
cluding the node itself. In other words, in G rows of zeroes are
substituted with rows of ones.

Let NG be the (adjacency matrix of the) resulting graph, and ND be
the diagonal matrix of the outdegrees of NG (i.e., dii is the number of
ones on the i-th row of NG). Let also 1 be the vector4 of all 1’s, and
v be any personalisation vector (a vector whose elements are all
non-negative and sum to 1, which is used to bias PageRank w.r.t. a
selected set of trusted pages).

We are providing a toy example in the Appendix that will guide
the reader through the paper. In Table 5, the example graph G and
its modiﬁed version NG are presented.

In the rest of the paper, we shall use the matrices deﬁned in Fig-
ure 1; some of them are functions of the damping factor ﬁ 2 T0; 1/,
and we will use a notation reﬂecting this fact. Note that Q.ﬁ/ is
well deﬁned for all ﬁ 2 T0; 1/, as .I ¡ ﬁ P/ is known to be invert-
ible [20].

P VD ND¡1 NG

A.ﬁ/ VD ﬁ P C .1 ¡ ﬁ/1T
C.ﬁ/ VD I ¡ ﬁ P
Q.ﬁ/ VD PC.ﬁ/¡1

v

Figure 1: Basic PageRank deﬁnitions.

The PageRank vector r.ﬁ/ is deﬁned as the dominant eigenvec-
tor of A.ﬁ/; more precisely, as the only vector summing to 1 such
that r.ﬁ/A.ﬁ/ D r.ﬁ/. Noting that r.ﬁ/1T D 1, we get

r.ﬁ/¡ﬁ P C .1 ¡ ﬁ/1T

ﬁr.ﬁ/P C .1 ¡ ﬁ/v D r.ﬁ/

v¢ D r.ﬁ/

.1 ¡ ﬁ/v D r.ﬁ/.I ¡ ﬁ P/;

which yields the following closed formula for PageRank:

r.ﬁ/ D .1 ¡ ﬁ/vC.ﬁ/¡1:

(1)

This is Lemma 3 of [8], albeit in the original statement of this
lemma the factor 1 ¡ ﬁ is missing, probably due to an oversight.
Note that (1) can be written as

r.ﬁ/ D .1 ¡ ﬁ/v

.ﬁ P/t ;

1

Xt D0

which makes the dependence of PageRank on incoming paths very
explicit.

The reader can see the PageRank vector in Figure 7 (the prefer-
ence vector v is the uniform vector). PageRank is represented as a
function of ﬁ in Figure 8.

3. GENERAL BEHAVIOUR

In this section, we shall discuss the general behaviour of Page-
Rank as a function of the damping factor ﬁ, considering in particu-
lar what happens when ﬁ gets close to 1.
4All vectors in this paper are row vectors.

Recall that P (the row-normalised adjacency matrix) is a Markov
chain, but in general it is neither aperiodic nor irreducible. Usually,
though, in all practical cases P will be aperiodic, but reducible. In
this paper, we shall assume that P is indeed aperiodic.

Introducing the damping factor has the consequence of obtaining
an aperiodic irreducible chain.
Indeed, for all ﬁ 2 T0; 1U, A.ﬁ/
is a Markov chain; moreover, if ﬁ < 1, A.ﬁ/ is irreducible and
aperiodic. Hence, A.ﬁ/ admits a unique limit distribution r.ﬁ/.
3.1 Choosing the damping factor

Clearly, r.ﬁ/ is a rational (vector) function of ﬁ: usually, though,
one looks at r.ﬁ/ only for a speciﬁc value of ﬁ. All algorithms to
compute PageRank actually compute (or, more precisely, provide
an estimate of) r.ﬁ/ for some ﬁ that you plug in it, and it is by now
an established use to choose ﬁ D 0:85. This choice was indeed
proposed by Brin and Page [17], and it is rumored that Google
itself uses this value; it seems that the rankings obtained with this
choice are very natural and satisfactory for the users.

Many authors had tried to devise a more thorough a posteriori
justiﬁcation for 0:85.
It is easy to get convinced that choosing
a small value for ﬁ is not appropriate, because too much weight
would be given to the “uniform” part of A.ﬁ/: indeed, as we re-
marked in the introduction, A.0/ is the uniform matrix and r.0/ is
the uniform distribution.

Conversely, as ﬁ ! 1¡, the matrix A.ﬁ/ tends to P: this fact
seems to suggest that choosing ﬁ close to 1 should give a “truer”
or “better” PageRank:
this is a widely diffused opinion (as we
shall see, most probably a misconception). In any case, as we re-
marked in the introduction there are some computational obstacles
to choosing a value of ﬁ too close to 1. The Power Method con-
verges more and more slowly [9] as ﬁ ! 1¡, a fact that also in-
ﬂuences the other methods used to compute PageRank (which are,
after all, variants of the Power Method [17, 7, 6, 15, 11, 10]). In-
deed, the number of iterations required could in general be bounded
using the separation between the ﬁrst and the second eigenvalue,
but unfortunately the separation can be abysmally small if ﬁ D 1,
making this technique not applicable. Moreover, if ﬁ is large the
computation of PageRank may become numerically ill-conditioned
(essentially for the same reason [8]).
3.2 Getting close to 1

Even disregarding the problems discussed above, we shall pro-
vide convincing reasons that make it inadvisable to use a value of
ﬁ close to 1.

First observe that, since r.ﬁ/ is a rational (coordinatewise) bounded

function deﬁned on T0; 1/, the limit

r ⁄ D lim
ﬁ!1¡

r.ﬁ/

exists (the reader can see the vector r ⁄ for our example in the cap-
tion of Figure 7).

It is easy to see that r ⁄ is actually one of the limit distributions
of P (because limﬁ!1¡ A.ﬁ/ D P). There are some natural ques-
tions about r ⁄ that we want to address:

† can we somehow characterise the properties of r ⁄?

† what makes r ⁄ different from the other (inﬁnitely many, if P

is reducible) limit distributions of P?

The ﬁrst question is the most interesting, because it is about what
happens to PageRank when ﬁ ! 1¡; in a sense, fortunately, it is
also the easiest to answer.

Before doing this, recall some basic deﬁnitions and facts about

Markov chains.

† Given two states x and y, we say that x leads to y iff there is
some m > 0 such that there is a non-zero probability to go
from x to y in m steps.

† A state x is transient iff there is a state y such that x leads
to y but y does not lead to x. A state is recurrent iff it is not
transient.

† In every limit distribution p of an aperiodic Markov chain, if

px > 0 then x is recurrent [20].

Let us now introduce some graph-theoretical notation. Let G be

a graph.

† Given a node x of G, we write Tx UG for the (strongly con-

nected) component of G containing x.

† The component graph of G is a graph whose nodes are the
components of G, with an arc from Tx UG to TyUG iff there are
nodes x 0 2 Tx UG and y0 2 TyUG such that there is an arc from
x 0 to y0 in G. The component graph is acyclic, apart for the
possible presence of loops.

† If x, y are two nodes of G, we write x ˆG y iff there is a
nonempty directed path from x to y in G (by nonempty we
mean that the path should contain at least one arc).

Clearly, a node is recurrent in P iff Tx U NG is terminal; otherwise
said, x is recurrent (in the Markov chain P) iff x ˆ NG y implies
y ˆ NG x as well. Note that nodes with just a loop are recurrent
(and their component is looped, too).

We now turn to our characterisation theorem, which identiﬁes
recurrent states on the basis of G, rather than NG. The essence of the
theorem is that, for what concerns recurrent states, the difference
between G and NG is not signiﬁcant, unless there are no looped ter-
minal nodes among the components of G. The latter case, however,
is as pathological as periodicity in a large web graph.

THEOREM 1. Let G and P be deﬁned as above. Then:

1. if G has a component that is looped and terminal (in the
component graph), then a node is recurrent for P iff its com-
ponent is looped and terminal; hence, given any limit distri-
bution p for P, px > 0 implies that x is a node of G whose
component is looped and terminal;

2. if G does not contain a component that is looped and termi-

nal, then every node is recurrent.

PROOF. Note that x ˆ NG y means that there is a nonempty path
from x to y in NG. Such a path can be decomposed into a sequence
of (possibly empty) paths in G, from x D x0 to a loopless terminal
node y0, from a node x1 to a loopless terminal node y1, . . . , from
a node xk to yk D y. Moreover, either k > 0, or the only path (a
path from x to y in G) contains at least one arc.

For case (1), let x be contained in a looped terminal component,
and suppose that x ˆ NG y. By the observation above, this path in NG
can be decomposed into a sequence of paths of G towards loopless
terminal nodes, plus a ﬁnal path to y: but from x you cannot reach
a loopless terminal node of G (because x is contained in a looped
terminal component), so the path is simply a nonempty path of G,
i.e., x ˆG y. But then y is in the same component as x, so y ˆG x
as well, and we obtain the result. For the converse, suppose that x
is not in a looped terminal component: we will show that there is a
y such that x ˆ NG y but not y ˆ NG x. We distinguish two cases:

† suppose that there is a looped terminal component that can
be reached from Tx UG in the component graph of G; let y be
any node in such component. Clearly x ˆG y, and hence
x ˆ NG y, but y ˆ NG x does not hold (from y you can only
reach nodes of TyUG both in G and in NG);

† otherwise, suppose that there is a loopless terminal y such
that x ˆG y (or x D y if x itself is terminal); let z be any
node in a looped terminal component G: now x ˆ NG z (you
ﬁrst go from x to y and then you “jump” to z), but from z you
cannot reach x (because x is not in the same component).

THEOREM 2. The following identities hold:
1. r 0.ﬁ/ D .r.ﬁ/P ¡ v/C.ﬁ/¡1;
2. for all k > 0, r .kC1/.ﬁ/ D .k C 1/r .k/.ﬁ/PC.ﬁ/¡1.
PROOF. Multiplying (1) by C.ﬁ/ and differentiating member-

wise:

r.ﬁ/C 0.ﬁ/ C r 0.ﬁ/C.ﬁ/ D ¡v

r 0.ﬁ/C.ﬁ/ D ¡r.ﬁ/C 0.ﬁ/ ¡ v
r 0.ﬁ/C.ﬁ/ D r.ﬁ/P ¡ v:

(2)
(3)
(4)

For case (2), take any two nodes x and y of G. In the component
graph of G there will be two terminal components Tx 0UG and Ty0UG
that are reachable from Tx UG and TyUG, respectively. Both are, by
hypothesis, loopless. In other words, there are two terminal nodes
x 0 and y0 such that x ˆG x 0 (or x D x 0) and y ˆG y0 (or y D y0).
This means that x ˆ NG y and vice versa, unless x D y (and both are
terminal), in which case again both x ˆ NG y and vice versa.

The statement of the previous theorem may seem a bit unfath-
omable. The essence, however, could be stated as follows: except
for strongly connected graphs, or graphs whose terminal compo-
nents are all trivial and loopless, the recurrent nodes are exactly
those whose component is looped and terminal. These nodes are of-
ten called rank sinks, as they absorb all the rank circulating through
the graph.

As we remarked, a real-world graph will certainly contain at least
one looped terminal component, so the ﬁrst statement of the theo-
rem will hold. This means that most nodes x will be such that
r ⁄
x D 0.
In particular, this will be true of all the nodes in the
core component [13]: this result is somehow surprising, because
it means that many important Web pages (that are contained in the
core component) will have rank 0 in the limit (see, for instance,
node 0 in our example).

This is a rather convincing justiﬁcation that, contradicting the
common beliefs, choosing ﬁ too close to 1 does not provide any
good PageRank. Rather, PageRank becomes “sensible” somewhere
in between 0 and 1.

As far as the second question is concerned, we provide a

CONJECTURE 1. r ⁄ is the limit distribution of P when the start-

ing distribution is uniform, that is,

Since C.ﬁ/ is invertible:

r 0.ﬁ/ D .r.ﬁ/P ¡ v/C.ﬁ/¡1:

Moreover, differentiating once more (4), we obtain:

r 0.ﬁ/C 0.ﬁ/ C r 00.ﬁ/C.ﬁ/ D r 0.ﬁ/P

r 00.ﬁ/C.ﬁ/ D r 0.ﬁ/P ¡ r 0.ﬁ/C 0.ﬁ/
r 00.ﬁ/C.ﬁ/ D r 0.ﬁ/P C r 0.ﬁ/P

hence

r 00.ﬁ/ D 2r 0.ﬁ/PC.ﬁ/¡1;

which accounts for the base case (k D 1) of an induction for the
second statement. For the inductive step, again multiplying by
C.ﬁ/ and differentiating memberwise:
r .kC2/.ﬁ/C.ﬁ/ C r .kC1/.ﬁ/C 0.ﬁ/ D .k C 1/r .kC1/.ﬁ/P

and the thesis follows easily.

r .kC2/.ﬁ/C.ﬁ/ D r .kC1/.ﬁ/£.k C 1/P ¡ C 0.ﬁ/⁄

We can reformulate the statement concerning the ﬁrst-order deriva-

tive as follows:

COROLLARY 1. The following identity holds:

r 0.ﬁ/ D r.ﬁ/(cid:181)Q.ﬁ/ ¡

1

1 ¡ ﬁ

I¶ :

PROOF. From Theorem 2, we obtain r 0.ﬁ/ D r.ﬁ/PC.ﬁ/¡1 ¡

vC.ﬁ/¡1. Using (1) we can rewrite this as r.ﬁ/PC.ﬁ/¡1¡ 1
hence the result.

1¡ﬁ r.ﬁ/,

lim
ﬁ!1¡

r.ﬁ/ D lim
n!1

1
N

Pn :

Moreover, we can explicitly write a closed formula for the generic

derivative:

Note that the conjecture is trivial when P is irreducible, because in
that case P has but one stationary distribution.

4. DERIVATIVES

The reader should by now be convinced that the behaviour of
PageRank with respect to the damping factor is nonobvious: r.ﬁ/
should be considered a function of ﬁ, and studied as such.

The standard tool for understanding changes in a real function
is the analysis of its derivatives. Correspondingly, we are going to
provide mathematical support for this analysis.
4.1 Exact formulae

The main objective of this section is providing exact formulae
for the derivatives of r.¡/. Deﬁne r 0.ﬁ/, r 00.ﬁ/, . . . , r .k/.ﬁ/ as the
ﬁrst, second, . . . , k-th derivative of r.ﬁ/ with respect to ﬁ.

We start by providing the basic relations between these vector

functions:

COROLLARY 2. For every k > 0

r .k/.ﬁ/ D kW .r.ﬁ/P ¡ v/C.ﬁ/¡1 Q.ﬁ/k¡1

or, equivalently,

1

1 ¡ ﬁ

I¶ Q.ﬁ/k¡1:

r .k/.ﬁ/ D kW r.ﬁ/(cid:181)Q.ﬁ/ ¡

PROOF. Just proceed from Theorem 2 by iterate substitution,

and ﬁnally apply Corollary 1.
4.2 Approximating the derivatives

The formulae obtained in Section 4.1 do not lead directly to an
effective algorithm that computes derivatives: even assuming that
the exact value of r.ﬁ/ is available, to obtain the derivatives one
should invert C.ﬁ/ (see Theorem 2), a heavy (in fact, unfeasible)
computational task. However, in this section we shall provide a
way to obtain simultaneous approximations for PageRank and its

derivatives for a given value of ﬁ, and we will show how these
approximations converge to the desired vectors.

norm between the k-th iterate and the exact value is O¡ﬁk¢.

The simplest and most important algorithm that computes PageR-
ank [17] is an application of the Power Method; the algorithm
computes a sequence of vectors v0, v1, : : : where v0 D v and
vkC1 D vk A.ﬁ/. This sequence of vectors converges to r.ﬁ/, and
convergence speed depends on ﬁ; more precisely, the difference in
In
practice, the algorithm provides good approximation quickly: in
the original paper [17] the authors state that 40 to 50 iterations are
enough on reasonable data sets; of course, more sophisticated ap-
proaches have been proposed in the literature to reduce the number
of iterations and/or the amount of computation needed at each iter-
ation [17, 7, 6, 15, 11, 10], but they are basically all variants of the
Power Method.

The reader can see the ﬁrst few iterates of the Power Method

applied to our example in Figure 1.

t

We are going to present a modiﬁed version of the basic algorithm
that will compute PageRank and its derivatives up to (any desired)
index K , and to do this it will use K C 1 vectors. In other words, it
will build K C 1 vector sequences: the sequence s.0/
1 .ﬁ/,
: : : , s.0/
.ﬁ/, : : : will be used to approximate r.ﬁ/ (and will be
deﬁned exactly as in the classical PageRank algorithm); the se-
quence s.1/
.ﬁ/, : : : will be used to approxi-
mate r 0.ﬁ/; and so on. Note that the sequence s.k/
1 .ﬁ/, : : : ,
s.k/
.ﬁ/, : : : will not, in general, converge to r .k/.ﬁ/ per se; rather,
t
there will be an associated sequence q .k/
.ﬁ/,
: : : based on it, that will actually converge to the desired derivative.

1 .ﬁ/, : : : , s.1/
t

1 .ﬁ/, : : : , q.k/
t

0 .ﬁ/, q.k/

0 .ﬁ/, s.1/

0 .ﬁ/, s.0/

0 .ﬁ/, s.k/

s.0/
0 .ﬁ/ VD v
s.0/
t C1.ﬁ/ VD s.0/
t
s.kC1/
.ﬁ/ VD q.k/
0 .ﬁ/
0
.ﬁ/ VD ﬁs.kC1/
s.kC1/
t C1

t

.ﬁ/A.ﬁ/

.ﬁ/P C q.k/

t

.ﬁ/P

q.0/
t
q.1/
t
q.k/
t

.ﬁ/ VD s.0/
.ﬁ/ VD s.1/

t

t

.ﬁ/

.ﬁ/ ¡

.ﬁ/ VD ks.k/

t

.ﬁ/

1

s.0/
t

.ﬁ/

1 ¡ ﬁ
for all k ‚ 2:

Figure 2: Basic deﬁnitions for the approximation algorithm.

The vector sequences are deﬁned in Figure 2. Note that only the
.ﬁ/ (0 • k • K ) need to be stored, whereas
.ﬁ/ are only deﬁned for convenience, and can be implemented,

K C 1 vectors s.k/
q.k/
t
for example, as a function.

t

Our ﬁrst result is about convergence of the ﬁrst-order derivative.5
THEOREM 3. limt!1 q.1/

.ﬁ/ D r 0.ﬁ/, and the difference in

t

norm is O¡t ﬁt¢, that is:

q.1/
t

(cid:176)(cid:176)(cid:176)

5We do not assume a particular norm—all our proofs are correct
with any p-norm. We just note that kSk1 D 1 for any stochastic

.ﬁ/ ¡ r 0.ﬁ/(cid:176)(cid:176)(cid:176)
S (as we use row vectors), and so(cid:176)(cid:176)

D O¡t ﬁt¢ as t ! 1.
Pt(cid:176)(cid:176)p is bounded by a constant

that depends on P’s size, but not on P’s elements or on t.

.ﬁ/ ¡ r.ﬁ/(cid:176)(cid:176)(cid:176)
XsD0

t ¡1

PROOF. Recall that(cid:176)(cid:176)(cid:176)

q.0/
t

ond eigenvalue of A.ﬁ/ is at most ﬁ [9]. An easy proof by induction
shows that for all t

D O¡ﬁt¢, since the sec-

.ﬁ/ D v.ﬁ P/t C

q.0/
t ¡s¡1.ﬁ/.ﬁ P/s P;

s.1/
t

so

q.1/
t

.ﬁ/ D v.ﬁ P/t C

q.0/
t ¡s¡1.ﬁ/.ﬁ P/s P ¡

1

1 ¡ ﬁ

q.0/
t

.ﬁ/:

t ¡1

XsD0

Now, by Corollary 1, we have:

r 0.ﬁ/ D r.ﬁ/(cid:181)Q.ﬁ/ ¡

1

1 ¡ ﬁ

I¶ :

Since

Q.ﬁ/ D PC.ﬁ/¡1 D P.I ¡ ﬁ P/¡1 D

we have

1

r 0.ﬁ/ D

XsD0

r.ﬁ/.ﬁ P/s P ¡

1

1 ¡ ﬁ

r.ﬁ/:

Hence, we can bound the convergence rate as follows:

.ﬁ P/s P;

1

XsD0

1

t

t

1

1

C

C

t ¡1

(cid:176)(cid:176)(cid:176)

XsDt

r 0.ﬁ/ ¡ q.1/

C(cid:176)(cid:176)(cid:176)

•(cid:176)(cid:176)(cid:176)

r.ﬁ/ ¡ q.0/

C(cid:176)(cid:176)v.ﬁ P/t(cid:176)(cid:176) :

X /¡1 X n (whenever the ﬁrst series converges). Thus,

We provide an upper bound for each of the summands above. As
t Dn X t D .I ¡

.ﬁ/(cid:176)(cid:176)(cid:176)
XsDt
XsD0‡r.ﬁ/ ¡ q.0/
1 ¡ ﬁ (cid:176)(cid:176)(cid:176)

r.ﬁ/.ﬁ P/s P(cid:176)(cid:176)(cid:176)
t ¡s¡1.ﬁ/· .ﬁ P/s P(cid:176)(cid:176)(cid:176)
.ﬁ/(cid:176)(cid:176)(cid:176)
far as the ﬁrst summand is concerned, recall thatP1
(cid:176)(cid:176)(cid:176)
¢(cid:176)(cid:176).ﬁ P/t(cid:176)(cid:176) ¢ kr.ﬁ/Pk ;
and the ﬁrst summand is O¡ﬁt¢. The second summand can be
(cid:176)(cid:176)(cid:176)

XsD0‡r.ﬁ/ ¡ q.0/
t ¡s¡1.ﬁ/·.ﬁ P/s P(cid:176)(cid:176)(cid:176)
D O¡ﬁt¢(cid:176)(cid:176)(cid:176)
D O¡ﬁt¢
XsD0

PsC1(cid:176)(cid:176)(cid:176)
O.1/ D O¡t ﬁt¢:
The third and the fourth summands are both O¡ﬁt¢. All summands
are thus O¡t ﬁt¢—hence the result.

.I ¡ ﬁ P/¡1(cid:176)(cid:176)(cid:176)
•(cid:176)(cid:176)(cid:176)

r.ﬁ/.ﬁ P/s P(cid:176)(cid:176)(cid:176)

As far as the other derivatives are concerned, we have:
THEOREM 4. For every k > 1, limt!1 q.k/

bounded as follows:

.ﬁ/ D r .k/.ﬁ/,

XsD0

t ¡1

t ¡1

t ¡1

D

and the difference in norm is O¡tk ﬁt¢.

PROOF. First of all, by induction on k and t, one can prove that

t

s.k/
t

.ﬁ/ D .k ¡ 1/W

ﬁ

ﬁ ¡ 1

v.ﬁ P/t C

q.k¡1/
t ¡s¡1.ﬁ/.ﬁ P/s P;

t ¡1

XsD0

procedure step()

for i:=0, 1, : : : , N ¡ 1 do
for k:=0, 1, : : : , K do

s0Tk; i U VD 0;

end for

end for
for i:=0, 1, : : : , N ¡ 1 do
d:=outdegree of node i;
for all successors j of i do

.ﬁ/(cid:176)(cid:176)(cid:176)

s0T0; j U:=s0T0; j U C ﬁ C q(0, i)=d;
for k:= 1, 2, : : : , K do

s0Tk; j U:=s0Tk; j U C .ﬁsTk; i U C q(k ¡ 1, i)/=d;

•

end for

end for

end for

procedure computePageRankAndDerivatives()

init();
do step(); while not stopping condition;

for all k > 1 and all t. The base case t D 0 is trivial (by an easy
induction on all k > 1), whereas the case k D 2 can be obtained by
induction on t using Theorem 3, noting that the rule for computing
q.1/
.ﬁ/ is a special case. The inductive step is then obtained using
t
the rule that deﬁnes s.kC1/

.ﬁ/.

t C1

Now, recalling that (from Theorem 2)

r .k/.ﬁ/ D kr .k¡1/.ﬁ/PC.ﬁ/¡1 D k

r .k¡1/.ﬁ/.ﬁ P/s P;

1

XsD0

we have

(cid:176)(cid:176)(cid:176)

1

XsDt

k(cid:176)(cid:176)(cid:176)

r .k/.ﬁ/ ¡ q.k/

t

r .k¡1/.ﬁ/.ﬁ P/s P¡ks.k/

t

1

k

D(cid:176)(cid:176)(cid:176)

.ﬁ/(cid:176)(cid:176)(cid:176)
XsD0
r .k¡1/.ﬁ/.ﬁ P/s P(cid:176)(cid:176)(cid:176)
C k(cid:176)(cid:176)(cid:176)

t ¡1

C kW

ﬁ

1 ¡ ﬁ (cid:176)(cid:176)v.ﬁ P/t(cid:176)(cid:176) C
t ¡s¡1.ﬁ/· .ﬁ P/s P(cid:176)(cid:176)(cid:176)

:

XsD0‡r .k¡1/.ﬁ/ ¡ q.k¡1/

The result follows along the lines of the last part of the proof of
Theorem 3.

We remark two important points that deserve further analysis.
First of all, the big-oh notation hides a number of constants in-
dependent of t. However, when k is large or ﬁ very close to 1
these constants may become important. Second, we did not give a
detailed evaluation of the numerical precision that is necessary to
perform these computations.
4.3 Implementation of the algorithm

The results of the previous section can be used to modify the
classical PageRank algorithm, based on the Power Method, so to
compute an approximation of the derivatives of PageRank up to a
certain index.

The algorithm uses a vector sT¡; ¡U where the ﬁrst index rep-
resents the derivative index (from 0 to K , inclusive, where K is
the highest derivative order to be computed) and the second index
represents the node. In other words, at step t the vector sTk; ¡U
represents s.k/
.ﬁ/ is not itself represented as a
vector, but rather it is implemented by the procedure q().

.ﬁ/. The vector q.k/

t

t

The procedure init() initialises the vector sT¡; ¡U, whereas step()
computes the vector for the next iteration (the new vector is indi-
cated by s0T¡; ¡U).

The stopping criterion can be decided in many ways: for exam-
ple, at each step, the norms of the differences between each deriva-
tive and the derivative at the previous step are computed, and the
iteration is stopped if all such norms are below a certain threshold.

procedure q(k, i)

if k=0 then return sT0; i U;
else if k=1 then return sT1; i U ¡ sT0; i U=.1 ¡ ﬁ/;
else return k ¢ sTk; i U;

procedure init()

for i:=0, 1, : : : , N ¡ 1 do

sT0; i U:=vTi U;
for k:=1, : : : , K do

sTk; i U:=q(k ¡ 1, i);

end for

end for

5. MACLAURIN SERIES

The rational function r.¡/ can be expressed using its Maclaurin
series (e.g., the Taylor series about 0); let us denote by tn .ﬁ/ the
n-th degree Maclaurin polynomial of r.¡/ evaluated in ﬁ.

Clearly, Maclaurin polynomials offer an appealing way to study
PageRank in relation to ﬁ. To obtain an explicit formula for tn .ﬁ/,
just recall from Corollary 2 that r .k/.0/ D kW r.0/.Q.0/¡I /Q.0/k¡1.
Since r.0/ D v and Q.0/ D P, we have, for all k > 0,

r .k/.0/ D kW v.P ¡ I /Pk¡1:

Now, since tn .ﬁ/ DPn

kD0.1=kW/ﬁk r .k/.0/, we have

tn .ﬁ/ D v(cid:181)I C

n

XkD1

ﬁk¡Pk ¡ Pk¡1¢¶:

Two important problems face us now: ﬁrst of all, how to compute
tn .ﬁ/; second, how to choose n. Both problems will be solved by
a surprisingly simple relationship between Maclaurin polynomials
and the Power Method that will be proved in this section. To obtain
our main result, we will need the following:

LEMMA 1. Let C be a set of square matrices of the same size,
and R 2 C such that for every M 2 C we have M R D R. Then
for all M 2 C , ‚ 2 R and for all n we have

.‚M C .1 ¡ ‚/R/n D ‚n Mn C .1 ¡ ‚/

‚k R Mk :

n¡1

XkD0

or, equivalently,

.‚M C.1¡‚/R/n D ‚n Mn CR.I ¡‚n Mn¡1/CR

n¡1

XkD1

‚k¡Mk ¡Mk¡1¢:

PROOF. By an easy induction. The ﬁrst statement is trivial for
n D 0. If we multiply both members by ‚M C .1 ¡ ‚/R on the

right we have
.‚M C .1 ¡ ‚/R/nC1 D

‚nC1 MnC1 C .1 ¡ ‚/

C .1 ¡ ‚/2

n¡1

XkD0

‚k R D

D ‚nC1 MnC1 C .1 ¡ ‚/

C .1 ¡ ‚/2 1 ¡ ‚n
1 ¡ ‚

R D

‚kC1 R MkC1 C ‚n .1 ¡ ‚/RC

n¡1

XkD0

‚kC1 R MkC1 C ‚n .1 ¡ ‚/RC

n¡1

XkD0

D ‚nC1 MnC1 C .1 ¡ ‚/

‚k R Mk :

n

XkD0

The second statement can be then proved by expanding the summa-
tion and collecting monomials according to the powers of ‚.

Of course, the last result can be easily restated in any R-algebra.

We can now come to the main result of this section, which equates
analytic approximation (the degree of the Maclaurin polynomial)
with computational approximation (the number of iterations of the
Power Method):

THEOREM 5. The n-th approximation of PageRank computed
by the Power Method with damping factor ﬁ coincides with the n-
th degree Maclaurin polynomial of PageRank evaluated in ﬁ. In
other words, v A.ﬁ/n D tn .ﬁ/.

PROOF. Apply Lemma 1 to the case when M D P, R D 1T v

and ‚ D ﬁ. We have:

A.ﬁ/n D ﬁn Pn C1T

v ¡ ﬁn1T

v Pn¡1 C1T

v

n¡1

XkD1

ﬁk¡Pk ¡ Pk¡1¢;

hence

q.0/
n .ﬁ/ D v A.ﬁ/n D

D ﬁn

v Pn C v ¡ ﬁn

v Pn¡1 C v

D v C v

n¡1

XkD1

n¡1

ﬁk¡Pk ¡ Pk¡1¢ D
XkD1
ﬁk¡Pk ¡ Pk¡1¢ D tn .ﬁ/:

As a consequence:

COROLLARY 3. The difference between the k-th and the .k ¡

1/-th approximation of PageRank (as computed by the Power Method),
divided by ﬁk, is the k-th coefﬁcient6 of the Maclaurin series of
PageRank.

can be used to compute immediately PageRank for any other ﬁ,
obtaining the result of the Power Method after the same number of
iterations. Indeed, by saving the Maclaurin coefﬁcients during the
computation of PageRank with a speciﬁc ﬁ it is possible to study
the behaviour of PageRank when ﬁ varies. Even more is true, of
course: using standard series derivation techniques, one can ap-
proximate the k-th derivative (lowering of course by k the approxi-
mating polynomial). Note, however, that the algorithm presented in
Section 4.3 provides values of the derivatives for a speciﬁc ﬁ with
a precision guarantee.

The ﬁrst few coefﬁcients of the Maclaurin polynomial for our

example are shown in Figure 2.

6. EXPERIMENTAL RESULTS

Figure 3 illustrates from an experimental viewpoint the conver-
gence speed theorems of Section 4.2. We computed PageRank and
its derivatives up to index four (inclusive) and we plotted the differ-
ence, in L2-norm (we used for the computation a small, 325 557-
nodes graph of the sites of the Italian CNR), between two succes-
sive iterates during the ﬁrst 70 iterations; for every derivative we
also show the upper bounds proved in Theorems 3 and 4. Note that
there is a transient irregular behaviour due to the constants hidden
in the proofs.

Figure 4 shows the convergence of Maclaurin polynomials to-
ward the actual PageRank behaviour for a chosen node. Finally,
in Figure 9 we display the approximation obtained with a 100-
degree Maclaurin polynomial. We choose four nodes with differ-
ent behaviours (monotonic increasing/decreasing, unimodal con-
cave/convex) to show that the approximation is excellent in all these
cases. For this experiment we used a 41 291 594-nodes snapshot of
the Italian web gathered by UbiCrawler [1] and indexed by Web-
Graph [2].

 1000

 100

 10

 1

 0.1

 0.01

 0.001

 0.0001

 1e-05

 1e-06

 1e-07

0
1
2
3
4

 0

 10  20  30  40  50  60  70

Figure 3: The convergence speed in the computation of deriva-
tives up to order 4 (the label is the order of the derivative).

The previous corollary is apparently innocuous. However, as a
consequence the data obtained computing PageRank for a given ﬁ
6The coefﬁcients are vectors, because we are approximating a vec-
tor function.

7. CONCLUSIONS

We have presented a number of results which outline the ﬁrst an-
alytic study of PageRank when the damping factor changes. While
our results are mainly theoretical in nature, they provide efﬁcient

 3.5e-08

 3e-08

 2.5e-08

 2e-08

 1.5e-08

 1e-08

10
20
30
40
50
100

 5e-09

 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98  1

Figure 4: Approximating r.ﬁ/ for a speciﬁc node (cross-
shaped points) using Maclaurin polynomials of different de-
grees (shown in the legend).

ways to study the global behaviour of PageRank, and dispel a few
myths (in particular, about the signiﬁcance of PageRank when ﬁ
gets close to 1).

A last point that is worth being noted is that our algorithm to
obtain the Maclaurin polynomials for PageRank may be used to
determine new forms of ranking; for example, one may deﬁne the
0 rx .ﬁ/ dﬁ. This quantity (the area under
the PageRank curve of node x) is independent from ﬁ, and induces
interesting rankings that will be studied in a forthcoming paper.

total rank of a page x asR 1

8. REFERENCES
[1] Paolo Boldi, Bruno Codenotti, Massimo Santini, and

Sebastiano Vigna. Ubicrawler: A scalable fully distributed
web crawler. Software: Practice & Experience,
34(8):711–726, 2004.

[2] Paolo Boldi and Sebastiano Vigna. The WebGraph

framework I: Compression techniques. In Proc. WWW 13,
pages 595–601, Manhattan, USA, 2004. ACM Press.
[3] Soumen Chakrabarti, Byron Dom, David Gibson, Jon

Kleinberg, S. Ravi Kumar, Prabhakar Raghavan, Sridhar
Rajagopalan, and Andrew Tomkins. Hypersearching the web.
Scientiﬁc American, June 1999.

[4] Scott C. Deerwester, Susan T. Dumais, Thomas K. Landauer,

George W. Furnas, and Richard A. Harshman. Indexing by
latent semantic analysis. Journal of the American Society of
Information Science, 41(6):391–407, 1990.

[5] Nadav Eiron, Kevin S. McCurley, and John A. Tomlin.

Ranking the web frontier. In Proceedings of the thirteenth
international conference on World–Wide Web, pages
309–318. ACM Press, 2004.

[6] Gene H. Golub and Chen Greif. Arnoldi-type algorithms for
computing stationary distribution vectors, with application to
PageRank. Technical Report SCCM-04-15, Stanford
University Technical Report, 2004.

[7] Taher Haveliwala. Efﬁcient computation of PageRank.
Technical report, Stanford University Technical Report,
October 1999.

[8] Taher Haveliwala and Sepandar Kamvar. The condition
number of the PageRank problem. Technical Report 36,
Stanford University Technical Report, June 2003.

[9] Taher Haveliwala and Sepandar Kamvar. The second

eigenvalue of the Google matrix. Technical Report 20,
Stanford University Technical Report, March 2003.

[10] Sepandar Kamvar, Taher Haveliwala, Christopher Manning,

and Gene Golub. Exploiting the block structure of the web
for computing PageRank. Technical Report 17, Stanford
University Technical Report, March 2003.

[11] Sepandar D. Kamvar, Taher H. Haveliwala, Christopher D.

Manning, and Gene H. Golub. Extrapolation methods for
accelerating PageRank computations. In Proceedings of the
twelfth international conference on World Wide Web, pages
261–270. ACM Press, 2003.

[12] Jon M. Kleinberg. Authoritative sources in a hyperlinked

environment. Journal of the ACM, 46(5):604–632,
September 1999.

[13] Ravi Kumar, Prabhakar Raghavan, Sridhar Rajagopalan,

D. Sivakumar, Andrew Tomkins, and Eli Upfal. The Web as
a graph. In Proc. 19th ACM SIGACT-SIGMOD-AIGART
Symp. Principles of Database Systems, PODS, pages 1–10.
ACM Press, 2000.

[14] Amy N. Langville and Carl D. Meyer. Deeper inside

PageRank. Internet Mathematics, 1(3):355–400, 2004.

[15] Chris Pan-Chi Lee, Gene H. Golub, and Stefanos A. Zenios.
A fast two-stage algorithm for computing PageRank and its
extensions. Technical report, Stanford University Technical
Report, 2004.

[16] Ronny Lempel and Shlomo Moran. SALSA: the stochastic
approach for link-structure analysis. ACM Trans. Inf. Syst.,
19(2):131–160, 2001.

[17] Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry

Winograd. The PageRank citation ranking: Bringing order to
the web. Technical report, Stanford Digital Library
Technologies Project, Stanford University, Stanford, CA,
USA, 1998.

[18] Luca Pretto. A theoretical analysis of google’s PageRank. In

Proceedings of the Ninth Symposium on String Processing
and Information Retrieval, pages 131–144, 2002.

[19] Luca Pretto. A theoretical approach to link analysis

algorithms, 2002. PhD Thesis.

[20] Eugene Seneta. Non-Negative Matrices and Markov Chains.

Springer Series in Statistics. Springer-Verlag, 1981.

[21] Hui Zhang, Ashish Goel, Ramesh Govindan, Kahn Mason,

and Benjamin Van Roy. Making eigenvector-based
reputation systems robust to collusion. In Stefano Leonardi,
editor, Proceedings WAW 2004, number 3243 in LNCS,
pages 92–104. Springer-Verlag, 2004.

Appendix: An example
To clarify the discussion of the previous section, we provide a full
example in Figure 5. Node 3 is the only terminal node of the graph,
but nodes 4 and 5 belong to a looped terminal component (see Fig-
ure 6). Correspondingly, Figure 8 shows that PageRank for nodes
4 and 5 grows, whereas for all other nodes goes to 0 as ﬁ ! 1¡.
Note, however, the maximum attained by node 0 at ﬁ … 0:7.

Step Approximation

0
1
2
3
4

h0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100i
h0:415; 0:049; 0:075; 0:075; 0:113; 0:070; 0:049; 0:049; 0:049; 0:049i
h0:232; 0:100; 0:051; 0:062; 0:078; 0:072; 0:100; 0:100; 0:100; 0:100i
h0:391; 0:066; 0:070; 0:049; 0:097; 0:056; 0:066; 0:066; 0:066; 0:066i
h0:283; 0:093; 0:054; 0:056; 0:076; 0:063; 0:093; 0:093; 0:093; 0:093i

Table 1: The approximations computed in the ﬁrst iterations of the Power Method (with ﬁ D 0:85).

r.ﬁ/ D*¡5

8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200

.¡1 C ﬁ/‡ﬁ2 C 18 ﬁ C 4·
.¡1 C ﬁ/‡11 ﬁ2 C 8 ﬁ3 ¡ 10 ﬁ ¡ 20·
.¡1 C ﬁ/‡10 C 2 ﬁ C ﬁ2·

8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200

; ¡2

8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200

; ¡

¡2

; ¡2

.¡1 C ﬁ/‡10 C 2 ﬁ C ﬁ2·

8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200

; 2

.¡1 C ﬁ/‡7 ﬁ2 ¡ 5 ﬁ ¡ 10·

8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200

;

ﬁ4 C 16 ﬁ3 C 14 ﬁ2 ¡ 30 ﬁ ¡ 20

15 ﬁ3 C 6 ﬁ2 ¡ 20 ﬁ ¡ 20

.ﬁ C 1/¡8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200¢

.¡1 C ﬁ/‡10 C 2 ﬁ C ﬁ2·

8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200

; ¡2

.ﬁ C 1/¡8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200¢

.¡1 C ﬁ/‡10 C 2 ﬁ C ﬁ2·

8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200

; ¡2

.¡1 C ﬁ/‡10 C 2 ﬁ C ﬁ2·
8 ﬁ4 C ﬁ3 ¡ 170 ﬁ2 ¡ 20 ﬁ C 200+

; ¡

;

Figure 7: The explicit formula for PageRank as a function of ﬁ. Its limit is limﬁ!1¡ r.ﬁ/ D r ⁄ D h0; 0; 0; 0; 1=2; 1=2; 0; 0; 0; 0i.

0

6

7

8

9

1

4

2

3

0

5

6

7

8

9

1

4

2

3

5

 0.5

Figure 5: A graph with n D 10 nodes and its modiﬁed version.

 node 0
 node 1
 node 2
 node 3
 node 4
 node 5
 node 6
 node 7
 node 8
 node 9

 0.4

 0.3

 0.2

 0.1

0

1

6

7

8

9

2

3

4

5

0, 1, 2,
6, 7, 8, 9

3

4, 5

 0

 0

 0.2

 0.4

 0.6

 0.8

 1

Figure 6: The components of the graph in Figure 5 and the
corresponding component graph. The dashed line in the com-
ponent graph gathers components that are merged in NG. In
both G and NG the only terminal component is f 4; 5 g.

Figure 8: The behaviour of the components of r.ﬁ/. They all go
to zero except for nodes 4 and 5—the only nodes belonging to a
terminal component. Note, however, the maximum attained by
node 0 at ﬁ … 0:7.

Coefﬁcient
h0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100; 0:100i
h0:371; ¡0:058; ¡0:028; ¡0:028; 0:015; ¡0:034; ¡0:058; ¡0:058; ¡0:058; ¡0:058i
h¡0:253; 0:070; ¡0:033; ¡0:018; ¡0:048; 0:003; 0:070; 0:070; 0:070; 0:070i
h0:260; ¡0:055; 0:030; ¡0:021; 0:032; ¡0:026; ¡0:055; ¡0:055; ¡0:055; ¡0:055i
h¡0:207; 0:050; ¡0:029; 0:013; ¡0:040; 0:012; 0:050; 0:050; 0:050; 0:050i

ﬁ0
ﬁ1
ﬁ2
ﬁ3
ﬁ4

Table 2: The coefﬁcients of the Maclaurin series.

 2.6e-08

 2.4e-08

 2.2e-08

 2e-08

 1.8e-08

 1.6e-08

 1.4e-08

 1.2e-08

 0

 0.2

 0.4

 0.6

 0.8

 1

 1e-08

 8e-09

 0

 0.2

 0.4

 0.6

 0.8

 1

 5.5e-08

 5e-08

 4.5e-08

 4e-08

 3.5e-08

 3e-08

 2.5e-08

 2e-08

 0

 0.2

 0.4

 0.6

 0.8

 1

 1.5e-08

 0

 0.2

 0.4

 0.6

 0.8

 1

 1e-07

 9e-08

 8e-08

 7e-08

 6e-08

 5e-08

 4e-08

 3e-08

 2e-08

 3.5e-08

 3e-08

 2.5e-08

 2e-08

 1.5e-08

 1e-08

 5e-09

Figure 9: Examples of approximations obtained using a Maclaurin polynomial of degree 100, for nodes with different behaviours
(the points were tabulated by computing PageRank explicitly with 100 regularly spaced values of ﬁ).

