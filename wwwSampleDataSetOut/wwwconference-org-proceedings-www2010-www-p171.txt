Graph-Based Concept Identiﬁcation and Disambiguation

for Enterprise Search

Falk Brauer

SAP AG, SAP Research

Dresden, Germany
falk.brauer@sap.com

∗
Michael Huber
ARITHNEA GmbH

Taufkirchen, Germany

michael.huber@arithnea.de

Gregor Hackenbroich
SAP AG, SAP Research

Dresden, Germany

gregor.hackenbroich@sap.com

Ulf Leser

Humboldt-Universitaet

Berlin, Germany

leser@informatik.hu-berlin.de

Felix Naumann

Hasso-Plattner-Institut

Potsdam, Germany
naumann@hpi.uni-

potsdam.de

Wojciech M. Barczynski

SAP AG, SAP Research

Dresden, Germany

wojciech.barczynski@sap.com

ABSTRACT
Enterprise Search (ES) is different from traditional IR due to a
number of reasons, among which the high level of ambiguity of
terms in queries and documents and existence of graph-structured
enterprise data (ontologies) that describe the concepts of interest
and their relationships to each other, are the most important ones.
Our method identiﬁes concepts from the enterprise ontology in
the query and corpus. We propose a ranking scheme for ontology
sub-graphs on top of approximately matched token q-grams. The
ranking leverages the graph-structure of the ontology to incorpo-
rate not explicitly mentioned concepts. It improves previous so-
lutions by using a ﬁne-grained ranking function that is speciﬁcally
designed to cope with high levels of ambiguity. This method is able
to capture much more of the semantics of queries and documents
than previous techniques. We prove this claim by an evaluation of
our method in three real-life scenarios from two different domains,
and found it to consistently be superior both in terms of precision
and recall.
Categories and Subject Descriptors
H.3.1 [Content Analysis and Indexing]: [Thesauruses, Indexing
methods]; D.2 [Data Structures]: Graphs and networks
General Terms
Algorithms
1. ENTERPRISE SEARCH

Enterprise Search (ES) is different from searching a digital li-
brary or the web in many aspects [8]. One of the major differences
is that the corpora to be searched are highly speciﬁc and centered
around a set of Enterprise Concepts (EC), which describe the com-
pany’s business, such as products, purchase orders, etc. These ECs
are often captured in knowledge bases in the form of enterprise on-
tologies [17]. Using the knowledge about ECs for enterprise search
promises to capture more of the semantics within documents and
within queries and to thus improve search results. But this promise
∗Work has been done while afﬁliated with SAP Research.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2010, April 26–30, 2010, Raleigh, North Carolina, USA.
ACM 978-1-60558-799-8/10/04.

is impeded by numerous problems. In particular, it is difﬁcult to
identify ECs in text due to syntactic heterogeneity and ambiguity.
This paper describes a system for improving the identiﬁcation and
disambiguation of ECs, which in turn helps to improve the quality
of search results. Before we describe our approach in more detail,
we will describe a number of use-cases in which a technique like
the one presented here offers real business value.
1.1 Searching in Developer Networks

Developer networks (DNs) are community platforms for cus-
tomers and developers of software companies that help ﬁnd solu-
tions to given problems. Typically, such a network consists of a
large unstructured knowledge base of answered questions, techni-
cal notes, software documentation, etc., which can be searched by
customers. DNs have proven themselves in reducing the cost of
support by encouraging customers to self-support, assuming that
most customer problems are re-occurring. Consequently, most soft-
ware companies today provide a DN [44].

Documents within a DN capture information about a speciﬁc
topic, such as the solution to a known bug in a product or details
on conﬁguring a piece of software. However, ﬁnding a solution to
a speciﬁc problem is not as easy as it might seem. In fact, it has
been estimated that many of the forum questions have already been
answered at the time they are posted, but were not found [41].

Evidently, queries as well as documents deal with products or
concepts of the company (ECs)
[34]. A natural way to improve
response quality is thus to ﬁrst identify all ECs in a query and
match those to ECs in documents. However, usually neither queries
nor documents mention concepts in the same way as they are de-
scribed in a knowledge base. Users often use ad-hoc abbreviations,
drop tokens in multi-token concepts, mis-spell tokens, intersperse
their queries with error messages, trace snippets or code examples.
We highlight these difﬁculties with a concrete system, which also
serves as our running example throughout the paper. Note, that our
approach is especially helpful in answering queries that are short
text messages (> 5 tokens) rather than only keywords, which com-
prise 10% to 15% of the distinct queries, i.e. 600,000 per week, in
our example scenario.

The SAP Community Network (SCN) is a developer network for
all users of SAP software. Thus, almost every entry in the SCN
must relate to a SAP software product. The concepts used in SAPs
products and all their related components are maintained in SAP’s

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA171inhouse terminology SAPTerm1. SAPTerm comprises several ten
thousands of software components (“Component” in Fig. 1), orga-
nized in a disjoint union of hierarchies with a maximum depth of
eight. Combinations of components form the blueprints for soft-
ware products. In addition, SAPTerm contains hundred thousands
of technical terms (“Term” in Fig. 1) and corresponding acronyms
(“Variant” in Fig. 1), each associated with certain software compo-
nents. Technical terms also are associated among each other, point-
ing to synonyms, homonyms, etc. The different classes of ECs are
called EC types (bold border in Fig. 1). Each EC has a number of
attached textual attributes, such as long- and short-name of com-
ponents (“long_form” and “long_form” in Fig. 1) or the canonical
name for technical terms (“canon_form” in Fig. 1)

Figure 1: Schema of SAP Terminology Database

The availability of this background knowledge can be leveraged
to increase precision and recall when searching the SCN. But on
average only one third of all forum entries contain at least one com-
ponent name exactly as it appears in SAPTerm. This has many rea-
sons. First, EC names are often composed of multiple tokens, some
of which are often dropped in texts and queries. Second, EC names
and their individual tokens are highly ambiguous, i.e., they appear
multiple times in different contexts in SAPTerm. Third, names are
often abbreviated (and abbreviations are, again, highly ambiguous).
Last, the content of the SCN - as with many other DNs - is usually
not edited but consists of ad-hoc queries and answers that are full
of typos, ungrammatical sentences, ad-hoc abbreviations, jargon,
false names, etc. Additionally, as mentioned before, ECs are orga-
nized in hierarchies of concepts that subsume each other. Having
matched several ECs, a search engine has to decide which level of
the hierarchy is the most suitable to be considered in an answer.
Thus, even if customers would use exactly the predeﬁned compo-
nent names from SAPTerm in their searches, they would still miss
important hits.
1.2 Further Usage Scenarios

Proper identiﬁcation of ECs in text has many applications. Here,
we shortly describe two more of them. Note that these, in addition
to searching DNs, are also addressed in the evaluation in Sec. 6.

Routing support requests. SAP’s customers can subscribe to
commercial customer support. Thus, customers send support re-
quests via email and are provided with professional answers within
certain time constraints. Every such customer request must be
routed to an appropriate technician. The 1st level support routes
inquiries to experts of the 2nd level support, each being responsible

for a small set of software components. The routing requires man-
ual effort to ensure the correct mapping between request text and
addressed software component. If ECs could be identiﬁed automat-
ically, this routing could be sped up considerably, if not automated
completely.

Searching movie reviews. Searching movie reviews is concep-
tually similar to searching DNs. Entertainment companies main-
tain platforms for users to contribute movie reviews. Before buying
certain articles such as DVDs, users can browse opinions about a
movie. Movie reviews and queries for them reference movies or
actors directly and indirectly, e.g., by co-occurrence of a actor’s
real and cast name. Leveraging a graph-structured knowledge base
such as the Internet Movie Database (IMDB)2 allows for identiﬁ-
cation of movies and disambiguation of, e.g., actor names in movie
reviews when referenced only by their ambiguous surname.
1.3 Concept Identiﬁcation in Documents

Our approach for solving the problems outlined in the preceding
sections is based on the identiﬁcation of concepts from an enter-
prise ontology in queries and documents. More speciﬁcally, our
system ﬁrst takes a query and a DAG-structured3 enterprise ontol-
ogy as input. It identiﬁes the most relevant ECs for each text and
for the query. In doing so, it also considers information that is di-
rectly or indirectly associated with the EC within the ontology. For
each text (and the query), a subgraph of the enterprise ontology is
computed, which consists of all identiﬁed ECs and their neighbor-
hoods. These graphs are called document concept graphs (DCG)
and consist of nodes that represent matches between text and ECs’
derived from the ontology. Each EC within a DCG is scored re-
spectively. In the last step, all documents are ranked by computing
the similarity of the documents’ DCG with the DCG of the query.
The document ranking using relevant graphs retrieved via Infor-
mation Extraction (IE) was implemented successfully in the RankIE
System (Ranking on IE Graphs), presented in [7]. In this paper we
concentrate on the problem of identiﬁcation of the most relevant
ECs in documents wrt. the given enterprise ontology. We evaluate
our solution in all three previously discussed use cases.

In the following section, we present the main challenges in EC
ranking and disambiguation by means of an example. Our methods
for identifying ECs with high precision and recall despite spelling
errors, high level of ambiguity, and incomplete mentions are intro-
duced in Sec. 3. EC ranking is explained in Sec. 4. After consid-
ering related work in Sec. 5, we discuss experiments that illustrate
the practicability of our approach in Sec. 6.
2. PROBLEMS IN ENTERPRISE SEARCH
As explained above, the most prominent difference between en-
terprise search and other search scenarios is the availability of a
set of interconnected ECs. A typical (naive) approach to enterprise
search is to exactly match those ECs in documents and use the in-
tersection of matched ECs in the query and in a document from the
corpus as a score. However, this fails to (a) leverage the relation-
ships between ECs as encoded in the enterprise ontology and (b)
falls short in adequately considering lexical variations. In this sec-
tion, we describe the problems using a sample of 120,000 forum
entries created in the beginning of 2008. One such forum entry is
shown in Fig. 2.i. We start our analysis using only the 16,000 long
and short names of components in SAPTerm and later also consider
technical terms and acronyms. In the following, we use the word
“term” for any of these, i.e., textual values attached to components,
technical terms, and acronyms.

1http://help.sap.com/content/additional/
terminology

2http://imdb.com/
3DAG: Directed Acyclic Graph

Componentlong_formshort_formis_part_ofTermcanon_formPOSentry_typesubj_refterm1Term_crosslinkterm2classificationVariantlong_formterm_refclassification1**1**1***WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA172Figure 2: Mapping the text of a SCN forum entry to the enterprise ontology SAPTerm : Segments of the text are mapped to concepts
of the ontology. Partial, fuzzy, and indirect concept identiﬁcation techniques are required to achieve a good recall and precision.
2.1 Recall

the match on “operation”, a term assigned to “PM” in the knowl-
edge base (see Fig. 2.ii.d). This additional match would raise the
relevance of “Plant Maintainance”. However, the exemplary entry
contains many more additional hits that are assigned to the concept
“BC-XI” (see Fig. 2.ii). As a consequence, our approach would
rank “BC-XI” best. Note that such a technique allows the proper
identiﬁcation of components not only in situations where an am-
biguous concept is found, but also in cases where no component
name was matched at all. E.g., we may recognize the compo-
nent “BC-JAS” (abbreviaton for “Java Application Server”) by the
context information that “Conﬁguration Adapter Framework” (see
Fig. 2.ii.f) is a technical term related to the component “BC-JAS”
which would otherwise be neglected.

Another strategy to cope with ambiguity is to simply disregard
all possible matches except one. A popular choice is to always
consider the longest match as the correct one [51]. However, such
a method often fails in our case. For instance, the match “Con-
ﬁguration Adapter Framework” in Fig. 2.ii.b is the longest match
between text and ECs. But, in the given scenario the shorter match
“Adapter Framework” provides an clue towards “BC-XI”. Indeed,
here the user addressed “conﬁguration” of the “Adapter Frame-
work” and not the “Conﬁguration Adapter Framework”. Therefore,
all matches should be considered, though longer matches might ob-
tain a higher weight.
2.3 Aggregation and Abstraction of ECs

A dictionary-based approach identiﬁes only 37,000 exact occur-
rences of component names in the 120,000 forum entries. Assum-
ing that almost every forum entry addresses a problem in the setting
of at least one software component, this rate certainly is unsatis-
factory. Only 10% of matched names were longer than one token
while over 83% of the terms in SAPTerm contain more than one
token. Thus, partial matching strategies are needed to increase the
recall. Partial matches are more ambiguous than the full names are.
Another impediment to high recall is the fact that SCN forum
content often is error-prone. Therefore, fuzzy lookup strategies are
required that are able to ﬁnd names even in the presence of typos.
One such example can be seen in Fig. 2.ii.b where the user typed
“adaptor” though “Adapter” would have been the correct term. The
drawback is that a signiﬁcant number of terms are highly similar.
Thus, any fuzzy search strategy adds to the problem of ambiguity
and hence harms precision. Actually, after incorporating partial and
fuzzy matching methods to increase recall, we measured that 98%
of all matches were ambiguous.
2.2 Precision

Ambiguity is a major problem in any sizable enterprise ontol-
ogy. In SAPTerm, only 30% of all terms are distinct and consist
of only 23,000 distinct tokens. The most frequent token in compo-
nent names, “Management”, appears in approximate 3,600 terms.
A natural way to cope with such ambiguity is to consider addi-
tional, disambiguating information attached to the concepts. This
is possible by using the technical terms and acronyms assigned to
components. An extreme example for ambiguity is the component
name “PM” (long name is “Plant Maintenance”). Only about 10%
of “PM” matches refer to the EC in our knowledge base, while
90% of “PM” matches occured in a timestamp (see Fig. 2.ii.e).
For instance, one may consider the co-occurrence of “PM” with

The dictionary-based approach failed completely for ﬁnding ab-
stract components such as “AP” (aka. “Application Platform”) or
“BC” (aka. “Basic Components”). Those were never matched
directly in any of the 120,000 forum entries. However, in many
situations such abstract EC should be ranked top, e.g., when a
user addresses a integration problem between two or more “sub-
components”. We can identify abstract components by leveraging

VariantsAIIearly adaptorXI:  configuration adaptor frameworkBesides message exchange functionality of an adaptor, the Exchange Infrastructure  Adaptor Framework defines a series of requirements that an XI service interface must fulfill operation and support by SAP. Edited at Feb 4, 2008 9:07 PMXIBC-CCMIS-TExchange InfrastructureEnterprise ConceptsTextual DataPMChunksconfiguration adaptor  frameworkadaptor frameworkXIadaptorExchange InfrastructureoperationSAPservice access pointoperationPMSAPISBCTextual Data:   abc   -  chunk             - selected match   abc   - relevant for BC-XI Structured Data:           - matched chunk q-gram             - enterprise concept           - relevant sub-graph           - matches           - relatedToTXIBC-XIAdapter Frameworkoperationf(i)fabcdegLEGENDConfiguration Adapter  FrameworkBC-JASComponentTerms(ii)(iii)WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA173the pre-deﬁned relations among ECs and aggregate matches of re-
lated more concrete ECs to abstract ECs. However, this is not as
simple as it seems. Consider Fig. 2.iii.g. Here, we need to rank
“BC-XI” best and not “BC”, because the match of “BC-JAS” was
caused by ambiguity. Thus, carefully chosen aggregation strate-
gies are required to balance selections of more concrete or more
abstract ECs.
3. MATCHING ENTERPRISE CONCEPTS
Before we describe our ranking procedure in Sec. 4, we explain
how we ﬁnd potential ECs in a text. The main difﬁculty in this
step is that terms assigned to ECs often consist of many tokens of
which only a few may appear in a text, often interspersed with other
words and possibly in different orders. Further, we need to obtain
meaningful and detailed weights for each occurrence of a term in a
text as a basis for ranking later on.

There are two approaches to tackle this problem [49]: (1) sliding
windows, or (2) matching text chunks. The ﬁrst approach slides
a window over the text and scores each window by searching all
its tokens in the list of all tokens contained in any of the terms.
When terms also contain many “normal” words, as in the case of
SAPTerm, this method typically suffers from a very large num-
ber of token matches, resulting in a non-zero score for virtually
every window, thereby decreasing the performance. This prob-
lem becomes worse as the window size increases. In the case of
SAPTerm, where the longest terms comprise twelve tokens, a win-
dow size above 15 would have to be used to safely recognize all
terms, taking into account that token occurrences are usually inter-
spersed. Recently, Chandel et al. [10] proposed to prune the list of
recognized tokens by using a TF-IDF-based ranking scheme. How-
ever, a TF-IDF-based approach assumes statistical independence of
token occurrences, which leads to improper estimates when tokens
are highly ambiguous and the order of tokens is important (e.g,
“Adapter Framework” or “Conﬁguration Adapter Framework”). An-
other drawback of the sliding window approach is that it disregards
the grammatical structure of a sentence. Thus, a fragment such
as “Conﬁguration failed because the XI Adapter Framework ...”
would potentially (depending on the window size) obtain a high
score for the term “Conﬁguration Adapter Framework” compared
to the term “Adapter Framework”, an error no human reader would
ever make. Furthermore, “Adapter Framework” would get a higher
TF-IDF than “XI”, assuming a similar IDF, because it is built from
only one token. Further, “because” would obtain a high support
through IDF because it occurs twice in SAPTerm.

The second approach partitions the text into chunks and then
matches each chunk against the ontology. Assuming a sensible
chunking, this method adequately deals with token sequences (as
the whole chunk is used for comparison and not its individual to-
kens) and adapts the number of tokens that are matched. The con-
ventional approach for achieving a sensible chunking is using a
shallow parser [48], which breaks a sentence into grammatical units,
among which verbal phrases (VP) and noun phrases (NP) are the
most important ones. Such a linguistically-informed chunking also
solves the problem of ungrammatical matches and prunes many
less relevant matches, such as “because”.

Due to these advantages, we use the 2nd approach. SAPTerm’s
textual contents, such as component names or technical terms, are
(almost) always sequences of nouns potentially accompanied by
some modiﬁers such as adjectives. Therefore, we can safely as-
sume that their occurrence in a text will be inside a NP, which are
further used as chunks for matching. NPs are among those linguis-
tic structures that can be identiﬁed quite accurately.

Our entire term matching process breaks up into three steps:
(1) document pre-processing, (2) indexing the enterprise ontology

to speed up the matching phase, and (3) ﬁnding and weighting
matches between the NPs of the document and the indexed terms
from the enterprise ontology. After matching, all discovered terms
are used to rank ECs, as described in Section 4.
3.1 Text Pre-Processing

All texts are subjected to pre-processing. Therein, we ﬁrst sepa-
rate grammatical text from ungrammatical insertions, such as ex-
ception traces or code snippets. Separation is based on simple
heuristics that mostly use speciﬁc regular expressions to identify
typical insertions. Ungrammatical text parts are not considered fur-
ther. Grammatical text parts are broken into sentences. We prune
all sentences as ungrammatical text that would lead to unusual long
sentences (e.g., 1000 characters). Within sentences, NPs are tagged
by a state-of-the-art shallow parser.
3.2 Indexing the Ontology

To speed up the matching phase (see Sec. 3.3), we index all terms
of the ontology. As we also want to ﬁnd partial matches, thus we
not only index entire terms, but also their token subsequences, i.e.,
all their token q-grams. For instance, the term t =“Conﬁguration
Adapter Framework” ≡ abc results in six q-grams being indexed,
i.e., {˜t1, . . . , ˜t6} ≡ {a,b,c,ab,bc, abc}. Because we use all q-grams
(from q = 1 up to the length of the term), this method also cap-
tures reordered appearance of tokens in a text. Thus, the occur-
rence “Adapter Conﬁguration” would still match the above term,
but with a lower score than “Conﬁguration Adapter”.

We build one index structure per term class (see Fig. 1). Each
index is organized as a preﬁx tree that maps from q-grams to terms.
Its size grows at a manageable rate compared to a single token
index, because string values can be compressed by incremental
preﬁx-encoding (see [6] for details).

A particular problem occurs for extremely ambiguous q-grams,
i.e., those q-grams that occur frequently in the ontology. If those are
found in a text, the number of matches with the ontology becomes
extremely large (several thousand for SAPTerm and hundreds of
thousands for IMDB). Since such extremely ambiguous q-grams
carry very little information but incur high processing cost, we dis-
regard all q-grams that are more frequent than a threshold k, but
ensure that at least one q-gram of each term remains in the index.
We use a value for k (k = 250) that is so high that only very am-
biguous q-grams are pruned, leaving the ﬁnal ranking essentially
unchanged. Using preﬁx encoding and pruning of ambiguous q-
grams, the resulting index size for SAPTerm is only twice that of
a simple token index, but captures much more semantics in respect
to the sequence of tokens.

We add two more remarks: First, our pruning strategy inher-
ently prefers longer q-grams over shorter q-grams, as shorter q-
grams are in general more frequent and are therefore pruned more
often. Second, we deliberately build one index per term class,
as the distribution of tokens and token q-grams is quite different
within each class. Accordingly, a term in the class “component -
long_form” should be valued differently from a match in the class
“technical term - canon_form” (see Fig.1). Thus, e.g., the q-gram
“Management” in “component - long_form” remains in the index
(still highly ambiguous), while it is pruned for “technical term -
canon_form”.
3.3 Matching NPs and Ontology Concepts

At runtime, each NP is translated to a disjunctive query, contain-
ing all its token q-grams, against the ontology index. We retrieve
all matches from the index and keep only the longest one for each
matched term. For instance, the NP c ≡ abc results in the query
for the six q-grams {˜c1, . . . , ˜c6} ≡ {a,b,c,ab,bc,abc}. Given a

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA174term t ≡ axbc with ten q-grams ˜t1, . . . , ˜t10, we would ﬁnd four
matched q-grams, but derive only two of them, i.e. ˜c1 ≡ a ≡ ˜t1
and ˜c5 ≡ bc ≡ ˜t6. Each matched pair of term and NP q-gram
˜c ≡ ˜t is weighted with respect to its coverage of the matched term
t using the following formula:

wq(˜t, ˜c) =

|˜t|
|t| · pT.

Here, pT is a factor speciﬁc for each term class. Using this fac-
tor one can, for instance, give long names of components a higher
weight than short acronyms. Thus, the match of ˜t ≡ bc derived
from t ≡ axbc would obtain a weight of wq(˜t, t) = 2/4 assuming
that pT = 1. Note that these weights are pre-computed and stored
in the term index.

As explained in Sec. 2, fuzzy matching is important to allow for
linguistic variations and typos in texts. To this end, we actually
consider as matches all q-grams ˜t that are sufﬁciently similar to a
NP q-gram ˜c. We use pre-ﬁx ﬁltering [11] to speed up this look-up.
Similarity between term and NP q-grams is computed using Lev-
enshtein [42] distance sim, length-normalized by the number of
characters in the NP q-gram |˜c|. In principle, we consider all q-
grams as matches for which this value is larger than a similarity
threshold s. However, we found that in practice a further scaling
of the similarity value with 1/sim performs better, since it pun-
ishes a high edit distance more effectively. Together, the similarity
wsim ∈ [0, 1] is computed as

wsim(˜t, ˜c) =

1

sim(˜c, ˜t) + 1

1 − min arg(sim(˜c, ˜t),|˜c|)

|˜c|

(cid:19)

.

(cid:18)

Ambiguity is the most crucial problem when matching terms.
Not only q-gram matches derived from one NP q-gram ˜c are af-
ﬂicted with ambiguity. Sequences of matches overlap and intersect
each other. For instance assume that we found with c ≡ abcxd the
four matching term q-grams: ˜c1 ≡ ab ≡ { ˜t1, ˜t2}, ˜c2 ≡ bc ≡ { ˜t3}
and ˜c3 ≡ d ≡ { ˜t4}. Therein, the semantic of the NP sub-sequence
˜c1 ∪ ˜c2 ≡ abc remains unclear. To alleviate this problem, previ-
ous approaches prune (1) shorter matches and (2) more ambiguous
ones. Such a method often fails when identifying ECs as discussed
in Sec. 2. Thus, we keep all matches and weight each ˜t ≡ ˜c with
respect to the length of the match sequence it is contained in. Such
a match sequence c(cid:48) of a matching q-gram ˜t ≡ ˜c is the subsequence
of tokens from c that is derived by extending ˜c in c recursively with
overlapping and also matching NP q-grams. Finally, the ambiguity
weight is computed as

wamb(˜t, ˜c) =

(1 − pout)

N (˜t)

· |˜t|
|c(cid:48)| , ˜c ∈ c

(cid:48)

.

(1)

Here, N (˜t) is the number of term q-grams matched by the same
˜c and pout is a tunable parameter to adjust the individual weight of
a match by a general tendency that ˜c does not refer to any term in
the ontology, but rather to a term outside the known domain. Note
that pout also ensures that interspersed matches get a lower weight
than consecutive ones. Further, we use the raw N (˜t) without log-
arithmic smoothing because terms which occur frequently in the
ontology, occur similarly frequently in a text. Thus, the discrimi-
native nature of N (˜t) is balanced through the term frequency in a
text as discussed later on.
Figure 3 summarizes the computation of wamb and wq described
in this section. The NP c ≡ xabcye is broken into its q-grams
˜c1, . . . , ˜cn. Five term q-grams ˜t1, . . . , ˜t5 are matched by a ˜ci.
The value wamb is computed for each ˜ti (assuming pout = 1/5).
Therein, the semantically vague match sequence of ˜t1, . . . , ˜t4 is
c(cid:48) = abc leading to |c(cid:48)| = 3. The weight of q-gram ˜t5 is not
lowered through other intersecting matches. Finally, wq estimates
the coverage for each term q-gram ˜t with respect to its originating

term t. An equal weight pT = 1 for all term classes was used to
calculate wq for simpliﬁcation.

Figure 3: Matching and conﬁdence computation

3.4 Scoring Ontology Terms

Individual matches in a NP c are aggregated into a conﬁdence
score wconf (t, c) for a term t by summing the aggregated weights
of all matched q-grams ˜t ≡ ˜c, ˜t ∈ t, ˜c ∈ c. We normalize the in-
dividual scores by the number of non intersecting match sequences
in a NP, denoted as S(c), kept from calculations of wamb (see Eq.
1) to ensure wconf (t, c) ∈ [0, 1]. This leads to

wconf (t, c) =

wq(˜t, ˜c) · wsim(˜t, ˜c) · wamb(˜t, ˜c)

.

(2)

˜t∈t

S(c)

(cid:88)

The calculated conﬁdence score is used for ranking ECs with
respect to the whole document as explained in next section. We
store for each term match the ID of the EC that the term is assigned
to, the conﬁdence score, and the span of the NP, deﬁned as begin
and end index in the text.
4. GRAPHICAL MODEL AND RANKING
In the following, we introduce a graph-based model for ranking
ECs. Further, we discuss the application of ranked ECs for docu-
ment retrieval.
4.1 Document Concept Graphs

To rank ECs, we represent the text and the ontology in a uniﬁed
graph-based model, the so-called document concept graph. To rank
ECs, the following points have to be addressed: First, a term might
occur in several noun phrases (NPs) of a document. Next, sev-
eral terms might be assigned to one EC, such as the long and short
name of a software component, as illustrated in Fig. 1. Further, the
relations of ECs as deﬁned in the ontology have to be taken into
account to (1) disambiguate matches and (2) rank ECs that were
not directly matched through their assigned terms.

The document concept graph (DCG) represents term matches
and ECs in their ontological context. Formally, a DCG is a directed
acyclic graph G = (N, E, LE, LR). N is a set of nodes, E ⊆
N × N a set of edges, and LN and LE a set of node and edge labels
respectively. Nodes are either of type Term or of type EC. Each
term occurrence in an NP of the text is represented as a node (e.g.,
two distinct matches for “XI” in Fig. 2.ii.c). In the following, we
denote a term match in a NP by t. Further, we denote the conﬁdence
score between a term match t and an EC ε (see Eq. 2), as sconf (ε, t).
Several terms assigned to an EC lead to a higher certainty for this
EC, e.g., occurrences of long and short names. Several occurrences
of identical terms in several NPs increase certainty as well.

The graph-based model supports two basic types of relation-
ships: “match”-edges between matched terms and ECs and directed

Matching and scoringPre-processingzabc,     zab,     zbz,   eabxabcye, .,abc,..,ab,..,b,..,eabc,     ab,     ab,     b,    exabcyec=c1,..,cn=~~t1,.., t5=~~wamb=t1,.., t4=4/54/154/154/54/15wq=The configuration adaptor framework of XI ...3/42/31/32/31/3Text=WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA175“related to”-edges, between ECs as derived from the ontology. A
conﬁguration ﬁle determines the direction of relations between EC-
types, that is used to propagate scores in a DCG, e.g., from Variant
to Component for SAPTerm (see Fig.1). Such conﬁguration is sim-
ple for ontologies with less EC-types, such as SAPTerm or IMDB
(see Sec. 1). Approaches for weighting the importance of EC types
by statistics (e.g., [53]) may automate such conﬁguration in future.
An exemplary DCG that illustrates typical match situations is
shown in Fig. 4. Here, two NPs, namely c1, c2, match six terms
t1, . . . , t6. Eight ECs, i.e. EC1, . . . , EC8, are either directly or
indirectly connected to the matched terms.

Figure 4: Illustration of a Document Concept Graph.

4.2 Ranking Function for ECs

A DCG is used to score ECs for a given text. Based on the de-
composition of a text into NPs with assigned term matches, we can
express the score of a directly matched ECs simply as the sum over
conﬁdence scores of all terms that are assigned to an EC and were
matched by an NP. However, many relevant ECs are not directly
matched. Therefore, we introduce matching paths that spread con-
ﬁdence scores through the whole DCG. Let MP(ε, t) denote such a
matching path, i.e. a connected sequence of edges e1, . . . , em ∈ G
that link a matched term t with an EC ε. The weight of the “match”-
edge e1 ∈ MP is determined by the conﬁdence score (see Sec. 3.3).
The weights of edges ek ∈ MP, k (cid:54)= 1, that were derived from the
ontology, are adjusted by a decay as w(ek) = (1 − pself ), k (cid:54)= 1.
The parameter pself speciﬁes the extend to which the start node ε
of e dominates the scoring.

We also assign weights to nodes in the DCG. In the following,
let ε denote any EC, D a text, t any matched term in a NP of D, and
MP(ε, t) a matching path. The initial weight of any t in a DCG is
w(t) = 1/|D|, where |D| is the number of all term matches, thus
ensuring an upper bound of 1 for the ﬁnal score. The contribution
of matching paths to the score of an EC depends on its constituent
edge sequence e1, . . . , en ∈ MP that connects matches and ECs.
To summarize this section, we compute the score for an EC s(ε, D)
as

s(ε, D) =

w(t)

w(e).

(3)

MP(ε,t)

e∈MP

The derived scores for ECs lead to a novel, ﬁne grained ranking
of ECs using matching and aggregation strategies of various gran-
ularity. For the example in Fig. 2, we obtain a ranked list of sev-
eral hundred ECs in the order “BC-XI”, “BC”, “AII”, etc. Indeed
“BC-XI” is the most relevant EC with respect to the given text. It
gets a signiﬁcant higher score than the directly matched component
“PM”, because of the support through many matched terms in its
ontological context. Second and third ranked ECs are meaningful
as well in the context of a integration problem.

Furthermore, we realize that “Adapter Framework” in the con-
stituent sub-graph of “BC-XI” is a more likely interpretation for the
corresponding text segment than “Conﬁguration Adapter Frame-

(cid:88)

(cid:88)

t∈D

(cid:89)

work” in the sense of “BC-JAS”, and that “operation” is more likely
to be interpreted in the sense of “BC” than in that of “PM”.
4.3 Document Retrieval using ECs

Our approach aims to increase the performance of document re-
trieval in enterprise search. In the following, we explain brieﬂy the
application of the computed scores to rank documents.

After document processing as described in previous sections, the
highest scored ECs and their subsumed sub-graphs are stored. The
sub-graphs capture the most likely disambiguated sense of matches.
The EC scores capture the relevance for each EC in the actual con-
text. User queries are analyzed in the same way. A user may re-rank
ECs and discard false positives (see [7] for details). For comput-
ing the similarity between a query and previously processed docu-
ments, we represent them as vectors of EC scores, denoted as (cid:104)T(cid:105),
that encode their respective graphs’ structure. To rank documents,
we compute the cosine similarity between query Tquery and a doc-
ument Tdoc as

sim(Tquery, Tdoc) = cos(θ) =

(cid:104)Tquery(cid:105) · (cid:104)Tdoc(cid:105)
||Tquery||||Tdoc||.

(4)

Notice that the results of such an approach, although it captures
much more semantics than traditional Information Retrieval (IR)
techniques, are narrowed by the coverage of the ontology with re-
spect to the corpus. In order to address a broader range of queries,
our document ranking method is combined with previous IR sys-
tems by using rank aggregation techniques, such as [20].
5. RELATED WORK

This work touches upon several research areas. We shall discuss
its relationship with coreference resolution, semantically enhanced
document retrieval, search within (semi-)structured data sources
and ontologies, named entity recognition, as well as concept dis-
ambiguation and identiﬁcation.

Coreference Resolution. The problem discussed in this paper
can be viewed as a graph-based deduplication problem (see [21]
for a recent survey), where one of the objects under study is de-
scribed in a structured form (the enterprise ontology), whereas the
other is described in an unstructured fashion (forum entries, query).
Recent work has started to address less rigidly structured instances,
such as XML objects (e.g., [45]). We are not aware of deduplica-
tion approaches encompassing unstructured and structured data.

Semantically enhanced Document Retrieval. Information re-
trieval using structured knowledge bases is not an entirely new idea.
Many approaches leverage WordNet as an ontology (e.g., [46, 46,
36, 43]) that captures word senses and not ECs. Multi token con-
cepts are not addressed, which are of intrinsic importance in en-
terprise search. Approaches in this a area augment documents and
queries by synonym sets acquired during a rather simple, graph
intersection based disambiguation step. The ambiguity in Word-
Net is much lower, e.g., [43] reports on an average number of 3.1
senses per term. Further, our approach provides a list of EC sub-
graphs with scored concepts. [37] proposes to assign documents to
an ontology for enterprise search, but does not suggest a method
for matching and scoring ECs. EntityRank [13] ranks documents
that are linked by recognized concepts. Pre-deﬁned relationships
are not addressed.

Keyword search on (semi-)structured data. Some elements
of our ranking schemes resemble ideas proposed in the area of
keyword search over (semi-)structured data. For a given keyword
query a list of ranked joint tuple trees (JJTs) of a database or sub-
trees of a XML-document are generated that match all keywords.
Most methods leverage IR-style ranking. PageRank is favored by
[3, 30]. In our case, the direction of relations is ﬁxed by the type

Textc1c2t1t3t2t4t6t5OntologyEC1EC2EC3EC7EC6EC8EC5EC4WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA176of documents that are under investigation, e.g., for movie reviews
only the relations towards movies are relevant. A TF-IDF-style
ranking was discussed in [33, 28, 35, 54] by interpreting a query
and JJTs as “bag of words”, which proves inadequate when queries
are documents as in our case. Further, less compact JJTs are pruned
intensively [35, 32, 29, 26, 23], which leads to a decrease in accu-
racy for long queries (longer than eight tokens), as indicated in the
experiments of [54]. To the best of our knowledge, extremely long,
ambiguous queries (such as small documents) have not been stud-
ied in this area.

Keyword search on ontologies. Many approaches tackle search
within ontologies, such as [47, 19, 31]. NAGA [31] ranks an-
swers for structured queries. [47] provides answers for keyword
queries on ontologies. It uses a spread activation method in the on-
tology graph comparable to PageRank. SWOOGLE [19] addition-
ally leverages character q-gram similarity for matching queries and
concepts. However, character q-gram similarity performs poorly
for short terms such as acronyms (e.g., discussed in [52]). There-
fore, we do not use this feature, but rely on edit distance.

Geographic Information Retrieval. A closely related ﬁeld is
geographic information retrieval (GIR) [39]. Given a query, GIR
tries to match the geographic references from the query with geo-
graphic information extracted from documents using a spatial vicin-
ity (see for instance [12]), which is not possible in our case. Web-a-
Where [2] uses geographic taxonomies to determine the focus area
of a web page. Recognized location names are assigned a conﬁ-
dence value in certain match situations, e.g., 0.5 if the location is
ambiguous. Finally, the most relevant abstraction level in the tax-
onomy, an instance of city, state, or country is chosen, given a list
of matched locations with different abstraction levels. There are
important differences to our approach: Geospatial names usually
comprise much fewer tokens (usually one). Our approach addresses
a much higher level of ambiguity and computes conﬁdence scores
based on the constituent match situation between text and ECs.

Named Entity Recognition. Rule based and supervised learn-
ing methods for named entity recognition aim to extract unknown
concepts, which is beyond the scope of this paper. Many efﬁcient
algorithms for dictionary matching have been proposed [42]. So
far, only [10] addressed the recognition of top-k multi-token con-
cepts using dictionaries. Matches in a sliding text window are
weighted by token-based TF-IDF. However, such weighting tends
to provide improper estimates for ECs that contain highly ambigu-
ous tokens as discussed in Sec. 3. Furthermore, our approach ranks
the identiﬁed top-k ECs for a complete text and considers implicit
occurrences.

Concept Disambiguation. The problem of concept disambigua-
tion in text has been studied intensively. There are two general ap-
proaches in this area. The ﬁrst class of approaches employs data
acquired during bootstrapping or supervised learning that is stored
in an entity proﬁle for each concept and is used for disambiguation
at run time [18, 22, 4, 18]. Among the use cases presented in Sec. 1
only one offers a large annotated training corpus. A comparison
to a machine learning approach leveraging this data is discussed
in Sec. 6. Other approaches for disambiguation use structured ref-
erence data, similar to our approach. For instance [27] presented
an application speciﬁc approach to disambiguate person names.
[16] employed Wikipedia as reference data. Flat lists of context
concepts are used for disambiguation. Approaches such as [46, 25,
36] use WordNet for disambiguation. They essentially target the
disambiguation of words, not multi token concepts. Further, all
discussed approaches disambiguate explicitly mentioned concepts
in texts and do not consider implicit mentions.

Concept Identiﬁcation. Some previous work approached the

problem of linking an unstructured data source to a structured one.
[24] proposed relevance ranking of directly matched life-science
concepts using IDF-style word weights and weights that prefer “cor-
rectly” ordered tokens with respect to EC names. Our approach
additionally considers the structure of the ontology, uses token q-
grams to match EC names, and weights occurrences by the con-
stituent match situation. The work [40] investigated the identiﬁca-
tion of record-like ECs in text – no relations among ECs were con-
sidered. EROCS [9], the most similar system, allows the identiﬁ-
cation of ECs organized as trees. The ECs (also indirectly matched
ones) having the highest aggregated TF-IDF scores are identiﬁed
within sentence boundaries, which are ﬁnally used to determine an
optimal segmentation of a text with regard to ECs. Thus, EROCS
assumes that each sentence relates to one concept. A ﬁne grained
scoring was not targeted. Further, our approach outputs a ranked
list of entities that are mentioned across sentence boundaries, not a
segmentation.
6. EXPERIMENTS

We conducted an experimental study to compare our system’s
performance in ranking ECs with respect to documents. Assuming
that users are provided with an interface that allows to reﬁne the
information needs wrt. ECs, EC identiﬁcation in documents is the
most crucial processing step of the system.

We are not aware of any other method that solves exactly the
same problem we tackle in this work. However, to implement a
comparative study, we use three data sets to compare to related
approaches [33, 3, 30, 5, 40, 9, 22]. Furthermore, we study the
inﬂuence of the most important parameters of our ranking model.
The experiments were conducted on a desktop machine with a
2.0GHz double core processor and 3GB RAM running Windows
Vista. All DCGs were stored in a database. The system itself was
implemented in Java using the RapidUIM platform [7]. For token
based TF-IDF scoring, ECs were indexed with Lucene4 using its
white space tokenizer together with a stop word ﬁlter. We used
the LingPipe NLP API5 to implement a machine learning approach
with a language model classiﬁer.

Before discussing the achieved results in detail, we introduce the
data sets and the evaluation metrics, that have been used for our
experiments.
6.1 Data Sets and Metrics

SCN. The gold standard for the SCN-scenario as described in
the course of this paper was created by SAP experts. The ex-
perts created a ranked list of ECs, denoted as Un, with nmin =
2, nmax = 10 and ¯n ≈ 3.6 relevant software components of
SAPTerm for 100 randomly chosen forum entries. Note, that the
experts could discard forum entries that were not in their expertise.
CSS. We acquired a corpus of 7,700 real customer inquiries to
address the routing of support messages within the SAP Customer
Support Service (CSS) as described in Sec. 1. Support employ-
ees assigned a SAPTerm component for routing the inquiry to an
expert. We took these assignments as a gold standard and consid-
ered only the problem description for EC identiﬁcation. Because
of the huge amount of tagged data, we compare to a machine learn-
ing approach [22] in this scenario. 10% of the documents were
used as test corpus and the remaining 7,000 documents to train the
Language Model based classiﬁer. The training corpus consists of
5,000,000 words tagged with 1,500 components of SAPTerm. We
removed documents from the test corpus that were assigned to com-
ponents, which could not trained by at least 50 documents.

4http://lucene.apache.org/
5http://alias-i.com/lingpipe

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA177REVIEW. For the movie-review search introduced in Sec. 1,
we crawled 214 reviews of the most popular movies between 1920
and 19906. These reviews were split into segments of 8 sentences,
which allows to treat them as key word query for a web search en-
gine. Finally, more than 1,000 distinct documents for evaluation
were available. We removed the movie names at the beginning
of the articles, but kept them for evaluation. We left other occur-
rences of movie names in the documents, e.g., that point to previous
movies of actors. Finally, the Internet Movie Database (IMDB) was
applied as knowledge base in this scenario. The publicly available
web sites of IMDB, which provide exactly the same information as
the raw IMDB data, allowed a performance comparison with web
search engines. Web search engines interpret each EC as docu-
ment, thus, compares to previous approaches, such as [33, 29, 1,
28, 3, 30] (further explanations follow).

Knowledge Bases. We evaluate rankings of SAPTerm compo-

nents for SCN and CSS, and IMDB’s movies for REVIEW.

We considered only the English version of SAPTerm, that con-
tained 16,117 components with the term classes: short name and
long name; 112,381 technical terms and 20,579 variants. Apart
from the relations between variants, technical terms and compo-
nents, SAPTerm contains 15,789 relations among components. The
relations between technical terms were not further considered.

The IMDB was acquired via publicly available plain text ex-
ports and parsed into a RDBMS. The RDBMS contains 1,224,983
movie names and 263,542 alternative movie names (in the sense
of "‘also known as"’); 2,296,365 person names and 513,112 aka.
person names; 2,075,439 character names and 194,057 company
names. Apart from the relations between alternative and correct
names for movies and persons we counted 16,421,791 n-to-m re-
lations between movies, characters, and persons, 1,473,773 rela-
tions among companies and movies, and 785,818 relations between
movies (e.g., ‘remake of’,‘spin off from’, etc.). All these relation-
ships were used for ranking ECs.

Evaluation Metrics. Our approach can be seen as a reverse IR
task: Documents are queries and concepts of a structured vocabu-
lary (usually the query) are results. Thus, evaluation can proceed
along similar lines by comparing a user provided object list Un of
length n to a ranked list A provided by the system. To quantify
the intersection of both lists, we use slightly modiﬁed metrics of
Precision at k (Pk) and Recall at k (Rk) [38] to evaluate SCN.
Therefore, we compare the cropped user list Uarg min(n,k), simply-
ﬁed denoted as Uk, and system list Ak at rank k. The metrics Pk
and Rk are deﬁned as Pk = |Uk ∩ Ak|/k and Rk = |Uk ∩ Ak|/n.
Thus, Pk captures the number of correctly identiﬁed ECs above k
and Rk the ratio of expected ECs that were identiﬁed above k wrt.
the complete user list Un.

Three properties of these metrics have to be discussed. First,
even a perfect system can not achieve Rk = 1 if n > k. We will
observe a constantly growing Rk with increasing k. Next, a system
cannot achieve Pk = 1 if n < k, leading to constantly decreasing
Pk for k > n. Finally, the cropping of Un leads to an increasing Pk
within k < n, if the system provides a different ranking compared
to the user’s one. The described properties can be observed in recall
precision graphs (RCG), e.g. shown in Fig. 5(c).
It depicts the
average Rk and Pk for several documents. The left-most point of a
series shows R1 and P1 and the right-most point R10 and P10.

For CSS and REVIEW only the most relevant EC is available
as gold standard. Here, we apply the Success at k measurement
[15], denoted as Sk. It indicates whether the expected object ε was
identiﬁed above rank k of Ak, leading to Sk = Rk with n = 1.

6http://www.filmsite.org/allfilms2.html

6.2 Performance in Ranking ECs

We use a standard parameter setting pout = 0.2, and wT = 1,
s = 0.7 and k = 250 (the top-k limit for the term matcher), if
not stated differently. First, we compare to a web search engine
using the REVIEW-corpus, which compares to approaches like [33,
29, 1, 28, 3, 30]. Next, a machine learning approach [22] was
implemented, that would be the ﬁrst choice to identify ECs for the
CSS-corpus, because of the large amount of available training data.
Last, we discuss a comparison to [9, 40, 5] using CSS.

REVIEW. Our problem can be implemented by standard IR-
approaches in treating each DCG as a mini document as proposed
by [33]. A simple way to implement such approach, is to leverage a
standard we search engine. We used Google, depicted as G4IMDB
in Fig. 5(a), to implement EC-ranking for this scenario because
[33] showed that Google outperforms [29, 1, 28] in ranking ECs for
key word queries. Further, assuming that PageRank is one of the
most important ranking functions of Google, we compare indirectly
to approaches alike [3, 30]. Documents of REVIEW were sent as
keyword queries to Google’s webservice API with a restriction to
IMDB’s ﬁlm homepages that correspond to ECs. We retrieved the
list of ranked movie homepages including their titles, which were
manually compared to the gold standard. Results of our approach
are illustrated as MOV-OPT in Fig. 5(a).

The results of this experiment, shown in Fig. 5(a), indicate that
our ranking function outperforms G4IMDB for document process-
ing. We achieve ∆S1 ≈ 0.21 and ∆S10 ≈ 0.58. We assume
that popularity ranking, e.g., encoded in PageRank, is an important
performance factor for keyword search, but is inadequate when an-
alyzing documents, that refer in an equally distributed manner to
ECs.

CSS. We implemented an approach based on a generative Lan-
guage Model [4] that would be the ﬁrst choice to detect ECs in text
if a large training corpus is available. In particular, we trained the
token q-gram based language model by the 7,000 training docu-
ments as described above. We applied experiments for uni-, three-
and 5-gram tokenizers (1GramLM, 2GramLM and 5GramLM in
Fig. 5(b)). We realized that in CSS almost no component names
were matched, thus a lower decay (pself = 0.1) was used, to gap
longer distances between matches and ECs. Further, the matcher
had to support a higher bandwidth of linguistic variations, thus we
used pself = 0.1 allowing on average three edits for Levensthein.
The results of those settings are depicted as CSS-OPT. Addition-
ally, we show FullPropTfIdf and NoPropTfIdf that used TF-IDF for
scoring individual matches. They use for aggregation pself = 1 and
pself = 0 for aggregation. FullPropTfIdf is an adaption of EROCS
[9], which uses the summed TF-IDF scores for ranking and treats
the whole document as one segment (see Sec. 5). NoPropTfIdf in-
terprets ECs as records and leverages only directly attached terms.
Thus, it extends [40] by incorporating the frequency of matched
terms. Further, we extended the EROCS like approach by a decay
over distance and tested all possible parameterizations. A value of
pself = 0.3 lead to the best results, illustrated as BestTfIdf.

Fig. 5(b) summarizes evaluation results for CSS. First of all, we
realize that FullPropTfIdf as well as NoPropTfIdf are not applica-
ble to this data set, because neither the direct matched ECs, nor the
most abstract ones lead to the correct results. Furthermore, we re-
alize a performance difference of ∆S1 ≈ 0.14 between CSS-OPT
and 5GramLM. The difference increases to ∆S2 ≈ 0.23 and de-
creases for k > 2. For k > 8 the language model outperforms
our approach. We assume that the reason behind this behavior is
that the language model is only aware of 10% of the components in
SAPTerm. BestTfIdf provided comparable results as the language
model up to S7. Considering the application, we show that our ap-

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA178(a) Sk using REVIEW

(b) Sk using CSS

(c) RPG for Pk and Rk using SCN

Figure 5: Performance evaluation for REVIEW, CSS and SCN

(a) SCN, varying pself

(b) CSS, varying pself and s

(c) Proﬁle of Fig. 6(b)

Figure 6: Inﬂuence of parameter settings for SCN and CSS

proach provides a list of ECs for routing customer inquiries that
contains the correct EC in one of two cases.

SCN. We used FullPropTfIdf, NoPropTfIdf and BestTfIdf to com-
pare to TF-IDF based approaches. We found pself = 0.7 as best
setting for BestTfIdf. We implemented additionally CentEC as a
variant of our approach using a score aggregation function inspired
by BANKS [5], which considers structural compact graphs. It in-
terprets each EC as the central node of a possible result and sums
scores of neighboring ECs in the DCG (1-Star Tree). Match and
edge weights were computed with the standard settings as described
above and pself = 0.3, which turned out to produce the best results
for this approach. The experiment NoSelf uses the weighting de-
scribed in the course of this paper, but runs with pself = 0. The
results of our approach using pself = 0.3 are depicted as SCN-OPT.
Fig. 5(c) summarizes evaluation results for SCN. First of all, we
found that NoPropTfIdf performed badly with a maximum pre-
cision at P5 = 0.032, but achieves a good recall R10 ≈ 0.8.
The EROCS like approach NoPropTfIdf achieves same recall level
as NoPropTfIdf at k = 6, which ends up in P10 ≈ 0.9. Best-
TfIdf produces a better precision between 2 < k < 8 of approxi-
mately 0.08. The low precision arises because the top scored term
matches are often not relevant. Thus, the relevant ECs are mostly
ranked at an upper k. SCN-OPT outperforms CentEC and NoSelf
by ∆P1 ≈ 0.10. The performance of CentEC drops signiﬁcantly
for Pk>1 to ∆P5 ≈ 0.20 compared to SCN-OPT. Thus, objects
which are ranked lower in Un are often dropped. Further, SCN-OPT
outperforms CentEC in recall by ∆R5 ≈ 0.29 and ∆R10 ≈ 0.37,
and NoSelf by ∆R5 ≈ 0.10 and ∆R10 ≈ 0.15. The good P1
and R1, but rather low R10 and P10 of CentEC indicate that struc-
tural compact graphs perform well in identifying the most relevant
result, e.g. important for keyword searches, but not for scenarios,
where several ECs have to be identiﬁed. The comparison of SCN-
OPT and NoSelf shows that a proper setting for pself constantly
helps improving recall and precision, here, by 10 to 15 percentage
points.
6.3 Parameter Settings

The trade-off between qualitative performance and processing
time for top k retrieval has been studied intensively (see, e.g., [10,

14, 50]), thus, we do not investigate the parameter k. Furthermore,
we found pout = 0.2 to perform well in all experiments and used
wT = 1 for simpliﬁcation. We discuss the inﬂuence of the param-
eter pself for SCN and CSS. Next, we evaluate the inﬂuence of the
similarity threshold s for CSS.

Impact of decay factor. The parameter for pself has a major in-
ﬂuence on recall and precision of our approach because different
scenarios address different abstraction levels. A rough heuristic to
determine a value for pself is the usage of the reciprocal average
depth of the ontology, that is pself = 1/4.9 ≈ 0.2 for SAPTerm.
Fig. 6(a) shows the results for SCN for varying pself with respect
to Rk and Pk. We identiﬁed a maximum at pself = 0.3 with
P1 = 0.9 that slightly outperforms pself = 0.2 with P1 = 0.83.
We show the results for varying pself for CSS in Fig. 6(b) and
Fig. 6(c). Here, we realize a better performance for pself = 0.1
that outperforms the estimated value pself = 0.2 for upper k. For
k = 1 indeed pself = 0.2 would be the best setting in combination
with s = 0.1.

Impact of similarity threshold. We use CSS to show the inﬂu-
ence of s. We realized that in general a low s produces better results
for S1, but does not impact the results for S10. In particular, a value
of s = 0.1 leads to S1 ≈ 18% and s = 0.7 leads to S1 ≈ 6% in
this experiment. However, s = 0.7 lowers the number of nodes in a
DCG from 5,000 to 1,000 nodes compared to s = 0.1. Thus, high
values of s lead to signiﬁcantly better document processing times.
In practice, we apply s = 0.1 because support employees prefer a
better ranking over processing time.
7. CONCLUSION

In this paper, we addressed the problem of identifying complex
enterprise concepts (EC) in textual documents. Since the ECs are
predeﬁned and available in an enterprise ontology, the essence of
this problem is to ﬁrst recognize potential ECs and to map them
to the ontology. Both steps are difﬁcult due to the nature of the
documents we consider (non grammatical, typos, frequent use of
abbreviations and jargon, etc.) and due to the high ambiguity of
ECs and the words they are formed of. We presented solutions to
all these problems based on a scoring scheme that considers the
conﬁdence and the relevance of each potential match. In particular,

 0 0.2 0.4 0.6 0.8 1 0 1 2 3 4 5 6 7 8 9 10SkkIMDB on MOV-450-1MOV-OPTG4IMDB 0 0.2 0.4 0.6 0.8 1 0 1 2 3 4 5 6 7 8 9 10SkkSAPTerm on CSN-700-1CSS-OPTNoPropTfIdfFullPropTfIdfBestTfIdf1GramLM3GramLM5GramLM 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PkRkSAPTerm on SCN-100-10SCN-OPTNoSelfNoPropTfIdfFullPropTfIdfBestTfIdfCentEC 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PkRkSAPTerm on SCN-100-100.00.10.20.30.50.70.9 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6Sk    SAPTerm on SCN-100-10k=1k=3k=10pself      sSk     0 0.2 0.4 0.6 0.8 1 0 0 0.2 0.4 0.6Sk    SAPTerm on SCN-100-10k=1k=3k=10  pself and sSk    WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA179we showed that a careful combination of the evidence of multiple
potential matches within a text, together with an exploitation of the
logical structure deﬁned by the ontology helps to boost the perfor-
mance of EC recognition considerably.

There are multiple ways of further improving our approach. First,
to be applicable in heavily loaded online forums (like SCN), we
need to improve execution speed, we expect to be not too difﬁ-
cult because many of the calculations are repetitive. Furthermore,
we plan to combine our approach with other document processing
techniques, such as document classiﬁcation and topic detection to
estimate edge weights of the knowledge base on an individual ba-
sis.
Acknowledgments
This work is supported by the FP7 EU Large-scale Integrating Project
"‘OKKAM - Enabling a Web of Entities"’7 (contract no.
ICT-
215032). We like to thank members of the Data Management and
Analytics team at SAP Research, especially the former colleagues
Alexander Löser and Hong-Hai Do, for valuable discussions.

8. REFERENCES
[1] S. Agrawal, S. Chaudhuri, and G. Das. DBXplorer: A System for

Keyword-Based Search over Relational Databases. In Proc. ICDE 2002.

[2] E. Amitay, N. Har’El, R. Sivan, and A. Soffer. Web-a-where: geotagging web

content. In Proc. SIGIR 2004.

[3] A. Balmin, V. Hristidis, and Y. Papakonstantinou. Objectrank: Authority-based

keyword search in databases. In Proc. VLDB 2004.

[4] K. Balog, L. Azzopardi, and M. de Rijke. Formal models for expert ﬁnding in

enterprise corpora. In Proc. SIGIR 2006.

[5] G. Bhalotia, A. Hulgeri, C. Nakhe, S. Chakrabarti, and S. Sudarshan. Keyword

Searching and Browsing in Databases using BANKS. In Proc. ICDE 2002.
[6] C. Binnig, S. Hildenbrand, and F. Färber. Dictionary-based order-preserving
string compression for main memory column stores. In Proc. SIGMOD 2009.

[7] F. Brauer, W. Barczynski, G. Hackenbroich, M. Schramm, and A. Mocan.

RankIE: Document Retrieval on Ranked Entity Graphs. In Proc. VLDB 2009
(Demo Track).

[8] A. Z. Broder and A. C. Ciccolo. Towards the next generation of enterprise

search technology. IBM Syst. J., 43(3):451–454, 2004.

[9] V. T. Chakaravarthy, H. Gupta, P. Roy, and M. Mohania. Efﬁciently linking text

documents with relevant structured information. In Proc. VLDB 2006.

[10] A. Chandel, P. C. Nagesh, and S. Sarawagi. Efﬁcient Batch Top-k Search for

Dictionary-based Entity Recognition. In Proc. ICDE 2006.

[11] S. Chaudhuri, V. Ganti, and R. Kaushik. A Primitive Operator for Similarity

Joins in Data Cleaning. In Proc. ICDE 2006.

[12] Y.-Y. Chen, T. Suel, and A. Markowetz. Efﬁcient query processing in

geographic web search engines. In Proc. SIGMOD 2006.

[13] T. Cheng, X. Yan, and K. C.-C. Chang. EntityRank: searching entities directly

and holistically. In Proc. VLDB 2007.

[14] W. W. Cohen, P. Ravikumar, and S. E. Fienberg. A Comparison of String

Metrics for Matching Names and Records. In KDD Workshop on Data
Cleaning and Object Consolidation, 2003.

[15] N. Craswell and D. Hawking. Overview of the TREC 2004 Web Track. In E. M.

Voorhees and L. P. Buckland, editors, TREC, volume Special Publication
500-261. National Institute of Standards and Technology (NIST), 2004.

[16] S. Cucerzan. Large-scale named entity disambiguation based on Wikipedia

data. In Proc. of EMNLP-CoNLL, 2007.

[17] J. L. G. Dietz. Enterprise Ontology: Theory and Methodology. Springer-Verlag

New York, Inc., Secaucus, NJ, USA, 2006.

[18] S. Dill, N. Eiron, D. Gibson, D. Gruhl, R. Guha, A. Jhingran, T. Kanungo,

S. Rajagopalan, A. Tomkins, J. Tomlin, et al. SemTag and Seeker:
Bootstrapping the semantic web via automated semantic annotation. In Proc.
WWW 2003.

[19] L. Ding, T. Finin, A. Joshi, R. Pan, R. S. Cost, Y. Peng, P. Reddivari, V. Doshi,
and J. Sachs. Swoogle: a search and metadata engine for the semantic web. In
Proc. CIKM 2004.

[20] C. Dwork, R. Kumar, M. Naor, and D. Sivakumar. Rank aggregation methods

for the Web. In Proc. WWW 2001.

[21] A. K. Elmagarmid, P. G. Ipeirotis, and V. S. Verykios. Duplicate Record
Detection: A Survey. IEEE Trans. Knowl. Data Eng., 19(1):1–16, 2007.

[22] H. Fang and C. Zhai. Probabilistic Models for Expert Finding. In Proc. ECIR

2007.

7http://www.okkam.org

[23] F. Farfán, V. Hristidis, A. Ranganathan, and M. Weiner. XOntoRank:

Ontology-Aware Search of Electronic Medical Records. In Proc. ICDE 2009.

[24] S. Gaudan, A. J. Yepes, V. Lee, and D. Rebholz-Schuhmann. Combining

evidence, speciﬁcity, and proximity towards the normalization of gene ontology
terms in text. EURASIP J. Bioinformatics Syst. Biol., pages 1–9, 2008.

[25] J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigarran. Indexing with WordNet

synsets can improve text retrieval. Arxiv preprint cmp-lg/9808002, 1998.
[26] L. Guo, F. Shao, C. Botev, and J. Shanmugasundaram. XRANK: ranked

keyword search over XML documents. In Proc. SIGMOD ’03.

[27] J. Hassell, B. Aleman-Meza, and I. B. Arpinar. Ontology-Driven Automatic

Entity Disambiguation in Unstructured Text. In Proc. ISWC 2006.

[28] V. Hristidis, L. Gravano, and Y. Papakonstantinou. Efﬁcient IR-Style Keyword

Search over Relational Databases. In Proc. VLDB 2003.

[29] V. Hristidis and Y. Papakonstantinou. DISCOVER: Keyword Search in

Relational Databases. In Proc. VLDB 2002.

[30] V. Kacholia, S. Pandit, S. Chakrabarti, S. Sudarshan, R. Desai, and

H. Karambelkar. Bidirectional expansion for keyword search on graph
databases. In Proc. VLDB 2005.

[31] G. Kasneci, F. M. Suchanek, G. Ifrim, M. Ramanath, and G. Weikum. NAGA:

Searching and Ranking Knowledge. In Proc. ICDE 2008.

[32] G. Li, B. C. Ooi, J. Feng, J. Wang, and L. Zhou. EASE: an effective 3-in-1

keyword search method for unstructured, semi-structured and structured data.
In Proc. SIGMOD 2008.

[33] F. Liu, C. Yu, W. Meng, and A. Chowdhury. Effective keyword search in

relational databases. In Proc. SIGMOD 2006.

[34] A. Löser, W. M. Barczynski, and F. Brauer. What’s the Intention Behind Your

Query? A few Observations From a Large Developer Community. In Proc.
IRSW 2008.

[35] Y. Luo, X. Lin, W. Wang, and X. Zhou. Spark: top-k keyword query in

relational databases. In Proc. SIGMOD 2007.

[36] R. Mandala, T. Takenobu, and T. Hozumi. The use of WordNet in information

retrieval. In Use of WordNet in Natural Language Processing Systems:
Proceedings of the Conference, 1998.

[37] C. Mangold, H. Schwarz, and B. Mitschang. u38: A framework for

database-supported enterprise document-retrieval. In Proc. IDEAS 2006, 2006.

[38] C. D. Manning, P. Raghavan, and H. Schtze. Introduction to Information

Retrieval. Cambridge University Press, New York, NY, USA, 2008.

[39] K. S. McCurley. Geospatial mapping and navigation of the web. In Proc WWW

2001.

[40] M. Michelson and C. A. Knoblock. Unsupervised information extraction from
unstructured, ungrammatical data sources on the World Wide Web. Int. J. Doc.
Anal. Recognit., 10(3):211–226, 2007.

[41] K. Muthmann, A. Loeser, W. Barczynski, and F. Brauer. Near-Duplicate

Detection for Web-Forums. In Proc. IDEAS 2009.

[42] G. Navarro. A guided tour to approximate string matching. ACM Comput. Surv.,

33(1), 2001.

[43] R. Navigli and P. Velardi. An analysis of ontology-based query expansion

strategies. In Workshop on Adaptive Text Extraction and Mining, 2003.
[44] J. K. Owyang, S. VanBoskirk, S. Glass, C. S. Overby, G. O. Young, and

A. Polanco. The Forrester Wave: Community Platforms, Q1 2009. Forrester
Wave (white paper), 2009.

[45] S. Puhlmann, M. Weis, and F. Naumann. XML Duplicate Detection Using

Sorted Neighborhoods. In Proc. EDBT 2006.

[46] R. Richardson and A. Smeaton. Using WordNet in a knowledge-based approach

to information retrieval. In Proceedings of the BCS-IRSG Colloquium, Crewe,
1995.

[47] C. Rocha, D. Schwabe, and M. P. Aragao. A hybrid approach for searching in

the semantic web. In Proc. WWW 2004.

[48] E. F. T. K. Sang. Memory-based shallow parsing. J. Mach. Learn. Res.,

2:559–594, 2002.

[49] S. Sarawagi. Information Extraction. Foundations and Trends in Databases,

1(3):261–377, 2008.

[50] M. Theobald, G. Weikum, and R. Schenkel. Top-k query evaluation with

probabilistic guarantees. In Proc. VLDB 2004.

[51] Y. Tsuruoka and J. ichi Tsujii. Improving the performance of dictionary-based

approaches in protein name recognition. Journal of Biomedical Informatics,
37(6), 2004.

[52] W. Wang, C. Xiao, X. Lin, and C. Zhang. Efﬁcient approximate entity

extraction with edit distance constraints. In Proc. SIGMOD 2009.

[53] X. Yang, C. M. Procopiuc, and D. Srivastava. Summarizing Relational

Databases. Proc. VLDB 2009.

[54] Q. Zhou, C. Wang, M. Xiong, H. Wang, and Y. Yu. SPARK: Adapting Keyword

Query to Semantic Search. In Proc. ISWC/ASWC 2007.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA180