Large-scale Bot Detection for Search Engines

∗

Hongwen Kang

Carnegie Mellon University
Pittsburgh, PA 15213, USA
hongwenk@cs.cmu.edu

Kuansan Wang
Microsoft Research,

Redmond, WA 98052, USA

Kuansan.Wang@microsoft.com
Zijian Zheng

Fritz Behr

David Soukal

Microsoft, Redmond, WA

98052, USA

dsoukal@microsoft.com

Microsoft, Redmond, WA

98052, USA

fritzb@microsoft.com

Microsoft, Redmond, WA

98052, USA

zijianz@microsoft.com

ABSTRACT
In this paper, we propose a semi-supervised learning ap-
proach for classifying program (bot) generated web search
traﬃc from that of genuine human users. The work is moti-
vated by the challenge that the enormous amount of search
data pose to traditional approaches that rely on fully an-
notated training samples. We propose a semi-supervised
framework that addresses the problem in multiple fronts.
First, we use the CAPTCHA technique and simple heuristics
to extract from the data logs a large set of training samples
with initial labels, though directly using these training data
is problematic because the data thus sampled are biased. To
tackle this problem, we further develop a semi-supervised
learning algorithm to take advantage of the unlabeled data
to improve the classiﬁcation performance. These two pro-
posed algorithms can be seamlessly combined and very cost
eﬃcient to scale the training process. In our experiment, the
proposed approach showed signiﬁcant (i.e. 2 : 1) improve-
ment compared to the traditional supervised approach.

Categories and Subject Descriptors
H.2.8 [Information Systems]: Data mining; I.5 [Computing
Methodologies]: Pattern recognition

General Terms
Algorithms, Experimentation

Keywords
Semi-supervised learning, bot detection, search engine, query
logs, click logs, CAPTCHA

1.

INTRODUCTION

Web search engines play an important role in satisfying
users’ information needs. However, due to the openness of
web search engines and the proﬁt potential in manipulat-
ing the search result pages, malicious use of the search en-
∗
Part of this work was done when the ﬁrst author was on
a summer internship with Microsoft Research and the Bing
Search Data Mining Group.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2010, April 26–30, 2010, Raleigh, North Carolina, USA.
ACM 978-1-60558-799-8/10/04.

gine has been widely observed [11, 30, 31, 45]. Speciﬁcally,
robots1, a type of programs that issue queries and clicks
automatically to web search engines can consume a large
portion of the overall traﬃc for the search engines. It is cru-
cial to detect and separate these automatically generated
search activities from those of genuine human users’ for the
following reasons. First, program generated traﬃc can usu-
ally peak to a large traﬃc volume in a very short period of
time, causing an increase of the search engine response time
that degrades the human user’s experience. Second, search
logs that record users’ interactions with the search engines
are often retained for later analysis. Search engine logs cor-
rupted by bot activities can mislead and even cause serious
problems when important conclusions are to be drawn from
these logs [37]. Third, it is usually very important to pre-
process the data logs and ﬁlter out irrelevant records [10]
before carrying out other tasks such as modeling user search
behaviors [1]. Speciﬁcally, one example is learning to rank
by user clicks, in which case the ranking algorithms learned
from polluted data will not be eﬀective and useful [14, 28].
One diﬃculty in detecting bots in search engine is the di-
versity in their behaviors. There are bots that behave ethi-
cally by clearly identifying themselves in their visits [15, 21,
25]. However, based on our observations on a popular search
engine, only a very small fraction of the bot traﬃcs belong
to this class. Other types of bots behave very diﬀerently.
For example, some bots attempting to reverse engineer the
search engine index would issue query terms extracted from
a dictionary, i.e. consecutive queries that only diﬀer by one
or two characters, while some bots submit the same queries
and sometimes click on the similar results in an attempt
to boost the ranking for some speciﬁc keywords or search
results. The diverse search behaviors are also mirrored by
the genuine human users, one speciﬁc reason being diﬀerent
users exhibit various sophistication level in using the search
engine [22].

Prior researches in automated web traﬃc detection mainly
focused on detecting bots on websites. For example [40]
used behavioral features, such as percentage of multimedia
requests, average time between clicks, and total number of
page requested to characterize the navigational patterns of
users and then apply a decision tree algorithm to learn and
determine if the user is a human or not.
[39] used sim-

1In this paper, we use “robots” and “bots” interchangeably
to refer to automated online programs.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA501ilar user behavioral features but formulated the problem
under Bayesian classiﬁcation framework that demonstrated
promising results for detecting crawlers inside Web-server
access logs. However, almost ironically, in these prior re-
searches one major type of robots were the web crawlers
from search engines, and work focused on the detection of
automatically generated traﬃc targeted at search engines
has been limited.
[37] classiﬁes search sessions into typi-
cal and atypical behaviors, and showed that by ﬁltering out
these atypical (outlier) sessions, one can improve the conﬁ-
dence in the click through rate (CTR) estimation. While it
is natural that reducing data variance leads to higher conﬁ-
dence of parameter estimation, the classiﬁcation task itself
mixes genuine user behavior with robots’ activities. There-
fore it sheds limited light on detecting robot behaviors. Our
work is largely inspired by and built upon [4] which were
based on active learning framework, and [5] which used un-
labeled data to help identify the samples that need to be
labeled. Compared to these prior work, our contribution is
a cost-eﬃcient way of generating large number of initial sam-
ples and propose a semi-supervised learning framework that
can improve the classiﬁcation performance using unlabeled
data in an iterative EM process.

In this paper, we propose a novel approach of combining
the use of CAPTCHA [42] and some simple heuristics to
generate large number of training data at essentially no ad-
ditional labeling cost. Further, we propose a semi-supervised
learning approach for the bot detection problem. Our semi-
supervised learning approach is advantageous in handling
the sampling bias issue during the initial training dataset
generation. This is achieved by introducing a large num-
ber of unlabeled data from randomly sampling the whole
dataset, again at no labeling cost. We demonstrate the ef-
fectiveness of our semi-supervised learning approach in dis-
tinguishing bot traﬃc from genuine human user traﬃc. Our
comparison to a fully supervised learning algorithm shows
that the semi-supervised learning approach performs signif-
icantly better under human judgments.

2. 0-COST TRAINING DATA GENERATION
For the scale of modern web search engines, it is costly
to organize human judges to manually inspect and label the
user search logs as training set for bot detection. What
is practically possible is often a tiny fraction of one day’s
search log. However, since there are millions of online users,
researchers have made successful attempts in utilizing these
valuable resources, such as asking them to recognize scanned
documents that are extremely challenging for current com-
puter programs to handle [42] and, at the same time, use
the process as a veriﬁcation technique to determine if the
user is a genuine human or some automated program.

In some systems, every user must pass the CAPTCHA
challenge in order to access some speciﬁc service, such as
web email account application, online banking, etc. For web
search engines, this strategy is not viable because the goal
of a web search engine is to help users retrieve useful in-
formation as quickly as possible, that one of the most im-
portant design objectives is to minimize the eﬀorts a user
spends on the search engine. For this reason, blindly apply-
ing CAPTCHA challenge for every user is apparently not
acceptable. On the other hand, it is also necessary to send
out CAPTCHA challenges to some users selectively to guard
against malicious use.

Figure 1: The number of all users and users who
were present with CAPTCHA pages. Numbers of
all users are normalized to the maximum number
during the week. Numbers of CAPTCHAed users
are normalized to each day respectively and percent-
ages are shown here.

Our current search engine implements a mechanism to
send CAPTCHA challenges to a small fraction of users 2
mainly based on the following criteria: 1), server load status,
i.e. CAPTCHA challenges are sent out when some servers
are experiencing high traﬃc volume; 2), user behavior, when
a user, tracked by a unique identiﬁer, is behaving abnor-
mally, such as sending in large number of queries in a very
short interval; 3), IP block, such as when the traﬃc from
a certain IP address exceeds a high threshold that all users
from this address will be asked to verify their identities; 4),
random selection, especially when the server continues to
experience heavy traﬃc volume; and 5), some other thresh-
olds have been exceeded, such as those from the baseline
algorithm described later in the paper. After correctly re-
sponding to the challenge, the user will be exempted from
further veriﬁcation for a period of time. We have found this
mechanism a good balance between user experience and sys-
tem stability.

Figure 1 shows the overall traﬃc and the percentage of
users who were presented with the challenges in the data
collected during the period of July 3 to July 9, 2009. The
number of overall users ﬂuctuates periodically on a weekly
basis and peaks on Monday and Tuesday. On average, less
than 1% of overall users are requested for veriﬁcation.

When presented with a CAPTCHA challenge, a user can
either disregard the challenge (“no response”) by closing the
browser or exiting the search session, or attempt to answer
the challenge. Every time a wrong answer is submitted,
the server changes the image shown in the veriﬁcation web
page. As long as the user answers correctly in one of the
challenges, the user is regarded as having passed the chal-
lenge and labeled “correct response” .
If the user fails to
correctly answer the challenges after all trials, the user is
marked as “wrong response”. Figure 2 shows the response
categorization of these users. It partially demonstrates the
eﬀectiveness of the veriﬁcation mechanism since, among all

2A user is identiﬁed by a unique user id stored in the cookies.
The algorithm discussed in this paper only handles the cases
where users accept cookies. To further simplify the process,
a user with the same user id is classiﬁed independently in
diﬀerent sessions. Here, a session is characterized as con-
secutive visits from the same user and can consist of several
query actions taking place within a temporal interval, say,
30 minutes.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA502Figure 2: Categorize users based on their response
to the CAPTCHA pages. Since the CAPTCHA
users were sampled non-uniformly, most of them
were likely to be robots, and therefore large por-
tion of the CAPTCHA pages were not responded.
For the users who do respond, the correct rate is
about 80%.

the users who receive the veriﬁcation requests, over 99.9% of
them do not respond at all. This lends to the belief that most
current bots do not implement the functionality to respond
to the CAPTCHA challenges, let alone the sophisticated
algorithms needed to overcome them. For users who do re-
spond to the veriﬁcation requests, we see that the correct
response rate is roughly 80%. The rate depends on many
factors, such as the diﬃculty of diﬀerent CAPTCHA chal-
lenges and the user expertise levels in online usage [22] that
make some users more experienced in solving the challenges
than others.

For users who correctly answer the challenges, we label
them as genuine human users and use their records as the
“human” class in our training dataset. Even though we be-
lieve that the majority of users who do not respond to the
challenges are bots, it is still possible that some human users
are turned oﬀ by the challenge or simply do not understand
how to respond. Therefore, we use some heuristics to select
a fraction that are most likely to be bots from the set of “no
response” users. The set of heuristics include 1), number of
clicks in a time period, 2), number of search result pages
browsed, and 3), number of IPs that the user “originates”
simultaneously. The deﬁnition of these measurement will be
further discussed in Section 3. The users who do not respond
and exceed the thresholds of the heuristic measurements are
initially labeled as “bot”.

From the data, we observe that user behaviors appear to
be multi-modal and vary notably among the search verticals
such as web search, image search, video search, etc. In this
paper, we restrict our discussion to web search only. Figure 3
shows the categorization of web search users based on the
combination of their responses to the CAPTCHA challenges
and our heuristic based classiﬁcation. The diﬀerent response
rates compared to the overall response rate are shown in
Figure 2. Note that in these datasets we use only the most
suspicious subset of the users who do not respond as “bot”
samples.

By making use of the existing CAPTCHA mechanism and
some simple heuristics, our training data generation process
has essentially incurred “0-cost” for the developers to extract
a large number of labeled data. However, this set of data is
not uniformly sampled over the whole dataset and has the
following issues to use them directly for supervised training.

Figure 3: Categorize web search users based on the
combination of their response to the CAPTCHA
challenge and heuristics. Note the diﬀerent user re-
sponse rate on web search vertical compared to that
in Figure 2 for all users.

First, as we discussed before, the users who were selected
to present the CAPTCHA challenge are sampled unevenly
towards those who have large number of requests. Second,
the users who correctly answer the challenges are biased to-
wards the users with more online experience. Third, the
samples in the “bot” class is only a partial representative
of the whole “bot” class due to the high thresholds in our
heuristic rules, and therefore only a small fraction of the
users who do not respond are used as the “bot” samples. It
is well known that when the labeled training dataset does
not reﬂect the underlying data distribution, the classiﬁers
will have skewed classiﬁcation boundaries that will lead to
poor generalization capability [3, 6, 46, 47].

Obviously, the beneﬁt of generating a large amount of data
in a cost eﬃcient way must be accompanied by the data be-
ing useful for training. To compensate the data bias issues,
we further include a large amount of unlabeled data by uni-
formly sampling from the whole search logs and use a semi-
supervised learning approach to correct the skewed decision
boundary. We describe the details of the semi-supervised
learning algorithm that we developed from Bayes network
[18] (Section 4), and then we demonstrate its eﬀectiveness
by comparing the proposal with a supervised learning algo-
rithm based on decision tree [32] (Section 5).

It is important to note that bot detection and the user ver-
iﬁcation mechanism are closely related. A good bot detec-
tion system will make the user veriﬁcation mechanism more
eﬃcient and improve the experience of the genuine human
users. On the other hand, selectively verify the identity of
certain users can also help a bot detection algorithm learn
to better distinguish human user behaviors from those au-
tomatically generated by programs. Due to the space limit,
this intricacies between these two issues are left out of this
article.

3. FEATURE DESCRIPTION

Here we brieﬂy describe the features we use in the bot
detection algorithms. Generally speaking, the features can
be categorized into two types. First, the numerical user
behavior features are the type of summarized measurements

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA503Figure 4: PageTrackedCount (page views).

Figure 6: AllHitCount

Figure 5: UserClickCount.

Figure 7: UserUniqueIPs.

derived from the whole, per-user search sessions. The second
type of features is the boolean blacklist features that are
basically hand crafted rules. The blacklist features are very
powerful in identifying bots when triggered, although the
frequency of these features being triggered is low in practice.
In the following we describe these diﬀerent types of features
and, for clarity, mark their value types in parentheses.
3.1 PageTrackedCount (numeric)

PageTrackedCount measures the number of pages that the
user browses. Empirical observations lead to the impres-
sion that bots tend to behave in two extremes. Some bots
will only submit queries and not browse any of the result
pages (except the ﬁrst one), ostensibly with the intention
to increase the query frequency for certain keywords. The
other extreme sees the bots fetch all the result pages for each
query, probably trying to reverse engineer the index of the
search engine, while genuine human users would probably
just browse the ﬁrst few pages of the query results selec-
tively.

Figure 4 shows the PageTrackedCount distributions of the
diﬀerent classes. We can see that both “human” and “bot”
classes are slightly skewed toward higher PageTrackedCount
due to the reason we described before.
3.2 UserClickCount (numeric)

UserClickCount measures the number of mouse clicks on
the search result pages. This includes clicks on the web
search results, i.e. results that are deemed relevant to the
query term, and the sponsored items (i.e., advertisements).
At this point we do not distinguish these two items and sum
the clicks into a single number, although counting them sep-
arately can be potentially useful in capturing the ad-fraud
bots that intentionally click on advertisements placed on the
search result pages. Figure 5 shows the UserClickCount dis-
tributions of the diﬀerent user classes.

3.3 AllHitCount (numeric)

AllHitCount measures the overall “impressions” that the
user receives in addition to the search results. Since on a
web search engine the major contributor to this feature is
the page views, this feature (Figure 6) is closely correlated
to the PageTrackedCount depicted in Figure 4. However,
the correlation is weaker for image and video search where
the impressions of the media contents are not necessarily
bounded by the search result pages.
3.4 UserUniqueIPs (numeric)

UserUniqueIPs measures the unique number of IPs a user
is using. [11] and [45] have both reported that a large num-
ber of bots can assemble a network to attack online services
in a well coordinated manner, and one way to discover these
attacks is by counting the number of unique IPs that are as-
sociated with each user. Although the IP address of a user
could change when the user moves from one place to another,
e.g. home v.s. oﬃce, the frequency of the IP changes is typi-
cally much smaller than that of a bot net. In our experiment
we did not discover these malicious networked activities in
our search logs, thus the “human” and “bot” classes are less
distinguishable on this dimension than others (Figure 7).
3.5 UserUniqueQueries (numeric)

UserUniqueQueries measures the unique number of queries
issued by a single user in a search session. There are two
key observations from inspecting the distribution shown in
Figure 8: 1), “bots” tend to issue either a very small number
of repeated queries or a large number of unique ones, and
2), the users in the “human” class tend to have more unique
queries than the overall user population. One possibility is
that the users labeled as “human” might be more experienced
users that are more versed in formulating queries.
3.6 Rules (boolean)

We implement the following rules (boolean) in our current
bot detection algorithm: 1) RuleBlacklistForm: this rule is
triggered when a user includes in the query certain obscure

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA504First, compared to fully supervised learning, very few la-
beled data samples are needed in order to reach comparable
performances. This property is especially appealing because,
as we have seen, web search users that are presented with
the CAPTCHA challenges are only a very small fraction
(≤ 1%) of the whole user set, and among these users only
a very small fraction of them will respond to the challenges
(Figure 2 and Figure 3). Therefore, our labeled data are a
very sparse sample of the original data corpus that seem to
be more suitable with a semi-supervised than with a fully
supervised learning approach.

Second, semi-supervised learning is especially advisable
when the labeled data samples’ distribution are skewed from
the underlying data distribution, e.g. Figure 4 - Figure 9.
According to the Bayes rule, P (Y |X) =
If the
training data distribution, P (X(cid:2)
), used in the supervised
learning algorithm diverges from the actual data distribu-
tion P (X), the learned classiﬁcation model P (Y |X(cid:2)
) will
not generalize well over X [6, 46]. Again, our dataset is gen-
erated with known biases that make it appealing to avoid
supervised learning.

P (Y,X)
P (X) .

A common way to incorporate the unlabeled data into the
learning process is through the Expectation-Maximization
(EM) algorithm[12]. The algorithm starts by using the la-
beled data (X L) only to bootstrap an initial classiﬁer P (Y |X L).
This initial classiﬁer is then applied to annotate the unla-
beled data (X U ) with the posterior probabilities, P (Y |X U ),
for each unlabeled observation Y . These probabilistically
labeled data are then added to the training dataset, and
their posterior probabilities were used as “soft” counts for
the purpose of updating the conditional probabilities in the
EM iterations. At the end of each iteration, a new classiﬁer,
P (Y |X), is obtained and this new classiﬁer is then applied
to annotate the unlabeled data. The process is repeated
until certain convergence criteria are met. This approach
is also known as a self-training algorithm since the learning
algorithm is feeding back on its own classiﬁcation outcomes
[35, 36, 44]. A temporal version of this method leads to the
Baum-Welsh algorithm for Hidden Markov Model (HMM)
training [33].

When the feature dimension is suﬃciently large, co-training
algorithm [3] splits the features into two subsets, assuming
that each subset is distinctive enough to train a good classi-
ﬁer independently. In the co-training algorithm, the labeled
data are ﬁrst used to train each classiﬁer. Afterwards, un-
labeled data are classiﬁed by each classiﬁer and the samples
with high conﬁdence from one classiﬁer are added to the
training dataset of the other classiﬁer. Each classiﬁer is
trained again with the new training dataset and this pro-
cess is repeated iteratively. Two assumptions are required
for this co-training algorithm to perform well: ﬁrst, each
sub-feature set is suﬃciently distinctive and, second, the
conditional independence assumption is required for these
two feature sets [29]. Relaxations to these strong indepen-
dence assumptions were explored in [7, 19].

In addition to the generative models, semi-supervised learn-
ing framework has also been enhanced with discriminative
methods that optimize P (Y |X) directly without explicitly
model the data generation process, i.e. P (X|Y ) and P (X, Y ).
For the unlabeled data to be useful in the discriminative ap-
proach, a connection between P (X) and P (Y |X) has to be
made [38]. Transductive support vector machines (TSVMs)
accomplishes this by requiring that the decision boundary

Figure 8: UserUniqueQueries

Figure 9: Rules

codes that are designed mostly for internal search engine in-
strumentation purposes that should be unfamiliar to most
genuine human users. 2) RuleBlacklistIp: we maintain a list
of IPs that are publicly identiﬁed as Internet spammers and
labeled all the traﬃc from these IPs as “bot”. 3) RuleBlack-
listQuery: this rule is triggered when the query composition
is too complicated to be manually typed in by a human
user. In this work, we combine these rules into a single fea-
ture (Figure 9) that assumes the value “1” whenever one of
the rules is triggered and “0” otherwise.

4. BOT DETECTION ALGORITHMS

4.1 Supervised learning for bot detection

A straightforward way to utilize the labeled data extracted
using the techniques described above is to directly learn a
bot detector in a fully supervised manner.
In our experi-
ment, we choose a speciﬁc implementation (J48 [43]) of the
popular C4.5 algorithm [32] as our supervised learning al-
gorithm for bot detection. The details of the decision tree
algorithm are omitted here.

Since our initial labeled dataset is extracted using CAPTCHA

response and heuristics, the decision tree algorithm can ﬁt
very well the labeled training dataset. However, as clearly
seen in Figure 4 through 9, the labeled samples we extracted
are indeed skewed from the true data distribution, bringing
in the question that how well the classiﬁcation boundaries
learned directly from this subset will be able to generalize.
4.2 Semi-supervised learning for bot detection
Indeed, our problem actually matches the strengths of the
semi-supervised learning framework [3, 6, 46, 47], in which
unlabeled data are included in the classiﬁcation boundary
learning process and the optimization of the learning process
is carried out with both labeled and unlabeled data samples.
The advantages of applying semi-supervised learning to the
bot detection problem are based on the following properties
commonly observed in a semi-supervised learning system.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA505be away from high density areas with large P (X) [2, 17,
23]. It maximizes the margin on both the labeled data and
the unlabeled data, and as a result the decision boundary
minimizes the generalization error on unlabeled data [41].

Our work is mostly related to the study that only one
class’s label is available (in our case the users who pass the
CAPTCHA challenge are known to be “human”).
[13] as-
sumes that the prior distribution P (Y ) is known and showed
that it is theoretically possible to estimate P (Y |X) using
Bayes rule.
[27] address this problem using two rounds of
the EM algorithm. In the ﬁrst round, the labeled data sam-
ples are split into two parts unevenly, with the larger split
being used on its own, while the smaller split, called the
spy documents, is mixed with the unlabeled samples to form
the opposing class of data. A classiﬁer is learned using the
EM algorithm. The posterior probability of the spy doc-
uments are considered as a relative standard to determine
which data samples have high probability to belong to the
other class, after which these data samples and the initial
labeled samples are used to train a ﬁnal classiﬁer through a
second EM algorithm. [26] adopts a more aggressive scheme
by ﬁrst treating all unlabeled data as the opposing class to
the labeled samples, and using a weighted logistic regression
algorithm to learn a linear classiﬁcation function. As a re-
sult, this approach is not suitable for cases where the oppos-
ing classes are not linearly separable, or when the unlabeled
samples overwhelmingly outnumber the labeled samples.

In this paper we develop a semi-supervised learning al-
gorithm using Bayesian network classiﬁer that has various
advantages in handling incomplete data set, encoding causal
relationship, and avoiding over-ﬁtting [20]. The training of a
Bayesian network is composed of two parts, i.e. the structure
learning and the parameter estimation.

4.2.1 Bayesian network structure learning

Given a set of training samples, the goal of structure learn-
ing is to generate a graph that best describes the causal re-
lationships in the data. Here, the goodness of the graph
structure can be measured in many ways, ranging from the
entropy, the posterior probability given the training data, to
the minimum description length [34]. Regardless the metric
chosen, the structure learning problem amounts to deﬁning
a search algorithm that optimizes for the metric by system-
atically changing the graph structure.

Unfortunately, even for fully labeled dataset, learning the
optimal Bayesian network structure is NP-hard [8] that ap-
proximation and heuristics are often adopted in practice [9,
16]. In this work, we learn the Bayesian structure using the
labeled data only.
In addition to the computational com-
plexity concern, it is also because, during the dataset gen-
eration process, we heavily utilizes the domain knowledge
that is representative of the nature of the problem that it is
reasonable to believe the the structure learned from the la-
beled data can generalize well. We use a structure learning
algorithm similar to that of [16] in which a tree structure
is formed by calculating the maximum weight spanning tree
using the methods described in [9].

4.2.2

Semi-supervised Bayesian network parameter
estimation

After acquiring the Bayesian network structure, we learn
the conditional probabilities for each node and its parents.
We represent each feature (Xi) and the class label (Y ) as

Table 1: Terminologies and notations used in semi-
supervised Bayesian network parameter learning

Description

Observation (features)

Class label/prediction

Y =

Bayesian classiﬁer posterior

(cid:2)

X

Notation
0 : “human(cid:2)(cid:2)
1 : “bot(cid:2)(cid:2)
P (Y |X)
d(X, Y )

H
B
U

D = H ∪ B ∪ U
= ∪d(X, Y )
H ∩ B = 0,
H ∩ U = 0,
B ∩ U = 0
d ∈ [0, 1], i ∈ {0, 1}
wi
#(X = x, Y = y)

C
α
N
T

A data sample
Human data

Bot data

Unlabeled data

Training data corpus

Weight for a data sample

Weighted count of a sample
with observation x and label y

CAPTCHA trust factor

Laplacian smoothing factor

Total number of data samples

Maximum EM iterations

nodes in the Bayesian network, and the task is to learn the
following posterior probability for any given observation [24]:

P (Y |X0, X1, ..., Xn) =

(cid:3)
P (X0, X1, ..., Xn, Y )
Y P (X0, X1, ..., Xn, Y )

.

(1)

n(cid:4)

As can be seen in the above equation, the problem of learn-
ing the conditional probabilities is equivalent to learning the
joint probability of P (X0, X1, ..., Xn, Y ). Based on the lo-
cal Markovian assumption and the chain rule of probability,
this joint probability can be factorized as

P (X0, X1, ..., Xn, Y ) =

P (Xi|P aXi ),

(2)

i=0

where P aXi represents all the parents nodes of Xi. With
this factorization, the parameter learning is further simpli-
ﬁed as the process of estimating the conditional probability
of a random variable Xi given its parents P axi . Without loss
of generality, we explain our parameter learning algorithm
in the special case that variable Xi has only one parent node
Y (i.e., Na¨ıve Bayes). The terminologies and notations used
in the algorithm are listed in Table 1 and, whenever ap-
propriate, we shorthand P (X = x, Y = y) as P (X, Y ) for
simplicity in notation.

At the core of the parameter learning is the iterative EM
algorithm, summarized in Algorithm 1, in which the poste-
rior probabilities of the data samples can be updated using
the weights learned in the preceding iteration:

P (Y |X) =

=

P (X, Y )
P (X)
(cid:3)
P (X, Y )
Y P (X, Y )

,

P (X, Y ) =

#(X, Y ) + α

N + α

.

(3)

(4)

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA506Algorithm 1: Expectation-Maximization algorithm for
semi-supervised Bayesian network parameter learning
Data: D(X, Y ) = H ∪ B ∪ U
Result: P (Y |X)
begin

Initialization:
Set #(X, Y ) = 0;
for each d ∈ D do
if d ∈ H then
d = 1, w1
else if d ∈ B then
d = 0, w1
else if d ∈ U then
d = 0, w1

Set w0

Set w0

Set w0

d = 0,

d = 1,

d = 0,

i = 0;
Maximization: learn Bayesian classiﬁer P 0(Y |X)
as Equation (3) − (6);
i + +;
while i < T do

Expectation: Update weights
for each d ∈ D do

if d ∈ B or d ∈ U then

else if d ∈ H then

Set w0
Set w1

Set w0
Set w1

d = P i−1(Y = 0|X);
d = 1 − P i−1(Y = 0|X);
d = (P i−1(Y = 0|X))
1
C ;
d = 1 − (P i−1(Y = 0|X))

1
C ;

Maximization: learn Bayesian classiﬁer
P i(Y |X) as Equation (3) − (6);
i + +;

Return P (Y |X);

end

Figure 10: Averaged change of posterior probabili-
ties after each EM iteration.

Combining (3) and (4) we have

P (Y |X) =

(cid:3)

#(X, Y ) + α
Y (#(X, Y ) + α)

,

where the weighted count is deﬁned as

#(X = x, Y = y) =

wi=y

d

.

(cid:5)
d ∈ D
X = x
Y = y

(5)

(6)

Our semi-supervised learning algorithm is slightly diﬀer-

ent from many other algorithm in that we introduce a CAPTCHA
trust factor (C) in the parameter learning process. As in
Algorithm 1, the soft count of each data sample is updated
based on its previous label. If a sample is initially labeled
as “bot” or “unlabeled”, we update its soft count with the
posterior probability learned from the previous iteration. If
the sample is initially labeled as “human”, i.e. the user has
correctly answered the CAPTCHA challenge, its soft count
is the posterior discounted by a CAPTCHA trust factor C.
This factor controls to which degree we trust the CAPTCHA
system. Even though at this moment no computer pro-
gram could automatically solve the CAPTCHA challenge
problem, it is possible that one can make use of manual
labors to cheat CAPTCHA. We use a large trust factor C
with a belief that the CAPTCHA system is reliable in most
cases. However, when some samples have a very high poste-
rior probability to be “bots”, soft counts can still be drawn
from these samples and added to the “bots” class. Note that
C → ∞ means that we absolutely trust the CAPTCHA sys-
tem and therefore the identity of the “human” users can not
be changed in the EM training process. We tested various C
values and found that 10 seems to be a good balance. Figure
11 shows the eﬀect of diﬀerent C values on the performance.
Our current EM algorithm stops after a ﬁxed number of it-
erations (e.g. 10). Figure 10 shows the average change of
posterior probability for the training dataset, which can also
serve as a convergence criteria.

5. EXPERIMENT

Our training data is composed of a week’s web search log
data on a popular search engine from July 03 to July 09,
2009. The initial labeled dataset is generated through the
process described in Section 2. For computational considera-
tions, we further sample both the “human” and “bot” dataset
from the log, and ﬁnally extract 20000 “human” records and
6000 “bot” records that keep the original ratio unchanged.
For the semi-supervised learning algorithm, we uniformly
sample the whole week’s logs to generate an “unlabeled”
dataset. The ﬁnal labeled/unlabeled dataset size ratio is,
1 : 9. The feature distributions of the three diﬀerent set are
shown in Figure 4 - Figure 9.

As for testing, we generated a smaller dataset composed
of 170 user sessions. In order to be fair for all algorithms,
we invited 10 web search researchers to label the full testing
dataset so that each search session is judged by 3 diﬀerent
persons. We developed a visualization tool to render the
search log and display a user’s search session in its original
temporal order. The visualized information includes 1) nu-
meric/boolean features as deﬁned in Section 3; 2) the ﬁrst
100 raw query terms; 3) referrer’s link; 4) clicked links; 5)

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA507Table 2: Testing dataset human judgment

Description

Numbers

Total number of user sessions
Number of user sessions with

at least 2 judges reach agreement

Number of user sessions with

at least 2 judges agreed on

either “human” or “bot” labels
Number of user sessions with

at least 2 judges agreed on

“uncertain” labels

Agreement percentage
“for sure” percentage

(i.e. either “human” or “bot”)

170
111

102

“human”: 71

“bot”: 31

9

111/170 ≈ 65%
102/170 ≈ 60%

Table 3: Performance comparison for the supervised
learning algorithm (D-Tree) and our proposed semi-
supervised learning approach

Algorithm

D-Tree

Semi-supervised
Bayesian network

Precision Recall F-measure

28%
75%

39%
72%

35%
73%

dwell time. For each session, a judge could choose among
the three diﬀerent labels: “human”, “bot”, or “uncertain”.

The statistics of the labels in the test set are summarized
in Table 2. Note that even for human, the problem of dis-
tinguishing bot from a genuine human user seems extremely
diﬃcult3. Among all the 170 sessions, only about 60% of
them that an agreement is reached by a majority of 2 over
3 judges. This subset on which we have higher conﬁdence
with the judgment labels and in total has 71 “human” ses-
sions and 31 “bot” sessions, is used as the test set to evaluate
various bot detection algorithms.

In our experiment, we use the J48 implementation of [32,
43] as our supervised learning algorithm. All the parameters
are set to their default values.

For the semi-supervised learning approach, we developed
our own algorithm based on the implementation of [34]. We
ﬁrst used the labeled data to learn the Bayesian network
structure using the built-in Tree Augmented Na¨ıve Bayes
structure learning algorithm, and then kept this graph struc-
ture ﬁxed for the EM algorithm to learn the conditional
probability tables (CPT) for each Bayesian network node.
We used standard Laplacian smoothing in CPT estimation,
with smoothing factor α = 1 throughout the experiment.
The inference process used the built-in inference algorithm
[34]. To pre-process the original numerical features, we used
the built-in supervised quantization algorithm [43]. More
speciﬁcally, we used the labeled dataset to learn the quan-
tization bins for each feature dimension, and then applied
this binning scheme to the unlabeled dataset. Our exper-
iments were conducted on an Intel Xeon workstation with
8GB of memory. The structure learning from 26000 labeled

3Because we are using user id to track users, it requires the
user to enable cookies. In reality, there are a large number
of bots that do not accept cookies and are not considered
here. As for the bots that do accept cookie, they tend to be
more sophisticated and better disguised, which contributes
to the diﬃculty of the detection problem.

Figure 11: The eﬀect of diﬀerent CAPTCHA
trust factors on the performance, measured by F-
measures.

Figure 12: Distribution of the posterior probability
for the misclassiﬁed samples in our approach.

data samples took about 3 minutes. For the parameter esti-
mation, we ﬁxed the maximum EM iteration to 10, and the
training on around 200 thousand samples took about 3 − 5
minutes on average.

The performance for each algorithm is summarized in Ta-
ble 3, where the precision and recall are averages of the two
classes. Because the decision tree algorithm was trained
with skewed training dataset, its performance on the testing
set was far from comparable to the semi-supervised learning
algorithm we proposed in this work. For most of the per-
formance measures, the semi-supervised learning approach
performs over 2 times better than the supervised learning
approach. Figure 12 shows the distribution of the poste-
rior probabilities of the mis-classiﬁed samples in the semi-
supervised learning approach. Note that a large portion
of the errors are made close to the classiﬁcation boundary.
Manual inspection over the mis-classiﬁed examples shows
that the errors mostly fall under the following two cases, 1),
when the user session is short, there is very little information
that the algorithm can infer from; 2), there are some cases
that a user issues a lot of queries and the algorithm tends to
classify such a behavior as a bot. However, human judges
can tell these sessions are from genuine human users because
“the queries were semantically related and the queries and
clicks were coherent with each other”.

6. CONCLUSIONS AND FUTURE WORK

In this paper, we propose a semi-supervised learning frame-
work for detecting automatically generated web search traf-

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA508ﬁc. One important issue for applying machine learning al-
gorithms to this type of Internet scenarios is data annota-
tion scalability, to which we propose a 0-cost approach that
makes use of the existing CAPTCHA technique to extract
data logs of genuine human users. The advantage of this ap-
proach is that it is virtually cost free to harvest large amount
of human annotations through the existing user veriﬁcation
mechanism. We also propose using the simple heuristics
from domain experts to generate the initial positive (“bot”)
dataset. We address the skewed sample issue of the proposed
approach and formulate the problem under semi-supervised
learning framework. The proposed approach makes use of
a large number of unlabeled data, evenly sampled from the
whole dataset (which again is virtually 0-cost). Compared
to the supervised learning algorithms that only base on the
labeled dataset, our semi-supervised learning approach per-
forms signiﬁcantly better in our evaluation (2 : 1).

Many aspects in the proposed approach can be further im-
proved. First, the feature set used in our current algorithm
seems to be not distinctive enough for this problem. For
example, it may be helpful to learn users’ search intention
in order to classify if the user is a genuine human or a bot as
most genuine users typically use search engines when they
have information needs. This could be done by further in-
cluding the query content and the correlation between query
and clicks into the feature set . In essence, our experiment
is still preliminary because we use only one week’s data that
might not be long enough to capture some bot activities. It
is therefore not clear if our model can generalize well over a
longer time span. Ideally, the learning approach should be
adaptive in nature so that the system performance can be
automatically improved as more and more new data are col-
lected. In its current form, human judgments are involved
only for testing data annotation, but it is straightforward to
extend the judgment eﬀorts towards the active learning ap-
proach so that new ambivalent data, when detected, can be
quickly added into the adaptation data to broaden the scope
and enrich the capabilities of the system. As mentioned be-
fore, the CAPTCHA technique and our bot detection system
could be better combined.

7. ACKNOWLEDGMENTS

The authors would like to thank anonymous reviewers for
helpful suggestions. The authors are also grateful to the col-
leagues at Microsoft who generously oﬀered help in the user
judgment study. Hongwen Kang thanks Christos Faloutsos,
Nikolas Gloy and Jay Stokes for helpful discussions.

8. REFERENCES
[1] R. A. Baeza-Yates, C. A. Hurtado, M. Mendoza, and

G. Dupret. Modeling user search behavior. In
LA-WEB, pages 242–251. IEEE Computer Society,
2005.

[2] K. P. Bennett and A. Demiriz. Semi-supervised

support vector machines. In Proceedings of the 1998
conference on Advances in neural information
processing systems II, pages 368–374, Cambridge, MA,
USA, 1999. MIT Press.

[3] A. Blum and T. Mitchell. Combining labeled and

unlabeled data with co-training. In COLT’ 98:
Proceedings of the eleventh annual conference on
Computational learning theory, pages 92–100, New
York, NY, USA, 1998. ACM.

[4] G. Buehrer, J. W. Stokes, and K. Chellapilla. A

large-scale study of automated web search traﬃc. In
AIRWeb ’08: Proceedings of the 4th international
workshop on Adversarial information retrieval on the
web, pages 1–8, New York, NY, USA, 2008. ACM.
[5] G. Buehrer, J. W. Stokes, K. Chellapilla, and J. C.
Platt. Classiﬁcation of automated search traﬃc. In
I. King and R. A. Baeza-Yates, editors, Weaving
Services and People on the World Wide Web, pages
3–26. Springer, 2009.

[6] O. Chapelle, B. Sch¨olkopf, and A. Zien.

Semi-Supervised Learning (Adaptive Computation and
Machine Learning). The MIT Press, 2006.

[7] N. V. Chawla and G. J. Karakoulas. Learning from

labeled and unlabeled data: An empirical study across
techniques and domains. J. Artif. Intell. Res. (JAIR),
23:331–366, 2005.

[8] D. Chickering, D. Geiger, and D. Heckerman.

Learning bayesian networks is np-hard. Technical
report, Microsoft Research, 1994.

[9] C. Chow and C. Liu. Approximating discrete

probability distributions with dependence trees. IEEE
Transactions on Information Theory, 14(3):462–467,
1968.

[10] R. Cooley, B. Mobasher, and J. Srivastava. Data
preparation for mining world wide web browsing
patterns. Knowl. Inf. Syst., 1(1):5–32, 1999.

[11] N. Daswani and M. Stoppelman. The anatomy of
clickbot.a. In HotBots’07: Proceedings of the ﬁrst
conference on First Workshop on Hot Topics in
Understanding Botnets, pages 11–11, Berkeley, CA,
USA, 2007. USENIX Association.

[12] A. P. Dempster, N. M. Laird, and D. B. Rubin.

Maximum likelihood from incomplete data via the em
algorithm. Journal of the Royal Statistical Society.
Series B (Methodological), 39(1):1–38, 1977.

[13] F. Denis, A. Laurent, R. Gilleron, and M. Tommasi.
Text classiﬁcation and co-training from positive and
unlabeled examples. In Proceedings of the ICML 2003
Workshop: The Continuum from Labeled to Unlabeled
Data, pages 80–87, 2003.

[14] Z. Dou, R. Song, X. Yuan, and J.-R. Wen. Are

click-through data adequate for learning web search
rankings? In CIKM ’08: Proceeding of the 17th ACM
conference on Information and knowledge
management, pages 73–82, New York, NY, USA, 2008.
ACM.

[15] D. Eichmann. Ethical web agents. Comput. Netw.

ISDN Syst., 28(1-2):127–136, 1995.

[16] N. Friedman, D. Geiger, M. Goldszmidt, G. Provan,

P. Langley, and P. Smyth. Bayesian network
classiﬁers. In Machine Learning, pages 131–163, 1997.
[17] G. Fung and O. Mangasarian. Semi-supervised support
vector machines for unlabeled data classiﬁcation, 2001.

[18] Z. Ghahramani. An introduction to hidden markov

models and bayesian networks. pages 9–42, 2002.

[19] S. A. Goldman and Y. Zhou. Enhancing supervised

learning with unlabeled data. In ICML ’00:
Proceedings of the Seventeenth International
Conference on Machine Learning, pages 327–334, San
Francisco, CA, USA, 2000. Morgan Kaufmann
Publishers Inc.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA509[20] D. Heckerman. A tutorial on learning with bayesian

networks. pages 301–354, 1999.

[21] O. Heinonen, K. H¨at¨onen, and M. Klemettinen.

WWW robots and search engines. In K. Oksanen,
editor, Seminar on Mobile Code, Technical Report
TKO-C79. Helsinki University of Technology,
Department of Computer Science, May 1996.

[22] C. H¨olscher and G. Strube. Web search behavior of

internet experts and newbies. In Proceedings of the 9th
international World Wide Web conference on
Computer networks : the international journal of
computer and telecommunications netowrking, pages
337–346, Amsterdam, The Netherlands, The
Netherlands, 2000. North-Holland Publishing Co.

[23] T. Joachims. Transductive inference for text

classiﬁcation using support vector machines. In ICML
’99: Proceedings of the Sixteenth International
Conference on Machine Learning, pages 200–209, San
Francisco, CA, USA, 1999. Morgan Kaufmann
Publishers Inc.

[24] D. Koller and N. Friedman. Probabilistic Graphical

Models: Principles and Techniques. MIT Press, 2009.

[25] M. Koster. Robots in the web: threat or treat ?

ConneXions, 9(4), April 1995.

[26] W. S. Lee and B. Liu. Learning with positive and

unlabeled examples using weighted logistic regression.
In T. Fawcett and N. Mishra, editors, ICML, pages
448–455. AAAI Press, 2003.

[27] B. Liu, W. S. Lee, P. S. Yu, and X. Li. Partially

supervised classiﬁcation of text documents. In ICML
’02: Proceedings of the Nineteenth International
Conference on Machine Learning, pages 387–394, San
Francisco, CA, USA, 2002. Morgan Kaufmann
Publishers Inc.

[28] T.-Y. Liu, J. Xu, T. Qin, W. Xiong, and H. Li. Letor:

Benchmark dataset for research on learning to rank
for information retrieval. In LR4IR 2007, in
conjunction with SIGIR 2007, 2007.

[29] K. Nigam and R. Ghani. Analyzing the eﬀectiveness

and applicability of co-training. In CIKM ’00:
Proceedings of the ninth international conference on
Information and knowledge management, pages 86–93,
New York, NY, USA, 2000. ACM.

[30] N. Provos. The reason behind “we’re sorry ...” message.
http://googleonlinesecurity.blogspot.com/2007/
07/reason-behind-were-sorry-message.html, July
2007.

[31] N. Provos, J. McClain, and K. Wang. Search worms.

In WORM ’06: Proceedings of the 4th ACM workshop
on Recurring malcode, pages 1–8, New York, NY,
USA, 2006. ACM.

[32] J. R. Quinlan. C4.5: programs for machine learning.

Morgan Kaufmann Publishers Inc., San Francisco,
CA, USA, 1993.

[33] L. R. Rabiner. A tutorial on hidden markov models

and selected applications in speech recognition. pages
267–296, 1990.

[34] R. B. Remco. Bayesian network classiﬁers in weka.

Technical report, University of Waikato, 2004.

[35] E. Riloﬀ, J. Wiebe, and T. Wilson. Learning

subjective nouns using extraction pattern
bootstrapping. In Proceedings of the seventh
conference on Natural language learning at
HLT-NAACL 2003, pages 25–32, Morristown, NJ,
USA, 2003. Association for Computational Linguistics.

[36] C. Rosenberg, M. Hebert, and H. Schneiderman.
Semi-supervised self-training of object detection
models. In Seventh IEEE Workshop on Applications of
Computer Vision, January 2005.

[37] N. Sadagopan and J. Li. Characterizing typical and
atypical user sessions in clickstreams. In WWW ’08:
Proceeding of the 17th international conference on
World Wide Web, pages 885–894, New York, NY,
USA, 2008. ACM.

[38] M. Seeger. Learning with labeled and unlabeled data.

Technical report, University of Edinburgh, 2001.

[39] A. Stassopoulou and M. D. Dikaiakos. Web robot

detection: A probabilistic reasoning approach.
Comput. Netw., 53(3):265–278, 2009.

[40] P.-N. Tan and V. Kumar. Discovery of web robot

sessions based on their navigational patterns. Data
Min. Knowl. Discov., 6(1):9–35, 2002.

[41] V. N. Vapnik. Statistical Learning Theory.

Wiley-Interscience, September 1998.

[42] L. von Ahn, M. Blum, N. J. Hopper, and J. Langford.

Captcha: Using hard ai problems for security. In In
Proceedings of Eurocrypt, volume 2656, pages 294–311,
2003.

[43] I. H. Witten and E. Frank. Data mining: practical

machine learning tools and techniques with java
implementations. SIGMOD Rec., 31(1):76–77, 2002.

[44] D. Yarowsky. Unsupervised word sense disambiguation
rivaling supervised methods. In Proceedings of the 33rd
annual meeting on Association for Computational
Linguistics, pages 189–196, Morristown, NJ, USA,
1995. Association for Computational Linguistics.

[45] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and

E. Gillum. Botgraph: large scale spamming botnet
detection. In NSDI’09: Proceedings of the 6th
USENIX symposium on Networked systems design and
implementation, pages 321–334, Berkeley, CA, USA,
2009. USENIX Association.

[46] X. Zhu. Semi-supervised learning literature survey.

Technical Report 1530, Computer Sciences, University
of Wisconsin-Madison, 2005.

[47] X. Zhu, J. Laﬀerty, and Z. Ghahramani. Combining

active learning and semi-supervised learning using
gaussian ﬁelds and harmonic functions. In ICML 2003
workshop on The Continuum from Labeled to
Unlabeled Data in Machine Learning and Data
Mining, pages 58–65, 2003.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA510