Factorizing Personalized Markov Chains

for Next-Basket Recommendation

∗
Steffen Rendle

Department of Reasoning for

Intelligence

Christoph Freudenthaler

Information Systems and

Machine Learning Lab

Lars Schmidt-Thieme
Information Systems and

Machine Learning Lab

The Institute of Scientiﬁc and

Institute for Computer Science

Institute for Computer Science

Industrial Research

Osaka University, Japan

rendle@ar.sanken.osaka-

u.ac.jp

University of Hildesheim,

University of Hildesheim,

Germany

freudenthaler@ismll.uni-

hildesheim.de

Germany
schmidt-

thieme@ismll.uni-

hildesheim.de

ABSTRACT
Recommender systems are an important component of many
websites. Two of the most popular approaches are based on
matrix factorization (MF) and Markov chains (MC). MF
methods learn the general taste of a user by factorizing the
matrix over observed user-item preferences. On the other
hand, MC methods model sequential behavior by learning a
transition graph over items that is used to predict the next
action based on the recent actions of a user. In this paper, we
present a method bringing both approaches together. Our
method is based on personalized transition graphs over un-
derlying Markov chains. That means for each user an own
transition matrix is learned – thus in total the method uses
a transition cube. As the observations for estimating the
transitions are usually very limited, our method factorizes
the transition cube with a pairwise interaction model which
is a special case of the Tucker Decomposition. We show
that our factorized personalized MC (FPMC) model sub-
sumes both a common Markov chain and the normal matrix
factorization model. For learning the model parameters, we
introduce an adaption of the Bayesian Personalized Ranking
(BPR) framework for sequential basket data. Empirically,
we show that our FPMC model outperforms both the com-
mon matrix factorization and the unpersonalized MC model
both learned with and without factorization.

Categories and Subject Descriptors
I.2.6 [Artiﬁcial Intelligence]: Learning—Parameter Learn-
ing

General Terms
Algorithms, Experimentation, Measurement, Performance

Keywords
Basket Recommendation, Markov Chain, Matrix Factoriza-
tion
∗Steﬀen Rendle is currently on leave from the Machine
Learning Lab, University of Hildesheim, Germany.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2010, April 26–30, 2010, Raleigh, North Carolina, USA.
ACM 978-1-60558-799-8/10/04.

1.

INTRODUCTION

A core technology of many recent websites are recom-
mender systems. They are used for example to increase sales
in e-commerce, clicking rates on websites or visitor satisfac-
tion in general.
In this paper, we deal with the problem
setting where sequential basket data is given per user. An
obvious example is an online shop where a user buys items
(e.g. books or CDs). In these applications, usually several
items are bought at the same time, i.e. we have a set/basket
of items at one point of time. The target is now to recom-
mend items to the user that he might want to buy in his
next visit.

Recommender systems based on a Markov chain (MC)
model utilize such sequential data by predicting the users
next action based on the last actions. Therefore a transition
matrix is estimated that gives the probability of buying an
item based on the last purchases of the user. The transi-
tion matrix of the MC models is assumed to be the same
over all users. The personalization is made by applying the
(general) transition matrix on the user’s last actions. On
the other hand, one of the most successful model classes
are factorization methods (MF) based on matrix or ten-
sor decomposition. The best approaches [3, 4] for the 1M$
Netﬂix challenge1 are based on this model class. Also on
the ECML/PKDD discovery challenge2 for tag recommen-
dation, a factorization model based on tensor decomposition
has outperformed the other approaches [8]. These models
learn the general taste of the user disregarding sequential
information. Both MF and MC have their advantages: MF
uses all data to learn the general taste of the user whereas
MC can capture sequence eﬀects in time by using a non-
personalized transition matrix, i.e. the transition matrix is
learned over all data of all users.

In this paper, we present a model based on an underly-
ing MC where the transitions are user-speciﬁc. We model a
transition cube where each slice is a user-speciﬁc transition
matrix of an underlying MC on the users basket history.
With this personalization, we bring together both advan-
tages of MC and MF: (1) the sequential data is captured by
the transition matrix and (2) as all transition matrices are
user-speciﬁc, the user-taste over all data is captured. Besides
introducing personalized MCs, the central contribution of

1http://www.netﬂixprize.com/
2http://www.kde.cs.uni-kassel.de/ws/dc09

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA811this work is the estimation of the transition tensor. Because
of the sparsity of the data, it is not possible to get good
estimates of the personalized transition matrices by using
standard counting approaches (which are Maximum Likeli-
hood Estimators) on a complete parametrization. Instead,
we model the transition tensor by a factorization model.
This allows to propagate information among similar users,
similar items and similar transitions. By using a factoriza-
tion model based on pairwise interactions, it is possible to
deal with high sparsity. We show that this model subsumes
both the MF model and the unpersonalized MC model. For
learning the factorization parameters, the Bayesian Person-
alized Ranking (BPR) framework [7] is extended to basket
data.

In our evaluation chapter, we apply our method to an
anonymized real-world dataset of an e-commerce website.
We show that our proposed method FPMC outperforms MF
and MC.

In total the contributions are as follows:

• We introduce personalized Markov chains relying on
personalized transition matrices. This allows to cap-
ture both sequential eﬀects and long term user-taste.
We show that this is a generalization of both standard
MC and MF models.

• To deal with the sparsity for the estimation of transi-
tion probabilities, we introduce a factorization model
that can be applied both to personalized and normal
transition matrices. This factorization approach re-
sults in less parameters and due to generalization to a
better quality than full parametrized models.

• We empirically show that our model outperforms other

state-of-the-art methods on sequential data.

2. RELATED WORK

Markov chains or recommender systems have been stud-
ied by several researchers. Zimdars et al.
[10] describe
a sequential recommender based on Markov chains. They
investigate how to extract sequential patterns to learn the
next state with a standard predictor – e.g. a decision tree.
Mobasher et al. [5] use pattern mining methods to discover
sequential patterns which are used for generating recommen-
dations. Shani et al. [9] introduce a recommender based on
Markov decision processes (MDP) and also a MC based rec-
ommender. To enhance the maximum likelihood estimates
(MLE) of the MC transition graphs, they describe several
heuristic approaches like clustering and skipping.
Instead
of improving the MLE estimates with heuristics, we use a
factorization model that is learned for optimal ranking in-
stead of transition MLE. In total, the main diﬀerence of our
work to all the previous approaches is the use of person-
alized transition graphs which bring together the beneﬁts
of sequential, i.e. time-aware, MC with time-invariant user
taste. Furthermore factorizing transition probabilities and
optimizing the parameters for ranking is new.

On the other hand, most of the recommender systems do
not take sequential patterns into account and recommend
based on the whole user history. Besides a very large litera-
ture on rating prediction (i.e. regression) emerging from the
Netﬂix contest (e.g. [3, 4]), item recommendation from im-
plicit feedback has started to get more into the focus [2, 6, 7].
Item recommendation is a harder prediction problem than

rating prediction, as only positive observations are made
and standard sparse regression and classiﬁcation methods
like the ones from the Netﬂix contest can not directly be ap-
plied. Three recent methods for item recommendation are
based on the matrix factorization model that factorizes the
matrix of user-item correlations. Both Hu et al. [2] and Pan
and Scholz [6] optimize the factorization on user-item pairs
(u, i) where observed pairs are treated as positive and non-
observed ones as negative. Hu et al.
[2] use a least-square
optimization where case weights are used for controlling the
importance of observations. Pan and Scholz [6] also use case
weights but with several optimization criteria like hinge-loss
and least-square. Because non-observation of an item does
not mean that the user does not want to select it in the fu-
ture, Rendle et al. [7] take another optimization approach by
learning over observation pairs (u, i, j), e.g. a user u prefers
item i over item j. All these methods have been shown
to outperform standard approaches like k-nearest-neighbour
based on Pearson similarity. In this work, we will bring the
advantages of these MF models together with MC models.

Figure 1: Sequential basket data with four users and
ﬁve items {a, b, c, d, e}. The task is to recommend
items at time t given a basket history Bt−1, Bt−2, . . ..

3.

ITEM RECOMMENDATION FROM SE-
QUENTIAL SET DATA

Item recommendation is the task of suggesting a speciﬁc
user a personalized list of items (e.g. products, songs).
This can be seen as creating a personalized ranking on the
items. Usually, recommender systems rely on statistical
models that use the event history (e.g. purchases, listen-
ing) of users on items to generate recommendations. Time
and thus sequential behavior is an important additional in-
formation that is tracked in almost any real-world applica-
tion. Secondly, we consider the problem setting with set
data – e.g. in online-shopping usually a basket of products
is bought at the same time.
In total, our setting is item
recommendation from sequential set data. An example of
such data can be found in ﬁgure 1.

3.1 Sequential vs. General Recommender

The most common approach to generate recommendations
is to discard any sequential information and learn what items
a user is typically interested in. On the other hand, recom-
mendations of sequential methods (mostly relying on Mar-
kov chains) are based only on the last user events by learn-
ing what an arbitrary user buys next when he has bought
a certain item in the recent past. Both methods have their

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA812strengths and disadvantages. Imagine a user that in general
buys movies like ‘Star Trek’ and ‘Star Wars’.
In contrast
to his usual buying behavior, he recently has purchased ‘Ti-
tanic’ and ‘Dirty Dancing’ to watch with his girlfriend. After
that a MC based recommender of length 2 would only recom-
mend movies like ‘Notting Hill’ and other romantic movies.
In contrast, a global personalized recommender would cor-
rectly account for the general taste of the user and recom-
mend also movies like ‘Back To the Future’, ‘Alien’ or other
science ﬁction movies. But there are also examples where
sequential recommenders have advantages: E.g. good rec-
ommendations for a user that has recently bought a digital
camera are accessories that other users have bought after
buying that camera – this is exactly what a Markov chain
model does. Global personalized recommender would not
adapt directly to the recent purchase (the digital camera)
but would recommend items this user likes in general.

3.2 Formalization

Before describing our approach to solve this problem, we
introduce the notation of this paper. Let U = {u1, . . . , u|U |}
be a set of users and I = {i1, . . . , i|I|} a set of items. For
each user u, a purchase history Bu of his baskets is known:
Bu := (Bu
t ⊆ I. The purchase history
of all users is B := {Bu1 , . . . Bu|U | }.

tu−1) with Bu

1 , . . . Bu

Given this history, the task is to recommend items to a
user the next time t the user visits the shop. Note that we
deal not with absolute time points (i.e. 1st January 2010)
but with relative ones regarding a user, e.g. the ﬁrst, second,
etc. basket of a user. The item recommendation task can
be formalized in creating a personal ranking

<u,t⊂ I 2

over all pairs of items for user u for his t-th basket. With
this ranking, we can recommend the user the top n items.

4. FACTORIZING PERSONALIZED MAR-

KOV CHAINS (FPMC)

First, we introduce MC for sequential set data and ex-
tend this to personalized MCs. We discuss the weakness
of Maximum Likelihood Estimates for the transition cubes.
To solve this, we introduce factorized transition cubes where
information among transitions is propagated. We conclude
this section by combining both ideas into FPMCs.

4.1 Personalized Markov Chains for Sets

First, we describe how to model the unpersonalized MC
for sets with a reasonable state space. Then we show how
to estimate the parameters for this unpersonalized MC with
the maximum likelihood estimator (MLE). Afterwards, the
extension of both the model and the estimation to personal-
ized MCs is simple. Finally, we will show the limitations of
full parametrized transition graphs (i.e. one parameter per
transition) and the MLE method for personalized Markov
chains.

4.1.1 Markov Chains for Sets

In general, a Markov chain of order m is deﬁned as

p(Xt = xt|Xt−1 = xt−1, . . . , Xt−m = xt−m)

(1)

where Xt, . . . , Xtm are random variables and xt−m their re-
alizations. In a recommender application without sets, the

random variables are deﬁned over I – i.e. realizations are
single items i ∈ I. But in our case, the variables are deﬁned
over P(I) as the realizations are whole baskets B and thus
the size of the state space is 2|I|. Obviously, deﬁning a long
chain over the whole state space is not feasible for sets. To
handle this huge state space, we make two simpliﬁcations:
(1) we use chains of length m = 1 and (2) the transition
probabilities are simpliﬁed.

An unpersonalized Markov chain of order m = 1 for the

basket problem is:

p(Bt|Bt−1)

(2)

In recommender scenarios without sets, usually longer chains
(e.g. m = 3) are preferable [9] because a history with size
m = 1 contains only one item. In our case with sets, even
a chain with length m = 1 is reasonable because it relies
already on many items (all items of the basket) – e.g.
in
the application of our evaluation there are about 10 items
on average (see table 1).

Markov chains of length m = 1 are described by their sto-
chastic transition matrix A over the state space. In our case
the state space over sets is P(I) and thus the dimensionality
of the transition matrix would be 2|I| ×2|I|. Thus, instead of
modeling transition over baskets, we model transitions over
|I| binary variables that describe a set/ basket:

al,i := p(i ∈ Bt|l ∈ Bt−1)

(3)

Using this representation has the following implications:

• The state space is now I and thus the size of the tran-
sition matrix A is |I|2 – by factorization, we will later
reduce the number of parameters needed to represent
this space from |I|2 to 2 k |I| where k is the number of
latent dimensions used in the factorization model.

• The elements of the state space are i ∈ B which are
binary variables, thus p(i ∈ Bt|l ∈ Bt−1)+p(i 6∈ Bt|l ∈
Bt−1) = 1. Note that the transition matrix A is no

longer stochastic, because Pi∈I al,i 6= 1.

For item recommendation, we are interested in the probabil-
ity of purchasing an item given the last basket of a user. This
can be deﬁned as the mean over all transition probabilities
from purchases of the last basket to this item:

p(i ∈ Bt|Bt−1) :=

1

|Bt−1| Xl∈Bt−1

p(i ∈ Bt|l ∈ Bt−1)

(4)

And the full Markov chain over baskets can be expressed by:

p(Bt|Bt−1) ∝ Yi∈Bt

p(i|Bt−1)

(5)

Note that we are looking for a ranked list of items and thus
are not interested in the full Markov chain (eq. (5)), but in
sortable single-item probabilities (eq. (4)).

4.1.2 Estimation of Transition Probabilities

To make predictions using the Markov chain in eq. (4),
the transition probabilities al,i have to be estimated. The
maximum likelihood estimator for al,i given the data B is:

ˆal,i = ˆp(i ∈ Bt|l ∈ Bt−1) =

ˆp(i ∈ Bt ∧ l ∈ Bt−1)

ˆp(l ∈ Bt−1)

=

=

|{(Bt, Bt−1) : i ∈ Bt ∧ l ∈ Bt−1}|

|{(Bt, Bt−1) : l ∈ Bt−1}|

(6)

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA813Figure 2: Non-personalized Markov chain: The transition matrix contains the MLE estimates for the proba-
bility p(i ∈ Bt|l ∈ Bt−1) using the data of ﬁgure 1. The column # states how many observations were used to
estimate this transition. In this example, the users 1 and 2 as well as 3 and 4 share a similar taste for items
a, c and items c, e respectively. Thus, one would expect to ﬁnd d before b in the recommendation list for user
4, but the MC would recommend b as best unknown item.

An example for non-personalized MLE can be seen in ﬁgure
2. Here, the buying history for the four users of ﬁgure 1
are translated into transitions A of eq. (4). The transition
matrix can then be applied to predict which items should
be recommended given the last basket. E.g. for user 4, the
probabilities would be:

p(a ∈ Bt|{c, e}) = 0.5(0.3 + 0.0) = 0.15
p(b ∈ Bt|{c, e}) = 0.5(0.7 + 0.0) = 0.35
p(c ∈ Bt|{c, e}) = 0.5(0.3 + 0.0) = 0.15
p(d ∈ Bt|{c, e}) = 0.5(0.0 + 0.0) = 0.00
p(e ∈ Bt|{c, e}) = 0.5(0.3 + 1.0) = 0.65

As the user has already bought item c and e, the best recom-
mendation of unknown items would be b and then a. Look-
ing only at the items this and similar users have bought in
the past, one would expect, that item d might be a better
recommendation.

4.1.3 Personalized Markov Chains for Sets

Until now, the MC has been deﬁned unpersonalized, i.e.
independently of the user. Next, we extend this to a per-
sonalized MC per user:

p(Bu

t |Bu

t−1)

(7)

Again, we represent each MC by the transitions over items,
but now user-speciﬁc:

au,l,i := p(i ∈ Bu

t |l ∈ Bu

t−1)

(8)

And thus also the prediction depends only on the user’s tran-
sitions:

p(i ∈ Bu

t |Bu

t−1) :=

1
|Bu

t−1| Xl∈Bu

t−1

p(i ∈ Bu

t |l ∈ Bu

t−1)

(9)

Also MLE can be applied analogously but now the transi-
tions for user u are only estimated from his history Bu –
that means u is not a free variable anymore:

ˆau,l,i = ˆp(i ∈ Bu

t |l ∈ Bu

t−1) =

=

|{(Bu

t , Bu
|{(Bu

t−1) : i ∈ Bu
t , Bu

t−1) : l ∈ Bu

t ∧ l ∈ Bu
t−1}|

ˆp(i ∈ Bu

t ∧ l ∈ Bu

t−1)

t−1)

ˆp(l ∈ Bu
t−1}|

(10)

That means for each user we have an own transition matrix
Au which in total gives a transition tensor A ∈ [0, 1]|U |×|I|×|I|.

Figure (3) shows the personalized transition matrix of our
example. Many of the parameters cannot be estimated be-
cause there is no observation in the data. Also the transi-
tions that are estimated are based only on a small number of
observations that means they are unreliable. At ﬁrst glance,
using personalized MCs seems to be unreasonable. We will
discuss next what are the reasons for the poor estimations
and show how to ﬁx it.

4.1.4 Limitations of MLE and Full Parametrization
The problem of unreliable transition probabilities both
for unpersonalized and even more for personalized MCs lies
in the fact that they work with a full parametrized tran-
sition graph (e.g. matrix and tensor respectively) and the
way of parameter estimation. Full parametrization means
we have |I|2 and |U | |I|2 respectively independent parame-
ters for describing the transitions. Note that MLE estimates
each transition parameter al,i independently from the oth-
ers, i.e. none of the cooccurrences (l, i) will contribute to
another transition probability estimator (l, j) but only to
p(i ∈ Bt|l ∈ Bt−1). This is even worse for personalized MCs
as a triple (u, l, i) does not contribute to the estimate of
(u′, l, i). In addition, the important properties of MLE (e.g.
Gaussian distribution, unbiased estimator, minimal variance
under all unbiased estimators) only exist in asymptotic the-
ory. In cases of less data they suﬀer from underﬁtting. Since
in our scenario the data is extremely sparse, Maximum Like-
lihood Estimators easily fail.

To get more reliable estimates for the transitions, we fac-
torize the transition cube which breaks the independence of
the parameters and the estimation. This way, each transi-
tion is inﬂuenced by similar users, similar items and simi-
lar transitions because information propagates through this
model. In our evaluation, we show that this way (1) better
transition graphs than MLE can be generated for the non-
personalized setting and (2)
that personalized MCs
outperform both non-personalized factorized MC and
non-personalized full parametrized MLE MCs.

4.2 Factorizing Transition Graphs

In the following, we will derive a factorization model for
the transition cube A. That means we model the unobserved
transition tensor A by a low rank approximation ˆA. The
advantage of this approach over a full parametrization is
that it can handle sparsity and generalizes to unobserved

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA814Figure 3: Personalized Markov chains: For each user an individual transition matrix is given. The transition
matrices contain the MLE estimates for the probability p(i ∈ Bu
t−1). Entries with ? are missing values
as there is no data to estimate the probabilities. Obviously, estimating the personalized transition matrices
directly results in very poor transitions as each estimate is not reliable. This problem will be solved later by
factorizing the transitions.

t |l ∈ Bu

models like the Canonical Decomposition (CD) aka paral-
lel factor analysis (PARAFAC). The parallel factor model
assumes a diagonal core tensor, i.e.

cfu,fi,fj =(1,

0,

if fu = fi = fj
else

(14)

with equal factorization dimensionality: kU = kL = kI .

As the observed transitions for A are very sparse, we use

a special case of CD that models pairwise interactions:

ˆau,l,i := hvU,I

u , vI,U

i

i + hvI,L

i

, vL,I

l

i + hvU,L

u , vL,U

l

i

(15)

Figure 4: Personalized transition cube: Stacking all
transition matrices of the individual users leads to
a transition cube. Instead of a fully parametrized
cube which is very sparse, a factored cube is used to
generate better transition estimates.

or equivalently:

ˆau,l,i :=

kU,I

Xf =1

vU,I
u,f vI,U

i,f +

vI,L
i,f vL,I

l,f +

kI,L

Xf =1

kU,L

Xf =1

vU,L
u,f vL,U

l,f

(16)

data because information propagates through the model –
i.e. parameters inﬂuence each other.

4.2.1 Factorization of the Transition Cube

A general linear factorization model for estimating the

tensor A is the Tucker Decomposition (TD):

ˆA := C ×U V U ×L V L ×I V I

(11)

where C is a core tensor and V U is the feature matrix for
the users, V L is the feature matrix for the items in the last
transition (outgoing nodes) and V I is the feature matrix
for the items to predict (ingoing nodes). They have the
following structure:

C ∈ RkU ,kL,kI ,

V L ∈ R|I|×kL ,

V U ∈ R|U |×kU ,
V I ∈ R|I|×kI

(12)

(13)

with the factorization dimensions kU , kL and kI .

The Tucker Decomposition subsumes other factorization

This model directly models the pairwise interaction between
all three modes of the tensor, i.e. between U and I, U and J
as well as J and I. In total for each mode (i.e. user U, item
I, item J), we have two factorization matrizes:

1. For the interaction between U and I: V U,I ∈ R|U |×kU,I
modelling the user features and V I,U ∈ R|I|×kU,I for
the last item i.

2. For the interaction between I and L: V I,L ∈ R|I|×kI,L
for the next item i and V L,I ∈ R|I|×kI,L for the last
item l.

3. For the interaction between U and L: V U,L ∈ R|U |×kU,L
for the user features and V L,U ∈ R|I|×kU,L for the
features of the last item l.

An advantage of this model over TD is that the predic-
tion and learning complexity is much lower than for TD [8].
Furthermore even though TD and PARAFAC subsume the

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA815pairwise interaction model, with standard regularization es-
timation procedures have problems identifying such a model
[8].

In section 5 we describe how to optimize the model pa-
rameters (factorization matrices) for item recommendation.

4.2.2 Factorization of the Transition Matrix

The proposed model for factorizing transition cubes can
also be applied to estimate a transition matrix A (see for-
mula (3)) for cases where no personalization of the transition
graph is desired. By skipping the user-interactions in equa-
tion (15), a factorization model for normal transition graphs
is obtained:

ˆal,i := hvI,L

i

, vL,I

l

i

(17)

Also the parameter estimation method in section 5 can be
used for optimizing the factorization matrices.

4.3 Summary of FPMC

Bringing together the personalized set MC (eq. 9) with
the factorized transition cube (eq. 15) results in the factor-
ized personalized Markov chain (FPMC):

p(i ∈ Bu

t |Bu

t−1) =

1
|Bu

t−1| Xl∈Bu

t−1

p(i ∈ Bu

t |l ∈ Bu

t−1)

(18)

We model p(i ∈ Bu
ˆA:

t |l ∈ Bu

t−1) with the factorization cube

ˆp(i ∈ Bu

t |Bu

t−1) =

1
|Bu

t−1| Xl∈Bu

t−1

ˆau,l,i

=

1
|Bu

t−1| Xl∈Bu

t−1

(hvU,I

u , vI,U

i

i + hvI,L

i

, vL,I

l

i

+ hvU,L

u , vL,U

l

i)

(19)

And as the factorization (U, I) is independent of l, we can
remove it from the sum:

ˆp(i ∈ Bu

u , vI,U

i

i

t |Bu
t−1) = hvU,I
1
|Bu

t−1| Xl∈Bu

t−1“hvI,L

i

+

, vL,I

l

i + hvU,L

u , vL,U

l

i” (20)

In the next section, we apply this model to the task of item
recommendation. We will show that in this case, the model
can be simpliﬁed even more because the interaction between
U and L vanishes.

Besides better generalization of factorization models com-
pared to a full parametrized transition cube, a further ad-
vantage is that less parameters are needed.
Instead of
|U | · |I|2 parameters in a full parametrized cube or |I|2 in a
full parametrized matrix, the factorization model only needs
2 · kI,L · |I| parameters for the non-personalized model and
2 · kI,L · |I| + kU,I · (|U | + |I|) parameters for the personalized
model. This is especially important for applications with a
high number of items where a full parametrization with |I|2
parameters might not be feasible.

5.

ITEM RECOMMENDATION FROM SE-
QUENTIAL SET DATA WITH FPMC

So far, a factorization model for personalized Markov
chains has been introduced.
In the following, we will ap-
ply this model to the task of item recommendation. That

means, the model parameters should be optimized for rank-
ing. First, we derive S-BPR which is a general optimization
criterion for item recommendation from sequential set data.
This optimization criterion is not limited to our FPMC model
and can be applied also to other models like kNN or standard
MF. Secondly, we apply S-BPR to FPMC and show how the
model can be simpliﬁed in the case of item recommendation
using S-BPR. Afterwards we present a stochastic gradient
descent learning algorithm based on bootstrap sampling for
optimizing the model parameters with S-BPR.

5.1 Optimization Criterion S-BPR

As described in section (3), the goal of item recommenda-
tion from sequential basket data is to derive a ranking >u,t
over the items. To model the ranking, we assume there is an
estimator ˆx : U × T × I → R – e.g. the buying probability
of the personalized Markov Chain – which is used to deﬁne
the ranking:

i >u,t j :⇔ ˆxu,t,i >R ˆxu,t,j

(21)

As >R is a total order on (a closed subset of) the real num-
bers R, also >u,t will be a total order. Thus ˆxu,t,i is able to
generate a personalized ranking3 for a speciﬁc time t on the
items I.

Next, we derive the sequential BPR (S-BPR) optimization
criterion analogously to the general BPR approach [7]. The
best ranking >u,t⊂ I 2 for user u at time t can be formalized
as:

p(Θ| >u,t) ∝ p(>u,t |Θ) p(Θ)

where Θ are the model parameters – in our case the param-
eters are Θ = {V U,I , V I,U , V L,I , V I,L, V U,L, V L,U }.

Assuming independence of baskets and users, this leads
to the maximum a posterior (MAP) estimator of the model
parameters:

argmax

Θ Yu∈U YBt∈Bu

p(>u,t |Θ) p(Θ)

(22)

Expanding >u,t for all item-pairs (i, j) ∈ I 2 and using the
same assumptions as in [7], the probability of p(>u,t |Θ) can
be rewritten as:

Yu∈U YBt∈Bu Yi∈Bt Yj6∈Bt

p(i >u,t j|Θ)

(23)

Next we use the model deﬁnition of eq.
p(i >u,t j|Θ):

(21) to express

p(i >u,t j|Θ) = p(ˆxu,t,i >R ˆxu,t,j | Θ)

= p(ˆxu,t,i − ˆxu,t,j >R 0 | Θ)

(24)
(25)

The Θ can be skipped as they are the model parameters for
ˆx – i.e. ˆx = ˆx(Θ). And we deﬁne p(z > 0) := σ(z) = 1
using the logistic function σ:

1+e−z

p(i >u,t j|Θ) = σ(ˆxu,t,i − ˆxu,t,j)

(26)

Furthermore, we assume Gaussian priors on the model pa-
rameters: θ ∼ N (0, 1
λθ

).

3In case of identities ˆxu,t,i = ˆxu,t,j a random order between
these two is chosen.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA816In total this leads to the MAP-estimator for sequential

Factorizing an unpersonalized Markov chain using equa-

BPR:

argmax

ln p(>u,t |Θ) p(Θ)

Θ

= argmax

= argmax

Θ

ln Yu∈U YBt∈Bu Yi∈Bt Yj6∈Bt
Θ Xu∈U XBt∈Bu Xi∈Bt Xj6∈Bt

σ(ˆxu,t,i − ˆxu,t,j)p(Θ)

ln σ(ˆxu,t,i − ˆxu,t,j) − λΘ||Θ||2
F

(27)

where λΘ is the regularization constant corresponding to σΘ.

5.2 Item Recommendation with FPMC

For item recommendation with FPMC, we express ˆx by
the FPMC model and apply S-BPR. We will show that one
of the pairwise eﬀects of FPMC vanishes which leads to a
more compact model.

First, we use FPMC to express ˆx:

ˆx′
u,t,i := ˆp(i ∈ Bu
t |Bu
1
|Bu

u , vI,U

i+

= hvU,I

i

t−1)

t−1| Xl∈Bu

t−1“hvI,L

i

, vL,I

l

i + hvU,L

u , vL,U

l

i”

Lemma 1

(Invariance of (U,L) decomposition). For

ranking of items and optimization with S-BPR, the FPMC
model is invariant to the (U,L) decomposition, i.e. ˆx′ is
invariant to ˆx with:

ˆxu,t,i := hvU,I

u , vI,U

i

i +

1
|Bu

t−1| Xl∈Bu

t−1

hvI,L

i

, vL,I

l

i

(28)

Proof. Let >′ be the ranking generated by ˆx′ and > the
ranking of ˆx according to eq. (21). Two things have to be
shown: (1) both models (ˆx′ and ˆx) lead to the same ranking
and (2) learning both models with S-BPR leads to the same
parameters Θ. Both proofs rely on the fact that:

∀u, t, i, j : ˆx′

u,t,i − ˆx′

u,t,j = ˆxu,t,i − ˆxu,t,j

(29)

This holds because the additional termPl∈Bu

u , vL,U
in ˆx′
u,t,· is independent of i and j given u and t and thus van-
ishes on subtraction. Now it is easy to show the equivalence
of the rankings for all u, t, i, j:
u,t,i >R ˆx′

u,t j) ⇔ (ˆx′

u,t,j) ⇔ (ˆx′

u,t,i − ˆx′

u,t,j >R 0)

hvU,L

(i >′

t−1

i

l

eq.29
⇔ (ˆxu,t,i − ˆxu,t,j >R 0) ⇔ (ˆxu,t,i >R ˆxu,t,j ⇔ i >u,t j)

(2) The equivalence of model parameters under S-BPR op-
timization (eq. (27)) follows directly from eq. (29).

Thus for item recommendation with FPMC the simpler model
ˆx from eq. (28) should be used.

5.2.1 Expressiveness

Next, we will show the analogies of the simpliﬁed FPMC
model to standard matrix factorization (MF) and a factor-
ized Markov chain (FMC). First, we will recollect the deﬁni-
tions of MF and FMC. In our notation, the standard Matrix
factorization model for item recommendation [2, 6, 7] is:

ˆxMF
u,t,i = hvU,I

u , vI,U

i

i

(30)

where ˆx is independent of the sequential behaviour, i.e. in-
dependent of t.

tion (4) and (17) leads to:

ˆxFMC
u,t,i :=

1

|Bt−1| Xl∈Bt−1

hvI,L

i

, vL,I

l

i

(31)

Thus FPMC (eq. (28)) is a linear combination of both mod-
els:

ˆxFPMC
u,t,i = ˆxMF

u,t,i + ˆxFMC

u,t,i

(32)

This means FPMC can generalizes both models: By setting
the factorization dimensionality of (U,I) to zero (kU,I = 0)
a pure FMC is obtained and analogously setting kI,L = 0
leads to a pure MF model.

It is important to note, that even though the model equa-
tion for FPMC in the case of item recommendation can be
expressed by a combination of a MF and a FMC model, it
is diﬀerent from a simple ensemble of a single MF with a
single FMC model because in our case the model parame-
ters are learned jointly. Thus the learned model parameters
jointly represent the personalized Markov chain instead of
just pure user-item interactions and a global MC. This gets
more obvious in the general case of FPMC where the model
equation cannot be expressed by a linear combination of MC
and FMC. Examples are (1) optimizing for another objective
criterion (e.g. least-square) where the (U, L) decomposition
cannot be dropped because here the invariance to the objec-
tive (Lemma 1) does not hold like in S-BPR. And (2) using
another factorization model for A in FPMC than pairwise
interaction (e.g. PARAFAC or TD) also leads to a diﬀerent
model equation even for item recommendation with S-BPR.

5.3 Learning Algorithm

Next, we adapt the BPR-learning algorithm to S-BPR and
apply it to FPMC. As FPMC subsumes MF and FMC, both
of these models can also be optimized for S-BPR with the
provided algorithm.

t ∈ Bu, i ∈ Bu

Trying to optimize S-BPR directly is time consuming,
i.e.
because the number of (u, t, i, j) quadruples is huge,
O(|S| |I|) where S := {(u, t, i)|u ∈ U, Bu
t }.
Thus standard gradient descent and also basket-wise sto-
chastic gradient descent methods will converge very slowly
(see [7] for more details) and are not applicable for prob-
lems of reasonable size. Instead, we follow [7, 8] and draw
the quadruples independently by bootstrapping and perform
stochastic gradient descent on these bootstrap samples. This
learning method has been shown to be eﬃcient for two re-
lated problem classes: standard item recommendation [7]
and tag recommendation [8].

The complete algorithm is shown in ﬁgure 5.

In each
iteration a quadruple (u, t, i, j) is drawn consisting of an item
i in the basket Bu
t of user u at time t and an item j that is
not in this basket. Then gradient descent on S-BPR using
this quadruple is performed. The gradients of S-BPR with
respect to a model parameter θ and a given (u, t, i, j) are:

∂

∂θ `ln σ(ˆxu,t,i − ˆxu,t,j) − λθ θ2´

=(1 − σ(ˆxu,t,i − ˆxu,t,j))

∂
∂θ

(ˆxu,t,i − ˆxu,t,j) − 2 λθ θ

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA817draw V U,I, V I,U , V I,L, V L,I from N (0, σ2)
repeat

1: procedure LearnSBPR-FPMC(S)
2:
3:
4:
5:
6:
7:

draw (u, t, i) uniformly from S
draw j uniformly from (I \ Bu
t )
δ ← (1 − σ(ˆxu,t,i − ˆxu,t,j))
for f ∈ {1, . . . , kU,I } do

8:

9:

10:
11:
12:

13:

14:

15:
16:

17:

u,f + α“δ (vI,U
i,f + α“δ vU,I
j,f + α“−δ vU,I

vU,I
u,f ← vU,I
i,f ← vI,U
vI,U
vI,U
j,f ← vI,U
end for
vL,I
η ← 1
|Bu
l,f
for f ∈ {1, . . . , kI,L} do

t−1| Pl∈Bu

t−1

j,f ) − λU,I vU,I

i,f − vI,U
u,f − λI,U vI,U

u,f”

u,f − λI,U vI,U

i,f ”
j,f ”

vI,L
i,f ← vI,L
j,f ← vI,L
vI,L
for l ∈ Bu

i,f + α“δ η − λI,L vI,L
i,f ”
j,f + α“−δ η − λI,L vI,L
j,f ”

t−1 do
vL,I
l,f ← vL,I

l,f + α„δ

I,L
i,f −v
v
|Bu

I,L
j,f

l,f «
t−1| − λL,I vL,I

end for

end for

18:
19:
20:
21:
22: end procedure

until convergence
return V U,I , V I,U , V I,L, V L,I

Figure 5: Optimizing FPMC for S-BPR with
learning rate α and regularization parameters
λU,I , λI,U , λI,L, λL,I .

with

∂

∂vU,I
u,f
∂

∂vI,U
i,f
∂

∂vI,U
j,f
∂

∂vL,I
l,f
∂

∂vI,L
i,f

∂

∂vI,L
j,f

(ˆxu,t,i − ˆxu,t,j) = vI,U

i,f − vI,U

j,f

(ˆxu,t,i − ˆxu,t,j) = vU,I
u,f

(ˆxu,t,i − ˆxu,t,j) = −vU,I
u,f

(ˆxu,t,i − ˆxu,t,j) =

(ˆxu,t,i − ˆxu,t,j) =

1
|Bu
t−1|
1
|Bu

(ˆxu,t,i − ˆxu,t,j) = −

(vI,L

i,f − vI,L
j,f )

t−1

t−1| Xl∈Bu
t−1| Xl∈Bu

1
|Bu

t−1

vL,I
l,f

vL,I
l,f

The complexity of the algorithm is O(#it (kU,I + kI,L |B|))
where |B| the average basket size in B and #it is the number
of iterations.

6. EVALUATION

We empirically compare the recommender quality of our
proposed factorized MC methods (factorized personalized
Markov chain FPMC and factorized Markov chain FMC)
to non-factorized Markov chain (‘MC dense’), matrix fac-
torization (MF) and the most-popular baseline (MP) – i.e.
ranking all items by how often they have been bought in the
past. Note that this comparison includes the strong base-
line method BPR-MF [7]. As MF (kI,L = 0) and FMC

(kU,I = 0) are a special case of FPMC, we use the FPMC
learning algorithm for all three methods.

6.1 Dataset

We evaluate our recommender on anonymized purchase
data of an online drug store4. The dataset we used is a 10-
core subset, i.e. every user bought in total at least 10 items

(PB∈Bu |B|) > 10 and vice versa each item was bought by

at least 10 users. The statistics of the dataset can be found
in table 1. We also created a dense subset of the 10-core
dataset to study the eﬀect of sparsity on the methods.

6.2 Evaluation Metrics

We evaluated by splitting the dataset S into two non over-
lapping sets: a training set5 Strain and a testing set Stest.
This split is done by putting the last basket for each user
into Stest and the remaining ones into Strain. The recom-
menders were trained on Strain and then the performance
on Stest is measured. We removed those users from the eval-
uation that have bought less then 10 diﬀerent items in the
past (i.e. Strain). Secondly, for each user we removed all
items from the test baskets (and the corresponding predic-
tions) that this user has already bought in the past – this is
because we want to recommend to the user items that are
new/ unknown to him. Note that this makes the predic-
tion task much harder and explains the low f-measure of all
methods in ﬁgure 6. Otherwise just rerecommending already
bought items would be a simple but very successful strategy
for non-durable products in drug stores like toothbrushes
or cleaner. However, this is not the task of recommender
systems because they should help the user to discover new
things.

The quality is measured for each user u on the basket
Bu in the test dataset. Therefore we rank all items with
our methods and let ˆru : I ↔ {1, . . . , |I|} be the (bijective)
mapping from an item i to its (predicted) rank. We use the
following quality measures to evaluate the estimated ranking
against the actual bought items:

• Half-life-utility (HLU) aka ‘Breese score’ [1]:

HLU(B, ˆru) := 100 P|I|

r=1 δ(ˆr−1

α−1

u (r) ∈ B) 2− r−1
r=1 2− r−1
P|B|

α−1

Where we set the half-life parameter α to 5. We report
the average HLU over all test baskets.

• Precision and recall of the top-N list:

T op(ˆru, N ) := {ˆr−1

u (1), . . . , ˆr−1
|Top(ˆru, N ) ∩ B|

u (N )}

Prec(B, ˆru, N ) :=

Rec(B, ˆru, N ) :=

N

|Top(ˆru, N ) ∩ B|

|B|

We report the f-measure (harmonic mean) over the av-
erage precision and average recall over all test baskets
using top-5 list.

4http://www.rossmannversand.de/
5Hyperparameter search is done by removing for each user
the last basket of Strain and using these baskets for the val-
idation set.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA818Table 1: Characteristics of the datasets in our experiments in terms of number of users, items, baskets and
triples (u, i, t) where t is the sequential time of the basket. The dense dataset is a subset of the sparse one
containing the 10,000 users with most purchases and the 1000 most purchased items.

dataset
Drug store 10-core (sparse)
Drug store (dense)

users |U |
71,602
10,000

items |I|
7,180
1,002

baskets
233,476
90,655

avg. basket size
11.3
9.2

avg. baskets per user
3.2
9.0

triples
2,635,125
831,442

Table 2: Properties of the MC transition matrix estimated by the counting scheme. For the sparse dataset,
only 12% of the entries of the transition matrix are non-zero and non-missing. For the dense subset, 88% are
ﬁlled.

dataset
Drug store 10-core (sparse)
Drug store (dense)

total
51,552,400 (100%)
1,004.004 (100%)

missing values
1,041,100 (2.0%)
0 (0.0%)

non-zero
6,234,371 (12.1 %)
889,419 (88.6 %)

zero
44,276,929 (85.9%)
114,585 (11.4%)

• Area under the ROC curve:

AUC(B, ˆru) :=

1

|B| · |I \ B| Xi∈B Xj∈I\B

δ(ˆru(i) < ˆru(j))

We report the average AUC over all test baskets.

The runtime of model training linearly depends on the num-
ber of features. With our implementation, training of the
largest models (k = 128) took about 4 hours for MF, 31
hours for FMC and 34 hours for FPMC on the larger (sparse)
dataset.

6.3 Results

In ﬁgure 6 you can see the quality on the sparse and dense
online-shopping dataset. For the factorization methods we
run each method with kU,I = kI,L ∈ {8, 16, 32, 64, 128} fac-
torization dimension. The x-axis of the diagrams reﬂects this
increasing dimensionality. As expected all methods outper-
form the most-popular baseline clearly on both datasets and
all quality measures. Secondly, with reasonable factorization
dimensions (e.g. 32) all the factorization methods outper-
form the standard MC method. And in total, the factorized
personalized MC (FPMC) outperforms all other methods.

6.3.1 MC vs. FMC

First, we want to discuss the advantage of factorization
over a dense transition model by comparing MC with non-
personalized FMC. The results indicate that learning a fac-
torized transition matrix leads to better estimates than usual
counting schemes. Factorization has two advantages (1) it
can densify a sparse transition matrix and (2) it prevents
overﬁtting of the estimates by using a low-rank approxima-
tion. The sparseness of the transition matrix estimated by
counting schemes can be seen in table 2. In the dense set-
ting also the transition matrix is ﬁlled in 88% whereas on
the sparse dataset this drops to 12%. Comparing the qual-
ity on the sparse and dense setting in ﬁgure 6, one can see
that the advantages of FMC over MC are much higher in
the sparse setting than in the dense one. But even in the
dense setting where also MC’s transition matrix is almost
completely ﬁlled, FMC outperforms MC because the factor-
ization prevents overﬁtting by using less parameters.

6.3.2 MF vs. FMC vs. FPMC

Comparing the factorized Markov chain with the matrix
factorization, one can see that in the dense setting MF seems

to outperform MC whereas in the sparse one MC is supe-
rior. The reason could be that in the dense setting there is
much more information per user, thus the MF method using
all the users purchase information has advantages over the
MC model that only relies on the last purchases. And the
other way around, MC has advantages on the sparse dataset.
FPMC that combines the advantages of both methods out-
performs them on both datasets.

7. CONCLUSION

In this paper, we have introduced a recommender method
based on personalized Markov chains over sequential set
data.
Instead of using the same transition matrix for all
users, this method uses an individual transition matrix for
each user which in total results in a transition cube. As di-
rect estimation (e.g. by Maximum Likelihood) over a full
parametrized transition cube leads to very poor estimates,
we introduce a factorization model that gives a low-rank ap-
proximation to the transition cube. The advantages of this
approach is that each transition is inﬂuenced by transitions
of similar users, similar items and similar transitions. Thus
the quality of the ﬁnal transition graph is much higher than
that of a full parametrized model. Secondly, we apply fac-
torized personalized Markov chains (FPMC) to the task of
item recommendation with sequential set data by extending
the BPR framework [7]. Additionally, we show that FPMC
subsumes the popular matrix factorization model and a non-
personalized factorized Markov chain. Due to the expres-
siveness of FPMC it combines the advantages of both the
state-of-the-art global personalized approach (MF) and the
sequential MC method. Empirically, we show on real-world
data that FPMC outperforms MF, FMC and normal MC
both on sparse and dense data.

Acknowledgments
We would like to thank Artus Krohn-Grimberghe for pre-
paring the data set. Steﬀen Rendle is supported by a re-
search fellowship of the Japan Society for the Promotion of
Science (JSPS). This work is partially co-funded through
the European Commission FP7
project MyMedia
(www.mymediaproject.org) under the grant agreement no.
215006.
This work is co-funded by the European
Regional
LEFOS
(www.ismll.uni-hildesheim.de) under the grant agreement
no. 62700.

Development

Fund

project

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA819Online−Shopping (sparse)

Online−Shopping (sparse)

Online−Shopping (sparse)

7

6

5

4

3

8

7

6

5

4

 

5
p
o
T
@
 
e
r
u
s
a
e
M
−
F

SBPR−FPMC
SBPR−FMC
SBPR−MF
MC dense
most popular

20

40

60

80

100

120

Dimensionality

Online−Shopping (dense)

 

 

5
p
o
T
@
e
r
u
s
a
e
M
−
F

SBPR−FPMC
SBPR−FMC
SBPR−MF
MC dense
most popular

0
5
0
.
0

0
4
0
.
0

0
3
0
.
0

0
2
0
.
0

0
5
0
.
0

0
4
0
.
0

0
3
0
0

.

0
2
0
0

.

)

C
U
A

(
 
e
v
r
u
c
 
C
O
R

 
r
e
d
n
u
 
a
e
r
A

4
8
.
0

2
8
.
0

0
8
.
0

8
7
.
0

6
7
.
0

SBPR−FPMC
SBPR−FMC
SBPR−MF
MC dense
most popular

SBPR−FPMC
SBPR−FMC
SBPR−MF
MC dense
most popular

20

40

60

80

100

120

20

40

60

80

100

120

Dimensionality

Dimensionality

Online−Shopping (dense)

Online−Shopping (dense)

)

C
U
A

(
 
e
v
r
u
c
 
C
O
R

 
r
e
d
n
u
a
e
r
A

 

0
8
.
0

5
7
.
0

0
7
0

.

5
6
0

.

0
6
0

.

SBPR−FPMC
SBPR−FMC
SBPR−MF
MC dense
most popular

SBPR−FPMC
SBPR−FMC
SBPR−MF
MC dense
most popular

)

U
L
H

(
 
y
t
i
l
i
t
u
 
e
f
i
l

−

f
l
a
H

)

U
L
H

(
 
y
t
i
l
i
t

u
e

 

f
i
l

−

f
l

a
H

20

40

60

80

100

120

20

40

60

80

100

120

20

40

60

80

100

120

Dimensionality

Dimensionality

Dimensionality

Figure 6: Comparison of factorized personalized Markov chains (FPMC) to a factorized Markov chain (FMC),
matrix factorization (MF) [7], a standard dense Markov chain (MC dense) learned with Maximum Likelihood
and the baseline ‘most-popular’. The factorization dimensionality is increased from 8 to 128.

8. REFERENCES
[1] J. S. Breese, D. Heckerman, and C. Kadie. Empirical

analysis of predictive algorithms for collaborative
ﬁltering. In Proceedings of the Fourteenth Conference
on Uncertainty in Artiﬁcial Intelligence (UAI-98),
pages 43–52, San Francisco, 1998. Morgan Kaufmann.

[2] Y. Hu, Y. Koren, and C. Volinsky. Collaborative
ﬁltering for implicit feedback datasets. In IEEE
International Conference on Data Mining (ICDM
2008), pages 263–272, 2008.

[3] Y. Koren. Factorization meets the neighborhood: a

multifaceted collaborative ﬁltering model. In KDD ’08:
Proceeding of the 14th ACM SIGKDD international
conference on Knowledge discovery and data mining,
pages 426–434, New York, NY, USA, 2008. ACM.

[4] Y. Koren. Collaborative ﬁltering with temporal

dynamics. In KDD ’09: Proceedings of the 15th ACM
SIGKDD international conference on Knowledge
discovery and data mining, pages 447–456, New York,
NY, USA, 2009. ACM.

[5] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa.

Using sequential and non-sequential patterns in
predictive web usage mining tasks. In ICDM ’02:
Proceedings of the 2002 IEEE International
Conference on Data Mining, page 669, Washington,
DC, USA, 2002. IEEE Computer Society.

[6] R. Pan and M. Scholz. Mind the gaps: weighting the

unknown in large-scale one-class collaborative
ﬁltering. In KDD ’09: Proceedings of the 15th ACM
SIGKDD international conference on Knowledge
discovery and data mining, pages 667–676, New York,
NY, USA, 2009. ACM.

[7] S. Rendle, C. Freudenthaler, Z. Gantner, and

L. Schmidt-Thieme. BPR: Bayesian personalized
ranking from implicit feedback. In Proceedings of the
25th Conference on Uncertainty in Artiﬁcial
Intelligence (UAI 2009), 2009.

[8] S. Rendle and L. Schmidt-Thieme. Pairwise

interaction tensor factorization for personalized tag
recommendation. In Proceedings of the Third ACM
International Conference on Web Search and Data
Mining (WSDM 2010). ACM, 2010.

[9] G. Shani, D. Heckerman, and R. I. Brafman. An

mdp-based recommender system. Journal of Machine
Learning Research, 6:1265–1295, 2005.

[10] A. Zimdars, D. M. Chickering, and C. Meek. Using

temporal data for making recommendations. In UAI
’01: Proceedings of the 17th Conference in Uncertainty
in Artiﬁcial Intelligence, pages 580–588, San
Francisco, CA, USA, 2001. Morgan Kaufmann
Publishers Inc.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA820