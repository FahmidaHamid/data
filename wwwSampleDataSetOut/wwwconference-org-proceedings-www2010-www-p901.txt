Optimal Rare Query Suggestion With Implicit User

Feedback

Yang Song, Li-wei He

Microsoft Research,
One Microsoft Way,

Redmond, WA 98052, USA

{yangsong, lhe}@microsoft.com

ABSTRACT
Query suggestion has been an eﬀective approach to help
users narrow down to the information they need. How-
ever, most of existing studies focused on only popular/head
queries. Since rare queries possess much less information
(e.g., clicks) than popular queries in the query logs, it is
much more diﬃcult to eﬃciently suggest relevant queries to
a rare query. In this paper, we propose an optimal rare query
suggestion framework by leveraging implicit feedbacks from
users in the query logs. Our model resembles the principle of
pseudo-relevance feedback which assumes that top-returned
results by search engines are relevant. However, we argue
that the clicked URLs and skipped URLs contain diﬀerent
levels of information and thus should be treated diﬀerently.
Hence, our framework optimally combines both the click
and skip information from users and uses a random walk
model to optimize the query correlation. Our model speciﬁ-
cally optimizes two parameters: (1) the restarting (jumping)
rate of random walk, and (2) the combination ratio of click
and skip information. Unlike the Rocchio algorithm, our
learning process does not involve the content of the URLs
but simply leverages the click and skip counts in the query-
URL bipartite graphs. Consequently, our model is capa-
ble of scaling up to the need of commercial search engines.
Experimental results on one-month query logs from a large
commercial search engine with over 40 million rare queries
demonstrate the superiority of our framework, with statis-
tical signiﬁcance, over the traditional random walk models
and pseudo-relevance feedback models.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Text Mining

General Terms
Algorithms

Keywords
query suggestion, random walk, pseudo-relevance feedback,
query log analysis

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2010, April 26–30, 2010, Raleigh, North Carolina, USA.
ACM 978-1-60558-799-8/10/04.

1.

INTRODUCTION

Web search engines have completely changed the way peo-
ple acquire information during the last ten years. By pro-
viding a comprehensive portal between the Internet users
and the Web, search engines are able to take a user query
and return a ranked list of web pages according to the rel-
evance between queries and the search engine index, which
consists a subset of the entire Web. Recent study indicates
that search is still quite diﬃcult, approximately 50% of times
search engines fail to return relevant documents.

The reason of failure is that the length of the queries is
usually quite short, so that understanding user intents cor-
rectly has been a critical yet quite diﬃcult task for search
engines. Among a variety of techniques, query suggestion
related techniques [1, 2, 3, 8, 11, 12, 14, 18] have become an
eﬀective way to interact between users and search engines,
hence to improve the relevance of search results.

Among all query suggestion techniques, one of the most
important and eﬀective techniques refers to query log anal-
ysis [2, 3, 8, 12, 18]. Speciﬁcally, query logs are server-end
logs that record user activities in search engines. A typi-
cal query log entry contains timestamp, query, clicked Urls
as well as user personal information.
In order to learn a
query suggestion model, a commonly used approach is to
leverage graph representation which forms query and URL
relationship into bipartite graphs. A query-URL bipartite
graph usually consists of two disjoint sets of nodes, corre-
sponding to queries and URLs respectively. An example of
this bipartite representation has been shown in Figure 1(a),
where the left-hand set of nodes are queries and the right-
hand set are URLs. The edge between a query q and a URL
u indicates user clicks of u when issuing q (for simplicity,
the click numbers are omitted from the graph). The click
graph possesses large amount of potential information that
can be learnt for query suggestion, query clustering, query
reformulation and so on. As a matter of fact, a myriad of
techniques have been proposed. Among them, random walk
technique is one of the most eﬀective methods [12, 7].

However, leveraging only the click information has a seri-
ous drawback. That is, the models learnt from click graph
can only beneﬁt popular queries which possess enough user
click feedbacks. While for rare queries that have only ap-
peared a handful of times in the logs with very few clicks,
click graph is unable to capture the underlying relationship
between queries. For example, in Figure 1(a), q1 and q2
do not have commonly clicked URLs, thus a random walk

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA901Queries Urls

Queries

Urls

audi parts

audi bodywork

audi

q1

q2

q3

u1

u2

u3

u4

u5

audipartstore.com

audiusa.com

audi parts

q1

audirepair.autorepairlocal.com

NWaAudidealers.com

audi bodywork

en.wikipedia.org/wiki/Audi

audi

q2

q3

u1

u2

u3

u4

u5

audipartstore.com

audiusa.com

audirepair.autorepairlocal.com

NWaAudidealers.com

en.wikipedia.org/wiki/Audi

(a)  Click Graph

(b)  Skip Graph

Figure 1: An illustrative example of query-URL click graph (a) and skip graph (b). Query audi parts and audi
bodywork are not correlated if only performs random walk on the click graph, but will be highly correlation
if random walk is performed on the skip graph. More details on the text.

model which discovers query relationship according to their
common clicks is unable to discover any correlation between
q1 and q2.

While it is well known that in search engines, query fre-
quencies follow a power-law distribution where most queries
are issued very few times by users, rare queries together
constitute a great amount of search traﬃc which potentially
aﬀects the relevance and revenue of search engines signiﬁ-
cantly. Therefore, the lack of eﬃcient and eﬀective proposals
to deal with rare queries needs our immediate attentions.
1.1 Motivation of Our Work

Figure 1 presents a motivation of our approach. The left
ﬁgure (a) shows the click graph for three queries and ﬁve
URLs that returned as top SERP results. Ideally, audi parts
should be a good suggested query for audi bodywork (and
vice versa). However, after performing a random walk on
the click graph, only the query audi can be suggested to audi
parts because there is no commonly clicked URLs between
audi parts and audi bodywork so that their correlation is zero.
However, if we leverage the top-skipped URLs1 for audi parts
and audi bodywork as shown in Figure 1(b), it can be clearly
observed that both queries skipped their top-returned two
URLs: NwaAudidealers.com and en.wikipedia.org/wiki/Audi.
As a result, a random walk on the skip graph will assign a
high correlation score to these two queries.

Our work is inspired by the principle of pseudo-relevance
feedback [16, 15, 10, 20, 19] which assumes that the top-
k returned documents from search engines are always rele-
vant to the queries, regardless of whether they are clicked or
not. However, for rare queries, many times the top skipped
URLs contain diﬀerent levels of information than the clicked
URLs. Because top-returned URLs are more likely to have
high static rank scores which are representative of the high-
level topic that the query belongs to. e.g., the URL u5 is a
general entry about audi, while queries audi parts and audi
bodywork address diﬀerent aspects of user need of the spe-
ciﬁc car model. Although users who issued these two queries
clicked on more speciﬁc URLs like audipartstore.com, a gen-
eral URL oﬀers a potential topic link between these queries.
To further back up our argument regarding using both
clicked and skipped URLs for rare query suggestion, we care-

1We deﬁne a URL to be skipped if it was viewed by the user
without being clicked. So if a user clicked the 3rd-ranked
URL, then the 1st and 2nd URLs are said to be skipped.

fully analyzed query logs from a commercial search engine.
Figure 2 shows user session statistics in one of the data sets
we use in the experiment which contains 40 million unique
queries. The ﬁgure compares the query frequency (x-axis)
against the number of clicked and skipped URLs (y-axis). It
can be observed that when the query frequency is low, more
URLs are skipped than clicked during the same user session.
However, with the increase of query popularity, the click pat-
terns become more stable. Generally, users are tend to click
more often on top-returned results for popular queries, while
for rare queries, the clicks are more random and thus have
higher entropy scores.

We further analyzed the quality of skipped URLs for rare
queries. We selected 6,000 queries which have been issued
less than 20 times within a week and asked human judgers
to judge the relevance on a 1-5 scale (5 means the best). Fig-
ure 3 demonstrates the comparative ratings between skipped
and clicked URLs. Overall, skipped URLs indicate a little
bit less relevance than clicked URLs. On average, clicked
URLs have a rating of 3.78 while skipped URLs have 3.65.
This observation further supports our claim that skipped
URLs should be leveraged for rare queries in the context of
relevance measurement.
1.2 Contribution of This Paper

In this paper, we propose a novel graph combination-
based rare query suggestion framework. Our proposal can
be sketched into four major steps:

1. construct two query-URL bipartite graphs from query
logs, where the click graph contains query-URL click
information and the skip graph contains query-URL
skip information,

2. perform random walk on each of the graphs, using the

random walk with restart (RWR) technique [17],

3. build a correlation matrix for URLs from the category

of URLs,

4. based on the URL correlation, iteratively optimize the
model to estimate the best parameters of random walk
and the combination rate of click and skip graphs. Fi-
nally, combine two query correlation matrices to form
the optimal query correlation matrix, which is used for
query suggestion.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA902s
L
R
U

 
f
o
#

 

14

12

10

8

6

4

2

0
 
0

 

URLs Clicked

10

20

30

50

40
60
Query Frequency

70

80

90

100

s
L
R
U

 
f
o
#

 

14

12

10

8

6

4

2

0
 
0

 

URLs Skipped

10

20

30

50

40
60
Query Frequency

70

80

90

100

Figure 2: Number of URLs clicked vs. number of
URLs skipped in the same user sessions from one
week search log. There are more URLs skipped than
clicked for queries with lower frequencies.

Our model speciﬁcally addresses two concerns. First, how
to choose the optimal restarting rate for the random walk?
Second, given two query-URL correlation matrices, how to
optimally combine them? The reason is that the restart-
ing rate directly aﬀects the transition probability of random
walk from nodes to nodes, which aﬀects the distribution of
query relevance scores that is critical for determining the
most relevant neighbor nodes. On the other hand, the com-
bination rate decides the level of contributions from click
and skip graphs respectively. In pseudo-relevance feedback
models, this ratio is the same for both clicked and skipped
URLs, which is not optimal in practice for rare queries, as
we shall see in the empirical analysis.

To the best of our knowledge, we are among the ﬁrst to
address the importance of the restarting rate (or jumping
rate) of random walk, and optimize the parameter in a prin-
cipled way. In other random walk-like models, this rate is
either pre-ﬁxed (e.g., the original PageRank paper [13] used
0.85 as the jumping rate), or empirically chosen without any
support information [7].

The rest of the paper is organized as follows: Section 2
presents the literature in query suggestion, query clustering
related research; Section 3 introduces our framework for op-
timal rare query suggestions; Section 4 provides empirical
results on the performance of our model; ﬁnally, Section 5
concludes our proposal with future work.

2. RELATED WORK

A variety of research eﬀorts have been devoted to ad-
dress query suggestion related problems in literature, such
as query classiﬁcation, query clustering and query reformu-
lation. Among them, most of the proposals directly or in-
directly make use of query logs that contain query click in-
formation. By representing the relationship between queries
and URLs into a click graph, many researchers have investi-
gated in using random walk-related techniques for learning
underlying query-document relevance. In [7], Craswell and
Szummer proposed a Markov random walk model on the
click graph to rank documents given a user query. The au-
thors proposed a backward random walk comparing to the
traditional forward random walk techniques such as page
rank [13]. Speciﬁcally, the backward walk addresses the
bias towards documents with more clicks in the forward
walk models, by assuming a uniform prior on all documents.
Experimental results indicate that the backward model are
more eﬀective in retrieving relevant documents for images.
Essentially, the backward model can be treated as a nor-

 

URL Skipped
URL Clicked

5

4.5

4

3.5

3

2.5

2

1.5

1

0.5

 

g
n
i
t
a
R
L
R
U
 
e
g
a
r
e
v
A

0

 

2

4

6

8

10
12
Query Frequency

14

16

18

20

Figure 3: Human judger ratings in terms of rele-
vance for clicked and skipped URLs in query logs.
Break down accordingly to query frequency. Clicked
URLs and skipped URLs have almost the same rat-
ings for rare queries (queries with frequency less
than 20).

malization on the document clicks instead of query counts.
Thus the most likely transition from a document to query
will not be aﬀect by the raw account of the queries, which
eliminates the click bias.

Similarly, Deng et. al [9] proposed an entropy-bias frame-
work to represent the edge weights between query and URLs.
Comparing to the traditional raw-click frequency-based count
of edge weights, the authors argued that various clicks should
be treated diﬀerently based on the importance of the URLs
and the queries. i.e., clicks on more speciﬁc URLs should be
weigh more than clicks on general URLs. An inverse query
frequency (IQF) based weighting mechanism was introduced
to estimate the click quality. The authors applied the IQF
model on random walk and the experimental results indi-
cated superiority over the traditional count-frequency mod-
els.

In [12], Mei et. al introduced a parameter-free random
walk model for query suggestion. This query-dependent
model addressed the eﬃciency issue in random walk by con-
structing a subset of nodes in the click graph based on
a depth-ﬁrst search from the target node. Their model
estimated the transition probabilities between two queries
via an inner product-based similarity measurement. Con-
sequently, the model is able to suggest semantically related
queries to the original query by iteratively performing ran-
dom walk and output the highest scored nodes.

Not until recently has the importance of rare query classi-
ﬁcation/suggestion attracted enough attention from the IR
community. In [6], Broder et. al leveraged the results from
search engines as an external knowledge base for building
the word features for rare queries. The authors trained a
classiﬁer on a commercial taxonomy consists of 6,000 nodes
for categorization. Experimental results indicated a signif-
icant boost in terms of precision than the baseline query
expansion methods. Lately, Broder et. al proposed an on-
line expansion of rare queries in [5]. Their framework started
by training an oﬄine model that is able to suggest a ranked
list of related queries to the incoming rare query. The rare
query is then expanded by a weighted linear combination of
the original query and the related queries according to their

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA903similarity. The framework was speciﬁcally targeted for ads
suggestion. The matching precision on the expanded queries
demonstrated improvement over the original un-expanded
version of queries.

3. OUR APPROACH

This section introduces our framework for rare query sug-
gestion. Since our model is inspired by pseudo-relevance
feedback, it is valid to assume that search engines do not
generate random top results. Users click the results based
on their own perception of relevance so that the a URL may
be clicked by one user but skipped by others. Ideally, all re-
turned URLs should be considered relevant. However, since
we are only conﬁdent about top-ranked URLs, we will only
consider the skipped URLs above the last user click. Next,
we discuss how the query-URL graphs are generated.
3.1 Constructing Query-URL Graphs

We construct two bipartite graphs that correspond to ex-
plicit user feedback (clicks) and implicit user feedback (skips)
from query logs respectively. The data we use is projected
from the search log of a commercial search engine which
serves millions of users daily. Each (simpliﬁed) record of the
log contains (q, uq, Iq), where q corresponds to a user-issued
query instance, u is a set of top-k URLs returned by search
engine, i.e., uq = {uq
k}, and Iq is a vector that con-
tains the corresponding binary variables indicating whether
i ∈ {0, 1}. Note that
a URL has been clicked or not, i.e., I q
diﬀerent users may issue the same query instance but click
on diﬀerent URLs. Thus, it is quite common that a query
q have multiple query instances. To aggregate the clicks
and skips from all query instances for a speciﬁc query q, we
deﬁne a triplet (q, uq, cq, sq), where

1, ..., uq

dX

j=1

dX

j=1

cq
i =

sq
i =

I(I q

i = 1), i = 1, ..., k,

I(I q

i = 0), i = 1, ..., k.

(1)

Here I is an indicator function that equals 1 when the con-
dition holds and 0 otherwise. Mathematically, cq
i and sq
i
indicate the number of time a URL ui has been clicked and
skipped when users issued query q. For example, a query q
has three query instances {q1, q2, q3}, and the click pattern
of the top-5 returned URLs is

using eq.(1), we can get the aggregated clicks and skips:

q
c
s

q

= {3, 1, 1, 0, 2},
= {0, 2, 1, 2, 0}.

(3)

q
q
2andu
Notice that here tw0 URLs u
3 are both clicked and
skipped by diﬀerent query instances.

Next, given a set of m user-issued queries q and the union
of n returned URLs u, we represent the relationship between
queries and URLs using two squared weight matrices W +
and W −

, deﬁned as follows:

„

«

„

«

W +

=

0 C
CT
0

, W −

=

0
ST

S
0

where

C ∈ Rm×n, C(i, j)
S ∈ Rm×n, S(i, j)

,

(cid:2)
= cqi
uj
(cid:2)
= sqi
uj

.

Since the constructed matrices correspond to the bipartite
graphs of a query set and a URL set, there exists no edges
between queries (and URLs), as indicated by the big 0 in
the diagonal of both W + and W −
, which should be learnt
from our model.

Table 1 shows several queries and the number of times
It can be
the top-returned URL being clicked / skipped.
observed that for popular queries like facebook and ebay, the
top-ranked URLs are much more likely to be clicked, re-
sulting a low click entropy. While for queries with lower
bowling shoes, the top-ranked URLs, al-
frequencies e.g.
though being relevant, do not have a clear advantage over
the lower-ranked URLs in terms of clicks. And in fact, these
rare queries have much higher entropies that is more diﬃcult
for search engines to determine user intents.

Table 1: Example of URL clicks and skips. Popular
queries have more clicks than skips and thus lower
entropies, while rare queries often exhibit much
higher entropies.

q1 = {1, 1, 0, 0, 0},
I
q2 = {1, 0, 0, 0, 1},
I
q3 = {1, 0, 1, 0, 1}.
I

(2)

3.2 Random Walk with Restart

  Clicked
Skipped
Unobserved

1

2

3

4

5

6

......

10

Figure 4: An example of clicked, skipped and unob-
served URLs for query instance q3 in eq.(2).

Figure 4 shows the example of q3 that consists of clicked,
skipped and unobserved URLs. Summarizing eq.(2) up by

Given the weight matrices of query-URL relationships, our
objective is to deﬁne a score that indicates how closely two
queries are. Since the original W matrices contain no such
information, we propose to leverage the technique of ran-
dom walk with restart (RWR) to learn the relevance score
between queries [17]. RWR is a technique which speciﬁes a
starting node for a walk, then iteratively visits its neighbors
with probability proportional to the edge weights. At each
step, the walk has a constant probability of p to jump back
to its starting node. It has been shown that after a certain
number of steps, the probability of visiting a node j given
the starting node i will become stable. We can thus deﬁne

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA904 

e
r
o
c
S
e
c
n
a
v
e
e
R

l

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

 

0
0

 

Original Query−URL weight matrix

Weight Matrix with p = 0.1 random walk

p = 0.9

p = 0.5

p = 0.1

Weight Matrix with p = 0.5 random walk

Weight Matrix with p = 0.95 random walk

50

100

150

Figure 5: The neighborhood relevance score distri-
bution w.r.t. diﬀerent restarting rates p of random
walks.

the ranking vector for all nodes given i as starting node:

Ri = pW Ri + (1 − p)Ei,

(4)

where W is the weight matrix, Ei deﬁnes a starting vector
whose ith entry is 1 and the rest 0. Each entry of Rij deﬁnes
the relevance score of node j to the starting node i. It can be
observed that the above equation can be solved iteratively by
replacing Ri from the previous iteration. After convergence,
the ﬁnally ranking matrix R = {R1, ..., Rq} for q nodes is a
column-normalized matrix that contains the stable relevance
scores of all nodes within the graph. For example, in Figure
1, the most relevant query for q1 (audi parts) is q3 (audi)
according to the click graph, since R13 = 0.24 and R12 = 0.
On the other hand, the skip graph suggests that q2 (audi
bodywork) has a higher relevance score than q3.

The only parameter in eq.(4) is the restarting rate p which
controls the shape of the probability distribution of neigh-
borhood relevance scores. Higher p values have more local
eﬀect which assign very higher scores to its nearby nodes
and generally ignoring the nodes far apart, while lower p
values generate ﬂatter probability distributions so that the
start node i are more likely to reach out to distant nodes.
Choosing the right restarting rate is critical for learning the
query relevance scores. As it can be seen from Figure 5, the
ranking vector will lose discriminative power when p is too
low. On the other hand, if p is set to be very high, many
nodes will end up with no correlations with the starting node
i. Figure 6 further plots the density of weight matrix and
shows the impact of p.

Unfortunately, optimizing the restarting rate has gener-
ally been ignored in literature. For example, in the random
walk-like pagerank algorithm [13], the restarting (jumping)
rate is pre-ﬁxed to be 0.85 without optimization. In some
other eﬀorts, researchers empirically chose p in a grid-search
way which is however dataset-dependent [7]. In the next two
sub-sections, we propose a gradient optimization framework
which leverages URL categorization information from ODP
to choose the best parameters.
3.3 Determine URL Correlation

To get the ground-truth of URL correlation, we acquire
the categorization labels of URLs from the Open Direc-
tory Project (ODP)2. ODP is a human-edited repository

2http://www.dmoz.org/

Figure 6: The density of weight matrix with dif-
ferent restarting rates. p=0.1 gives an over-dense
matrix while p=0.95 results in a matrix that is too
sparse. Note that self-correlation has been removed
from the graph.

of URLs and categories that contains more than 4 million
URLs with over 590,000 categories. The categories of URLs
are organized in a tree-structured taxonomy where more
general topics are at higher levels. In this paper, we lever-
age the top three levels of the ODP categorization. For
example, the URL {research.microsof t.com} belongs to
/Computers/Companies/M icrosof t Corporation/. An ex-
ample of taxonomy can be found in Figure 7.

To eﬃciently generate labels for millions of URLs, we
make a simpliﬁed assumption that all URLs within a do-
main have the same category. For URLs that do no belong
to the ODP repository, we leverage a content-based hierar-
chical classiﬁer to generate labels [4], which classiﬁes a URL
from top to bottom and reﬁnes the categories by propagating
classiﬁcation errors in a bottom-up manner. However, since
in our framework we point out a general guideline of lever-
aging URL information for query suggestion, the generation
of URL labels is beyond the scope of this paper.

In order to determine the correlation between URLs, dif-
ferent weights are assigned to each level of the taxonomy.
Generally, lower levels receive higher weights since the cate-
gories are more speciﬁc than top levels. Algorithm 1 sketches
the process to calculate correlation, where the multiplier
m controls the bias towards lower levels. For example, for
m = 2, top-three levels get weights of {1, 2, 4} respectively.
Therefore, node 1 and 2 in Figure 7 will have correlation of
3/7, node 3 and 4 correlation of 7/7, and node 1 and 3 of
1/7.

It should be noted that under our assumption that URLs
having the same category in each domain, the query-URL
weight matrix can therefore be compacted into query-domain
matrix, which could possibly save much more computational
time for random walk. However, it is critical to understand
that the URL correlation is a guideline for optimizing the
parameters for random walk as we shall see in the next sec-
tion, but should not aﬀect the relevance between queries.
For example, users issue buy printers and buy monitors are
very likely to visit both dell.com and hp.com, but apparently
these two queries have diﬀerent intents. Aggregating URLs
into domains will possibly rank buy monitors to be more

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA905Computers

Companies

Conferences

Dell

IBM

AI

1

2

3

4

1

2

3

4

http://www.dell.com

http://www.ibm.com

http://www.nips.cc

http://www.icml2006.org

Figure 7: An example of ODP taxonomy for URLs.
We leverage the top three levels of categorization in
this paper.

Algorithm 1 URL Correlation Calculation
1: Input two URLs {u1, u2} with hierarchical labels {l1, l2}, the

multiplier m

if l1(i) = l2(i)

sim = sim + weight

2: Initialize weight = 1, sim = 0, denominator = 0
3: for each level i in the tree
4:
5:
6:
7:
8:
9: end for
10: sim =
11: Output sim

end if
denominator = denominator + weight
weight = weight ∗ multiplier

denominator

sim

relevant to buy printers than other queries such like printer
supplies.
In practice, we also notice that the query-URL
matrix performs better than query-domain matrix in terms
of determining query relevance.
3.4 Parameter Optimization via Gradient Search

After performing random walk as in eq.(4), two ranking
−
matrices R+ and R
can be obtained from the click and
skip graphs respectively, which can be further decomposed
into

«

„

„

+

R

=

˜Q+

( ˜Q+ ˜U+)T

˜Q+ ˜U+

˜U+

−

, R

=

−
˜Q
− ˜U
−

)T

( ˜Q

− ˜U
˜Q
−
˜U

«

−

where ˜Q is the estimated query correlation matrix, ˜U the
estimated URL correlation matrix, and ˜Q ˜U the normalized
estimated query-URL relationship.

−
Since both R+ and R

are column-normalized weight ma-
trices, a linear combination is proposed to estimate the ideal
correlation matrix, so that the combination will preserve the
property of column normalization:
+ (1 − α)R

−, α ∈ [0, 1],

+
˜R = αR

(5)

therefore, the estimated URL correlation matrix is also a
linear combination

˜U = αU

+

+ (1 − α)U

−, α ∈ [0, 1].

Along with the restarting rate p of random walk, the com-
bination ratio α is the other parameter in our model. Since
we have the ground-true URL correlations U from ODP
data, we can optimize the parameters by minimizing the
absolute loss of the estimated ˜U,

(p(cid:2), α(cid:2)

) = arg min

p(cid:2),α(cid:2) || ˜Up,α − U||,

(6)

(7)

where ˜Up,α is the estimated URL correlation given param-
eters p and α.

Algorithm 2 Parameter Optimization
1: Input two weight matrices {W +, W

−}, URL correlation ma-

trix U

2: Initialize p and α randomly
3: do
4: calculate f (p, α) according to eq. (8)
5: ﬁnd the Jacobian and Hessian matrices numerically

“

”

∂f =

= (dfp, dfα).

∂f
∂p ,

 

2

∂

f =

∂f
∂α

dfp
∂p
dfα
∂p

!

.

dfp
∂α
dfα
∂α

„

(cid:2)
p
(cid:2)
α

«

„

«

=

p
α

− [∂

2

f ]

−1

∂f

6: update (p, α) by the equation

7: Until convergence
8: Output optimal query ranking matrix Q(cid:2)

Since the above equation does not have a close-form so-
lution, we propose to estimate the optimal value using nu-
merical methods. To be concrete, we specify a function f of
p and α,

f (p, α) =

{U(i, j) − ˜Up,α(i, j)},

(8)

X

X

i

j

and α(cid:2)

and use Newton’s method to ﬁnd its ﬁrst and second deriva-
tives so that during each iteration, both p and α are opti-
mized. The new set of p(cid:2)
is then used to perform a
new round of random walk as well as the combination, in or-
der to update the estimated URL correlation matrix ˜Up(cid:2),α(cid:2) .
The process continues until the change of f becomes insignif-
icant. Figure 8 illustrates an example of this optimization.
Each sub-plot is a density plot of a matrix that shows the
absolute diﬀerence between ˜Up,α and U. Each dot shows
a point-level diﬀerence, where darker color indicates higher
diﬀerence and white color means subtle diﬀerence (we used
1.0e−6 here). It can be seen that during the beginning with
iteration = 1, the diﬀerence is signiﬁcant since p and α are
randomly initialized. With the function gradually being op-
timized with better parameters, the discrepancy starts to
vanish. After the 20th iteration, only less than 5% entries
in the matrix are signiﬁcantly diﬀerent. Typically, the opti-
mization ﬁnishes within 30 iterations. Finally, the optimal
query correlation ˜Qopt is leveraged for query suggestion.

4. EXPERIMENTS

This section provides empirical results of how the pro-
posed method performs on a large-scale data set, as well as
the comparison between diﬀerent random walk models.
4.1 Data Preparation and Evaluation Method
We collected a sample of one month query logs between
March 16 and April 14 from a large commercial search en-
gine, which contains approximately 40 million unique queries
and 110 million query instances. Since our focus is on rare
queries, we ﬁltered out all popular queries and only kept
queries with less than 20 appearances in the log. We also
removed queries that have URL fragments and long queries
(more than 10 words). Overall, we used 3,299,278 unique
queries in our experiments. The data set also contains 8,139,150
user clicks and 13,577,113 skips on a total of 7,784,037 URLs.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA906top j suggested queries, the precision at the cut-oﬀ rank j
can be deﬁned as:

P (j) =

# of relevant queries

j

.

(9)

The top N precision is the aggregated precision from all
queries in the evaluation set (K is the total number of queries):

PK

i=1 P (N )

K

P @N =

.

(10)

Figure 8: An illustration of the absolute loss (eq.(7))
of || ˜Up,α − U|| during diﬀerent iterations with p and α
values. Darker color indicates higher inconsistency
(more loss).

For comparison, three algorithms were tested on the same
data set. The baseline approach is a random walk with
restart model that only leverages click information from the
query log (RWR-Base). We use the same algorithm as shown
in Algorithm 2 to optimize the restarting parameter p, ex-
cept that in this case the combination rate α is set to be 1.
The second approach is similar to pseudo relevance feedback
[15, 19], where all top URLs returned by a search engine are
treated as relevant (RWR-Pseudo). We form edges between
a query and top-10 returned URLs. We then perform a ran-
dom walk on the click graph that includes all these edges.
Finally, we also implemented the backward random walk
[7] using the pseudo relevance model (RW-Back). We only
considered the ”101-0.9-backward” model since it performed
the best among all models. Here 101 means 101-step ran-
dom walk and 0.9 indicates the self-transition probability.
Notice that the ﬁrst and the second methods are supervised
random walks which are optimized use ground-truth, while
for the third method, the number of random walk steps and
the transition probability are ﬁxed but not optimized for the
data set. Since our algorithm is a combination of positive
and negative feedbacks, we denote it as RWR-Combo.

We used a similar evaluation process as in [7]. Since it
is diﬃcult to judge all the results for this data set with 3
million queries, we resort to sampling methods instead. We
ﬁrst uniformly sampled 500 queries from the set. The top
5 suggested queries generated from each of the four algo-
rithms are evaluated, which results in a total of 2,500 rele-
vance judgments. Each of the suggested queries are judged
by two human judgers. Each query was judged to be either
relevant or irrelevant. The survey tool was designed in the
way that judgers are able to browse the search engine result
page (SERP) for the given query when judging the relevance
of suggested queries. The judgers are also allowed to navi-
gate through links in SERP to help better understand the
meanings of the query if necessary. The list of suggested
queries from the four algorithms are randomly ordered so
that the judgers are not aware of the particular algorithm
behind them.

We employ two well-known metrics in information retrieval
(IR) community to measure: Precision at rank N (P @N )
and Mean Average Precision (M AP ). Given a query qi and

On the other hand, M AP averages the precision of a given
query after each relevant query is retrieved, this metric fo-
cuses on both precision and recall so that the earlier relevant
documents are retrieved, the higher M AP score will be. To
be speciﬁc, for each query qi,

PM
j=1(P (j) × I(j))

# of relevant queries

AvePi =

,

(11)

where P (j) is the precision at position j as deﬁned in eq.(9),
I(j) is an indicator function that equals 1 when the j’s sug-
gested query is relevant and 0 otherwise. M AP is the aver-
age score over all K queries in evaluation.
4.2 Performance Comparison

Table 2 summarizes the overall performance of the four al-
gorithms in the sample set. Our algorithm (RWR-Combo)
successfully outperforms all other methods in both M AP
and P @5. The random walk using pseudo-relevance (RWR-
Pseudo) also has a good performance and beats the back-
ward random walk (RW-Back). The random walk method
leveraging only click information (RWR-Base) shows the
worst performance. These results indicate two facts: (1)
using only click information and ignoring the skipped URLs
is not eﬀective in suggesting relevant queries, and (2) treat-
ing clicks and skips with equal importance (RWR-Pseudo)
is not as eﬀective as assigning diﬀerent weights to both feed-
backs (RWR-Combo). We also notice that the unsupervised
RW-Back method outperforms the baseline RWR-Base a lit-
tle bit in both metrics.

Next, we break down the performance of these four al-
gorithms into individual queries. Figure 9 shows P @5 for
diﬀerent queries. While performing the best on most of
the queries, our RWR-Combo model also exhibits the lowest
variance (0.021). The baseline RWR-Base shows the high-
est variance 0.036 among all. Overall, RWR-Combo outper-
forms RWR-Pseudo in 19 queries out of the 24 samples.

We also want to observe the quality of query suggestion at
diﬀerent positions. Therefore, we calculate P @1 as well as
P @5 as illustrated in Figure 10. Our algorithm shows 65%
of precision at position 1, an improvement of 9% over P @5.
We notice that the baseline approach only has less than 3%
of improvement at position 1, which demonstrates that with
only click information, even the top-suggested queries are
not quite relevant in the case of rare queries.

To illustrate the signiﬁcance of the performance improve-
ment, we conducted rigorous statistical signiﬁcance test on
the results of P @5. Usually, a p-value of less than 0.05
indicates a signiﬁcant improvement. We performed paired
t-test on every pair of the four algorithm. Table 3 sum-
marizes the results. Each row shows an algorithm which
compares the performance improvement over each column
of algorithms. For example, the entry of the ﬁrst row and
ﬁrst column can be interpreted as: RWR-Combo performs

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA907Algorithm
RWR-Base

RWR-Pseudo

RW-Back

RWR-Combo

M AP

0.402839237
0.57829303
0.452837391
0.622839822

P @5

0.357734005
0.509583332
0.402468081
0.56725468

Table 2: Overall performance comparison of four al-
gorithms in terms of M AP and P @5. Our algorithm
(RWR-Combo) outperforms others in both metrics.

6% better than RWR-Pseudo on average, which is statisti-
cally signiﬁcant with a p-value = 0.002. From this table, we
also observe that using pseudo relevance show signiﬁcantly
better precision than both the backward walk and walk on
only click graphs. On the other hand, although RWR-Back
shows some performance improvement over the baseline as
indicated in Table 2, the improvement is not signiﬁcantly
enough (p-value = 0.11).

To show the parameter sensitivity, we plot the value of
f (p, a) as in eq.(8) in Figure 11. The optimal result is
achieved while f is minimized, when α = 0.765 and p =
0.837. The worst result is when p = 1 (always jump back to
starting node without hitting other nodes) and α = 0 (with-
out using any click information).
It can also be observed
from Figure 11 that for any particular value of α, the value
of p around 0.6 and 0.85 gives the best results. Likewise, for
any particular value of p, α between 0.65 and 0.8 performs
the best.
It is also observable that the loss function pos-
sesses a global minimum, so that no matter how parameters
are initialized, the best result can always been achieved.

5
@
P

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 

RWR−Combo
RWR−Base
RWR−Pseudo
RW−Back

 

1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

Query ID

Figure 9: Performance break down of precision for
each query. RWR-Combo performs best for most
rare queries.

Table 4 shows some example queries and the suggestions
by diﬀerent algorithms, where queries with bold font are
judged to be relevant by judgers. Our algorithm returns
more relevant queries than any others in all four cases. The
queries valentine one and single ladies are diﬃcult queries
which has diﬀerent intents than their literal meanings. Our
algorithm successfully discovers the underlying user intent
and makes correct suggestions. On the other hand, our algo-
rithm also exhibits its capability of diversifying suggestions
to queries that have multiple intensions, e.g., dc ups could
refer to both the power system and the postal service.

0.7

0.6

0.5

n
o
i
s
i
c
e
r
P

0.4

0.3

0.2

0.1

0

 

RWR−Combo
RWR−Pseudo
RWR−Base
RW−Back

 

P@5

P@1

Figure 10: Precision at diﬀerent rank of suggested
queries. RWR-Combo achieves the highest precision
of 65% among all algorithms at position 1 and 5.

)
α

 
,

p
(
f
 

s
s
o

l
 

d
e
z
i
l

a
m
r
o
n

0.9

0.8

0.7

0.6

0.5

0.4
0

0.2

0.4

0.6

0.8

p

1.0

1

0.8

0.6
α

0.2

0

0.4

Figure 11: Normalized loss as in eq.(8), as a function
of p and α. Smaller values indicate better results.
Best achieved when α = 0.765 and p = 0.837.

4.3 Why does our model work?

Overall, our model is quite straightforward. We com-
bine query correlations from click and skip graphs and use
URL categories as guideline to perform optimal random
walk. So why is the model more successful on rare queries
than others, e.g., pseudo-relevance feedback? The reason
is that we somehow smooth the click graph by adding po-
tential relevant edges according to the skip graph. While
the pseudo-relevance feedback model treat all top-returned
result as relevant, we perform it diﬀerently in a principled
way. As indicated in Figure 11, the best result is achieved
when α = 0.765, suggesting that every click on a URL
should be assigned with 0.765 edge weight, while every skip
on a top-ranked URL should be treated with 0.235 edge
weight. A rough calculation indicates that edges in click
graph should be treated 0.765/0.235 ≈ 3 times more impor-
tant as in the skip graph. Due to the characteristics of high
entropy and low click frequency of rare queries, this model
is capable of discovering potential edges between queries
and skipped URLs, while not over-smoothing the graph like
pseudo-relevance feedback which introduces lots of noises.
On the other hand, the optimal restarting rate in our model
is 0.837, which is surprisingly coherent with the jumping rate

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA908RWR-Combo (performs better than)
RWR-Pseudo (performs better than)

RW-Back (performs better than)

RWR-Pseudo

0.06 (p-value = 0.002)

(cid:2)
(cid:2)

RWR-Base

0.22 (p-value< 0.001)
0.16 (p-value < 0.001)

(cid:2)

RWR-Base

0.18 (p-value < 0.001)
0.12 (p-value = 0.003)
0.04 (p-value = 0.11)*

*: insigniﬁcance of the comparison results.

Table 3: Statistical signiﬁcance test on performance improvement of the four algorithms in comparison. Each
entry contains the relative precision increase as well as the p-value. A p-value of less than 0.05 indicates a
signiﬁcance improvement.

Table 4: Examples of query suggestions by four diﬀerent algorithms. Bold queries are judged as relevant.
Our algorithm RWR-Combo has the most number of relevant suggestions in all four cases. RWR-Combo is
also capable of diversifying the suggestions to multi-intensional queries.

(0.85) as used in the pagerank algorithm. To summarize, a
simpliﬁed way of leveraging our model to make suggestion
for rare queries can be conducted as follows (the parameters
are speciﬁed for the cut-oﬀ value of 20 for query frequency):

1. perform random walk with p around 0.85 on click and

skip graphs respectively,

2. multiple the positive ranking matrix R+ by 0.75, the

negative ranking matrix R

by 0.25, respectively,

−

−
3. combine R+ and R

linearly to get Ropt and extract

the optimal query correlation matrix Qopt.

α values

p values

1

0.8

0.6

0.4

0.2

0

20

50

100

Query Cut−off Frequency

1

0.8

0.6

0.4

0.2

0

20

50

100

Query Cut−off Frequency

In our empirical analysis, when a query set contains more
frequent queries, the skip graph becomes less important dur-
ing the smoothing process. We ran three tests to obtain the
optimal values of α and p on three diﬀerent datasets, with
query frequency cut-oﬀ values of 20, 50 and 100 respectively.
Figure 12 shows the bar plots in terms of the best parameter
values. There is an obvious up trend of α values when the
query frequency increases, while for the restarting value p,
it stabilizes relatively around 0.85.

5. CONCLUSION AND FUTURE WORK

In this paper, we proposed an optimal solution for rare
query suggestions. Rare queries are those diﬃcult (long-

Figure 12: Optimal values of parameters w.r.t. dif-
ferent query frequency cut-oﬀs. α value increases
with the query frequency, while p is not correlated
with the query frequency.

tail) queries in search engines that appeared very few times.
We proposed to tackle this problem by random walk on the
query logs. Speciﬁcally, we leveraged both click and skip in-
formation from query log to form an optimal random walk
and combination model. Our model was related to both
pseudo-relevance feedback and smoothing technique used in
natural language processing. Our major discovery was that
user skipped URLs (observed by users but without clicks)

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA909played an important role in ﬁnding relevant information for
rare queries, but they should be treated with diﬀerent weight
comparing to user clicked URLs. Since our model only re-
lied on the click/skip information without the involvement of
URL/query content, we were able to implement the frame-
work on a large-scale data set which contained 40 million
unique queries. The empirical result comparing with other
random walk models indicates that our model can generate
higher precision scores for rare query suggestion.

Since in this paper we only focused on the observed URLs
from users, in the future, it would also be interesting to
investigate unobserved URLs below the last user clicks to
see if they can beneﬁt our model or bring noises instead.
This way we can break down eq.(5) into three diﬀerent pieces
(clicked, skipped and unobserved URLs) and optimize them
jointly. It would also be useful to investigate other methods
for ﬁnding correlations between URLs, e.g., topic models.
And of course, it is worthy of further investigation how our
model behaves for rare queries in diﬀerent verticals, e.g.,
news, sports, commercial-intent and so on.

6. REFERENCES
[1] E. Agichtein, S. Lawrence, and L. Gravano. Learning

search engine speciﬁc query transformations for
question answering. In WWW ’01: Proceedings of the
10th international conference on World Wide Web,
pages 169–178, New York, NY, USA, 2001. ACM.

[2] R. Baeza-yates, C. Hurtado, and M. Mendoza. Query
recommendation using query logs in search engines. In
In International Workshop on Clustering Information
over the Web (ClustWeb, in conjunction with EDBT),
Creete, pages 588–596. Springer, 2004.

[3] D. Beeferman and A. Berger. Agglomerative clustering
of a search engine query log. In KDD ’00: Proceedings
of the sixth ACM SIGKDD international conference
on Knowledge discovery and data mining, pages
407–416, New York, NY, USA, 2000. ACM.

[4] P. N. Bennett and N. Nguyen. Reﬁned experts:

improving classiﬁcation in large taxonomies. In SIGIR
’09: Proceedings of the 32nd international ACM
SIGIR conference on Research and development in
information retrieval, pages 11–18, New York, NY,
USA, 2009. ACM.

[5] A. Broder, P. Ciccolo, E. Gabrilovich, V. Josifovski,

D. Metzler, L. Riedel, and J. Yuan. Online expansion
of rare queries for sponsored search. In WWW ’09:
Proceedings of the 18th international conference on
World wide web, pages 511–520, New York, NY, USA,
2009. ACM.

[6] A. Z. Broder, M. Fontoura, E. Gabrilovich, A. Joshi,
V. Josifovski, and T. Zhang. Robust classiﬁcation of
rare queries using web knowledge. In SIGIR ’07:
Proceedings of the 30th annual international ACM
SIGIR conference on Research and development in
information retrieval, pages 231–238, New York, NY,
USA, 2007. ACM.

[7] N. Craswell and M. Szummer. Random walks on the

click graph. In SIGIR ’07: Proceedings of the 30th
annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 239–246, New York, NY, USA, 2007. ACM.

[8] H. Cui, J.-R. Wen, J.-Y. Nie, and W.-Y. Ma.

Probabilistic query expansion using query logs. In
WWW ’02: Proceedings of the 11th international
conference on World Wide Web, pages 325–332, New
York, NY, USA, 2002. ACM.

[9] H. Deng, I. King, and M. R. Lyu. Entropy-biased

models for query representation on the click graph. In
SIGIR ’09: Proceedings of the 32nd international
ACM SIGIR conference on Research and development
in information retrieval, pages 339–346, New York,
NY, USA, 2009. ACM.

[10] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and
G. Gay. Accurately interpreting clickthrough data as
implicit feedback. In SIGIR ’05: Proceedings of the
28th annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 154–161, New York, NY, USA, 2005. ACM.

[11] R. Jones, B. Rey, O. Madani, and W. Greiner.
Generating query substitutions. In WWW ’06:
Proceedings of the 15th international conference on
World Wide Web, pages 387–396, New York, NY,
USA, 2006. ACM.

[12] Q. Mei, D. Zhou, and K. Church. Query suggestion
using hitting time. In CIKM ’08: Proceeding of the
17th ACM conference on Information and knowledge
management, pages 469–478, New York, NY, USA,
2008. ACM.

[13] L. Page, S. Brin, R. Motwani, and T. Winograd. The
pagerank citation ranking: Bringing order to the web.
Technical report, Stanford InfoLab, November 1999.
[14] F. Radlinski, A. Broder, P. Ciccolo, E. Gabrilovich,

V. Josifovski, and L. Riedel. Optimizing relevance and
revenue in ad search: a query substitution approach.
In SIGIR ’08: Proceedings of the 31st annual
international ACM SIGIR conference on Research and
development in information retrieval, pages 403–410,
New York, NY, USA, 2008. ACM.

[15] F. Radlinski and T. Joachims. Query chains: learning

to rank from implicit feedback. In KDD ’05:
Proceedings of the eleventh ACM SIGKDD
international conference on Knowledge discovery in
data mining, pages 239–248, New York, NY, USA,
2005. ACM.

[16] J. Rocchio. Relevance Feedback in Information

Retrieval, pages 313–323. 1971.

[17] H. Tong, C. Faloutsos, and J.-Y. Pan. Random walk
with restart: fast solutions and applications. Knowl.
Inf. Syst., 14(3):327–346, 2008.

[18] J.-R. Wen, J.-Y. Nie, and H.-J. Zhang. Query

clustering using user logs. ACM Trans. Inf. Syst.,
20(1):59–81, 2002.

[19] G.-R. Xue, H.-J. Zeng, Z. Chen, Y. Yu, W.-Y. Ma,

W. Xi, and W. Fan. Optimizing web search using web
click-through data. In CIKM ’04: Proceedings of the
thirteenth ACM international conference on
Information and knowledge management, pages
118–126, New York, NY, USA, 2004. ACM.

[20] C. Zhai and J. Laﬀerty. Model-based feedback in the
language modeling approach to information retrieval.
In CIKM ’01: Proceedings of the tenth international
conference on Information and knowledge
management, pages 403–410. ACM, 2001.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA910