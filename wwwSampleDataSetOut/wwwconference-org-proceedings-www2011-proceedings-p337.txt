A Word at a Time: Computing Word Relatedness using

Temporal Semantic Analysis

Kira Radinsky∗, Eugene Agichtein†, Evgeniy Gabrilovich‡, Shaul Markovitch∗

∗ CS Department, Technion—Israel Institute of Technology, 32000 Haifa, Israel
‡ Yahoo! Research, 4301 Great America Parkway, Santa Clara, CA 95054, USA

† Math & CS Department, Emory University, 400 Dowman Drive, Atlanta, GA 30322, USA
‡ gabr@yahoo-inc.com

† eugene@mathcs.emory.edu

∗

{kirar|shaulm}@cs.technion.ac.il

ABSTRACT
Computing the degree of semantic relatedness of words is
a key functionality of many language applications such as
search, clustering, and disambiguation. Previous approaches
to computing semantic relatedness mostly used static lan-
guage resources, while essentially ignoring their temporal
aspects. We believe that a considerable amount of relat-
edness information can also be found in studying patterns
of word usage over time. Consider, for instance, a newspa-
per archive spanning many years. Two words such as “war”
and “peace” might rarely co-occur in the same articles, yet
their patterns of use over time might be similar. In this pa-
per, we propose a new semantic relatedness model, Temporal
Semantic Analysis (TSA), which captures this temporal in-
formation. The previous state of the art method, Explicit
Semantic Analysis (ESA), represented word semantics as a
vector of concepts. TSA uses a more reﬁned representation,
where each concept is no longer scalar, but is instead rep-
resented as time series over a corpus of temporally-ordered
documents. To the best of our knowledge, this is the ﬁrst
attempt to incorporate temporal evidence into models of se-
mantic relatedness. Empirical evaluation shows that TSA
provides consistent improvements over the state of the art
ESA results on multiple benchmarks.
Categories and Subject Descriptors
H.3.1 [Information Storage and Retrieval]: Content
Analysis and Indexing; I.5.4 [Pattern Recognition]: Ap-
plications
General Terms
Algorithms, Experimentation
Keywords
temporal dynamics, temporal semantics, semantic analysis,
word relatedness, semantic similarity
1.

INTRODUCTION

The ability to quantify semantic relatedness of texts un-
derlies many fundamental tasks in natural language pro-
cessing, including information retrieval, word sense disam-
biguation, text clustering, and error correction. Previous
approaches to computing semantic relatedness used various

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2011, March 28–April 1, 2011, Hyderabad, India.
ACM 978-1-4503-0632-4/11/03.

linguistic resources, such as WordNet, Wikipedia, or large-
scale text corpora for methods like Latent Semantic Analysis
(LSA). Yet all of these approaches essentially considered the
underlying linguistic resource as a static collection of texts
or concepts. In this paper we argue that there is an addi-
tional source of rich information about semantic relatedness
of words, which can be revealed by studying the patterns of
word occurrence over time.

Consider, for example, words such as “war” and “peace”.
While these words are clearly related, they might rarely be
mentioned in the same documents. However, they are likely
to be mentioned roughly around the same time (say, in dif-
ferent articles posted during the same day, or in adjacent
days).
In this work, we use the New York Times archive
spanning over 130 years. For each word, we construct the
time series of its occurrence in New York Times articles. We
posit that if there is a correlation between the time series of
two words, then the meanings of the two words are related.
In principle, there are a number of cases when temporal
information could oﬀer a complementary source of signal,
which is not captured by other models. Synonyms (that is,
words with similar meanings) are rarely used in the same
article since an author usually sticks to one set of terms, yet
they can be used by diﬀerent authors in diﬀerent articles de-
scribing the same events. Looking at their coordination in
time allows us to leverage the opinions of multiple authors
collectively. As another example, consider pairs of words
that form stock phrases, such as “luxury car”. Taken in-
dividually, the two words in each pair have very diﬀerent
meanings, and are likely to be judged as such by existing
methods. On the other hand, these words are indeed re-
lated, and the frequency of their use over time exhibits non-
trivial correlation. Especially interesting are pairs of words
that have implicit relationships such as “war” and “peace”
or “stock” and “oil”, which tend to correlate in frequency of
use over time. Figures 1 and 2 depict these correlations in
time. The proposed method, Temporal Semantic Analysis,
captures such correlations, and is able to better estimate se-
mantic relatedness than methods that only use static snap-
shots of linguistic resources.

The contributions of this paper are threefold. First, we
propose to use temporal information as a complementary
source of signal to detect semantic relatedness of words.
Speciﬁcally, we introduce Temporal Semantic Analysis (TSA),
which leverages this information and computes a reﬁned
metric of semantic relatedness. Second, we construct a new
dataset for semantic relatedness of words, which we have
judged with the help of Amazon’s Mechanical Turk service.

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India337as del.icio.us. This is similar to recent semantics approaches
such as ESA [16]. However, while ESA uses a static repre-
sentation of each concept, we use the concept dynamics—
its behavior over time, represented by the time series of the
concept occurrence. Thus, instead of representing a word
with a vector of unit concepts, vectors of time series are
manipulated, where each time series describes concept dy-
namics over time. Our hypothesis is that concepts that be-
have similarly over time, are semantically related. Such a
rich representation of words (adding the extra temporal di-
mension) could facilitate the discovery of implicit semantic
relationships between the original words. As we will show
experimentally, the naive approach of directly computing
temporal correlation between words (without the concept
vector representation) is not eﬀective.

Thus, our TSA method consists of three main steps:

1. Represent words as concept vectors: using a con-
cept repository of choice (e.g., Wikipedia or Flickr im-
age tags), represent a word as a set of associated con-
cepts with weights (Section 2.1).

2. Extract temporal dynamics for each concept:
using a corpus of choice (e.g., New York Times archive),
quantify concept occurrence for each time period (e.g.,
a day) and build its time series (Section 2.2).

3. Extending static representation with temporal
dynamics: ﬁnally, scale each concept’s time series ac-
cording to the concept’s original weight from item 1
above (Section 2.3).

2.1 Representing Words as Concept Vectors

In our representation, each word is mapped into a vector
of concepts — a concept vector. For each concept a static
weight is computed. We consider several such representa-
tions over multiple folksonomies:

1. Wikipedia Concepts — Wikipedia is among the largest
knowledge repositories on the Web, which is written
collaboratively by millions of volunteers around the
world, and almost all of its articles can be edited by
any user. Wikipedia is available in dozens of languages,
while its English version is the largest of all with more
than 500 million words in over three million articles.
Vector space models based on this ontology have been
used by many works for semantic relatedness [16, 32].
In those representations, each entry in the concept vec-
tor is a TFIDF-based function of the strength of associ-
ation between the word and the concept in Wikipedia.

2. Flickr Image Tags — Flickr is an online image host-
ing community. Photo submitters have the option to
add metadata to each image in the forms of natural
language tags. This feature enables searchers to ﬁnd
images related to speciﬁc topics. The natural concepts
in this representation are the Flickr tags.

3. Del.icio.us Bookmarks — del.icio.us is a social URL
bookmarking service, with the possibility to search and
explore new bookmarks. The service had, by the end
of 2008, more than 5.3 million users and 180 million
unique bookmarked URLs. Del.icio.us users can tag
each of their bookmarks with free text, and we use
these tags as concepts.

Figure 1: Time series (1870-1988) of the words “war”
(red) and “peace”(blue). The words correlate over time.

Figure 2: Time series (1870-1988) of the words “stock”
(red) and “oil”(blue). The words correlate over time.

In contrast with the previous standard benchmark, WS-353,
our new dataset has been constructed by a computer algo-
rithm (also presented below), which eliminates subjective se-
lection of words. We make the new dataset publicly available
for further research in the ﬁeld. Finally, empirical evaluation
shows that TSA exhibits superior performance compared to
the previous state of the art method (ESA), and achieves
higher correlation with human judgments on both datasets.

2. TEMPORAL SEMANTIC ANALYSIS

We propose Temporal Semantic Analysis (TSA), which is
composed of two novel components: a new approach, de-
scribed in this section, for representing the semantics of nat-
ural language words, and a new method, described in Section
3, for computing the semantic relatedness between words.

Our method is based on associating each word with a
weighted vector of concepts. Such concepts can be derived
from crowd intelligence folksonomies such as Wikipedia, co-
tagging in Flickr, or from online bookmarking services such

FrequencyTimeTimeFrequencyWWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India338(cid:10) ˆts1, ˆts2

n}
1, . . . , ts1
m}
1, . . . , ts2

Procedure Semantic Relatedness(t1, t2)
(1)C(t1) = {ts1
(2)C(t2) = {ts2
(3)R(t1, t2) ← 0
(4)Repeat M in(m, n) times
(5)
(6) R(t1, t2) ← R(t1, t2) + Q( ˆts1, ˆts2)
(7) C(t1) ← C(t1)\{ ˆts1}
(8) C(t2) ← C(t2)\{ ˆts2}
(9)Return R(t1, t2)

(cid:11) = arg max(cid:104)ts1,ts2(cid:105)∈C(t1)×C(t2) Q(ts1, ts2)

Figure 4: A greedy algorithm for computing the se-
mantic relatedness between two words. The procedure
assumes the availability of a function Q that determines
relatedness between a pair of time series tsi associated
with two concepts.

3. USING TSA FOR COMPUTING SEMAN-

TIC RELATEDNESS

To compute semantic relatedness of a pair of words we
compare their vectors (as deﬁned in Section 2.3) using mea-
surements of weighted distance between multiple time series,
combined with the static semantic similarity measure of the
concepts. This approach, therefore, integrates both tempo-
ral and static semantic behavior of the words.
3.1 TSA-based Semantic-Relatedness Algorithm

The ESA method for computing semantic relatedness is
based on the assumption that related words share highly-
weighted concepts in their representations. The TSA ap-
proach does not assume so. We only assume that highly-
weighted concepts of the related words are related.

1, . . . , c1

1, . . . , c2

Suppose we are trying to ﬁnd the relatedness between
words t1 and t2. Assume that t1 is mapped to a set of
concepts C(t1) = {c1
n} and t2 is mapped to C(t2) =
{c2
m}. Suppose we have a function Q that determines
relatedness between two individual concepts using their dy-
namics (as deﬁned in Section 2.2). Assuming w.l.o.g n ≤ m,
we can deﬁne the relatedness R between t1 and t2 as the
maximal sum of pairwise concept relatedness over all or-
dered subsets of size n of C(t2):

(cid:88)

R(t1, t2) = max
jl∈(1...(m

n))

l=1,...,n

Q(c1

l , c2

jl )

(2)

This exhaustive search over all possible pairs is, however, in-
feasible. Therefore we take an alternative greedy approach,
which is formally described in Figure 4. The procedure at
each step ﬁnds a pair of time series with the highest related-
ness Q (line 5 in the algorithm), removes them and proceeds
(lines 7 and 8). Iteratively, the relatedness R(t1, t2) is com-
puted as the sum of relatedness of the matching concepts
(line 6). This procedure complexity is O(n · m · max(|ts|)),
where |ts| is the length of the time series representing the
concepts.
3.2 Similarity Between Individual Time Series
The relatedness Q between two concepts is determined by
comparing their dynamics. Our basic assumption is that
related concepts correlate in their temporal behavior. For
comparing the concepts associated time series, we use two

Figure 3: Each word is represented by a weighted vector
of concept time series (produced from a historical archive
H). The weight wi of each concept corresponds to the
concept “importance” w.r.t. the original word.

2.2 Temporal Concept Dynamics

Let c be a concept represented by a sequence of words
wc1, . . . , wck. Let d be a document. We say that c appears
in d if its words appear in the document with a distance of
at most ε words between each pair wci, wcj, where ε is a
proximity relaxation parameter (in the experiments we set
ε = 20). That is, a concept appears in a document if there
is a window of size ε where all the concept words appear.
For example, for the concept c — “Great Fire of London”
— we say that the c appears in a document d, if the words
“Great”, “Fire”, “of”, “London” appear in the document with
a distance of at most ε between each word.

Let t1, . . . , tn be a sequence of consecutive discrete time
points (e.g., days). Let H = D1, . . . , Dn be a history rep-
resented by a set of document collections, where Di is a
collection of documents associated with time ti. We deﬁne
the dynamics of a concept c to be the time series of its fre-
quency of appearance in H:

Dynamics(c) = (cid:104)|{d ∈ D1|appears(c, d)}|
|{d ∈ Dn|appears(c, d)}|
(cid:105)

|D1|

, . . . ,

|Dn|

(1)

In the experiments described in this paper we used New
York Times articles since 1870 for history. Each time point
is a day, and the collection of documents associated with a
day is the set of articles appearing on that day.
2.3 Extending Static Representation with Tem-

poral Signals

Our approach is inspired by the desire to augment text

representation with massive amounts of temporal world knowl-
edge. Hence, we represent a word as a weighted mixture of
concept time series, where the weights correspond to the
concept “importance” w.r.t. the original word (Figure 3).

In common semantic representations (such as ESA [16]) a
word is represented as a weighted vector of concepts (derived
from Wikipedia articles). In ESA, each vector entry contains
a single (static) TFIDF weight, which expresses the strength
of association of the word and the concept. Our TSA method
extends ESA so that each entry in the vector corresponds to
a time series, computed as described above.

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India339existing methods for measuring time series similarity — cross
correlation and dynamic time wrapping (DTW).
3.2.1 Cross Correlation
In statistics, cross correlation is a method for measuring
statistical relations, e.g., measuring similarity of two random
variables. A common measurement for this purpose is the
Pearson’s product-moment coeﬃcient which is deﬁned as:

corr(X, Y ) =

cov(X, Y )

σX σY

σX σY
(xi − ¯x)(yi − ¯y)

=

n(cid:80)
(cid:80)N
i=1(xi − x)2

i=1

(cid:113) 1

N

(cid:113) 1

N

E[(X − E(X))(Y − E(Y ))]

=

(3)

(cid:80)N
i=1(yi − y)2

In signal processing, cross-correlation is used as a measure of
similarity of two signals as a function of a time-lag applied on
one of the signals — a variation of the Pearson coeﬃcient
to diﬀerent time delays between two time series in Figure
5. An innate characteristic of this measure is identiﬁcation
of similar time series in volume, with consideration of time
shifts. In our representation, where words are represented as
time series, words whose frequencies correlate in volume, but
with a time lag, will be identiﬁed as similar. When we wish
to evaluate the correlation of the two words’ time-series, we
compare the time series starting from the ﬁrst time point
they both started appearing, until the time point when one
of the words stopped appearing. For example, the word
“computer” did not appear during the 1800s, and started to
appear only around 1930. Therefore, when we compare it
to the word “radio”, we calculate the cross correlation only
during the period starting at 1930.
3.2.2 Dynamic Time Warping
The DTW algorithm [5] measures the similarity between
two time series that may diﬀer in time scale, but similar in
shape. In speech recognition, this method is used to iden-
tify similar sounds between diﬀerent speakers whose speech
speed and pitch might be diﬀerent. The algorithm deﬁnes a
local cost matrix C ∈ R|ts1|×|ts2| of two time series ts1 and
ts2 as
Ci,j = (cid:107)ts1[i] − ts2[j](cid:107), i ∈ (cid:104)1 . . .|ts1|(cid:105), j ∈ (cid:104)1 . . .|ts2|(cid:105)
(4)
where (cid:107)ts1[i]−ts2[j](cid:107) is a distance metric between two points
of the time series.

Given this cost matrix, DTW constructs an alignment
path that minimizes the cost over this cost matrix. This
alignment p is called the “warping path”, and deﬁned as a
sequence of points pairs p = (pair1, . . . pairk), where pairl =
(i, j) ∈ (cid:104)1 . . .|ts1|(cid:105) × (cid:104)1 . . .|ts2|(cid:105) is a pair of indexes in ts1
and ts2 respectively. Each consequent pair preserves the or-
dering of the points in ts1 and ts2, and enforces the ﬁrst
and last points of the warping path to be the ﬁrst and last
points of ts1 and ts2. For each warping path p we compute
l=1 C(pairl). The DTW is deﬁned to be

its cost as c(p) =(cid:80)k

the minimum optimal warping path

DT W (ts1, ts2) = min{c(p)|p ∈ P

|ts1|×|ts2|}

(5)

where P are all possible warping paths. A dynamic program-
ming algorithm (similar to the one in Figure 6) is usually
applied to compute the optimal warping path of the two
sequences.

This similarity measurement, as opposed to time series
cross-correlation distance (cf. Section 3.2.1) is much more
ﬂexible, hence we decided to experiment with it as well.
3.2.3 Temporal Weighting Function
As the meaning of the words changes over time, more re-
cent concept correlation are more signiﬁcant than past cor-
relation. Therefore, when measuring the distance between
two individual time series, higher weights to recent similari-
ties should be given. We apply several linear and non-linear
weighting functions to the above time series distance func-
tions (see Section 5.2.4). Let f (i, j) be such a function,
whose parameters are two time points i, j. Thus, we modify
DTW deﬁnition of (cid:107)ts1(i) − ts2(j)(cid:107) to
(cid:107)ts1(i) − ts2(j)(cid:107) · f (i, j)

(6)

and the covariance deﬁnition in the cross-correlation dis-
tance now changes to
cov(ts1, ts2) ← cov(ts1, ts2)+

f (i, j) · [(ts1[index] − E(ts1)) · (ts2[delayedIndex] −
−E(ts2))]
(7)

We described how our TSA method represents words as
concepts (Section 3.1), and how the temporal dynamics of
the concept usage over time can be used to compute seman-
tic relatedness (Section 3.2). We now turn to the experi-
mental evaluation of our approach.

4. EXPERIMENTAL SETUP

We implemented our TSA approach using the New York
Times archive (1863-2004). For each day we had an average
of 50 abstracts of articles, which after parsing yielded 1.42
GB of texts with a total of 565,540 distinct words. In this
section we describe the methodology we used in our experi-
ments and then describe a novel algorithm for automatically
creating benchmarks for word relatedness tasks.

Both ESA and TSA were implemented on the concepts
extracted from the folksonomies presented in Section 2.1,
and therefore use the same vector representations. This will
allow us to isolate the performance of the temporal dimen-
sion in the TSA semantics.
4.1 Experimental Methodology
Methods compared: We compare our algorithm and rep-
resentations to the state of the art semantic representation
— Explicit Semantic Analysis (ESA), which has been shown
to be signiﬁcantly superior to other approaches [16]. This
approach projects words into a high-dimensional space of
concepts derived from Wikipedia. Using machine learning
techniques, it represent the meaning of a word as a weighted
vector of Wikipedia-based concepts. Each concept in the
vector is weighted by relevance to the word. Assessing the
relatedness of words in this space is done by utilizing co-
sine distance – a conventional metric of comparison of high-
dimensional vectors.
Evaluation metrics: As in prior published studies, in our
evaluation we use Spearman correlation coeﬃcient to com-
pare the predicted relatedness scores with human judge-
ments. The comparison is applied on both our algorithm
and representations and the current state of the art.
Statistical Signiﬁcance: We compare the rank correlation
coeﬃcient of our method, rank1, to the competitive methods

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India340Procedure Cross Correlation(ts1, ts2)
(1)similarity(ts1, ts2) = 0
(2)cov(ts1, ts2) = 0
(3)For delay = {−delaymin . . . delaymax}
(4) For index = {0 . . . M in(|ts1|,|ts2|)}
(5)
(6)
(7)
(8)
(9)Return similarity(ts1, ts2)

delayedIndex = index + delay
cov(ts1, ts2) ← cov(ts1, ts2) + (ts1[index] − E(ts1)) ∗ (ts2[delayedIndex] − E(ts2))
corr@delay(ts1, ts2) ← cov(ts1,ts2)
N·σts1 σts2
similarity(ts1, ts2) ← M ax(similarity(ts1, ts2), corr@delay(ts1, ts2))

Figure 5: Time series cross correlation

Procedure DTW(ts1, ts2, C)
(1)n ← M in(|ts1|,|ts2|)
(2)dtw(ts1, ts2) ← new [|ts1| × |ts2|]
(3)For i = {1 . . . n}
(4)
(5)
(6)For i = {1 . . . n}
(7) For j = {1 . . . n}
(8)
(9)Return dtw(n, n)

dtw(i, 1) ← dtw(i − 1, 1) + c(i, 1)
dtw(1, i) ← dtw(1, i − 1) + c(1, i)

dtw(i, j) = (cid:107)ts1(i) − ts2(j)(cid:107) + M in(dtw(i − 1, j), dtw(i, j − 1), dtw(i − 1, j − 1))

Figure 6: Dynamic time warping algorithm

rank coeﬃcient, rank2, and calculate statistical signiﬁcance,
using the following standard formula:

p = 0.5 · ErrorF unction(

(8)

|z1 − z2|
√
N−3

2 ·(cid:113) 2
(cid:82) x
0 e−t2

), and ErrorF unction(x) = 2√

where N is the number of word pairs the dataset, zi = 0.5 ·
ln( 1+ranki
dt is the
1−ranki
standard Gauss error function.
4.2 Dataset Construction Algorithm

π

Evaluating word relatedness is a natural ability humans
have and is, therefore, considered a common baseline. To as-
sess word relatedness, we use the WS-353 benchmark dataset,
available online [14], which contains 353 word pairs. Each
pair was judged, on average, by 13-16 human annotators.
This dataset, to the best of our knowledge, is the largest
publicly available collection of this kind, which most prior
works [16, 37, 36, 35] use in their evaluation.

As an eﬀort to provide additional evaluation data in this
problem domain, we created a new dataset1 to further eval-
uate our results upon. We present a principled method to
create additional datasets, as opposed to the WS-353 bench-
mark where the word pairs were extracted manually. We
propose to draw the word pairs from words which frequently
occur together in large text domains. The relatedness of
these pairs of words is then evaluated using human annota-
tors, as done in the WS-353 dataset.
Selecting word pairs to evaluate: To create a balanced
dataset of both related words and unrelated words, we ap-
plied the following procedure: Let W be a set of all words in
the New York Times news articles. As we wish to compare
between entities, we intersect this collection with entities ex-
tracted from DBpedia. We further proceed with removing
stop words and rare words (words appearing less than 1000

1

http://www.technion.ac.il/ kirar/Datasets.html

over the entire time period), and stemmed the remaining
words. We annotate this collection as W (cid:48). For each word
pair (ai, aj) ∈ W ‘×W ‘, their point-wise mutual information
(PMI) is computed over the entire set of the articles, i.e., a
group G of all possible word pairs, ordered by their PMI
values

G = {(a1, b1), . . . , (an, bn) |P M I(ai, bj)

≤ P M I(ai+1, bj+1), (ai, bj) ∈ W ‘ × W ‘}

where P M I is deﬁned as:

P M I(ai, aj) = log

p(ai, aj)
p(ai)p(aj)

(9)

(10)

|W (cid:48)×W (cid:48)|

Eventually, given a pre-deﬁned number n of desired test
-th pair from the G(cid:48) ordering is cho-
pairs, every
sen. Formally, we construct the ﬁnal set
|gj ∈ G, j ≤ |W

D = {g

(11)

(cid:48) × W

(cid:48)|}

n

1+i· |W (cid:48)×W (cid:48)|

n

Intuitively, this process performs a stratiﬁed sampling, con-
taining both frequently and infrequently co-occurring words,
with decent coverage of the entire spectrum of co-occurrence
values (as measured by mutual information).
Obtaining human ratings from Amazon MTurk work-
ers: The human “ground truth” judgements were obtained
by using the Amazon’s Mechanical Turk workers, in batches
of 50 word pairs per assignment, resulting in 280 word pairs
labeled overall. Up to 30 workers per batch were assigned,
with the average of 23 MTurk workers rating each word pair,
on average. Ten (distinct) pairs from WS-353 dataset were
injected into each batch, in order to provide a calibration
baseline to discard poor-quality work. Additionally, a sim-
ple “captcha” requiring to solve a simple math problem was
given to each worker. As a result, the work of the annotators
with ratings that correlated less than 50% on the WS-353
subset of the batch, or those that failed the “captcha” was

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India341discarded (approximately 7% of the submitted ratings were
discarded through this procedure).

5. EXPERIMENTAL RESULTS

We ﬁrst report the main experimental results comparing
TSA to ESA on the WS-353 and MTurk datasets described
above. Then, we analyze the performance of TSA in more
detail on the WS-353 dataset to gain more insights into the
eﬀects of the diﬀerent system parameters.
5.1 Main Results

In this section we compare the results of TSA to known
similarity measurements. The section ﬁrst provides empiri-
cal evidence that temporal signals contribute to measuring
semantic relatedness of words, and then we show that our
representation as a vector of concepts combined with tem-
poral data outperforms previous temporal similarity tech-
niques.

5.1.1 TSA vs. ESA
The comparison results of TSA on the WS-353 dataset
are reported in Table 1. TSA results shown in the table are
computed using cross correlation with a quadratic weighted
function as the distance metric between single time series.

Table 1: TSA algorithm vs. ESA (WS-353 dataset)

Algorithm

Correlation
with humans

ESA-Wikipedia [16]

ESA-ODP [16]
TSA (Section 3)

0.75
0.65
0.80

As reported in Table 1, TSA performs signiﬁcantly better

compared to the ESA-Wikipedia approach, with p < 0.05.

We also evaluate the performance of ESA-Wikipedia and
TSA, on the additional dataset we created (we refer to it
as the MTurk dataset). The results are presented in Table
2. Again, TSA performs substantially better than ESA, con-
ﬁrming that temporal information is useful on other datasets.

Table 2: TSA algorithm vs. state-of-the-art (MTurk
Dataset)

Algorithm

Correlation
with humans

ESA-Wikipedia [16]

TSA (Section 3)

0.59
0.63

5.1.2 TSA vs Temporal Word Similarity
Some works [8] proposed measuring semantic similarity of
queries through temporal correlation analysis alone – with-
out expending to a vector of semantic concepts. We there-
fore compare to additional two baselines: Word-Similarity
using cross correlation and Word-Similarity using DTW as
the distance measurement of the time-series of the two words.
The results using the WS-353 and Mturk dataset can be seen
in Table 3. In both datasets TSA signiﬁcantly outperformed
the baselines. This suggests that temporal vector similarity
combined with static similarity is essential.

Table 3: TSA algorithm vs. temporal word similar-
ity (WS-353 dataset)

Algorithm Dataset

WS-353 MTurk

Word-Similarity (cross correlation)

Word-Similarity (DTW)

TSA (Section 3)

0.51
0.59
0.80

0.56
0.58
0.63

5.2 TSA Performance Analysis

This section analyzes the performance of TSA for vary-
ing settings to gain more insights into the advantages and
limitations of the TSA method.
5.2.1 Word Frequency Effects
To further analyze the performance of our algorithm we
conducted experiments to test on which type of word pairs
our algorithm outperforms the state of the art to this end.
We chose to focus on word frequency. We investigated whether
our algorithm performs better on frequent or rare words. We
measured frequency in both domains — Wikipedia and New
York Times. In order to evaluate the joint frequency of a
pair of words, we combine their frequency by three types of
measurements: minimum frequency of the two words, aver-
age, and maximum frequency of the two words. We divide
the word pairs into three buckets, each containing an equal
number of data points. We compute Spearman correlation
separately in each bucket.

The results for the minimum criteria for the New York
Times and Wikipedia corpora are reported in Tables 4 and
5, respectively. Similar results were obtained for the average
and maximum frequency measurements. The results show
that TSA performs signiﬁcantly better than ESA on low-
frequency words. This can be attributed to the fact that
ESA is based on statistical information about words and
concepts, which requires suﬃcient number of occurrences.
Low-frequency words do not have enough statistical data,
hence any additional signal, such as the temporal behavior
of the words, can improve the performance.

Table 4: Grouping word pairs by NYT word fre-
quency (WS-353 dataset)

Type of Bucket ESA Correlation TSA Correlation

with humans

with humans

Low

Medium

High

0.73
0.74
0.76

0.82
0.76
0.79

Table 5: Grouping word pairs by Wikipedia word
frequency (WS-353 dataset)

Type of Bucket ESA Correlation TSA Correlation

with humans

with humans

Low

Medium

High

0.72
0.68
0.78

0.79
0.68
0.81

The results on the Mturk Dataset comparing ESA-Wikipedia,

and TSA are reported in Table 6. While the absolute values
of the TSA and ESA correlations with humans are lower,
the trend persists: TSA signiﬁcantly outperforms ESA, par-
ticularly on words with low frequency. The lower absolute

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India342values are likely due to increased level of noise in the MTurk
ratings, despite performing best-of-practice ﬁltering of poor-
quality MTurk work [31], and as explained in Section 4.2.

Table 6: Grouping word pairs by Wikipedia word
frequency (Mturk dataset)

Type of Bucket ESA Correlation TSA Correlation

with humans

with humans

Low

Medium

High

0.52
0.50
0.77

0.61
0.48
0.79

Size of Temporal Concept Vector

5.2.2
In this subsection we experiment with several sizes of the
temporal concept vector in several diﬀerent natural repre-
sentations. In many of the folksonomy domains presented
in Section 2.1, we are able to obtain only vectors of about 10
concepts (based on API limitation in Flickr and Del.icio.us),
i.e., for each word we are not able to produce all the words
and their co-occurrence weight, but only the word’s related
tags. Due to this limitation, a traditional cosine measure-
ment cannot be computed between those partial vectors —
as each vector contains diﬀerent concepts. We deﬁne a size
of a concept vector to be the number of concepts. The main
advantage of the distance measurement we deﬁned in Sec-
tion 3.1 is the ability to measure distance between vectors
with diﬀerent concepts representation, and even vectors of
diﬀerent sizes. We ran the experiments on various vector
sizes. We deduce from the results (as appear in Table 7)
that the optimal vector size is 10. Additional improvements
for larger vector sizes might be achieved with additional fea-
ture selection.

Table 7: Eﬀect of concept vector size on perfor-
mance (WS-353)

Vector Size

5

10

50

Correlation with humans

0.78

0.80

0.80

100
0.79

5.2.3 Time Series Distance Functions
In this subsection we experiment with several distance
functions, that are applied during the measurement of the
semantics distance of the temporal concept vectors. Cross
correlation outperforms DTW in each setting, where TSA
with cross-correlation performance is 0.80, and with DTW it
drops to 0.74. This indicates that, for the purpose of mea-
suring similarity of concept’s vectors, correlations in time
series volume are more signiﬁcant than measuring general
similarity in time series structure (as in DTW).
5.2.4 Temporal Weighting Functions
Several weighting functions can be applied on the words’
time series to produce higher weighting to more recent cor-
relations (as we discussed in Section 3.2.3).
In this work,
we deﬁne several variations for a weighing function f (t1, t2).
This function receives two time points of two time series,
and is used to weigh the distance between the time-series at
these points. The functions we experiment upon are:

1. Constant Weighting Function: f (t1, t2) = Constant,

which weighs all time points equally.

2. Power Weighting Function: f (t1, t2) = (M ax(t1, t2))n
which is a power model of weight, in which volume dif-
ferences in more recent time points are weighted higher
based on the power of the function. We have experi-
mented on n = 1, 2.

3. Exponential Weighting Function: f (t1, t2) = eM ax(t1,t2)
which is an exponential model of weight, in which vol-
ume diﬀerences in recent time points are weighted ex-
ponentially higher.

The results of the performance for the TSA algorithm
(with cross correlation distance function over WS-353) are
presented in Table 8. The results provide evidence for the
need to weigh the recent changes in time series distance
measurement higher than the ancient changes. While lin-
ear, quadratic, and exponential temporal weighting func-
tions perform similarly, the quadratic performs best, and we
use it for all the experiments described in this paper. A few

Table 8: Eﬀect of temporal weighting function

Temporal Weighting Function

Correlation
with humans

Constant

Linear

Quadratic
Exponential

0.70
0.79
0.80
0.80

examples to illustrate those changes in performance can be
seen in Table 9. It is clear from the rankings presented in
the table, that quadratic weighting yields more signiﬁcant
correlation with human ranking than the constant weighting
function. The correlation of such words, such as “Mars” and
“water” in 1900 should be weighted diﬀerently from the cor-
relation they exhibit in 2008, when NASA images suggested
the presence of water on Mars.

Table 9: Temporal weighting inﬂuence

Word 1 Word 2 Humans TSA-Const TSA-Quadratic

Mars
peace

water
plan

Rank

46
102

Rank
210
220

Rank

94
108

6. DISCUSSION

In order to gain more intuition on which cases TSA ap-
proach should be applied, we provide real examples of the
strengths and weaknesses of our methods compared to the
state of the art ESA method. The results are derived from
the application of the TSA algorithm with cross correlation
and a quadratic weighting function as the distance metric
between single time series.
6.1 Strengths of TSA

Synonyms are the ﬁrst type of words for which the TSA
method seems to outperform the ESA method. The reason
for that is that synonyms have similar patterns of occur-
rence over time, as writers in the news corpus tend to use
them interchangeably. Therefore, the two synonyms time-
series in the same corpus strongly correlate over time. On
the other hand, ESA represents each word as a vector of

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India343concepts - where the weight is the TFIDF value. For each
concept’s Wikipedia article the number of distinct authors
is limited, and therefore, the language model, and, as a con-
sequence, the use of diﬀerent synonyms is quite limited. For
this reason, the TFIDF values of the synonyms in the ESA
representation tend to be quite diﬀerent. A sample of those
cases can be seen in Table 10, where we present for each pair
of synonyms the ranking given by human judgements, the
ESA rank and the TSA rank. The rankings are based on
the rank of the similarity of the pair of words out of the 353
pairs in the WS-353 dataset.

Table 12: Implicit Relations

Word 1 Word 2

closet

summer
disaster

cup
cup

clothes
drought

area

tableware

liquid

canyon

landscape

tiger

jaguar

Humans ESA TSA
Rank Rank
297
180
282
86
206
44
7
283
173
23
253
131
201
302

Rank
296
237
172
217
146
263
296

Table 10: Synonyms

Word 1 Word 2

asylum madhouse
coast
boy

shore
lad

problem challenge

Human ESA TSA
Rank Rank
Rank
336
338
347
341
291
337
209
252

61
232
198
74

are not always straight forward to humans. For example,
the correlation between ”drink“ and ”car“. In the news, many
times alcohol drinking correlates with car accidents, however
humans tend not to ﬁnd them related at all. Another repre-
sentative example is ”psychology“ and ”health“. These words
are considered very related by humans, however no true cor-
relation in the news was found between the two words. More
information about these examples can be seen in Table 13.

As our method also captures co-occurrences of words in a
single article (as we construct time-series aggregated over all
articles on a certain date), phrases can also be identiﬁed well.
ESA represents each word as a vector of Wikipedia concepts,
weighted by the TFIDF of the word in the concept’s arti-
cle. Therefore, when measuring similarity of “hundred” and
“percent’ the similarity score is quite low - as the words
appear in diﬀerent articles and acquire completely diﬀerent
meanings in diﬀerent contexts. Therefore, word phrases like
“hundred-percent” are not identiﬁed well by ESA. More of
those examples are presented in Table 11.

Table 11: Word Phrases

Word 1 Word 2 Humans ESA TSA
Rank Rank
235
341
166
78
276
151

Rank
189
247
166

percent
series

luxury
hundred

game

car

Implicit relations are one of the diﬀerentiating strengths of
the TSA representation and the new distance metric we pre-
sented. For example, causality relations, such as “summer
causes draught”, are easily detected using correlation of the
words’ time-series. Relations of “type-of” (such as canyon
is a type of landscape) are also relations we have found to
be common when TSA outperforms ESA. We attribute that
to the fact that many words in Wikipedia are associated
to the general concepts (in our example “landscape”) and
therefore, when measuring the distance between the con-
cepts’ TFIDF vectors, the relation of each sub-object (such
as ”canyon“) declines. Table 12 presents additional examples
of pairs belonging to these relations and the ranking of hu-
man judgments, ESA and TSA algorithms for the WS-353
dataset.
6.2 Limitations of TSA

Although we have seen many results in which TSA per-
forms better than ESA, we also present in this work some
examples in which TSA performs worse.

One of the strength of the algorithm sometimes also serves
as its weakness. Although this phenomenon is not too com-
mon, TSA identiﬁes very complex implicit relations, which

Table 13: Complex Implicit Relations
Word 1 Word 2 Humans ESA TSA
Rank Rank
203
107

40
268

50
239

health

Rank

drink

psychology

car

Some problems of our representation arise from the corpus
we have selected to represent the concept’s temporal behav-
ior. The corpus is, unfortunately, sparse in certain topics
— mostly speciﬁc topics such as technology and science (see
Table 14). Therefore, correlations between words such as
“physics” and “proton” are not identiﬁed well. A possible
solution for this problem would be to add other sections of
the New-York-Times news (such as sports, technology and
science), and weigh the words frequency by the appearance
in each one of those sections (so small sections will not be
“discriminated”). Considering adding additional temporal
corpus like blogs, tweets and so on, might also be useful.
Unfortunately, we did not have access to this kind of data
at the time.

Table 14: News Corpus Bias

Word 1 Word 2

physics
network
boxing

proton

hardware

round

Humans ESA TSA
Rank Rank
298
244
326

Rank
306
316
271

31
94
106

7. RELATED WORK

Automatically estimating word similarity (WS) and se-
mantic relatedness (SR) have been fundamental problems
for decades, and have been addressed by diverse techniques
in cognitive science, computational linguistics, artiﬁcial in-
telligence, and information retrieval. For example, in com-
putational linguistics, applications of WS include word sense
disambiguation, information retrieval, word and text clus-
tering [7]. This section ﬁrst brieﬂy reviews previous estab-
lished approaches to the WS and SR problems; we then

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India344focus on more recent approaches that make use of of collab-
oratively generated content (CGC) such as Wikipedia, and
ﬁnally frame our approach in the context of previous work
on using temporal information for WS and other problems.
7.1 Word Similarity and Relatedness

Until recently, computing semantic relatedness of natural
language texts (ranging from a single word to a document
in length) required encoding vast amounts of common-sense
and domain-speciﬁc world knowledge. Prior work pursued
three main directions: comparing text fragments as bags
of words in vector space [2], using hand-crafted lexical re-
sources such as WordNet [13], and using Latent Semantic
Analysis (LSA) [10]. The former technique is the simplest,
but performs sub-optimally when the compared texts share
few words, for instance, when the texts use synonyms to
convey similar messages. Unfortunately, this family of tech-
niques are not appropriate for comparing individual words.
Lexical databases such as WordNet [13] or Roget’s The-
saurus [29] encode relations between words such as syn-
onymy, hypernymy. Multiple metrics have been proposed
for computing relatedness using properties of the underly-
ing graph structure of these resources [7, 20, 3, 28, 24, 21,
17]. A serious drawback of relying on such curated lexical
resources is that it requires signiﬁcant expertise and eﬀort,
and consequently such resources cover only a small fragment
of the language lexicon. Speciﬁcally, such resources contain
few proper names, neologisms, slang, and domain-speciﬁc
technical words. Furthermore, these resources have strong
lexical orientation and mainly contain information about in-
dividual words but little world knowledge in general.

In contrast, LSA [10], a purely statistical technique, lever-
ages word cooccurrence information from a large unlabeled
corpus of text. LSA does not rely on any human-organized
knowledge; rather, it “learns” its representation by apply-
ing Singular Value Decomposition (SVD) to the words-by-
documents cooccurrence matrix. LSA is essentially a di-
mensionality reduction technique that identiﬁes a number of
most prominent dimensions in the data, which are assumed
to correspond to “latent concepts”. Meanings of words and
documents are then compared in the space deﬁned by these
concepts. Latent semantic models are notoriously diﬃcult
to interpret, since the computed concepts cannot be readily
mapped into natural concepts manipulated by humans. An-
other statistical approach is estimating semantic relatedness
of words through “distributional similarity” [23, 9] - that is,
the similarity of the contexts in which the words occur.

In this paper we deal with “semantic relatedness” rather
than “semantic similarity” or “semantic distance”, which are
also often used in the literature. In their extensive survey of
relatedness measures, Budanitsky et al [7] argued that the
notion of relatedness is more general than that of similar-
ity, as the former subsumes many diﬀerent kind of speciﬁc
relations, including meronymy, antonymy, functional associ-
ation, and others. They further maintained that computa-
tional linguistics applications often require measures of re-
latedness rather than the more narrowly deﬁned measures
of similarity. For example, word sense disambiguation can
use any related and not just similar words from the context.
7.2 Using Collaboratively Generated Content
Some works [30, 26] proposed to use the Web as a source of
additional knowledge for measuring similarity of short text

snippets. A major limitation of this technique is that it is
only applicable to short texts, because sending a long text as
a query to a search engine is likely to return few or even no
results at all. More closely related to our work, Gabrilovich
et al. [16] presented an approach to WS that relied on ex-
ploiting Wikipedia for “Explicit Semantic Analysis” or ESA,
and have demonstrated high correlation with human anno-
tators. Strube et al. [32] also used Wikipedia for computing
semantic relatedness.
7.3 Exploiting Temporal Dynamics

As many datasets have important temporal dimensions
(e.g., stock quotes, sensor readings, search engine query
popularity), there exist numerous techniques to analyze and
mine time series data. In particular, Vlachos et al. [33] and
subsequent work identiﬁed similar objects based on their tra-
jectories through time series analysis. Among many known
approaches to time series similarity we consider Dynamic
Time Warping (DTW) [6], which we use as one of the meth-
ods for identifying words with similar trajectories.

Gruhl et al. [18] and others [22] analyzed temporal infor-
mation diﬀusion in blogosphere, including the temporal pat-
terns in word popularity. Efron [11] considered term popu-
larity in a document collection, to assign better term weights
for document ranking. More similar to our work, but in
the context of analyzing temporal search engine query logs
(which often exhibit strong temporal regularities [4]), some
work [8, 25, 39] proposed a method for detecting semanti-
cally similar queries through temporal correlation analysis.
More generally, time series analysis has been used previously
to detect similar topic patterns [34], among many other ap-
plications. However, to the best of our knowledge, temporal
information has not yet been used to improve general word
relatedness estimation. In the related context of searching
evolving document collections, several prior studies focused
on versioned document retrieval models, where the objective
is to eﬃciently access previous versions of the same docu-
ment [38, 19]. Elsas and Dumais [12] studied the dynamics
of document content change with applications to document
ranking. Research on topic detection and tracking (TDT)
analyzed the evolution of stories and topics over time [1].
Gabrilovich et al. [15] studied the dynamics of information
novelty in evolving news stories. Olston and Pandey [27] in-
troduced the notion of information longevity to devise more
sophisticated crawling policies.

While our work also makes use of temporally evolving
statistics of a document collection, our goal is diﬀerent in
that we seek to identify related words based on temporal
patterns, rather then improve performance on a speciﬁc ap-
plication such as ranking or web crawling. Furthermore, our
work presents a novel way of representing terms in a vector
space of concept time series, which can then be compared
with time-series similarity measurements as building blocks.
Finally, we provide a ways of combining the static and tem-
poral information for computing relatedness - resulting in
a signiﬁcantly more accurate estimation of relatedness than
using either signal in isolation.

8. CONCLUSIONS

We proposed a novel approach to computing semantic re-
latedness with the aid of a large scale temporal corpus. We
use the New York Times archive that spans over a large pe-
riod of time, and which, to the best of our knowledge, have

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India345not been used before in such tasks. Speciﬁcally, we intro-
duced two innovations over the previous words’ semantic re-
latedness methods: ﬁrst, a new method, Temporal Semantic
Analysis, for representing the semantics of natural language
terms, and a new method for measuring semantic related-
ness of terms, using this representation. The algorithm is
robust in that it can be naturally tuned to assign diﬀerent
weights to time periods, and can be used for studying lan-
guage evolution over time.

Our empirical evaluation conﬁrms that using TSA leads
to signiﬁcant improvements in computing words relatedness
over two large datasets. Compared with the previous state
of the art, TSA yields statistically signiﬁcant improvements
in correlation of computed relatedness scores with human
judgements.

We also provide an algorithm for the automatic construc-
tion of new datasets of measuring semantic relatedness of
words, and provide additional dataset to the community for
further research in the ﬁeld.

We believe that more accurate identiﬁcation of word relat-
edness provided by TSA, will enable more intelligent search,
improve text classiﬁcation accuracy, and enable other tasks
that normally require understanding of subtle relationships
between words.

9. REFERENCES
[1] James Allan. Introduction to topic detection and tracking.

In Topic detection and tracking: event-based information
organization, pages 1–16. 2002.

[2] Ricardo Baeza-Yates and Berthier Ribeiro-Neto. Modern

Information Retrieval. Addison Wesley, 1999.

[3] Satanjeev Banerjee and Ted Pedersen. Extended gloss

overlaps as a measure of semantic relatedness. In IJCAI,
pages 805–810, 2003.

[4] S.M. Beitzel, E.C. Jensen, A. Chowdhury, O. Frieder, and
D. Grossman. Temporal analysis of a very large topically
categorized web query log. JASIST, 58(2):166–178, 2007.

[5] R. Bellman and R. Kalaba. On adaptive control processes.

IRE Transactions on Automatic Control, 4:1–9, 1959.

[6] D. Berndt and J. Cliﬀord. Using dynamic time warping to

ﬁnd patterns in time series. In AAAI-94 workshop on
knowledge discovery in databases, 1994.

[7] Alexander Budanitsky and Graeme Hirst. Evaluating

wordnet-based measures of lexical semantic relatedness.
Computational Linguistics, 32(1):13–47, 2006.

[8] S. Chien and N. Immorlica. Semantic similarity between

search engine queries using temporal correlation. In WWW,
pages 2–11, 2005.

[9] Ido Dagan, Lillian Lee, and Fernando C. N. Pereira.

Similarity-based models of word cooccurrence probabilities.
Machine Learning, 34(1–3):43–69, 1999.

[10] Scott Deerwester, Susan Dumais, George Furnas, Thomas

Landauer, and Richard Harshman. Indexing by latent
semantic analysis. Journal of the American Society for
Information Science, 41(6):391–407, 1990.

[11] Miles Efron. Linear time series models for term weighting

in information retrieval. JASIST, 6(7):1299–1312, 2010.

[12] J.L. Elsas and S.T. Dumais. Leveraging temporal dynamics
of document content in relevance ranking. In WSDM, 2010.

[13] Christiane Fellbaum, editor. WordNet: An Electronic
Lexical Database. MIT Press, Cambridge, MA, 1998.

[14] Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud

Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin.
Placing search in context: The concept revisited. ACM
TOIS, 20:116–131, 2002.

[15] Evgeniy Gabrilovich, Susan Dumais, and Eric Horvitz.

Newsjunkie: providing personalized newsfeeds via analysis
of information novelty. In WWW, pages 482–490, 2004.

[16] Evgeniy Gabrilovich and Shaul Markovitch. Computing

semantic relatedness using wikipedia-based explicit
semantic analysis. In IJCAI, pages 1606–1611, 2007.

[17] Gregory Grefenstette. SEXTANT: Exploring unexplored

contexts for semantic extraction from syntactic analysis. In
ACL’92, pages 324–326, 1992.

[18] Daniel Gruhl, Ramanathan V. Guha, David Liben-Nowell,

and Andrew Tomkins. Information diﬀusion through
blogspace. In WWW, 2004.

[19] Jinru He, Hao Yan, and Torsten Suel. Compact full-text

indexing of versioned document collections. In CIKM,
pages 415–424, 2009.

[20] Mario Jarmasz. Roget’s thesaurus as a lexical resource for
natural language processing. Master’s thesis, University of
Ottawa, 2003.

[21] Jay J. Jiang and David W. Conrath. Semantic similarity

based on corpus statistics and lexical taxonomy. In
ROCLING’97, pages 57–63, 1997.

[22] Ravi Kumar, Jasmine Novak, Prabhakar Raghavan, and

Andrew Tomkins. On the bursty evolution of blogspace. In
WWW, 2003.

[23] Lillian Lee. Measures of distributional similarity. In ACL,

pages 25–32, 1999.

[24] Dekang Lin. An information-theoretic deﬁnition of word

similarity. In ICML’98, pages 296–304, 1998.

[25] Z. Vagena M. Vlachos, C. Meek and D. Gunopulos.

Identifying similarities, periodicities and bursts for online
search queries. In SIGMOD, 2004.

[26] Donald Metzler, Susan Dumais, and Christopher Meek.

Similarity measures for short segments of text. In Advances
in Information Retrieval, volume 4425, pages 16–27. 2007.

[27] Christopher Olston and Sandeep Pandey. Recrawl

scheduling based on information longevity. In WWW, 2008.

[28] Philip Resnik. Semantic similarity in a taxonomy: An

information-based measure and its application to problems
of ambiguity in natural language. Journal of Artiﬁcial
Intelligence Research, 11:95–130, 1999.

[29] Peter Roget. Roget’s Thesaurus of English Words and

Phrases. Longman Group Ltd., 1852.

[30] Mehran Sahami and Timothy Heilman. A web-based kernel
function for measuring the similarity of short text snippets.
In WWW, pages 377–386, 2006.

[31] R. Snow, B. O’Connor, D. Jurafsky, and A.Y. Ng. Cheap

and fast—but is it good?: evaluating non-expert
annotations for natural language tasks. In EMNLP.

[32] Michael Strube and Simon Paolo Ponzetto. WikiRelate!

Computing semantic relatedness using Wikipedia. In
AAAI’06, pages 1419–1424, 2006.

[33] M. Vlachos, D. Gunopoulos, and G. Kollios. Discovering

similar multidimensional trajectories. In ICDE, 2002.

[34] X. Wang, C.X. Zhai, X. Hu, and R. Sproat. Mining

correlated bursty topic patterns from coordinated text
streams. In KDD, page 793. ACM, 2007.

[35] Eric Yeh, Daniel Ramage, Christopher D. Manning, Eneko

Agirre, and Aitor Soroa. Wikiwalk: Random walks on
wikipedia for semantic relatedness. In TextGraphs
Workshop, pages 41–49, 2009.

[36] T. Zesch, C.M¨uller, and I. Gurevych. Using wiktionary for

computing semantic relatedness. In AAAI, 2008.

[37] Torsten Zesch and Iryna Gurevych. Wisdom of crowds

versus wisdom of linguists - measuring the semantic
relatedness of words. Journal of Natural Language
Engineering., 16(01):25–59, 2010.

[38] Jiangong Zhang and Torsten Suel. Eﬃcient search in large

textual collections with redundancy. In WWW, 2007.

[39] Qiankun Zhao, Steven C. H. Hoi, and Tie yan Liu.

Time-dependent semantic similarity measure of queries
using historical click-through data. In WWW, 2006.

WWW 2011 – Session: Semantic AnalysisMarch 28–April 1, 2011, Hyderabad, India346