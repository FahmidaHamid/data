Improving Recommendation for Long-tail Queries

via Templates

Idan Szpektor
Yahoo! Research

Haifa, Israel

idan@yahoo-inc.com

Aristides Gionis
Yahoo! Research
Barcelona, Spain

gionis@yahoo-inc.com

Yoelle Maarek
Yahoo! Research

Haifa, Israel

yoelle@ymail.com

ABSTRACT
The ability to aggregate huge volumes of queries over a large
population of users allows search engines to build precise
models for a variety of query-assistance features such as
query recommendation, correction, etc. Yet, no matter how
much data is aggregated, the long-tail distribution implies
that a large fraction of queries are rare. As a result, most
query assistance services perform poorly or are not even trig-
gered on long-tail queries. We propose a method to extend
the reach of query assistance techniques (and in particu-
lar query recommendation) to long-tail queries by reasoning
about rules between query templates rather than individ-
ual query transitions, as currently done in query-ﬂow graph
models. As a simple example, if we recognize that ‘Mon-
tezuma’ is a city in the rare query “Montezuma surf” and if
the rule ‘<city> surf → <city> beach’ has been observed,
we are able to oﬀer “Montezuma beach” as a recommenda-
tion, even if the two queries were never observed in a same
session. We conducted experiments to validate our hypothe-
sis, ﬁrst via traditional small-scale editorial assessments but
more interestingly via a novel automated large scale eval-
uation methodology. Our experiments show that general
coverage can be relatively increased by 24% using templates
without penalizing quality. Furthermore, for 36% of the 95M
queries in our query ﬂow graph, which have no out edges and
thus could not be served recommendations, we can now oﬀer
at least one recommendation in 98% of the cases.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Query for-
mulation; H.2.8 [Database Applications]: Data Mining

General Terms
Algorithms, Experimentation

Keywords
query templates, query recommendation, query mining

1.

INTRODUCTION

Mining query logs on a large scale has been shown to be
tremendously useful for web search and web applications.
Query logs have been successfully explored for a variety of

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2011, March 28–April 1, 2011, Hyderabad, India.
ACM 978-1-4503-0632-4/11/03.

purposes such as core ranking, automatic query expansion,
web caching, user modeling, matching ads, and more. One
of the most direct and visible applications of query log min-
ing is query recommendations in its multiple forms, from
dynamic query suggestions “as you type” to related searches
displayed on the search-engine results page.

Yet, in spite of their relative success, all query-log based
methods exhibit the same weakness: they cease being as
useful when reaching the long tail. As a result, methods
that operate at the level of individual queries cannot, as of
today, handle rare or one-time queries and this leads to a
signiﬁcant coverage issue on the long tail.

One approach could be to simply ignore the long tail and
concentrate on serving best head and torso needs. This
approach, we believe, would probably be a mistake.
In-
deed, Goel et al. [12] conducted a thorough analysis of the
“anatomy of the long tail,” and showed that most “ordinary
people ..[have].. extraordinary tastes,” i.e. all of us exhibit a
certain level of eccentricity. Even more importantly, it turns
out that supporting the tail boosts the head by providing
users a convenient one-stop shop for both their mainstream
and niche interests. Following this view, we believe that it is
critical to appropriately handle long-tail queries, especially
in the query-recommendation family of applications.

In this paper, we focus on related query recommendation,
one of the tasks for which the long-tail issue is the most
visible. We propose to address the long-tail problem by
leveraging query templates [1], which are query constructs
that abstract and generalize queries. Our key idea is to
identify rules between templates as means for suggesting re-
lated queries. The rationale for our approach is based on the
fact that many individual queries share the same query in-
tent while focusing on diﬀerent entities. Hence, their related
queries also share similar structures. As an example, assume
that the queries “Los Angeles hotels”, “New York hotels”
and “Paris hotels” have been abstracted into the common
query template “<city> hotels”. In addition, if “Los An-
geles restaurants” is a query recommendation for “Los
Angeles hotels” and similarly “New York restaurants” is
a recommendation for “New York hotels”, we can extract
the general rule:

‘<city> hotels → <city> restaurants’

Using such a rule, we could then oﬀer for the query “Yancheng
restaurants”, the suggested query “Yancheng hotels” even
if both are rare queries and had never been observed before.
The key challenge in this approach is to ensure that while
signiﬁcantly improving coverage for query recommendations,
we maintain a certain level of quality in order to satisfy

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India47users. We even argue that a small drop in quality would be
acceptable as long as the user has enough valid recommenda-
tions to select from. In contrast, not oﬀering any suggestion
damages the user experience, as lack of coverage remains a
signiﬁcant issue: we have observed on a Yahoo! query log
sample that 34M queries, out of 95M, had no consecutive
query. Thus, in our sample, any query recommendation sys-
tem that leverages query reformulation would not be able to
derive any information for more than 36% of the queries.

In this paper we make the following contributions:
• We introduce the concept of rules between query tem-
plates, which can be used to infer recommendations
for rare or previously unseen queries. We apply the
concept of template rules on the query-ﬂow graph [5].
At a high level, the concept is general and can be used
to enhance other query-log constructs.

• We explain how to build templates and more speciﬁ-
cally how to extract template rules. Note that unlike
prior work on templates, which used semi-supervision
on restricted domains [1, 16], we can aﬀord to work
at a general, large-scale level because we extract rules
rather than stand-alone templates and ambiguity is
therefore automatically reduced (see Section 4.5).

• We introduce the query-template ﬂow graph as an en-
richment of the query-ﬂow graph with templates. We
then describe how to use the query-template ﬂow graph
for the task of query recommendation.

• We provide an experimental evaluation, which shows
that using a query-template ﬂow graph instead of a
query-ﬂow graph construct consistently improves the
quality of recommendations, especially for long-tail queries.
We verify our claims using manual evaluation, as well
as a novel automated large-scale evaluation process
over millions of tested recommendations.

2. RELATED WORK
Query recommendations. Most query-recommendation
methods use similarity measures obtained by mining (i) the
query terms, (ii) the clicked documents, and/or (iii) the
user sessions containing the queries. Typical methods use a
combination of these factors.

Query recommendation based on clicked documents.
Baeza-Yates et al. [3] propose a measure of query similarity
and use it to build methods for query expansion. Their
technique is based on a term-weight vector representation of
queries, obtained from the aggregation of the term-weight
vectors of the URLs clicked after the query. Wen et al. [27]
also present a clustering method for query recommendation
that is centered around the query-click graph [4].

The query-click graph is also utilized for ﬁnding related
documents using random walks [8], ﬁnding related keywords
for advertising [11], query rewriting through co-citation gen-
eralization [2] and ranking related queries using the notion
of hitting time [19].

Query recommendation based on query reformula-
tions. Many eﬀective approaches focus on the analysis of
user query sessions [10, 14, 30]. Fonseca et al. [10] propose
a query recommendation system based on association rules.
Another attempt of extracting information from the query

log is due to Zhang and Nasraoui [30], who represent each
user session by a complete graph where consecutive queries
are connected with an edge of a predeﬁned weight d. Non-
consecutive queries are connected by an edge weighted with
the product of the weights on the walk connecting them.
Recent papers have shown that not only the previous query,
but also the long-term interests of users, are important for
understanding their information needs [18, 22].

Jones et al. [14] introduce the notion of query substitu-
tion:
for each query, a set of similar queries is obtained
by replacing the whole query or its sub-phrases. White et
al. [28, 29] use the query rewrites observed in a query log to
generate query recommendations. Sadikov et al. [23] have
recently proposed to cluster the reﬁnements of a user query
by performing a random walk on a query-document graph
that incorporates both session and click information.

One limitation for query recommendation that is common
to the above works is that recommendations cannot be made
for queries that were not seen before. Additionally, the qual-
ity of recommendations declines for infrequent queries.

Name-entity and template extraction using query
logs. A few researchers have addressed the problem of ex-
tracting name-entities and hierarchy knowledge-bases from
query logs [9, 21]. The main idea of these papers is to use
the query log in order to extract entities and populate lex-
icons and/or ontology data. Since in this paper we are not
concerned with building an entity hierarchy, such a line of
research is orthogonal and complementary to ours.

Few works attempt to tag query terms [13, 16], an impor-
tant step towards generating templates for queries. These
works apply semi-supervised approaches for tagging with
predeﬁned categories. Recently, Agarwal et al. [1] intro-
duced query templates as means to detect query intent and
query attributes for a speciﬁc domain. They propose a semi-
supervised approach for learning relevant templates in a do-
main, where both the domain attributes and seed queries are
manually provided. Unlike these works, we aim at broad-
coverage recommendation using templates for any query,
with neither predeﬁned categories nor speciﬁc domains.

Templates in Natural Language Processing Finally
we note that templates and rules between them have been
successfully used in a number of NLP tasks such as infor-
mation extraction [26], taxonomy population [24], question
answering [17] and machine translation [6].

3. PRELIMINARIES

In this section we review the concepts of query logs and the
query-ﬂow graph, which are central concepts in our paper.
3.1 Query logs

Query-log analysis is typically used by search engines to
build models of the interaction of the users with the search
engine, and it is applicable to a wide range of applications.
A typical query log L is a set of records (cid:3)qi, ui, ti, Vi, Ci(cid:4),
where qi is a query submitted to the search engine; ui is an
anonymized identiﬁer for the user who submitted the query;
ti is a timestamp; Vi is the set of documents returned as
results to the query; and Ci is the set of clicked documents.
A useful concept is a physical session, or simply session:
a sequence of queries of one particular user within a speciﬁc
timeout tθ. A typical timeout threshold often used in query-
log analysis is tθ = 30 minutes.

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India483.2 The Query-Flow Graph

The query-ﬂow graph, which was introduced by Boldi et
al. [5], is a graph structure that aggregates information con-
tained in a query log. At an intuitive level, a query-ﬂow
graph is a graph in which nodes are queries, and edges (qi, qj)
with large weights indicate that query qj is a very likely re-
formulation of query qi. Formally, a query-ﬂow graph is
deﬁned as a directed graph Gq = (Q0, Eqq, sqq) where:

• Q0 = Q ∪ {s, t} is the set of distinct queries Q sub-
mitted to the search engine plus two special nodes s
and t, representing a starting state and a terminal state
of any user search task;

• Eqq ⊆ Q0 × Q0 is the set of directed edges;
• sqq : Eqq → (0..1] is a weighting function that assigns
to every pair of queries (qi, qj) ∈ Eqq a score sqq(qi, qj).
In the basic construction of the query-ﬂow graph, two queries
qi and qj are connected by an edge if there is at least one ses-
sion in the query log in which qj follows qi. The edge weight
w may depend on the application; one simple deﬁnition is
to use as weight the frequency of the transition (qi, qj) out
of all instances of qi. While there are more sophisticated
versions of query-ﬂow graph the deﬁnition of edge weights
is orthogonal to the focus of this paper and so we set query-
ﬂow graph edge weights to be transition probabilities.

One application of the query-ﬂow graph, suggested by
Boldi et al., is query recommendation. The idea is fairly
natural: for a query qi recommend queries qj for which the
weight of the edge (qi, qj) in the query-ﬂow graph is high
enough. Various alternatives for picking those queries were
studied. Those alternatives were inspired by ideas based on
PageRank and personalized PageRank.

An obvious limitation of using the query-ﬂow graph for
query recommendation is that no recommendation can be
made for queries that were not seen before. This is the
limitation that we try to alleviate with the present work.

4. QUERY TEMPLATES AND THE QUERY

TEMPLATE FLOW GRAPH

In this section, we describe our query-template approach
for handling the long-tail problem of query logs. We for-
mally describe query templates and template construction.
We then introduce relations between templates, and present
a recommendation algorithm based on a query-ﬂow graph
enhanced with templates.
4.1 Query Templates

Our notion of query templates is similar to the one used
by Agarwal et al. [1]; the main diﬀerences are that (i) we
deﬁne templates over a hierarchy of entity types, and (ii) we
deﬁne a global set of templates for the whole query log and
we do not restrict our templates on speciﬁc domains (say,
travel, weather, or movies).
We start our discussion by considering the set of all queries
Q = {q1, q2, . . .} that appear in a query log of a search en-
gine, where each query, q ∈ Q is a sequence of search terms,
q = w1 . . . wr. For a query q we deﬁne a tokenization to be
a grouping of the terms of q into consecutive sequences of
terms. For example, all possible tokenizations of “chocolate
cookie recipe” are: (chocolate)(cookie)(recipe), (cho-
colate)(cookie recipe), (chocolate cookie)(recipe), and

(chocolate cookie recipe), where parentheses are used only
for indicating the token boundaries. Very often, not all pos-
sible tokenizations of a query are meaningful.

In addition to the query log, we also assume that we have
access to an additional source of information: a generaliza-
tion hierarchy H = (E, R) on a set of entities E. As usual,
the set of generalizations R ⊆ E × E contains a pair ei → ej
if the entity ej is a semantic generalization of the entity ei
(R induces a DAG on E). We also say that ei is a type of
ej. For example, R may contain the following pairs:

chocolate → food
chocolate → drink
cookie → dessert
chocolate cookie → dessert
dessert → food
food → substance
recipe → instruction
. . .

We overwrite the notation to denote ei → ej if there is a
sequence of generalizations in R that leads from entity ei
to entity ej in the hierarchy H. So, in the above example,
we have chocolate → substance, since chocolate → food
→ substance. If ei → ej, we write d(ei, ei) to denote the
shortest path from ei to ej using the generalizations of R.
So, d(chocolate,substance) = 2.

Now let q = w1 . . . wr be a query with a tokenization
q = k1 . . . ks. Assume that the i-th token of the query, ki
is present as an entity in the generalization hierarchy H,
namely ki = ei ∈ E, and that ei → ej, for some other en-
tity ej. We deﬁne a template t(q | ki → ej) of q by replacing
the entity ki with a placeholder of type <ej> in the query q.
In other words t(q | ki → ej) =k 1 . . . ki−1<ej>ki+1 . . . ks.
The angle brackets <·> are used to indicate that a substi-
tution by a placeholder has taken place. We denote the set
of templates of q by T (q) ={ t1, t2, . . .}.

In our running example, some of the possible templates

for the query q =“chocolate cookie recipe” are:

<food> cookie recipe
<drink> cookie recipe
<food> recipe
<substance> recipe
chocolate cookie <instruction>

We deﬁne kq(t) to be the token ofq that was replaced when
generating t and e(t) to be the placeholder in t.
In our
example, kq(“<food> recipe”) is ‘chocolate cookie’ and
e(“<food> recipe”) is ‘food’.

A template is utilized by instantiating it with a token
whose type matches the type of the template placeholder.
We denote by IH(t | k) the query generated by instantiating
template t with token k based on the generalization hierar-
chy H. For example, IH(“<food> recipe” | “soup”) is “soup
recipe”. The result of instantiating an invalid token of an
unmatched type is null. The power of template instantiation
lies in its ability to generate queries that were not observed
before, as a cross product of templates and entities.
For each template t ∈ T (q) of a query q we associate
a score sqt(q, t). This score provides a measure of good-
ness of the template t as a generalization of the query q.
Intuitively, for our query “chocolate cookie recipe”, the
template “<food> recipe” should have a higher score than
“<substance> recipe”. This captures the notion that the

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India49more we generalize a query, the less conﬁdent we are, the
risk being to over-generalize. In addition, “<food> recipe”
should have a higher score than “<drink> cookie recipe”,
so as to give preference to more semantically valid templates.
4.2 Template Rules

Rules among templates enable the inference of meaningful
recommendations for queries that have been seen very rarely,
even for the ﬁrst time. Once queries have been generalized
to templates, the next step is to mine for frequent transi-
tions among templates, which we call template rules. The
transition ‘<city> hotels → <city> restaurants’ shown
in the introduction is an example of a template rule.

The power of template rules lies in their ability to provide
inference rules by aggregating over many diﬀerent individual
query transitions. Thus, template rules eliminate noise very
eﬀectively and capture meaningful transitions. More discus-
sion on template rules follows in the rest of this section.
4.3 The Query-Template Flow Graph

4.3.1 Representation

A central concept in this paper is the query-template ﬂow
graph, which extends the query-ﬂow graph of Boldi et al [5].
The query-template ﬂow graph is a graph whose nodes rep-
resent not only the queries Q but also the templates T . In
addition to the query-to-query edges Eqq, there are also
edges Eqt that specify the mapping from a query q to its
templates T (q), and also edges Ett between templates. More
formally, the query-template ﬂow graph is a graph Gt =
(Q0, T, Eqq, Eqt, Ett, sqq, sqt, stt), where

• Q0, as in the query-ﬂow graph, is the set of queries

plus the starting and terminal queries;

• T is the set of all templates formed by the queries of Q,

(cid:2)

that is, T =

q∈Q T (q);

• Eqq is the set of query-to-query transition edges, as in

the query-ﬂow graph;

• Eqt is the set of query-to-template mapping edges, that
is, edges between queries q ∈ Q and templates of T (q);
• Ett is the set of template-to-template transition edges,

to be deﬁned shortly;

• sqq are query-to-query scores on the edges of Eqq, as

in the query-ﬂow graph;

• sqt are query-to-template scores on the edges of Eqt

mentioned above, to be deﬁned shortly;

• stt are template-to-template scores on the edges of Ett;
stt(t1, t2) is a measure of goodness that template t2 is a
good transition from template t1, to be deﬁned shortly;

We next describe how the parts of the query-template ﬂow
graph are constructed in this paper, namely, the set of tem-
plates T , the query-to-template and template-to-template
edges, Eqt and Ett, and their respective scores sqt and stt.

4.3.2 Template construction

As discussed above, templates are constructed with the
help of a generalization hierarchy H over entities.
In our
implementation, H is the WordNet 3.0 hypernymy hierar-
chy [20] and the Wikipedia category hierarchy, connected

together via the yago1 induced mapping [25]. This hier-
archy features more than 1,750,000 entities with more than
4,470,000 direct generalizations between them. In general,
our approach can employ any method for generating an en-
tity hierarchy, e.g. from query logs [9, 21].

All the distinct queries in the query-ﬂow graph are pro-
cessed. For each query q we construct the set of templates
T (q) as follows:

First we normalize q by converting all characters to lower
case, collapsing continuous spaces, removing non-printable
characters, etc.

Then, every word n-gram up to length 3 in q is considered
as a token for replacement by a placeholder. For every n-
gram k, we add to T (q) all the templates formed by replacing
k with each of its generalizations in H (if any). We note that
n-grams that consist of stop-words are ignored.

In addition to the above general scheme, we found that
the coverage of the produced templates can be improved by
taking care of a small number of special cases, which appear
often in query logs, when an n-gram is not found in the
yago hierarchy. If there are context words around such an
n-gram (the n-gram is not the whole query) we further look
into the following cases:

• If the n-gram is an email address, we generate an
email-typed template, e.g., “ggg@yahoo.com instant
message” becomes “<email> instant message”.

• If the n-gram is a url, we generate a url-typed tem-
plate, e.g. “nbc.com login” becomes “<URL> login”.

• If the n-gram contains numbers, we generate a numerically-
typed template, e.g., “555-7777 address”becomes “<000-
0000> address”.

• Otherwise, if the n-gram is a noun-phrase, we create a
postﬁx-typed template, e.g., “luxury cars sale” be-
comes “<?-cars> sale”.

4.3.3 Query-to-template edges

Query-to-template edges Eqt are used to specify the map-
ping from a query q to the templates T (q). That is, we have
(q, t) ∈ Eqt if and only if t ∈ T (q). As already mentioned,
some templates in T (q) are more conﬁdent generalizations
than others, a notion captured by the score sqt(q, t) as the
goodness of the edge (q, t) ∈ Eqt.
Let q be a query and t ∈ T (q) be a template for q. To
compute the score sqt(q, t) we ﬁrst compute a score Sqt(q, t),
and we then normalize all scores Sqt(q, t) to ensure that the
total score from the query q sums to 1. For the unnormalized
scores Sqt(q, t) we use the following rules, which we found
to work well in practice.

• If t was obtained by substituting the token kq(t) with
an entity e in the hierarchy H then, intuitively, the
higher e is located in the hierarchy, the less conﬁdent
we are in the template quality. Consequently, we se-
lect our score to be exponentially decaying with the
distance d(kq(t), e) between the token and the gener-
alization e in the hierarchy:

Sqt(q, t) =α d(z,e)

where α was set to 0.9 in our experiments.

1

www.mpi-inf.mpg.de/yago-naga/yago/

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India50• For all email-typed, url-typed, and numerically-typed

templates t of a query q we set Sqt(q, t) = 0.5.

• Finally, for all postﬁx-typed templates t of a query q

we set Sqt(q, t) = 0.1.

In addition, if q(cid:3)
is a query and (q, q(cid:3)
convenience of notation, we set Sqt(q, q(cid:3)
Sqt(q, q(cid:3)

) = 0. Normalization is then performed by setting
, where t ∈ T (q) ∪ Q

Sqt(q, t)

(cid:3)

sqt(q, t) =

t(cid:2)∈T (q)∪Q Sqt(q, t(cid:3))

) ∈ Eqq then, for
) = 1, otherwise,

It is important to note that both the template construc-
tion procedure and the query-to-template score function are
not dependent on query occurrences in the query log, only
on the hierarchy H. Hence, whenever we encounter a new
query q that is currently not in Q0 (an unseen query), we
can add it to Q0 as well as its mapping edges to already
existing templates in T in an on-line fashion.

4.3.4 Template-to-template edges

The set of edges Ett forms the set of template rules that
were introduced in Section 4.2. Template rules describe the
possible transitions between templates for suggesting related
templates. Recalling our running example, a possible transi-
tion could be ‘<food> recipe → healthy <food> recipe’.
Each template rule in Ett is accompanied by a score stt,
which captures the conﬁdence of generating valid related
queries by instantiating the corresponding templates.

Consider two templates t1 and t2 in the query-template
ﬂow graph. A directed edge (t1, t2) is in Ett if and only if:
• e(t1) = e(t2), i.e., they have the same placeholder type.
• there is at least one edge (q1, q2) in the query-ﬂow
graph between queries q1 and q2 such that t1 ∈ T (q1),
t2 ∈ T (q2) and kq1 (t1) = kq2 (t2), that is the substi-
tuted token in q1 and in q2 is the same. We call such
query-to-query edges support edges and denote the set
of support edges for (t1, t2) by Sup(t1, t2).

As an example, an edge ‘sandwich recipe → healthy
sandwich recipe’ in the query-ﬂow graph would give rise
to the edge ‘<food> recipe → healthy <food> recipe’ in
the query-template ﬂow graph.

To compute the score stt(t1, t2) between the templates t1
and t2, we sum over the scores of all supporting pairs of
queries, and we normalize so that the total score out of each
template sums to 1:

St(t1, t2) =

stt(t1, t2) =

(cid:4)

(q1,q2)∈Sup(t1,t2)
St(t1, t2)
(cid:3)
t St(t1, t)

.

sqq(q1, q2),

4.4 Generating Query Recommendations

We next discuss how to utilize the query-template ﬂow
graph in order to provide query recommendations. Given
an input query q that was submitted by a user, our task is
to recommend other queries q(cid:3)
that are likely to be helpful
for the user. Our output is a ranked list of candidate related-
queries, ordered by their conﬁdence score (highest ﬁrst).
are those for which there is a directed edge (q, q(cid:3)
The related query conﬁdence score r(q, q(cid:3)

Using the query-ﬂow graph, the candidate related queries
) inE qq.

) is sqq(q, q(cid:3)

).

Similarly, utilizing the query-template ﬂow graph, the can-
didate related queries are those for which there is either a
directed edge (q, q(cid:3)
) in Eqq or there is a mapping edge (q, t)
and a template-to-template transition edge (t, t(cid:3)
), such that
IH(t(cid:3) | kq(t)) = q(cid:3)
, that is the instantiation of template t(cid:3)
with the mapping token of q to t results in q(cid:3)

.

For example, one recommendation for the query “Adele As-
taire” is “Adele Astaire biography”, based on the map-
ping edge ‘Adele Astaire → <artist>’ and the transition
edge ‘<artist> → <artist> biography’.
Notice that the recommended query q(cid:3)

does not have to be
in Q, i.e. it does not have to appear in the query log. This
is because q(cid:3)
is generated as an instantiation of a template
with a token extracted from the input query (which itself
could be an unseen query). The conﬁdence score r(q, q(cid:3)
)
based on the query-template ﬂow graph is:
r(q, q(cid:3)

sqt(q, t)·stt(t, t(cid:3)

) =s qt(q, q(cid:3)

)·sqq(q, q(cid:3)

(cid:4)

)+

).

t∈T (q) ∧
(t,t(cid:2))∈Ett ∧
IH(t(cid:2)|kq (t))=q(cid:2)
Since both scores sqt(q, t) and stt(t, t(cid:3)

) are normalized,
r(q, q(cid:3)
) is always between 0 and 1. In particular, it can be
interpreted as the probability of going from q to q(cid:3)
by one
of the feasible paths in the query-template ﬂow graph. We
note that in our experiments we rank ﬁrst queries that were
seen before as related (sqq(q, q(cid:3)
) > 0), assuming that they
are more reliable recommendations.
4.5 Discussion

Choosing the right template or set of templates for a query
is a diﬃcult task, since many queries consist of more than
one term, and many terms are ambiguous. For example, in
“jaguar transmission fluid” it is unclear on which term
the focus is. Additionally, “jaguar” has several meanings
based on which the query could be generalized. Hence,
prior work on query templates focused on semi-supervised
approaches in speciﬁc domains, where the task is simpler [1,
16]. However, we aim at a general large-scale application
of template rules for all kinds of queries. For our advan-
tage, extracting rules instead of single templates diminishes
the problems mentioned above. First, shared terms between
queries typically coincide with the query focus. Second, ag-
gregating occurrence statistics for rules emphasizes the cor-
rect sense of ambiguous terms under the query context.
For example, the query transition ‘jaguar transmission
fluid → jaguar used parts’ indicates that “jaguar” is the
focus. In addition, by observing other transitions, e.g. ‘toy-
ota transmission fluid → toyota used parts’, the tem-
plate rule ‘<car> transmission fluid → <car> used parts’
is brought forward as the frequent rule, diminishing the
eﬀect of other possibly extracted rules, such as ‘<feline>
transmission fluid → <feline> used parts’.
4.6 Complexity and System Design

One nice feature of the proposed method is that it can be
implemented eﬃciently in a map-reduce environment, such
as the hadoop platform2. For building the query-template
ﬂow graph, templates may be generated independently for
each query, together with their mapping scores, at hadoop
nodes that keep the hierarchy H in memory. Template nodes
are then aggregated at reduce time. If H is too big to ﬁt

2

http://hadoop.apache.org/

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India51Table 1: Statistics for the query-ﬂow graph and the
query-template ﬂow graph used in our experiments
(query statistics are the same for the query-ﬂow
graph and the query-template ﬂow graph).
templates
5,382,051,983
4,345,497,267
0.81
34,249
(<album>)
133,874
(<institution>)

95,279,132
83,513,590
0.88
14,145
(craigslist)
14,317
(youtube)

# nodes
# edges
avg in/out degree
max out-degree

max in-degree

queries

Table 2: Accuracy of each conﬁguration and each
sample-set based on manual evaluation

qfg

qtfg
set-A 98.48% 97.84%
set-B 97.65% 98.86%
set-C
94.38%

—

in main memory, it may be partitioned among the hadoop
nodes. In this case, diﬀerent n-gram pieces of one query may
be processed by diﬀerent hadoop nodes and be aggregated at
the end. Finally, the template-to-template edges and scores
may also be computed in a map-reduce fashion as a sequence
of joins—we omit the details.

On the other hand, generating query recommendations
needs to be an online process. For a computationally viable
solution, the idea is again to split the query-template ﬂow
graph among diﬀerent back-end nodes, mapped according
to queries and query templates. A new query is ﬁrst parsed
by a broker to generate the set of possible templates. Then
the templates are sent to the appropriate back-end nodes
to compute candidate recommendations and scores, which
are returned to the broker in order to be aggregated and
produce the ﬁnal ranking.

5. EXPERIMENTS

In this paper, we tested the proposed query-template ﬂow
graph on the task of query recommendation. We compared
between two conﬁgurations: (i) recommendations using the
query-ﬂow graph, denoted qfg; and (ii) recommendations
using the query-template ﬂow graph, denoted qtfg.

We conducted two experiments. The ﬁrst experiment fol-
lows the typical manual evaluation of query recommendation
methods [3, 10, 18], where the quality of recommendations is
assessed by human judges. However, manual evaluation suf-
fers from limitations, such as human labor and scale. There-
fore, as a second experiment, we propose a novel automatic
evaluation approach for the query recommendation task.
5.1

Implementation

For constructing the query-ﬂow graph, and consequently
the query-template ﬂow graph, we used a development query
log from which we sampled user sessions. For testing the
graphs, sessions were sampled from a later query log, de-
noted the test-query-log (see each experiment for the exact
test-set construction details).

Table 1 presents statistics for the two graphs. From the
ﬁgures we see that 56 candidate templates are generated
on average for each query, and this reﬂects the number of
template-to-template edges generated. While the query-
template ﬂow graph performance is signiﬁcantly better than

the query-ﬂow graph (see the following sections), this gener-
ation is still noisy and many of the generated templates and
edges between templates are incorrect, though with lower
scores. In future work, we plan to improve our identiﬁca-
tion of correct templates and edges that should be generated
for a given query or a given edge in the query-ﬂow graph.

The average degree of a node is very small, but the vari-
ance is huge. While about a third of the nodes (both for
queries and templates) have no outgoing edges and about
a similar percentage have no incoming edges, the maximum
in and out degrees are very large. For templates, some of
the large degrees are due to very general templates, while
some queries (and consequently templates) are simply very
frequent in sessions, as shown in the table.

5.2 Manual Evaluation

Following the typical evaluation procedure in prior work,
the authors evaluated a random sample of query recommen-
dations for the two tested conﬁgurations, qfg and qtfg.

For each conﬁguration we randomly sampled 300 queries
that occurred in the test-query-log, and which were followed
by a consecutive query within a single session. Each system
suggested related queries, from which one recommendation
was chosen randomly out of the top 10 recommendations. In
total, 300 pairs of an input query and one of its recommen-
dations were sampled for each conﬁguration, denoted set-A.
In addition, 100 pairs were randomly chosen from the 300
pairs sampled for qfg. We then extracted, for the input
queries in these pairs, the recommendations by qtfg that
were ranked in the same position as those in the query-ﬂow
graph pairs. This sample, denoted set-B, compares more
directly between the two methods on the same input queries
and the same recommendation ranked positions.

Finally, 100 queries, for which no recommendation could
be provided by qfg (queries that were not seen before), were
randomly sampled from the test-query-log, and one of the
top 10 recommendations by qtfg was randomly selected
for each. This sample, denoted set-C, assesses the extension
capabilities of the query-template ﬂow graph.

In total, 800 query-recommendation pairs were evaluated.
Two of the authors blindly evaluated these pairs, with an
overlap of 100 queries for agreement assessment. The mea-
sured agreement between the two judges is 93% and the
corresponding Kappa statistic [7] is 0.37, which is typically
viewed as “fair” agreement [15]. No decision was made by
the authors for about 10% of the examples.

Table 2 presents the results of the manual evaluation. The
accuracy of both methods is very high, with a slight gain for
the query-ﬂow graph in general (set-A). Yet, when looking
at proposed related queries for the same input queries at the
same ranked position (set-B), we see that actually it is qtfg
that has a slight gain over qfg. Nevertheless, the power
of qtfg over qfg is demonstrated by the results on the
set of unseen queries (set-C): for this set, even though the
overall performance of qtfg drops slightly it still remains
very high (94.38%), while the qfg could not provide any
recommendation at all.

5.3 Automatic Evaluation

5.3.1 Motivation

While manual evaluation provides a good quality assess-
ment for query recommendation systems, it has several lim-

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India52itations. First, the task is hard to deﬁne—which recommen-
dations should be considered as valid related queries. This
diﬃculty is reﬂected in the mediocre Kappa value achieved
for the inner annotator agreement. Furthermore, the two an-
notators reported that though almost all recommendations
seem “related”, some seem more useful than others, a quality
that is hard to measure.

A second limitation of the manual evaluation is that the
amount of examples that are analyzed manually typically
sums up to no more than several hundred examples [3, 8,
10, 30], which may not be statistically indicative (compared
to query-log sizes). Finally, manual evaluation is a slow
process, which poses a real problem when several rounds
of evaluation are needed during the development of a new
system or algorithm.

A diﬀerent approach is to directly evaluate a tested rec-
ommendation method in a search engine via bucket test-
ing. Yet, this is not a feasible option for the majority of
researchers in the ﬁeld.

5.3.2 Methodology

To overcome the limitations of the current evaluation ap-
proaches, we propose a novel automatic evaluation based on
a previously unseen query log. This query log is partitioned
into sessions and from each session the list of consecutive
query pairs are extracted. Our assumption is that if a user
entered two queries, {qi, qi+1}, one after the other in the
same session, then the second query may be viewed as a
valid related query for the ﬁrst query. Furthermore, we as-
sume that since a user explicitly entered qi+1 as related to
qi, qi+1 should be considered more related to qi compared
to other possible related queries. Thus, a recommendation
system should also provide qi+1 as a recommendation to qi,
and rank it high. These seem reasonable assumptions, as
they are also behind recommendation methods that learn
from query logs, such as the query-ﬂow graph.
Our proposed automatic evaluation is to test how many
of the pairs {qi, qi+1}, extracted from the new query log,
are also proposed by the tested recommendation system.
Furthermore, these recommendations should be ranked high.
This evaluation setup has the advantage of being fast, as
it is automatic. In addition, it may be applied to a large
number of pairs (several millions in our experiment bellow).
Finally, there are no agreement issues between annotators,
since any related query generated by real users is taken as a
valid example – as the gold standard.

We note that this evaluation ignores other recommenda-
tions for a given query by the tested system, which may also
be valid. Thus, the absolute quality of recommendations is
not directly assessed. Yet, the proposed evaluation is very
useful as a relative comparison between diﬀerent recommen-
dation systems, since when testing on a large volume of rec-
ommendations that were useful for users, each system should
propose (and rank high) a reasonable amount of them. This
evaluation measures how well a recommendation system an-
swers the need for related queries as explicitly formulated
by a large number of real users.

5.3.3 Experimental Setup

We extracted pair occurrences from the sampled sessions
in our test-query-log (see Section 5.1). We experimented
with two versions of this test-set. In the ﬁrst version, de-
noted all-pairs, all pairs of consecutive queries were extracted

from each session, summing up to 3,134,388 pairs. In the sec-
ond version, denoted ﬁrst-last, we generated just one pair
from each session, which consists of the ﬁrst and the last
query in the session. In this setup, which contains 4,591,044
pair occurrences, we assume that the last query in a session
is the real target query of the user, and we test if the systems
can propose it given the ﬁrst query in the session.

To conﬁrm that these gold-standard pairs indeed describe
related queries, 100 pairs were sampled from the ﬁrst-last
dataset and were blindly evaluated by two of the authors
together with the 800 examples judged in Section 5.2 (900
in total). The accuracy achieved for this sample is 100%,
that is all pairs are related queries. This result further sup-
ports our choice of user generated pairs as a valid test-set
for related query recommendation.

We measured the following ﬁgures over the performance

of each tested conﬁguration:

• How many of the tested pairs could be proposed by

the system (upper-bound coverage).

• How many pairs were ranked in the top 100 recom-

mendations of the system.

• How many pairs were ranked in the top 10 recommen-
dations of the system (the typical list visible for users).

• How many pairs were ranked highest (ﬁrst place).
• Mean Average Precision (MAP) of the test-pairs, view-
ing no more than 100 recommendations per query (if
the pair is not in the top 100, its precision is 0).

• Average position (rank) of test-pairs, only for those

that appear in the top 100 recommendations.

Some of the pairs occur in our dataset more than once.
We thus report the above ﬁgures both for pair occurrences
and for unique pairs (considering each pair only once).

While our initial target for using the query-template ﬂow
graph was to address the long tail of infrequent queries
and unseen queries, we also noticed that the query-template
ﬂow graph helps to better rank recommendations in general.
Thus, in addition to the qfg and qtfg conﬁgurations we ex-
perimented, on the ﬁrst-last data-set, with a conﬁguration of
query-template ﬂow graph restricted only for re-ranking rec-
ommendations by query-ﬂow graph, denoted qtfg-rerank.

5.3.4 Results

Tables 3 and 4 present the results for the all-pairs and
ﬁrst-last test-sets. The ﬁrst result seen from the tables is
that by utilizing our current implementation of the query-
template ﬂow graph the coverage of the test-pairs increases
relatively by 22-24% (depending on the test-set).
If only
unique pairs are considered, the increase is even more sub-
stantial, by about 45% for both test-sets. This shows that
the query-template ﬂow graph signiﬁcantly increases the
coverage for the long tail of infrequent or unseen queries. For
example, for the input query “1956 dodge lancer”, qtfg
ranked ﬁrst the test-pair {“1956 dodge lancer”, “1956 dodge
lancer for sale”} using rules such as ‘1956 <car> → 1956
<car> for sale’, while qfg could not suggest any related
query for “1956 dodge lancer”. Other examples are pre-
sented in Table 5.

When focusing on the top-10 recommendations per query,
the diﬀerence in test-pair coverage is widening. This result

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India53Table 3: Results on the all-pairs data-set for each conﬁguration

pair occurrences
qfg

qtfg

relative increase

total in test-set
upper-bound coverage
# in top-100
# in top-10
# ranked highest
MAP
avg. position

3134388
(22.65%) 709832
(16.97%) 531854
(9.49%) 297462
(2.86%)
89740
0.050
18.35

3134388
(28.17%) 882851
(25.49%) 799001
(20.74%) 649939
(10.01%) 313638
0.137
8.3

unique pairs

24.37%
50.23%
118.49%
249.5%

qfg

qtfg

relative increase

total in test-set
upper-bound coverage
# in top-100
# in top-10
# ranked highest
MAP
avg. position

2755922
(13.28%) 366047
(12.06%) 332487
(8.41%) 231811
78783
(2.86%)
0.047
12.33

2755922
(19.38%) 533960
(17.25%) 475323
(13.52%) 372481
(6.5%) 179093
0.089
9.43

45.87%
42.96%
60.68%
127.32%

Table 4: Results on the ﬁrst-last data-set for each conﬁguration

pair occurrences

qfg

qtfg-rerank

qtfg

total in test-set
upper-bound coverage
# in top-100
# in top-10
# ranked highest
MAP
avg. position

4591044
(27.63%) 1268579
(18.78%) 862232
(10.22%) 469165
(3.21%) 147501
0.055
19.36

qfg

4591044
(27.63%) 1268579
(24.79%) 1137920
(19.37%) 889383
(9.32%) 427828
0.128
9.52

unique pairs

qtfg-rerank

4591044
(33.85%) 1554282
(28.59%) 1312408
(21.53%) 988568
(10.11%) 464260
0.140
10.75

relative increase

qtfg vs. qfg

22.52%
52.21%
110.71%
214.75%

qtfg

relative increase

qtfg vs. qfg

total in test-set
upper-bound coverage
# in top-100
# in top-10
# ranked highest
MAP
avg. position

3856355
(15.51%) 598114
(13.7%) 528333
(9.23%) 355843
(3.33%) 128267
0.052
13.48

3856355
(15.51%) 598114
(14.48%) 558255
(11.63%) 448383
(6.01%) 231797
0.079
8.63

3856355
(22.62%) 872377
(18.86%) 727220
(14.13%) 545062
(6.92%) 266862
0.094
10.97

45.85%
37.64%
53.17%
108.05%

is also reﬂected by the higher MAP values when utilizing
query-template ﬂow graph. The diﬀerence is at its most
when looking at the highest ranked recommendation, where
the number of user-generated related queries that are ranked
ﬁrst is twice as much for unique queries and more than thrice
as much for pair occurrences. This surprising result indi-
cates that query-template ﬂow graph not only provides rec-
ommendations for unseen or rare queries, but it also helps
to better rank recommendations that are proposed by the
query-ﬂow graph. For example, qtfg ranked ﬁrst the test-
pair {“gangrene”, “gangrene symptoms”} using rules such as
‘<pathology> → <pathology> symptoms’, while qfg ranked
it at 23rd place.

The surprising result that the query-template ﬂow graph
helps to better rank the query-ﬂow graph recommendations
is also expressed by the performance of the qtfg-rerank
conﬁguration, where a signiﬁcant improvement in perfor-
mance is achieved just by re-ranking the query-ﬂow graph
output by the query-template ﬂow graph. This is further
emphasized by looking at the average position of recom-
mendations in the top-100. While qtfg recommendations
are better positioned on average than qfg, qtfg-rerank
achieves the best average positions for user-generated re-

lated queries. The reason for lower positions in qtfg than
in qtfg-rerank is due to additional unseen queries for
which only qtfg could provide recommendations. For these
queries the average position is lower than for the seen ones,
as expected, and hence the lower overall average position.

5.3.5 Analysis

To further understand the behavior of the query-template
ﬂow graph vs. the query-ﬂow graph, we conducted several
analyses on the results of the ﬁrst-last test-set. We ﬁrst
looked at the potential of the query-template ﬂow graph
to extend the query-ﬂow graph for nodes in the query-ﬂow
graph that have no outgoing edges. The queries in these
nodes were seen before (in the development query log, from
which the query-ﬂow graph was constructed), but no related
queries were observed for them (they were only observed as
related queries for other queries). There are 33,883,564 such
queries (36% of the nodes), and the query-template ﬂow
graph managed to propose at least one related query for
98% of them. This further emphasizes the potential beneﬁt
of the query-template ﬂow graph for previously unseen query
relations.

Next, we analyzed the change in test-pairs ranking when

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India54Table 5: Examples of test-pairs that were ranked high by qtfg while qfg could not propose any related query
for the input query, showing the large verity of rules that were learned by our approach.
Example rule used

Rank

Pair

{“8 week old weimaraner”, “8 week old weimaraner puppy”}
{“a thousand miles notes”, “a thousand miles piano notes”}
{“aaa office twin falls idaho”, “aaa twin falls idaho”}

{“1910 swimsuit”, “1910 swimsuit mens”}

{“air force titles”, “air force ranks”}
{“beach cameras”, “live beach cameras”}
{“guangzhou flights”, “guangzhou map”}

{“i am legend action figure”, “i am legend”}
{“name for salt”, “chemical name for salt”}

8 week old <breed> → 8 week old <breed> puppy

1910 <clothing> → 1910 <clothing> mens
<single> notes → <single> piano notes

aaa office <city> → aaa <city>

<military service> titles → <military service> ranks
<geo formation> cameras → live <geo formation> cameras

<capital> flights → <capital> map
<fiction> action figure → <fiction>

name for <compound> → chemical name for <compound>

1
1
2
1
2
1
6
2
2

Table 6: Ranking diﬀerences of suggestions for the ﬁrst-last test-set

qfg

qtfg

total in test-set
# in top-100
# in top-100 but not in the top-100 of the other
# in top-10 but not in the top-10 of the other
# better positioned when both in top-100

2755922
528333
7486
16211
71170

2755922
727220
(28.38%) 206373
(28.25%) 205430
(35.05%) 254919

(1.42%)
(3.07%)
(13.47%)

)

%

(
 
0
1
-
p
o
t
 
t
a
 
s
r
i
a
p
-
t
s
e
t
 
#

 20
 18
 16
 14
 12
 10
 8
 6
 4
 2
 0

QFG
QTFG

 2

 4

 6

 8

 10

 12

 14

 16

query length (words)

)

%

(
 
0
1
-
p
o
t
 
t
a
 
s
r
i
a
p
-
t
s
e
t
 
#

 35

 30

 25

 20

 15

 10

 5

 0

QFG
QTFG

 10

 20
query frequency

 30

 40

 50

Figure 1: ﬁrst-last pair coverage at top-10 sugges-
tions vs. query length

Figure 2: ﬁrst-last pair coverage at top-10 sugges-
tions vs. query frequency

the input query length (in words) varies. From the graph
presented in Figure 1, we see that the query-ﬂow graph
shows a typical decline in performance for longer queries,
as these are less frequent and thus have less history to rely
on. However, things are diﬀerent when using the query-
template ﬂow graph. It actually performs better when the
input queries have a few additional words, since they act
as a disambiguating context for ranking appropriate recom-
mendations (see Section 4.5).

In our third analysis, presented in Figure 2, we looked
at the change in test-pairs ranking quality when the input
query frequency varies. The plot in Figure 2 shows that
both conﬁgurations ﬁnd it hard to suggest test-pairs as rec-
ommendations for queries that occur only once in the test
set. This behavior agrees with the manual evaluation, which
showed lower suggestion quality for unseen queries. There is
a substantial increase in performance for queries that occur
twice and then a decline as the frequency increases, since
frequent queries have a more diverse history and its hard
to predict the best suggestions from this history. Yet, we

see that the query-template ﬂow graph consistently outper-
forms the query-ﬂow graph, managing to pick more appro-
priate suggestions for frequent queries. For example, for the
query “jack johnson lyrics”, which occurred 14 times in
the test-set, qtfg ranked the pair {“jack johnson lyrics”,
“jack johnson music”} 5th, while qfg ranked it 43rd.

Finally, we analyzed the diﬀerences in ranks of the same
suggestions by the query-ﬂow graph and the query-template
ﬂow graph. This analysis, presented in Table 6, shows that
many test-pairs that either cannot be processed by the query-
ﬂow graph or are ranked very low, are positioned in the top-
10 recommendations in the query-template ﬂow graph. This
indicates that the query-template ﬂow graph handles well
recommendations that cannot be processed by the query-
ﬂow graph. Furthermore, only very few pairs (3%) are ranked
signiﬁcantly higher by the query-ﬂow graph than by the
query-template ﬂow graph (in the top-10), which means that
the query-template ﬂow graph hardly hurts the ranking of
well ranked recommendations by the query-ﬂow graph. This
is despite the fact that about 13% of the test-pairs are ranked

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India55higher by the query-ﬂow graph than by the query-template
ﬂow graph. These improvements are not signiﬁcant, as they
are mainly at the lower part of the top-100 ranks and are
usually not displayed to users.

To conclude, the analysis shows that utilizing the query-
template ﬂow graph on top of the query-ﬂow graph improves
consistently the ranking of user-generated related queries,
without any signiﬁcant loss in performance for a speciﬁc
type of queries.

6. CONCLUSIONS

We introduced the concepts of rules between query tem-
plates and the query-template ﬂow graph as an abstraction
and a generalization approach for relations between queries.
This novel approach is useful for addressing the long tail of
rare or previously unseen queries in various search-related
tasks. Yet, it is also helpful in discovering important rela-
tions between frequent queries, for example for better rank-
ing possible suggestions in query recommendation.

We conducted two query-recommendation experiments,
a manual evaluation and a novel large-scale automated eval-
uation. The manual evaluation showed that both the query-
template ﬂow graph and the baseline query-ﬂow graph are
very adequate as methods for query recommendations. Yet,
our automatic evaluation over millions of query-recommen-
dation pairs showed that the query-template ﬂow graph con-
sistently outperforms the query-ﬂow graph by ranking higher
recommendations that were explicitly chosen by users. More
importantly, the query-template ﬂow graph provides good
suggestions for many unseen queries, for which the query-
ﬂow graph could not provide any suggestion.

In future work, we plan to apply the query-template ﬂow
graph on other search-related tasks and to further explore its
structure and behavior. In addition, we want to improve the
quality of rule extraction. Finally, we would like to inves-
tigate the identiﬁcation of edges from templates to queries,
which capture relations such as between diﬀerent towns in
a district and the single airport that serves them.

7. REFERENCES
[1] G. Agarwal, G. Kabra, and K. C.-C. Chang. Towards
rich query interpretation: Walking back and forth for
mining query templates. In WWW, 2010.

[2] I. Antonellis, H. Garcia-Molina, and C.-C. Chang.

Simrank++: Query rewriting through link analysis of
the click graph. In VLDB, 2008.

[3] R. A. Baeza-Yates, C. A. Hurtado, and M. Mendoza.

Query recommendation using query logs in search
engines. In EDBT Workshops, 2004.

[4] D. Beeferman and A. Berger. Agglomerative clustering

of a search engine query log. In KDD, 2000.

[5] P. Boldi, F. Bonchi, C. Castillo, D. Donato, A. Gionis,

and S. Vigna. The query-ﬂow graph: model and
applications. In CIKM, 2008.

[6] D. Chiang. A hierarchical phrase-based model for

statistical machine translation. In ACL, 2005.

[7] J. Cohen. A coeﬃcient of agreement for nominal

scales. Educational and Psychological Measurement,
20(1):37–46, April 1960.

[8] N. Craswell and M. Szummer. Random walks on the

click graph. In SIGIR, 2007.

[9] M. Fern´andez-Fern´andez and D. Gayo-Avello.

Hierarchical taxonomy extraction by mining topical
query sessions. In KDIR, 2009.

[10] B. M. Fonseca, P. B. Golgher, E. S. de Moura, and

N. Ziviani. Using association rules to discover search
engines related queries. In LA-WEB, 2003.

[11] A. Fuxman, P. Tsaparas, K. Achan, and R. Agrawal.

Using the wisdom of the crowds for keyword
generation. In WWW, 2008.

[12] S. Goel, A. Broder, E. Gabrilovich, and B. Pang.

Anatomy of the long tail: ordinary people with
extraordinary tastes. In WSDM, 2010.

[13] J. Guo, G. Xu, X. Cheng, and H. Li. Named entity

recognition in query. In SIGIR, 2009.

[14] R. Jones, B. Rey, O. Madani, and W. Greiner.

Generating query substitutions. In WWW, 2006.

[15] J. R. Landis and G. G. Koch. The measurement of

observer agreement for categorical data. Biometrics,
33(1), 1977.

[16] X. Li, Y.-Y. Wang, and A. Acero. Extracting
structured information from user queries with
semi-supervised conditional random ﬁelds. In SIGIR,
2009.

[17] D. Lin and P. Pantel. Discovery of inference rules for

question answering. Natural Language Engineering,
7(4):343–360, 2001.

[18] J. Luxenburger, S. Elbassuoni, and G. Weikum.

Matching task proﬁles and user needs in personalized
web search. In CIKM, 2008.

[19] Q. Mei, D. Zhou, and K. Church. Query suggestion

using hitting time. In CIKM, 2008.

[20] G. A. Miller. Wordnet: A lexical database for english.

In Communications of the ACM, 1995.

[21] M. Pa¸sca. Weakly-supervised discovery of named
entities using web search queries. In CIKM, 2007.
[22] M. Richardson. Learning about the world through

long-term query logs. ACM Transactions on the Web,
2008.

[23] E. Sadikov, J. Madhavan, L. Wang, and A. Halevy.

Clustering query reﬁnements by user intent. In
WWW, 2010.

[24] R. Snow, D. Jurafsky, and A. Y. Ng. Learning

syntactic patterns for automatic hypernym discovery.
In NIPS, 2005.

[25] F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: A

core of semantic knowledge - unifying wordnet and
wikipedia. In WWW, 2007.

[26] I. Szpektor and I. Dagan. Learning entailment rules

for unary templates. In COLING, 2008.

[27] J.-R. Wen, J.-Y. Nie, and H.-J. Zhang. Clustering user

queries of a search engine. In WWW, 2001.

[28] R. W. White, M. Bilenko, and S. Cucerzan. Studying
the use of popular destinations to enhance web search
interaction. In SIGIR, 2007.

[29] R. W. White, M. Bilenko, and S. Cucerzan.

Leveraging popular destinations to enhance web
search interaction. ACM Transactions on the Web,
2(3), 2008.

[30] Z. Zhang and O. Nasraoui. Mining search engine

query logs for query recommendation. In WWW, 2006.

WWW 2011 – Session: RecommendationMarch 28–April 1, 2011, Hyderabad, India56