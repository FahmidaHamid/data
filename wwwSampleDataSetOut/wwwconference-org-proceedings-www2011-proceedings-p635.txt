EP-SPARQL: A Uniﬁed Language for Event Processing and

Stream Reasoning

Darko Anicic

FZI Research Center for
Information Technology

Karlsruhe, Germany
darko.anicic@fzi.de

Paul Fodor

Stony Brook University
Stony Brook, NY, U.S.A

pfodor@cs.sunysb.edu

Sebastian Rudolph
Karlsruhe Institute of

Technology

Karlsruhe, Germany
rudolph@kit.edu

Nenad Stojanovic
FZI Research Center for
Information Technology

Karlsruhe, Germany

nenad.stojanovic@fzi.de

ABSTRACT
Streams of events appear increasingly today in various Web
applications such as blogs, feeds, sensor data streams, geospa-
tial information, on-line ﬁnancial data, etc. Event Process-
ing (EP) is concerned with timely detection of compound
events within streams of simple events. State-of-the-art EP
provides on-the-ﬂy analysis of event streams, but cannot
combine streams with background knowledge and cannot per-
form reasoning tasks. On the other hand, semantic tools can
eﬀectively handle background knowledge and perform rea-
soning thereon, but cannot deal with rapidly changing data
provided by event streams.

To bridge the gap, we propose Event Processing SPARQL
(EP-SPARQL) as a new language for complex events and
Stream Reasoning. We provide syntax and formal semantics
of the language and devise an eﬀective execution model for
the proposed formalism. The execution model is grounded
on logic programming, and features eﬀective event process-
ing and inferencing capabilities over temporal and static
knowledge. We provide an open-source prototype imple-
mentation and present a set of tests to show the usefulness
and eﬀectiveness of our approach.

Categories and Subject Descriptors
H.2.4 [Database Management]: Rule-Based Databases;
D.1.6 [Logic Programming]:

General Terms
Languages, Algorithms
Keywords
ETALIS, Complex Event Processing, Semantic Web, Rule
Systems, Streams

1.

INTRODUCTION

In the recent decade, information representation on the
Web has undergone a shift from static or quasi-static to

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2011, March 28–April 1, 2011, Hyderabad, India.
ACM 978-1-4503-0632-4/11/03.

dynamic. The average size of singular information items
has become smaller (compare, e.g. blogs with tweets) and
their mutual temporal relatedness gained in importance. In
many domains the view on information has changed from a
bag-of-knowledge to a stream-like, event-based perspective.
In general, an event is something that occurs, happens or
changes the current state of aﬀairs. For example, an event
can be a tweet, geospatial data sent by a GPS-enabled de-
vice, a newly updated status of a Web 2.0 application user
or the status of an object there. In order to describe more
complex dynamic matters that involve several events, for-
malisms have been created which allow for combining (sim-
pler) events into compound ones, so-called complex events,
using diﬀerent event operators and temporal relationships.
The ﬁeld of Event Processing1 (EP) has the task of real-
time processing streams of events with the goal of detecting
complex events, according to meaningful event patterns.

Current EP systems are based on database stream tech-
nologies [1, 6, 8]. They provide on-the-ﬂy analysis of data
streams enabling real-time decisions and actions, but fall
short of combining streams with higher-level knowledge rep-
resentation and reasoning necessary for handling background
knowledge describing the context or domain in which stream-
ing data are interpreted. After all, both semantic as well as
temporal relationships are needed for an appropriate descrip-
tion of complex events. On the other hand, standard Seman-
tic Web technologies allow for handling background knowl-
edge in the form of ontologies representing time-invariant or
slowly evolving knowledge. However, the task of conjunc-
tively reasoning over streaming data and background knowl-
edge constitutes a new challenge known as Stream Reasoning
[10].

The goal of this work is to provide a fundamental frame-
work for Event Processing and Stream Reasoning exceeding
the state-of-the-art in both EP and Semantic Web. We be-
lieve that such a framework is needed in order to address
dynamic aspects in streaming knowledge, and move toward
the Real-time Semantic Web. Our contribution involves:

• EP-SPARQL: A language for Event Process-
ing and Stream Reasoning. We provide the syntax

1Also known as Complex Event Processing (CEP).

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India635and a formal semantics of a new language called Event
Processing SPARQL (EP-SPARQL). The language ex-
tends the SPARQL language with its event processing
and stream reasoning capabilities;

• A logic-based account for Event Processing and
Stream Reasoning. We provide the basic mech-
anism for Event Processing and Stream Reasoning,
grounded in Logic Programming. EP-SPARQL is a
high-level language based on this mechanism. Our
approach is based on event-driven backward chaining
rules that realize an eﬀective event-driven inferencing.
It features both eﬀective event processing, and infer-
ence capabilities over temporal and static knowledge.
We are aware of no approach that implements both
features in one clean, logic framework;

• Implementation and evaluation. We provide an
open-source prototype implementation of the proposed
approach. The prototype is implemented in Prolog
language (and could be realized in other declarative
rule languages, too). We have conducted a set of tests
to show the usefulness and eﬀectiveness of our ap-
proach with respect to expressivity and run-time per-
formance.

2. RELATED WORK

The work related to ours mainly ﬁts into three areas:
Streaming Database systems [1, 16, 8, 9], temporal RDF
models [12, 17, 20], and Stream Reasoning approaches [4,
5, 21, 7].

Streaming Databases. Database approaches [1, 16,
8, 9] are based on languages with SQL-like syntaxes, and
database execution models adapted to process streaming
data. These approaches are dominant today due to their
capability to handle large volumes of streaming data with
low latency. As such database approaches are widely used in
automated stock trading, logistic services, transaction man-
agement, business intelligence etc. However, they are not
well suited for applications including Web structured data,
ontologies, and other forms of knowledge bases (e.g., Linked
Open Data) where support for semantic-based event pro-
cessing and reasoning is required. We also showed on two
examples (Esper and TelegraphCQ, which are systems that
belong to this category of related work) that these systems
do not necessarily perform better than our approach based
on logic programming techniques.

Temporal RDF. The work in [12] introduces time as
a new dimension in RDF graphs. The authors provide a
semantics for temporal RDF graphs and a temporal query
language for RDF, following concepts of temporal databases.
They are concerned with evolution of RDF graphs through
time, and provide a framework for temporal entailment and
querying over changing graphs.

Our work diﬀers from this approach in that our aim is to
detect temporal complex patterns in (near) real time rather
than just once posing a query and getting a singular re-
sponse. We want to detect situations of interest continuously
as soon as they happen. Hence patterns need to be contin-
uously evaluated in order to process occurrences of relevant
triples, and further to recognize complex events.

SPARQL-ST [17] is an extension of SPARQL for com-
plex spatial and temporal queries. The language and a cor-
responding implementation deal with temporal data (and

possible reasoning about that data). However as in [12],
SPARQL-ST queries need to be triggered rather than being
continuously active. The same argumentation also applies
to other SPARQL approaches like Temporal SPARQL [20],
stSPARQL [14], and T-SPARQL [11].

The work in [19] motivates the need for a semantic man-
agement of streaming data. Streaming data are represented
in RDF format with the purpose of its exploitation in seman-
tic-web applications (semantically annotated data and rea-
soning services). For this purpose, they propose a Time-An-
notated RDF model and Time-Annotated SPARQL. How-
ever the authors explicitly mention that continuous queries,
as one typical requirement of streaming data management
systems, are not considered in that work.

Stream Reasoning. Continuous SPARQL (C-SPARQL)
[5] is a language for continuous query processing and Stream
Reasoning. It extends the SPARQL language by adding sup-
port for window and aggregation operations. In C-SPARQL,
the set of currently valid RDF statements is determined
based on a query (including its window speciﬁcation), and
classical reasoning on that RDF set is performed as if it were
static.
In our work, we focus more on detection of RDF
triples in a speciﬁc temporal order (e.g., sequence versus
conjunction). We strongly believe that additionally tempo-
ral relatedness between events (e.g., within the sliding win-
dow, an event happened before another event) as deﬁned in
streaming database systems [1, 8, 9] is required to capture
more complex patterns over RDF streaming data. Addi-
tionally, in C-SPARQL queries are divided into static and
dynamic parts. The static part is evaluated by a RDF triple
storage, while a stream processing engine evaluates the dy-
namic part of the query. In such settings, these two parts
act as “black boxes” and C-SPARQL cannot take advantage
of a query pre-processing and optimizations over the uniﬁed
(static and dynamic) data space. We propose an approach
based on logic rules where the both parts are handled in a
uniform framework.

Streaming Knowledge Bases [21] is a reasoner dealing with
streaming RDF triples and computation of RDFS closures
with respect to an ontology. For instance, the reasoner can
identify a triple from a stream having a subject that is an
instance of a certain class (or any of its subclasses, deﬁned
in an ontology). The approach is based on TelegraphCQ [8]
that is an eﬃcient data stream system. In order to speed
up stream reasoning, the authors propose to pre-compute
all inferences in advance, and to store them in a database.
Although this is an interesting approach, we believe that
stream reasoning demands both: on-the ﬂy-inference capa-
bilities, and scalability.

The work in [7] introduces Streaming SPARQL. The ap-
proach is built on temporal relational algebra, and the au-
thors provide an algorithm to transform SPARQL queries
to that algebra. Similarly as in [5], the approach does not
detect sequences of RDF triples occurring in a speciﬁc order.
The same holds for [4] where the authors propose stream
reasoning based on incremental maintenance of materializa-
tions. Streaming RDF triples (as they occur) trigger an
inference procedure that maintains materializations. Al-
though promising, it is not clear how this approach works
for multiple queries with diﬀerent time window deﬁnitions
(in [4], materializations are assumed to be maintained only
for one query).

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India6363. PROBLEM STATEMENT

We argue – and the above review of current approaches in
the literature clearly witnesses this – that Event Processing
and Stream Reasoning in the Semantic Web as two research
disciplines may contribute to and complement each other,
and hence open new possibilities in direction of the Real-
time Semantic Web. These areas served as design principles
we followed when proposing EP-SPARQL.

We see the following dimensions where current Stream
Reasoning research can greatly beneﬁt from Event Process-
ing (EP):
Support for Rapidly Changing Information on the
Web. While existing semantic technologies and reasoning
engines are constantly being improved in dealing with time
invariant domain knowledge, they lack in support for pro-
cessing real-time streaming data (events). Real-time Web
data is valuable only if it is captured, processed, and de-
livered instantly. EP is a set of techniques and tools that
help us understand and control real-time and event-driven
systems [15]. As such, it is a technology that can help in
processing real-time data on the Web, too.
Information Push versus Pull. According to Wikipedia,
the Real-Time Web is a set of technologies and practices
which enable users to receive information as soon as it is
published by its authors, rather than requiring periodic up-
dates. Hence, there is no need to pull information, it will
be delivered to users nearly at the moment it is published.
For instance, no more waiting for web services to commu-
nicate from one polling instance to another. We notice a
paradigm shift from information pull to information push;
or from request-response based web services to event-driven
web services with possibly unforeseen consequences.

On the other hand, Semantic Web technologies clearly

surpass current EP approaches in the following aspects:
Structured Events. Various sensors, gps-enabled devices
and the Internet of Things are all sources of events that
can easily be structured. Today event stream systems do
not use ontologies to specify common-agreed vocabularies
for events and event-driven applications. An important con-
tribution of the Semantic Web to EP is to provide structured
events. This will enable not only knowledge-based EP with
Stream Reasoning capabilities, but also easier communica-
tion between event-driven applications and services, as well
as, simpler integration of heterogeneous data streams and
their interpretation on the Web.
Stream Reasoning in Knowledge-based EP. As men-
tioned above, current EP systems [1, 6, 8] do real-time pat-
tern matching over unbound event streams. But they can-
not combine data streams with evolving knowledge, and they
cannot perform reasoning tasks over streaming data. Se-
mantic technologies can enhance today’s EP by providing
and evaluating domain knowledge (e.g., in order to enrich
recorded events, to detect more complex situations of inter-
est, to propose certain intelligent recommendations on-the-
ﬂy etc.).

Consequently, the problem addressed in this paper com-
bines tasks of Event Processing and Stream Reasoning. That
is, we propose an approach to detect complex events (spec-
iﬁed in an appropriate formal language) within a stream of
RDF triples (atomic events). Detection of complex events
may additionally require reasoning over background knowl-
edge (expressed as an RDF graph or an RDFS ontology).
We assume that the timeliness of this detection is crucial

and algorithmically optimize our method towards a contin-
uous evaluation of patterns and a fast response behavior.

4. EP-SPARQL
4.1 Syntax

In this section, we introduce the syntax of EP-SPARQL,
our extension of the SPARQL querying language in order to
enable stream-based querying that takes into account tem-
poral situatedness of triple assertions. Thereby, we ensure
syntactical and semantic downward-compatibility to plain
SPARQL in the sense detailed below. We assume the reader
to be familiar with RDF and SPARQL; For a thorough in-
troduction to these formalisms see, e.g. [13].

Syntactically, we deﬁne EP-SPARQL to be SPARQL ex-
tended by the binary operators seq, equals, optionalseq,
and equalsoptional used to combine graph patterns in
the same way as union and optional in pure SPARQL.
Intuitively, all those operators act like a (left, right or full)
join, but they do so in a selective way depending on how
the constituents are temporally interrelated, as indicated
by their naming: P1 seq P2 joins P1 and P2 only if P2 oc-
curs2 strictly after P1, whereas P1 equals P2 performs the
join if P1 and P2 are exactly simultaneous. optionalseq
and equalsoptional are temporal-sensitive variants of op-
tional.

Moreover, we add the function getDURATION() to be used
inside ﬁlter expressions. This function yields a literal of type
xsd:duration giving the length of the time interval associ-
ated to the graph pattern the filter condition is placed in.
Likewise, we add functions getSTARTTIME() and getEND-
TIME() to retrieve the time stamps (of type xsd:dateTime)
of the start and end of the currently described interval.

We provide a few examples to give some intuition on the
newly introduced operators. The following EP-SPARQL
query is supposed to search for companies whose stock price
has decreased by over 30% and subsequently risen by more
than 5% within a time frame of 30 days.

SELECT ?company WHERE

{ ?company hasStockPrice ?price1 }
SEQ { ?company hasStockPrice ?price2 }
SEQ { ?company hasStockPrice ?price3 }

FILTER ( ?price2 < ?price1 * 0.7 && ?price3 > ?price1 * 1.05

&& getDURATION() < "P30D"^^xsd:duration)

(1)

The next EP-SPARQL query will identify companies with
a more than 50% stock price drop and – in case some rat-
ing agency previously downrated this company, this rating
agency will be indicated as well.

SELECT ?company ?ratingagency WHERE

?company downratedby ?ratingagency}

{
OPTIONALSEQ
{

(2)

{ ?company hasStockPrice ?price1 }

SEQ { ?company hasStockPrice ?price2 }}

FILTER (?price2 < ?price1 * 0.5)

It is worth mentioning that – just like for pure SPARQL
– negation (i.e., requiring the absence of some triple pat-
tern instead of its presence) is not an explicit part of the
formalism, but can be expressed via optional and filter.
For instance, the following query asks for companies hav-
ing a larger than 50% stock price increase in less than 15

2in a sense to be deﬁned more precisely in the formal se-
mantics

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India637days without having acquired another company during that
period.

SELECT ?company WHERE

{ ?company hasStockprice ?price1 }

SEQ { { ?company hasAcquired ?othercompany }

(3)

OPTIONALSEQ
{ ?company hasStockPrice ?price2 } }

FILTER ( ?price2 < ?price1 * 1.5 && !BOUND(?othercompany) &&

getDURATION() < "P15D"^^xsd:duration )

Moreover, we allow for recursion by employing construct
queries, conceiving them as a kind of production rule. There-
by, the result graph of such a query is assumed to be added
to the RDF stream. For instance, the following statement
gathers “temporally distributed” rating information to cre-
ate a triple indicating an event of being downrated, which
in turn can be used in other construct or select queries.

CONSTRUCT ?company downratedby ?ratingagency
WHERE

{ ?rating1 rater ?ratingagency ;

rated ?company ; score ?score1 }

SEQ { ?rating2 rater ?ratingagency ;

rated ?company ; score ?score2 }

FILTER ( ?score2 < ?score1 )

(4)

Finally, the forthcoming extended SPARQL standard3 fea-
turing subqueries and expressions allows for as complex mech-
anisms as aggregation over sliding windows. As an example
we present a query monitoring the average stock price of a
company ACME Inc. over the last 10 days. First, we use
a construct rule that aggregates counts and sums of stock
prices within the given time frame and feeds this informa-
tion back into the stream. Thereby, the equalsoptional
and ﬁlter part make sure that no price signal is left out.

CONSTRUCT _:aaa
{ SELECT ?count AS ?prevcount + 1

:hasCount ?count . _:aaa

WHERE

?sum
{{ ?point :hasCount ?prevcount .

AS ?prevsum + ?price

:hasSum

?sum .

?point :hasSum ?prevsum

. }

SEQ { :ACME :hasStockPrice ?price . }}

EQUALSOPTIONAL

{{ ?point :hasCount ?prevcount .

?point :hasSum ?prevsum

. }

SEQ { :ACME :hasStockPrice ?inbetween . }
SEQ { :ACME :hasStockPrice ?price . }}

FILTER ( !BOUND(?inbetween) &&

getDURATION() < "P10D"^^xsd:duration )}

(5)

Next, we calculate and output the average value as soon

as the duration of our time window is exceeded.

SELECT ?sum / ?count AS ?average
WHERE {{ :ACME :hasStockPrice ?price . }

SEQ { ?point :hasCount

?prevcount .

?point :hasSum ?prevsum . }}

EQUALSOPTIONAL

{{ :ACME :hasStockPrice ?price . }

SEQ { :ACME :hasStockPrice ?inbetween . }
SEQ { ?point :hasCount

?prevcount .

?point :hasSum ?prevsum . }}

FILTER ( !BOUND(?inbetween) &&

getDURATION() > "P10D"^^xsd:duration )

(6)

It may take some consideration and checking back with
the formal semantics to verify that this realizes the intended
behavior. In practice, additional constructs may be intro-
duced as syntactic sugar to facilitate speciﬁcation of patterns
that are often used.

3http://www.w3.org/TR/2009/WD-sparql-features-
20090702/

4.2 Formal Semantics

We deﬁne the formal semantics for EP-SPARQL along the
same lines as it is done for pure SPARQL [18], that is, in a
relational way. Thereby, the query is ﬁrst translated into an
algebraic expression. Recall that this conversion transforms
simple graph patterns4 (lists of triples) P into expressions of
the form BGP (P ). Moreover, juxtapositions of graph triples
are translated into the function Join, union into Union,
optional into LeftJoin. We reuse but extend this transla-
tion to map the new operators as follows: seq (cid:55)→ SeqJoin,
equals (cid:55)→ EqJoin, optionalseq (cid:55)→ SeqRightJoin, and
equalsoptional (cid:55)→ EqLeftJoin. Each of these functions
is meant to return the result of the subquery it describes,
which is a formal representation of the corresponding result
table – as opposed to plain SPARQL, each row of these inter-
mediary result tables is additionally associated with a time
interval.

To make this more formal, note that we pose our query
against an RDF stream which we deﬁne as a set S con-
sisting of triple occurrences being pairs (cid:104)(cid:104)s, p, o(cid:105), t, t(cid:48)(cid:105) where
(cid:104)s, p, o(cid:105) is an RDF triple and t, t(cid:48) are time stamps denoting
the boundaries of the time interval of the occurrence. Now,
we say that the tuple (cid:104)µ, tα, tω(cid:105) is a solution for an expres-
sion of the form “BGP( list of triples )” exactly if the
following conditions are satisﬁed:

1. µ is a partial function the domain of which consists
exactly of the variables that occur in the given list of
triples.

2. for the triple set {(cid:104)s1, p1, o1(cid:105), . . . ,(cid:104)sn, pn, on(cid:105)} obtained
from substituting the variables in the triple list via µ,
there exist time stamps t1, t(cid:48)

1, . . . , tn, t(cid:48)

n such that

1(cid:105), . . .(cid:104)(cid:104)sn, pn, on(cid:105), tn, t(cid:48)

n(cid:105)} ⊆ S,

• {(cid:104)(cid:104)s1, p1, o1(cid:105), t1, t(cid:48)
• tα = min(t1, . . . , tn), and
• tω = max(t(cid:48)

1, . . . , t(cid:48)

n).

α, t(cid:48)

Now deﬁne results for the other operators. A pair of so-
ω(cid:105) is said to be compatible
lutions (cid:104)µ, tα, tω(cid:105) and (cid:104)µ(cid:48), t(cid:48)
if every variable that is mapped by both µ and µ(cid:48) is also
mapped to the same RDF term by both solutions. If this
is the case, their combination (cid:104)µ, tα, tω(cid:105) (cid:46)(cid:47) (cid:104)µ(cid:48), t(cid:48)
ω(cid:105) can
be deﬁned as the tuple (cid:104)µ(cid:48)(cid:48), t(cid:48)(cid:48)
α),
t(cid:48)(cid:48)
ω = max(tω, t(cid:48)

α = min(tα, t(cid:48)

ω(cid:105) with t(cid:48)(cid:48)

ω), and

α, t(cid:48)(cid:48)

α, t(cid:48)

 µ(x)

µ(cid:48)(x)

undeﬁned

(cid:48)(cid:48)

µ

(x) =

if x occurs in the domain of µ
if x occurs in the domain of µ(cid:48)

in all other cases

Based on this, we deﬁne how to evaluate the introduced
functions on sets Ψ, Ψ(cid:48) of solutions. Thereby, we use σtαtω to
denote the operator substituting getDURATION() by tω − tα,
getSTARTTIME() by tα, and getENDTIME() by tω in ﬁlter
expressions.

• Filter (F, Ψ) contains those (cid:104)µ, tα, tω(cid:105) ∈ Ψ for which

• Join(Ψ, Ψ(cid:48)) contains (cid:104)µ, tα, tω(cid:105) (cid:46)(cid:47) (cid:104)µ(cid:48), t(cid:48)

the expression µ(σtαtω (F )) evaluates to true.
α, t(cid:48)
ω(cid:105) ∈ Ψ(cid:48)

compatible (cid:104)µ, tα, tω(cid:105) ∈ Ψ and (cid:104)µ(cid:48), t(cid:48)

α, t(cid:48)

ω(cid:105) for all

4For the sake of brevity, we assume that the graph patterns
do not contain blank nodes, as they can be replaced by (non-
distinguished) variables without changing the semantics.

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India638• Union(Ψ, Ψ(cid:48)) = Ψ ∪ Ψ(cid:48)
• LeftJoin(Ψ, Ψ(cid:48), F ) contains

α, t(cid:48)

– every (cid:104)µ, tα, tω(cid:105) (cid:46)(cid:47) (cid:104)µ(cid:48), t(cid:48)

ω(cid:105) for every compat-
ible (cid:104)µ, tα, tω(cid:105) ∈ Ψ and (cid:104)µ(cid:48), t(cid:48)
ω(cid:105) ∈ Ψ(cid:48) with
α, t(cid:48)
(µ (cid:46)(cid:47) µ(cid:48))(σtαtω (F )) = true and t(cid:48)
ω < tω.
– every (cid:104)µ, tα, tω(cid:105) ∈ Ψ for which there is no compat-
ible (cid:104)µ(cid:48), t(cid:48)
ω(cid:105) ∈ Ψ(cid:48) with (µ (cid:46)(cid:47) µ(cid:48))(σtαtω (F )) =
α, t(cid:48)
true and t(cid:48)
ω < tω.

• SeqJoin(Ψ, Ψ(cid:48)) contains (cid:104)µ, tα, tω(cid:105) (cid:46)(cid:47) (cid:104)µ(cid:48), t(cid:48)

compatible (cid:104)µ, tα, tω(cid:105) ∈ Ψ and (cid:104)µ(cid:48), t(cid:48)
tionally satisfying tω < t(cid:48)

α, t(cid:48)

α

ω(cid:105) for all
α, t(cid:48)
ω(cid:105) ∈ Ψ(cid:48) addi-

• SeqRightJoin(Ψ(cid:48), Ψ, F ) contains

– all solutions from Filter (F, SeqJoin(Ψ(cid:48), Ψ)) as well

as

– all (cid:104)µ, tα, tω(cid:105) ∈ Ψ for which there is no compatible
ω(cid:105) ∈ Ψ(cid:48) with both (µ (cid:46)(cid:47) µ(cid:48))(σtαtω (F )) =

α, t(cid:48)

(cid:104)µ(cid:48), t(cid:48)
true and tα > t(cid:48)
ω.

• EqJoin(Ψ, Ψ(cid:48)) contains (cid:104)µ, tα, tω(cid:105) (cid:46)(cid:47) (cid:104)µ(cid:48), t(cid:48)
α, t(cid:48)

compatible (cid:104)µ, tα, tω(cid:105) ∈ Ψ and (cid:104)µ(cid:48), t(cid:48)
tionally satisfying tα = t(cid:48)
α and tω = t(cid:48)

ω

ω(cid:105) for all
α, t(cid:48)
ω(cid:105) ∈ Ψ(cid:48) addi-

• EqLeftJoin(Ψ, Ψ(cid:48), F ) contains

– all solutions from Filter (F, EqJoin(Ψ, Ψ(cid:48))) as well

as

– all (cid:104)µ, tα, tω(cid:105) ∈ Ψ for which there is no compatible
ω(cid:105) ∈ Ψ(cid:48) with all (µ (cid:46)(cid:47) µ(cid:48))(σtαtω (F )) =

α, t(cid:48)

(cid:104)µ(cid:48), t(cid:48)
true and tα = t(cid:48)

α and tω = t(cid:48)
ω.

We would like to add the following remarks to justify
some aspects of our deﬁnition of the EP-SPARQL seman-
tics. First, we endorse the principle of timewise monotonic-
ity: the querying formalism is intended to work on triple
streams (i.e., triples continuously enter the system in the
order of their associated time stamps) and query results are
supposed to be output as soon as they are detected. This
leads to the straightforward requirement that it should not
be possible that query results once obtained get invalidated
by later triple inputs. More formally, we have to guarantee
that for any EP-SPARQL query and any RDF stream S all
solutions for the stream {(cid:104)µ, tα, tω(cid:105) | tω < t1} are also solu-
tions for the stream {(cid:104)µ, tα, tω(cid:105) | tω < t2} given that t1 ≤ t2.
Note that a hypothetical constructor seqoptional (speci-
fying a mandatory pattern followed by an optional one) de-
ﬁned as the inverse version of optionalseq would violate
this principle since the solution (cid:104){x (cid:55)→ a}, 0, 0(cid:105) would be a
solution to the query

SELECT ?x ?y WHERE ?x ?x ?x . SEQOPTIONAL ?y ?y ?y .

(7)

when posed against the stream {(cid:104)(cid:104)a, a, a(cid:105), 0, 0(cid:105)} but not
when posed against the augmented stream {(cid:104)(cid:104)a, a, a(cid:105), 0, 0(cid:105),
(cid:104)(cid:104)b, b, b(cid:105), 1, 1(cid:105)}. As second principle, we obtain downward
compatibility in the following sense: as a consequence of the
syntax deﬁnition, every (pure) SPARQL query q is also an
EP-SPARQL query. Now, given an RDF graph {(cid:104)s1, p1, o1(cid:105),
. . . , (cid:104)sn, pn, on(cid:105)}, we obtain µ as a result of the SPARQL
query q if and only if we obtain (cid:104)µ, t, t(cid:105) as a solution to the
EP-SPAQL query against the RDF stream {(cid:104)(cid:104)s1, p1, o1(cid:105), t, t(cid:105),
. . . (cid:104)(cid:104)sn, pn, on(cid:105), t, t(cid:105)} for any ﬁxed time stamp t.

To ﬁnish the semantics deﬁnition, we have to consider
the construct rules. Given such a statement q with the
graph pattern Pq following the construct command and
q of solutions to the where part w.r.t. some given
the set ΨS
q (Pq) denote the set of tuples (cid:104)(cid:104)s, p, o(cid:105), t, t(cid:48)(cid:105)
stream S, let ΨS
for which there is a solution (cid:104)µ, t, t(cid:48)(cid:105) ∈ ΨS
q such that (1) µ
has as domain at least all variables occurring in Pq, and (2)
(cid:104)s, p, o(cid:105) ∈ µ(Pq). Now, given an RDF stream S and a set
Q of construct statements, we deﬁne the Q-closure of S
(closQ(S)) as the smallest set for which both S ⊆ closQ(S)
(Pq) ⊆ closQ(S) for every q ∈ Q. We can
as well as Ψ
see the Q-closure of S as the stream S enriched by the triple
occurrences following from (possibly iterated) application of
the construct rules. Consequently, in the presence of such
rules, select-queries get evaluated not against the pure in-
put stream but against its Q-closure. Moreover, in the case
of SELECT queries, after calculating the solution set, it is
further processed (with respect to variable projection and
output formatting) like for normal SPARQL.

closQ(S)
q

5. EXECUTION MODEL
This section describes how complex events, as deﬁned in
Section 4, are computed at run-time. We describe an exe-
cution mechanism that is based on event-driven backward
chaining (EDBC) rules,
introduced in [2]. EP-SPARQL
queries are compiled into EDBC rules, which enable timely,
event-driven, and incremental detection of complex events
(i.e., answers to EP-SPARQL queries). EDBC rules are
logic rules,5 and hence can be mixed with other background
knowledge (domain knowledge that is used for Stream Rea-
soning). Therefore, we provide a uniﬁed execution mecha-
nism for Event Processing and Stream Reasoning which is
grounded in Logic Programming (LP).
For our encoding, we use a simple correspondence between
RDF triples of the form (cid:104)s, p, o(cid:105) and Prolog predicates of
the form triple(s(cid:48), p(cid:48), o(cid:48)) so that s(cid:48), p(cid:48), and o(cid:48) correspond
to the RDF symbols s, p, and o, respectively. This means
that whenever a triple (cid:104)s, p, o(cid:105) is satisﬁed, the correspond-
ing predicate triple(s(cid:48), p(cid:48), o(cid:48)) is satisﬁed too, and vice versa.
Consequently, a time-stamped RDF triple (cid:104)(cid:104)s, p, o(cid:105), tα, tω(cid:105)
corresponds to a predicate triple(s(cid:48), p(cid:48), o(cid:48), T (cid:48)
ω) where T (cid:48)
α
and T (cid:48)
ω denote time stamps. Time stamps are assigned to
triples either by a triple source (e.g., a sensor or an appli-
cation that generates triple updates) or by an EP-SPARQL
engine (e.g., our prototype implementation). They facilitate
time-related processing, and do not necessarily need to be
kept once the stream has been processed (e.g., the pure RDF
part could be persisted in a RDF triple store without time
stamps).
Sequence operator (SeqJoin). Let us consider a sequence
of three triples (events), represented by Example (1) (in Sec-
tion 4.1) when the filter expression is omitted. This EP-
SPARQL query can be represented by rule (8), where the
seq operator has the identical meaning, i.e., triple(τ, T1, T6)
is detected6 when triple(τ1, T1, T2) occurs in a data stream,
followed by triple(τ2, T3, T4), and triple(τ3, T5, T6). We can
always represent this pattern with rule (9).

α, T (cid:48)

5which we represent in a Prolog-like syntax
6For brevity, we use τ with possible super- and subscripts
to denote triplets s, p, o.

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India639triple(τ, T1, T6) ← triple(τ1, T1, T2) seq

triple(τ2, T3, T4) seq triple(τ3, T5, T6).

triple(τ, T1, T6) ← (triple(τ1, T1, T2) seq

triple(τ2, T3, T4)) seq triple(τ3, T5, T6).

(8)

(9)

We refer to this rewriting as binarization of patterns. Ef-
fectively, in binarization we introduce triples that are binary
intermediate goals. For example, now we can rewrite rule (8)
as an intermediate triple(τ(cid:48), T1, T4) ← triple(τ1, T1, T2) seq
triple(τ2, T3, T4), and triple(τ, T1, T6) ← triple(τ(cid:48), T1, T4)
seq triple(τ3, T5, T6). Every monitored pattern (capturing
either a triple or a derived triple) will be associated with one
or more logic rules. Rules are ﬁred as soon as certain triples
occur, hence they are driven by streaming triples (events).
Use of binarization eases construction of these (event-driven)
rules for three reasons: First, it is easier to implement an
event operator when events are considered on a “two by two”
basis (and to create an automated procedure that compiles
EP-SPARQL expressions into executable rules). Second, the
binarization increases the possibility for computation sharing
of common subexpressions among complex patterns (when
the granularity of intermediate goals is reduced). Third, the
binarization eases the management of rules. Each new triple
(being monitored in a pattern) amounts to appending one or
more rules to the existing rule set. However, what is impor-
tant for the management of rules, we do not need to modify
existing rules when adding new ones.

Here we presented a left-associative binarization (events
and goals are coupled from left to right). The left-associative
binarization is a good choice when the rightmost event(s)
in a pattern rule have a higher occurrence rate than the
others (e.g., event triple(τ3, T5, T6) occurs more frequently
than event triple(τ1, T1, T2)), since in that situation event
triple(τ3, T5, T6) is joined later.
It is also possible to do
such a coupling from right to left. The right-associative cou-
pling is beneﬁcial when the leftmost event(s) have a higher
rate of occurrence(s). Other combinations are possible, too.
See for example bushy plan and inner plan in [16]. These,
and similar plans and cost optimizations as proposed in [16]
are applicable in our framework. They are, however, out
of scope of this paper, and will be addressed in our future
work.

In the following, we give more details about rule assign-
ment for each monitored triple, and sketch the execution
model for a sequence of triples.

triple(τ, T1, T4) ← triple(τ1, T1, T2) seq triple(τ2, T3, T4).

(10)

Rule 10 represents a binary sequence goal, and rules (11)
and (12) represent the pair of event-driven backward chain-
ing rules (EDBC) into which (10) is translated.

triple(τ1, T1, T2) ←
assert(

goal(triple(τ2, , ), triple(τ1, T1, T2), triple(τ, , ))

).

triple(τ2, T3, T4) ←
goal(triple(τ2, , ), triple(τ1, T1, T2), triple(τ, , )),
T2 < T3,
retract(

goal(triple(τ2, , ), triple(τ1, T1, T2), triple(τ, , ))

),
triple(τ, T1, T4).

(11)

(12)

In general, the EDBC rules created by our translation
can be grouped in two diﬀerent classes of rules. We refer
to the ﬁrst class as goal-insertion rules. The second class
corresponds to checking rules. For example, rule (11) be-
longs to the ﬁrst class as it asserts a goal. This rule will
ﬁre when triple(τ1, T1, T2) occurs, and the meaning of the
goal it inserts is as follows: “an event triple(τ1, T1, T2) has
, ) to
occurred at [T1, T2], and we are waiting for triple(τ2,
, )”. Obviously, the goal
happen in order to detect triple(τ,
does not carry information about times for triple(τ2,
, ) and
, ), as we do not know when they will occur. In
triple(τ,
general, the second event in a goal always denotes the event
(triple) that has just occurred. The role of the ﬁrst event is
to specify what we are waiting for to detect an event that is
on the third position (i.e., a derived triple).

, ), triple(τ1, T1, T2),

, )) already exists (meaning that triple(τ1, T1, T2)

Rule (12) belongs to the second class, being a checking
rule.
It checks whether certain prerequisite goals already
exist in the knowledge base, in which case it triggers a more
complex event. For example, that rule will ﬁre whenever
triple(τ2, T3, T4) (the triple from the rule head) occurs. It
checks whether goal(triple(τ2,
triple(τ,
has previously happened), in which case it triggers
triple(τ, T1, T4) by calling that triple. The triple occur-
rence time span (i.e.
[T1, T4]) is deﬁned based on the oc-
currence of constituting events (i.e.
triple(τ1, T1, T2), and
triple(τ2, T3, T4), see Section 4.2). Calling triple(τ, T1, T4),
this event is eﬀectively either propagated further (if it is an
intermediate event) or triggered as a ﬁnished complex event.
We see that our backward chaining rules compute goals in
a forward chaining manner. The goals are crucial for com-
puting complex events incrementally. Goals can persist over
a period of time. It is worth noting that checking rules can
also delete goals (see retract predicate in rule 12). Once a
goal is “consumed”, it is removed from the knowledge base.7
In this respect, goals are kept persistent as long as (but not
longer) they are needed.

So far, we have explained how the seq operator is im-
plemented with EDBC rules. optionalseq is implemented
similarly. The operator allows information to be added to
the answer where certain triples are available, but do not
reject the answer when some part of the query pattern does
not match. Hence the functionality of optionalseq opera-
tor is the same as for seq operator, and optionalseq sub-
patterns are translated into event-driven rules and computed
in the same way as the mandatory part. However, at the
end, the pattern is detected when all mandatory conditions
are satisﬁed (regardless whether an optional sub-pattern has
been satisﬁed by that moment or not). The same applies for
the equals and equalsoptional operators.
Filters. A filter expression in an EP-SPARQL query can
be represented as a rule, too.8 The head of that rule may
be part of a goal. When the goal gets evaluated, the cor-
responding rule will be evaluated, too. For example, let us
consider again rule (1) from Section 4.1 and its filter ex-
pression. We said that triple(τ, T1, T6) can be represented
as triple(τ, T1, T6) ← triple(τ(cid:48), T1, T4) seq triple(τ3, T5, T6)

7Removing “consumed” goals is often needed for space rea-
sons but might be omitted if events are required in a log for
further processing or analyzing.
8Here we focus on ﬁlters without time constraints. Time
constrained ﬁlters will be explained later in this section.

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India640where triple(τ(cid:48), T1, T4) is an intermediate triple, speciﬁed as
triple(τ(cid:48), T1, T4) ← triple(τ1, T1, T2) seq triple(τ2, T3, T4).
When the filter expression is considered, throughout the
binarization process triple(τ, T1, T6) becomes triple(τ, T1, T6)
← triple(τ(cid:48)(cid:48), T1, T6) seq condition(P rice1, P rice2, P rice3),
and triple(τ(cid:48)(cid:48), T1, T6) ← triple(τ(cid:48), T1, T4) seq
triple(τ3, T5, T6) where condition is deﬁned as the following
rule.9

condition(P rice1, P rice2, P rice3)

← P1 is (P rice1 ∗ 0.7), P1>P rice2,
P2 is (P rice1 ∗ 0.5), P rice3>P2.

(13)

Background knowledge. To enable detection of more
complex events, our approach combines streams with back-
ground knowledge. This knowledge describes the context
(domain) in which complex events are detected. As such, it
enables detection of real-time situations that are identiﬁed
based on explicit data (e.g., events) as well as on implicit
knowledge (derived from the background knowledge).

The background knowledge may be speciﬁed as a Prolog
knowledge base or as an RDFS ontology.10 This enables
our execution model to have all relevant parts expressible
in a uniﬁed (logic rule) formalism, and ultimately to rea-
son over a uniﬁed space. For example, while detecting a
sequence of two events, we may check whether their joined
attribute is an instance of a certain class (or any of its sub-
classes) deﬁned in an ontology (e.g., see Test 2 in Section
6). To prove this on-the-ﬂy, an inference procedure needs
to be executed. In this respect, our execution model detects
time relations among streaming triples (events), and per-
forms reasoning tasks when necessary. Since all components
of an EP-SPARQL query (including background knowledge)
are represented as (Prolog) rules, we can use a Prolog infer-
ence engine to serve as an EP-SPARQL engine.
Equals operation (EqJoin). Two events are equal if they
happen right at the same time. Hence, in order to implement
the equals operator we again use the rules of the type (11)-
(12). Additionally, we use the rule (14) to check whether the
occurrence intervals of two events are equal, i.e., the rule
compares whether the start of the ﬁrst interval (T I1 S) is
equal to the start of the second interval (T I2 S). The same
check is done for the end of the two intervals.

equals(T I1, T I2) ←

T I1 = [T I1 S, T I1 E], validT imeInterval(T I1),
T I2 = [T I2 S, T I2 E], validT imeInterval(T I2),
T I1 S = T I2 S, T I1 E = T I2 E.

validT imeInterval(T I) ←

T I = [T I S, T I E], T I S@ < T I E.

(14)

(15)

Rule (15) is an auxiliary rule which makes sure that pa-

rameters of rule (14) are valid time intervals.

Other operators, such as juxtapositions of graph triples
and union, are similarly translated into EDBC rules. Due
to space limitations, we cannot provide details here. Instead,
the interested reader is referred to the conjunction ( and )
and disjunction ( or ) operations, described in [3].
Memory management and time windows. We have

implemented two memory management techniques to prune
outdated events.

The ﬁrst technique modiﬁes the binarization step by push-
ing time window constraints (set by filter expressions with
time constraints,11 e.g., 30 days in EP-SPARQL query (1)
from Section 4.1). The technique ensures that time window
constraints are checked during the incremental event de-
tection. Therefore, unnecessary intermediary sub-complex
events will not be generated if time constraints are violated
(i.e., time expired).

The second solution prunes expired events (goals) by us-
ing system generated events (SGE). Similar to the ﬁrst tech-
nique, rules are deﬁned with time window constraints, and
the binarization pushes the constraints to sub-components.
This technique, however, does not check its constraints at
each step in the event detection incrementally.
Instead,
events (goals) are pruned periodically as SGE are triggered.
For time sliding windows, we also need to prune expired
events. This has been realized by using one of the two men-
tioned memory management techniques. The system gener-
ates frequent SGE, which prune outdated events so that an
aggregation function can be recomputed on the set of valid
events. An output-aggregation event is triggered whenever a
new valid event occurs. Frequency of SGEs can be speciﬁed
for every EP-SPARQL pattern, individually.

6. EXPERIMENTAL RESULTS

To evaluate our approach, we have implemented the sys-
tem called ETALIS.12 ETALIS is implemented in Prolog and
runs on many Prolog systems, including YAP, SWI, SICS-
tus, and XSB Prolog. The test cases presented here were
carried out on a workstation with Intel Core Quad CPU
Q9400 2,66GHz, 8GB of RAM, running Ubuntu 9.10. Our
engine automatically loads the RDF knowledge base into
Prolog and compiles RDF stream triples into Prolog. All
tests were ran on a single dedicated CPU core (no multi-
core platform is currently deployed).

Performance tests include: (1) event processing evalua-
tion; (2) stream reasoning capabilities; (3) implementation
of two example applications that use both (1) and (2).
Test 1: Event Processing. We compared ETALIS with
Esper 3.3.0.13 Esper is a state-of-the-art data stream engine
(also used for commercial purposes). We chose Esper as it
is a freely available open source engine.

In Figure 1(a), we measured the throughput for the EP-
SPARQL queries (5) and (6) from Section 4.1. The query
is run over an RDF stream in ETALIS (with YAP Prolog)
and also with Esper. The stream was generated so that
every streaming triple contributes to the derivation of com-
plex events. The RDF stream in the XML format for Esper
was pre-parsed before the test as we wanted to exclude the
pre-processing time. Figure 1(b) shows the evaluation of a
similar EP-SPARQL query, with the diﬀerence that the win-
dow size is determined by a speciﬁed number of events. Both
queries are typical EP patterns, and both show dominance
of ETALIS over Esper. For tests that involve the stream rea-
soning (test (2) and test (3)) Esper cannot be used, hence
we show the experimental results for ETALIS only.

9Note that P rice1, P rice2, P rice3 are contained in τ1, τ2, τ3.
10In the latter case, we utilize an existing library www.swi-
prolog.org/pldoc/package/semweb.html to transform an
RDFS ontology into Prolog rules and facts.

11Users are encouraged to specify time constraints in queries,
as it enables the system to regularly free up its memory.
12ETALIS: http://code.google.com/p/etalis/
13Esper: http://esper.codehaus.org

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India641Figure 1: Event Processing: (a) Time sliding window (b) Aggregation over count sliding window

Test 2: Stream Reasoning. To provide a performance
evaluation for the stream reasoning functionality, we have
reconstructed an experiment from [21]. The goal of the test
is to listen to streaming triples, and to infer whether the sub-
ject of a triple is an instance of the class of concern (or any of
its subclasses). The class of concern is http://spire.umbc.
edu/ontologies/EthanPlants.owl#Tracheobionta, that has
40,080 subclasses with a maximum class-hierarchy depth of
eight. As in [21], we measured delay caused by the auto-
mated reasoning process needed to determine whether an
entry in a streaming triple is an instance of the class of con-
cern. The work in [21] provides three implementations: the
ﬁrst based on Jena,14 the second based on pre-computed in-
ference results stored in a hash table, and the third based
on a streaming database engine, TelegraphCQ [8] (none of
which is available for download and testing). According
to [21], the fastest implementation is the third one (which
also pre-computes all inferences and stores them in a Post-
greSQL database). Figure 2 shows results of the same test
with ETALIS. Our system is more than 20 times faster. On
one hand, we did the test on a faster machine. On the
other hand, ETALIS was doing stream reasoning on-the-ﬂy
(with no persisted inferences), and still performed signiﬁ-
cantly faster.

In the future, we also plan to provide persistence of infer-
ences (as in [21]) in order to speed up query processing. fil-
ter sub-patterns which demand access and reasoning over
static knowledge (ontologies) can be pre-computed. These
results can then be reused every time a query needs to be ex-
ecuted. This approach may be beneﬁcial when large ontolo-
gies are used, and events are streamed with a high frequency
(e.g., hundred thousands events per second).
Test 3: Example applications. We developed an ap-
plication using both static RDF knowledge bases and RDF
event streams. The application implements a Goods De-
livery System in the city of Milan. The system comprises
of a set of delivery agents that need to deliver the manu-
factured products to the consumers. Each of them has a
list of locations that it needs to deliver goods to. While an
agent is visiting a particular location, the system “knows”

14Jena: http://jena.sourceforge.net/

Figure 2: Delay caused by stream reasoning

her next location and “listens” to traﬃc-update events on
that route(s).
If the agent requests the next route at the
moment when the route is currently inaccessible, the sys-
tem will ﬁnd another route (calculating a transitive closure
on-the-ﬂy over the background ontology). We use a Mi-
lan ontology15 to explore routes in Milan. The application
has been implemented on top of EP-SPARQL and ETALIS.
Due to space limitations we cannot show patterns from the
whole application here.
Instead, we show in Figure 3 re-
sults obtained for 1 and 10 delivery agents when visiting
20 locations (the time spent at a location is irrelevant for
the test, and hence it is ignored). We simulated situations
where more than 50% of the connections between the vis-
iting locations were inaccessible, so that the system needed
to recalculate the transitive closure frequently (as response
to traﬃc-update events).

15Milan ontology was generously provided by AMAT Milano
and CEFRIEL team: http://www.larkc.eu/resources/
published-data-sources/

051015202530100500100050000Throughput (1000 x Events/Sec) Count window size  Throughput vs. Window size (Sum over Sequence) Esper 3.3.0EALIS-YAP400050006000700080009000100001310Throughput (Event/Sec) Time window size (Sec) Throughput vs. Window size ETALIS-YAPEsper051015202530100500100050000Throughput (1000 x Events/Sec) Count window size  Throughput vs. Window size (Sum over Sequence) Esper 3.3.0EALIS-YAP400050006000700080009000100001310Throughput (Event/Sec) Time window size (Sec) Throughput vs. Window size ETALIS-YAPEsper!"#$"%$&'()*+,$-,#$.+/,"0(01$2+*/3!"!!#!!!#"!!$!!!"!!!#!!!!#"!!!$!!!!!456+'$"%$&'()*+,.+/,"0(01$2+*/3$(0$5,%&'()*+,'-WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India642Figure 3: Milan Sightseeing: (a) Delay caused by processing (b) Memory consumption

and the prediction Hp exceeds a threshold (30mm for the
North Paciﬁc as prescribed by the NDBC). The diﬀerence
magnitude was continuously calculated over historic NDBC
data from May 2005 until September 2010. In this period,
44310 sensor readings were reported to ETALIS. The sys-
tem detected pressure diﬀerences higher than 30mm only 3
times (all of them during 3 hours, on 23.03.2010). Results
are shown as a histogram in Figure 4. The according sen-
sor station18 is located in the Bering Sea, close to Alaska
(55◦0’40”N 171◦58’50”W ).

The goal of the test was to show the usefulness of our for-
malism in a real-use scenario, as well as to show that the
application scales well with the increase of number of agents
(throughput for one agent is about 10 times higher than the
throughput for 10 agents, indicating a linear relationship in
the investigated range, see Figure 3 (a)). Similarly, Figure 3
(b) shows the memory consumption for the same test (like-
wise indicating a linear space dependency w.r.t. the number
of agents).

For the second application, we have developed a real-time
service for detection of tsunamis. A tsunamis gauge is de-
signed to detect and report tsunamis based on buoy sensor
data. Data is provided by the National Data Buoy Center
(NDBC).16 We have implemented a tsunami detection al-
gorithm17 which works by predicting the amplitudes of the
pressure ﬂuctuations within the tsunami frequency band and
then testing these amplitudes against a threshold value. The
prediction is calculated by the following formula:

3(cid:88)

(cid:48)

) =

Hp(t

w(i)H

∗

(t − i · ∆t)

i=0

where w(i) are coeﬃcients that come from Newton’s formula
for forward extrapolation. The NDBC uses the following
values for these coeﬃcients:

w(0) = 1.16818457031250
w(1) = −0.28197558593750
w(2) = 0.14689746093750
w(3) = −0.03310644531250

Buoy sensor data is updated every 15 seconds, providing
the sea level pressure, air temperature, wind speed, wave
hight etc. The asterisk H∗ denotes average pressure. Four
values are continuously produced over a 3 hour sliding win-
dow (i = 0, .., 3 where a new value is output every hour,
i.e., ∆t = 1 hour), and t(cid:48) is the prediction time which is
set to 5,25 minutes. A tsunami is detected if the diﬀer-
ence between the observed pressure (current sensor value)

16NDBC : http://www.ndbc.noaa.gov/
17http://www.ndbc.noaa.gov/dart/algorithm.shtml

Figure 4: Tsunami detection histogram

Further on, we have utilized GeoNames as a worldwide
geographical knowledge base. If a sensor detects a tsunami,
GeoNames can provide all geographical places within a cer-
tain radius from the sensor location. These places can then
automatically be warned of a detected tsunami. We have set
up an on-line demo for this application19 to continuously
monitor live data provided by NDBC and detect tsunami
warnings in real-time.

18http://www.ndbc.noaa.gov/station_page.php?
station=46073
19http://etalis.fzi.de

3 94 109 130 31 889 1076 1295 0500100015005101520Consumed time in ms Number of locations No. of Locations vs. Consumed Time 1 Visitor10 Visitors35 86 119 165 204 810 1039 1503 05001000150020005101520Consumed Memory in kB Number of locations No. of Locations vs. Consumed Memory 1 Visitor10 Visitors3 94 109 130 31 889 1076 1295 0500100015005101520Consumed time in ms Number of locations No. of Locations vs. Consumed Time 1 Visitor10 Visitors35 86 119 165 204 810 1039 1503 05001000150020005101520Consumed Memory in kB Number of locations No. of Locations vs. Consumed Memory 1 Visitor10 Visitors-0.04-0.0200.020.040.060.08Pressure differenceThresholdTimePressureWWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India6437. CONCLUSIONS AND FUTURE WORK
Addressing dynamics and notiﬁcation on the Web has re-
cently become an important area of research. Real-time data
is generated by multiple social networks, sensor networks,
various on-line services etc. The challenge is to get advan-
tage of real-time data, and recognise important situations of
interest in a timely fashion.

We proposed a new language, EP-SPARQL, for Event
Processing and Stream Reasoning. EP-SPARQL speciﬁes
complex events by temporally situating real-time streaming
data, and uses background ontologies to enable stream rea-
soning. We deﬁned the language with a clear syntax and a
formal semantics. Further, our contribution includes an ex-
ecution model which eﬃciently derives complex RDF events
in (near) real-time. We also provided an implementation of
our approach and conducted several types of tests.

We foresee several extensions to this work. Promising
candidates for further investigation are support for stream
reasoning over more expressive formalisms (e.g., OWL and
its diﬀerent proﬁles). Also adaptive optimizations as well as
distributed stream reasoning are aﬃrmative areas of future
work.

8. ACKNOWLEDGMENTS

This work was partially supported by the European Com-
mission funded project PLAY (FP7-20495) and by the Ex-
presST project funded by the German Research Foundation
(DFG). We thank Ahmed Khalil Hafsi and Jia Ding for their
help in implementation and testing of ETALIS.

9. REFERENCES
[1] J. Agrawal, Y. Diao, D. Gyllstrom, and N. Immerman.

Eﬃcient pattern matching over event streams. In
Proceedings of the 28th ACM SIGMOD Conference,
pages 147–160, 2008.

[2] D. Anicic, P. Fodor, S. Rudolph, R. St¨uhmer,

N. Stojanovic, and R. Studer. A rule-based language
for complex event processing and reasoning. In
Proceedings of the 4th International Conference on
Web Reasoning and Rule Systems (RR 2010), pages
42–57, 2010.

[3] D. Anicic, P. Fodor, S. Rudolph, R. St¨uhmer,

N. Stojanovic, and R. Studer. Etalis: Rule-based
reasoning in event processing. In S. Helmer,
A. Poulovassilis, and F. Xhafa, editors, Reasoning in
Event-based Distributed Systems, Studies in
Computational Intelligence series. LNCS, Springer
Verlag, 2011.

[4] D. F. Barbieri, D. Braga, S. Ceri, E. Della Valle, and

M. Grossniklaus. Incremental reasoning on streams
and rich background knowledge. In Proceedings of the
7th Extended Semantic Web Conference (ESWC’10),
pages 1–15, 2010.

[5] D. F. Barbieri, D. Braga, S. Ceri, and

M. Grossniklaus. An execution environment for
C-SPARQL queries. In Proceedings of the 13th
International Conference on Extending Database
Technology (EDBT’10), pages 441–452, 2010.

[6] R. S. Barga, J. Goldstein, M. H. Ali, and M. Hong.

Consistent streaming through time: A vision for event
stream processing. In Proceedings of the 3rd Biennial

Conference on Innovative Data Systems Research
(CIDR’07), pages 363–374, 2007.

[7] A. Bolles, M. Grawunder, and J. Jacobi. Streaming

SPARQL - extending SPARQL to process data
streams. In Proceedings of the 5th European Semantic
Web Conference (ESWC’08), pages 448–462, 2008.

[8] S. Chandrasekaran, O. Cooper, A. Deshpande, M. J.

Franklin, J. M. Hellerstein, W. Hong,
S. Krishnamurthy, S. Madden, V. Raman, F. Reiss,
and M. A. Shah. Telegraphcq: Continuous dataﬂow
processing for an uncertain world. In Proceedings of
the 1st Biennial Conference on Innovative Data
Systems Research (CIDR’03), 2003.

[9] M. Cherniack, H. Balakrishnan, M. Balazinska,

D. Carney, U. ¸Cetintemel, Y. Xing, and S. B. Zdonik.
Scalable distributed stream processing. In Proceedings
of the 1st Biennial Conference on Innovative Data
Systems Research (CIDR’03), 2003.

[10] E. Della Valle, S. Ceri, F. van Harmelen, and

D. Fensel. It’s a streaming world! Reasoning upon
rapidly changing information. IEEE Intelligent
Systems, 24(6):83–89, 2009.

[11] F. Grandi. T-SPARQL: a TSQL2-like temporal query

language for RDF. In International Workshop on on
Querying Graph Structured Data, pages 21–30, 2010.

[12] C. Gutierrez, C. A. Hurtado, and A. A. Vaisman.

Introducing time into rdf. The IEEE Transactions on
Knowledge and Data Engineering, 19(2):207–218,
2007.

[13] P. Hitzler, M. Kr¨otzsch, and S. Rudolph. Foundations

of Semantic Web Technologies. Chapman &
Hall/CRC, August 2009.

[14] M. Koubarakis and K. Kyzirakos. Modeling and

querying metadata in the semantic sensor web: The
model stRDF and the query language stSPARQL. In
Proceedings of the 7th Extended Semantic Web
Conference (ESWC’10), pages 425–439, 2010.

[15] D. Luckham. The Power of Events: An Introduction

to Complex Event Processing in Distributed Enterprise
Systems. Addison-Wesley, Reading, MA, USA, 2002.
[16] Y. Mei and S. Madden. Zstream: a cost-based query

processor for adaptively detecting composite events. In
Proceedings of the 29th ACM SIGMOD Conference,
pages 193–206, 2009.

[17] M. Perry, A. P. Sheth, and P. Jain. SPARQLST:

Extending SPARQL to support spatiotemporal
queries. In Technical Report. KNOESIS-TR-2009-01,
2008.

[18] E. Prud’hommeaux and A. Seaborne. SPARQL query

language for RDF. In
http://www.w3.org/TR/rdf-sparql-query/, 2008.

[19] A. Rodriguez, R. E. McGrath, and J. Myers. Semantic

management of streaming data. In Workshop on
Semantic Sensor Nets at ISWC ’09, 2009.

[20] J. Tappolet and A. Bernstein. Applied temporal RDF:

Eﬃcient temporal querying of RDF data with
SPARQL. In Proceedings of the 6th European Semantic
Web Conference (ESWC’09), pages 308–322, 2009.

[21] O. Walavalkar, A. Joshi, T. Finin, and Y. Yesha.

Streaming knowledge bases. In International
Workshop on Scalable Semantic Web Knowledge Base
Systems, 2008.

WWW 2011 – Session: Query and Ontology LanguagesMarch 28–April 1, 2011, Hyderabad, India644