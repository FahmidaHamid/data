A Uniﬁed Platform for Data Driven Web Applications with

Automatic Client-Server Partitioning

Fan Yang1, Nitin Gupta1, Nicholas Gerner1, Xin Qi1, Alan Demers1, Johannes Gehrke1,

Jayavel Shanmugasundaram2
1 Cornell University
Ithaca, NY

2 Yahoo!
Santa Clara, CA

{yangf, niting, nsg7, qixin, ademers, johannes}@cs.cornell.edu,

jaishan@yahoo-inc.com

ABSTRACT
Data-driven web applications are usually structured in three
tiers with diﬀerent programming models at each tier. This
division forces developers to manually partition application
functionality across the tiers, resulting in complex logic, sub-
optimal partitioning, and expensive re-partitioning of appli-
cations.

In this paper, we introduce a uniﬁed platform for auto-
matic partitioning of data-driven web applications. Our ap-
proach is based on Hilda [14, 26], a high-level declarative
programming language with a uniﬁed data and program-
ming model for all the layers of the application. Based on
run-time properties of the application, Hilda’s run time sys-
tem automatically partitions the application between the
tiers to improve response time while adhering to memory
and/or processing constraints at the clients. We evaluate
our methodology with traces from a real application and
with TPC-W, and our results show that automatic parti-
tioning outperforms manual partitioning without the asso-
ciated development overhead.

Categories and Subject Descriptors
H.4.m [Information Systems]: Miscellaneous; D.1.m [Pro-
gramming Techniques]: Miscellaneous; D.2.11 [Software
Engineering]: Software Architectures; D.2.8 [Software
Engineering]: Metrics—performance measures

General Terms
Design Languages Performance

Keywords
Hilda, Client Server Partitioning, Declarative Language, Web
2.0, Data Driven Application

1.

INTRODUCTION

An important class of applications is data-driven web ap-
plications, i.e., web applications that run on top of a back-
end database system. Examples of such applications are b2c
portals such as online shopping sites and online auctions,

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2007, May 8–12, 2007, Banff, Alberta, Canada.
ACM 978-1-59593-654-7/07/0005.

Figure 1: Tiers in a Data-Driven Web Application

and various b2b portals. Data-driven web applications are
usually structured in three tiers: a database system that
stores persistent data as the lowest tier, an application server
that contains most of the application logic as the middle-tier,
and the client web browser that contains some client-speciﬁc
application logic and presentation as the top tier (see Fig-
ure 1).

Current development platforms use diﬀerent programming
models at each tier. For example, server side application
development frameworks such as J2EE and Enterprise Java
Beans (EJBs) wrap relational data as Java objects. PHP
and ASP.NET bridge the diﬀerence between the data model
at the lowest tier and the middle tier in similar ways. The
top tier usually uses a diﬀerent programming model, such
as AJAX or FLASH [1], which allows the developer to build
rich clients. The diﬀerence in programming model between
the diﬀerent tiers forces the developer to decide manually
how to partition application functionality across the tiers,
and to implement functionality at each tier separately using
diﬀerent programming languages and models.

Exposing the boundaries between tiers to the programmer

in this way has four signiﬁcant drawbacks.

Increased Development Time. Having diﬀerent pro-
gramming models in diﬀerent tiers makes it hard to develop,
maintain, and optimize applications, as the developer must
manually bridge the diﬀerences between the individual mod-
els (for example, the relational model, EJBs, and HTML
forms).

Complex Logic due to Partitioning. Partitioning ap-
plication logic across the tiers requires complex logic to syn-
chronize the state of the application. For example, in order
to enable partial updates (a well known strategy in AJAX
[2]), data can be cached at the client side. However, client-

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications341side caching can allow content shown in the browser to be-
come outdated due to concurrent updates to the application
state from diﬀerent users. Such application-level conﬂicts
are diﬃcult to detect, and existing systems do not provide
automatic support for conﬂict detection.

Suboptimal Partitioning. Since the decision of how to
partition the application is left to the developer (who may
have little data on which to base her decisions), the resulting
division of the application may be be suboptimal in terms
of system performance.

Expensive Re-Partitioning. Once a partitioning of the
application has been implemented, moving functionality be-
tween layers is complex. For example, consider an applica-
tion that allows a user to sort on a column of a table: this
may initially be implemented in the application server as
an SQL order by query issued over a relational database.
If the developer later decides to move sorting to the client
side to improve responsiveness, the sort functionality must
be reimplemented in a diﬀerent programming model such as
JavaScript.

In this paper, we introduce a uniﬁed platform for auto-
matic partitioning of data-driven web applications. Our
approach is based on Hilda, a high-level declarative pro-
gramming language with a uniﬁed data and programming
model for all layers of the application [26].
In particular,
we show how to automatically partition a Hilda applica-
tion between the client and middle tier based on run-time
behavior of the application — all of this completely trans-
parent to the developer. Our way of partitioning automat-
ically synchronizes state between client and server with-
out the developer having to write any additional code to
achieve this. A web application developer thus can focus
on the core application logic without worrying about the
partitioning of the application or changes to the partitions.
The Hilda system is available as open-source software at
http://www.cs.cornell.edu/database/hilda.

In summary, this paper makes the following contributions.
• We have developed a run-time environment for Hilda
that allows us to automatically partition a data-driven
web application dynamically between client and mid-
dle tier in a way that is completely transparent to the
developer. (Section 2)

• We model client-middle tier partitioning as an opti-
mization problem. The resulting problem is NP-hard
with the client side space constraint, but we give an ap-
proximation algorithm that is provably within a factor
of three of the optimal solution of the problem. (Sec-
tion 3)

• We show how we can use trace data to instantiate the
optimization model and how to derive practical deci-
sions about client-middle tier partitioning. In a thor-
ough experimental evaluation using a technical bench-
mark and a real application, we show the eﬃcacy of
our techniques. (Section 4)

We discuss related work in Section 5, and we conclude in
Section 6.

2. CLIENT-SERVER PARTITIONING

We ﬁrst review Hilda, a high-level language for data-driven
applications on which our model is based. We then come to
the ﬁrst contribution of the paper, the Hilda Runtime Sys-
tem that enables automatic client-server partitioning.

2.1 Hilda

Hilda is a high-level declarative language designed for de-
veloping data-driven web applications [26]. It is based on
UML [5] and the relational data model [19]. Instead of us-
ing diﬀerent data models and languages for diﬀerent layers
of the application stack, Hilda presents a uniﬁed program-
ming model for all layers (see Figure 1). Our discussion in
this section summarizes the aspects of Hilda that are impor-
tant for this paper; a full discussion of Hilda can be found in
our prior work, which is the source of some of the material
in this subsection [26].

A Hilda program consists of building blocks called AUnits
(for Application Units), analogous to UML classes. Each
AUnit models a functional component of the application
and encapsulates the operations and the data associated
with (one or more) web pages, subpages, or a frame of a
webpages. An AUnit is a single-entry single-exit program-
ming construct that has an (optional) input schema and
an (optional) output schema (similar to arguments and re-
turn values of functions). The input and output schemas
are both relational schemas [19]. The developer organizes
AUnits into parent-child relationships, resulting in a hierar-
chical structure that models the hierarchical structure of a
website. The leaf level AUnits represent basic components
such as HTML forms that allow user interaction. For exam-
ple, the Navigation Bar AUnit represents a form containing
options, one of which can be selected by a user. One of the
AUnits in a Hilda program is designated as the root AUnit,
which intuitively corresponds to the “main” function in a
program.

A running Hilda program consists of instances of AUnits;
we call the construction of an instance of an AUnit activa-
tion, and the destruction of an instance of an AUnit deac-
tivation. An AUnit instance A is activated from its parent
AUnit instance; the parent passes input data through the
input schema; when A gets deactivated it returns output
data back to the parent through its output schema.

The activation of child AUnits is controlled through a part
of the parent AUnit called its activators. Each activator
speciﬁes the following information: (i) the child AUnit of
which it creates instances; (ii) an activation condition, which
deﬁnes when and how instances of the child AUnit should
be activated; (iii) an activation ID that uniquely identiﬁes
each child AUnit instance, (iv) input data for instances of
the child AUnit; and (v) optional operations triggered by
the outputs of the child AUnit instances. An activator can
activate multiple instances of the same child AUnit; the ID
serves as the primary key to distinguish between diﬀerent
instances of the same child AUnit. Thus within an AUnit,
we can distinguish child AUnits by their IDs; this also al-
lows us to globally identify AUnit instances by through a
concatenation of its ID with the IDs of its ancestor AUnit
instances. In Hilda, all conditions, activators, etc. of an AU-
nit are written as declarative SQL queries. Rendering logic
is deﬁned for every AUnit to specify the visual appearance
of the AUnit at the client.
Example: A Course Management System. Figure 2

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications342Figure 2: A part of the AUnit hierarchy that models the Course
Management System

Figure 3: Activation tree and the corresponding webpage

shows part of the AUnit hierarchy for a Course Management
System (CMS) we developed at Cornell. The CMS AUnit
represents the application, and contains AUnits for faculty,
students and system administrators, which are modelled by
child AUnits Faculty, Student and Sys Admin, respectively.
A faculty member can view students, add and remove staﬀ,
edit assignments and perform other course related opera-
tions, each of which is implemented as a child of the Faculty
AUnit. For example, the StaﬀList AUnit encapsulates the
data corresponding to the list of staﬀ members associated
with the current course. This AUnit allows the faculty mem-
ber to view and update, in a browser, the complete list of
staﬀ members. The ID of a Faculty AUnit instance is the
faculty’s NetID; the ID of a FacultyCourse AUnit instance
is the name of the course; its KEY is a tuple consisting of
the course ID and the faculty’s NetID. The activation con-
dition for Faculty is that the current user logs in as a course
faculty member.(cid:2)

To start a Hilda program, the system creates an instance
of the root AUnit of the Hilda program. The system then
recursively activates children of the root AUnit according to
their activation conditions, and constructs a tree of AUnit
instances called the activation tree. The system maintains
this activation tree for each user session. At any time, the
activation tree represents the part of the application cur-
rently available to the user through a web browser.

When a user performs an operation, such as submitting

Figure 4: Activation tree and the corresponding webpage after
selecting editing staﬀ

Figure 5: System Architecture

a form, the leaf level AUnit corresponding to that opera-
tion returns data to its parent AUnit, which then performs
operations to update the application state, and/or returns
data to its parent, and so forth. AUnit instances can only
get data from and return data to their parents, which is
analogous to the data ﬂow in function invocations. After
the return chain terminates, a new activation tree is con-
structed by reevaluating every activation condition based
on the updated state.1 Thus in Hilda a web application is
no longer considered as a connected graph of individual web
pages that allows users to navigate from any page to any
other page. Instead, execution of a web application is mod-
elled as a sequence of transitions from one activation tree
to another, where the transition is triggered by the users’
interaction with a leaf-level AUnit.
Example: CMS (Continued). The CMS AUnit is the
root AUnit of the application in Figure 2. A new instance of
this root AUnit is activated each time a new user connects
to the application, and this instance is deactivated when
the user disconnects. Consider a case in the CMS, when
a user logs in as course faculty and navigates to a course
page. Figure 3 shows the current activation and the page
in the browser. Each activated AUnit instance corresponds
to a sub-page of the content shown in the browser. Navi-
gationBar 1 corresponds to the navigation bar at the top of
the page, and NavigationBar 2 corresponds to the one at the
left. Suppose the user wants to view and edit the list of staﬀ
members in the current course and selects that option from
the navigation bar. NavigationBar 2 returns the selected
option to its parent FacultyCourse and updates the local
state2 of its parent. When the return chain ﬁnishes (in this
case, the chain only has one step), the new activation tree
is constructed based on the updated state. One StaﬀList
instance will be activated based on its activation condition.
Figure 4 shows the resulting activation tree and its appear-
ance in a web browser. Again if the user wants to view
the student list for this course and chooses “Student” from
the navigation bar, the NavigationBar 2 AUnit instance re-
turns to the FacultyCourse instance and updates the state,
which then deactivates the StaﬀList instance and activates
a new instance of the StudentList AUnit. The webpage gets
updated and will show student information.(cid:2)
2.2 The Hilda Runtime System

1Reconstruction of the whole activation tree after each re-
turn chain terminates is only the semantics of the execution
model; more eﬃcient implementations are possible [26].
2We omit the details of local states of AUnit here, which
are also expressed as tables. In this case, we have a Cur-
rentChoice table which keeps track of the options users se-
lected. Please refer to [26] for more details

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications343the same activation tree. In the ﬁrst case, we keep the com-
plete activation tree at the server side, while in the second
case, we keep part of it at the client side. The main draw-
back of running everything at the server side is that the
client must contact the server for every operation the user
performs. The server then resends the entire refreshed page
in HTML format to the client. However, if the navigation
bar and Staﬄist instances are executed at the client, the
run time system can cache the data needed by them. Then,
if the user adds or removes staﬀ, the list of staﬀ members
is updated locally in the client, and the server is contacted
only when the Submit button is clicked by the user. Only
after this step are the updates in the staﬀ list sent to the
server, which updates the database. Note that the client
already has all the data and code for the new staﬀ list, un-
less it has been updated by other users — which is detected
by the run time synchronization algorithm. This allows the
RTSC to create HTML at the client without waiting for the
server to respond. Other parts of the page, such as naviga-
tion bars, are normally unaﬀected by the transmitted data,
and therefore keep their place in the page.

Maintaining AUnit instances at the client can therefore
result in better system response time and a better user ex-
perience. This can also be seen from our experiments, dis-
cussed in Section 4. Similar caching logic for partial updat-
ing of pages can be implemented in frameworks like AJAX
only by extensive client side coding. In our framework, such
partitions are automatic.

3. MODEL OF CLIENT-SERVER

PARTITIONING

In this section, we present a cost model for client-server
partitioning. We ﬁrst deﬁne the problem and formulate it
as an optimization problem. We show that the problem is
NP-hard. We then give an algorithm that approximates the
optimum partition, and prove a bound on the approximation
error.

3.1 Partitioning Philosophy

A plausible method of solving the client-server partition-
ing problem would be partition at the granularity of AU-
nit deﬁnitions; i.e., to partition the set of AUnit deﬁnitions
into two sets, one corresponding to AUnits whose instances
will run on the server, and the other corresponding to AU-
nits whose instances will run on the client. However, this
method would not capture the fact that diﬀerent instances
of the same AUnit may require very diﬀerent amounts of
computation and data transfer. For example, in the Course
Management System, the EditCourse AUnit provides the
functionality for course staﬀ to edit courses. The amount
course-related data, such as the number of students enrolled,
the number of assignments, etc., can diﬀer substantially be-
tween courses. We may want to ship the data and computa-
tion to the client for small courses while keeping big courses
at the server side to save bandwidth. This motivates our
decision to group similar instances together, proﬁle their
execution and then partition programs at the level of AUnit
instances based on the proﬁles.

Diﬀerent types of clients can have very diﬀerent comput-
ing and storage resources. For example, moving computing
and data to a powerful desktop client may be desirable, while
doing the same for a PDA client may adversely aﬀect its re-

Figure 6: Activation tree with diﬀerent partitions

The Hilda RunTime Systems, for both the server and the
client, are evaluation engines for Hilda programs. They ex-
ecute the application logic speciﬁed in a program by main-
taining the activation trees, and maintain consistency be-
tween the client and server states. We use RTSS to refer to
the run time system residing at the server, and RTSC for
the system residing at the client. The RTSS is a Java servlet
running in some application server (such as JBOSS or We-
blogic), and has connections to the back end database. It
communicates with the RTSC. The RTSC runs as a “sticky”
applet, which resides in the secondary cache of the client and
is available for quick loading by browsers [16].

Based on the semantics of Hilda, the RTSS and RTSC
coordinate with each other to maintain the activation tree.
An AUnit instance is activated when its activation condition
is satisﬁed and is deactivated when the conditions fails to be
satisﬁed. The location (client or server) where an instance
is activated is not predeﬁned by the application developer;
instead, it is determined and can be changed at run time by
the run time system.

The RTSC caches local data at the client.

It uses this
data to generate webpages dynamically (e.g. student info
list), and to store a user’s temporary input (e.g.
items in
a shopping cart). This temporary data is stored in main
memory, and reused by the RTSC. The RTSC contacts the
RTSS to check for updates to its input data. The system
imposes an upper bound on how out-of-date the client state
can be by periodically contacting the server using heartbeat
messages. To avoid sending the cached data back and forth
between the client and the server, the RTSS maintains a
copy of the data sent to each client. On receiving an update
request, the server checks for updates to the client input
data, and responds with only the updated data. To limit
the amount of server-side data required for each client ses-
sion, the developer can specify a maximum life span for the
data in the server cache, as well as the heartbeat frequency
of the client. Our cache consistency strategy is similar to
a detection based approach for transactional client server
caching [12, 25, 18], although the system allows for the in-
tegration of other strategies in the future.

Client-server partitioning is done based on the activation
proﬁle of an application. The activation proﬁle speciﬁes
which AUnit instances, identiﬁed by their unique key, should
be activated in the client. When the run time system ac-
tivates an instance of some AUnit, it refers to the conﬁgu-
ration proﬁle to determine whether the RTSS or the RTSC
should activate the instance. The activation proﬁle is gen-
erated automatically, based on the observed workload of the
system. We will discuss its generation in the next section.
CMS example: Figure 6, shows two diﬀerent partitions of

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications344sponse time. This motivates us to partition the application
based on the types of clients. We make the assumption that
the cost associated with a partition is independent of the
load on the server, so that partitions corresponding to dif-
ferent clients do not interfere with each other’s performance.
Essentially, we are assuming that server load can be man-
aged using existing load-balancing techniques [8]; improving
server system scalability is outside the scope of the paper.
The solutions for each client type thus obtained can be com-
bined to yield an overall optimal solution for the application.
Therefore, we describe the cost model for only a single client
type.
3.2 Terminology

Recall that Hilda models an application in a hierarchical
manner, where each AUnit contains other AUnits. Let aid
be a unique identiﬁer associated with each AUnit deﬁnition.
Then, we deﬁne the class graph of a Hilda program P as:
Deﬁnition 1: ClassGraph(P ) = (V, E) where V = {v|v is
an AUnit deﬁnition in P}, and E = {(v, w)|v, w ∈ V and w
is a child AUnit of v} (cid:2)

For a valid Hilda program, the class graph must be a
DAG. However, instances of an AUnit may be activated for
diﬀerent keys. These instances can be uniquely identiﬁed
by the pair (aid, key), where key captures the path from a
root AUnit instance to the current AUnit instance in the
activation tree. This leads us to the deﬁnition of the key
tree of a given Hilda program P :
Deﬁnition 2: KeyT ree(P ) = (V, E) where V = {(aid, key)|
aid is the identiﬁer of some AUnit deﬁnition in P}, and
E = {(v, w)|v, w ∈ V and w.aid corresponds to a child AU-
nit of the AUnit corresponding to v.aid} (cid:2)

Note that each AUnit corresponds to a diﬀerent key, where
the key includes the key of the AUnit’s parent node. There-
fore, an instance of any AUnit, except the root, is activated
by exactly one parent. Thus the key tree must be a tree.
Note that the class graph of a Hilda program is eﬀectively
an aggregated version of the key tree, obtained by merg-
ing nodes that have the same aid.
In order to estimate
the response time of a system, we require for each node of
a key tree, various annotations such as the expected time
for processing the AUnit instance and expected data to be
processed for that instance. We next deﬁne an annotation
function for the key tree of a Hilda program P as:
Deﬁnition 3: The annotation function A (P ) : V → R
4 for
the key tree (V, E) of a hilda program P is a function that
maps each node v of the key tree onto a 4-tuple, where the
ﬁelds correspond to the following: the probability pv that a
randomly chosen activation over the space of all executions
of P is on the AUnit that v is associated with; the expected
time tv for processing queries of the node, the expected sum
dv of the size of input and output data, and the expected
number lv of connections3 established, respectively. By the
deﬁnition of the probabilities pv we also have

(cid:2)

pv = 1.

v

. (cid:2)
3One HTTP connection is established for every client server
communication.

We describe here the partitioning of a Hilda program into
the client part and the server part, at the granularity of its
key tree. Whether an AUnit instance is activated and evalu-
ated at the client or the server depends on how the partition-
ing is done. Let ζ : V ∈ KeyT ree(P ) → {client, server} be
a function specifying where AUnit instances in the key tree
of program P are located. Then, we deﬁne a parameter
α, which is the ratio of the client computation time to the
server computation time for a given operation, as:

α =

tu
tv

where ζ(u) = server and ζ(v) = client.

The data size of any given AUnit instance is assumed to be
independent of ζ. This is because the input and output data
of any instance remains the same, regardless of whether the
instance is located at the server or the client. The partition
of a hilda program P , then, is deﬁned by a cut C as:
Deﬁnition 4: P artition(P ) ≡ C = (Gs, Gc) a cut in the
tree KeyT ree(P ) = (V, E) s.t. Gs and Gc are disjoint, Gs is
connected, the root node belongs to Gs, and Vs ∪ Vc = V 4.
(cid:2)

In this deﬁnition, Gs = (Vs, Es) is the part that runs
on the server and Gc = (Vc, Ec) is the part that runs on
the client, i.e. an AUnit instance a will be activated and
maintained at client side iﬀ ∃v ∈ Vc (cid:8) a.key = v.key. We
denote the set of edges between the two sides of the partition
by Ecut = E − (Es ∪ Ec).
3.3 Cost Model

In this paper, our goal is to optimize the average response
time for users. Optimizing other goals, such as system
throughput, would involve a similar analysis but a diﬀerent
cost model. We leave this as future work. Recall that we
assume that the key trees corresponding to diﬀerent types
of clients are independent of each other, and do not aﬀect
the cost model for any given tree. We therefore consider the
key tree for only a single type of client.

Before formalizing our cost model, we want to justify sev-
eral implications that make the model more tractable. First,
we ignore the cost at server side for synchronization and
processing heart beat messages, because it is done asyn-
chronously and thus does not noticeably aﬀect users’ re-
sponse time. Second, we do not consider the cost of trans-
ferring the run time system and Hilda code to the client side.
These are implemented as sticky applets and can be reloaded
from the client machine at low cost after being downloaded
for the ﬁrst time. Finally, we ignore web browser rendering
time, which should be the same across diﬀerent partitioning
scenarios.
Given the key tree KeyT ree(P ) = (V, E) of a program
P , the annotation function A, and the cut C = (Gs, Gc)
that partitions the tree into server and client subgraphs, we
deﬁne the expected user response time as:

costC (P ) =

v∈KeyT ree(P )

(cid:2)

pv × tC

v

The time to perform AUnit instance processing, given a
partition, includes the time to process the AUnit instance
at the client (return queries and later reactivation queries),
the time to send query results to and from the server and
the time to process the queries at the server:
4Vs and Vc are the nodes on server and client respectively

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications345tC
v = tclient

v

+ tdata

v + tserver

v

v

v

where tclient
is the expected time for processing v at the
client, tdata is the expected time for sending result sets to
and from the server, including the time for preparation of the
data, and tserver
is the expected time for processing queries
at the server. Based on our earlier assumption that the time
to process an AUnit instance at the client is proportional to
the time to process the same instance at the server, and
assuming that the data transmission time for transferring a
result set between client and server is proportional to the
size of that result set, we have:

(cid:3)

tclient
v

=

tserver
v

=

0
α × tv
(cid:3)

tv
0

if ζ(v) = server
if ζ(v) = client

if ζ(v) = server
if ζ(v) = client

We also have

(cid:3)

tdata
v =

γ × dv + L × lv + dv/β if ∃u s.t. (u, v) ∈ Ecut
0

otherwise

v

Here, the data transmission cost tdata
consists of three parts:
the expected time for preparing the data to transfer, ex-
pected overhead of the handshaking process for establishing
TCP connections, and the expected time for transferring the
data. We assume that the expected time for preparing and
transferring data is proportional to the expected amount of
data transferred, with proportionality constants γ and β, re-
spectively. L is the expected overhead for the handshaking
process(initial round trip time), which allows us to take into
account the number of connections.

These deﬁnitions yield the following optimization problem

to choose a cut C for a program P :

arg min

C

costC (P )

We deﬁne an additional constraint to take into account
client memory limitations. Let MC (T ), the memory usage
at the client given the cut C, be given by:

(cid:2)

MC (P ) =

v∈KeyT ree(P ),ζ(v)=client

mv

where mv is the maximum memory that is used by any query
of the AUnit instance v. Then, if ˆM is the maximum mem-
ory available for the application at the client, we have the
constraint MC (T ) ≤ ˆM .
3.4 Solution For Partitioning

The problem of ﬁnding an optimal partition with con-
straints for a given key tree has been proven to be NP-
hard [27]. Therefore, we design an approximation algorithm,
which guarantees to give a result which is within three times
of the optimal in the worst case. The technique we use is
Randomized Rounding [21]: we ﬁrst formulate the problem
as an Integer Programming (IP) problem, relax it to a Linear
Programming (LP) problem, solve it, and use a randomized
algorithm, similar to that in [15], to round the solution to
an integral one that is not much worse.
Given a key tree KeyT ree(P ) = (V, E), for every node
v ∈ V , we deﬁne a variable xv and for every edge e ∈ E,

we deﬁne a variable ye. The optimal partition problem for
a given Hilda program P , with the annotation function A
can then be formulated as the following IP problem:

(1 − xv) ∗ M (v) ≤ ˆM

Constraints:
• xroot = 1, root is the root of KT
• ∀v ∈ V, xv ∈ {0, 1}
• ∀e ∈ E, ye ∈ {0, 1}
• ∀e(v1, v2) ∈ E xv1 ≥ xv2 and ye ≥ xv1 − xv2
• (cid:4)
• (cid:4)
ye ∗ n(e)
For each node v ∈ V and edge e = (u, v) ∈ Ecut,
c(v) = α × tv is the computing cost at client side
s(v) = tv is the computing cost at server side
M (v) = mv is the memory cost at client side
n(e) = (1/β + γ) × dv + L × lv is the data transfer cost

(1 − xv) ∗ c(v) +

(cid:4)
e∈E

(cid:4)
v∈V

Minimizing function:
xv ∗ s(v) +

v∈V

v∈V

(cid:3)

xv =

The optimal solution for above integer programming will
give us an optimal partition c = (Gs, Gc), Ecut in the fol-
lowing way:

(cid:3)

0 if v ∈ Vs
1 if v ∈ Vc

and ye =

0 if e (cid:10)∈ Ecut
1 if e ∈ Ecut

We can relax the above problem, by allowing xv ∈ [0, 1]
and ye ∈ [0, 1], and get an LP problem that is solvable in
polynomial time, with solution X∗
. We can then round each
x∗
v to 0 or 1 with a threshold uniformly randomly chosen
from [1/3, 2/3]. This special rounding technique guarantees
that the objective function and constraints are still within
a reasonable bound.

It is provable that the response time of the partition gen-
erated by our algorithm is at most three times as much as
the optimal response time obtained using LP, which is no
more than the optimal response time. The proof is omit-
ted due to space constraints. Please refer to the Technical
Report [27] for more details on the algorithm and the proof.
Note that the theoretical bound given here is a theoreti-
cal worst-case bound. In practice, we have found that the
response time obtained using our algorithm is very close to
the optimal response time for the applications that we con-
sidered in our experimental evaluation.

4. EXPERIMENTAL EVALUATION

In this section, we ﬁrst describe the setup for the experi-
ments we performed to evaluate the performance our Hilda
system (Section 4.1). We then compare the performance
of a Hilda and a J2EE implementations of a real world
application (CMS) and a technical benchmark (TPC-W).
These comparisons show the beneﬁts of automatic client-
server partitioning (Section 4.2).
4.1 Experimental Setup

We ﬁrst discuss how we estimate the annotation of a key
tree using a trace of the running application. We then de-
scribe how we apply the result of the optimization problem
to achieve a partition of the application, and we give an
overview of the physical setup for the experiments.

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications3464.1.1 Parameter Estimation

4.1.3 Physical Setup

A trace consists of a sequence of AUnit activations, along
with meta data for the time, data and number of connections
associated with each activation.
Deﬁnition 5: Let P be a Hilda program. A trace T race(P ) =
i )|1 ≤ i ≤ n(cid:12) of P is a sequence of ﬁve-tuples
(cid:11)(i, vi, ti, di, li, tγ
called events. The number i is the sequence number of the
event, vi = (aid, key) uniquely identiﬁes an AUnit instance
in P , ti is the time taken to process the queries in this in-
stance, di is sum of the size of the input and output data
for the instance, li is the number of connections established
between the client and the server, and tγ
is the time spent
to prepare the data by this instance. (cid:2)

i

Given the above deﬁnition, the annotation function of the
keytree of program P can be estimated through an aggre-
gated version of the trace. Since multiple events in the
trace may be associated with the same node v of the key
tree, we can estimate the value of v’s annotation by count-
ing and aggregating the trace data for each node. More
precisely, we estimate the annotation function for a node
v ∈ KeyT ree(P ) as follows. Let A (v) = (p, t, d, l). Then
we can estimate (p, t, d, l) with (ˆp, ˆt, ˆd, ˆl) as follows:
) ∈ T race(P )}|
) ∈ T race(P )}
,
) ∈ T race(P )}
) ∈ T race(P )}

|{i|∃(i, v(cid:4), t(cid:4), d(cid:4), l(cid:4), t(cid:4)(cid:4)
(cid:4){t|∃(i(cid:4), t, d(cid:4), l(cid:4), t(cid:4)(cid:4)
n
p × n
(cid:4){d|∃(i(cid:4), t(cid:4), d, l(cid:4), t(cid:4)(cid:4)
p × n
(cid:4){l|∃(i(cid:4), t(cid:4), d(cid:4), l, t(cid:4)(cid:4)
p × n

ˆd =

ˆp =

ˆl =

ˆt =

,

,

.

The other parameters for optimization were speciﬁed ac-
cording to the physical setup. We ran the experiments on
the PlanetLab network. Given that only powerful desktop
clients are used in PlanetLab, we assumed that the client
and the server have similar computing power. Therefore,
we set parameter α = 1, and no bound was imposed for the
memory available at the client. The bandwidth (β) of the
network was roughly 300KB, and the round trip time L was
approximated as 10ms. We could also have estimated these
parameters automatically at runtime; this is left as future
work. We also estimated γ as follows:
tγ
i
di

(cid:2)

γ =

1
n

.

i≤n

4.1.2 Partitioning Logic

The client-server partitioning for a program P is done at
the granularity of key trees. Given a cut C = (Gs, Gc) in
the key tree, we ship the data of the AUnit instances in Vc to
the client. However, note that our constructed annotation
function assumes that the future workload is very similar to
the one seen before.
In practice, the future workload can
contain AUnit instances that have never been encountered
before. Therefore, the partitioning is also done at the class
graph level, using nodes from the class graph as represen-
tatives for instances not yet seen in the trace. For unseen
instances, we will position the instance based on the com-
puted partitions for the class graph.

We illustrate the beneﬁts of Hilda using a Course Manage-
ment System and an Online Book Store application that is
based on the TPC-W benchmark. We compare the average
users’ response time, which we refer to as responsiveness,
of a Hilda implementation and a J2EE implementation of
the two applications. The applications were deployed in a
JBOSS application server setup on a 2.66Ghz machine hav-
ing 4GB of RAM, and used MS SQL 2005 as the backend
database management server. The client simulators were
deployed on the PlanetLab network, and included the Hilda
RTSC.

We measured the response time for each operation, i.e.
the time taken to submit a request, process it at the server/-
client and receive the resulting page from the server. There-
fore, this measure includes the time spent on the server to
process the request, the time spent at the client and the
network transmission time. However, we did not take into
account the time taken by the web browsers to render the
resulting HTML pages. Also, in order to reduce the error
due to the erratic nature of the PlanetLab network, the ex-
periments were conducted twice. The values we present in
the next section are therefore averages over two runs of the
simulation.
4.2 Experimental Results

We now present experimental results from two applica-

tions: a CMS and an Online Book Store.

4.2.1 Course Management System

Our ﬁrst experiments were performed on CMS, a Course
Management System developed at the Cornell Computer
Science Department which is currently in use by more than
2000 students, staﬀ and faculty [6]. The original version
of CMS was developed using traditional application devel-
opment tools such as J2EE/EJB, JavaScript and HTML,
while a new version has been developed using Hilda.

The J2EE version of the CMS was developed by experi-
enced programmers, and therefore included extensive client-
server partitioning that was done manually. Most of the
client-side application logic was implemented using JavaScript,
which allowed for web pages to be updated dynamically. For
example, features such as sorting tables based on selected
column values, showing or hiding portions of a web page,
and caching users’ input temporarily in the browser were
already implemented at the client side.

To calculate the average response time, we emulated the
operations performed on the CMS in one semester. A us-
age log consisting of 60000 operations was collected from the
J2EE version of the system, along with the necessary param-
eters. Table 1 lists the operations that the users performed.
The ﬁrst three thousand operations from this log were used
as a trace to construct the annotation function, which was
then used to compute a partition for the application. The
remaining operations were then evaluated based on the com-
puted partition. The average response time shown in Table
2 does not include the time to collect the trace. Table 2 also
presents the performance measure of the application when
it is deployed at the server without any partitioning.

It is evident from Table 2 that the Hilda version of CMS
with automatic partitioning is comparable to the J2EE ver-
sion in average response time. The automatically parti-
tioned version, however, reduces the average data trans-

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications347Operation Description
O1
O2

O3
O4

O5

O6
O7

O8

O9
O10
O11
O12
O13
O14
O15
O16
O17
O18
O19
O20
O21
O22

O23

View CMS homepage
View course management
system summary
Add/remove courses
View course property
page(as instructor)
View course property
page(as admin)
Edit course property
View course
homepage(as student)
View course
homepage(as instructor)
View student list page
View add students page
Add/edit students
Drop students
Update students ﬁnal grades
View adding assignment page
View editing assignment page
view assignment list
View assignment details
Editing assignment
View adding category page
View edit category schema page
View edit category content page
Add/remove/edit columns
in category schema
Add/remove/edit
rows of category content

Number
24994
244

18
219

83

91
7912

1858
1858
9
133
867
48
25
158
841
846
20923
497
205
120
150
103

16

Table 1: Operations in the CMS Application

System

Average Response Average Data
Time(ms)
278.80
312.64
270.01

J2EE
Server Only
Client Server
Table 2: CMS: Response Time and Data Transmission

Transmission(KB)
17.99
19.09
12.74

ferred between the client and the server by roughly 30%.

Figure 8 shows the average data transfer for each opera-
tion. Owing to the fact that caching user input at the client
reduces the amount of data transferred between the client
and the server, operations such as O3, O11, O12, O13, O14,
O19, O22, O23 that involve updates result in comparatively
less data transfer. For example, consider O3 – after the
system administrator creates a new course, the page is re-
freshed with a new list of courses. However, if the AUnit for
the course list gets pushed to the client, the page generated
at client side is able use locally cached data.

The J2EE version of the CMS allows a web browser to
cache webpages for later visit, at the page level, while the
Hilda run time system caches data at the AUnit (subpage)
level. For example, a navigation bar that is present on most
pages includes the list of available courses, and contains the
assignment and category list corresponding to each course.
After partitioning, the Hilda run time system keeps the AU-
nit instances for the navigation bar at the client, including
the data and the logic to generate HTML segments for nav-
igation bars. Such partial updating yields beneﬁts in the re-
sponse time for the operations O1, O7, O8, O16, O17, O19
and O20. The Hilda run time system also makes sure that
the data for a navigation bar (list of assignments, courses
and categories) is up to date, by periodically checking with
the server for any changes.

Bad design decisions may sometime result in suboptimal
In the J2EE version of the CMS, the logic

performance.

Figure 7: Average Response Time for Diﬀerent Operations in
CMS

Figure 8: Average Amount of Data Transmitted for Diﬀerent
Operations in CMS

for users to sort tables based on diﬀerent columns is always
pushed to the client. However, all pages in the system are
assembled dynamically, and the Javascript generated on the
ﬂy is embedded in the HTML pages. This Javascript makes
the size of pages with sortable tables very large (600K on
average).
It increases the network transmission time and
results in poor response time even compared to the Hilda
version without any partitions (Figure 7: O10, O11, O12
and O13).

4.2.2 Online Book Store

The TPC-W [10] benchmark speciﬁes an online book shop
application as the test case for evaluating application server
performance.
In this application, users can register, view
book details, manage their shopping carts and check out,
while managers can add new book details into their inven-
tory. We implemented the application using both J2EE and
Hilda, and evaluated the average response time of the two
systems using a trace synthesized according to the speciﬁ-
cations in the benchmark. In the J2EE version, we did not
implement any application logic at the client side except for
the basic HTML presentations. We took the ﬁrst 5 per-
cent of the workload as training set for the system to collect
statistics, and then measured the response time after the
application ran with the computed optimal partition for the
Hilda version with partitioning enabled.

Table 4, Figure 9 and Figure 10 show the average response
time and the average data transmission for each operation of
the application, in the J2EE version and the Hilda versions
with and without automatic partitioning. The Hilda system

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications348Operation Description
O1
O2
O3
O4
O5
O6
O7
O8
O9
O10

View website homepage
Register as new user
Add a book to product list
Register an author of a book
View book details
Add a book into shopping cart
View shopping cart details
View checkout page
Checkout
View order status

Number
118
999
2098
970
1542
4593
814
918
1799
920

Table 3: Operations in TCP-W Online Bookstore Applica-
tion

System

J2EE
Server Only
Client Server

Average Response Average Data
Time(ms)
221.80
231.88
143.48

Transmission(KB)
21.7
21.9
3.3

Table 4: Average Response Time and Data Transmission for
TPC-W

beneﬁts from activating instances of shopping cart AUnit at
the client side. A user can add the book she viewed (O5)
into the shopping cart (O6) and view the details at a later
time (O7), possibly before checkout. The shopping cart and
the details about the books in the shopping cart are cached
along with the AUnit instance, which make the add to the
cart (O6) and view detail (O7) operations locally executable,
resulting in a much better response time.

5. RELATED WORK

In recent years, many programming models and frame-
works [4, 7, 9, 11, 13] have been proposed for designing and
developing web applications. A few of these frameworks also
propose a high level programming model to develop appli-
cation logic for diﬀerent tiers of an application. Hilda takes
the further step of automating the process of client-server
partitioning using a quantitative approach.

Caching data and query results at clients is a concept that
has been studied in relational and object-oriented database
systems. Work in this area has focused on Transactional
Client-Server Cache Consistency [12, 18, 25], a technique
that evaluates part of a transaction at the client by shipping
it the required data. This work is concerned with guarantee-
ing the ACID properties of a transaction, and proposes many
diﬀerent approaches such as the Avoidance Based Approach
(Adaptive CallBack Locking) and the Detection Based Ap-

Figure 9: Average Response Yime for Diﬀerent Operations in
TPC-W

Figure 10: Average Amount of Data Transmitted for Diﬀerent
Operations in TPC-W

proach (Adaptive Optimistic Concurrency Control). How-
ever, the work assumes a predeﬁned partition of transactions
across the server and the client, and thus is complementary
to what Hilda achieves.

Hybrid Shipping Architectures have been proposed to run
queries in a distributed setting [22, 23]. The motivation be-
hind these systems is that data shipping (query execution
at clients) and query shipping (query execution at servers)
can be done together. However, these architectures only
consider the partitioning of a single read-only query. They
decompose each query into operators such as join, scan and
display etc. and then distribute these operations across dif-
ferent sites, taking into account the parallelism and commu-
nication costs. They use standard optimization techniques
to achieve this. Our goal, on the other hand, is to partition
queries in one transaction across the server and the client
and to cache data for multiple queries.

Another related area of research is Mobile Code, which
aims at transforming a centralized program into a distributed
architecture and utilizing resources in distributed systems [3,
17, 20, 24]. The system in [17] takes the binary code of
a program and distributes the components and the proce-
dures among a cluster in order to optimize the communica-
tion cost. Wang et al. address the problem of partitioning
programs in the context of mobile devices [24]. They repre-
sent a program in the form of a Task Control Flow Graph
(TCFG), i.e. a directed graph, where each node represents
a task, and each edge represents data transfer between the
tasks. Their cost model includes computation time, commu-
nication time, scheduling time, and data registration time.
They formulate the optimization problem as a parameter-
ized min-cut/max-ﬂow problem, where common parameters
include buﬀer size, input size, command-line options, etc.
The Abacus system [3] consists of a programming model
and a run-time system. The proposed programming model
encourages the programmer to develop data-intensive appli-
cations using small, functionally independent components
or objects. The run time system automates the placement
of the objects in data-intensive applications and ﬁle systems
among the nodes of a cluster. The J-Orchestra [20] system
partitions Java applications into distributed ones using Java
RMI. By rewriting the code using Java RMI, their system
can distribute components which share data in memory and
thus result in ﬁner granularity for partitioning. However,
none of this work consider the concepts of consistency and
conﬂicts for the cached table data between client and server

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications349sides. Another drawback is that the language model used
by all of this work is not declarative, and therefore the eﬃ-
cacy of the system is limited by how programmers code the
components and the procedures.

[9] S. Ceri, P. Fraternali, and A. Bongio. Web modeling
language (webml): a modeling language for designing
web sites. In Proc. the ninth International World
Wide Web Conference, 2000.

6. CONCLUSION AND FUTURE WORK

In this paper, we introduced a uniﬁed platform for data
driven web applications. The platform is based on Hilda,
a high level declarative language that allows dynamic par-
titioning of the web application between the client and the
server in a manner that is completely transparent to the
developer. This automatic partitioning helps in avoiding
manual application partitioning decisions, which can be ad
hoc and suboptimal. Based on the observed workload, the
Hilda run time system determines a client-server partition
of the application, which is close to the optimal partition,
using a quantitative method. We also illustrated the ben-
eﬁts of Hilda and automatic client-server partitioning by
comparing it with J2EE, using two web applications — a
Course Management System with a real workload and an
Online Book Store with a benchmark workload. We showed
that the performance of the CMS is comparable for both
Hilda and J2EE, and that Hilda gains on the amount of data
transferred between the client and the server. The TPC-W
benchmark Online Book Store illustrated a 35 percent im-
provement in response time for Hilda over a corresponding
J2EE implementation.

There are several avenues for future work. The current
Hilda optimization model treats each user operation inde-
pendently, but does not take into account the client side op-
erations performed by the users. Interesting techniques such
as asynchronous prefetching and anticipating user actions to
prefetch data are not supported. The optimization goal cur-
rently focuses only on improving a user’s experience and the
system’s response time. It would be interesting to consider
other goals for optimization, such as system throughput by
automating load balancing at server side.

7. REFERENCES
[1] Adobe ﬂash.

http://en.wikipedia.org/wiki/Macromedia Flash.

[2] Asynchronous javascript and xml.

http://en.wikipedia.org/wiki/Ajax (programming).

[3] K. Amiri et al. Dynamic function placement for

data-intensive cluster computing. In USENIX 2000
Annual Technical Conference, San Diego, CA, June
2000., pages 307–322, 2000.

[4] A. Bongio, S. Ceri, P. Fraternali, and A. Maurino.

Modeling data entry and operations in webml. In The
World Wide Web and Databases (WebDB, Selected
Papers), pages 201–214, 2000.

[5] G. Booch et al. The Uniﬁed Modeling Language User
Guide,The Addison-Wesley Object Technology Series.
Addison Wesley, 1998.

[6] C. Botev et al. Supporting workﬂow in a course

management system. In Proc. SIGCSE, 2005.

[7] M. Brambilla et al. Declarative speciﬁcation of web

applications exploiting web services and workﬂows. In
Proc. SIGMOD, pages 909–910, 2004.

[8] V. Cardellini, M. Colajanni, and P. S. Yu. Dynamic

load balancing on web-server systems. IEEE Internet
Computing, 3(3):28–39, 1999.

[10] T. W. Commerce. Tpc benchmark

http://www.tpc.org/tpcw/.

[11] E. Cooper, S. Lindley, P. Wadler, and J. Yallop.

Links: Web programming without tiers. In Submitted
to ESOP 2007.

[12] M. J. Franklin, M. J. Carey, and M. Livny.

Transactional client-server cache consistency:
alternatives and performance. ACM Trans. Database
Syst., 22(3), 1997.

[13] P. Fraternali. Tools and approaches for developing

data-intensive web applications: A survey. ACM
Computing Surveys, 31(3):227–263, 1999.

[14] N. Gerner et al. Automatic clientserver partitioning of
data driven web applications. In Proc. SIGMOD, 2006.

[15] A. Hayrapetyan, D. Kempe, M. P´al, and Z. Svitkina.

Unbalanced graph cuts. In European Symposium on
Algorithms (ESA), Mallorca, Spain, 2005.

[16] http://java.sun.com/j2se/1.4.2/docs

/guide/plugin/developer guide/applet caching.html.

[17] G. C. Hunt and M. L. Scott. The coign automatic

distributed partitioning system. In Operating Systems
Design and Implementation, pages 187–200, 1999.

[18] M. Ozsu, K. Voruganti, and R. Unrau. An

asynchronous avoidance-based cache consistency
algorithm for client caching dbmss, 1998.

[19] R. Ramakrishnan and J. Gehrke. Database

Management Systems. McGraw-Hill, 3 edition, 2003.

[20] E. Tilevich and Y. Smaragdakis. J-orchestra:

Automatic java application partitioning. European
Conference on Object-Oriented Programming
(ECOOP), Malaga, June 2002.

[21] V. V. Vazirani. Approximation Algorithms.

Springer-Verlag, Berlin, 2001.

[22] K. Voruganti, M. T. Ozsu, and R. C. Unrau. An

adaptive hybrid server architecture for client caching
ODBMSs. In The VLDB Journal, pages 150–161,
1999.

[23] K. Voruganti, M. T. ¨Ozsu, and R. C. Unrau. An

adaptive data-shipping architecture for client caching
data management systems. Distrib. Parallel
Databases, 15(2):137–177, 2004.

[24] C. Wang and Z. Li. Parametric analysis for adaptive
computation oﬄoading. In PLDI ’04: Proceedings of
the ACM SIGPLAN 2004 conference on Programming
language design and implementation, 2004.

[25] K. Wu, P. fei Chuang, and D. J. Lilja. An active

data-aware cache consistency protocol for
highly-scalable data-shipping dbms architectures. In
CF ’04: Proceedings of the 1st conference on
Computing frontiers, 2004.

[26] F. Yang et al. Hilda: A high-level language for

data-driven web applications. In Proc. ICDE, 2006.

[27] F. Yang et al. A uniﬁed platform for data driven web
applictions with automatic client-server partitioning.
Technical report, Cornell University, 2007.
http://techreports.library.cornell.edu.

WWW 2007 / Track: Performance and ScalabilitySession: Performance Engineering of Web Applications350