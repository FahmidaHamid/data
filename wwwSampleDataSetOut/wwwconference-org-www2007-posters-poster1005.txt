U-REST: An Unsupervised Record Extraction SysTem

MIT Computer Science and Artiﬁcial Intelligence

MIT Computer Science and Artiﬁcial Intelligence

32 Vassar Street, Cambridge MA, 02139 USA

32 Vassar Street, Cambridge MA, 02139 USA

Yuan Kui Shen

Laboratory

yks@csail.mit.edu

David R. Karger

Laboratory

karger@csail.mit.edu

ABSTRACT
In this paper, we describe a system that can extract record
structures from web pages with no direct human supervi-
sion. Records are commonly occurring HTML-embedded
data tuples that describe people, oﬀered courses, products,
company proﬁles, etc. We present a simpliﬁed framework
for studying the problem of unsupervised record extraction
– one which separates the algorithms from the feature en-
gineering. Our system, U-REST formalizes an approach to
the problem of unsupervised record extraction using a simple
two-stage machine learning framework. The ﬁrst stage in-
volves clustering, where structurally similar regions are dis-
covered, and the second stage involves classiﬁcation, where
discovered groupings (clusters of regions) are ranked by their
likelihood of being records. In our work, we describe, and
summarize the results of an extensive survey of features for
both stages. We conclude by comparing U-REST to related
systems. The results of our empirical evaluation show en-
couraging improvements in extraction accuracy.

Categories and Subject Descriptors
H.3.m [Information Systems]: Miscellaneous

General Terms
algorithms, experimentation

Keywords
record extraction, clustering

1.

INTRODUCTION

Records are data tuples wrapped in HTML. On the web,
records are presented as collections of consistently formatted
HTML snippets. They manifest in list pages such as search
results, course catalogues, or directory listings. While there
are many types of records (nested records, tree records, etc.),
our focus is on ﬂat records: records characterized as having
an ordered set of ﬁelds corresponding to the columns of an
underlying data source (such as a database table). Given a
list page P , the task of record extraction is to return the set
of regions C = r1 . . . rn that best matches a human labelled
reference set, L. When this task is accomplished without

Copyright is held by the author/owner(s).
WWW 2007, May 8–12, 2007, Banff, Alberta, Canada.
ACM 978-1-59593-654-7/07/0005.

any human supervision, we call it unsupervised record ex-
traction (URE). The supervised variant of this problem has
been studied extensively. For instance, most recently, Hogue
et al [2] demonstrated the use of a tree model to represent
the extraction pattern. In general, supervised methods use
learning techniques to induce an extraction pattern from a
set of labelled examples. Because records repeat it is intu-
itive to think that simply searching for repetitions should aid
in ﬁnding record instances. However not all repetitions are
records. Some repetitions are composed of parts of records
(ﬁelds), other constitute collection-of-records, and yet oth-
ers come from formatting regularities that serve functions
such as navigation or advertising. Hence, the URE task is
diﬃcult because there are diﬀerent types of repetitions, and
repetitions are often noisy. Several recent works have tried
to tackle the URE problem. Omini [1] searched for record
separator tags between contiguous record instances, pos-
ing the problem as one of segmentation. MDR/DEPTA [5]
compared successive groups of subtrees and returned similar
groupings as record regions. ViNT [6] utilized visual hints,
content lines, as record identiﬁcation features. However, lit-
tle attention has been devoted to how features independently
aﬀect the system accuracy. Our work uses known machine
learning techniques and survey some simple features to gain
a clearer insight into the importance of features in the URE
task.

2. SYSTEM OVERVIEW

The input to U-REST is a record-containing list page, the
output is a set of potential record instances (record sets).
List pages are ﬁrst converted into a tag tree. A tag tree (or
DOM) has a node for each open and close HTML tag pair.
Each subtree of the page tag tree represents a distinct con-
tinuous (visible) region (or a block) on the web page. Any
single subtree or set of adjacent subtrees (sibling subtrees)
can represent a potential record instance. Our task is to
return the sets of subtrees (or sibling subtrees) that best
correspond to records.

During U-REST’s pattern discovery phase, the page DOM
is decomposed into constituent subtrees. Those subtrees
that are clearly non-records: root of the page or non-content-
bearing leaf nodes (e.g. <BR> tags) are removed. The re-
sulting subtrees undergo clustering, using HAC (hierarchical
agglomerative clustering). The goal of clustering is to ﬁnd
salient structural repetitions. HAC iteratively merges the
closest two points (trees or clusters of trees). The HAC clus-
tering metric determines the threshold at which the merging
process terminates. We designed this metric as a tree-pair-

WWW 2007 / Poster PaperTopic: XML1347wise similarity function: φ(Ti, Tj) : hφ1(Ti, Tj), . . . , φn(Ti, Tj)i
→ {0, 1}, φ is 1 if the pair is similar enough to be in the same
cluster (0 otherwise). φ is a trained classiﬁer deﬁned by its
vector of features over tree pairs. In our experiments, a lin-
ear kernel SVM was found to be the most eﬀective. We also
surveyed an extensive set of features [4] (some top perform-
ing ones are noted in table 1). Using feature selection, we
found a three-optimal combination: 1) Tree edit-distance -
using the standard polynomial time tree-edit distance algo-
rithm compute the optimal alignment between two (ordered
labelled) trees; the edit distance score is the count of the
matching nodes in the optimal alignment. 2) Tree context
- also an edit distance metric but applied on the tag path,
the tag label sequence from the subtree to the root of the
page. 3) Tri-gram model - models the tree as a vector of la-
bel triplets: the label of the root, the ith child, and (i + 1)th
child. Our results show that preserving the structural order
of trees is critical when comparing trees: tree-edit distance
predominates all n-gram based metrics. After clustering,

Feature
Tree-Edit-Distance
Tree Context
Parent-Child-
Child (3-gram)
2-gram
1-gram

recall
0.98458
0.90909
0.98582

precision
0.92731
0.66714
0.39688

f-score
0.94985
0.73903
0.50056

0.90926
0.90939

0.34137
0.26980

0.41022
0.33532

Table 1: Summary of top φi features. Reported here
are test recall/precision values for classiﬁers trained and
tested on 10000+ tree pairs extracted from ten list pages.

the discovered clusters contain non-record as well as record
repetitions; non-record types include: ﬁelds, collections of
records, decorative blocks, or navigational content. To dif-
ferentiate record from these non-record clusters, we designed
a record cluster classiﬁer, modeled as a function over clus-
ters: ψ(Ci) : hψ1(Ci), . . . , ψn(Ci)i → [0, 1]. ψ assigns the
most record-like cluster the highest score. Our feature sur-
vey and feature selection work [4] yielded three classes of
features that performed well in this subtask. 1) Contigu-
ity is the amount of content interleaved between record in-
stances; intuitively, record instances that are close to each
other should have very little content in between instances.
This feature aids in diﬀerentiating ﬁelds from records. 2)
Content coverage is the page-relative ratio of content that
(the members of) a cluster occupy; the higher content cover-
age, the more importance that cluster adds to the page. This
feature diﬀerentiates navigational content from records. 3)
Variation is the measure of the mean formatting diversity
under each subtree. Record clusters have high variation be-
cause each instance contains ﬁelds, and adjacent ﬁelds are
usually formatted diﬀerently. Visually, individual record in-
stances appear heterogeneously formatted, but collections of
records appear homogenously formatted (For more details
see [4]). An SVM trained on features from these three classes
produces an optimal ψ; the system returns the highest ψ
scoring cluster as the record cluster.

3. EVALUATION AND RESULTS

We compared the record sets extracted by U-REST, Omini
and MDR [3] with a reference human-labelled record set.
The evaluation metric (reported in Table 2) is the number

System
U-REST
Omini
MDR
Best Possible
Baseline

#correct (/62)

29
22

14/54

37
9

%

46.8
35.5
25.9
59.7
14.5

Table 2: System performance comparison with cluster
quality at f-score ≥ 0.75. Baseline ranks clusters based on
their content coverage; Best-possible presupposes that
an oracle has selected the best cluster after clustering
(the upper limit imposed by clustering quality).

of pages correctly labelled at or above a ﬁxed f-score1. Our
evaluation metric diﬀers from those reported by Omini or
MDR because the metric is not an average of f-scores over
record instances but the number of pages for which the sys-
tems achieved a ﬁxed extraction quality. This evaluation
method is more useful as it guarantees a base level of ac-
curacy for the system. Manual analysis of Omini/MDR
results shows that the mis-identiﬁcation of record collec-
tions as records is one of key causes of system errors. The
variation feature introduced in our work helped diﬀerentiate
much of the record-collection cases.

4. CONCLUSION

We demonstrated a simple two stage model URE system:
U-REST. In the pattern detection subtask, we found that
order-preserving features such as tree edit distance outper-
formed approximations such as n-gram models when com-
paring pairs of subtrees (for clustering). In the record cluster
detection subtask, we found that a combination of varia-
tion, contiguity, and content coverage features produced the
most accurate results. Our results show that features play
a strong role in the ﬁnal performance of an URE system;
by simply optimizing features and feature selection, we can
gain accuracy while maintaining system simplicity2.

5. REFERENCES
[1] D. Buttler, L. Liu, and C. Pu. A fully automated

extraction system for the world wide web. In IEEE
ICDCS-21, April 2001.

[2] A. Hogue and D. Karger. Thresher: Automating the
unwrapping of semantic content from the world wide
web. In WWW 2005 Conference, 2005.

[3] B. Liu, R. Grossman, and Y. Zhai. Mining data records

in web pages. UIC Technical Report, 2003.

[4] Y. K. Shen. Automatic record extraction from the

world wide web. Master’s thesis, MIT, 2005.

[5] Y. Zhai and B. Liu. Web data extraction based on

partial tree alignment. In WWW ’05: Proceedings of
the 14th international conference on World Wide Web,
pages 76–85, New York, NY, USA, 2005. ACM Press.
[6] H. Zhao, W. Meng, Z. Wu, V. Raghavan, and C. Yu.

Fully automatic wrapper generation for search engines,
2005.

p+r , where p =

1f-score = 2pr
2Thanks to Alex Gruenstein, Ali H. Mohammad, Boris Katz for
their helpful comments on this paper.

and r =

|C∩L|
|C|

|C∩L|

|L|

WWW 2007 / Poster PaperTopic: XML1348