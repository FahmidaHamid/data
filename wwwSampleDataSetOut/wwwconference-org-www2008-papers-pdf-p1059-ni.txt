Dissemination of Heterogeneous XML Data

∗
Yuan Ni

IBM China Research Lab
niyuan@cn.ibm.com

Chee-Yong Chan

National University of Singapore
chancy@comp.nus.edu.sg

ABSTRACT
A lot of recent research has focused on the content-based
dissemination of XML data. However, due to the heteroge-
neous data schemas used by diﬀerent data publishers even
for data in the same domain, an important challenge is
how to eﬃciently and eﬀectively disseminate relevant data
to subscribers whose subscriptions might be speciﬁed based
on schemas that are diﬀerent from those used by the data
publishers. This paper examines the options to resolve this
schema heterogeneity problem in XML data dissemination,
and proposes a novel paradigm that is based on data rewrit-
ing. Our experimental results demonstrate the eﬀectiveness
of the data rewriting paradigm and identiﬁes the tradeoﬀs
of the various approaches.

Categories and Subject Descriptors
H.4.m [Information Systems]: Systems-Query processing

General Terms
Algorithms, Design, Performance

Keywords
data rewriting, dissemination, heterogeneous, XML

1.

INTRODUCTION

The ubiquity of XML data and the eﬀectiveness of the
content-based pub/sub-based paradigm of delivering rele-
vant information has led to a lot of interest in content-based
dissemination of XML data (e.g., [1]).
Existing work on
XML data dissemination, however, are all implicitly based
on a homogeneous schema assumption where both the data
published by diﬀerent publishers as well as the users’ sub-
scriptions share the same schema. However, since the data
publishers in a pub/sub system are autonomous and inde-
pendent, they generally do not use the same schemas even
when their published data are related and belong to the same
domain (e.g., product catalogues). Consequently, if a user’s
subscription is based on the schema of a speciﬁc publisher
(say P ), then while the user can receive relevant documents
∗
University of Singapore

The work was done while the author was at the National

Copyright is held by the author/owner(s).
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

from P that match his subscription, it is very likely that
his subscription will not match relevant data from another
publisher P (cid:2)
are dif-
ferent. Thus, the eﬀectiveness of the pub/sub systems in
pushing relevant data to consumers becomes diminished in
the presence of heterogeneous data schemas.

if the data schemas used by P and P (cid:2)

In this paper, we address the problem of how to improve
the eﬀectiveness of XML data dissemination in the presence
of heterogenous data schemas. Our problem, referred to as
heterogeneous data dissemination problem, can be stated as
follows. We consider a pub/sub system where data published
by diﬀerent publishers are based on diﬀerent schemas. The
problem is how to eﬀectively disseminate a document (based
on some publisher’s schema S) to relevant subscribers whose
subscriptions might be based on schemas diﬀerent from S.
For simplicity and without loss of generality, we assume that
all the published data are of the same domain such that it
is possible to use a single global schema to resolve the struc-
tural conﬂicts among diﬀerent publishers’ schemas (of the
same domain). Our problem and proposed techniques can
be easily extended to the general case by ﬁrst partitioning
the collection of publishers’ schemas into groups of schemas
with similar domains, and then generating a global schema
for each group of related schemas.

The well-known data integration problem[3] handles the
problem about how to query multiple data sources with
diﬀerent schemas by adopting a query rewritten based ap-
proach (QRA). However, a fundamental diﬀerence exists
between the data integration problem and our heteroge-
neous data dissemination problem, which is that the inte-
gration problem belongs to a single-query-multiple-data sce-
nario while the dissemination problem belongs to a single-
data-multiple-queries scenario. To adopt the QRA in the
heterogeneous data dissemination problem would incur a
scalability problem as each input subscription needs to be
rewritten into one subscription for each local schema. This
increases the space overhead for storing and indexing the
expanded set of local subscriptions at each router since the
number of subscriptions on each router is large.

In this paper, we present a novel paradigm to solve the
heterogeneous data dissemination problem that is based on
the principle of data rewriting. We refer to our new approach
as DRA for data rewriting approach. The conceptual idea
of DRA is as follows. Firstly the collection of local schemas
from the publishers is integrated to form a global schema Sg
which is then made available to users to specify their sub-
scriptions. Unlike QRA, our DRA does not require query
rewriting which means that only the input global subscrip-

1059WWW 2008 / Poster PaperApril 21-25, 2008 · Beijing, Chinations are indexed at each router. For each incoming data D(cid:2)
(conforming to some local schema S(cid:2)) to a router, our DRA
rewrites D(cid:2) to Dg (Dg may not be materialized here) such
that the evaluation of subscriptions is actually conducted
against Dg.

In contrast to QRA, our proposed DRA is more eﬀective
for the heterogeneous data dissemination problem because
pub/sub systems are typically characterized by two proper-
ties : (1) the number of subscriptions at each router is large
(which limits the scalability of QRA); and (2) the data being
disseminated is relatively small (which incurs only a small
processing overhead for data rewriting).

2. DATA REWRITING FRAMEWORK

This section presents our framework to solve the heteroge-
neous data dissemination problem by using data rewriting.
2.1 System Architecture

We use S(cid:2) to denote some publisher’s local schema, and
Sg to denote a global schema integrated from a collection of
local schemas of the same domain. We use D(cid:2) (resp., Dg)
to denote a document conforming to schema S(cid:2) (resp. Sg).
Similar to existing pub/sub systems, we have a mediator
agent (MA) that serves as a coordinator between the data
publishers and routers [2]. Besides collecting schemas from
publishers and registering queries for users, the MA is also
responsible for resolving the structural conﬂicts among vari-
ous schemas to generate a global schema. The MA creates a
schema mapping for each local schema S(cid:2) that is integrated
to a global schema Sg. The schema mapping is essentially a
data transformation speciﬁcation that enables an input doc-
ument D(cid:2) to be mapped into an output document Dg that
preserves the appropriate information content of D(cid:2).
2.2 Data Rewriting Approaches

2.2.1 Static Data Rewriting (SDR)

In the static data rewriting (SDR) approach, each pub-
lished data D(cid:2) is rewritten to Dg statically (but only once)
by the mediator agent (denoted as MA). The advantage of
employing the MA to rewrite the data is that the publish-
ers are shielded from the details of the schema mappings and
rewriting processing; this requires each publisher to ﬁrst for-
ward D(cid:2) to the MA for the rewriting before the MA forwards
the transformed data to the routers for dissemination.

Once D(cid:2) has been rewritten to Dg, both D(cid:2) and Dg are
forwarded together to the network of routers for dissemina-
tion. Since the subscriptions stored in each router are based
on the global schema Sg, Dg is used for matching against
the subscriptions to detect matching subscriptions and de-
cide to which router(s) the data needs to be forwarded next;
D(cid:2) (possibly with an attached digital signature for veriﬁca-
tion of data integrity) is forwarded to any matching local
subscribers at a router.

One advantage of SDR is that it is a non-intrusive ap-
proach that can be easily implemented. However, the trade-
oﬀ is that the amount of data that is being forwarded is
roughly doubled compared to the conventional approach.

2.2.2 Dynamic Data Rewriting (DDR)

To avoid the transmission overhead of SDR, an alterna-
tive strategy is for each router to forward only D(cid:2) but the
tradeoﬀ is that each router now needs to rewrite the data

D(cid:2) dynamically. We refer to this approach as dynamic data
rewriting (DDR) approach. Note that DDR does not mod-
ify D(cid:2) and also does not physically materialize Dg. Instead,
the rewriting of D(cid:2) to Dg is performed dynamically as D(cid:2)
is being parsed. Speciﬁcally, the parsed events from D(cid:2) are
used to generate parsed events corresponding to Dg which
are matched against the subscriptions, and D(cid:2) is then for-
warded to any matching routers/subscribers.

We have proposed two dynamic data rewriting approaches

based on where the data rewriting is performed.
NDDR. The ﬁrst option is to perform the rewriting outside
of the matching engine by installing a new software compo-
nent, called the data rewriter, between the document parser
and matching engine. The data rewriter essentially rewrites
D(cid:2) to Dg by intercepting the sequence of events E(cid:2) that is
generated by the event-based XML parser (as it parses the
input document D(cid:2)) and generating a modiﬁed sequence of
events Eg to the matching engine such that Eg is equiva-
lent to the sequence of events generated by parsing Dg. We
refer to this approach as non-intrusive dynamic data rewrit-
ing (NDDR) approach since it does not require making any
changes to the existing XML parser and matching engine
components. The implementation of NDDR requires addi-
tional memory to cache some parsed events.
IDDR. The second option is to rewrite the data within the
matching engine itself. We refer to this approach as intru-
sive dynamic data rewriting (IDDR) approach as it entails
making modiﬁcations to the matching engine. The IDDR
approach avoids the using of additional memory, however it
makes the matching more complicated.

3. DISCUSSIONS

Based on our experimental results, we have the following
observations on the eﬃciency of various approaches. First,
SDR does not perform well due to the transmission of addi-
tional data, especially when the bandwidth is small or the
number of hops to subscribers is large. IDDR does not scale
well as the number of subscriptions or the size of documents
increases due to its more complicated matching engine. Fi-
nally, our experiments show that NDDR overall achieves the
best performance. Moreover, the memory space that NDDR
incurs for the dynamic data rewriting is small: among the
set of documents we experimented, the maximum memory
overhead of NDDR is about 32% of the document size, and
only three of the documents actually require memory space
overhead of over 20% of the document size. For the major-
ity of the documents, the memory space overhead is only
around 5% of the document size. Since the size of the doc-
uments in data dissemination is usually small, the memory
space overhead of NDDR is small which makes NDDR an
attractive approach.

4. REFERENCES
[1] C.-Y. Chan, P. Felber, M. Garofalakis, and R. Rastogi.

Eﬃcient ﬁltering of XML documents with XPath
expressions. VLDB, 11(4), 2002.

[2] Y. Diao, S. Rizvi, and M. J. Franklin. Towards an

internet-scale XML dissemination service. In VLDB,
2004.

[3] I. Manolescu, D. Florescu, and D. Kossmann.

Answering XML queries over heterogeneouse data
sources. In VLDB, 2001.

1060WWW 2008 / Poster PaperApril 21-25, 2008 · Beijing, China