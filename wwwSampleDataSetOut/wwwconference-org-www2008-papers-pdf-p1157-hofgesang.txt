Online Change Detection in Individual Web User Behaviour

Peter I. Hofgesang

hpi@few.vu.nl

Jan Peter Patist
jpp@few.vu.nl

VU University Amsterdam, Department of Computer Science
De Boelelaan 1081A, 1081 HV Amsterdam, The Netherlands

ABSTRACT
Based on our ﬁeld studies and consultations with ﬁeld ex-
perts, we identiﬁed three main problems that are of key
importance to online web personalization and customer re-
lationship management: 1) detecting changes in individual
behaviour, 2) reporting on user actions that may need spe-
cial care, and 3) detecting changes in visitation frequency.

We propose solutions to these problems and experiment
on real-world data from an investment bank collected over
1.5 years of web traﬃc. These solutions can be applied on
any domains where individuals tend to revisit the website
and can be identiﬁed accurately.

Categories and Subject Descriptors
E.1 [Data]: Data Structures - Trees; H.2.8 [Database Man-
agement]: Data Mining

General Terms
Algorithms, Experimentation

Keywords
Incremental Web Mining, User Proﬁling, Change Detection

1.

INTRODUCTION

Web personalization techniques allow companies to cus-
tomize their web services according to their customer’s needs.
However, changing customer behaviour and frequent struc-
tural changes and content updates of websites are likely to
impair the underlying models. Current personalization tech-
niques require periodic updates and human interaction to
cope with this problem and thus maintain up-to-date per-
sonalization. To automate this process, we need to identify
points of change (see e.g.
[1]) in user behaviour automati-
cally as the data ﬂows in. Identifying such changes - whether
they are seasonal or temporal, or a long-term behavioural
trend shift - and promptly taking appropriate action in re-
sponse leverages business advantage.

During our analysis of numerous web usage datasets, in-
cluding data from online retail shops and an online bank,
we identiﬁed three main problems that we summarize in the
following three goals:

Copyright is held by the author/owner(s).
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

Goal 1: Detect changes in individual behaviour A
solution to this problem should include incremental mainte-
nance of a compact user proﬁle for each individual and the
output of changes. Change signals can be used to update
personalized content or for marketing actions while the base
proﬁles can help selecting the proper personalized content.
Goal 2: Report ”interesting” sessions From time
to time online users may not be able to ﬁnd some content
or they may have technical diﬃculties. The idea behind
the second problem is to identify such points, ”interesting”
sessions, in a stream of user actions. Based on such alerts,
an assistant may oﬀer instant online help (e.g. chat or voice
call) or the system may take prompt automated action.

Goal 3: Detect changes in user activity Detecting
changes in an individual’s visitation frequency seems to re-
late to our ﬁrst problem; however, it requires diﬀerent treat-
ment both technically and in the types of output alert. For
example, early identiﬁcation of a decrease in an individual’s
visitation frequency may support actions for customer re-
tention. Based on the diﬀerent types of change in visitation
frequency, we may label changes as ”runner up” or ”slower
down” based on the increase or decrease in frequency.

The contribution our work makes is the identiﬁcation of
three relevant problems in individual, on-the-ﬂy web per-
sonalization and their proposed space and computationally
eﬃcient solutions.

2.

INDIVIDUAL USER PROFILES

We choose to use a tree-like structure to represent user
proﬁles. Each node may contain more than one page id, a
frequency counter, a reference to its parent and a vector of
references to its children.

Adding a session (we keep visited pages as sets, dis-
carding order and cardinality information) to a proﬁle tree
can be broken down as a simpler recursive procedure. The
procedure is called, in each step, by a given tree node n and
the remaining pages to be inserted, P . As a ﬁrst step, we
select the children of n that have the highest overlap with
P . If there are more nodes with equal, non-zero overlap we
If P has no overlap with any of the
select the ﬁrst one.
children nodes we insert P as a new node under n. Other-
wise, we identify the type of overlap. In case the children
node is equivalent to P or is fully part of P , we increase the
counter of the children and invoke another recursive step on
the children node and the non-overlapping remainder of P .
In the other two cases, we need to split the children node
by subtracting and raising the overlap directly above it as a
new parent node, update the frequency counters and insert

1157WWW 2008 / Poster PaperApril 21-25, 2008 · Beijing, Chinathe non-overlapping part, if there is any, as a new children
node under the newly created node of common pages.

In our methods, we maintain the proﬁles over a sliding
window. This can be easily done by maintaining references
to leaf nodes in the tree in a ”round” vector.

Here we deﬁne a distance metric over a proﬁle tree and
an incoming session (S). In fact, we deﬁne a similarity met-
ric and we transform a distance by dist = 1 − sim. The
similarity measure basically selects a branch with the high-
est overlap to the input session and calculates a score on
it. Once again, we can deﬁne this metric recursively as each
node returns the number of its overlapping pages with the
subset of pages it received plus the total overlap on the re-
mainder of pages returned from its children nodes. Each
recursive step also returns a subscore and, among identical
overlaps, we return the highest score as similarity. We cal-
culate the scores at each node by taking the minimum of
the normalised node frequency ( n.f requency
) and the page
probability (normP ). Both norms are known upfront to the
algorithm. normT is simply the number of pages added to
the tree and normP = 1/|S|.

normT

3. CHANGE DETECTION FRAMEWORK
Goal 1: Detect changes in individual behaviour A
user proﬁle is maintained for each individual and compared,
with a window of most recent sessions. First, the tree is
initialized with n sessions. The score of an incoming session
is calculated using the distance function deﬁned in Section
If the session is not an outlier (score < toutlier), it is
2.
added to a buﬀer (ref ), excluding the last m scores, which
are kept in a buﬀer W . A change is detected when the dis-
tance (d) between the most recent scores (W ) and ref is
larger than a threshold, Tchange. The distance is deﬁned as
wW ecdfref (w), where ecdf (x) is the empiri-
d(ref, W ) =
cal cumulative distribution function of ref . If we maintain
the ecdfref using a balanced tree algorithm, the complexity
of the algorithm is O(log(|ref|)) and the distance function,
dist, can be calculated eﬃciently as well.

(cid:2)

Goal 2: Report ”interesting” sessions The prob-
lem of ﬁnding ”interesting” sessions is rather subjective and
cannot be clearly formulated. We choose to rate pages as
”highly interesting” when they are popular for a speciﬁc indi-
vidual but rarely visited by others. Interesting sessions are
those containing interesting pages. We consider only out-
lier sessions (calculated in Goal 1) as potential interesting
sessions. We calculate a new score over the outlier session
based on an automatically maintained popularity matrix.
The components of this matrix are weights calculated by
the T F − IDFi,j = ni,j(cid:3)
|{dj :ti∈dj}| weighting applied
to our data, where i refers to a term (web pages) and j to
documents (individual sessions) and nij is the number of
occurrences of term i in document j. We label a session as
interesting if its overall score is higher than a user-deﬁned
threshold.

k nk,j

|D|

log

Goal 3: Detect changes in user activity While the
ﬁrst two problems, Goals 1 and 2, can be included in a com-
mon framework, we need another layer of data abstraction
and a diﬀerent system for the third problem. The prob-
lem at hand is detecting change in a stream of binary data
representing whether the user was active on a given day.
Our algorithm is based on the CUSUM (cumulative sum)
algorithm [3] and we model the probability density func-

c

(cid:3)

tion (pdf ) of the data by the poisson distribution. For a
given user we incrementally estimate the probability ˆp of
visitation on a given day. The estimate ˆp is compared to
h alternatives palt via the Sc =
) sums, where
t is the last change point and c is the current time. Each
Sc, for every h, is maintained incrementally. The h alter-
natives are ﬁxed upfront. Given that ˆp is more likely than
the alternatives, Sc has a downward trend. An increasing
Sc indicates a change in the trend and a change is detected
if Sc − mint...c Sc > Talarm. The complexity is linear in the
number of alternatives, which is O(|H1|) per session.

t log( palt

pdf ˆp

4. EXPERIMENTAL RESULTS

Our experiment included results on server-side web ac-
cess log data of an investment bank collected over a 1.5-
year period. To evaluate our change detection methods,
we randomly selected two sets each of 200 individuals with
their sessions, and labelled them together with ﬁeld experts.
We looked at the individual sessions evolving over time and
marked the points of change.

Goal 1: evaluation The accuracy of our method is
69.57% with 67 false alarms and the mean detection latency
is 5.12 sessions.

Goal 2: evaluation While experimenting with the TF-
IDF scoring, we found that the high popularity of a relatively
few pages among all individuals resulted in extreme high
term frequency (T Fi,j) components that overweighed the
IDFi,j scores and, even though popular pages were present
in most proﬁles, their ﬁnal T F − IDFi,j scores were much
higher for common pages than the much more interesting
rare pages. To avoid the eﬀect of the power law distribution
of web pages, we ignored the T Fi,j weight and used only the
IDFi,j component in ﬁnal scoring.

Goal 3: evaluation The accuracy of our method is
77.36% with 117 false alarms, and the mean detection la-
tency is 6.37 days.

Figure 1 shows an example of score evolution and change
detection both for Goal 1 and Goal 3. For more experimental
results we refer the reader to [2].

1

0

−2

−3

s
e
r
−1
o
c
s
 
e
g
n
a
h
C

−8

−7

−4

−5

−6

−9
0

50

 Change score
 Change point
 Change detected

2.5

2

1.5

1

0.5

s
e
r
o
c
s

 

e
g
n
a
h
C

 User activity data
 Change score
 Change detected
 Change point

100

150

Sessions over time

250

300

200

350

400

0
0

20

60

80

40

User activity over time

100

120

140

160

180

Figure 1: Example Goal 1 (left) and Goal2 (right):
Score evolution and change detection for individuals

5. REFERENCES
[1] M. Basseville and I. V. Nikiforov. Detection of Abrupt
Changes - Theory and Application. Prentice-Hall, Inc.,
1993.

[2] P. I. Hofgesang and J. P. Patist. Online change

detection in individual web user behaviour. In http: //
www. few. vu. nl/ ~hpi/ papers/ IndivChangeDet. pdf .
Technical Report, Vrije Universiteit Amsterdam, 2007.

[3] E. Page. On problems in which a change in a parameter

occurs at an unknown point. Biometrika, 44:248–252,
1957.

1158WWW 2008 / Poster PaperApril 21-25, 2008 · Beijing, China