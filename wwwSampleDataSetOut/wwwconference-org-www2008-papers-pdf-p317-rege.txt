Graph Theoretical Framework for Simultaneously

Integrating Visual and Textual Features for Efﬁcient Web

Image Clustering

Manjeet Rege

Ming Dong

Machine Vision Pattern Recognition Lab

Jing Hua

Graphics and Imaging Lab

Department of Computer Science, Wayne State University

Detroit, MI 48202, USA

{rege, mdong, jinghua}@wayne.edu

ABSTRACT
With the explosive growth of Web and the recent develop-
ment in digital media technology, the number of images on
the Web has grown tremendously. Consequently, Web image
clustering has emerged as an important application. Some of
the initial eﬀorts along this direction revolved around clus-
tering Web images based on the visual features of images
or textual features by making use of the text surrounding
the images. However, not much work has been done in us-
ing multimodal information for clustering Web images. In
this paper, we propose a graph theoretical framework for
simultaneously integrating visual and textual features for
eﬃcient Web image clustering. Speciﬁcally, we model visual
features, images and words from surrounding text using a
tripartite graph. Partitioning this graph leads to clustering
of the Web images. Although, graph partitioning approach
has been adopted before, the main contribution of this work
lies in a new algorithm that we propose - Consistent Isoperi-
metric High-order Co-clustering (CIHC), for partitioning the
tripartite graph. Computationally, CIHC is very quick as it
requires a simple solution to a sparse system of linear equa-
tions. Our theoretical analysis and extensive experiments
performed on real Web images demonstrate the performance
of CIHC in terms of the quality, eﬃciency and scalability in
partitioning the visual feature-image-word tripartite graph.

Categories and Subject Descriptors
I.5.3 [Pattern Recognition]: Clustering-algorithms

General Terms
Algorithms, Performance, Experimentation, Theory.

1.

INTRODUCTION

Over the last decade, the Web has evolved from its ini-
tial days of infancy into an unstructured database that we
know of today. The initial search engines applied the text
information retrieval model wherein a Web document was
retrieved based on the relevance matching between the user
provided query and the words appearing in the document.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

However, with the recent development in the ﬁeld of digi-
tal media technology which has resulted in the generation
of a huge number of images rapidly, eﬃcient Web image
search and browsing have become an important application.
Consequently, Web image clustering has drawn signiﬁcant
attention in the research community recently. For example,
properly grouped Web images can provide a very neat bird’s
eye view of the retrieved images to the user.

Much of the earlier eﬀorts on image clustering were solely
based on low-level visual features of images [14, 25]. To
cluster images, visual features such as color histogram or
wavelet-based [13] texture extracted from images were sub-
jected to traditional data clustering algorithms [17]. The
major drawback in this approach is that the state-of-the-art
visual features are unable to represent the image content
on a semantic level. As a result, image clustering suﬀers
from the semantic gap between visual features and high-
level semantic concepts. A low-tech and a naive solution
adopted by search engines to overcome this problem to a
certain extent has been to treat image clustering as a text
clustering problem. Web images are represented using tex-
tual features in terms of the surrounding texts and captions.
Images clustered based on these textual features are then re-
trieved accordingly. But, since images are not actually text
documents, this approach is hardly a solution to the problem
at hand.

A better approach is to incorporate both visual and tex-
tual features together for eﬃcient Web image clustering. In
[3], a single index vector of an image is formed by combining
textual and visual statistics. Textual statistics are captured
in a vector form using latent semantic indexing (LSI) [5]
based on text in the containing HTML document, while vi-
sual statistics are also stored in a vector form using color and
orientation histograms. A similar approach was adopted in
[29] where the textual and visual features were ﬁrst com-
bined into a global vector following which the LSI technique
was applied. In both these works, the two diﬀerent kinds of
image representations were simply combined together in a
rather rigid way without any theoretical basis. Cai et al. [2]
has used three image representations - viz., visual, textual,
and link information, to construct a relationship graph of
Web images. In this work, images were ﬁrst clustered into
diﬀerent semantic groups by employing the textual and link
features. This step was then followed by visual feature-based
clustering of images in each semantic group. A problem in
this two-step process is that an erroneous ﬁrst step results

317WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, Chinacan propagate to the second step leading to poor image clus-
tering. The use of visual, textual, and link features was also
employed in [21]. Here, an iterative algorithm was applied
to combine the co-clustering between images and surround-
ing text and the one-sided clustering of images based on
visual features. The convergence property of this algorithm
was not proven and the kind of combination is unsymmet-
rical according to the status of visual and textual features.
From the above discussion, it is clear that the earlier eﬀorts
were along the direction of combining the information from
visual and textual features instead of integrating them to-
gether synchronously under a sound theoretical framework.
In this paper, we propose the Consistent Isoperimetric
High-Order Co-clustering (CIHC) framework for simultane-
ous integration of visual and textual features for eﬃcient
Web image clustering under a graph theoretical approach.
Speciﬁcally, visual features, images and textual features are
modelled as the three types of vertices of a tripartite graph.
This tripartite graph is treated as two bipartite graphs of
visual features & images and that of images & textual fea-
tures from the surrounding texts of the image. Co-clustering
is then achieved by simultaneously partitioning these two
bipartite graphs together such that the information from
both the kinds of features is optimally utilized. Note that
the simultaneous partitioning of the two bipartite graphs is
performed in such a way that the local clustering of each
graph need not be optimal under the constraint that the
fusion of the two results yields optimum image clustering.
Actually, a similar concept was presented by Gao et al.
[11] where the Consistent Bipartite Graph Co-partitioning
(CBGC) was proposed under the spectral graph partitioning
paradigm. An iterative algorithm using semi-deﬁnite pro-
gramming (SDP) [1] is used to partition the tripartite graph
which is computationally expensive and does not work well
on large data sets. On the other hand, the proposed method-
ology requires a simple solution to a sparse system of overde-
termined linear equations. Moreover, the CIHC framework
has been derived from the isoperimetric graph partitioning
approach which has been shown to achieve superior results
than the spectral approach in terms of the quality, eﬃciency
and stability of the partition [15, 16, 26]. Experimental
results performed on images extracted from real Websites
demonstrate the advantage of CIHC over CBGC in cluster-
ing Web images.

2. RELATED WORK

In this Section, we introduce some essential background

on graph theory and review related work in the literature.
2.1 Homogeneous Graphs for clustering
An undirected homogeneous graph G ={V, E} consists
of a set of vertices V = {v1, v2, ...., v|V |} and a set of edges
E={eij| edge between vi and vj , i, j <= |V |}, where |V |
is the number of vertices. In a weighted graph, each edge
eij has a positive weight denoted by w(eij ). The weight of
the edge signiﬁes the level of association between the ver-
tices. An edge weight of zero denotes the absence of an edge
between the two respective vertices. Given a vertex num-
bering and the edge weights between the vertices, graphs
can be represented by matrices. We begin with deﬁnitions
of a few graph terminologies that play an essential role in
the paper. The adjacency matrix J of the graph is deﬁned
as,

(cid:2)

Jij =

(cid:3)

w(eij),
0,

if eij exists
otherwise

The degree of a vertex vi denoted by di is deﬁned as,

di =

w(eij),

eij

∀eij ∈ E

(1)

(2)

The degree matrix D of the graph is a diagonal matrix hav-
ing degree of vertices along the diagonal while a degree vec-
tor d of a graph is a vector consisting of degree of all the
vertices. The Laplacian matrix L of a graph is a symmetric
matrix with one row and column for each vertex such that,

Lvi,vj =

−w(eij),
0,

if i = j
if eij exists
otherwise

(3)

⎧⎨
⎩ di,

Suppose we bipartition set V into subsets V1 and V2, then
the corresponding graph cut is deﬁned as,
Jij

cut(V1, V2) =

(4)

(cid:3)
i∈V1,j∈V2
(cid:3)

n<θ

The above deﬁnition can be extended to k -partitioning of
the graph. The cut in which case is deﬁned as,
cut(Vn, Vθ)

cut(V1, V2, ....., Vk) =

(5)

A graph partitioning algorithm assigns a set of values to each
vertex in the graph. We will refer to a vector consisting of
the values for each of the vertices as the indicator vector of
the graph. The cutting of the graph is dividing the indicator
vector based on the values associated with each vertex using
a splitting value. If u denotes the indicator vector of the
graph and s is the splitting value, then the vertices are par-
titioned into the set of i such that ui > s and the set such
that ui ≤ s. Spectral graph theory [4] which is based on
performing eigen decomposition on matrices of the graphs,
has been one of the most popular and widely applied graph
partitioning methods. In [27], Shi and Malik have applied
the spectral method to image segmentation. The objective
function used in this work is,

min

xT Lx
xT Dx

, subject to x

T

De = 0, x (cid:5)= 0

(6)

where e is a unit vector and x is a column vector such that
xi = c1 if i ∈ V1 and xi = −c2 if i ∈ V2, where c1 and c2 are
constants derived from the degree matrix D. By relaxing xi
from discrete to continuous, it can be shown that the solu-
tion to Equation (6) is the eigenvector corresponding to the
second smallest eigenvalue λ2 of the generalized eigenvalue
problem [4, 12],

Lx = λD x

(7)

clustering

Partitions are then obtained by running a clustering algo-
rithm such as k -means [17] on the eigenvector x correspond-
ing to λ2.
2.2 Bipartite Graph Model for pair-wise co-
An undirected bipartite graph G ={M, W, E}, has two
sets of vertices, viz., M and W and a set of graph edges E.
Let B be an |W| by |M| graph weight matrix. An entry Bij
in this matrix is the weight of an edge appearing between a
vertex wi ∈ W and a vertex mj ∈ M. There are no edges
between vertices of the same group. Then, the adjacency
matrix of the bipartite graph is expressed as,

(cid:8)

(cid:7)

J =

0 B
BT
0

(8)

318WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, Chinam 1

m 2

m 3

m 4

m 5

m 6

w 1

w 2

w 3

w 4

w 5

w 6

w 7

Figure 1: The square and circular vertices (m and w, re-
spectively) denote the two data types in the co-clustering
problem that are represented by the bipartite graph.
Partitioning this bipartite graph leads to co-clustering
of the two data types.

where the ﬁrst |W| vertices index W and the last |M| in-
dex M. The two data types in the co-clustering problem can
be represented by the two vertices of the weighted bipartite
graph. Co-clustering of the data is achieved by partitioning
the bipartite graph. In Figure 1, we show the bipartite graph
partitioned using dotted lines. The two partitions obtained
are {m1, m2, m3, w1, w2, w3} and {m4, m5, m6, w4, w5, w6, w7},
respectively. Therefore, the objects in M are clustered into
{m1, m2, m3} and {m4, m5, m6}, while those in W are clus-
tered into {w1, w2, w3} and {w4, w5, w6, w7} simultaneously.
In order to compute these partitions using the spectral ap-
proach, we also need to solve a generalized eigenvalue prob-
lem as in Equation (7). However, due to the bipartite nature
of the problem, the eigenvalue problem reduces to a much
eﬃcient Singular Value Decomposition (SVD) [12] problem,
and has found application for co-clustering in varied ﬁelds
[6, 19, 7]. Recently, Isoperimetric Co-clustering Algorithm
(ICA) [26] was proposed to achieve pairwise co-clustering
by partitioning a bipartite graph. ICA bears resemblance to
the spectral approach in the sense that it does not require
the coordinate information of the vertices of the graphs and
allows us to ﬁnd partitions of an optimal cardinality instead
of a predeﬁned cardinality.
It has been shown that ICA
outperforms the spectral approach in terms of the quality,
eﬃciency and stability in partitioning a bipartite graph.
2.3 Tripartite Graph Model for triplet

co-clustering

f1

f2

f3

f4

f5

f6

 VISUAL
FEATURES

  WEB
IMAGES

m 1

m 2

m 3

m 4

m 5

m 6

SURROUNDING
TEXT WORDS

w 1

w 2

w 3

w 4

w 5

w 6

w 7

Figure 2: Tripartite graph of visual features, web images
and the words coming from the surrounding text of the
images.

The integration of multimodal information for eﬃcient

Web image clustering can be represented using a star-structured
k-partite graph. The structure of this weighted graph is such
that the central data type (images) is connected to all the

other data types (diﬀerent features). There are no direct
edges between the feature vertices. Images are able to uti-
lize multimodal information by being connected to the diﬀer-
ent kinds of feature vertices simultaneously. In an abstract
level, a star-structured k-partite graph can be considered as
a generalized version of a tripartite graph. As a prelimi-
nary attempt, in this work, we integrate visual and textual
features simultaneously using a tripartite graph, shown in
Figure 2. An undirected tripartite graph G ={F, M, W,
E}, has three sets of vertices, viz., F, M and W with E as
the set of edges. If A and B represent the weight matrices
for feature-image and image-word bipartite graphs respec-
tively, then the adjacency matrix of the graph is deﬁned as,

⎡
⎣ 0 A 0
AT
0 BT

0 B
0

⎤
⎦

J =

(9)

Every entry in A and B represents the importance of a par-
ticular feature and word for that image, respectively. For
B, word frequency in the surrounding text of the images
is used. Partitioning this graph lets us achieve Web image
clustering by integrating information from visual and textual
features synchronously. Gao et al. [11] have used a similar
tripartite graph model in their Consistent Bipartite Graph
Co-partitioning (CBGC) framework. The tripartite graph is
considered to be a fusion of the two bipartite graphs that are
partitioned simultaneously using the spectral approach. Let
q = [f m]T and p = [m w]T denote the indicator vec-
tors for the two bipartite graphs and D(f m), D(mw), L(f m)
and L(mw) represent the diagonal and Laplacian matrices
of the two bipartite graphs. Then the objective function
to minimize for the tripartite graph is expressed as a lin-
ear combination of objective functions of the two bipartite
graphs as follows,

(cid:2)

(cid:13)

min

β

qT L(f m)q
qT D(f m)q

+ (1 − β)

T
subject to q
T

D

p

D

(f m)

(mw)

pT L(mw)p
pT D(mw)p
e = 0, q (cid:5)= 0
e = 0, p (cid:5)= 0
0 < β < 1

(10)

where the parameter β speciﬁes the weightage for each bi-
partite graph in the linear combination. Illumined by this
work and the recent results of ICA for pair-wise co-clustering
[26], we propose to partition the visual feature-image-word
tripartite graph using isoperimetric graph partitioning.

3.

ISOPERIMETRIC GRAPH PARTITION-
ING FOR WEB IMAGE CLUSTERING

We partition the tripartite graph of features, web images
and surrounding text words by extending the ICA frame-
work. To proceed, we ﬁrst provide a brief overview of ICA
to partition a bipartite graph.

ICA has been motivated from the combinatorial formu-
lation of the classic isoperimetric problem [8, 24, 15, 16]:
For a ﬁxed area, ﬁnd the shape with minimum perimeter. It
provides polynomial time heuristic for the NP-hard prob-
lem of ﬁnding a region with minimum perimeter for a ﬁxed
area. Let V = {M
W} be the set of vertices of the bipar-
(cid:14)
tite graph. ICA partitions V into sets S and Sc, such that
Sc = φ. Like other graph partitioning
S
algorithms, ICA achieves optimum partitioning by ﬁnding S
and Sc so that isoperimetric ratio of the graph hG deﬁned

Sc = V and S

(cid:14)
(cid:15)

319WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, Chinaas,

|ΔS|
V olS

hG =

(11)

m 1

m 2

m 3

m4

m 5

m 6

is minimized. The numerator and denominator represent
the boundary area and the volume of S, respectively. The
boundary of S is deﬁned as,
ΔS = {eij| edges between a vertex in S and Sc}. Conse-
quently,

w(eij)

(12)

|(cid:6)S| =

(cid:3)
eij∈(cid:3)S

The combinatorial volume [8] can be deﬁned as,

V olS = |S|,

(13)

After a few mathematical deductions, ICA achieves the min-
imization of Equation (11) by solving a sparse system of
linear equations as,

(cid:7)

(cid:8)

L

m
w

= e

(14)

where L is the Laplacian matrix of the bipartite graph,
[m w]T is the indicator vector to indicate partitioning of
the two types of vertices, and e is a vector of ones of size
|M| + |W|. Solving this system of equations results in a
real valued [m w]T .
In order to get partitions, this solu-
tion needs to be cut using a splitting value (as explained in
Section 2).

To partition the visual feature-image-word tripartite graph,
intuitively it might seem obvious to perform traditional ex-
tension of ICA (abbreviated as TICA) by solving a similar
system of linear equations corresponding to the adjacency
matrix deﬁned in Equation (9) as follows,

⎡
⎣ f

m
w

L

⎤
⎦ = e

(15)

(16)

where L, the indicator vector [f m w]T and e are similarly
deﬁned for the tripartite graph. However, by doing so the
visual feature-image-word tripartite graph actually ends up
being a bipartite graph of image and visual feature & word.
This can be seen by shifting the visual feature vertices on to
the side of the word vertices as illustrated in Figure 3. Due
to this, we will be unable to distinguish between cutting
a visual feature-image edge and an image-word edge and is
thus a conceptual misrepresentation of the basic structure of
visual features, images and words as in Figure 2. An alter-
native approach is to use a weighting parameter α to prevent
the mixing of visual feature and word vertices by deﬁning
the adjacency matrix of the tripartite graph as follows,

⎡
⎣ 0
AT
0

J =

⎤
⎦

A
0
αBT

0
αB
0

However, as demonstrated in Section 3.1 and 5, the numer-
ical weightage is unable to prevent the problem. Moreover,
even if it works on a particular dataset, it is not possible
to decide the numerical weight a priori and will not work
across other datasets.

To overcome the ill-partitioning of Figure 3, we propose

the Consistent Isoperimetric High-order Co-clustering (CIHC)
to partition the visual feature-image-word tripartite graph
by considering it as two bipartite graphs coupled together.

f1

f2

f3

f4

f5

f6

w 1

w 2

w 3

w 4

w 5 w 6

w 7

Figure 3: Traditional extension of ICA (TICA) for par-
titioning the feature-image-word tripartite graph ends
up actually partitioning a bipartite graph of image and
feature & word.

f1

f2

f3

m 1

m 2

m 3

m 4

m 5

m 6

m 7

m 8

w 1

w 2

w 3

w 4

w 5

w 6

Figure 4: Toy problem of 3, 8 and 6 vertices of F, M
and W, respectively with uniform weights along all edges.
The dotted line shows the ideal cut for partitioning this
graph.

x 10−16

CIHC

12

10

8

6

4

2

0

s
e
g
a
m

i
 
f

l

o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

−2

0

2
16
     F                                M                                         W           

10

12

14

4

6

8

18

Figure 6: CIHC results for partitioning the toy graph.
We are able to get perfect partitioning for each of F, M
and W vertices.

It is easy to see that applying ICA separately on the two bi-
partite graphs will result in two diﬀerent partitioning results
on the images. In order to achieve consistent results, we need
to partition the two bipartite graphs simultaneously. That
is, visual feature-image bipartite graph needs to be parti-
tioned under the constraints enforced on images by words
while, the partitioning of image-words bipartite graph has
to be under the constraints enforced on images by visual fea-
tures. In other words, we achieve consistent partitioning of
images under the constraints that the partitioning of visual
feature-image or image-word need not be optimal. By do-
ing so, we can consistently integrate the visual and textual
features simultaneously for clustering the Web images.

Applying ICA to the visual feature-image bipartite graph,

we get,

(cid:7)

(cid:8)

(f m)

L

f
m

(f m)

= e

(17)

320WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, Chinas
e
g
a
m

l

i
 
f
o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

2000

0

−2000

−4000

−6000

−8000

−10000

−12000

−14000

−16000

−18000

0

TICA with α=0.01

TICA with α=1

TICA, with α=100

TICA, with α=1000

2

1

0

−1

−2

−3

−4

s
e
g
a
m

l

i
 
f
o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

2
16
F                             M                                        W               

10

12

14

4

6

8

18

−5

0

2

4

6

8

10

12

14

16

18

F                                   M                                          W

s
e
g
a
m

l

i
 
f
o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

−0.8

0

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

s
e
g
a
m

l

i
 
f
o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

2
16
F                                 M                                       W              

10

12

14

4

6

8

18

−0.8

0

2
16
F                                M                                              W          

10

12

14

4

6

8

18

Figure 5: TICA results for partitioning the toy problem graph of Figure 4. Each sub-ﬁgure shows the results for α =
0.01, 1, 100 and 1000.

Similarly, image-word bipartite graph yields us,

(cid:7)

(cid:8)

(mw)

L

m
w

(mw)

= e

(18)

We combine the above two system of linear equations as,

(cid:7)

L(f m)

0

0

L(mw)

⎤
⎦ =

(cid:8)⎡
⎣ f

m
w

(cid:7)

(cid:8)

e(f m)
e(mw)

(19)

F r = v

where v is a vector of ones of size |F| + 2|M| + |W|. Note
that, F is not a square matrix, i.e. this is an overdetermined
system of linear equations where the number of equations is
more than the number of variables. Overdetermined system
of linear equations is usually inconsistent and does not have
any solution. However, many least squares methods exist
to approximate the solution [20]. We adopted the QR de-
composition method due to its simplicity and eﬃciency to
solve Equation (19). Notice that, any other method can be
employed as well. Amongst the common methods for cut-
ting the indicator vector are the median cut and the ratio
cut. Median cut uses the median of the indicator vector
r as the splitting value to produce equally sized partitions
while ratio cut chooses one such that the resulting partitions
have the lowest isoperimetric ratio of the graph indicating
optimal partitioning. As our goal is not to necessarily pro-
duce equally sized clusters, we employ the ratio cut to get a
bipartition.
3.1 Illustrative Toy problem

Above, we discussed the need for partitioning the tripar-
tite graph by simultaneously partitioning the two bipartite
graphs. We now illustrate this on a toy problem that TICA
does not yield optimum results. For this, we created a tri-
partite graph shown in Figure 4 having 3 F, 8 M and 6 W
vertices with uniform weights along all the edges. It is easy
to infer the ideal partitioning of this graph shown in the
Figure using a dotted line. We partitioned this graph using
TICA with adjacency matrix deﬁned in Equation (16). In
Figure 5, we show the corresponding results achieved when
we varied the value of α from 0.01 to 1000. The X-axis has
the vertices in the order of F, M and W with the dotted line
separating each of them. Embedding value for each vertex
in the indicator vector is plotted along the Y-axis. The two
pattern plots (∗ and (cid:6)) represent the two clusters obtained.
These results clearly show that in spite of increasing edge
weights for one of the bipartite graphs drastically over the
other, TICA is still unable to distinguish between cutting

an F-M edge from an M-W edge on a simple graph. On the
other hand, Figure 6 shows the results achieved using CIHC.
We can see that, CIHC achieves perfect clustering for all the
vertices. Through this toy problem, we have shown the need
to consistently apply isoperimetric co-clustering simultane-
ously. More results, on real Web images will be presented
in Section 5.
3.2 Algorithm Summary

The main steps of CIHC can be summarized as follows:

1. Using weight matrix A of the visual feature-image bi-
partite graph, construct the Laplacian matrix L(f m).

2. Similarly, using weight matrix B of the image-word

bipartite graph, construct L(mw).

3. Using Equation (19), construct F, r and v, and solve

the system of linear equations F r = v.

4. Employ ratio cut on r to get the partitions.
3.3 Advantages of CIHC over CBGC

Both CIHC and CBGC partition the visual feature-image-
word tripartite graph by considering it as a fusion of the
two bipartite graphs. However, as we explain below the
CIHC framework has a number of advantages over CBGC.
In CBGC, the spectral objective functions of the two bipar-
tite graphs are transformed into single-objective function of
Equation (10) by expressing it as a weighted linear combina-
tion. As argued in [9], this is a very ad-hoc approach and not
a principled one. The two objective functions represent two
diﬀerent kinds of information. Hence, instead of converting
the original dual-objective problem into a single objective
problem, one should use a dual-objective algorithm directly.
Another drawback of CBGC, is that its performance is de-
pendent on three parameters, viz. β, θ1 and θ2. β is the
weighting parameter used in the linear combination of ob-
jective functions while θ1 and θ2 are parameters used to put
constraints on the SDP bound controllers. The problem here
is that these three parameters have to be predetermined. In
their work, the authors test the performance of CBGC on
few image categories by varying the values of the parame-
ters and choose the best values. As we show in our results
(Section 5), this approach for tuning the CBGC parameters
works on only those few categories and performs poorly on
the other datasets.
In the real world application for Web
image clustering, it is impossible to know what parameter
values are to be chosen for clustering the images retrieved.
On the other hand, CIHC is a completely parameter-less

321WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, Chinaapproach and does not require a priori speciﬁcation of any
parameters. In terms of computational complexity, CIHC is
much more eﬃcient compared to CBGC as it only requires
a simple solution to a sparse system of linear equations.

Diﬀerentiating this equation with respect to ρ,

q

δL(f m)

δρ

+ L

(f m) δq
δρ

(f m)

= D

q

δλ2
δρ

+ λ2q

δD(f m)

δρ

4. THEORETICAL ANALYSIS OF CIHC

4.1 Time Complexity

Computational time required by CIHC depends on the
solution to Equation (19). In particular, the time complexity
is dependent on the number of non-zero entries in L(f m) and
L(mw), which asymptotically is O(|E|) where E is the set of
edges in the tripartite graph. Note that, this only measures
the time complexity to compute the indicator vector. We
also need to include the time complexity to employ the ratio
cut which is of the order of O(h logh) where h = |F| +
|M| + |W|. Factoring this in, the time complexity of CIHC
is O(|E|+h logh). Empirical results on computational speed
are presented in Section 5.3.

4.2 Sensitivity Analysis

In this section, we analyze the sensitivity of CIHC and

CBGC with respect to a general parameter ρ.

4.2.1 CIHC

+λ2D

(f m) δq
δρ

(25)

Using Rayleigh quotient and the Chain rule, it is possible to
calculate δλ2
δρ .

The Rayleigh quotient is,

λ =

qT L(f m)q

qT q

Applying Chain rule,

δλ2
δρ

=

δλ2
δq

δq
δρ

(26)

(27)

In the above equation, δλ2

δq can be calculated from equa-

tion (26) as,

= 2L

(f m)

T

q(q

q)

−1 − 2q

T

(f m)

L

q(q

T

q)

−2

q

(28)

δλ2
δq

From Equation (25), since all the terms are either known
or can be calculated analytically, we get a system of linear
equations which may be solved for δq
δρ .

If we now consider the second term in Equation (22), and

proceed similarly, we get

Recall from Equation (19), CIHC requires a solution to a

sparse system of linear equations represented by,

p

δL(mw)

δρ

+ L

(mw) δp
δρ

(mw)

= D

p

δλ2
δρ

+ λ2p

δD(mw)

F r = v

Diﬀerentiating this equation with respect to ρ,

F

δr
δρ

= −r

δF
δρ

+

δv
δρ

(20)

(21)

For a given solution to Equation (20), F and r are known
and δF
δρ can be determined analytically. In order to deter-
mine the derivative at point r, δr
δρ can be solved for as a
system of linear equations.

4.2.2 CBGC

(cid:2)

The CBGC objective function is,
+ (1 − β)

min

β

qT L(f m)q
qT D(f m)q

pT L(mw)p
pT D(mw)p

(cid:13)

subject to certain constraints

(22)

If we drop the constant weighting parameter β and consider
only the ﬁrst term, we get,

(cid:2)

(cid:13)

min

qT L(f m)q
qT D(f m)q

(23)

With reference to the previous discussion on Spectral graph
partitioning in Section 2, we know from Equations (6) and
(7) that the solution for minimizing this term is the eigen-
vector corresponding to second smallest eigenvalue λ2 of the
generalized eigenvalue problem,

(f m)

L

q = λ2 D

(f m)

q

(24)

δρ

(mw) δp
δρ

(29)

+λ2D

We can analyze the eﬀect of a speciﬁc parameter, e.g., edge
weight, by substituting for the general parameter ρ. Equa-
tions (21), (25) and (29) show that the derivative of the
CIHC solution is never degenerate. On the other hand, the
CBGC solution may be degenerate depending on the value
of λ2 and the state of its corresponding eigenvector.

5. EXPERIMENTS AND RESULTS

5.1 Data Preparation

For dataset preparation we followed the same approach as
in [11]. A web crawler was ﬁrst sent out to crawl some of
the Webpages in the Yahoo directory1 to extract images and
their surrounding texts. Images having width-height ratios
larger than 5 or less than 1/5 and images having both width
and height less than 60 pixels were removed. After this,
the image database consisted of 15, 000 images which were
manually assigned to 42 categories.

The surrounding text extracted was ﬁltered to remove
common stop words such as conjunctions, articles, etc. The
words left over after this were considered to be the textual
features of the image. We observed that the quality of the
surrounding text varies depending on the source Webpage
from where an image was extracted. Correspondingly, we
refer to the textual features for each category to be “poor”,
“average” or “good”. For the experiments, we randomly se-
lected 10 of these categories shown in Table I. To ensure that
the image-text bipartite graph is not disconnected when two
1http://dir.yahoo.com/Arts/Visual Arts/Photography/

322WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, ChinaTable I: Image categories used in the experiments
Category Name Category Size Text Quality

Owls

Flowers

Lions

Elephants

Horses

Snow Mountains

Flying Eagle

Dusk
Plants

Railways

71
64
56
85
76
82
67
58
79
77

Average
Average
Average

Good

Average
Average
Average

Poor
Poor
Good

categories are mixed together, we added an extra dummy
word to the graph that connects to all the images. The
weights for each of these edges was set to be the recipro-
cal of the number of images in the graph. For the visual
features, we used the PCA-SIFT2 image descriptors [18].
5.2 Web Image clustering results

We ﬁrst demonstrate the need to integrate both the visual
and textual features simultaneously. We present the results
for clustering Web images using only textual features and
only visual features and then show that the performance can
be improved by integrating the two simultaneously using
CIHC framework. We will also compare image clustering
results of CIHC with TICA and CBGC.

Image−Text Co−clustering

Image−Text Co−clustering

s
e
g
a
m

i
 
f

o

 
s
e
u
a
v
 

l

i

g
n
d
d
e
b
m
E

800

700

600

500

400

300

200

100

0

−100

0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180

Elephants and Railways images

s
e
g
a
m

i
 
f

o

 
s
e
u
a
v
 

l

i

g
n
d
d
e
b
m
E

1300

1200

1100

1000

900

800

700

600

500

400

0

10

20

30

40

60

50
Dusk and Plants images

70

80

90 100 110 120 130 140

Image-Text Co-clustering.

Figure 7:
(Left) Both
Elephants and Railways have “good” textual features lead-
ing to perfect clustering. (Right) Dusk and P lants have
“poor” textual features that are not suﬃcient in sepa-
rating the two categories. Most of the Web images have
noisy surrounding text and is not by itself suﬃcient for
clustering.

For Web image clustering using only surrounding text, we
selected 4 image categories viz., Elephants, T rains, Dusk
and P lants. We mixed Elephants & T rains that both
have “good” textual features and Dusk & P lants that have
“poor”. We applied the ICA algorithm to the Image-Text
bipartite graph to get the partitions. For all the experi-
ments, we have used the volume as per Equation (13). In
Figure 7, we show the embedding values of the images and
the partitioning obtained. The dotted line separates the
image categories. As expected in the case of Elephants &
T rains, we get perfect clustering results. However, Dusk
& P lants images were extracted from some photo gallery
webpages that hardly had any worthwhile text in them. Im-
ages from these two categories had a lot of noisy text such
2http://www.cs.cmu.edu/˜yke/pcasift/

as photographer name, photographer address, copyrights, etc.
Consequently, the clustering result on these categories using
only surrounding text is very poor. This experiment shows
that if the textual features of the image categories are very
good, then those themselves are enough to yield optimum
results. However, that is not always true with the surround-
ing text around the Web images.

Image−Feature Co−clustering

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

s
e
g
a
m

i
 
f

l

o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

58

57.5

57

56.5

56

55.5

55

0

5

10

15

25

20
50
Horses and Snow Mountain images

30

35

40

45

55

60

65

70

 

 

 

 

 

Figure 8: Image-Feature Co-clustering. Most of the im-
ages selected from Horses and Snow M ountains are sep-
arable using only the visual features. Images from the
Horses category that were misclassiﬁed were due to their
similar backgrounds such as sky or snow.

With regards to Web image clustering by relying only
on visual features, we selected 4 categories viz., Horses,
SnowM ountains, Owls and F lyingEagle. For this exper-
iment, we ﬁrst mixed Horses and SnowM ountains by se-
lecting 35 visually dissimilar images from each of them. In
Figure 8, we show sample images from both these categories
and the image clustering results achieved by applying ICA
to the Image-Feature bipartite graph.
Images from these
two categories are mainly dissimilar with few similarities in
some images such as the sky or greenery in the background.
Due to this fact, we are able to separate the two categories
to a great extent using only the visual features. On the other
hand, although Owls and F lyingEagle belong to two dif-
ferent semantic categories, their images resemble on a num-
ber of grounds as shown in Figure 9.
Images from these
categories have a bird-like object with similar backgrounds.
Owing to the semantic gap, the visual features are unable to
represent the semantics accurately. Figures 7, 8 and 9 show
that integrating the low-level visual feature representation
and high-level semantics coming from the textual features
together simultaneously may yield better clustering results.

Image−Feature Co−clustering

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

s
e
g
a
m

i
 
f

l

o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

56

55

54

53

52

51

50

49

0

5

10

15

20

30

45
25
Owls and Eagles images

35

40

50

55

60

65

70

 

 

 

 

 

Figure 9: Image-Feature Co-clustering. Owls and Eagles
are inseparable using only the visual features due to the
semantic gap. Images from both the categories have sim-
ilar backgrounds and a bird-like structure at the center
of the image.

323WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, China 

 

 

 

0.1

0.05

0

−0.05

−0.1

−0.15

0

10

20

30

s
e
g
a
m

i
 
f

l

o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

TICA with α=0.01

−542.91

−542.92

−542.93

−542.94

−542.95

−542.96

−542.97

−542.98

−542.99

s
e
g
a
m

i
 
f

l

o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

0

10

20

30

 

50

40
80
Flowers and Lions images

60

70

TICA with α=1

x 10−3

TICA with α=100

6

4

2

0

−2

−4

−6

s
e
g
a
m

i
 
f

l

o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

50

40
80
Flowers and Lions images

60

70

90

100 110 120

0

10

20

30

50

40
80
Flowers and Lions images

60

70

s
e
g
a
m

l

i
 
f
o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

x 10−4

10

TICA with α=500

8

6

4

2

0

−2

−4

−6

−8

0

10

20

30

50

40
80
Flowers and Lions images

60

70

90

100 110 120

s
e
g
a
m

l

i
 
f
o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

x 10−4

TICA with α=1000

6

4

2

0

−2

−4

−6

−8

0

10

20

30

50

40
80
Flowers and Lions images

60

70

90

100 110 120

90

100 110 120

90

100 110 120

Figure 10: TICA is unable to separate F lowers and Lions
images despite the varying values of α from 0.01 to 1000.
Images from both these categories have “average” textual
features and visually dissimilar images. TICA performs
disastrously due to the ill-partitioning of the tripartite
graph explained in Figure 3

In Section 3, we had discussed the need for simultaneously
partitioning the two bipartite graphs of visual features & im-
ages and images & textual features. We now show experi-
mentally that TICA does not yield optimum results for clus-
tering Web images. For this, we mixed F lowers and Lions
images. Sample images from these two categories and the
results obtained using TICA are shown in Figure 10. Both
these categories have “average” textual features with images
having similar backgrounds. The value of the weighting pa-
rameter α was varied from 0.01 to 1, 000. This experiment
demonstrates that TICA actually ends up partitioning the
bipartite graph of images and the two features together. As
was the case with the toy problem results (Section 3.1), even
the change in the values of α does not help in getting better
results. Figure 11 displays the results we get for partition-
ing the same dataset using CIHC. From these results, we
can make two key observations. First of all, we can see the
advantages of utilizing the information from both kinds of
features simultaneously. In most of the real-world scenarios,
it is unlikely that either of the features would be capable
of completely describing the respective categories on their
own. “Average” textual features with tolerable amount of
noise along with visual features is good enough to get de-
cent clustering results. Secondly, the capability of CIHC to
achieve the same can be seen.

We have compared CIHC with CBGC in terms of the im-
age clustering results, scalability and computational speed.

s
e
g
a
m

i
 
f

l

o
 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

x 10−16

CIHC

−5

−6

−7

−8

−9

−10

−11

−12

−13

0

10

20

30

50

80
40
Flowers and Lions images

70

60

90

100 110 120

Figure 11: CIHC performs well in grouping F lowers and
Lions images by successfully integrating the visual and
textual features simultaneously.

As mentioned in Section 3.3, CBGC is a very parameter-
dependent framework which relies heavily on the values of
θ1, θ2 and β. To decide on the values for these 3 parame-
ters, we followed the approach suggested by the authors [11].
We randomly selected two image categories (Elephants and
SnowM outains) and varied the values of all the parame-
ters between 0 and 1 for the partitioning. Values that gave
best clustering result were chosen and used for the rest of
the categories. The problem with CBGC is that these val-
ues are category speciﬁc and have to be retuned for the
other categories. As an example, in Figure 12, we show
the clustering results for Elephants and SnowM ountains
using CBGC and CIHC. Based on the above parameter val-
ues, CBGC is able to get perfect clustering results. On the
same dataset, CIHC gets similar results. In another case in-
volving F lying Eagle and Lions shown in Figure 13, CBGC
has misclassiﬁed a number of Lions images. CIHC on the
other hand was able to generate very good clusters. The
same is true in the case of F lowers and Horses shown in
Figure 14 where CBGC produces disastrous results and is
completely outperformed by CIHC. We observed similar re-
sults in the clustering of other categories. To summarize, in
CBGC, parameters tuned for partitioning certain categories
produce excellent results for those particular categories and
may not work well for others. CIHC framework instead does
not require any parameter values to be pre-determined.

s
e
g
a
m

i
 

e
h

t
 
f

o

l

 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

6

4

2

0

−2

−4

−6

x 10−3

CBGC

s
e
g
a
m

i
 
f

o

l

 
s
e
u
a
v
 
g
n
d
d
e
b
m
E

i

0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180

Elephants and Snow Mountains images

9

8

7

6

5

4

3

2

1

x 10−16

CIHC

0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180

Elephants and Snow Mountains images

Figure 12:
In the clustering of Elephants and Snow
M outains, CBGC is able to get perfect clustering due
to the fact that the values used for the parameters β, θ1
and θ2 are suitable for separating these two categories.
CIHC is devoid of any parameters and is able to get
comparable results on the same dataset.

To evaluate the image clustering performance of CIHC
and CBGC across all the categories, we have used the cross-
accuracy metric [11]. If two image categories having n1 and
n2 images respectively are mixed, then the ground truth

324WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, Chinax 10−16

CIHC

Table II: Average clustering performance

x 10−3

CBGC

3

2

1

0

−1

−2

−3

−4

−5

s
e
g
a
m

i
 
f

o
 
s
e
u
a
v
 

l

i

g
n
d
d
e
b
m
E

−2

−3

−4

−5

−6

−7

−8

−9

s
e
g
a
m

i
 
f

o
 
s
e
u
a
v
 

l

i

g
n
d
d
e
b
m
E

−6

0

10

20

30

40

60

50
Eagles and Lions images

70

80

90 100 110 120 130 140

−10

0

10

20

30

40

60

50
Eagles and Lions images

70

80

90 100 110 120 130 140

Figure 13: Parameters previously set for CBGC are
unable to separate F lying Eagles and Lions. A number of
Lions images are misclassiﬁed. On the other hand, CIHC
performs well.

x 10−3

−1

CBGC

x 10−16

10

CIHC

s
e
g
a
m

i
 
f

o
 
s
e
u
a
v
 

l

i

g
n
d
d
e
b
m
E

−1.5

−2

−2.5

−3

−3.5

−4

−4.5

−5

0

10

20

30

40

50

60

70

80

90 100 110 120 130 140

Roses and Horses images

s
e
g
a
m

i
 
f

o
 
s
e
u
a
v
 

l

i

g
n
d
d
e
b
m
E

9

8

7

6

5

4

3

2

0

10

20

30

40

50

60

70

80

90 100 110 120 130 140

Flowers and Horses images

Figure 14: Another example of the eﬀect of a set of
parameter values on other image categories. The set
parameter values of CBGC perform very poorly in sep-
arating F lowers and Horses. Once again, as can be seen
CIHC gets decent results.

Boolean vector rt can be written as,

rt = (1, 1, ..., 1, 0, 0, ..., 0)

(30)

i

i

n1 + n2

n1 + n2

(cid:3)

(cid:3)

, 1 −

⎧⎪⎪⎨
⎪⎪⎩

accuracy = max

(rti ⊕ rci)

where the ﬁrst n1 elements are set to 1 and the rest n2
elements are set to 0. The image clustering results can be
represented as a Boolean vector rc having the same ordering
of elements as rt. Cross-accuracy is deﬁned as follows,
(rti ⊕ rci)

⎫⎪⎪⎬
⎪⎪⎭
(31)
where ⊕ represents the exclusive-OR operation. We mixed
every image category with the rest of the category and mea-
sured the accuracy of the clustering. In Figure 15, we have
plotted the accuracy of CIHC (Y-axis) vs CBGC (X-axis).
Each circle in the plot represents a possible image category
pair. It can be seen that most of the circles fall in the upper
part of the diagonal. This indicates that in the clustering of
most of the image category pairs, CIHC outperforms CBGC.
The few circles on the lower part of the diagonal are the cat-
egory pairs for which CBGC has been properly tuned with
the parameter values.
In Table II, we show the mean ac-
curacy between each category and all other categories for
both the algorithms. CIHC has a higher mean accuracy and
outperforms CBGC on all the categories.
5.3 Computational Speed

Owls

Lions

Flowers

Elephants

Category Name CBGC CIHC
0.8241
0.8342
0.8132
0.8941
0.8244
0.7746
0.8608
0.5614
0.6543
0.8070

0.5898
0.6248
0.6544
0.8706
0.6363
0.6050
0.6728
0.5412
0.6386
0.6631

Snow Mountains

Dusk
Plants

Flying Eagle

Railways

Horses

1

0.9

0.8

0.7

0.6

0.5

C
H
C

I

 
f

o
 
y
c
a
r
u
c
c
A

0.4

0.4

Clustering performance comparison on all image category pairs

0.5

0.6

0.7

0.8

0.9

1

Accuracy of CBGC

Figure 15: Clustering performance of CBGC and CIHC
on all image category pairs. Each circle represents a
possible category pair. Most of the circles fall in the
upper part of the diagonal.

s
d
n
o
c
e
s
 
n
i
 
e
m
T

i

1800

1600

1400

1200

1000

800

600

400

200

0

0

Computational Speed for CIHC and CBGC

CBGC
CIHC

500

1000

1500

2000

2500

3000

3500

4000

Total number of vertices in the tripartite graph

Figure 16: Computational speed comparison of CIHC
with CBGC. The time required by each of the algorithms
to compute the indicator vector are displayed for increas-
ing number of vertices in the tripartite graph.

In other words,
the sparseness of the two data matrices.
it takes more time to partition a densely connected tripar-
tite graph compared to a sparsely connected one. For this
reason, we considered the worst case scenario of a fully con-
nected tripartite graph (with uniform weights) where every
vertex in both the bipartite graphs is connected with all
other vertices of the other type. Since the time required to
cut the indicator vector is the same for both algorithms, we
compare on the basis of the time required to calculate the
indicator vector. The algorithms were implemented using
MATLAB 7.03. For CBGC implementation, we made use of
the SDP library SDPA-M 4 [10]. The experiment was per-
formed on a machine with a 3 GHz Intel Pentium 4 processor
with 1 GB RAM. In Figure 16, we plot the time required
by the algorithms as the number of vertices in the fully con-
nected tripartite graph increases. Time for CIHC gradually

We now compare the computational speed of CIHC with
CBGC. The time take by both algorithms is dependent on

3http://www.mathworks.com
4http://grid.r.dendai.ac.jp/sdpa/

325WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, Chinaincreases with the number of vertices. For the maximum
number of vertices we increased to - about almost 4, 000,
CIHC required about 98 seconds only. CBGC on the other
hand, was unable to keep up with CIHC. As can be seen, the
time required by CBGC really shoots up for a few hundred
vertices in the graph. Moreover, CBGC is unscalable and is
unable to handle larger sized graphs, which was also veriﬁed
by [23, 22]. In our experiment, CBGC was unable to han-
dle graphs with more than 1, 500 vertices. This experiment
clearly demonstrates the computational eﬃciency of CIHC
and the potential for applicability in large-scale real-world
applications.

6. CONCLUSIONS AND FUTURE WORK

In this paper, we addressed the problem of Web image
clustering by simultaneous integration of visual and textual
features from a graph partitioning perspective.
In partic-
ular, we modelled visual features, images, and words from
the surrounding text of the images using a tripartite graph.
This graph is actually considered as a fusion of two bipartite
graphs that are partitioned simultaneously by the proposed
CIHC framework. Although a similar approach has been
adopted before, the main contribution of this work lies in
the computational eﬃciency, quality in Web image cluster-
ing and scalability to large image repositories that CIHC is
able to achieve. We demonstrate this through experimental
results performed on real Web images.

In future work, there are a number of directions we are
actively pursuing. Currently, in order to get more than two
partitions, we recursively apply CIHC which is a common
approach in many other graph partitioning algorithms [11,
26, 15, 28]. We are currently investigating methods to get
more than two clusters directly. Another extension of this
work is to get ﬂexible clusterings for each of the vertex types
in the tripartite graph. That is, currently we have a hard
partitioning framework where there is a one-one association
between features, images and words belonging to one cluster.
It would be interesting to discover the association between
visual features grouped in one cluster and words or images
grouped in another. We are also working on having diﬀerent
number of partitions for each of visual features, images and
words, instead of all having the same. To this end, we have
found the recent work on matrix factorization by Long et al.
[23, 22] very interesting and helpful.

7. ACKNOWLEDGMENTS

This research was partially funded by the 21st Century
Jobs Fund Award, State of Michigan, under grant: 06-1-
P1-0193, and by National Science Foundation, under grant:
IIS-0713315.

8. REFERENCES
[1] S. Boyd and L. Vandenberghe. Convex Optimization.

Cambridge University Press, 2004.

[2] D. Cai, X. He, Z. Li, W.-Y. Ma, and J.-R. Wen.

Hierarchical clustering of www image search results using
visual, textual and link information. In proc. of ACM
Multimedia, 2004.

[3] M. Cascia, S. Sethi, and S. Sclaroﬀ. Combining textual and

visual cues for content-based image retrieval on the world
wide web. In proc. of IEEE CBAIVL, 1998.

[4] F. R. K. Chung. Spectral Graph Theory. American

Mathematical Society, 1997.

[5] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K.

Landauer, and R. Harshman. Indexing by latent semantic
analysis. Journal of the American Society for Information
Science, 41(6):391–407, 1990.

[6] I. S. Dhillon. Co-clustering documents and words using

bipartite spectral graph partitioning. In proc. KDD, 2001.
[7] C. H. Q. Ding. Unsupervised feature selection via two-way

ordering in gene expression analysis. Bioinformatics,
19:1259 – 1266, 2003.

[8] J. Dodziuk. Diﬀerence equations, isoperimetric inequality
and the transience of certain random walks. Transactions
of the American Mathematical Society, 284:787–794, 1984.

[9] A. A. Freitas. A critical review of multi-objective

optimization in data mining: a position paper. SIGKDD
Explor. Newsl., 6(2):77–86, 2004.

[10] K. Fujisawa, Y. Futakata, M. Kojima, S. Matsuyama,
S. Nakamura, K. Nakata, and M. Yamashita. Sdpa-m
(semideﬁnite programming algorithm in matlab) user’s
manual - version 6.2.0. Technical report, Dept. Math. &
Comp. Sciences, Tokyo Institute of Technology,
http://grid.r.dendai.ac.jp/sdpa/publication.html, 2000.
[11] B. Gao, T.-Y. Liu, T. Qin, X. Zheng, Q.-S. Cheng, and

W.-Y. Ma. Web image clustering by consistent utilization
of visual features and surrounding texts. In proc. of ACM
Multimedia, 2005.

[12] G. H. Golub and C. F. Van-Loan. Matrix Computations.

John Hopkins Press, 1989.

[13] R. C. Gonzalez and R. E. Woods. Digital Image Processing.

Prentice Hall, Upper Saddle River, NJ, 2002.

[14] S. Gordon, H. Greenspan, and J. Goldberger. Applying the
information bottleneck principle to unsupervised clustering
of discrete and continuous image representations. In proc.
of IEEE ICCV, 2003.

[15] L. Grady and E. L. Schwartz. Isoperimetric graph

partitioning for image segmentation. IEEE Transactions on
PAMI, 28(3):469– 475, 2006.

[16] L. Grady and E. L. Schwartz. Isoperimetric partitioning: A

new algorithm for graph partitioning. SIAM Journal on
Scientiﬁc Computing, 27(6):1844–1866, 2006.

[17] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering:

a review. ACM Comput. Surv., 31(3):264–323, 1999.

[18] Y. Ke and R. Sukthankar. Pca-sift: A more distinctive

representation for local image descriptors. In proc. of IEEE
CVPR, 2004.

[19] R. Kumar, U. Mahadevan, and D. Sivakumar. A

graph-theoretic approach to extract storylines from search
results. In proc. of ACM KDD, 2004.

[20] C. L. Lawson and R. J. Hanson. Solving Least Squares
Problems. Soc for Industrial and Applied Math, 1995.

[21] Z. Li, G. Xu, M. Li, W.-Y. Ma, and H.-J. Zhang. Grouping

www image search results by novel inhomogeneous
clustering method. In proc. of MMM, 2005.

[22] B. Long, X. Wu, Z. Zhang, and P. S. Yu. Unsupervised

learning on k-partite graphs. In proc. of ACM KDD, 2006.

[23] B. Long, Z. Zhang, X. Wu, and P. S. Yu. Spectral clustering

for multi-type relational data. In proc. of ICML, 2006.
[24] B. Mohar. Isoperimetric numbers of graphs. Journal of

Combinatorial Theory, Series B, 47:274–291, 1989.

[25] G. Qiu. Image and feature co-clustering. In proc. of IEEE

ICPR, 2004.

[26] M. Rege, M. Dong, and F. Fotouhi. Co-clustering

documents and words using bipartite isoperimetric graph
partitioning. In proc. of IEEE ICDM, 2006.

[27] J. Shi and J. Malik. Normalized cuts and image

segmentation. IEEE Trans PAMI, 22(8):888 – 905, 2000.

[28] H. Zha, X. He, C. H. Q. Ding, H. Simon, and M. Gu.

Bipartite graph partitioning and data clustering. In proc. of
ACM CIKM, 2001.

[29] R. Zhao and W. I. Grosky. Narrowing the semantic gap -
improved text-based web document retrieval using visual
features. IEEE Trans. on Multimedia, 4(2):189–200, 2002.

326WWW 2008 / Refereed Track:  Rich MediaApril 21-25, 2008. Beijing, China