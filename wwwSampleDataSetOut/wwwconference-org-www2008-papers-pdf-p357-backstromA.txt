Spatial Variation in Search Engine Queries

Lars Backstrom

Jon Kleinberg

Ravi Kumar

Jasmine Novak

Dept. of Computer Science

Cornell University
Ithaca, NY 14853.

{lars,kleinber}@cs.cornell.edu

Yahoo! Research

701 First Ave

Sunnyvale, CA 94089.

{ravikumar,jnovak}@yahoo-inc.com

ABSTRACT
Local aspects of Web search — associating Web content and
queries with geography — is a topic of growing interest.
However, the underlying question of how spatial variation
is manifested in search queries is still not well understood.
Here we develop a probabilistic framework for quantifying
such spatial variation; on complete Yahoo! query logs, we
ﬁnd that our model is able to localize large classes of queries
to within a few miles of their natural centers based only
on the distribution of activity for the query. Our model
provides not only an estimate of a query’s geographic cen-
ter, but also a measure of its spatial dispersion, indicating
whether it has highly local interest or broader regional or
national appeal. We also show how variations on our model
can track geographically shifting topics over time, annotate
a map with each location’s “distinctive queries,” and delin-
eate the “spheres of inﬂuence” for competing queries in the
same general domain.

Categories and Subject Descriptors: H.2.8 Database
Management: Database Applications – Data Mining

General Terms: Measurement, Theory

Keywords: Web search, geolocation

1.

INTRODUCTION

There has been growing interest in local aspects of Web
search, associating geographic information with Web content
[1, 2, 4, 11, 12, 13] and search engine queries [7, 19]. Such
applications point to the outlines of a broad and largely open
issue: understanding and quantifying the types of spatial
variation that search queries can exhibit.

Many topics have a geographic focus of interest; sports
teams, newspapers, schools, airlines, cell-phone companies,
politicians, tourist attractions, cuisine, hobbies, weather events,
and styles of music are just a few examples. This diversity of
examples exposes a corresponding diversity in the way that
spatial variation can be manifested: interest in a topic can
be tightly concentrated at a particular location or spread
diﬀusely over a broader region; it can have one geographic
“center” or several; it can move over time. To characterize

Supported in part by NSF grants CCF-0325453, CNS-
0403340, BCS-0537606, and IIS-0705774, and by the John
D. and Catherine T. MacArthur Foundation.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

queries according to this continuum of possible geographic
traits, we need a model and a source of data rich enough to
be able to discover subtle distinctions in spatial properties.
Here we describe a framework for modeling the spatial
variation in search queries, using data from search engine
query logs, supplemented with geolocation techniques to as-
sign accurate locations to a (large) subset of the IP addresses
issuing the queries. In this way, we deﬁne the geographic fo-
cus of a topic by the locations of the people who search for
it, rather than the locations of the servers hosting the Web
content itself — in other words, according to the locus of
user interest expressed by searches.

Our model is probabilistic, and discovers for each query a
maximum-likelihood value for a center — the “hot spot” of
interest — and a dispersion — the extent to which interest in
the query is tightly concentrated around the query or more
diﬀuse. Each of these two quantities has a natural meaning:
the center provides a location, while the dispersion situates
the query on a continuous spectrum ranging from local to
national appeal. In this way, they function similarity to the
concepts of power and spread considered by Ding et al. in the
context of Web resources [4], but deﬁned in a very diﬀerent
way here based on a probabilistic model over usage data.

Determining an accurate center and dispersion has po-
tential applications in a number of contexts. It clearly has
a role in focusing search-based marketing and advertising
eﬀorts by region, based on geographic distinctions among
diﬀerent queries.
It can also be useful as a component of
search engine rankings themselves, for reﬁning or reorder-
ing query results based on geographic information. Finally,
it can help in tools concerned with tracking news and cur-
rent awareness, by distinguishing among diﬀerent interest in
news topics by locale.

Ultimately, then, the question is whether there is enough
signal in raw query logs to produce values for the center
and dispersion of a query with reasonable accuracy. To take
a concrete example, will the query “Yankees” really local-
ize to New York City — and will a much less searched-for
term like “Royals” really localize to Kansas City — based
purely on the latitudes and longitudes of queries, and de-
spite the highly uneven distribution of locations from which
these queries are being made, as well as the potentially ob-
fuscating additional meanings of each? And will the range
of dispersions for a topic such as baseball indeed distinguish
teams (such as the Yankees) with a national following from
those whose following is mainly local?

357WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, ChinaBasic properties of the model. We ﬁnd, in fact, that a
natural generative model for query production based on ge-
ography can produce highly accurate centers and dispersions
for a broad range of queries, even reﬂecting geographic dis-
tinctions that are subtle, short-range, and sometimes tem-
porally varying. The model is based on a decomposition of
the surface of the earth into small grid cells; we assume that
for each grid cell x, there is a probability px that a random
search from this cell will be equal to the query under con-
sideration. In the basic form of the model, we then posit
that each px should decrease with the distance of x from a
“hot-spot” cell z; the cell z is then the center, and the rate
of decrease of px as a function of its distance from z deter-
mines the dispersion. We develop an eﬃcient algorithm to
compute the maximum-likelihood values for the center and
dispersion, capable of scaling to handle complete query logs.
We describe a range of tests indicating that our method
is eﬀective at accurately localizing queries when there is a
natural “ground truth” value for the center: to mention just
a few examples, the names of almost all professional baseball
teams are localized to their home cities, the names of almost
all U.S. Senators are localized to their home states, and the
names of national parks are localized to their physical lo-
cations. Indeed, we show through a comparative evaluation
that for localization accuracy on these types of queries, our
probabilistic model signiﬁcantly outperforms simpler geo-
metric techniques, as well as state-of-the-art commercial soft-
ware for query localization. This evaluation is based on the
computed center; we also show that the dispersion follows
a natural pattern for these classes of queries, ranging from
queries that have broad appeal to those that are tightly fo-
cused geographically.

With a scalable method for determining centers and dis-
persions for queries, it becomes possible to assess the spatial
variation of large collections of queries. We ﬁnd that among
the most 1000 frequent queries in the full log, there is sur-
prising geographic concentration in a number of them. And
with a simpler heuristic version of our probabilistic model,
we perform a much more massive study — analyzing the
100,000 most frequent queries, and tagging each location
on the surface of the earth with the queries that have the
most signiﬁcant concentration in that location with respect
to the model. The resulting map of signiﬁcant queries re-
veals trends that range from the global — such as the kinds
of on-line social-networking sites favored in diﬀerent parts
of the world — to the very local — with striking geographic
speciﬁcity as names of community colleges, high schools, and
local newspapers vary between locations as little as ten miles
apart.

Further extensions to the model. We can extend the
model to handle other forms of spatial variation as well. To
begin with, a number of queries have the property that their
geographic focus noticeably shifts over time — for exam-
ple, seasonal eﬀects over slow time scales, and news events
over more rapid time scales. We show how to extend the
model to allow the center and dispersion to vary with time
— incorporating an additional probabilistic component that
favors relatively “smooth” temporal motion in these quanti-
ties. Tracking these quantities over time can then be done
eﬃciently with a shortest-path computation in a graph de-
rived from the spatial arrangement of the grid cells from
which the queries are issued. Here too the results can be

quite striking:
for the query “Hurricane Dean,” for exam-
ple, one can see the query center moving day-by-day in a
way that tracks the storm center’s westward movement into
Mexico — and with a dispersion that starts out very con-
centrated but expands widely as the hurricane approaches
land and begins appearing in the national news.

We describe other extensions as well, including a method
for modeling spatial variation with multiple centers, and a
method for comparing the geographic concentration of mul-
tiple queries to determine the approximate “sphere of inﬂu-
ence” of each.

Organization of the paper. The remainder of the paper
is organized as follows. In Section 2 we describe the model
and our algorithms for estimating the maximum-likelihood
values for the center and dispersion. In Section 3 we pro-
vide examples of the method’s performance on queries with a
natural geographic focus, including a description of its eval-
uation relative to other approaches. We describe extensions
to the model, including temporal variation and the problem
of identifying multiple centers, in Section 4. In Section 5, we
discuss methods to simultaneously locate many queries on
a shared map, thereby illustrating regional variation at the
level of large numbers of topics. Finally, we discuss related
work in Section 6 and conclude in Section 7.
2. MODELING SPATIAL VARIATION
2.1 Methodology

Our data consists of Yahoo! search query logs. For each
query, these logs give us both the query string and an ap-
proximation of the latitude and longitude from which the
query originated (based on IP address). In order to reduce
the eﬀect of factors like network address translation, which
allows many users to appear to come from the same IP, we
ﬁrst remove all queries that originate from IP addresses with
particularly high search frequencies. The removed IPs ac-
count for less than 1% of all the queries. Furthermore, we
focused only on North American queries, discarding any fur-
ther west than 135◦ W, or further east than 60◦ W, as well
as those south of 15◦ N or north of 60◦ N.

To reduce the variability introduced by people’s usage
habits, we further process the data so that no IP address
is considered to issue more than a single query during the
time window we consider. Thus, with respect to a particu-
lar query, we consider how many distinct IP addresses from
each geographic location issued at least one query during a
time window, and how many of those IP addresses issued the
particular query under consideration at least once. (For ease
of discussion, we will often refer to “users” issuing queries,
although for the above-mentioned reasons, IP addresses are
in fact our basic unit of analysis.)
2.2 Model

For a given query, we posit a simple generative model to
explain the diﬀerential frequency with which the query ap-
pears across geographic regions. In this model, each query
has a geographic center represented by a single point. This
center corresponds to the point at which the query should
occur most frequently, with frequency then falling oﬀ in dis-
tance from the center.

In addition to its central point, each query in this model
has two other parameters associated with it: a constant, C,

358WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, Chinagiving the frequency at the query’s center, and an exponent
α determining how quickly the frequency falls oﬀ as one gets
further away from the center. The model posits that when
a random user at distance d from the query’s center issues a
query, it is equal to the query under consideration with prob-
ability Cd−α. For queries that are very local, such as the
name of a small city, we expect a large value of α, indicating
that people rarely search for that query unless they are quite
close to the query’s center. On the other hand, a query with
essentially no geographic aspects or regional bias might have
α very close to zero, indicating that the frequency is essen-
tially uniform over geography. The polynomial functional
form is employed here based on initial exploratory analysis
of the data, and for tractability of the model; it is also suﬃ-
cient for our purposes, as it is capable of ranging smoothly
(as α varies) from a uniform distribution of user interest to
distributions that are sharply peaked.
2.3 Algorithm

With this model in mind, we can focus on a particular
query q and take a maximum-likelihood approach to discov-
ering the parameters for q from the data. For a particular C,
and α, we can compute the probability that the true query
logs came from this model. For each log entry consisting of a
user issuing a query, we compute p = Cd−α, where d is that
person’s distance from the query center. If that person is-
sues query q, we multiply the overall probability of the data
by p, and by 1 − p otherwise. (To avoid underﬂow, we work
by adding logarithms of probabilities, rather than actually
multiplying.)

We now have a way to evaluate a particular set of parame-
ters on a particular query; but it would be far too expensive
to consider a wide range of parameters using a brute force
method of simply trying many of them. Instead, we ﬁrst ob-
serve that moving the center a little bit tends not to aﬀect
the overall log-odds very much. Thus, our search algorithm
starts by trying centers on a coarse mesh. It then selects the
best one, and uses a ﬁner grain mesh on the region around
that best one. This can be repeated until the desired accu-
racy is reached. In practice we ﬁnd that starting with points
at every two degrees of latitude and longitude, and ending
with points at tenths of degrees works well.

Once we have selected a center, we now have to optimize
the other two parameters. Our approach is based on The-
orem 1, below, which establishes that the log-likelihood as
a function of C and α is unimodal; we therefore develop
techniques based on optimization of unimodal multivariate
functions to ﬁnd the optimal parameters. For scalability,
we bucket all the queries by their distance from the center,
enabling us to evaluate a particular choice of C and α very
quickly.

To establish the necessary unimodality property, we pro-
ceed as follows. Let S be the set of log entries for query q
(indexed by users who issued this q), and let di be the dis-
tance of a user i from the query’s center. Then f (C, α) =
Pi∈S log Cd
) is the log of the prob-
ability for parameters C and α.

i +Pi /∈S log(1− Cd
−α

−α
i

Lemma 1. f (C, α) is concave in C.

Lemma 2. f (C, α) is concave in α.

Theorem 1. f (C, α) has exactly one local maximum over

its parameter space.

−α2
−α1
0 = C2d
0

Proof. For sake of a contradiction, imagine that there
were two choices of parameters, (C1, α1) and (C2, α2), each
of which was a local maximum. Unless α1 = α2 (in which
case they can’t both be maxima by Lemma 2), there is some
d0 such that C1d
We now consider all functions Cd−α that cross the point
−α1
). Each is fully determined by the
(d0, C1d
value of the exponent α, having C(α) = C1dα−α1
0
. We now
consider the likelihood f (C(α), α). By simply taking the sec-
ond derivative of f (C(α), α) with respect to α, we ﬁnd that
it is always negative, contradicting our original assumption
of two maxima.

−α2
= C2d
0

.

0

f (C(α), α) = X
i∈S

00

f

(C(α), α) = X
i /∈S

log C1dα−α1

0

−α
d
i

+ X
i /∈S
−(C1d
(1 − C1d
−C1d

( d0
di
( d0

−α
0
−α1
0
−α
( d0
0
1 − C1d

+

log 1 − C1dα−α1

0

−α
d
i

)α)2

d )α)2
d )α log2 d0
−α1
0

d )α

( d0

d

−α
C1d
0

( d0
di

)α is a probability in [0, 1], which makes the ﬁrst
term at most 0. The second term is also non-positive for the
same reason. The only way that the expression can evaluate
to 0 is if C1 is 0. However, in this case the log-odds will have
a log 0 for each i ∈ S.

In practice, our numerical methods converge quickly to the
single maximum value. Our (unoptimized) implementation
runs in under 30 seconds on a modern machine.

3. ASSESSING THE MODEL

We now discuss some of the results that can obtained from
this model, running on the complete set of query logs. These
results can be organized by the kinds of queries for which
spatial variation stands out: on the one hand, there are
classes of queries that by their nature have a geographic fo-
cus (for example, names of schools, newspapers, or sports
teams); and on the other hand, there are queries whose ge-
ographic content is a priori less apparent. Queries in this
latter category can be found eﬀectively by enumeration —
that is, applying the model to all the frequent queries in the
log and identifying those with large exponents, indicating
geographic concentration.

We begin with the simplest kinds of examples — those
queries for which there is a natural geographic focus. For
analysis and evaluation, we consider several classes of such
queries here: names of the most populous U.S. cities, names
of certain universities, names of high-circulation U.S. news-
papers, names of all Major League Baseball teams, names of
all U.S. national parks, names of all U.S. Senators, as well
as certain companies such as banks, airlines, and cell-phone
carriers that have a regional focus. We will refer to these
categories as our basic classes. Each query in one of the basic
classes has an a priori natural geographic center, though the
center may be conceptually a “point” (e.g.
in the case of a
national park or the home city of a sports team) or a broader
region (e.g. in the case of a state represented by a Senator
or a region served by a cell-phone carrier). In all cases, the
model identiﬁes these natural centers with high accuracy, as
our more detailed evaluation below demonstrates.

359WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, ChinaFigure 2: Performance of algorithms on baseball
team queries.

By way of example, Figure 1 shows the query distribution
for three queries in these classes: “Red Sox,” “Bell South,”
“Grand Canyon National Park.” The ﬁrst two queries are
clearly easy to localize: We see that the query “Red Sox”
has a conceptual hot-spot in New England, while the hot-
spot for “Bell South” closely tracks the boundaries of the
states that this company primarily serves. “Grand Canyon
National Park” is one instance of a class of examples that
is more subtle for several reasons. First, there is relatively
little data on this query, even at the scale of complete logs;
and as the image makes clear, the location of the park itself
is found although the hot-spot is not immediately apparent
visually. But beyond this, it should not have been clear
in advance that the location of the park should even be a
natural “center” for this query: the fact that it emerges as
the center suggests that there is a hot-spot in query activity
coming from people who are already at the physical location,
rather than people from nearby population centers planning
future vacations. We ﬁnd this in general with geographic
destinations in less-populated areas — despite the fact that
a large fraction of visitors come from some distance away,
the center is generally at the location itself.

In addition to the basic classes of queries, applying the
model to all frequent queries turns up geographic informa-
tion about queries that have no a priori “home.” As one il-
lustration, the model uncovers the oft-discussed observation
that diﬀerent social-networking sites have particular concen-
tration in diﬀerent regions. For example, despite the enor-
mous penetration of Facebook, a hot-spot is still uncovered
in Southern Ontario — a fact about the Facebook user de-
mographics that the company has remarked on in its own
publicity. Similar observations are easily found for other
social-networking sites as well.

We now turn from these examples to a more systematic
evaluation of the model’s eﬀectiveness at localizing centers.
3.1 Evaluation

We begin by formulating a framework within which to
evaluate the model. The premise is that for a basic class in
which the a priori natural centers have precise coordinates
(e.g. the home city of a sports team), we deﬁne aq to be

Figure 1: Geolocation of queries “Red Sox,” “Grand
Canyon National Park,” and “Bell South”. (The cap-
italization of queries is reduced to a canonical form
in our experiments.) These ﬁgures are drawn as heat
maps, with the color spectrum indicating the query
intensity per grid cell (and hence there is value in
viewing these, as well as later ﬁgures, on a color
display or color print-out). The arrows indicate the
centers computed using our model.

 0 5 10 15 20 25 30 0 200 400 600 800 1000 1200 1400 1600 1800 2000cumulative countdistance in milesBaseball teamsMeanMedianHighest FrequencyMost Likely360WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, ChinaNewspaper
The Wall Street Journal
USA Today
The New York Times
New York Post
The Daily News
Washington Post
Los Angeles Times
The Star Ledger
Detroit Freepress
San Francisco Chronicle
Chicago Tribue
Philadelphia Inquirer
Chicago Sun Times
The Boston Globe
The Arizona Republic
Dallas Morning News
Houston Chronicle
Star Tribune

α

0.111327
0.263173
0.304889
0.459145
0.601810
0.719161
0.782538
0.998462
1.068055
1.091030
1.102554
1.140618
1.165482
1.171179
1.284957
1.286526
1.289576
1.337356

Figure 3: Performance of algorithms on high-
population U.S. cities.

Accuracy Mean Median

51

12

Our
Local
density model

80

90

Table 2: Estimation of exponents α for high-
circulation U.S. newspapers.

Table 1: Accuracy of algorithms for localizing sena-
tors inside their respective states.

this natural center, and we deﬁne bq to be the center com-
puted by the model. Evaluating the distance between them,
d(aq, bq), gives an indication of how accurate the model’s
localization is.

To compare our model with simpler baselines, we also de-
termine the distance from aq to centers computed by other
means; speciﬁcally:

• nq, the weighted center of gravity of all instances of

query q;

• mq, the point at the median latitude and median lon-

gitude of all instances of query q; and

• ‘q, the point with the highest local density of instances
of q — that is, with the lowest likelihood relative to
the overall base-rate for query q.

Note that the ﬁrst two methods are geometric, while the
third is probabilistic but much simpler than our model. In
Figure 2, we compare all these methods at localizing all Ma-
jor League Baseball team names to their home cities — in
particular, depicting the cumulative distribution of distances
to aq over all teams. We see that our model’s center bq
and the optimum log-odds center ‘q greatly outperform the
geometric methods, with both bq and ‘q localizing almost
all team names to within 60 miles of their respective home
cities. This is in a sense somewhat surprising, given the mul-
tiple meanings (other than baseball-related ones) that many
baseball team names have. Also, recall that our model, in
addition to producing the center bq, is also estimating dis-
persion in the form of the exponent α, whereas one gets only
a center from the baseline ‘q. Due in part to the need to ﬁt
the full query distribution via this exponent, our model is
less exact in its localization (compared to ‘q) for distances
signiﬁcantly under 60 miles.

City
New York
Chicago
Phoenix
Dallas
Houston
Los Angeles
San Antonio
Philadelphia
Detroit
San Jose

α

0.396527
0.528589
0.551841
0.588299
0.608562
0.615746
0.763223
0.783850
0.786158
0.850962

Table 3: Estimation of exponents α for the 10 most
populous U.S. cities.

We perform an analogous evaluation for the names of all
U.S. Senators, in which the natural center is no longer a
point but a region (namely, their home state.) We eval-
uate, for our model and the three baseline methods, how
many of the 100 Senators are localized to a center within
the state they represent. Table 1 shows these results; our
model outperforms all the baselines, with mean and me-
dian performing particularly poorly. (Certain queries in this
class illustrate additional qualitative contrasts between the
models; for example, our method localizes the query “Lisa
Murkowski” to her home state of Alaska, while the three
baseline methods all put the center in the continental U.S.)
It is also natural to evaluate our model against state-of-
the-art commercial services, which employ features other
than usage, for inferring whether a query is “local.” In par-
ticular, we use the service WhereOnEarth, a leading exem-
plar of this type of application. Our ﬁrst ﬁnding is that
query log data reveals strong spatial variation for much
broader ranges of queries than services such as WhereOn-
Earth pick up. As a result, direct comparison is a bit diﬃ-
cult, since many of even our basic classes above are not con-
sidered localizable by these services. For example, Where-
OnEarth does not consider the names of any U.S. Senators

 0 10 20 30 40 50 60 70 80 90 100 0 500 1000 1500 2000 2500 3000 3500cumulative countdistance in milesCitiesMeanMedianHighest FrequencyMost Likely361WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, ChinaSchool
Harvard
Caltech
Columbia
MIT
Princeton
Yale
Stanford
U. Penn
Duke
U. Chicago

α

0.386832
0.423631
0.441880
0.457628
0.497590
0.514267
0.627069
0.729556
0.741114
1.097012

Table 4: Estimation of exponents α for the 10
highest-ranked U.S. universities according to U.S.
News & World Report.

or Major League Baseball teams to be local queries for which
a center can be inferred, despite the fact that our model ﬁnds
correct centers for almost all from usage data.

For other basic classes, such as high-population U.S. cities,
major U.S. universities, and U.S. national parks, WhereOn-
Earth can determine exact values for almost all by table
look-up. Our model does well in all these cases too, de-
spite having no comparable access to hard-coded data; and
it outperforms the three baselines nq, mq, ‘q in all these
cases. Figure 3 shows the performance for U.S. cities; note
that our model signiﬁcantly outperforms the other three ap-
proaches, and the the center of gravity nq outperforms the
simple probabilistic baseline ‘q in this case.

3.2 Exponents and Dispersion

Thus far we have been considering the centers computed
by the model, but there is additional value in the exponent
as well. This provides the measure of dispersion mentioned
in the introduction; a large exponent indicates rapid decay
away from the center, and hence strong geographic concen-
tration, while a smaller exponent indicates interest over a
broader region.

Thus, particularly when we compare exponents for queries
from the same basic class, we can place items on a spectrum
ranging from local appeal to more national appeal. For ex-
ample, Tables 2-4 show the exponents for the 10 most pop-
ulous U.S. cities, for the 10 highest-ranked U.S. universities
according to U.S. News & World Report, and for a collection
of high-circulation U.S. newspapers.

Ranking each of these lists by exponent places them on a
spectrum from local to national appeal. For example, the
Wall Street Journal and USA Today are the two newspapers
with the lowest exponents, indicating national interest, with
the New York Times close behind. Other high-circulation
newspapers are regional in their appeal, with exponents that
are much higher. We also see that the spatial variation in
queries for city names does not directly correspond to the
populations of the cities; for example, Los Angeles has a
comparatively large exponent, while the second-lowest ex-
ponent among large U.S. cities belongs to one that is not in
the top 10: Las Vegas, with an exponent of .482. While we
omit the list of national parks due to space limitations, there
is signiﬁcant variation in exponents here too, with Death
Valley, the Grand Canyon, and the Everglades having the
lowest values (and hence the most national reach in queries).

Figure 4: The path of Hurricane Dean’s storm cen-
ter, moving west through the Caribbean, alongside
the smoothed path of query centers for “Hurricane
Dean.”

Figure 5: Change in the exponent for “Hurricane
Dean” by hour, as interest in the topic shifted from
local to national.

4. EXTENSIONS: TEMPORAL VARIATION

AND MULTIPLE CENTERS

4.1 Temporal Aspects

While most localizable queries maintain relatively stable
centers and dispersions over time, it is easy to ﬁnd queries
which vary in both of these dimensions. A local news story
might start with limited dispersion as only people in the
region are aware of it. If the story then gains national at-
tention, the center may stay the same, but the exponent α
can decrease as query traﬃc increases from farther away.

In other cases, the center may move as well, and a good
source of examples for this comes from large weather phe-
nomena. For instance, as a hurricane moves over time, the
people who are next in its path at any given moment tend
to search for it with the highest intensity, and thus we might
expect the query center to roughly track the storm’s center.
We can observe this in the query-log data by considering
a sequence of 24-hour time slices, at oﬀsets of one hour from

 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 0 50 100 150 200 250 300alphaHourAlpha over time for Hurricane Dean362WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, ChinaFigure 6: Multiple centers for the query “United Airlines.”

each other (i.e. considering the 24 hours starting at mid-
night, then the 24 hours starting at 1 AM, and so forth).
We can then calculate the center for each of these 24 hour
periods. By using a sliding window in this way, we are able
to ﬁt our parameters to more data, making them more re-
liable. Employing 24-hour periods has the useful eﬀect of
mitigating diurnal variation, since all times of day are rep-
resented in each period.

In the case of a major recent hurricane, Hurricane Dean,
we observe a clear westerly trend, with centers starting far
out in the Caribbean, and tending to move westward towards
Southeast Texas as the hurricane does so. There is also
a clear trend towards decreasing α as the hurricane gains
national attention.

For a number of reasons, however, the sequence of query
centers computed for each time slice in isolation does not
move very smoothly.
In large part, this is because the
amount of query-log data for a single hurricane, even a ma-
jor one, is relatively small, especially before it approaches
mainland North America. Thus, we improve the results us-
ing a more complex method: we couple the computation of
centers across the diﬀerent time-slices by a natural and eﬃ-
cient algorithm, obtaining a smooth query-center path that
tracks the true path of the storm’s center with surprising
ﬁdelity (Figure 4).

The coupled computation works as follows. For each 24-
hour period, and each latitude and longitude, we compute
the cost of the center at that location as the negative log-
probability for the optimal choice of C and α. In order to
account for diﬀerence in total volume between diﬀerent 24-
hour periods, we normalize by dividing the cost at a point
A by the the minimum cost over all possible centers for that
same 24-hour period. Thus, we have a normalized cost for
every coordinate for every time window. We now deﬁne
a cost for moving the center from point A to point B as
γ|A − B|2. Thus paths which jump around a lot are pe-
nalized, while smooth paths which move at a constant rate
have relatively low cost. The goal now is to ﬁnd a sequence
of centers for the sequence of 24-hour windows (each oﬀset
by one hour from the previous one) that minimizes the sum

of the costs from the placement of the centers and the costs
for the movement from each center to the next.

It is easy to ﬁnd the lowest-cost sequence of centers for
various constants γ using dynamic programming. Once we
have done this, we can examine the smoothed paths taken
by the center of the query for diﬀerent γ, one of which is
shown in Figure 4. We see a striking similarity between the
actual path of the storm’s center and the smoothed path
taken by the computed center.

In addition to tracking the storm’s motion through query
logs, we can also watch how the query’s dispersion changes
over time (Figure 5). By examining the optimal choices of
α over time for the smoothed path, we can see that the
hurricane started out as an event of very local interest, with
its center near the Lesser Antilles. As the storm moved west
and intensiﬁed, more and more people started taking notice,
and it eventually became a major news story, as it was the
one of the most intense hurricanes to ever reach land.
4.2 Multiple Centers

While the simple, single-center model describes many queries

fairly well, some queries are clearly better modeled with mul-
tiple centers. For example, major airlines typically have
three or four hub cities, and it is clear from the query-log
data that the regions around each of these cities have high
query frequency for their respective airlines.

To model this sort of spatial variation we extend our gen-
erative model by placing multiple centers, each with its own
C and α parameters. For each point, we use the probability
given by the center which yields the highest probability to
that point. Thus, we can easily calculate the log-odds for a
choice of multiple centers with diﬀerent parameters.

This, however, makes the maximum-likelihood optimiza-
tion problem much harder, and so we use a heuristic based
on the K-means clustering algorithm. We start with K cen-
ters placed at random, for some constant K. We then op-
timize each of these centers, treating each one as if it were
the only center being used (our previous algorithm). After
we do this for every center, we look at each geographic point
and determine which of the K centers gives that point the
highest probability, according to the polynomial-decay prob-

363WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, ChinaFigure 7: Distinctive queries for locations in the San Francisco Bay Area.

ability function. We now say that each point is associated
with the center giving it the highest probability. We then
reoptimize each center independently, but considering only
those points that were associated with it during the previ-
ous iteration. This process is repeated a number of times
until it converges. The algorithm is sensitive to the starting
locations of the centers, but by running it many times and
choosing the best outcome, we achieve good results.

As an illustration, Figure 6 shows the results of this algo-
rithm for the query “United Airlines.” United’s largest hub
is in Chicago, and it also has hubs in Denver, Washington
DC, San Francisco, and Los Angeles. The algorithm places
centers in Chicago, Washington, and near Denver. It places
a fourth center oﬀ the coast of California, which has the
eﬀect of hitting both San Francisco and Los Angeles some-
what equally. (Note that it is a natural consequence of the
probabilistic model, even with one center, that there may be
low query density at the exact point corresponding to the
center itself.) We see similar results for other airlines.

The multiple-center model is also useful for queries with
two distinct geographic meanings. For example, on the
query “Washington,” with two centers, the algorithm places
one center in DC and the other in Washington state. For
the query “Cardinals,” the algorithm places one center in

St. Louis (the home of the baseball team) and the other in
Arizona (the home of the football team).

5. ENUMERATING MULTIPLE QUERIES ON

A SHARED MAP

5.1 Distinctive Queries for all Locations

Given a way to assess the spatial variation of individual
queries, we can enumerate all the queries in the log and — for
each location on earth — ﬁnd the queries that are the most
“unusual” or “distinctive” for that location. In this section
we describe the results of such a computation, leading to an
annotated world map of which the image in Figure 7 is a
tiny portion.

We deﬁne locations as before, using tenth-of-a-degree grid
(For reference, such a cell has a side length of less
cells.
than 10 miles .) We deﬁne “distinctiveness” at a given cell
x using a variant of the probabilistic model from Section 2.
For each query q, let p denote the fraction of all entries in
the log corresponding to users issuing q. Let tx be the to-
tal number of log entries from x, and let sx be the number
of log entries from x corresponding to users issuing q. As-
suming a simple independence-based model, the probability
of this observed data given the background probability p is

364WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, ChinaFigure 8: Spheres of inﬂuence of baseball teams.

sxpsx (1 − p)tx−sx . We choose the queries q for which this
 tx
probability is lowest to serve as the most distinctive queries
for location x — they are the ones that deviate the most
signiﬁcantly at x from their global background rate.

We perform the computation on queries issued during a
week. To have suﬃcient sample size, we only consider loca-
tions with at least 5000 queries during the week. This yields
3154 locations worldwide with 2643 locations in the conti-
nental US; for each, we ﬁnd the most distinctive queries.

We illustrate some of the results of this in Figure 7; for
ease of presentation, we only display the San Francisco Bay
Area, and only a subset of the locations there. While one
might have expected a region this small to have roughly the
same distinctive queries in each cell (things like “San Fran-
cisco,” “San Jose,” and so forth), in fact we see signiﬁcant
and meaningful diﬀerences between locations that are only
a few miles apart (see for example, the distinction between
queries being issued in Palo Alto and Sunnyvale.)

5.2 Spheres of Inﬂuence

If we consider many of the basic classes of queries from
Section 3, they represent entities that are at least implic-
itly in competition. (Consider, for example, baseball teams,
universities, or newspapers.) By representing all the queries
from a single class on a shared map, we can try understand-
ing and visualizing their respective “spheres of inﬂuence” —
the regions in which each is dominant. In Figure 8, we de-
pict such regions of inﬂuence for all Major League Baseball
teams on a map of the U.S.: thus the team names are the
queries, and each grid cell is colored according to the dis-
tribution of queries for baseball teams issued from that cell.

We now discuss the methodology underlying images such as
this, then make some observations about this image itself.

To deﬁne regions of inﬂuence, we need a way to represent
the queries that are dominant at diﬀerent grid cells. The
simplest way would be just to see which query produces the
most log entries for each cell, and color the cell with this
most abundant query. However, due to the sparsity of the
data, this produces a fairly noisy representation, with adja-
cent cells generally diﬀering in color, and it doesn’t capture
the diﬀerence between minor dominance and strong domi-
nance in a given cell.

A better way to represent the regions of inﬂuence, then,
is to imagine that each query from a particular cell acts as a
vote for that query. The pixels are then colored by blending
colors according to the voting. Done in a straightforward
way, this now has the opposite problem — most regions are
too blended in the image. To strike a balance, we produce
the image in Figure 8 by counting a query with N log entries
in a cell as having N c votes for a small constant c > 1.
Varying c lets us bring out the dominant color, but still
allowing blending when there are close competitors.

The ﬁrst observation about Figure 8, of course, is that
despite the highly uneven national volumes of queries for
diﬀerent teams, we see a very clean geographic breakdown
of who follows which teams. It is also somewhat surprising
to see the extent to which team dominance breaks down
along state lines — a number of the colored regions follow
state boundaries very clearly. For instance, in Michigan,
across the lake from Chicago but far from Detroit, it is the
Tigers, not the Cubs who have the largest following. It is
also interesting to note the regions which do not have a clear-

365WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, Chinacut winner. For instance, in the Carolinas and Louisiana
there are many queries for baseball teams, but there is no
one team that stands out above the rest.

6. RELATED WORK

Prior work related to this paper can be grouped roughly
into four high-level areas: geolocation of Web content, ge-
olocation of search queries, eﬃcient query processing with
geographic information, and spatial hot-spot models.

There is a signiﬁcant line of work on inferring geographic
locations for Web pages and other on-line content. Buyukkok-
ten et al. [2] use geographic entities and network IP address
information to geolocate Web pages. McCurley [12] pro-
posed a spatial browsing of Web data; his approach was to
use a rich set of geographic features, including telephone
numbers, to infer geospatial context. Amitay et al.
[1] de-
scribe a system, Web-a-Where, that assigns each page a ge-
ographic focus. Further work includes [11, 14, 18]. Ding
et al.
[4] introduced the idea of the power and spread of a
Web page, which are analogous to the center and dispersion
parameters in our model. However, their approach is not
based on a probabilistic model or corresponding optimiza-
tion criterion for the parameters. Some applications of Web
content geolocation include mining spatio-temporal themes
[13] and geographically focused collaborative crawling [6].

In contrast, much less work has been done on geolocating
Web queries, our focus here. Gravano et al.
[7] performed
an early investigation of this issue, using machine learning
techniques to classify search queries as either local or global.
Closer to our work, the paper of Wang et al.
[19] searches
for the “dominant location” of a query in the context of a
system for exploiting query localization to improve retrieval
performance. They include power and spread among their
features, and again the approach is quite diﬀerent, and does
not include a speciﬁc model for spatial variation.

Query processing with geographic constraints is an active
research area. Much work here constructs and processes
spatial representations to enable eﬃcient query processing.
Some recent work in this area is by Chen et al. [3], Tezuka
et al. [17], and Schockaert and De Cock [16].

Finally, spatial hot-spot models have been extensively stud-
ied in statistics. For a good account of the work in this area,
ranging from the ad hoc to the model-based, see the discus-
sion in Neill et al.
[15], as well as Kulldorﬀ [9] and the
book edited by Lawson and Denison [10]. There are also
connections to temporal hot-spot models, which use one-
dimensional analogues of these computations [5, 8].

7. CONCLUSIONS

We have seen that large-scale query-log data contains enough

information to build eﬀective models of spatial variation. In
addition to ﬁnding centers for queries with an accuracy that
outperforms competing baselines, and extracting geographic
information for a broader range of queries than is accessible
to commercial systems, our models also form the basis for
algorithms that incorporate temporal processes, as well as
methods to analyze variation for many queries simultane-
ously at a global level.

There are a number of directions in which this work could
be extended. It would be interesting to consider our analysis
of simultaneous spatial and temporal variation (as in Section
4.1) in the context of further probabilistic models, poten-

tially exploring connections with the methodology in [13]. It
would also be interesting to incorporate more complex mod-
els of user behavior into a framework that explicitly took
spatial variation into account, potentially resulting in more
accurate kinds of localization for broader classes of queries.
Ultimately, as the local applications of search continue to
broaden, we can expect to see questions of this sort arise
increasingly from the rich interaction between Web informa-
tion, user interests, and the geographic and spatial frames
of reference in which they are embedded.

8. REFERENCES
[1] E. Amitay, N. Har’El, R. Sivan, A. Soﬀer.

Web-a-where: Geotagging Web content. In SIGIR,
pages 273–280, 2004.

[2] O. Buyukkokten, J. Cho, H. Garcia-Molina,
L. Gravano, and N. Shivakumar. Exploiting
geographical location information of Web pages. In
WebDB (Informal Proceedings), pages 91–96, 1999.

[3] Y.-Y. Chen, T. Suel, and A. Markowetz. Eﬃcient

query processing in geographic Web search engines. In
SIGMOD, pages 277–288, 2006.

[4] J. Ding, L. Gravano, N. Shivakumar. Computing

geographical scopes of Web resources. In VLDB, pages
545–556, 2000.

[5] M. Dubinko, R. Kumar, J. Magnani, J. Novak, P.

Raghavan, A. Tomkins. Visualizing tags over time. In
WWW, pages 193–202, 2006.

[6] W. Gao, H. C. Lee, Y. Miao. Geographically focused

collaborative crawling. In WWW, pages 287–296, 2006.

[7] L. Gravano, V. Hatzivassiloglou, and R. Lichtenstein.

Categorizing Web queries according to geographical
locality. In CIKM, pages 325–333, 2003.

[8] J. Kleinberg. Temporal dynamics of online information

streams. In M. Garofalakis, J. Gehrke, R. Rastogi
(eds.) Data Stream Management. Springer, 2008.

[9] M. Kulldorﬀ. A spatial scan statistic. Communications

in Statistics: Theory and Methods, 26(6):1481–1496,
1997.

[10] B. Lawson and D. G. T. Denison, editors. Spatial

Cluster Modelling. Chapman & Hall, 2002.

[11] B. Martins, M. S. Chaves, M. J. Silva. Assigning

geographical scopes to Web pages. In ECIR, pages
564–567, 2005.

[12] K. S. McCurley. Geospatial mapping and navigation of

the Web. In WWW, pages 221–229, 2001.

[13] Q. Mei, C. Liu, H. Su, and C. Zhai. A probabilistic

approach to spatiotemporal theme pattern mining on
weblogs. In WWW, pages 533–542, 2006.

[14] Y. Morimoto, M. Aono, M. E. Houle, and K. S.

McCurley. Extracting spatial knowledge from the
Web. In SAINT, pages 326–333, 2003.

[15] D. B. Neill, A. W. Moore, and G. F. Cooper. A

Bayesian spatial scan statistic. In NIPS, 2005.
[16] S. Schockaert and M. D. Cock. Neighborhood
restrictions in geographic IR. In SIGIR, pages
167–174, 2007.

[17] T. Tezuka, T. Kurashima, and K. Tanaka. Toward
tighter integration of Web search with a geographic
information system. In WWW, pages 277–286, 2006.

[18] C. Wang, X. Xie, L. Wang, Y. Lu, W.-Y. Ma.

Detecting geographic locations from Web resources. In
GIR, pages 17–24, 2005.

[19] L. Wang, C. Wang, X. Xie, J. Forman, Y. Lu, W.-Y.

Ma, and Y. Li. Detecting dominant locations from
search queries. In SIGIR, pages 424–431, 2005.

366WWW 2008 / Refereed Track: Search - Query AnalysisApril 21-25, 2008 · Beijing, China