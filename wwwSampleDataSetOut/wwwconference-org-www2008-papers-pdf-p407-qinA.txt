Learning to Rank Relational Objects and Its Application to

Web Search

∗

Tao Qin

Tsinghua University
Beijing, P.R.China

tsintao@gmail.com
De-Sheng Wang
Tsinghua University
Beijing, P.R.China

wangdsh_ee@mail.thu.edu.cn

Tie-Yan Liu

Microsoft Research Asia

Beijing, P.R.China

tyliu@microsoft.com

Wen-Ying Xiong∗
Peking University
Beijing, P.R.China

ﬂykitej@gmail.com

Xu-Dong Zhang
Tsinghua University
Beijing, P.R.China

zhangxd@mail.thu.edu.cn

Hang Li

Microsoft Research Asia

Beijing, P.R.China

hangli@microsoft.com

ABSTRACT
Learning to rank is a new statistical learning technology on
creating a ranking model for sorting objects. The technology
has been successfully applied to web search, and is becoming
one of the key machineries for building search engines. Exist-
ing approaches to learning to rank, however, did not consider
the cases in which there exists relationship between the ob-
jects to be ranked, despite of the fact that such situations are
very common in practice. For example, in web search, given
a query certain relationships usually exist among the the
retrieved documents, e.g., URL hierarchy, similarity, etc.,
and sometimes it is necessary to utilize the information in
ranking of the documents. This paper addresses the issue
and formulates it as a novel learning problem, referred to
as, ‘learning to rank relational objects’. In the new learning
task, the ranking model is deﬁned as a function of not only
the contents (features) of objects but also the relations be-
tween objects. The paper further focuses on one setting of
the learning problem in which the way of using relation in-
formation is predetermined. It formalizes the learning task
as an optimization problem in the setting. The paper then
proposes a new method to perform the optimization task,
particularly an implementation based on SVM. Experimen-
tal results show that the proposed method outperforms the
baseline methods for two ranking tasks (Pseudo Relevance
Feedback and Topic Distillation) in web search, indicating
that the proposed method can indeed make eﬀective use of
relation information and content information in ranking.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval - Retrieval models; H.3.4 [Information
Systems Applications]: Systems and Software - perfor-
mance evaluation

General Terms
Algorithms, Experimentation, Theory

∗This work was conducted at Microsoft Research Asia.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

Keywords
Learning to Rank Relational Objects, Relational Ranking
SVM, Pseudo Relevance Feedback, Topic Distillation

1.

INTRODUCTION

Ranking is a central problem for web search, because the
goodness of a search system is mainly evaluated by the ac-
curacy of its ranking results. Traditionally, ranking model is
constructed by tuning a few parameters with a small amount
of labeled data. It is only recently machine learning tech-
nologies called ‘learning to rank’ have been intensively ap-
plied to the task. In the approach, a large number of features
and a large amount of training data are used to create the
ranking function and various optimization techniques (loss
functions and algorithms) are employed to train the rank-
ing function. Previous work shows that learning to rank
has certain advantages when compared with the traditional
approaches. Many methods have been proposed including
Ranking SVM [15, 18], RankBoost [12], RankNet [4], List-
Net [6], AdaRank [34], MHR [23], and FRank [31].

Existing technologies on learning to rank are limited to
one setting of ranking, namely ranking based on content in-
formation. Speciﬁcally, in web search given a query and a
number of retrieved documents containing the query, a rank-
ing function is deﬁned as a function of query and document.
There are other search applications in which relation in-
formation between documents can be or must be exploited.
The relation information can be represented in a graph, or
more generally, a matrix. For example, web pages from the
same site form a sitemap hierarchy. If both a page and its
parent page are about the topic of the query, then it would be
better to rank higher the parent page for this query. This is
a problem referred to as Topic Distillation at TREC [33]. As
another example, similarities between documents are avail-
able, and we can leverage the information to enhance rele-
vance ranking. This is a problem close to Pseudo Relevance
Feedback [29] in IR. Other problems like Subtopic Retrieval
[36] also need utilize relation information. Existing learning
to rank methods, however, cannot handle the problems.

In this paper, we propose a new learning framework re-
ferred to as learning to rank relational objects (e.g., rank
relational documents in web search). In the ranking task,
we make use of both content information and relation infor-
mation. In conventional learning to rank, (when applied to

407WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, Chinaweb search), the ranking function is deﬁned as that of query
and document pair. In contrast, in the new learning task,
the ranking function is deﬁned as that of not only query
and document pair, but also relations between documents.
The framework is very general, and in this paper we address
two speciﬁc tasks: Pseudo Relevance Feedback and Topic
Distillation as examples.

We focus on one setting of learning to rank relational ob-
jects, in which the way of using the relationships between
objects is predeﬁned, while the parameters of the ranking
function need to be trained by using labeled training data.
We formalize the learning task as an optimization problem.
The optimization problem appears to be a challenging issue,
because of the nested structure of the ranking function. We
know of no existing method that can be directly applied.
We then propose a new method to solve the problem, and
speciﬁcally an implementation method based on SVM. Ex-
perimental results show that the proposed method outper-
forms the baseline methods for Pseudo Relevance Feedback
and Topic Distillation.

The remaining part of the paper is organized as follows. In
Section 2, we introduce related work. In Section 3, we give
a deﬁnition on the problem ‘learning to rank relational ob-
jects’ and in Section 4 we propose one solution to the prob-
lem. An SVM-based algorithm is then presented in Section
5, followed by experiments in Section 6. Finally, conclusions
are given in the last section.

2. RELATED WORK

2.1 Learning to rank

Learning to rank is a new area in statistical learning, in
parallel with learning for classiﬁcation, regression, etc. The
area is attracting broad interests recently, in part because
there are many application issues which can be formalized
as ranking, for example, web search, and in part because it
is a novel learning task and there are many unknown issues
which need to be addressed.

Previously, researchers have tried to transform the prob-
lem of ranking into that of classiﬁcation and apply existing
classiﬁcation techniques to perform the task. For example,
as classiﬁcation techniques one can employ SVM, Boosting,
and Neural Network, and this leads to the methods of Rank-
ing SVM [15], RankBoost [12], and RankNet [4], previously
proposed in the literature. Methods for employing the learn-
ing methods in web search have been proposed (e.g., [18]).
Furthermore, methods for making the transformation more
appropriate for search have also been studied (e.g., [5, 23,
31]). See also [30, 8, 11, 13] for other work.

More recently, a number of authors have proposed directly
deﬁning a loss function on list of objects and directly op-
timizing the loss function in learning [6, 34, 35, 26]. This
approach formalizes the ranking problem in a more straight-
forward way and thus tends to be more eﬀective.

All the learning to rank methods, however, are based on
the assumption that there is no relation information between
the objects that should be used in ranking. This is not the
case in practice, for example, in search, as we pointed out.
As a result, existing methods cannot be directly applied to
such kind of setting. Simply extending existing methods
to the setting would not work well, as will be seen in the
experimental results section.

2.2 Using Relation Information in Search

Relation information between documents plays an impor-
tant role in many web search tasks. For example, ranking
web pages on the basis of importance, improving relevance
ranking by using similarity information, diversifying search
results.

Relation information has been used for importance rank-
ing [22, 19]. The basic idea is that if a page has many inlinks,
then the page is likely to be important, and the importance
score can be propagated through the link graph. PageRank
[22] and HITS [19] are well known algorithms for computing
importance of web pages. They rank web pages based on the
Markov chain model and authority-hub model respectively;
both leverage the use of hyperlink (relation) information on
the web.

Similarity between documents is useful information for
search ranking as well. Subtopic Retrieval is an example
In the task, given a query, the returned documents
[36].
should cover as many subtopics as possible.
If there are
documents about the same subtopic, then only one docu-
ment should be selected and ranked high.
(See also [7].)
In other search tasks, similarity between documents is used
to boost relevance, for example, in Pseudo Relevance Feed-
back [29]. The technique ﬁrst conducts a round of relevance
ranking, assumes that the top ranked documents are rele-
vant, and extracts new terms from the relevant documents.
It then formulates a new query and conducts a second round
of ranking. With two rounds of ranking, some relevant doc-
uments dropped in the ﬁrst round can be ranked higher.

Topic Distillation is another example of using relation in-
formation in web search. Here, Topic Distillation refers to
the search task in which we select a few pages that can best
represent a topic by exploiting structure (relation) informa-
tion on the web. It is found that propagating the relevance
of a document to its neighborhood on the hyperlink graph
can improve performance of Topic Distillation [27]. Further-
more, propagating the relevance of a web page to its parent
pages can also boost the accuracy of the task [24].

Although relation information between documents has been

used in search. So far there has been no previous work
on learning to rank which leverages relation information in
ranking. In this paper, we propose a new learning to rank
method which utilizes both content information and relation
information. We take Pseudo Relevance Feedback and Topic
Distillation as examples.
2.3 Learning Using Relation Information

There are a number of learning problems in which relation

information is used.

Semi-supervised learning on graph data is an example,
which is a problem as follows. Given a graph (either directed
or undirected), some of the nodes are labeled, we are to use
the graph, i.e., relation information, to label the remaining
nodes [38, 37, 3]. Some existing methods perform the task
by only using relation information [38, 37], while the others
try to use both content and relation information [3].

Cluster on graph data is another example of using relation
information in learning [9, 28]. Some existing methods make
use of similarity relation [28], while the others make use of
co-occurrence relation [9].

The major diﬀerence between our work and these work
is that ours is based on supervised learning, while they are
based on semi-supervised learning or unsupervised learning.

408WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, ChinaThere are also methods proposed for learning to rank net-
work entities, such as papers in citation graph [1] and pages
in Web graph [32]. In the methods, only relation information
is utilized.

3. GENERAL FRAMEWORK
3.1 Motivation

There are many application problems in which one wants
to learn a model to rank objects by using both content in-
formation and relation information. Let us take web search
as example.

The central problem in web search is ranking. Given a
query, we retrieve a number of web pages which contain
the query from the index, rank the web pages based on a
number of factors such as the relevance of the pages to the
query, importance of the pages, diversities of the pages, and
then present the top ranked pages (for example, 1000) to
the users. The ranking function (model) is usually created
and tuned in advance and oﬀ-line, using certain amount of
labeled data (e.g., relevant, irrelevant).

Relevance mainly depends on the contents of the query
and the web pages. If the query matches well against the
content of a web page, for example, the query words occur
many times in the page, then the relevance of the pages
should be high. The content information can be and is
widely used in search ranking.

Sometimes relation information between the web pages is
also available, and we want to make eﬀective use of it as
well. For instance, similarities between web pages can be
calculated, and if two pages are similar with each other and
one of the pages is relevant to the query, then it is very likely
that the other page is also relevant. If for some reason the
former page is ranked in top position, while the latter is not,
then we can use the similarity information to further boost
the latter. This is close to the technique Pseudo Relevance
Feedback in IR. In this paper, for simplicity we also refer
to it as Pseudo Relevance Feedback. As another example,
if two pages form a parent-child relation at a website, even
both of them are relevant to the query (it is very likely that
such phenomenon occurs), we may only want to rank high
the parent page. The parent-child relationship between web
pages can be found from the URL hierarchy of a website [25].
This is a task referred to as Topic Distillation at TREC.

The question then becomes how to combine both the con-
tent information and relation information in learning and
ranking.
3.2 Formulation

We consider a new problem of learning to rank, referred
to as learning to rank relational objects.
In the task, we
consider the use of both contents of objects and relations
between objects.
Let X be an n × d matrix representing d dimensional fea-
ture vectors of n objects; each row corresponds to one object
and each column corresponds to one feature. Let R denote
an n × n matrix representing relationships between the n
objects; each row and each column respectively correspond
to one object. Let y be a vector representing ranking scores
of the n objects.

In learning, we are given N training samples: (X1, R1, y1),
(X2, R2, y2), . . ., (XN , RN , yN ), drawn from an unknown
joint probability distribution P (X, R, y) where X, R, and

y denote feature vectors of objects, relations between ob-
jects, and ranking scores of objects respectively. Here, each
sample contains n objects to be ordered1. Ranking only hap-
pens within a sample which consists of a ‘group of objects’.
It does not make sense to make comparison between objects
across samples.

Suppose that f is a function, such that

y = f (X, R).

The goal of learning is to select the best function (cid:98)f from a
using the learned function, i.e., yt = (cid:98)f (Xt, Rt). yt actually

In prediction, given features Xt and relations Rt for n
objects drawn from the same joint distribution, we output yt

function space F using the training data.

(1)

represents the ranking scores of the given n objects having
features Xt and relation Rt. Obviously we make use of both
feature (content) information and relation information in the
ranking function.

We deﬁne a loss function and formulate the learning prob-
lem as that of minimizing the total loss with respect to the
given training data.

(cid:98)f = arg min

f∈F

N(cid:88)

k=1

L(f (Xk, Rk), yk)

where L denotes loss function.

We refer to the above learning problem as ‘learning to

rank relational objects’.

It is easy to see that the conventional ‘learning to rank’
problem is a special case of the current problem. Speciﬁcally,
if we ignore the relations R, then we get the same function
as that in conventional learning to rank,

f (X, R) = f (X).

3.3 Application to Web Search

Many problems in web search can be formalized as learn-
ing to rank relational objects. In this paper, we only con-
sider two examples: Pseudo Relevance Feedback and Topic
Distillation.

Given a query, there are n retrieved documents. X is
a matrix representing the feature vectors derived from the
query and the documents. R is a matrix representing the
relations between the documents. y is a vector representing
the ranking scores of the documents.

In training, the labeled data about N queries is given.
Each consists of the feature vectors X, the relations R, and
the ‘true’ ranking scores y.2 We learn a ranking function f
using the training data.

In ranking, given n documents of a new query, we use the
trained ranking function to assign scores to the documents
and sort them.

In the Pseudo Relevance Feedback deﬁned in this paper, R
is simply a matrix representing the similarities between the
documents. In Topic Distillation, R is a matrix representing
the parent-child relationship between web pages in a web
site.

1For simplicity, we assume that all the samples contain the
same number of objects. It is easy to generalize to the case
in which diﬀerent samples have diﬀerent objects.
2Again, for simplicity, we assume that all the queries have
the same number of retrieved documents n.

409WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, China4. OUR METHOD

We propose a novel method for learning to rank relational

objects.
4.1 Setting

First, we specify the ranking function (1) in the following

way

y = f (h(X), R)

(2)

where X and R denote features and relations respectively, h
is a function of X. That is to say, ranking based on relations
is deﬁned in the outer function f , while ranking based on
contents is deﬁned in the inner function h.

There are three settings for learning the nested ranking

function.

Setting 1 : inner function h is predeﬁned, but outer func-

tion f is to be learned

Setting 2 : outer function f is predeﬁned, but inner func-

tion h is to be learned

Setting 3 : both inner function h and outer function f are

to be learned

In this paper, we address setting 2. We leave settings
1 and 3 to future work since they are somewhat complex.
Speciﬁcally, we deﬁne the ranking function as

y = f (h(X; ω), R).

where ω is an unknown parameter. Then, learning becomes
the following optimization problem:

N(cid:88)

k=1

min

ω

L(f (h(Xk; ω), Rk), yk)

where L denotes loss function, f (h(X; ω), R) denotes rank-
ing function, and y denotes ground truth. Again in f (h(X; ω), R),
the outer function of f is predeﬁned, but the inner function
of h with parameters ω is not. Now the key question is how
to deﬁne the function f to integrate relation information.
4.2 Ranking Function

We propose deﬁning f as a solution of minimizing the

linear combination of two objectives.

f (h(X; ω), R) = arg min

z

{l1(h(X; ω), z) + βl2(R, z)}

(3)

where z denotes any possible ranking scores, the ﬁrst ob-
jective l1(h(X; ω), z) measures the diﬀerence between h and
z, and the second objective l2(R, z) measures the inconsis-
tency between elements in z under R. Furthermore, β is a
non-negative coeﬃcient, representing the trade-oﬀ between
the two objectives.

The ﬁrst objective l1(h(X; ω), z) can simply be

l1(h(X; ω), z) = (cid:107)h(X; ω) − z(cid:107)2

(4)

where (cid:107).(cid:107) denotes L2 norm.

When β = 0 and h(X; ω) is a linear model, the ranking

model Eq.(3) degenerates to the model:

f (X, R; ω) = h(X; ω) = Xω,

(5)

and the learning problem in Eq.(3) becomes that of learning
of a linear ranking model such as linear Ranking SVM.

The second objective l2(R, z) may have diﬀerent forms,
depending on the types of the relationships between objects.
An intuitive explanation of function f in Eq.(3) is as fol-
lows. There are n objects. Each object receives a score from
the function h. The objects then propagate the scores with
each other on the basis of the relationships given in R (for
example, R can be a undirected graph). The propagation
must reach a stable state and the n objects obtain their ﬁnal
scores z. The propagation is deﬁned as minimization of a
total objective function, or an energy function. The total ob-
jective function represents a trade-oﬀ between maintaining
local consistence with the output from h and maintaining
global consistence with the restraints from R.

Similar techniques have been employed in graph based
semi-supervised learning and unsupervised learning. To the
best of our knowledge, this is the ﬁrst time, the technique
is used in a supervised learning setting. This is also the key
idea of our method for learning to rank relational objects.

In the following subsections, we give explicit forms of the
function f in diﬀerent applications in which diﬀerent rela-
tionships are deﬁned and thus diﬀerent objective functions
l2(R, z) are utilized.
4.3 Pseudo Relevance Feedback

We consider a variant of Pseudo Relevance Feedback, in
which we make use of both the relevance of documents to
the query and the similarities between documents in ranking.
We represent the similarity relationship between documents
in an undirected graph, in which the nodes represent ob-
jects, and the weights on the edges represent the similarities
between objects. Such kind of graph is widely used in clus-
tering and semi-supervised learning. It is easy to see that
we can use a matrix notation to represent the graph.

The second objective function l2(R, z) can then be deﬁned

as

l2(R, z) = 1/2

Ri,j(zi − zj)2

(6)

(cid:88)

(cid:88)

i

j

where Ri,j is the i-th row j-th column element of matrix R,
and represents the similarity between documents i and j. zi
is the i-th element of vector z. The rationale behind is that
by minimizing this objective we can guarantee that if two
documents are similar, then their ﬁnal ranking scores should
also be similar. Speciﬁcally, the larger the value of Ri,j is,
the more similar the objects i, j are, and thus the closer the
ranking scores zi and zj are.

With Eq.(4) and Eq.(6), the ranking model in Eq.(3) can

be re-written as

f (X, R; ω) = arg min

z

{(cid:107)h(X; ω)−z(cid:107)2+β/2

(cid:88)

(cid:88)

Ri,j(zi − zj)2}

i

j

(7)

Let us denote the total objective in Eq.(7) as

l(z) = (cid:107)h(X; ω) − z(cid:107)2 +

β
2

(cid:88)

(cid:88)

i

j

Ri,j(zi − zj)2

(cid:80)

Let D be a diagonal matrix with Di,i =
can write the total objective as

j Ri,j. Then we

l(z) = (cid:107)h(X; ω) − z(cid:107)2 + βzT (D − R)z.

Note that D − R is in fact the Laplacian matrix of the re-
lationship graph. Setting the derivative of l(z) with respect

410WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, Chinato z to 0, we obtain

∂l(z)

∂z

= 2(z − h(X; ω)) + 2β(D − R)z = 0.

This yields

(I + β(D − R))z = h(X; ω)

(8)
where I denotes an n × n identity matrix. Since β is non-
negative, thus matrix I + β(D − R) is diagonally dominant,
and so I + β(D − R) is invertible, according to the Levy-
Desplanques theorem.
In this way, we obtain the explicit
form of the ranking model for Pseudo Relevance Feedback
as follows:

f (X, G; ω) = (I + β(D − R))

−1h(X; ω)

(9)

For n objects, the time complexity of straightforwardly
computing the ranking model is of order O(n3) and thus is
expensive. The main cost of the computation comes from
matrix inversion.

We employ the following technique to quickly carry out
the computation. First, we note that solving the system of
linear equation (8) is enough to obtain the ranking model.
Let A = I + β(D − R). If A is a banded matrix with band-
width k (cid:191) n, then the score z in Eq.(8) can be solved with
time complexity O(n) [14]. If R is a banded matrix, then
A is also a banded matrix, and the bandwidth of A is the
same as that of R. In order to make R a banded matrix,
we should not compute the similarity between all document
pairs, and in fact this is not necessary in practice. Instead,
for each document we only consider the k nearest neighbor-
hoods of it. As a result, R becomes a sparse matrix, which
has at most k non-zero values in each row and each column.
By Gibbs-Poole-Stockmeyer algorithm [20], we can convert
a sparse matrix to a banded matrix with linear time. In this
way, the time complexity of creating a relational ranking
model becomes of linear order of n and thus is comparable
with that of the existing learning to rank methods.

Note that the ‘Pseudo Relevance Feedback (PRF)’ in this
paper slightly diﬀers from the conventional Pseudo Rele-
vance Feedback. Conventional PRF only considers the simi-
larity between the top ranked documents and the other doc-
uments in the second round ranking. By contrast, our PRF
in principle takes into consideration the similarity between
all document pairs.
4.4 Topic Distillation

We consider Topic Distillation, in which we make use of
both the relevance of web pages to the query and the parent-
child relation between the web pages in a web site. We
represent the parent-child relationship between web pages
in a matrix R,

(cid:40)

Ri,j =

1 if object i is the parent of j,
0 other.

(10)

Note that the matrix is asymmetric in the sense if i is the
parent of j then the converse is not true.

The second objective function l2(R, z) can then be deﬁned

as

l2(R, z) =

Ri,j exp(zj − zi)

(11)

(cid:88)

(cid:88)

Note that each exponential function exp(zj − zi) only con-
tributes when its corresponding Ri,j equals one, which means

i

j

i is the parent of j. In that case, if i has a larger score than
j, then the objective will be low;
in contrast, if i has a
smaller score than j, then the objective will be high. The
relationship is represented as an exponential function. This
is similar to the use of exponential objective function in su-
pervised learning such as Boosting.

With Eq.(4) and Eq.(11), the ranking model in (3) can be

written as

f (X, R; ω) = arg min

z

{(cid:107)h(X; ω)−z(cid:107)2+β

(cid:88)

(cid:88)

Ri,j exp(zj − zi)}

i

j

(12)

(cid:88)

(cid:88)

Let us denote the total objective in Eq.(12) as

l(z) = (cid:107)h(X; ω) − z(cid:107)2 + β

Ri,j exp(zj − zi)

i

j

It appears diﬃcult to ﬁnd an analytic solution of minimiza-
tion of the total objective function. Here, we choose to make
an approximation of the function.
First, we approximate exp(zj − zi) using the Taylor ex-

pansion3:

exp(zj − zi) ≈ 1 + (zj − zi) +

(zj − zi)2.

1
2

Then, we approximate l(z) as
l(z) ≈ (cid:107)h(X; ω)−z(cid:107)2+β

Ri,j

1 + (zj − zi) +

(cid:189)

(cid:88)

(cid:88)

i

j

(cid:190)

.

(zj − zi)2

1
2

We have

(cid:80)

l(z) = (cid:107)h(X; ω) − z(cid:107)2 + β(g0 + gT

(cid:80)

(cid:80)

1 z + zT (D − R)z),

i Ri,k −(cid:80)
(cid:80)

(cid:80)

j Rk,j, k =
where g0 =
1, 2, ..., n, D is a diagonal matrix with Dk,k = 1
2 (
i Ri,k +
j Rk,j), k = 1, 2, ..., n. Setting the derivative of l(z) with

j Ri,j, g1k =

i

respect to z to 0, we obtain

∂l(z)

∂z

= 2(z − h(X; ω)) + βg1 + β(2D − R − RT )z = 0.

This yields

(2I + β(2D − R − RT ))z = 2h(X; ω) − βg1.

(13)
Similarly, matrix 2I +β(2D−R−RT ) is invertible, according
to the Levy-Desplanques theorem. In this way, we obtain the
explicit form of the ranking model for Topic Distillation:
f (X, R; ω) = (2I +β(2D−R−RT ))
−1(2h(X; ω)−βg1) (14)
The time complexity of computing the ranking model is
of order O(n3) for a general matrix R. In fact, in sitemap
hierarchy, a webpage has at most one parent page, and so
matrix R has at most n non-zero elements. That is, R is
naturally very sparse. Similarly to Pseudo Relevance Feed-
back, for a sparse matrix R we can compute the ranking
model in linear time.

5. OPTIMIZATION BASED ON SVM

The learning (optimization) task in Eq.(3) is speciﬁed,
when the ranking function is deﬁned, for example, as in
Eq.(9) and Eq.(14). One can use diﬀerent techniques to
implement the optimization problem, such as SVM, Boost-
ing and Neural Network. In this section we consider using
3In our experiments, we found that |zj − zi| is very small,
and so this approximation is reasonable.

411WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, Chinathe SVM technique. We refer to the method as ‘Relational
Ranking SVM’. For simplicity, we consider the linear func-
tion h(X; ω) = Xω.
5.1 Ranking SVM

We ﬁrst make a review of Ranking SVM. Ranking SVM is
a state of the art method for learning to rank, and its learn-
ing task is deﬁned as the following quadratic programming
problem:

1

2(cid:107)ω(cid:107)2 + c

minω,ξq,i,j
q,i,j ξq,i,j
s.t. ωT xq,i ≥ ωT xq,j + 1 − ξq,i,j,

∀xq,i (cid:194) xq,j, ξq,i,j ≥ 0

where xq,i (cid:194) xq,j implies that object i is ranked ahead of
object j for query q in the training data, ξq,i,j denotes slack
variable, and (cid:107)ω(cid:107)2 denotes structural loss. For ease of ex-
planation, we re-write the above optimization in a matrix
form:

(cid:80)

(cid:80)

(15)

(16)

minω,ξq

1

2 ωT ω + c

q 1T

q ξq

s.t. ∀q ∈ Q, Cqf (Xq; ω) ≥ 1q − ξq,

f (Xq; ω) = Xqω, ξq ≥ 0

where Q is the set of training queries, Cq denotes a con-
straint matrix for query q, 1q denotes a vector with all the
elements being 1, and its dimension is the same as that of
ξq. Each row of Cq represents a pairwise constraint: one el-
ement is 1, one element is −1, and the other elements are all
0. For example, for query q, if document 1 is ranked ahead
of document 3, and document 2 ahead of document 4, then
we have

(cid:181)

(cid:182)

Cq =

0 −1
1

0
0 −1

Note that Eq.(16) can be written in a similar form as Eq.(3):

1

q [1q − Cqf (Xq; ω)]+
minω,ξq
s.t. ∀q ∈ Q, f (Xq; ω) = arg minz (cid:107)Xqω − z(cid:107)2

2 ωT ω + c

q 1T

(17)

1
0

(cid:80)

where [x]+ indicates the positive part of x. This implies
that our formulation of the learning problem in Eq.(3) is
quite general.
5.2 Relational Ranking SVM

We next describe Relational Ranking SVM. Combining
Eq.(9) with Eq.(16), we can get the optimization problem
of Relational Ranking SVM for Pseudo Relevance Feedback,

minω,ξq

1

2 ωT ω + c

q 1T

q ξq

s.t. ∀q ∈ Q, Cqf (Xq, Rq; ω) ≥ 1q − ξq, ξq ≥ 0

f (Xq, Rq; ω) = (I + β(Dq − Rq))−1Xqω

(18)

This is a Linear Constrained Quadratic Programming prob-
lem, and can be solved by employing existing optimization
techniques.

Similarly, for Relational Ranking SVM in Topic Distilla-

tion, we have an optimization problem as follows:

minω,ξq

1

2 ωT ω + c

q 1T

q ξq

s.t. ∀q ∈ Q, Cqf (Xq, Rq; ω) ≥ 1q − ξq, ξq ≥ 0

f (Xq, Rq; ω) = (2I + β(2Dq − Rq − RT

q ))−1(2Xqω − βgq,1)
where gq,1 is the vector g1 in Eq.(13) for query q. This prob-
lem can also be solved by employing existing optimization
techniques.

(19)

(cid:80)

(cid:80)

6. EXPERIMENTS

We applied Relational Ranking SVM to the tasks of Pseudo
Relevance Feedback and Topic Distillation. We used LETOR
[21] in our experiments, which is a dataset created for learn-
ing to rank research4. We used OHSUMED in LETOR for
Pseudo Relevance Feedback and TREC in LETOR for Topic
Distillation. As evaluation measure, we utilized NDCG@n
(Normalized Discounted Cumulative Gain) [17].
6.1 OHSUMED: Pseudo Relevance Feedback
We compared the performances of Relational Ranking SVM
and several baseline methods in Pseudo Relevance Feedback
using the OHSUMED data set in LETOR.
6.1.1 Data Set
The OHSUMED data set in LETOR has been derived
from the OHSUMED benchmark data [16] for information
retrieval research. The document collection is a subset of
MEDLINE, a database on medical publications. The col-
lection consists of 348,566 records (out of over 7 million)
from 270 medical journals during the period of 1987-1991.
The ﬁelds of a record include title, abstract, MeSH indexing
terms, author, source, and publication type.

There are 106 queries in OHSUMED data set, each with
a number of associated documents. The relevance degrees
of documents with respect to the queries are judged by hu-
mans, on three levels: deﬁnitely relevant, partially relevant,
or not relevant. There are in total 16,140 query-document
pairs with relevance judgments. Each query-document pair
is represented by a 25 dimension feature vector. For the
details of the features, please refer to [21].

Similarity between documents is provided as relation in-
formation. The similarity between two documents is calcu-
lated in the following way. First stop words are removed
from the documents. Each document is represented by a
term vector in the vector space model [2]. The similarity
Ri,j between two documents i and j is deﬁned as cosine be-
tween the term vectors of the two documents. Note that
a term vector diﬀers from a feature vector in learning; the
former is a function of document, while the latter a function
of query document pair.
6.1.2 Experiment Procedure
As baseline, we adopted Ranking SVM and Ranking SVM
plus relation [10]. For reference purposes, we also tested
BM25 and Pseudo Relevance Feedback based on BM25. For
BM25 and Pseudo Relevance Feedback, we used the tools
provided in Lemur toolkit5.

In Ranking SVM, we only use content information.

In
comparison with this baseline, we can see whether Relational
Ranking SVM can eﬀectively leverage relation information
to perform better ranking. Actually, the results of Ranking
SVM are already provided in LETOR.

In Ranking SVM plus relation, we make use of both con-
tent information and relation information. Following the
proposal in [10], we conduct regularization on the scores out-
put by Ranking SVM, using similarities between documents
. In comparison with this baseline, we can verify whether
it is better to integrate relation information into learning
process, as in Relational Ranking SVM.
4The
http://research.microsoft.com/users/LETOR/.
5http://www.lemurproject.org/

downloaded

from

data

can

set

be

412WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, ChinaFigure 1: Comparison with Learning Methods

Figure 2: Comparison with Non-Learning Methods

We conducted 5 fold cross validation experiments, using

the partitions provided in LETOR.

For all the SVM models in the experiments, we employed
Linear SVM, because the result of Ranking SVM in the
LETOR data set is based on Linear Ranking SVM.

There is a parameter β in the ranking model Eq.(3). In
the experiments, we heuristically set β as 0.1, 0.2, 0.3, and
conducted experiments with the values for Relational Rank-
ing SVM and Ranking SVM plus relation.

6.1.3 Experimental Results
Figure 1 show the average performances of Ranking SVM,
Ranking SVM plus relation, and Relational Ranking SVM
over 5 folds. Here ‘RSVM’ stands for Ranking SVM, ‘RSVM+R’
stands for Ranking SVM plus relation and ‘RRSVM’ stands
for Relational Ranking SVM.

For all the β values, RRSVM performs much better than
RSVM and RSVM+R in terms of NDCG at all positions.
Particularly for NDCG@1, RRSVM works signiﬁcantly bet-
ter than RSVM, with more than 10% relative improvement.
Furthermore, RRSVM also works better than RSVM+R.

Figure 2 show the results of BM25 and Pseudo Relevance
Feedback (PRF) based on BM25. We can see that PRF
is better than BM25. RRSVM signiﬁcantly outperforms
BM25 and PRF, which veriﬁes the correctness of the claim
that learning methods using relation works better than non-
learning methods using relation.

In summary, RRSVM can really outperform the baseline

methods.

6.1.4 Discussion
Table 1 and 2 show the top 10 results of RSVM and
RRSVM for query “FIBROMYALGIA/FIBROSITIS, DIAG-
NOSIS AND TREATMENT” separately. The documents in
red are ‘deﬁnitely relevant’, documents in blue are ‘partially
relevant’, and documents in black are ‘not relevant’.

It is easy to ﬁnd that RRSVM is better than RSVM for
this query. Document 114913 is a ‘deﬁnitely relevant’ doc-
ument. RSVM is only able to rank it to position 5. This
document is in fact very similar to document 142171 which
is ranked at position 1. Using the similarity information
between them, RRSVM can eﬀectively boost it to top 3.
This example shows why we can improve the performance
of relevance by using similarity information.

Figure 3: RRSVM with Diﬀerent β Values

The coeﬃcient β represents a trade-oﬀ between the uses
of content information and relation information. Figure 3
shows the performance curve of RRSVM with diﬀerent β val-
ues. Note that when β = 0 RRSVM degenerates to RSVM.
RRSVM achieves the highest NDCG@1 value when β = 0.1.
When β gets larger, RRSVM’s performance begins to dete-
riorate. That is, we need to select relatively small β for this
task.
6.2 TREC: Topic Distillation

We compared the performances of Relational Ranking SVM

and several baseline methods in Topic Distillation using the
TREC2004 data set in LETOR.

6.2.1 Data Set
In TREC 2004, there was a special track for web search.
The goal of this track was to investigate the behaviors of
search methods when the document collection is from the
web. The track used the .gov data as document collec-
tion, which is from a crawl of the .gov domain on January,
2002. There are in total 1,053,110 HTML documents, and
11,164,829 hyperlinks. The track also provided queries and
relevance judgments on documents.

The TREC dataset in LETOR has been derived from the
.gov collection. There are 75 queries, each associated with
about 1,000 documents. The relevance degrees of documents
with respect to the queries are oﬀered by TREC, on two
levels: relevant or not relevant. There are 44 features deﬁned
as functions over a query-document pair [21].

0.50.520.540.56RSVMRRSVM(β=0.1)RRSVM(β=0.2)RRSVM(β=0.3)RSVM+R0.420.440.460.48NDCG@1NDCG@3NDCG@100.30.350.40.450.50.55NDCG@1NDCG@3NDCG@10RRSVM(β=0.1)RRSVM(β=0.2)RRSVM(β=0.3)BM25PRF0.430.450.470.490.510.530.550.5700.20.40.60.81βvalueNDCG@1413WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, ChinaTable 1: Top 10 Results of RSVM

Table 2: Top 10 Results of RRSVM

Doc ID Title
142171
264930

Current pharmacologic therapy of arthritis.
Incidence of transient nephrotic syndrome
during pregnancy in diabetic women with and
without pre-existing microalbuminuria
Molecular relationships between the class II
HLA antigens and susceptibility to rheuma-
toid arthritis
Impaired carbohydrate metabolism of poly-
morphonuclear leukocytes in glycogen stor-
age disease Ib.
Current pharmacologic management of nar-
colepsy.
Reiter’s syndrome precipitated by a typhoid
vaccination
Neuropeptides in synovium of patients with
rheumatoid arthritis and osteoarthritis.
Electromyographic abnormalities in neuro-
logic injury associated with pelvic fracture:
case reports and literature review.
Synthesis and release of phospholipase A2 by
unstimulated human articular chondrocytes.
Role of the general practitioner in managing
patients with myocardial infarction

180409

103801

114913

188977

197502

114422

288849

266203

Doc ID Title
142171
264930

Current pharmacologic therapy of arthritis.
Incidence of transient nephrotic syndrome
during pregnancy in diabetic women with and
without pre-existing microalbuminuria
Current pharmacologic management of nar-
colepsy.
Electromyographic abnormalities in neuro-
logic injury associated with pelvic fracture:
case reports and literature review.
Impaired carbohydrate metabolism of poly-
morphonuclear leukocytes in glycogen stor-
age disease Ib.
Synthesis and release of phospholipase A2 by
unstimulated human articular chondrocytes.
Molecular relationships between the class II
HLA antigens and susceptibility to rheuma-
toid arthritis
Cardiopulmonary consequences of obstruc-
tive sleep apnea.
Neuropeptides in synovium of patients with
rheumatoid arthritis and osteoarthritis.
Defective CD2 pathway T cell activation in
systemic lupus erythematosus

114913

114422

103801

288849

180409

264301

197502

315397

Relation between web pages in a web site is given as a
matrix R. The element Ri,j equals 1 if page i is parent of
page j, and equals 0 for other cases.
6.2.2 Experiment Procedure
As baseline methods, we used Ranking SVM (RSVM).
We also tested existing non-learning method of sitemap
based relevance propagation [24]. The basic idea of sitemap
based relevance propagation is to use the relevance of a
child page to enhance the relevance of its parent page. This
method makes use of the parent-child relationship. There
are two variants of the method: sitemap based term propa-
gation (’ST’ for short) and sitemap based score propagation
(’SS’ for short).

Considering the fact that Ranking SVM does not use rela-
tion information, we tested another method, Ranking SVM
plus relation (RSVM+R). In this method, we use the rank-
ing score of a child page output by RSVM to enhance the
ranking score of its parent also output by RSVM. The idea is
similar to that of sitemap based relevance propagation [24].
We conduced 5-fold cross validation experiments, using
the partitions in LETOR. For Ranking SVM, we can make
use of the results of it provided in LETOR. For all the SVM
models in the experiment, we employed Linear SVM. This is
because the LETOR data set oﬀers results of Linear Ranking
SVM.

In the experiments, we heuristically set β as 0.1, 0.2, 0.3,

and applied them to Relational Ranking SVM.
6.2.3 Experimental Results
Figure 4 show the average performances of RRSVM, RSVM,

and RSVM+R in 5-fold cross validation.

RRSVM outperforms RSVM and RSVM+R, in all set-
tings of β, especially when β = 0.1. Although RSVM+R
boosts NDCG@1 score higher than RSVM, its NDCG@3

and NDCG@10 scores are not as good as those of RSVM.
The results indicate that learning relation information can
indeed boost the performance of Topic Distillation.

Moveover, Figure 5 show the average performances of RRSVM,

ST and SS in 5-fold cross validation.

We can see that RRSVM work much better than ST and
SS in terms of NDCG. For example, The NDCG values of
RRSVM are 10 points higher than the relevance propagation
methods, which represents 30% relative improvements. The
results show that the learning based method can achieve
better accuracy than non-learning methods.

Figure 4: Comparison with Learning Methods

6.2.4 Discussions
We investigated the reason that RRSVM can achieve bet-
ter results than RSVM and concluded that it is because
RRSVM can successfully leverage the relation information.

0.430.450.470.49RSVMRRSVM(β=0.1)0.350.370.390.410.43NDCG@1NDCG@3NDCG@10RRSVM(β=0.1)RRSVM(β=0.2)RRSVM(β=0.3)RSVM+R414WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, ChinaTable 4: Top 10 Results of RRSVM

Doc ID URL
4074
880
20325
22352
409215
183570
2443
899308
375621
692871

http://www.nasa.gov/
http://liftoﬀ.msfc.nasa.gov/
http://www.hq.nasa.gov/osf/
http://www.hq.nasa.gov/osf/heds/
http://spacelink.nasa.gov/nasa.../.index.html
http://www.lanl.gov/csse/
http://sse.jpl.nasa.gov/
http://technologyplan.nasa.gov/default.cfm?id=8.0
http://www.pnl.gov/microcats/apps/space/
http://www.jpl.nasa.gov/forum/

Figure 5: Comparison with Non-Learning Methods

Table 3: Top 10 Results of RSVM

Doc ID URL
4074
880
22352
20325
409215
53139
89693
2443
183570
375621

http://www.nasa.gov/
http://liftoﬀ.msfc.nasa.gov/
http://www.hq.nasa.gov/osf/heds/
http://www.hq.nasa.gov/osf/
http://spacelink.nasa.gov/nasa.../.index.html
http://core.nasa.gov/cu.html
http://www.hq.nasa.gov/osf/heds/hedsplan.html
http://sse.jpl.nasa.gov/
http://www.lanl.gov/csse/
http://www.pnl.gov/microcats/apps/space/

Table 3 and 4 show the case of query “space exploration”.

There are ten results returned by each of the methods RRSVM
and RSVM. The answer pages for this query are red colored.
In Table 3, the answer page (id 20325) is ranked below its
child page (id 22352) by RSVM, because its content feature
is not so strong as that of its child page. In Table 4, the an-
swer page (id 20325) is ranked higher than its child page (id
22352), because RRSVM can eﬀectively use the parent-child
relation information to boost the position of it.

The coeﬃcient β represents a trade-oﬀ between the uses
of content information and relation information. Figure
6 shows the performance curve of RRSVM with diﬀerent
β values. Note that with β = 0 RRSVM degenerates to
RSVM. Again, RRSVM achieves the highest NDCG@1 score
at β = 0.1. When β gets larger, RRSVM’ performance be-
gins to deteriorate. That is, we need to select relatively
small β for this task.

7. CONCLUSIONS

In this paper, we have proposed a new and general prob-
lem referred to as learning to rank relational objects, in
which the ranking model is deﬁned as a function of both con-
tent information and relation information of objects. Learn-
ing to rank relational objects can be applied to a large va-
riety of problems in web search, such as Pseudo Relevance
Feedback and Topic Distillation. We have focused on one
setting of the learning task and proposed a new learning
method for it on the basis of optimization. We have applied
the method to the above two web search tasks by deﬁning

Figure 6: RRSVM with Diﬀerent β Values

suitable ranking models. Furthermore, we have developed
SVM techniques for solving the optimization problem. Ex-
perimental results on two public data sets show that the pro-
posed method performs signiﬁcantly better than the baseline
methods.

There are still many issues which need further investiga-
tions. (1) We have assumed that all the training queries and
documents are labeled. It is interesting to study how to per-
form learning to rank relational objects when some of the
queries and documents are unlabeled. (2) We have looked
at one setting of the problem (setting 2 in Section 4.1), it
is interesting to know how to address the learning problems
in the other settings (setting 1 and 3). (3) We have formal-
ized the learning task as an optimization problem with a
nested ranking function. It is worth to see whether there are
any other approaches. (4) We have proposed one learning
method to solve the optimization issue. The generalization
ability of the method is not known. (5) We have applied
the SVM techniques to the problem. It is also interesting
to see how to apply other techniques such as Boosting and
Neural Network here. (6) We have studied two applications:
Pseudo Relevance Feedback and Topic Distillation. We also
need to look at other web search tasks.

8. ACKNOWLEDGMENTS

We would like to thank Eric P. Xing and John D. Laﬀerty
for their valuable comments and suggestions on the work.
We would also like to thank Xiu-Bo Geng, Yu-Ting Liu,
Cong-Kai Sun, Fen Xia, Zhen Liao, and Yin He for their
proof-reading of the paper.

0.40.450.5STSS0.20.250.30.35NDCG@1NDCG@3NDCG@10SSRRSVM(β=0.1)RRSVM(β=0.2)RRSVM(β=0.3)0.390.40.410.420.430.440.450.460.470.480.4900.10.20.30.40.5βvalueNDCG@1415WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, China9. REFERENCES
[1] A. Agarwal, S. Chakrabarti, and S. Aggarwal. Learning to

rank networked entities. In KDD ’06, pages 14–23, New
York, NY, USA, 2006. ACM Press.

[2] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information

Retrieval. Addison Wesley, May 1999.

[3] M. Belkin, P. Niyogi, and V. Sindhwani. Manifold

regularization: A geometric framework for learning from
labeled and unlabeled examples. J. Mach. Learn. Res.,
7:2399–2434, 2006.

[4] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds,

N. Hamilton, and G. Hullender. Learning to rank using
gradient descent. In ICML ’05: Proceedings of the 22nd
international conference on Machine learning, pages 89–96,
New York, NY, USA, 2005. ACM Press.

[5] Y. Cao, J. Xu, T.-Y. Liu, H. Li, Y. Huang, and H.-W. Hon.
Adapting ranking svm to document retrieval. In SIGIR ’06:
Proceedings of the 29th annual international ACM SIGIR
conference on Research and development in information
retrieval, pages 186–193, New York, NY, USA, 2006. ACM
Press.

[6] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning

to rank: from pairwise approach to listwise approach. In
ICML ’07: Proceedings of the 24th international conference
on Machine learning, pages 129–136, New York, NY, USA,
2007. ACM Press.

[7] W. Dai and R. Srihari. Minimal document set retrieval. In

CIKM ’05: Proceedings of the 14th ACM international
conference on Information and knowledge management,
pages 752–759, New York, NY, USA, 2005. ACM Press.

[8] H. M. de Almeida, M. A. Gon¸calves, M. Cristo, and

P. Calado. A combined component approach for ﬁnding
collection-adapted ranking functions based on genetic
programming. In SIGIR ’07: Proceedings of the 30th
annual international ACM SIGIR conference on Research
and development in information retrieval, pages 399–406,
New York, NY, USA, 2007. ACM.

[9] I. S. Dhillon. Co-clustering documents and words using

bipartite spectral graph partitioning. In KDD ’01, pages
269–274, New York, NY, USA, 2001. ACM Press.
[10] F. Diaz. Regularizing query-based retrieval scores.

Information Retrieval, 2007.

[11] W. Fan, M. D. Gordon, and P. Pathak. A generic ranking
function discovery framework by genetic programming for
information retrieval. Inf. Process. Manage., 40(4):587–602,
2004.

[12] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An

eﬃcient boosting algorithm for combining preferences. J.
Mach. Learn. Res., 4:933–969, 2003.

[13] X. Geng, T.-Y. Liu, T. Qin, and H. Li. Feature selection for

ranking. In SIGIR ’07: Proceedings of the 30th annual
international ACM SIGIR conference on Research and
development in information retrieval, pages 407–414, New
York, NY, USA, 2007. ACM.

[14] G. H. Golub and C. F. V. Loan. Matrix computations (3rd
ed.). Johns Hopkins University Press, Baltimore, MD, USA,
1996.

[15] R. Herbrich, T. Graepel, and K. Obermayer. Support
vector learning for ordinal regression. In ICANN1999,
pages 97–102, 1999.

[16] W. Hersh, C. Buckley, T. J. Leone, and D. Hickam.

Ohsumed: an interactive retrieval evaluation and new large
test collection for research. In SIGIR ’94, pages 192–201,
New York, NY, USA, 1994. Springer-Verlag New York, Inc.

[17] K. Jarvelin and J. Kekanainen. IR evaluation methods for
retrieving highly relevant documents. In SIGIR2000, pages
41–48, 2000.

[18] T. Joachims. Optimizing search engines using clickthrough

data. In KDD ’02: Proceedings of the eighth ACM
SIGKDD international conference on Knowledge discovery
and data mining, pages 133–142, New York, NY, USA,
2002. ACM Press.

[19] J. M. Kleinberg. Authoritative sources in a hyperlinked

environment. J. ACM, 46(5):604–632, 1999.

[20] J. G. Lewis. Algorithm 582: The gibbs-poole-stockmeyer
and gibbs-king algorithms for reordering sparse matrices.
ACM Trans. Math. Softw., 8(2):190–194, 1982.

[21] T.-Y. Liu, J. Xu, T. Qin, W.-Y. Xiong, and H. Li. Letor:

Benchmark dataset for research on learning to rank for
information retrieval. In Proceedings of SIGIR 2007
Workshop on Learning to Rank for Information Retrieval,
2007.

[22] L. Page, S. Brin, R. Motwani, and T. Winograd. The
pagerank citation ranking: Bringing order to the web.
Technical report, Stanford Digital Library Technologies
Project, 1998.

[23] T. Qin, T.-Y. Liu, W. Lai, X.-D. Zhang, D.-S. Wang, and
H. Li. Ranking with multiple hyperplanes. In SIGIR ’07,
pages 279–286, New York, NY, USA, 2007. ACM Press.

[24] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen, and W.-Y. Ma. A

study of relevance propagation for web search. In SIGIR
’05, pages 408–415, New York, NY, USA, 2005. ACM Press.
[25] T. Qin, T.-Y. Liu, X.-D. Zhang, G. Feng, D.-S. Wang, and

W.-Y. Ma. Topic distillation via sub-site retrieval.
Information Processing & Management, 43(2):445–460,
2007.

[26] T. Qin, X.-D. Zhang, M.-F. Tsai, D.-S. Wang, T.-Y. Liu,

and H. Li. Query-level loss functions for information
retrieval. Information Processing & Management, 2007.

[27] A. Shakery and C. Zhai. A probabilistic relevance

propagation model for hypertext retrieval. In CIKM2006,
pages 550–558, New York, NY, USA, 2006. ACM Press.

[28] J. Shi and J. Malik. Normalized cuts and image

segmentation. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 22(8):888–905, 2000.

[29] T. Tao and C. Zhai. Regularized estimation of mixture

models for robust pseudo-relevance feedback. In SIGIR ’06,
pages 162–169, New York, NY, USA, 2006. ACM.

[30] A. Trotman. Learning to rank. Inf. Retr., 8(3):359–381,

2005.

[31] M.-F. Tsai, T.-Y. Liu, T. Qin, H.-H. Chen, and W.-Y. Ma.

Frank: a ranking method with ﬁdelity loss. In SIGIR ’07,
pages 383–390, New York, NY, USA, 2007. ACM Press.

[32] A. C. Tsoi, G. Morini, F. Scarselli, M. Hagenbuchner, and

M. Maggini. Adaptive ranking of web pages. In WWW ’03:
Proceedings of the 12th international conference on World
Wide Web, pages 356–365, New York, NY, USA, 2003.
ACM.

[33] E. Voorhees and D. Harman. TREC: Experiment and

Evaluation in Information Retrieval. MIT Press, 2005.

[34] J. Xu and H. Li. Adarank: a boosting algorithm for

information retrieval. In SIGIR ’07, pages 391–398, New
York, NY, USA, 2007. ACM Press.

[35] Y. Yue, T. Finley, F. Radlinski, and T. Joachims. A

support vector method for optimizing average precision. In
SIGIR ’07, pages 271–278, New York, NY, USA, 2007.
ACM Press.

[36] C. X. Zhai, W. W. Cohen, and J. Laﬀerty. Beyond

independent relevance: methods and evaluation metrics for
subtopic retrieval. In SIGIR ’03: Proceedings of the 26th
annual international ACM SIGIR conference on Research
and development in informaion retrieval, pages 10–17, New
York, NY, USA, 2003. ACM Press.

[37] D. Zhou, O. Bousquet, T. Lal, J. Weston, and B. Sch¨olkopf.

Learning with local and global consistency, 2003. In 18th
Annual Conf. on Neural Information Processing Systems.

[38] D. Zhou, J. Huang, and B. Sch¨olkopf. Learning from

labeled and unlabeled data on a directed graph. In ICML
’05: Proceedings of the 22nd international conference on
Machine learning, pages 1036–1043, New York, NY, USA,
2005. ACM.

416WWW 2008 / Refereed Track: Search - Ranking & Retrieval EnhancementApril 21-25, 2008 · Beijing, China