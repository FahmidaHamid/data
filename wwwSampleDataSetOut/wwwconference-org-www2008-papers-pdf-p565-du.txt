Computing Minimum Cost Diagnoses to Repair Populated

DL-based Ontologies

State Key Laboratory of Computer Science,

Institute of Software, Chinese Academy of Sciences

State Key Laboratory of Computer Science,

Institute of Software, Chinese Academy of Sciences

Yi-Dong Shen

Beijing 100080, China
ydshen@ios.ac.cn

Jianfeng Du

Graduate University of the

Chinese Academy of Sciences

Beijing 100080, China

jfdu@ios.ac.cn

ABSTRACT
Ontology population is prone to cause inconsistency because
the populating process is imprecise or the populated data
may conﬂict with the original data. By assuming that the
intensional part of the populated DL-based ontology is ﬁxed
and each removable ABox assertion is given a removal cost,
we repair the ontology by deleting a subset of removable
ABox assertions in which the sum of removal costs is min-
imum. We call such subset a minimum cost diagnosis. We
show that, unless P=NP, the problem of ﬁnding a minimum
cost diagnosis for a DL-Lite ontology is insolvable in PTIME
w.r.t. data complexity. In spite of that, we present a feasi-
ble computational method for more general (i.e. SHIQ) on-
tologies. It transforms a SHIQ ontology to a set of disjoint
propositional programs, thus reducing the original problem
into a set of independent subproblems. Each such subprob-
lem computes an optimal model and is solvable in logarith-
mic calls to a SAT solver. Experimental results show that
the method can handle moderately complex ontologies with
over thousands of ABox assertions, where all ABox asser-
tions can be assumed removable.

Categories and Subject Descriptors
I.2.3 [Artiﬁcial Intelligence]: Deduction and Theorem
Proving; I.2.4 [Artiﬁcial Intelligence]: Knowledge Rep-
resentation Formalisms and Methods

General Terms
Algorithms

Keywords
Ontologies, Description Logics, Disjunctive Datalog, Diag-
nosis

1.

INTRODUCTION

Nowadays OWL [22] has been established as a core stan-
dard in the Semantic Web. It comes in three layers in as-
cending expressivity, i.e., OWL Lite, OWL DL and OWL

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

Full, where the former two coincide semantically with cer-
tain description logics (DLs) [1]. A DL-based ontology con-
sists of an intensional part and an extensional part. The
intensional part consists of a TBox and an RBox, and con-
tains knowledge about concepts and relations (called roles)
between the elements of the domain. The extensional part
consists of an ABox, and contains knowledge about individ-
uals and how they relate to the concepts and roles from the
intensional part. In this paper, the knowledge in intensional
parts is called axioms, whilst the knowledge in extensional
parts is called ABox assertions or simply assertions.

A crucial question in the vision of Semantic Web is how
to support and ease the process of creating and maintaining
DL-based ontologies. An important task within this process
is ontology population, which adds instances of concepts and
relations to the ontology.
In recent years, there has been
a great surge of interest in methods for populating ontolo-
gies from textual resources. To name a few, Text2Onto [3]
and KITE [30] are frameworks that integrate algorithms for
populating ontologies from textual data. The algorithms
include information extraction algorithms that assign anno-
tations carrying some semantics to regions of the data, and
co-reference algorithms that identify annotated individuals
in multiple places. As for populating DL-based ontologies,
the information extraction process behaves as adding con-
cept/role assertions, whilst the co-reference process behaves
as adding equality/inequality assertions. The populated on-
tology, however, may become inconsistent because the infor-
mation extraction/co-reference process is imprecise or the
populated data possibly conﬂict with the original data. In
order to repair the populated ontology, we propose to delete
a subset of assertions in which the sum of removal costs is
minimum, based on the following considerations. First, the
intensional part should not be changed, because in general
it is well prepared and coherent (i.e., having no unsatisﬁable
concepts) before the population. Second, for changing the
extensional part, only the deletion of assertions is consid-
ered because there is generally no criteria for revising asser-
tions. Third, for deleting assertions, some minimal criteria
on removable assertions (e.g., the cost of losing informa-
tion) should be considered. Fourth, the certainty informa-
tion on an assertion, given by the information extraction/co-
reference process, can be used as the cost of losing informa-
tion (called the removal cost), because deleting a more cer-
tain assertion generally loses more information. Fifth, the

565WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, Chinacollective removal cost of a set of assertions can be approx-
imated by the sum of removal costs in the set.

Therefore, we in this paper address computing a minimum
cost diagnosis for an inconsistent ontology KB, i.e. a subset
of removable assertions whose removal turns KB consistent
and in which the sum of removal costs is minimum. We show
that, unless P=NP, the problem of ﬁnding a minimum cost
diagnosis for a DL-Lite ontology is insolvable in polynomial
time (PTIME) w.r.t. data complexity, i.e. the complexity
measured in the size of the ABox only. Note that DL-Lite
is a fairly inexpressive DL language such that the consis-
tency checking problem for DL-Lite ontologies is in PTIME
in the size of the ontology [2]. This complexity result im-
plies that the problem of ﬁnding minimum cost diagnoses
is in general intractable. In spite of that, we develop a fea-
sible computational method for more general (i.e. SHIQ)
ontologies. It transforms a SHIQ ontology to a set of dis-
joint propositional programs by applying an existing trans-
formation method (from SHIQ to disjunctive datalog) [12,
21] and new grounding and partitioning techniques. Thus
our method reduces the problem of ﬁnding a minimum cost
diagnosis into a set of independent subproblems. Each such
subproblem computes an optimal model and is solvable in
O(log2 n) calls to a satisﬁability (SAT) solver, by assum-
ing that removal costs have been scaled to positive integers
polynomial in n the number of removable assertions.

We implement our method and experiment on several orig-
inally consistent, real/benchmark ontologies. Each test on-
tology has over thousands of assertions. We implement a
tool to inject conﬂicts into a consistent ontology, where a
conﬂict, caused by several inserted assertions, violates a
functional restriction or a disjointness constraint. Exper-
imental results show that, even when all assertions are as-
sumed removable, our method can handle all the test ontolo-
gies with injected conﬂicts. Especially, our method scales
well on the extended benchmark ontologies with increasing
number (from 1000) of conﬂicts.

2. RELATED WORK

There are some works that address repairing DL-based
ontologies. Kalyanpur et al. [13] extended Reiter’s Hitting
Set Tree (HST) algorithm [24] to compute a minimum-rank
hitting set, which is a subset of axioms that need to be re-
moved/ﬁxed to correct an unsatisﬁable concept, such that
the sum of axiom ranks in the subset is minimum. The no-
tion of minimum-rank hitting set is similar to that of min-
imum cost diagnosis, except that the former is on axioms
while the latter is on assertions. Schlobach [26] applied Re-
iter’s HST algorithm to compute a minimal subset of axioms
that need to be removed/ﬁxed to correct an unsatisﬁable
concept or an incoherent TBox. The above methods require
all minimal conﬂict sets be computed beforehand, where a
minimal conﬂict set is a minimal subset of axioms responsi-
ble for the unwanted consequence. Though the above meth-
ods can work with ABoxes as well (by viewing assertions
as axioms), it is impractical to adapt them to computing
minimum cost diagnoses. First, the problem of ﬁnding a
minimum hitting set from minimal conﬂict sets is intrinsi-
cally intractable [15]. Second, though there exist eﬃcient
methods for computing a minimal conﬂict set (e.g., [27, 14,
20]), computing all minimal conﬂict sets is still hard because
the number of minimal conﬂict sets can be exponential in
the number of assertions, as shown in the following example.

Example 1. Let the intensional part consist of two axioms
A (cid:2) ∀P.¬A(cid:4)∀Q.¬A and ¬A (cid:2) ∀P.A(cid:4)∀Q.A, and the ABox
be {A(a1), P (an, a1), Q(an, a1)} ∪ {P (ai, ai+1), Q(ai, ai+1) |
1 ≤ i ≤ n − 1}, where n is an odd number. Then the
ontology is inconsistent, because ¬A(a1) is one of its con-
sequences but conﬂicts with A(a1). The minimal conﬂict
sets over the ABox are of the form {A(a1), U1(a1, a2), . . . ,
Un−1(an−1, an), Un(an, a1)}, where Ui is either P or Q. So
the number of minimal conﬂict sets is 2n.

Hence, a method that computes minimum cost diagnoses
from minimal conﬂict sets may work in exponential time
and exponential space w.r.t. data complexity (e.g., when it
handles an ontology that is the union of the ontology in
the above example and the ontology given in the proof of
Theorem 2). In contrast, our method works in exponential
time (more precisely, in logarithmic calls to an NP oracle)
and polynomial space w.r.t. data complexity.

There exist some heuristics-based methods for repairing
DL-based ontologies. Schlobach [25] proposed an approxi-
mate approach to computing a subset of axioms whose re-
moval corrects an unsatisﬁable concept or an incoherent
TBox. Dolby et al. [4] exploited summarization and reﬁne-
ment techniques to compute a subset of assertions whose
removal turns an inconsistent ontology consistent. Their
proposed methods, however, cannot guarantee minimality
for the set of removed axioms/assertions.

There also exist some methods for revising problematic
axioms (e.g., [19, 13, 16, 23]). But they cannot be adapted
to revising assertions, because assertions are assumed atomic
in our work. We only consider the deletion of assertions.

As for dealing with inconsistency in DL-based ontologies,
there is another approach that simply avoids/tolerates the
inconsistency and applies a non-standard reasoning method
to obtain meaningful answers (e.g., [11, 17]). We can also
adapt our method to this approach, by deﬁning a consistent
consequence of an inconsistent ontology as a consequence
invariant under all minimum cost diagnoses. This is out of
the scope of this paper and is not discussed here.

3. PRELIMINARIES

3.1 SHIQ and DL-Lite

−

The SHIQ description logic [10] is a syntactic variant of
OWL DL [22] without nominals and concrete domain spec-
iﬁcations, but allowing qualiﬁed number restrictions.
A SHIQ RBox KBR is a ﬁnite set of transitivity axioms
T rans(R) and role inclusion axioms R (cid:2) S, where R and S
be the reﬂexive transitive closure of {R (cid:2)
are roles. Let (cid:2)∗
S, Inv(R) (cid:2) Inv(S) | R (cid:2) S ∈ KBR}, where Inv(R) = R
−
and Inv(R
) = R for a role R. A role S is simple if there is
S and either T rans(R) ∈ KBR or
no role R such that R (cid:2)∗
T rans(Inv(R)) ∈ KBR. The set of SHIQ concepts is the
smallest set containing (cid:8), ⊥, A, ¬C, C (cid:4) D, C (cid:10) D, ∃R.C,
∀R.C, ≤n S.C and ≥n S.C, where A is a concept name (i.e.
an atomic concept), C and D SHIQ concepts, R a role, S a
simple role, and n a positive integer. A SHIQ TBox KBT
is a ﬁnite set of concept inclusion axioms C (cid:2) D, where C
and D are SHIQ concepts. A SHIQ ABox KBA is a set
of concept assertions C(a), role assertions R(a, b), equality
assertions a ≈ b and inequality assertions a (cid:14)≈ b, where C
is a SHIQ concept, R a role, and a and b individuals. A
SHIQ ontology KB is a triple (KBR, KBT , KBA), where

566WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, China−

KBR is an RBox, KBT a TBox, and KBA an ABox. In
this paper, by KB we simply denote (KBR, KBT , KBA)
if there is no confusion.
DL-Lite [2] is a sub-language of SHIQ. The set of DL-
, ¬B
Lite concepts is the smallest set containing A, ∃R, ∃R
and C1 (cid:4) C2, where A is a concept name, R a role name, B
a basic concept (i.e. a concept of the form A, ∃R or ∃R
−
),
and C1 and C2 DL-Lite concepts. ∃R is actually an un-
qualiﬁed existential restriction ∃R.(cid:8). A DL-Lite ontology
KB = (KBT , KBA) consists of a TBox KBT and an ABox
KBA. KBT is a ﬁnite set of inclusion axioms B (cid:2) C and
functionality axioms (func R) and (func R
), where B is a
basic concept, C a DL-Lite concept and R a role. KBA is
a set of concept assertions B(a) and role assertions R(a, b),
where B is a basic concept, R a role, and a and b individuals.
The semantics of a SHIQ ontology KB is given by a
mapping π that translates KB into ﬁrst-order logic. Due to
space limitation, we refer readers to [12] for the deﬁnition
of π. KB is said to be consistent/satisﬁable if there exists
a ﬁrst-order model of π(KB). The semantics of a DL-Lite
ontology KB can still be given by the same mapping π,
because a functionality axiom (func R) is a syntactic variant
of (cid:8) (cid:2)≤1 R.(cid:8). Note that the unique name assumption
(UNA) [1] on individuals is applied in DL-Lite but not in
SHIQ. UNA can be explicitly axiomatized by appending
to the ABox all inequality assertions a (cid:14)≈ b for any two
individuals a and b that have diﬀerent URIs.

−

In our work we assume that all concept assertions are at-
tached to atomic concepts only, due to the following reasons.
First, the representation of non-atomic concept assertions
is not supported by the RDF/XML syntax of OWL (cf.
http://www.w3.org/TR/owl-ref), which is the main syn-
tax for representing DL-based ontologies nowadays. Sec-
ond, a non-atomic concept assertion C(a) can be reduced to
an atomic one by replacing C(a) with Q(a) and appending
C ≡ Q to the TBox, where Q is a new atomic concept.

3.2 Disjunctive Datalog
A disjunctive datalog program with equality [6] P is a ﬁnite
set of rules without function symbols of the form A1 ∨ . . . ∨
An ← B1, . . . , Bm (where Ai and Bi are atoms). Each rule
must be safe, i.e., each variable occurring in a head atom
Ai must occur in some body atom Bj. For a rule r, the
set of head atoms is denoted by head(r), whereas the set
of body atoms is denoted by body(r). A rule r is called a
constraint if |head(r)| = 0; a fact if |body(r)| = 0. An atom
is called negated if it leads with negation-as-failure. Typical
deﬁnitions of a disjunctive datalog program, such as [6], al-
low negated atoms in the body. In our work, negated atoms
cannot occur in a transformed program that we consider, so
we omit negation-as-failure from the deﬁnitions. Disjunc-
tive datalog programs without negation-as-failure are often
called positive programs.

The set of all ground instances of rules in P is denoted
by ground(P ). An interpretation M of P is a subset of
ground atoms in the Herbrand base of P . An interpreta-
tion M is called a model of P if (i) body(r) ⊆ M implies
head(r) ∩ M (cid:14)= ∅ for each rule r ∈ ground(P ), and (ii) all
atoms from M with the equality predicate ≈ yield a con-
gruence relation, i.e. a relation that is reﬂexive, symmetric,
transitive, and T (a1, . . . , ai, . . . , an) ∈ M and ai ≈ bi ∈ M
imply T (a1, . . . , bi, . . . , an) ∈ M for each predicate symbol
T in P . P is said to be satisﬁable if it has a model.

3.3 Reducing SHIQ to Disjunctive Datalog

Since SHIQ is a subset of ﬁrst-order logic, SHIQ ax-
ioms can ﬁrst be translated into logical formulas, then into
clausal form. The resulting clauses can be represented as dis-
junctive rules without negation-as-failure. However, due to
possible skolemization steps in the clausal form translation,
the resulting rules may contain function symbols. Standard
logic program engines, however, may not terminate in the
presence of function symbols. To cope with this problem,
Hustadt et al.
[12, 21] developed the KAON2 transforma-
tion method to get rid of function symbols without losing
ABox consequences.
The method reduces a SHIQ ontology KB to a positive
disjunctive datalog program DD(KB) = Γ(KBR, KBT ) ∪
Ξ(KBA) ∪ Δ(KB). Γ(KBR, KBT ) is a set of disjunctive
datalog rules computed from the intensional part of KB by
translating SHIQ axioms into clauses, adding logical con-
sequences, and translating clauses into disjunctive datalog
rules. Ξ(KBA) is a set of facts translated from KBA, where
each inequality assertion (of the form a (cid:14)≈ b) is translated
into a ground constraint (of the from ← a ≈ b), and other
assertions are directly translated into ground facts. Δ(KB)
is a set of facts of the form HU (a), HU (af ) and Sf (a, af ),
which are introduced to remove function symbols and in-
stantiated for each individual a occurring in KB and each
function symbol f .

Theorem 1

([21]). For KB a SHIQ ontology, KB is

unsatisﬁable if and only if DD(KB) is unsatisﬁable.

4. MINIMUM COST DIAGNOSIS

Given a possibly inconsistent SHIQ ontology KB in which
some assertions are removable and assigned removal costs,
our goal is to ﬁnd a subset of removable assertions whose
removal turns KB consistent and in which the sum of re-
moval costs is minimum. Such subset is called a minimum
cost diagnosis, formally deﬁned below.

Deﬁnition 1. Let KB be a possibly inconsistent SHIQ
ontology and RKB ⊆ KBA a set of removable assertions
such that each assertion α ∈ RKB is given a removal cost
c(α) > 0. Then, a subset of assertions R ⊆ RKB is called a
diagnosis for KB w.r.t. RKB if (KBR, KBT , KBA \ R) is
consistent. A diagnosis R is called a minimum cost diagnosis
for KB w.r.t. RKB if there is no diagnosis R
for KB w.r.t.
α∈R c(α). R is simply called
RKB such that
a diagnosis/minimum cost diagnosis if KB and RKB are
clear from the context.

α∈R(cid:2) c(α) <

(cid:2)

(cid:2)

(cid:3)

We consider the time complexity for ﬁnding a minimum
cost diagnosis. Complexity results in this paper refer to data
complexity, i.e. the complexity measured as a function of
the number of assertions in the ontology. Theorem 2 shows
that, unless P=NP, there is no polynomial time algorithm
for ﬁnding a minimum cost diagnosis for a DL-Lite ontology
KB w.r.t. KBA.
It implies that the problem of ﬁnding
minimum cost diagnoses for SHIQ ontologies is in general
intractable.

Theorem 2. Given a positive integer k and a possibly
inconsistent DL-Lite ontology KB = (KBT , KBA) where
each assertion α ∈ KBA is given a removal cost c(α) = 1,
deciding if there is a diagnosis R for KB w.r.t. KBA such
that

α∈R c(α) ≤ k is NP-hard w.r.t. data complexity.

(cid:2)

567WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, China(cid:3)

−

Proof. Given an arbitrary instance I of the SAT prob-
lem, we transform it into an instance I
of the given decision
problem. Let I be the formula f = C1 ∧ . . . ∧ Cm with m
(cid:3)
clauses and n boolean variables x1, . . . , xn. We construct I
as follows. (1) KBT consists of the following axioms:
−
(func S

∃T (cid:2) ¬∃S, ∃T

− (cid:2) ¬∃S

(func T

(2) For each boolean variable xi in f , KBA contains a cor-
responding constant ai.
(3) For each clause Cj contain-
ing nj literals lj,1, . . . , lj,nj whose corresponding constants
in KBA, introduced in (2), are aj,1, . . . , aj,nj respectively,
KBA contains a corresponding constant cj for Cj and nj
assertions U (aj,1, cj), . . . , U (aj,nj , cj ), where U (aj,k, cj ) is
T (aj,k, cj) if lj,k is positive, or S(aj,k, cj ) otherwise. (4) Let
k =

j=1(nj − 1).

(cid:2)m

−

),

,

).

Now we prove that f is satisﬁable if and only if there is a
diagnosis R for KB = (KBT , KBA) w.r.t. KBA such that
(cid:2)
a∈R c(a) ≤ k, i.e., |R| ≤ k. (⇒) Since f is satisﬁable,
for each clause Cj there is a literal lj,k assigned true. We
append to R all assertions in KBA of the form U (aj,p, cj )
(p (cid:14)= k), where U (aj,p, cj) is T (aj,p, cj ) if lj,p is positive, or
S(aj,p, cj ) otherwise. Clearly, R is a diagnosis for KB w.r.t.
KBA such that |R| ≤ k. (⇐) Suppose R is a diagnosis for
KB w.r.t. KBA such that |R| ≤ k.
It is not hard to see
that any set of assertions of the form U (aj,k, cj ) (U is either
T or S) must have exactly nj − 1 assertions in R and one in
KBA \ R. To see that f is satisﬁable, for each U (aj,k, cj) ∈
KBA \ R (j = 1, . . . , m), if U is T , we assign xj,k (i.e. the
corresponding variable of aj,k in f ) true; otherwise we assign
xj,k false. The above (partial) assignment on {x1, . . . , xn} is
consistent and ensures lj,k = true for all j = 1, . . . , m. Thus
f is satisﬁable.

Since the construction of KB is accomplished in PTIME
and the SAT problem is NP-complete, and since KBT has
a ﬁxed size, this theorem follows.

5. COMPUTING MINIMUM COST

DIAGNOSES

As analyzed in related work, a method that computes
minimum cost diagnoses based on minimal conﬂict sets is
impractical, because it may require both exponential time
and exponential space. We thus consider methods that need
not compute minimal conﬂict sets. A na¨ıve method is the
black-box method, which searches minimum cost diagnoses
over all subsets of removal assertions by applying a DL rea-
soner to check diagnoses. However, the black-box method
cannot compute a minimum cost diagnosis for a DL-Lite
ontology in polynomial calls to a DL reasoner, otherwise a
minimum cost diagnosis can be computed in PTIME w.r.t.
data complexity, contradicting Theorem 2. In order to ﬁnd
a practical computational method, we consider transforming
the input ontology KB into a positive program Π such that
for any subset S of RKB the set of removable assertions,
) = 1 |
KB \ S is consistent if and only if Π ∪ {assign(α
−
) = 0 | α ∈ RKB \ S} is satisﬁable,
α ∈ S} ∪ {assign(α
−
where α
is a fresh ground atom corresponding to ground
atom α in Π, and assign(β) denotes the 0-1 truth value of β.
Then, a minimum cost diagnosis corresponds to a valuation
of X such that
) is minimum and Π
is satisﬁable, where X = {α

α−∈X c(α) · assign(α
−

− | α ∈ RKB}.

(cid:2)

−

To ﬁnd such a valuation of X, we need to handle pseudo-
i cixi ≤ d
boolean constraints (PB-constraints) of the form
with constants ci, d ∈ Z and variables xi ∈ {0, 1}, or a linear

(cid:2)

(cid:2)

i cixi with
optimization function of the form minimize
constants ci ∈ Z and variables xi ∈ {0, 1}, where Z denotes
the integer domain. The SAT problems with PB-constraints
and linear optimization functions are well studied in the SAT
community (cf. http://www.cril.univ-artois.fr/PB07/).
A SAT problem with linear optimization functions can be
translated into a set of SAT problems with PB-constraints.
A SAT problem with PB-constraints can be either solved
by standard SAT solvers after translating PB-constraints to
SAT clauses [5], or solved by extended SAT solvers that
support PB-constraints natively (e.g., PUEBLO [28]).
Now, the remaining problems are how to transform a
SHIQ ontology to the intended positive program and how
to eﬃciently compute minimum cost diagnoses. We address
these problems in the following subsections.
5.1 Constructing a Repair Program

Given a possibly inconsistent SHIQ ontology KB, we
ﬁrst employ the KAON2 transformation method [12, 21],
described in Preliminaries, to reduce KB to a disjunctive
datalog program DD(KB) = Γ(KBR, KBT ) ∪ Ξ(KBA)
∪ Δ(KB), but introduce a special treatment. The original
KAON2 transformation method allows equality atoms (of
the form X ≈ Y or a ≈ b, where X, Y denote variables and
a, b denote constants) to occur in rule bodies in DD(KB)
while disallows inequality atoms (of the form X (cid:14)≈ Y or
a (cid:14)≈ b) to occur in DD(KB). To handle inequality assertions
in a similar way as other assertions, we ﬁrst move equality
atoms (X ≈ Y or a ≈ b) in any rule body in DD(KB) to the
corresponding rule head and replace them with inequality
atoms (X (cid:14)≈ Y or a (cid:14)≈ b), then append to DD(KB) a con-
straint ← X ≈ Y, X (cid:14)≈ Y (written R(cid:5)≈), so that Ξ(KBA) is
simpliﬁed to a direct translation from assertions in KBA to
ground facts in DD(KB). Having such treatment we simply
denote Ξ(KBA) as KBA. The modiﬁed rules in DD(KB)
are still safe due to the restricted form of the original rules
that have equality atoms in the body. In essence, our treat-
ment views an inequality atom as an ordinary one and does
not impact the satisﬁability of DD(KB). Then, we convert
DD(KB) to a repair program R(KB) deﬁned below. Intu-
itively, the decision atom α
is introduced to weaken KB,
so that α
= false) implies that α is re-
= true (resp. α
moved from (resp. kept in) KB. Note that decision atoms
in R(KB) are treated as nullary ground atoms.

−
−

−

Deﬁnition 2. For KB a possibly inconsistent SHIQ on-
tology and RKB ⊆ KBA a set of removable assertions such
that each assertion α ∈ RKB is given a removal cost c(α) >
0, a repair program of KB w.r.t. RKB , written R(KB), is
a disjunctive datalog program converted from DD(KB) as
follows: for each assertion α ∈ RKB, we introduce a corre-
sponding decision atom α
) = c(α),
then replace the ground fact α in DD(KB) with α∨α
−
. We
simply call R(KB) a repair program if RKB is clear from
the context.

and give it a cost c(α

−

−

Example 2. Let A, E, H, P , S, T , me and pa abbre-
viate Artif icer, Engineer, Human, P rof essor, Student,
T eacher, mentor and parent respectively. Given a SHIQ
ontology KB = (∅, KBT , KBA), where KBT = {S (cid:2)≤1
me (cid:4) ∃me.P (cid:4) H, H (cid:2) ∀pa.H, P (cid:2) E, ∃me.E (cid:2) ¬A,
E (cid:2) ¬T} and KBA = {S(s1), S(s2), me(s1, t1), me(s1, t2),
A(s2), T (t1), T (t2), T (p1), E(p2), pa(s1, p1), pa(s2, p1), t1 (cid:14)≈
t2, p1 ≈ p2}, and a set of removable assertions RKB =

568WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, China{S(s2), A(s2), T (t1), T (t2), E(p2), t1 (cid:14)≈ t2, p1 ≈ p2} such
that c(α) = 1 for each assertion α ∈ RKB, we construct the
repair program R(KB) as follows.

Y1 ≈ Y2 ← S(X), me(X, Y1), me(X, Y2).
P (Xf ) ← S(X), Sf (X, Xf ).

First, by applying the KAON2 transformation method
with our special treatment, we reduce KB to DD(KB) =
Γ(KBR, KBT ) ∪ {R(cid:5)≈} ∪ KBA ∪ Δ(KB), where Δ(KB) =
{Sf (s1, s1f ), Sf (s2, s2f ), Sf (t1, t1f ), Sf (t2, t2f ), Sf (p1, p1f )}
and Γ(KBR, KBT ) = {R1, . . . , R9} as given below.
R1:
R2:
R3: me(X, Xf ) ← S(X), Sf (X, Xf ).
R4: H(X) ← S(X).
R5: H(Y ) ← H(X), pa(X, Y ).
E(X) ← P (X).
R6:
R7: ← A(X), me(X, Y ), E(Y ).
R8: ← T (X), E(X).
R9: ← A(X), S(X).
Then, by introducing decision atoms and converting ground
facts in DD(KB), we obtain R(KB) = {R1, . . . , R9, R(cid:5)≈}∪
Δ(KB) ∪ {S(s1), me(s1, t1), me(s1, t2), T (p1), pa(s1, p1),
pa(s2, p1), S(s2) ∨ S(s2)
, T (t1) ∨ T (t1)
−
,
T (t2) ∨ T (t2)
, (t1 (cid:14)≈ t2) ∨ (t1 (cid:14)≈ t2)
−
,
−}.
(p1 ≈ p2) ∨ (p1 ≈ p2)

, E(p2) ∨ E(p2)

, A(s2) ∨ A(s2)

−

−

−

−

There exists a correspondence between minimum cost di-
agnoses for KB w.r.t. RKB and X-MC models of R(KB),
− | α ∈ RKB} (see Theorem 3). A model
where X = {α
M of a positive program P is called an X-MC model of P
β∈M(cid:2)∩X c(β) <
if there is no model M
(cid:2)
β∈M∩X c(β), where X is a set of ground atoms and c is a

of P such that

(cid:2)

(cid:3)

predeﬁned cost function over X.

− | α ∈ RKB}.

Theorem 3. Let KB be a SHIQ ontology, RKB ⊆ KBA
a set of removable assertions such that each assertion α ∈
RKB is given a removal cost c(α) > 0, R(KB) a repair
program of KB w.r.t. RKB , and X = {α
(Soundness) For each X-MC model M of R(KB), {α |
− ∈ M} is a minimum cost diagnosis for KB w.r.t. RKB;
α
(Completeness) For each minimum cost diagnosis R for KB
w.r.t. RKB, there exists an X-MC model M of R(KB) such
that R = {α | α
Proof sketch. (Soundness) Let M be an X-MC model
−|α ∈ R}.
− ∈ M} and M
of R(KB), R = {α | α
is a model of DD(KB)\R. By The-
(cid:3)
It can be shown that M
orem 1, R is diagnosis of KB w.r.t. RKB . Further, R must
be a minimum cost diagnoses, otherwise it can be shown that
) <
there exists a model M
(cid:2)

of R(KB) s.t.

= M \ {α

− ∈ M}.

α−∈M(cid:2)(cid:2)∩X c(α

α−∈M∩X c(α
(Completeness) Let R be a minimum cost diagnosis for
KB w.r.t. RKB. By Theorem 1, DD(KB) \ R is satisﬁable
(cid:3)
and thus has a model, say M . It can be shown that M
=
M ∪ {α
− | α ∈ R} is a model of R(KB). Further, M
(cid:3)
must be an X-MC model of R(KB), otherwise it can be
for KB w.r.t. RKB
shown that there exists a diagnosis R
s.t.
5.2 Computing X-MC Models

α∈R(cid:2) c(α) <

α∈R c(α).

(cid:2)

(cid:2)

(cid:2)

−

−

).

(cid:3)

(cid:3)

(cid:3)(cid:3)

By Theorem 3, the problem of ﬁnding minimum cost di-
agnoses for KB w.r.t. RKB is reduced to the problem of
computing X-MC models of R(KB), which can be realized
by applying SAT solvers. However, SAT solvers take a pos-
itive propositional program as input and do not distinguish

equality atoms from other atoms. To treat the equality pred-
icate ≈, which is interpreted as a congruence relation, as
an ordinary predicate, we use a well-known transformation
from [8]. For a disjunctive datalog program P , let P≈ denote
the program consisting of the rules stating that the equal-
ity predicate is reﬂexive, symmetric and transitive, and the
replacement rules given below, instantiated for each predi-
cate T in P (excluding ≈) and each position i. Note that
the reﬂexive rule is not safe and is instead represented as a
set of ground facts of the form a ≈ a, instantiated for each
constant a in P . Then, appending P≈ to P allows to treat
≈ as an ordinary predicate.
T (X1, . . . , Yi, . . . , Xn) ← Xi ≈ Yi, T (X1, . . . , Xi, . . . , Xn).
For the input issue, we need to ground R(KB) before
applying SAT solvers. A well-known grounding technique is
intelligent grounding (IG) [7], which only applies to equality-
free disjunctive datalog programs. That is, if the equality
predicate ≈ is present in a disjunctive datalog program P ,
we must append P≈ to P before grounding P using the IG
technique. The IG technique has been implemented in a dis-
junctive datalog engine DLV [18], but the current implemen-
tation cannot handle large disjunctive datalog programs due
to memory limitation1, especially when the equality predi-
cate is present. On the other hand, current implementa-
tions of SAT solvers lack scalability for large propositional
programs. To address these problems, we develop two disk-
based algorithms for grounding R(KB) to Π(KB) and for
partitioning Π(KB) to disjoint subprograms respectively, so
that the computation of minimum cost diagnoses can be sep-
arately performed over each subprogram.

Algorithm 1 is our algorithm for grounding a repair pro-
gram P . By Mdef we denote the unique minimal model of
the deﬁnite fragment of P , i.e. {R ∈ P | |head(R)| = 1}. C
is actually the set of congruence classes {C1, . . . , Cm} occur-
ring in P , where Ci = {b | a ≈ b ∈ Mdef} for an arbitrary
constant a occurring in some equality atom in Mdef that is
not of the form a ≈ a. fc(a,C) denotes the congruence class
in C that contains constant a. minc(C) denotes the con-
stant a ∈ C having the smallest value in {occ(a) | a ∈ C},
where occ(a) is the occurrence order of a in P . Ddef is
actually a set of non-equality atoms in Mdef such that for
each non-equality atom T (a1, . . . , ak) ∈ Mdef , there exists a
unique ground atom T (b1, . . . , bk) ∈ Ddef such that for each
i = 1, . . . , k, ai and bi are either the same or together in
some C ∈ C. D is the set of ground atoms occurring in the
grounded program Π.

Let S and S

be two sets of ground atoms. S≈ denotes the
subset of S consisting of all equality atoms in S; S\≈ denotes
S \ S≈. For a rule R, the function GetSubstitutes(R, S,
(cid:3)
S
) returns the set of all ground substitutes σ such that
body(Rσ) ⊆ S, head(Rσ)\≈ ∩ S
= ∅ and head(Rσ)≈ does
not contain equality atoms of the form a ≈ a. The function
Rewrite(S, C) rewrites all constants a in S such that fc(a,C)
exists to minc(fc(a,C)), and returns the modiﬁed S.

(cid:3)

(cid:3)

The algorithm consists of three steps. Step 1 (lines 1–13)
computes Mdef in a standard iterative manner, but repre-
sents Mdef as Ddef and C. Step 2 (lines 14–16) rewrites
the constants occurring in disjunctive ground facts (of the
form α ∨ α
−
) in P , because some constants occurring in α
1The current implementation with DB support, DLVDB
(http://www.mat.unical.it/terracina/dlvdb/), does not
work with DBs if the input program has disjunctions.

569WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, Chinaare represented by other constants in step 1. At a word, in
step 1 and step 2, all constants in a congruence class are
replaced with a same constant, so as to reduce the number
of instantiated rules in step 3. Step 3 (lines 17–26) grounds
P +, i.e. P ∪ P≈ excluding the deﬁnite ground facts, in a
standard iterative manner based on Mdef . Each instanti-
ated rule r such that head(r) ∩ Mdef (cid:14)= ∅ is ignored (line
22), because r has no impact on computing models of P . If
a (cid:14)≈ b ∈ Ddef , the equality atom a ≈ b in an instantiated
rule head is not appended to D (line 24), because it cannot
occur in any model of P . The ground atoms in Mdef are
removed from the body of any instantiated rule (lines 25–
26), because they are in every model of P . Note that the
function GetSubstitutes can be realized by applying a SQL
engine and its results can be stored in disk, so the algorithm
In what follows, by Π(KB) we denote the
is disk-based.
grounded repair program returned by Ground(R(KB)).

Algorithm 1. Ground(P )
Input: A repair program P .
Output: A set C of sets of constants and a positive propositional

def

def do

program Π.
C := ∅; Ddef := ∅; D(cid:3)

def := {⊥}; // to enforce Ddef (cid:4)= D(cid:3)

that are not together in some C ∈ C then

1.
2. while Ddef (cid:4)= D(cid:3)
def := Ddef ;
D(cid:3)
3.
for each rule R ∈ P s.t. |head(R)| = 1 do
4.
Θ := GetSubstitutes(R, Ddef , Ddef );
5.
for each σ sequentially retrieved from Θ do
6.
7.
8.

Ddef := Rewrite(Ddef , C); // executed once for Θ

Ddef := Ddef ∪ head(Rσ)\≈;
if head(Rσ)≈ = {a ≈ b} for some constants a and b
if fc(a, C) does not exist then Set fc(a, C) as {a};
if fc(b, C) does not exist then Set fc(b, C) as {b};
C := fc(a, C) ∪ fc(b, C);
C := (C \ {fc(a, C), fc(b, C)}) ∪ {C};

9.
10.
11.
12.
13.
14. for each disjunctive ground fact α ∨ α
−
) s.t. fc(a, C) exists do
15.
) to minc(fc(a, C));
16.
17. P + := {R ∈ P ∪ P≈ | |head(R)| > 1 or R is non-ground};
18. Π := ∅; D := Ddef ∪ {a ≈ a | a occurs in P}; D(cid:3)
19. while D (cid:4)= D(cid:3) do
20.
21.
22.
23.
24.

:= D;
Θ := GetSubstitutes(R, D, Ddef );
for each σ sequentially retrieved from Θ do

D(cid:3)
for each rule R ∈ P + do

D := D ∪ head(Rσ)\≈ ∪ {a ≈ b ∈ head(Rσ)≈ | a (cid:4)≈
B := body(Rσ) \ (Ddef ∪ {a ≈ a | a occurs in Rσ});
Π := Π ∪ {(cid:3)

head(Rσ) ← (cid:4)

for each constant a in α (or α

Rewrite a in α (or α

b (cid:4)∈ Ddef};

in P do

:= ∅;

B};

−

−

25.
26.
27. return (C, Π);

Example 3. Continue with Example 2. We now demon-
strate how Ground(R(KB)) works. In step 1, we compute
the unique minimal model Mdef of R(KB)def in an iterative
manner, obtaining C = {{t1, t2, s1f}} and Ddef = {S(s1),
me(s1, t1), T (p1), pa(s1, p1), pa(s2, p1), Sf (s1, t1), P (t1),
H(s1), H(p1), E(t1), Sf (s2, s2f ), Sf (t1, t1f ), Sf (t1, t2f ),
Sf (p1, p1f )}. In step 2, according to C, we replace the set of
disjunctive ground facts in R(KB) with {S(s2) ∨ S(s2)
−
,
A(s2) ∨ A(s2)
, T (t1) ∨ T (t1)
, (t1 (cid:14)≈
−
t1) ∨ (t1 (cid:14)≈ t1)
, (p1 ≈ p2) ∨ (p1 ≈ p2)
−
In step 3, we
ground R(KB) ∪ R(KB)≈ (excluding the deﬁnite ground

, E(p2) ∨ E(p2)

−}.

−

−

.

−

facts) in an iterative manner, obtaining a propositional pro-
gram Π(KB) = {r1, . . . , r22}, where r14 is instantiated from
← X ≈ Y, X (cid:14)≈ Y (i.e. R(cid:5)≈), r15, . . . , r20 are instantiated
from R(KB)≈. Note that for instantiating a rule that con-
tains X ≈ Y in the body, we only consider all ground sub-
stitutes σ such that occ(Xσ) ≤ occ(Y σ), where occ(a) is the
occurrence order of constant a in R(KB).
r1 : S(s2) ∨ S(s2)
r3 : (t1 (cid:14)≈ t1) ∨ (t1 (cid:14)≈ t1)
−
.
r5 : (p1 ≈ p2) ∨ (P1 (cid:14)≈ p2)
−
r7 : P (s2f ) ← S(s2).
r9 : H(s2) ← S(s2).
r11 :← A(s2), me(s2, s2f ), E(s2f ).
r13 :← A(s2), S(s2).
r15 : p2 ≈ p1 ← p1 ≈ p2.
r17 : E(p2) ← p1 ≈ p2, E(p1).
r19 : E(p1) ← p1 ≈ p2, E(p2).
r21 :← E(p1).

r2 : A(s2) ∨ A(s2)
−
.
r4 : T (t1) ∨ T (t1)
−
.
r6 : E(p2) ∨ E(p2)
−
r8 : me(s2, s2f ) ← S(s2).
r10 : E(s2f ) ← P (s2f ).
r12 :← T (t1).
r14 :← t1 (cid:14)≈ t1.

r16 : T (p2) ← p1 ≈ p2.
r18 : pa(s1, p2) ← p1 ≈ p2.
r20 : pa(s2, p2) ← p1 ≈ p2.
r22 :← T (p2), E(p2).

.

.

Algorithm 2. Partition(Π, X)

Input: A positive propositional program Π and a set X of ground

atoms occurring in Π.

Set map(α) as 0 for all ground atoms α occurring in Π;

Output: A set of disjoint subprograms of Π.
1.
2. Move constraints in Π in front of other rules in Π; k := 0;
3.
4.
5.

merged := false;
for each rule r sequentially retrieved from Π s.t. head(r) =

∅ or map(α) > 0 for all α ∈ head(r) \ X do

repeat

for each α ∈ head(r) ∪ body(r) s.t. map(α) = 0 do
if |map(r)| > 1 then

k := k + 1; map(α) := k;

merged := true; minid := min(map(r));
for each α ∈ head(r) ∪ body(r) do map(α) := minid;

6.
7.
8.
9.
10.
11. until not merged;
12. for i = 1, . . . , k do
13.
14. return {Πi (cid:4)= ∅ | 1 ≤ i ≤ k};

Πi := {r ∈ Π | ∀α ∈ head(r) ∪ body(r) : map(α) = i};

Algorithm 2 is our algorithm for partitioning a positive
propositional program Π based on a set X of ground atoms
occurring in Π. The basic idea is to ﬁlter out rules that have
no impact on M ∩ X when constructing an X-MC model M
of Π and put together remaining rules that have common
ground atoms to form disjoint subprograms.
In the algo-
rithm, each ground atom α occurring in Π is mapped to a
partition identiﬁer map(α). For a rule r, we use map(r)
to denote {map(α) | α ∈ head(r) ∪ body(r)}. To simplify
explanation, we call a rule r ∈ Π ready if head(r) = ∅ or
map(α) > 0 for all α ∈ head(r) \ X. Before a ground atom
is detected in some ready rule, it is mapped to 0 (line 1). To
process ready rules as early as possible, constraints (which
are ready rules) are moved in front of other rules in Π (line
2). Then, {map(α) | α occurs in Π} is adjusted in an itera-
tive manner until {map(r) | r ∈ Π} reaches a ﬁxpoint (lines
3–11). Each ground atom α ﬁrst detected in ready rules is
initially mapped to a unique partition identifer (lines 6–7).
All ground atoms in a ready rule r are mapped to the same
partition identiﬁer (lines 8–10). After the loop is ﬁnished,
all ready rules in Π mapped to the same partition identiﬁer
are put together, yielding a set of nonempty subprograms
{Πi}1≤i≤n (lines 12–13).

570WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, ChinaIt can be seen that the number of iterations (lines 3–11)
is at most |Π|, because the mapping adjustment (lines 9–10)
ensures that in each iteration, a ready rule rm having the
smallest value of min(map(r)) among {r ∈ Π | r is ready
and |map(r)| > 1} must reach a state that |map(rm)| = 1
and that map(rm) is unchanged in subsequent iterations.
Furthermore, Π0 = Π\(cid:5)n
i=1 Πi is the intended set of ﬁltered
rules (see Lemma 1); Πi and Πj contain no common ground
atoms for all 1 ≤ i < j ≤ n. Since Π is sequentially accessed
in each iteration, the algorithm is also disk-based.

(cid:3)

r∈Π0

(cid:5) P, M

= M ∪ (cid:5)

(cid:3) ∩ X.
Proof. Let M0 =

Lemma 1. Let P be the set of subprograms returned by
Partition(Π, X) and Π0 = Π \ (cid:5) P. For any X-MC
{α ∈ head(r) | α (cid:14)∈
model M of
X, map(α) = 0} is an X-MC model of Π such that M ∩ X =
M
{α ∈ head(r) | α (cid:14)∈ X, map(α) =
0}. Since M0 ∩ head(r) (cid:14)= ∅ for every r ∈ Π0, M
= M ∪ M0
satisﬁes every rule in Π0. Moreover, since map(α) > 0 for
(cid:5) P, M0 ∩ M = ∅ and
every ground atom α occurring in
(cid:5) P as M . It follows that
thus M
still satisﬁes every rule in
is an X-MC
M
model of Π such that M ∩ X = M
(cid:3) ∩ X.

is a model of Π. Since M0 ∩ X = ∅, M

r∈Π0

(cid:5)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

−

−
10:1.

Example 4. Continue with Example 3. Let X (cid:4) be the set
in Π(KB). We now demon-
of ground atoms of the form α
strate how Partition(Π(KB), X (cid:4)) works. We ﬁrst move
r11, . . . , r14, r21, r22 in front of other rules in Π(KB), then
map each ground atom in Π to a partition identiﬁer. In the
ﬁrst iteration for processing rules r ∈ Π, map(r) is set as
follows (for every ground atom α, αj:k denotes map(α) = j
before processing r at line 8 in Algorithm 2, and map(α) = k
after the ﬁrst iteration).
r11 :← A(s2)1:1, me(s2, s2f )2:1, E(s2f )3:1.
r12 :← T (t1)4:4.
r14 :← (t1 (cid:14)≈ t1)6:6.
r13 :← A(s2)1:1, S(s2)5:1.
r22 :← T (p2)8:7, E(p2)9:7.
r21 :← E(p1)7:7.
r2 : A(s2)1:1 ∨ A(s2)
r1 : S(s2)1:1 ∨ S(s2)
−
11:1.
r3 : (t1 (cid:14)≈ t1)6:6 ∨ (t1 (cid:14)≈ t1)
r4 : T (t1)4:4 ∨ T (t1)
−
−
12:6.
13:4.
15:7. r6 : E(p2)8:7 ∨ E(p2)
r5 : (p1 ≈ p2)14:7 ∨ (p1 ≈ p2)
−
−
16:7.
r7 : P (s2f )0:1 ← S(s2)1:1.
r8 : me(s2, s2f )1:1 ← S(s2)1:1.
r9 : H(s2)0:0 ← S(s2)1:1.
r10 : E(s2f )1:1 ← P (s2f )17:1.
r15 : (p2 ≈ p1)0:0 ← (p1 ≈ p2)14:7.
r16 : T (p2)8:7 ← (p1 ≈ p2)14:7.
r17 : E(p2)8:7 ← (p1 ≈ p2)8:7, E(p1)7:7.
r18 : pa(s1, p2)0:0 ← (p1 ≈ p2)7:7.
r19 : E(p1)7:7 ← (p1 ≈ p2)7:7, E(p2)7:7.
r20 : pa(s2, p2)0:0 ← (p1 ≈ p2)7:7.
In the second iteration, it is detected that |map(r)| = 1 for
all ready rules r ∈ Π, so the loop is ﬁnished. Finally we
obtain four disjoint subprograms from the resulting map-
ping: Π1 = {r11, r13, r1, r2, r7, r8, r10}, Π2 = {r12, r4}, Π3 =
{r14, r3} and Π4 = {r21, r22, r5, r6, r16, r17, r19}.

−
In what follows, we call a ground atom of the form α
a translated decision atom. Let C be the set of congru-
ence classes returned by Ground(R(KB)), and {Πi}1≤i≤n
the set of subprograms returned by Partition(Π(KB), X (cid:4)),
where X (cid:4) is the set of translated decision atoms occurring
in Π(KB). We intend to compute X-MC models of R(KB)
over each of {Πi}1≤i≤n, where X is the set of decision atoms
occurring in R(KB). However, some decision atoms are re-
i=1 Πi, because all constants in
placed with other atoms in
a congruence class in C are replaced with a same constant.

(cid:5)n

(cid:3)

(cid:3)

(cid:3)

−

−

(cid:2)

) =

Let X
(cid:5)n

i=1 Πi. X

), where bi

− ∈ X

(T (a1, . . . , ak)

T (b1,...,bk)−∈X,b1 .=C a1,...,bk

be the set of translated decision atoms occurring in
is said to be soundly converted from X w.r.t. C
if each ground atom T (a1, . . . , ak)
has been given a
(cid:3)
.=C ak
cost c
.
=C ai means that constants bi
c(T (b1, . . . , bk)
and ai are the same or together in some C ∈ C. Such conver-
−
sion is reasonable because all decision atoms T (b1, . . . , bk)
∈ X such that b1
−
.
=C ak for some T (a1, . . . , ak)
∈ X
must be present or absent together in every model of
R(KB). Moreover, given a subset S of X
, we deﬁne a decod-
ing of S w.r.t. X and C, written d(S, X,C), as {T (b1, . . . , bk)
−
∈ X | T (a1, . . . , ak)
=C ak}. Then,
.
a minimum cost diagnosis of KB corresponds to a disjoint
union of models in each subprogram (see Theorem 4).

.
=C a1, . . . , bk

.
=C a1, . . . , bk

− ∈ S, b1

(cid:3)

(cid:3)

(cid:3)

(cid:3)

−

−

−

−

−

−

(cid:5)4

(T (t1)

, A(s2)

Example 5. Continue with Example 4. Let X be the set
of decision atoms in R(KB). In
i=1 Πi, the set of ground
atoms soundly converted from X w.r.t. C = {{t1, t2, s1f}}
= {S(s2)
, (t1 (cid:14)≈ t1)
, (p1 ≈ p2)
−
−
is X
, T (t1)
,
−}, where each ground atom α
− ∈ X
(cid:3)
E(p2)
is given a cost
(cid:3)
−
(cid:3)
c
) = 2. Let Xi (i = 1, . . . , 4)
) = 1 except that c
(α
be the subsets of X
that occur in Πi. It is easy to see that
Π1 has two X1-MC models M1,1 = {S(s2)
, A(s2)} and
, P (s2f ), me(s2, s2f ), E(s2f )}; Π2
M1,2 = {S(s2), A(s2)
−}; Π3 has a unique
has a unique X2-MC model M2 = {T (t1)
X3-MC model M3 = {(t1 (cid:14)≈ t1)
−}; Π4 has two X4-MC
models M4,1 = {(p1 ≈ p2)
, E(p2)} and M4,2 = {E(p2)
−
,
p1 ≈ p2, T (p2)}. Hence, d(M1,1 ∩ X1, X,C) = {S(s2)
−};
−}; d(M2 ∩ X2, X, C) = {T (t1)
d(M1,2 ∩ X1, X, C) = {A(s2)
−
−}; d(M4,1∩X4, X,C)
T (t2)
= {(p1 ≈ p2)
−}. By The-
orem 4, we obtain four minimum cost diagnoses for KB
w.r.t. RKB : {S(s2), T (t1), T (t2), t1 (cid:14)≈ t2, p1 ≈ p2}, {A(s2),
T (t1), T (t2), t1 (cid:14)≈ t2, p1 ≈ p2}, {S(s2), T (t1), T (t2), t1 (cid:14)≈ t2,
E(p2)} and {A(s2), T (t1), T (t2), t1 (cid:14)≈ t2, E(p2)}.

−}; d(M4,2 ∩ X4, X, C) = {E(p2)

−}; d(M3∩X3, X,C) = {(t1 (cid:14)≈ t2)

−

(cid:3)

(cid:3)

(cid:5)n

that occur in Π1, . . . , Πn respectively.

i=1 d(Mi ∩ Xi, X,C)} is a minimum cost diag-

Theorem 4. For KB a SHIQ ontology and RKB ⊆
KBA a set of removable assertions such that each asser-
tion α ∈ RKB is given a removal cost c(α) > 0, suppose
Ground(R(KB)) returns (C, Π(KB)) and Partition(Π(KB),
X (cid:4)) returns {Πi}1≤i≤n, where X (cid:4) is the set of translated de-
cision atoms occurring in Π(KB). Let X
be the set of trans-
i=1 Πi which is soundly
lated decision atoms occurring in
− | α ∈ RKB}, and X1, . . . , Xn be
converted from X = {α
the subsets of X
(Soundness) For each Xi-MC model Mi of Πi (i = 1, . . . , n),
− ∈ (cid:5)n
{α | α
nosis for KB w.r.t. RKB;
(Completeness) For each minimum cost diagnosis R for KB
w.r.t. RKB, there exists an Xi-MC model Mi of Πi (i =
i=1 d(Mi ∩ Xi, X,C)}.
1, . . . , n) such that R = {α | α
Proof sketch. (Soundness) For i = 1, . . . , n, let Bi be
the set of ground atoms occurring in Πi and Mi an Xi-
MC model of Πi. Let Π0 = Π(KB) \ (cid:5)n
i=1 Πi and M =
{α ∈ head(r) | α (cid:14)∈ X (cid:4) ∪ (cid:5)n
(cid:5)
i=1(Mi ∩ Bi).
r∈Π0
(cid:3)
Let M
be the set of ground atoms derived by applying all
rules in R(KB)≈ over M ∪ {a ≈ b | a and b are together
in some C ∈ C}, and M + = M ∪ M
. It can be seen that
(cid:5)n
i=1 d(Mi ∩ Xi, X,C) = M + ∩ X. It can further be shown
that M + is an X-MC model of R(KB). By Theorem 3,
− ∈ M +} is a mini-
{α|α
mum cost diagnosis for KB w.r.t. RKB.

i=1 d(Mi ∩ Xi, X, C)} = {α|α

i=1 Bi} ∪ (cid:5)n

− ∈ (cid:5)n

− ∈ (cid:5)n

(cid:3)

571WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, China(Completeness) Let R be a minimum cost diagnosis for
KB w.r.t. RKB . By Theorem 3, there exists an X-MC
− ∈ M}. Let M
model M of R(KB) s.t. R = {α|α
be
a set of ground atoms converted from M by rewriting each
constant a in M s.t. fc(a,C) exists to minc(fc(a,C)).
It
(cid:3) ∩ Bi is an Xi-MC model of Πi
can be shown that Mi = M
− ∈ (cid:5)n
(i = 1, . . . , n) s.t. R = {α | α
i=1 d(Mi∩Xi, X,C)}.

(cid:3)

By Theorem 4, the problem of ﬁnding minimum cost diag-
noses for KB w.r.t. RKB is reduced to n subproblems, each
of which computes Xi-MC models of Πi (i = 1, . . . , n). We
consider computing Xi-MC models of Πi by applying SAT
solvers that support PB-constraints. We assume that the
cost of each atom in Xi has been scaled to a positive integer
polynomial in |X| the total number of removable assertions.
Then, the ﬁrst Xi-MC model of Πi can be computed by a bi-
(cid:2)
(cid:3)
β∈Xi c
nary search (within range [0,
(β)]) for the minimum
value vmin such that Πi ∪ {(cid:2)
(β) · assign(β) ≤ vmin}
(cid:3)
β∈Xi c
(cid:2)
(β)) = O(log2 |X|) calls
(cid:3)
β∈Xi c
is satisﬁable, taking O(log2
to a SAT solver. Let M = {M ∩ Xi | M is a previously com-
puted Xi-MC model of Πi}. Then a next Xi-MC model M
of Πi, such that M ∩ Xi (cid:14)= S for every S ∈ M, can be
computed as a model of Πi ∪ {(cid:2)
(β) · assign(β) ≤
vmin}∪{← (cid:4)
β∈S β | S ∈ M}, by calling a SAT solver once.

(cid:3)
β∈Xi c

Consider the time complexity for computing minimum
cost diagnoses. Under the data complexity assumption, the
number of non-ground rules in R(KB) and the number of
diﬀerent variables in each rule in R(KB) are bounded by
constants. Thus the number of rules in Π(KB) is polyno-
mial in |KBA|. It follows that Ground(R(KB)) is executed
in PTIME. Let X (cid:4) be the set of translated decision atoms
occurring in Π(KB). Partition(Π(KB), X (cid:4)) commits at
most |Π(KB)| iterations over Π(KB), so it is executed in
PTIME too. Let n be the number of removable assertions
in KB and {Πi}1≤i≤m be the set of propositional programs
returned by Partition(Π(KB), X (cid:4)). Note that the SAT
problem with a PB-constraint is NP-complete. Since Πi and
Πj have no common ground atoms for all 1 ≤ i < j ≤ m, m
calls to a SAT solver over Π1, . . . , Πm respectively amount to
one call to an NP oracle over
i=1 Πi. Under the assump-
tion that each removal cost has been scaled to a positive
integer polynomial in n, it follows from Theorem 4 that, the
ﬁrst minimum cost diagnosis is computed in O(log2 n) calls
to an NP oracle, and a next one, in one more call.

(cid:5)m

6. EXPERIMENTAL EVALUATION

We implemented the proposed method for computing min-
imum cost diagnoses in GNU C++. In the implementation,
MySQL is used as the back-end SQL engine; ABox asser-
tions and new ground atoms derived in the grounding pro-
cess are maintained in a SQL database; All ground substi-
tutes of rules, retrieved via SQL statements, are maintained
in disk ﬁles; The SAT solver MiniSat+ [5], which supports
PB-constraints and linear optimization functions by inter-
nally translating them into SAT clauses, is applied to com-
pute X-MC models. All the experiments were conducted on
a 3.2GHz Pentium 4 CPU 2GB RAM PC running Windows
XP and Cygwin.
6.1 Test Ontologies and Preparations

Semintec2 is an ontology about ﬁnancial services, created

2

http://www.cs.put.poznan.pl/alawrynowicz/

Table 1: The complexity of test ontologies

NC NR
16
59
49
27
34
86
86
34

NI
17,941
82,095
50,253
629,568

S
H
L1
L10

NA Nr

Features
221 EQ13,DS0
EQ7,DS7
159
EQ2,DS0
168
168
EQ2,DS0

65,291
154,110
120,274
1,293,286

−

Note: S stands for Semintec. H stands for HumanCyc
. L1
stands for LUBM1+. L10 stands for LUBM10+. NC is the
number of concept names. NR is the number of role names.
NI is the number of individuals. NA is the number of ABox
assertions stored in MySQL databases. Nr is the number
of rules transformed from the intensional part. The features
show how many special transformed rules: EQn means there
are n equality rules (i.e. rules containing equality atoms);
DSn means there are n disjunctive rules.

in the SEMINTEC project at the University of Poznan. Its
intensional part contains functional roles and disjointness
constraints.

HumanCyc3 is an ontology on human metabolic pathways
and human genome, created by the SRI International cor-
poration. Since its intensional part contains nomimals and
concrete domain speciﬁcations (e.g., a role range is of some
datatype, a concrete role is functional, etc.)
that cannot
be handled by our method, we converted nominals to new
atomic concepts and deleted concrete domain speciﬁcations.
The weakened intensional part still contains disjunctions,
functional roles/restrictions and disjointness constraints.

LUBM4 is a benchmark ontology developed at the Lehigh
University [9]. Since its intensional part has no functional
roles, number restrictions or disjointness constraints, which
implies that it cannot be inconsistent, we extended it by
adding a functional role headOf and an inverse functional
role isTaughtBy, where headOf (resp. isTaughtBy) is also
deﬁned as an inverse role of isHeadOf (resp. teacherOf),
and adding disjointness constraints X (cid:2) ¬N onX for each
existing concept name X, where N onX is a new concept
name. LUBM comes with an ABox generator. Let LUBMn
denote the ontology obtained from the generator by setting
the number of universities to n.

Before testing the proposed method, the intensional parts
of the above ontologies were oﬄine transformed to datalog
programs using the KAON2 DL reasoner5. Each transfor-
mation was performed in less than one second. Moreover,
ABox assertions of the above ontologies were stored into
MySQL databases, where duplicated ABox assertions were
removed. Table 1 summarizes the complexity of the test on-
tologies and the datalog programs transformed from their
denotes the weakened
intensional parts, where HumanCyc
HumanCyc, and LUBMn+ denotes the extended LUBMn.
We developed a tool, called Injector, to inject a given
number of conﬂicts into an ontology. Given a consistent
ontology KB and a number ncnf of conﬂicts to be injected,
Injector ﬁrst deduces into KB all atomic concept assertions
that are consequences of KB, then injects ncnf conﬂicts one
by one. Let SF R denote the set of functional/inverse func-

−

semintec.htm
3

4

5

http://humancyc.org/
http://swat.cse.lehigh.edu/projects/lubm/
http://kaon2.semanticweb.org/

572WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, Chinational roles, SDC denote the set of atomic concepts that have
disjoint concepts. To inject a conﬂict, Injector randomly
selects an entity in SF R∪SDC. In case an functional role R is
selected, if there exist role assertions over R in KB, Injec-
tor randomly selects one, say R(a, b), and appends R(a, c)
and b (cid:14)≈ c to KB, where c is a new individual; otherwise,
Injector appends R(a, b), R(a, c) and b (cid:14)≈ c to KB, where
a, b, c are new individuals. In case an inverse functional role
R is selected, Injector treats it as R
. In case an atomic
concept C is selected, if there exist concept assertions over
C in KB, Injector randomly selects one, say C(a), and
appends D(a) to KB for a randomly selected disjoint con-
cept D of C; otherwise, Injector appends C(a) and D(a)
to KB, where a is a new individual and D a randomly se-
lected disjoint concept of C. Injector was implemented in
JAVA, using the Pellet [29] API to deduce all atomic concept
assertions that are consequences of a consistent ontology.

−

6.2 Experimental Results

We injected diﬀerent number of conﬂicts to the four test
ontologies using Injector, obtaining a set of inconsistent
ontologies. We consider the hardest case where all asser-
tions in an obtained ontology are assumed removable. We
assume that each assertion is given a removal cost 1.
In
order to make the implemented system terminate in an ac-
ceptable time, we set a time limit of 20 minutes for one call
to MiniSat+.

The test results are reported in Table 2. In each block,
the ﬁrst row lists ncnf , i.e. the number of injected conﬂicts;
the second row lists the total execution time for computing
the ﬁrst minimum cost diagnosis, starting from transform-
, the
ing the input ontology. For Semintec and HumanCyc
implemented system cannot handle more injected conﬂicts
in our test environment, because when ncnf = 140 for Sem-
), some call to MiniSat+
intec (or ncnf = 60 for HumanCyc
exceeds the time limit. In contrast, the implemented system
scales well on LUBM1+/LUBM10+ ontologies with increas-
ing number (from 1000) of conﬂicts.

−

−

We also collected runtime statistics on the partitioning
process. Let KB be an inconsistent ontology reported in Ta-
ble 2. As can be seen, the number of rules in each grounded
repair program Π(KB) is up to millions. In addition, the
number of decision atoms in Π(KB) is at least in thousands.
We experimentally veriﬁed that any Π(KB), without being
partitioned, cannot be handled by MiniSat+ because the ex-
ecution exceeds the time or memory limit. This shows the
importance of the partitioning process.

|Π0|

Other statistics show the eﬀectiveness of the partition-
|Π(KB)| , is at
ing process. The percentage of ﬁltered rules,
least 11% for all reported ontologies (esp., at least 57% for
LUBM10+ ontologies). The number of disjoint subprograms
of Π(KB) (i.e. the number of partitions), #{Πi}, increases
when the number of conﬂicts increases. This shows that the
partitioning process improves the scalability.
Table 2 also reports the maximum number of ground rules
in each partition, max(|{Πi}|), and the maximum number
of translated decision atoms in each partition, max(|{Xi}|).
It can be seen that the total execution time is roughly dom-
inated by max(|{Πi}|) and max(|{Xi}|). For Semintec and
, since max(|{Xi}|) is up to tens of thousands,
HumanCyc
the execution of MiniSat+ over the largest partition quickly
exceeds the time limit when the number of conﬂicts increases
(as max(|{Πi}|) increases too).
In contrast, for LUBM1+

−

Table 2: Test results against diﬀerent number of
conﬂicts ncnf

Semintec

ncnf
Time (sec)
|Π(KB)|
|Π0|
|Π(KB)|
#{Πi}

max({|Πi|})
max({|Xi|})

ncnf
Time (sec)
|Π(KB)|
|Π0|
|Π(KB)|
#{Πi}

max({|Πi|})
max({|Xi|})

ncnf
Time (sec)
|Π(KB)|
|Π0|
|Π(KB)|
#{Πi}

max({|Πi|})
max({|Xi|})

60
191
241K

100
298
371K

80
155
230K

120
40
1144
53
159K
636K
73.8% 45.1% 53.1% 35.8% 24.9%
57
393K
18794

31
66K
16114

49
152K
20241

25
11K
7054

40
76K
14687
−

HumanCyc

20
326
607K

40
412
604K

30
531
620K

50
10
867
428
598K
639K
26.0% 25.6% 25.1% 25.7% 24.4%
21
483K
68197

10
465K
68175

5
443K
68155

19
449K
68181

7
451K
68159
LUBM1+

3000
554

2000
387

4000
814

5000
1000
1010
202
537K
978K 1490K 2306K 2877K
41.9% 25.9% 18.7% 13.3% 11.4%
4606
540K
898

2696
120K
895

3645
244K
901

1766
146K
859

886
43K
808

LUBM10+

2000
851

|Π0|

4000
1250

3000
1070

1000
736

ncnf
Time (sec)
|Π(KB)|
|Π0|
|Π(KB)|
#{Πi}

5000
1618
3893K 4111K 4165K 4338K 4753K
82.3% 70.8% 65.8% 62.8% 57.3%
4423
max({|Πi|})
34K
max({|Xi|})
1393
Note: |Π(KB)| is the number of rules in the grounded repair
|Π(KB)| is the percentage of rules ﬁltered
program Π(KB).
out in our partitioning algorithm. #{Πi} is the number of
partitions. max({|Πi|}) is the maximum number of ground
rules in each partition. max({|Xi|}) is the maximum number
of translated decision atoms in each partition.

1860
24K
1571

2713
31K
1961

3605
43K
2610

963
26K
810

and LUBM10+, since max(|{Πi}|) or max(|{Xi}|) is stable
around a relatively small value, the total execution time in-
creases smoothly when the number of conﬂicts increases.

We can conclude that the performance of our method de-
pends on the eﬀectiveness of the partitioning process. As
for what inﬂuences such eﬀectiveness when the number of
assertions and the number of conﬂicts are ﬁxed, we can see
from Table 1 and Table 2 that, equality rules have a stronger
impact than normal rules; further, disjunctive rules have a
stronger impact than equality rules. Hence, we believe that
our method can handle any real (populated) ontology that
has up to millions of assertions together with a moderately
complex intensional part, which can be transformed to up
to hundreds of datalog rules with a few disjunctive rules and
equality rules.

573WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, China7. CONCLUSION AND FUTURE WORK

A DL-based ontology may become inconsistent after it is
populated. In this paper, we proposed a solution to repair
the populated ontology by deleting assertions in a minimum
cost diagnosis. We ﬁrst showed the intractability of ﬁnding
a minimum cost diagnosis, then presented an exact method
for computing minimum cost diagnoses for SHIQ ontolo-
gies. The method transforms a SHIQ ontology to a set of
disjoint propositional programs in PTIME w.r.t. data com-
plexity, thus reducing the original problem into a set of inde-
pendent subproblems. Each such subproblem computes an
X-MC model and is solvable by applying SAT solvers. We
experimentally showed that the method can handle moder-
ately complex ontologies with over thousands of assertions,
where all assertions can be assumed removable. Especially,
the method scales well on the extended LUBM ontologies
with increasing number (from 1000) of conﬂicts.

For future work, we plan to enhance our method to cope
with concrete domain speciﬁcations, seek feasible approaches
to handling nomimals, and work on tractable approximate
methods for computing minimum cost diagnoses.

8. ACKNOWLEDGEMENTS

This work is supported in part by NSFC grants 60673103,

60721061 and 60373052.

9. REFERENCES
[1] F. Baader, D. Calvanese, D. L. McGuinness, D. Nardi,

and P. F. Patel-Schneider, editors. The Description
Logic Handbook: Theory, Implementation, and
Applications. Cambridge University Press, 2003.

[2] D. Calvanese, G. D. Giacomo, D. Lembo,

M. Lenzerini, and R. Rosati. Dl-lite: Tractable
description logics for ontologies. In Proc. of AAAI’05,
pages 602–607, 2005.

[3] P. Cimiano and J. V¨olker. Text2onto - a framework

for ontology learning and data-driven change
discovery. In Proc. of NLDB’05, pages 227–238, 2005.

[4] J. Dolby, J. Fan, A. Fokoue, A. Kalyanpur,

A. Kershenbaum, L. Ma, J. W. Murdock, K. Srinivas,
and C. A. Welty. Scalable cleanup of information
extraction data using ontologies. In Proc. of ISWC’07,
pages 100–113, 2007.

[5] N. E´en and N. S¨orensson. Translating pseudo-boolean

constraints into sat. JSAT, 2:1–26, 2006.

[6] T. Eiter, G. Gottlob, and H. Mannila. Disjunctive

datalog. ACM Trans. Database Systems,
22(3):364–418, 1997.

[7] T. Eiter, N. Leone, C. Mateis, G. Pfeifer, and

F. Scarcello. A deductive system for non-monotonic
reasoning. In Proc. of LPNMR’97, pages 364–375,
1997.

[8] M. Fitting. First-order Logic and Automated Theorem

Proving (2nd ed.). Springer-Verlag New York, Inc.,
Secaucus, NJ, USA, 1996.

[9] Y. Guo, Z. Pan, and J. Heﬂin. Lubm: A benchmark

for owl knowledge base systems. J. Web Sem.,
3(2–3):158–182, 2005.

[10] I. Horrocks, U. Sattler, and S. Tobies. Practical

reasoning for very expressive description logics. Logic
Journal of the IGPL, 8(3), 2000.

[11] Z. Huang, F. van Harmelen, and A. ten Teije.

[12] U. Hustadt, B. Motik, and U. Sattler. Reducing
description logic to disjunctive datalog

Reasoning with inconsistent ontologies. In Proc. of
IJCAI’05, pages 454–459, 2005.
SHIQ−
programs. In Proc. of KR’04, pages 152–162, 2004.
[13] A. Kalyanpur, B. Parsia, E. Sirin, and B. C. Grau.

Repairing unsatisﬁable concepts in owl ontologies. In
Proc. of ESWC’06, pages 170–184, 2006.

[14] A. Kalyanpur, B. Parsia, E. Sirin, and J. Hendler.

Debugging unsatisﬁable classes in owl ontologies. J.
Web Sem., 3(4):268–293, 2005.

[15] R. M. Karp. Reducibility among combinatorial

problems. In Proc. of a Symposium on the Complexity
of Computer Computations, pages 85–103, 1972.

[16] S. C. Lam, J. Z. Pan, D. H. Sleeman, and W. W.
Vasconcelos. A ﬁne-grained approach to resolving
unsatisﬁable ontologies. In Proc. of WI’06, pages
428–434, 2006.

[17] D. Lembo and M. Ruzzi. Consistent query answering

over description logic ontologies. In Proc. of RR’07,
pages 194–208, 2007.

[18] N. Leone, G. Pfeifer, W. Faber, T. Eiter, G. Gottlob,

S. Perri, and F. Scarcello. The dlv system for
knowledge representation and reasoning. ACM Trans.
Comput. Log., 7(3):499–562, 2006.

[19] T. Meyer, K. Lee, and R. Booth. Knowledge

integration for description logics. In Proc. of AAAI’05,
pages 645–650, 2005.

[20] T. Meyer, K. Lee, R. Booth, and J. Z. Pan. Finding
maximally satisﬁable terminologies for the description
logic ALC. In Proc. of AAAI’06, pages 269–274, 2006.

[21] B. Motik. Reasoning in Description Logics using
Resolution and Deductive Databases. PhD thesis,
Univesit¨at karlsruhe, Germany, Jan. 2006.

[22] P. F. Patel-Schneider, P. Hayes, and I. Horrocks. OWL

Web Ontology Language Semantics and Abstract
Syntax. W3C Recommendation, 2004.
http://www.w3.org/TR/owl-semantics/.

[23] G. Qi, W. Liu, and D. A. Bell. Knowledge base

revision in description logics. In Proc. of JELIA’06,
pages 386–398, 2006.

[24] R. Reiter. A theory of diagnosis from ﬁrst principles.

Artif. Intell., 32(1):57–95, 1987.

[25] S. Schlobach. Debugging and semantic clariﬁcation by

pinpointing. In Proc. of ESWC’05, pages 226–240,
2005.

[26] S. Schlobach. Diagnosing terminologies. In Proc. of

AAAI’05, pages 670–675, 2005.

[27] S. Schlobach and R. Cornet. Non-standard reasoning

services for the debugging of description logic
terminologies. In Proc. of IJCAI’03, pages 355–362,
2003.

[28] H. M. Sheini and K. A. Sakallah. Pueblo: A hybrid
pseudo-boolean sat solver. JSAT, 2:157–181, 2006.
[29] E. Sirin, B. Parsia, B. C. Grau, A. Kalyanpur, and

Y. Katz. Pellet: A practical owl-dl reasoner. J. Web
Sem., 5(2):51–53, 2007.

[30] C. Welty and J. W. Murdock. Towards knowledge

acquisition from information extraction. In Proc. of
ISWC’06, pages 152–162, 2006.

574WWW 2008 / Refereed Track: Semantic / Data Web - Semantic Web IApril 21-25, 2008 · Beijing, China