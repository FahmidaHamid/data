FacetNet: A Framework for Analyzing Communities and

Their Evolutions in Dynamic Networks

Yu-Ru Lin1 Yun Chi2 Shenghuo Zhu2 Hari Sundaram1 Belle L. Tseng3
1Arts, Media and Engineering Program, Arizona State University, Tempe, AZ 85281, USA
2NEC Laboratories America, 10080 N. Wolfe Rd, SW3-350, Cupertino, CA 95014, USA

3YAHOO! Inc., 2821 Mission College Blvd, Santa Clara, CA 95054 USA

1{yu-ru.lin,hari.sundaram}@asu.edu, 2{ychi,zsh}@sv.nec-labs.com, 3belle@yahoo-inc.com

ABSTRACT
We discover communities from social network data, and an-
alyze the community evolution. These communities are in-
herent characteristics of human interaction in online social
networks, as well as paper citation networks. Also, commu-
nities may evolve over time, due to changes to individuals’
roles and social status in the network as well as changes
to individuals’ research interests. We present an innovative
algorithm that deviates from the traditional two-step ap-
proach to analyze community evolutions. In the traditional
approach, communities are ﬁrst detected for each time slice,
and then compared to determine correspondences. We ar-
gue that this approach is inappropriate in applications with
noisy data. In this paper, we propose FacetNet for analyzing
communities and their evolutions through a robust uniﬁed
process. In this novel framework, communities not only gen-
erate evolutions, they also are regularized by the temporal
smoothness of evolutions. As a result, this framework will
discover communities that jointly maximize the ﬁt to the ob-
served data and the temporal evolution. Our approach relies
on formulating the problem in terms of non-negative ma-
trix factorization, where communities and their evolutions
are factorized in a uniﬁed way. Then we develop an itera-
tive algorithm, with proven low time complexity, which is
guaranteed to converge to an optimal solution. We perform
extensive experimental studies, on both synthetic datasets
and real datasets, to demonstrate that our method discov-
ers meaningful communities and provides additional insights
not directly obtainable from traditional methods.

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications—
Data mining; H.3.3 [Information Storage and Retrieval]:
Information Search and Retrieval—Information ﬁltering; J.4
[Computer Applications]: Social and Behavioral Sciences—
Economics

General Terms
Algorithms, Experimentation, Measurement, Theory

Keywords
Community, Evolution, Soft Membership, Non-negative Ma-
trix Factorization, Community Net, Evolution Net

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

1.

INTRODUCTION

Data from many social network datasets, including pa-
per co-authorship networks and the blogosphere, is a graph
where nodes represent individuals (e.g., club members, au-
thors, and bloggers) and edges represent the relationship
and interactions among individuals (e.g., interactions in a
club, co-authorship, and hyperlinks in blogs).
In such so-
cial networks, individuals form communities by building re-
lationships and interactions with each other. The analysis
of these communities (membership, structure and temporal
dynamics) is an important research issue.

Traditional analysis of social networks treats the network
as as a static graph, where the static graph is either derived
from aggregation of data over all time or taken as a snapshot
of data at a particular time. These studies range from well-
established social network analysis [22] to recent successful
applications such as HITS and PageRank [7, 15]. However,
this research omits one important feature of communities in
networked data— the temporal evolution of communities.
By ignoring community evolution, prior works have over-
looked a key aspect of online communities.

More recently, there has been a growing body of work on
the analysis of communities and their temporal evolution
in dynamic networks [1, 8, 9, 10, 11, 16, 19, 21]. How-
ever, a common weakness in these studies, as we will dis-
cuss in detail in related work, is that communities and their
evolutions are studied separately—usually community struc-
tures are independently extracted at consecutive timesteps
and then in retrospect, evolutionary characteristics are in-
troduced to explain the diﬀerence between these commu-
nity structures over time. Such a two-stage approach may
make sense when the community structure is unambiguous
(e.g., when the community aﬃliation is available). How-
ever, more often than not, data from real-world networks
are ambiguous and subject to noise. Under such scenar-
ios, if an algorithm extracts community structure for each
timestep independently of other timesteps, it often results in
community structures with high temporal variation. Con-
sequently, undesirable evolutionary characteristics may have
to be introduced in order to explain the high variation in the
community structures. Therefore, we argue that a more ap-
propriate approach is to analyze communities and their evo-
lutions in a uniﬁed framework where the community struc-
ture provides evidence about community evolutions and at
the same time, the evolutionary history oﬀers hints on what
community structure is more appropriate. For example, a
community structure that introduces dramatic evolutions in
a very short period of time is less desirable.

685WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of CommunitiesAnother common problematic issue in current community
analysis techniques is that an individual is usually assigned
to only one community at a time. On the contrary, an indi-
vidual may be engaged in multiple communities at the same
time. For example, a blogger who is a dance guru may also
be an amateur photographer at the same time. Because of
this, an individual who usually participates in multiple com-
munities should be assigned to multiple communities at the
same time. Therefore, instead of a hard community parti-
tion, we argue that a soft community membership is more
informative, as it provides more details about how an indi-
vidual participates in each of the communities.

In this paper, we propose a systematic framework for an-
alyzing communities and their evolutions in dynamic net-
works, and we term our framework FacetNet 1. Our main
contributions are threefold:

1. We introduce the FacetNet framework to analyze com-
munities and their evolutions in a uniﬁed process. In
our framework, the community structure at a given
timestep t is determined both by the networked data
at t and by the historic community evolution patterns.
As a result, the discovered communities and their evo-
lutions are more robust to noise and more reasonable
(e.g., dramatic change in a short time is unlikely).

2. We extend the soft clustering algorithm by Yu et al. [24]
from static graphs to dynamic networks. In contrast
to a hard community partition, in our framework an
individual can participate in multiple communities at
the same time and with diﬀerent participation levels.
Similarly, an observed relationship is generated due to
a combined eﬀect from various communities. Based
on the soft community membership, we further de-
ﬁne two novel concepts—Community Net and Evolu-
tion Net—to represent community structures and their
evolutions, respectively.

3. We provide an iterative algorithm that is guaranteed
to converge to (local) optimal solutions to the pro-
posed formulation. We prove the correctness and con-
vergence of our algorithm and show that this algorithm
has low time complexity. We also provide principled
solutions to some practical issues, such as how to de-
termine the number of communities and how to handle
adding and removing of individuals in a dynamic net-
work.

We use synthetic and real datasets (including a blog dataset
and a paper co-authorship dataset) to demonstrate that
compared to traditional methods, our framework provides
more reasonable results on communities and their evolu-
tions. We also show that our framework is able to discover
interesting insights in dynamic networks that are not di-
rectly obtainable from existing methods.

The rest of the paper is organized at follows. First, we
discuss related work.
In Section 2, we describe our basic
framework in detail. In Section 3, we introduce extensions of
our framework to handle some practical issues. In Section 4,
we provide experimental studies. Finally in Section 5, we
give the conclusion.

1FacetNet
Communities and EvoluTions in dynamic NETworks”.

for “a Framework for Analyzing

stands

Related Work
Community formation has been extensively studied in var-
ious research areas such as social network analysis, Web
community analysis, computer vision, etc.
In social net-
work analysis, an important research topic is to identify
cohesive subgroups of individuals within a network where
cohesive subgroups are deﬁned as “subsets of actors among
whom there are relatively strong, direct, intense, frequent,
or positive ties” ([22]). Many approaches, such as clique-
based, degree-based, and matrix-perturbation-based, have
been proposed to extract cohesive subgroups from social net-
work [22]. Communities also play an important role in Web
analysis. For example, Flake et al. [6] deﬁned Web commu-
nities as “a set of sites that have more links to members of
the community than to non-members”, and proposed algo-
rithms to identify Web communities based on a maximum
ﬂow/minmum cut framework. Newman et al. [13] deﬁned a
metric called modularity measure to quantify the strength
of community structure which we will discuss in detail in a
later section. In computer vision, community extraction is
closely related to image segmentation problem. One eﬀective
method in this area is the spectral clustering algorithm [4,
5, 18, 25] where the eigenvectors of certain normalized sim-
ilarity matrices are used for the clustering purpose. Later,
White et al. [23] pointed out the close relationship between
Newman’s modularity and the spectral clustering and pro-
posed several algorithms to combine the two approaches. Yu
et al. [24] proposed a novel clustering framework on graphs
where the cluster memberships are assigned in a probabilis-
tic way. In Yu’s framework, cluster memberships can be ex-
tracted in diﬀerent resolutions, representing local or global
cluster structures. A common issue in all the above studies
is that they only analyzed static networks where no tem-
poral analysis is used for evolution study. Another issue in
these studies is that they treat community extraction as a
graph partition problem and therefore always result in hard
community memberships, which disallows an individual to
participate multiple communities at the same time.

Recently, there exists a growing body of literature on an-
alyzing communities and their evolutions in dynamic net-
works. Kumar et al. [8] studied the evolution of the blogo-
sphere as a graph in terms of the change of characteristics,
(such as in-degree, out-degree, strongly connected compo-
nents), the change of communities, as well as the burstiness
in blog community. Leskovec et al. [10] studied the patterns
of growth for graphs in various ﬁelds and proposed genera-
tors that produce graphs exhibiting the discovered patterns.
Palla et al [16] analyzed a co-authorship network and a
mobile phone network, where both networks are dynamic,
by using the clique percolation method (CPM). Toyoda et
al. [21] studied the evolution of Web communities from a se-
ries of Web achieves by deﬁning diﬀerent types of community
changes, such as emerge, dissolve, grow, and shrink, as well
as a set of metrics to quantify such changes for community
evolution analysis. Spiliopoulou et al. [19] proposed a frame-
work, MONIC, to model and monitor cluster transitions over
time. They deﬁned a set of external transitions such as sur-
vive, split, disappear, to model transactions among diﬀerent
clusters and a set of internal transitions, such as size and
location transitions to model changes within a community.
Asur et al. [1] introduced a family of events on both com-
munities and individuals to characterize evolution of com-
munities. They also deﬁned a set of metrics to measure the

686WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of Communitiesstability, sociability, inﬂuence and popularity for communi-
ties and individuals. Sun et al. [20] proposed a parameter-
free algorithm, GraphScope, to mine time-evolving graphs
where the Minimum Description Length (MDL) principle is
employed to extract communities and to detect community
changes. Mei et al. [12] extracted latent themes from text
and used the evolution graph of themes for temporal text
mining. All these studies, however, have a common weak
point—community extraction and community evolution are
analyzed in two separated stages. That is, when commu-
nities are extracted at a given timestep, historic commu-
nity structure, which contains valuable information related
to current community structure, is not taken into account.
There are some recent studies on evolutionary embedding
and clustering that are closely related to our work. In [17],
Sarkar et al. proposed a dynamic method that embeds nodes
into latent spaces where the locations of the nodes at con-
secutive timesteps are regularized so that dramatic change is
unlikely. In [2], Chakrabarti et al. proposed the ﬁrst evolu-
tionary clustering methods where the cluster membership at
time t is inﬂuenced by the clusters at time t-1. Chi et al. [3]
extended similar ideas and proposed the ﬁrst evolutionary
spectral clustering algorithms. They used graph cut as a
metric for measuring community structures and community
evolutions. All these studies diﬀer from our work in that
they regularize the current community membership at time
t by using historic community membership indirectly.
In
Chakrabarti et al.’s evolutionary hierarchical clustering al-
gorithm, historic community structure aﬀects the tree-node
merging step in the current time. In their evolutionary k-
means clustering algorithm, historic centroids aﬀect the k-
mean process at the current time. In Chi et al.’s algorithms,
certain eigenvectors, instead of the community structure,
are regularized over time. In the work of Sarkar et al., al-
though the relationship among nodes in latent spaces is pre-
served over time, the issue of communities are not directly
addressed. In contrast, in our proposed framework, the com-
munity membership itself is directly regularized over time.

2. FORMULATION

2.1 Notation

First, a note on notations. In this paper, we use lower-case
letters, e.g., x, to represent scalars, vector-formed letters,
e.g., ~v, to represent vectors, and upper-case letters, e.g., W ,
to represent matrices. Both wij and (W )ij represent the
element at the i-th row and j-th column of W . We use
vec (W ) to denote the vectorization of W , i.e., stacking the
columns of W into a column vector. A subscript t on a
variable, e.g., Wt or wt;ij, denotes the value of that variable
at time t. However, to avoid notation clutter, we try not to
use the subscript t unless it is needed for clarity.

We assume that edges in the networked data are asso-
ciated with discrete timesteps. We use a snapshot graph
Gt(Vt, Et) to model interactions at time t where in Gt, each
node vi ∈ Vt represents an individual and each edge eij ∈ Et
denotes the presence of interactions between vi and vj . As-
suming Gt has n nodes, we use a matrix W ∈ Rn×n
(which
is short for Wt) to represent the similarity between nodes in
Gt, where wij > 0 if eij ∈ Et and otherwise wij = 0. With-

+

out loss of generality, we assume that Pi,j wij = 1. Over

time, the interaction history is captured by a sequence of
snapshot graphs hG1, · · · , Gt, · · · i indexed by time.

2.2 Basic Formulation

As mentioned in the introduction, we want to analyze
communities and their evolutions in a uniﬁed process. That
is, at time t, we prefer a community structure so that the
community evolution from t-1 to t is not unreasonably dra-
matic. To achieve this goal, we propose to use the commu-
nity structure at time t-1 (already extracted) to regularize
the community structure at current time t (to be extracted).
To incorporate such a regulation, we introduce a cost func-
tion to measure the quality of community structure at time
t, where the cost consists of two parts—a snapshot cost and
a temporal cost:

cost = α · CS + (1 − α) · CT

(1)

This cost function is ﬁrst proposed by Chakrabarti et al. [2]
in the context of evolutionary clustering. In this cost func-
tion, the snapshot cost CS measures how well a community
structure ﬁts W , the observed interactions at time t. The
temporal cost CT measures how consistent the community
structure is with respect to historic community structure (at
time t-1 ). The parameter α is set by the user to control the
level of emphasis on each part of the total cost.

2.2.1 Snapshot Cost

A community structure at time t should ﬁt W well, where
W is the observed interaction (similarity) matrix at time t.
This requirement is reﬂected in the snapshot cost CS in the
cost function Eq. (1). We ﬁrst describe how we model the
community structure and how we deﬁne the snapshot cost.
Assume there exist m communities at time t. We further
assume that the interaction (similarity) wij is a combined
eﬀect due to all the m communities. That is, we approximate
k=1 pk ·pk→i·pk→j, where
pk is the prior probability that the interaction wij is due to
the k-th community, pk→i and pk→j are the probabilities
that an interaction in community k involves node vi and vj,
respectively. Written in a matrix form, we have W ≈ XΛX T
where X ∈ Rn×m
is a non-negative matrix with xik = pk→i

wij using a mixture model wij ≈Pm

+

and Pi xik = 1. In addition, Λ is an m × m non-negative

diagonal matrix with λk = pk, where λk is short for λkk.
Matrices X and Λ (or equivalently, their product XΛ) fully
characterize the community structure in the mixture model.
This model was ﬁrst proposed by Yu et al. in [24].

v2

v1

v2

v1

v2

v1

v3

v6

v3

c1

c2

v4

v5

v4

v5

(a)

(b)

v6

v6

v3

x31
x32
x41

v4
w34 ≈ λ1x31x41
+λ2x32x42

c1

λ1

λ2

c2
x42

v5

(c)

Figure 1: Schematic illustration of soft communities:
(a) the original graph, (b) the bipartite graph with
two communities, and (c) how to approximate an
edge (w34)

In Fig. 1, we use a toy example with 6 nodes and 2 com-
munities to illustrate this model of community structure.
For a general graph (a), we use a special bipartite graph (b)
to approximate (a). Note that (b) has two more nodes, i.e.,
c1 and c2, corresponding to the two communities. However,

687WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of Communitiesbecause (b) is a bipartite graph (i.e., an edge can only occur
between a node v and a community c), it has less degree of
freedom and so it is a more parsimonious explanation of (a).
In (c), we show how an edge w34 is generated in the mixture
model as the sum of λ1x31x41 and λ2x32x42. Equivalently,
we are approximating W , which has rank n, by a product in
the form of XΛX T , which has rank m. Based on this model,
we deﬁne the snapshot cost CS as the error introduced by
such an approximation, i.e.,

CS = D(W kXΛX T )

where D(AkB) = Pi,j(aij log aij

− aij + bij) is the KL-
divergence between A and B. So the snapshot cost is high
when the approximate community structure XΛX T fails to
ﬁt the observed data W well.

bij

2.2.2 Temporal Cost

In the cost function Eq. (1), the temporal cost CT is used
to regularize the community structure so that it is less prob-
able for unreasonably dramatic community evolution from
time t-1 to t. We propose to achieve this regularization
by deﬁning CT as the diﬀerence between the community
structure at time t and that at time t-1. Recall that the
community structure is captured by XΛ. Therefore, with
Y

.
= Xt−1Λt−1, the temporal cost is deﬁned as

CT = D(Y kXΛ)

where D is the KL-divergence as deﬁned before. So the
temporal cost CT is high when there is a dramatic change
of community structure from time t-1 to t.

2.2.3 Putting It Together

Putting the snapshot cost CS and the temporal cost CT
together, we have an optimization problem as to ﬁnd the
best community structure at time t, expressed by X and Λ,
that minimizes the following total cost

cost = α · D(W kXΛX T ) + (1 − α) · D(Y kXΛ)

(2)

subject to X ∈ Rn×m
m non-negative diagonal matrix. Solving this optimization
problem is the core of our FacetNet framework.

, Pi xik = 1, and Λ being an m-by-

+

2.3 Justiﬁcation

We now provide two interpretations to the cost function
Eq. (2), one from the point of view of information theory
and the other from that of probabilistic generative model.

2.3.1 An Information Theory Interpretation

In information theory, the KL-divergence D(P kQ) is also
known as the relative entropy, and it represents the informa-
tion gain if we use the precise distribution P instead of the
approximate model Q (where Q tries to model P ). In our
community structure, XΛX T is the marginal distribution
induced from the bipartite model and it tries to approx-
imate W . As a result, D(W kXΛX T ) gives us the infor-
mation gain (or the error introduced) from our community
structure XΛX T to the true distribution W . A higher in-
formation gain suggests a larger error introduced by XΛX T
and therefore implies a higher snapshot cost CS.

Similarly, in D(Y kXΛ), Y represents the community struc-
ture at time t-1. When we try to use the current community
structure XΛ to explain Y , if the information gain from XΛ
to Y is larger, then the change of community structure from

time t-1 to t will be more dramatic, and therefore the tem-
poral cost CT will be higher.

2.3.2 A Probabilistic Interpretation

Next we provide a probabilistic interpretation of our frame-
work by using a ﬁrst-order Markov generative model. The
basic ideas are that (1) the currently observed data Wt is
generated from the current community structure following
a certain distribution and (2) the current community struc-
ture at time t is generated by using the community structure
at time t-1 as the prior distribution.

Let Ut be the community parameters at time t and Ut−1
be those at time t-1. The goal is then to estimate the unseen
parameters Ut, given Wt and Ut−1, i.e.,

U ∗ = arg max

log P (Wt, Ut|Ut−1)

Ut

We further assume a ﬁrst-order Markov model, as illustrated
in Fig. 2, and we have P (Wt, Ut|Ut−1) = P (Wt|Ut)P (Ut|Ut−1).
Therefore the log-likelihood function can be written as

L(Ut) = log P (Wt|Ut) + log P (Ut|Ut−1)

(3)

U0

W0

Dirichlet

Ut−1

Ut

multinomial

Wt−1

Wt

Figure 2: Schematic illustration of the probabilistic
model, where U = (X, Λ)

In our model, Ut−1 = (Xt−1, Λt−1) and Ut = (Xt, Λt).
Under the above probabilistic model, we have the following
theorem, whose proof is given in the Appendix.

Theorem 1. Under the assumptions that

(1) vec (Wt) follows a multinomial distribution with param-

eter θt, where θt = vec(cid:0)XtΛtX T

t (cid:1), and

(2) vec (XtΛt) follows a Dirichlet distribution with param-
eter φt, where φt = νvec (Xt−1Λt−1) + 1 and ν = (1 −
α)/α;

the parameter estimation of Xt and Λt by maximum a pos-
terior (MAP) in Eq. (3) is equivalent to that by minimizing
the cost function in Eq. (2).

2.4 Solution

In this subsection, we ﬁrst provide an iterative algorithm
to solve the optimization problem deﬁned by Eq. (2) and
then show the time complexity of our algorithm.

2.4.1 An Iterative Algorithm

In our algorithm, we use the following update rules and
as stated in the following theorem, in each iteration, the
algorithm updates the values of X and Λ in such a way
that the cost function deﬁned in Eq. (2) is monotonically
decreased.

688WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of CommunitiesTheorem 2. The following update rules will monotoni-
cally decrease the cost function deﬁned in Eq. (2) and there-
fore converge to an optimal solution to the objective function:

+ (1 − α) · yik

(4)

xik = 1, ∀k

yik

(5)

+ (1 − α) ·Xi

λk = 1.

wij · λk · xjk
(XΛX T )ij

xik ← xik · 2α ·Xj
then normalize such that Xi
λk ← λk · α ·Xij
then normalize such that Xk

wij · xik · xjk

(XΛX T )ij

The proof for the correctness and the convergence of the
above update rules is skipped due to space limit.

2.4.2 Time Complexity

We now show the time complexity for each iteration of
the updates in Theorem 2. The most time-consuming part
is to compute (XΛX T )ij for all i, j ∈ {1, . . . , n}. However,
it turns out that we do not have to compute (XΛX T )ij for
each pair of (i, j), thanks to the sparseness of W . In W , the
number of non-zero elements is the number of edges in the
snapshot graph, which we denote by ℓ. Then for each non-
zero wij , we compute the corresponding (XΛX T )ij, which
takes O(m) time with m being the number of communities.
As a result, the total complexity is O(ℓm). If we consider
m, the number of communities, to be a constant and if the
degree of nodes in the snapshot graph is bounded by another
constant, then the complexity is reduced to O(n), i.e., linear
in the number of nodes in the snapshot graph.

2.5 Communities and Their Evolutions

After obtaining the solution to Eq. (2) by using our algo-
rithm in Theorem 2, here are the ways we utilize the solution
to analyze communities and their evolutions.

2.5.1 Community Membership

i.e.,
Assume we have computed the result at time t-1,
(Xt−1, Λt−1), and the result at time t, i.e., (Xt, Λt).
In
addition, we deﬁne a diagonal matrix Dt, whose diagonal

elements are the row sums of XtΛt, i.e., dt;ii =Pj (XtΛt)ij .

Then we claim that the i-th row of D−1
t XtΛt indicates the
soft community memberships of vi at time t. We illustrate
this by using an example shown in Fig. 3. Recall that in the
bipartite graph at time t (the right side of Fig. 3(a)), the
weights of edges connecting vi to c1, c2, and c3 represent
the joint probability P (vi, c1), P (vi, c2), and P (vi, c3). The
D−1
part normalizes this joint probability to get P (c1|vi),
P (c2|vi), and P (c3|vi), i.e., the conditional probability that
vi belongs to c1, c2, and c3, respectively. And this condi-
tional probability is exactly the soft community membership
we are looking for. Furthermore, we can see that the i-th
diagonal element of Dt provides information about the level
of activity of vi at time t.

t

2.5.2 Community Net

t D−1

The community structure itself, on the other hand, is ex-
pressed by ΛtX T
t XtΛt. For this we again look at the
bipartite graph at time t (the right side of Fig. 3(a)). In-
duced from this bipartite graph, XtΛX T
t gives a marginal
distribution on the subgraph with nodes {v1, . . . , v6} in or-
der to approximate Wt. In a dual fashion, also induced from

c1

c2

v1

v2

v3

v4

v5

v6

c1

c3

c2

t−1

t

(a)

c1

c2

c3

t

(b)

c1

c2

t−1

c1

c3

c2

t

(c)

Figure 3: Schematic illustration of communities and
their evolutions: (a) two bipartite graphs at time t-1
and time t (merged by vi’s), (b) the Community Net
at time t induced by the bipartite graph at time t,
and (c) the Evolution Net from t-1 to t induced by
the two bipartite graphs

t D−1

this bipartite graph, ΛtX T
t XtΛt gives a marginal distri-
bution on the subgraph with nodes {c1, c2, c3} (Fig. 3(b))
and this is exactly the community structure we are looking
for. We call this induced subgraph on the community nodes
(i.e.,{c1, c2, c3}) a Community Net. Note that to induce the
community net, each node vi participates in all the commu-
nities, with diﬀerent levels. This is more reasonable than
traditional methods in which each node can only contribute
to a single community.

2.5.3 Evolution Net

To derive the community evolutions, we align the two bi-
partite graphs, that at time t-1 and that at time t, side by
side by merging the corresponding network nodes vi’s, as
illustrated in Fig. 3(a). Then a natural deﬁnition of com-
munity evolution (from ct−1;i at time t-1 to ct;j at time t) is
the probability of starting from ct−1;i, walking through the
merged bipartite graphs, and reaching ct;j. Such a walking
process produces what we call the Evolution Net to represent
community evolutions, as illustrated in Fig. 3(c). A simple
derivation shows that P (ct−1;i, ct;j) = (Λt−1X T
t XtΛt)ij
and P (ct;j|ct−1;i) = (X T
t XtΛt)ij . Again, each node
and each edge contribute to the evolution from ct−1;i to ct;j.
That is, all individuals and all interactions are related to all
the community evolutions, with diﬀerent levels. We believe
this is more reasonable than how community evolutions are
derived in traditional methods. In tradition methods, usu-
ally the intersection and union of community members at
diﬀerent time are used alone to compute community evolu-
tions, with a questionable assumption that all members in
a community should be treated with identical importance.

t−1D−1

t−1D−1

3. EXTENSIONS

In this section we introduce two extensions to our basic
framework in order to handle inserting and removing of in-
dividuals and to determine the number of communities in a
dynamic network over time.

3.1 Inserting and Removing Nodes

In real applications, it occurs very often that some new
individuals join a dynamic network (e.g., a new author in a

689WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of Communitiespaper co-authorship network) and existing ones leave (e.g.,
a blogger who stops blogging). We provide the following
heuristic techniques in our algorithm to handle such insert-
ing and removing of nodes.

Assume that at time t, out of the n nodes in the net-
work, n1 existing nodes are removed from and n2 new nodes
are inserted into the network. We ﬁrst handle the n1 re-
moved nodes by removing the corresponding n1 rows from
Y in Equations (4) and (5) to get Y ′. Next, we scale Y ′ to
get Y ′′ so that Y ′′ is a valid joint distribution, i.e., Y ′′ =
ij . The basic idea behind this heuristic is that we
assume the n1 nodes are randomly selected, independent of
their community membership. Under such an assumption,
Y ′′ is a conditional distribution, conditioning on the remain-
ing n − n1 nodes in the network. To add the n2 nodes, we
pad n2 rows of zeros to Y ′′ to get ˆY . This heuristic is actu-
ally equivalent to assuming that these n2 nodes have already
existed at time t-1 but as isolated nodes.

Y ′/Pij y′

3.2 Changing Community Numbers

So far we have assumed that the number of communi-
ties, m, is given beforehand by the user. However, such an
assumption will limit the scope of application of our frame-
work.
In this subsection we try to answer two questions:
how to automatically determine the number of communities
at a given time t and how to revise our framework to allow
the number of communities to change in diﬀerent timesteps.

3.2.1 Soft Modularity
In [13], Newman et al.

introduces an elegant concept,
the modularity Q, to measure the goodness of a community
partition Pm where Q is deﬁned as

Q(Pm) =

m

Xk=1" A(Vk, Vk)

A(V, V )

−(cid:18) A(Vk, V )

A(V, V ) (cid:19)2#

3.2.2 Extended Formulas

If we allow diﬀerent community numbers at time t and t-1,
then we have to revise Eq. (2) accordingly because in Eq. (2),
the term D(Y kXΛ) requires Y (the community structure at
t-1 ) and XΛ (the community structure at t) to have the
same number of columns and therefore the same number
.
of communities. To solve this issue, we ﬁrst deﬁne Z
=
Xt−1Λt−1X T

t−1 and then revise the cost function to be

cost = α · D(W kXΛX T ) + (1 − α) · D(ZkXΛX T )

(8)

The basic idea is that when the community numbers are dif-
ferent at time t and t-1, instead of regularizing the commu-
nity structure itself, we regularize the marginal distribution
induced by the community structure at time t (i.e., XΛX T ,
which approximates Wt) so that it is not too far away from
that at time t-1 (Xt−1Λt−1X T
t−1). For the cost function
given in Eq. (8), the following update rules are used.

Theorem 4. The following update rules will monotoni-
cally decrease the cost function deﬁned in Eq. (8) and there-
fore converge to an optimal solution to the objective function.

(α · wij + (1 − α) · zij) · λk · xjk

(XΛX T )ij

xik = 1, ∀k

xik ← xik ·Xj
then normalize such that Xi
λk ← λk ·Xij
then normalize such that Xk

(XΛX T )ij

λk = 1.

(α · wij + (1 − α) · zij) · xik · xjk

(9)

(10)

(6)

The proof for the correctness and the convergence of the
above update rules is skipped due to space limit.

with A(Vp, Vq) =Pi∈Vp,j∈Vq

wij . Basically, Q measures the
deviation between the chance for edges among communities
to be generated due to the community structure and the
chance for the edges to be generated randomly. Extensive
experimental results [13, 23] have demonstrated that Q is an
eﬀective measure for the community quality, where a maxi-
mal Q is a good indicator of the best community structure
and therefore the best community number m.

Here we extend the concept of modularity to handle soft

membership by deﬁning a Soft Modularity Qs:

Qs =T rh(D−1XΛ)T W (D−1XΛ)i

− ~1T W T (D−1XΛ)(D−1XΛ)T W~1

(7)

where ~1 is a vector whose elements are all ones. Qs has
the following nice property, whose proof is given in the Ap-
pendix.

Theorem 3. The Qs deﬁned in Eq. (7) has the same
probabilistic interpretation as the Q deﬁned in Eq. (6), but
in the context of soft community membership. In addition,
Qs is a generalized modularity in that Qs is identical to Q
when D−1XΛ becomes a hard community membership (i.e.,
each row of D−1XΛ has one 1 and m-1 zeros).

So to detect the best community number m at time t, we
run our algorithm for a range of candidates for m and pick
the best one determined by Qs.

4. EXPERIMENTAL STUDIES

In this section, we use several synthetic datasets, a blog
dataset, and a paper co-authorship dataset to study the per-
formance of our FacetNet framework.

4.1 Synthetic Datasets

4.1.1 Synthetic Dataset # 1

We start with the ﬁrst synthetic dataset, which is a static
network, to illustrate some good properties of our frame-
work. This dataset was ﬁrst studied by White et al. [23] and
is shown in Fig. 4(a). The network contains 15 nodes which
roughly form 3 communities—C1, C2, and C3— where edges
tend to occur between nodes in the same community. We
ﬁrst check our soft modularity measure. We apply our al-
gorithm to the network with various community numbers m
and the resulting Qs values are plotted in Fig. 4(b). In addi-
tion, in Fig. 4(b) we also show the modularity values Q that
are reported by White et al.
in [23]. As can be seen from
the plot, both Qs and Q show distinct peaks when m = 3,
which corresponds to the correct community number.

Next, after our algorithm correctly partitions the 15 nodes
into three communities, we illustrate the soft community
membership by studying two communities among the three—
C1 = {6, 7, 8, 9, 10} and C2 = {11, 12, 13, 14, 15}. In Fig. 4(a),
we use the same circle shape to represent these 10 nodes
but use diﬀerent gray levels to indicate their community

690WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of CommunitiesC2

12

14

13

11

15

1

3

5

2

4

C3

10

9

6

8

7

C1

(a)

0.5

0.4

0.3

0.2

0.1

0
1

Modularity Q
Soft Modularity Qs

2

3

4

5

Community Number

6

(b)

Figure 4: (a) The synthetic dataset (b) Modular-
ity and soft modularity under diﬀerent community
numbers

membership—we use white color to illustrate the level that
a node belongs to C1 and dark color to show the level that
a node belongs to C2. As can be seen, while node 7, node
14, and node 15 have very clear community memberships,
node 10 and node 13, who are on the boundary between C1
and C2, have rather fuzzy membership. That is, our algo-
rithm is capable of assigning meaningful soft membership
to a node to indicate to which level the node belongs to a
certain community.

4.1.2 Synthetic Dataset # 2

The second dataset is generated according to the descrip-
tion by Newman et al.
in [13]. This dataset contains 128
nodes, which are divided 4 communities of 32 nodes each.
We generate data for 10 consecutive timesteps.
In each
timestep from 2 to 10, dynamics are introduced in the fol-
lowing way:
from each community we randomly select 3
members to leave their original community and to join ran-
domly the other three communities. Edges are added ran-
domly with a higher probability pin for within-community
edges and a lower probability pout for between-community
edges. However, the average degree for the nodes is set to 16.
As a result, a single parameter z, which represents the mean
number of edges from a node to nodes in other communities,
is enough to describe the data.

Because we have the ground truth for the community
membership at each timestep, we directly study the accu-
racy of the community structure obtained by our framework.
We compare our FacetNet framework with 3 baseline algo-
rithms. The ﬁrst baseline, which we call EvolSpec, is the
evolutionary spectral clustering algorithm proposed by Chi
et al. [3]. Because EvolSpec is an evolutionary version of the
Normalized Cut (NCut) algorithm by Shi et al. [18], we take
NCut as our second baseline. Similarly, FacetNet is essen-
tially an evolutionary version of the soft clustering method
(SNMF ) by Yu et al. [24], we take SNMF as our third base-
line. Notice that FacetNet and EvolSpec are evolutionary
algorithms whereas NCut and SNMF are not—NCut and
SNMF work on each snapshot graph independently of other
snapshot graphs. In addition, to make the results compara-
ble, for FacetNet and SNMF we convert the soft membership
into 0/1 indicators by assigning each node to the commu-
nity it most likely belongs to. Furthermore, in all the ex-
periments, for FacetNet and EvolSpec we set α to be 0.9.
Fig. 5(a) and 5(b) show the accuracy and standard error of
the community membership obtained by the four algorithms
for two datasets generated with z = 3 and z = 5, respec-
tively. The accuracy is computed by the mutual information
between the derived community membership and the ground

n
o
i
t
a
m
r
o
f
n
I
 
l
a
u
t
u
M

1.4

1.38

1.36

1.34

1.32

1.3

1.28

(a) z = 3

(b) z = 5

EvolSpec
FacetNet
NCut
SNMF

EvolSpec
FacetNet
NCut
SNMF

0.25

0.2

0.15

n
o
i
t
a
m
r
o
f
n
I
 
l
a
u
t
u
M

2

6

4
Timestep

8

10

0.1

2

6

4
Timestep

8

10

Figure 5: Mutual information with respect to the
ground truth over 10 timesteps when (a) z = 3 and
(b) z = 5

truth, where a higher mutual information indicates better
accuracy. From the ﬁgures we can see that when z = 3, i.e.,
when there is less noise and hence the community structure
is easy to detect, both FacetNet and EvolSpec have accuracy
improved starting from the second timestep, which suggests
that an evolution framework is beneﬁcial in this dynamic
network. In comparison, NCut and SNMF have relatively
ﬂat accuracy over all timesteps, with NCut slightly outper-
forms SNMF. For the data where z = 5, there are more
edges going between communities and therefore the commu-
nity structure is more diﬃcult to detect. From Fig. 5(b)
we can see that although at the ﬁrst few timesteps FacetNet
does not perform as good as EvolSpec, as time going further,
FacetNet starts to outperform EvolSpec. This suggests that
the beneﬁts of FacetNet accumulates over time more than
EvolSpec.
In addition, as for the case with z = 3, when
z = 5, both FacetNet and EvolSpec clearly outperform their
non-evolutionary version, NCut and SNMF.

(a) Time per Iteration (sec)

(b) Iteration Numbers

0.2

0.15

0.1

0.05

0

0

2000
Size of Network

4000

6000

800

600

400

200

0

0

2000
Size of Network

4000

6000

Figure 6: Running time for networks of diﬀerent
sizes (a) time per iteration (sec) and (b) number of
iterations until converge

Next, we study the time performance of FacetNet. We
repeat the above experiment over a family of networks of
various sizes (node numbers). In Fig. 6(a) we show the aver-
age running time per iteration of our algorithm on networks
with diﬀerent sizes. In 6(b) we showed the number of itera-
tion needed for convergence when the convergence criterion
is that the change between two consecutive iterations is be-
low a threshold of 1e-5. As can be seen, ﬁrst, the running
time per iteration scales linearly with the size of network,
which validates our theoretical analysis in Section 2; second,
the number of iteration needed for convergence is insensitive
to the network size, which implies that the overall running
time of our algorithm scales linearly to the size of network.

691WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of Communities4.2 NEC Blog Dataset

The blog data was collected by an NEC in-house blog
crawler. Given seeds of manually picked highly ranked blogs,
the crawler discovered blogs that are densely connected with
the seeds, resulting in an expanded set of blogs that com-
municate with each other. The crawler then continued mon-
itoring for new entries over a long time period. This NEC
blog data set contains 148,681 entry-to-entry links among
407 blogs crawled during 12 consecutive month (a timestep
is one month), between August 2005 and September 2006.

Following [14], we deﬁne W by wij = ˜wij /Pp,q ˜wpq where

˜wii = 1, ˜wij = exp(−1/(γ · lij)) if eij ∈ Et, and otherwise
˜wij = 0. In the formula, lij is the edge weight (e.g., # of
links) of eij and γ, which is set to 0.2, is a parameter to
control marginal eﬀect when lij is increased.

(a) Soft Modularity Qs

(b) Mutual Information

0.23

0.225

0.22

0.215

0.21

2

4

6

8

Community Number

1

0.8

0.6

0.4

0.2

0

α = 0.1
α = 0.5
α = 0.9

2

4

6

8

10

12

Timestep

Figure 7: (a) Soft modularity and (b) mutual infor-
mation under diﬀerent α for the NEC dataset

We start with analyzing the overall picture of the dataset.
We ﬁrst aggregate all the edges over all timesteps into a sin-
gle network and apply our algorithm to compute the soft
modularity score Qs under diﬀerent community numbers.
As can be seen in Fig. 7(a), a clear peak shows when the
community number is 4. We draw the aggregated graph in
Fig. 8, according to the main community each blog most
likely belongs to. In addition, in Table 1 we list the top key-
words, measured by the tf-idf score, that occur in the posts
of these four communities. It seems that C1 focuses on tech-
nology, C2 on politics, C3 on international entertainment,
and C4 on digital libraries.

C1

@@R

  

C2

C3

  	

@@I

C4

Figure 8: Four communities in the NEC dataset

Next, we analyze the blog data as a dynamic network. Af-
ter studying the content of the blogs, we ﬁnd that the above

Table 1: Top keywords among the four communities
in the NEC dataset, sorted by the tf-idf score

C1

C2

C3

C4

iraqi, roberts, bush, clinton,

adsense, beta, skype, ﬁrefox, msn, rss, aol, yahoo, google, ebay, desk-
top, wordpress, voip, feeds, myspace, podcasting, technorati, search,
engine, browser, ads, gmail, windows, os, developer, venture, market-
ing, apple, podcasts, developers, engines, mac, publishers, ceo, linux
gop, uranium, hezbollah, democrats, rove, cia, republicans, saddam,
qaeda, tax, republican,
iraq, senate,
troops, terrorists, administration, terrorist, wilson, conservative, taxes,
liberal, intelligence, israel, terror, iran, weapons, war, soldiers
shanghai, robots, installation, japan, japanese, architecture, art, chi-
nese, china, saudi, phones, ﬁled, mobile, games, korea, rﬁd, sex, green,
camera, sound, cell, body, africa, phone, entertainment, ﬁlm, gay, in-
dia, fuel, archive, design, elections, ﬂash, device, water, wireless, south
library, learning, digital, resources, collection, conference, staﬀ, com-
munities, students, session, books, database, access, survey, university,
science, canada, myspace, articles, education, technologies, knowledge,
ﬁled, virtual, tools, research, david, learn, services, ﬂickr, computers

four communities stay rather stable over all the timesteps.
This eﬀect is partially due to the way these blogs are selected
by our focused crawler—our crawler chose to crawl a densely
connected subgraph of the blogosphere where each node in
the subgraph has large number of links and high level of in-
teraction intensities. Therefore, most of the selected blogs
belong to some well-known bloggers and they seldom move
around between communities. We apply our FacetNet algo-
rithm on the data with diﬀerent α. And we compute the
mutual information between the extracted communities at
each timestep and the four communities shown in Fig. 8.
Fig. 7(b) shows the results under α=0.1, 0.5, and 0.9. As
can be seen, as α increases, our algorithm emphasizes less
on the temporal smoothness and as a result, the community
structure has higher variation over time. In addition, as α
increases, the communities at each timestep deviate further
from the communities obtained from the aggregated data.
These results on one hand justify our arguments in the in-
troduction section and on the other hand demonstrate that
our FacetNet framework is capable of controlling the trade-
oﬀ between the snapshot cost and the temporal cost in the
cost function Eq. (1).

Aug 05

c3

c1

c4

c2

Aug 05

c3

c1

c4

c2

0.34 

0.42 

0.45 

0.42 

0.69 

0.88 

0.57 

0.36 

0.71 

0.24 

0.59 

0.87 

Sep 05

c3

c1

c4

c2

0.59 

0.31 

0.69 

0.24 

0.53 

0.75 

Oct 05

c3

c1

c4

c2

0.45 

0.38 

0.76 

0.41 

0.25 

0.87 

Nov 05

c3

c1

c4

c2

0.34 

0.51 

0.76 

0.48  0.43 

0.22 

0.67 

Dec 05

c3

c1

c4

c2

Sep 05

c3

c1

c4

c2

0.59 

0.32 

0.71 

0.41 

0.42 

0.87 

Oct 05

c3

c1

c4

c2

0.59 

0.34 

0.20 

0.71 

0.40 

0.38 

0.86 

Nov 05

c3

c1

c4

c2

0.58 

0.33 

0.20 

0.72 

0.27 

0.61 

0.79 

Dec 05

c3

c1

c4

c2

0.49 

0.39 

0.75 

0.23 

0.53 

0.80 

0.59 

0.33 

0.23 

0.70 

0.22 

0.53 

0.79 

Jan 06

c3

c1

c4

c2

Jan 06

c3

c1

c4

c2

0.33 

0.41 

0.24 

0.77 

0.28  0.57 

0.84 

0.55 

0.33 

0.22 

0.69 

0.60 

0.84 

Feb 06

c3

c1

c4

c2

Feb 06

c3

c1

c4

c2

(a) α = 1

(b) α = 0.5

Figure 9: The Evolution Net of the NEC dataset
when (a) α = 1 and (b) α = 0.5

Fig. 9 shows the Evolution Net derived from our frame-
work when α=1 and 0.5 (α = 1 means no temporal smooth-
ness is considered). In the Evolution Net, the size of a node
is proportional to λk and it represents the size of the corre-
sponding community. The edge label indicates the probabil-
ity of a transition from the source community at t-1 to the

692WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of CommunitiesC1

C2

C3

C4

Figure 10: The Community Net for the NEC dataset
in September 2005

target community at t. (To avoid clutter, we did not show
edges with probabilities less than 0.2). From Fig. 9(a) we see
that when no temporal smoothness is considered, C4 disap-
peared at the second timestep (Sep 05) and re-appeared in
the third timestep (Oct 05). However, by carefully examin-
ing the original data, we did not ﬁnd any signiﬁcant events so
support such changes. Therefore, we conjecture that these
changes are due to the data noises at the second timestep,
which triggered the algorithm to split C1 into two commu-
nities and merge C4 to one of them. In comparison, as can
be seen from Fig. 9(b), when there is a temporal smoothness
term, the four communities remain relatively stable. That
is, although there exist transitions among diﬀerent types of
communities, the majority of transitions are between com-
munities of the same type. These results demonstrate that
the FacetNet framework is more robust to data noise.

From the Evolution Net, we can also obtain some other
observations. For example, the political community C2 is
rather isolated from the rest communities over all the time.
In comparison, both C3 and C4 interacts with C1 heavily.
In addition, in Fig. 10 we show the Community Net at an
arbitrary timestep (Sep 05).
In the Community Net, the
node sizes are proportional to λt;k and the edge weights are
proportional to the corresponding entries in ΛtX T
t XtΛt
(self-loops are not shown). We can see that this Community
Net is a good synopsis of the aggregated network in Fig. 8.

t D−1

4.3 DBLP Co-authorship Dataset

The DBLP co-authorship dataset is a subset of that used
by Asur et al. [1]. It contains papers in 28 conferences over
10 years (1997–2006), which span three areas—database,
data mining, and artiﬁcial intelligence. We selected a dense
subgraph of 2950 authors from the original dataset and par-
tition the time into three periods with overlap: 1997–2000,
2000–2003, 2003–2006.

Due to the space limit, we skip the detailed performance
study and only point out two interesting issues about this
dataset. First, in the ﬁrst two periods, the soft modular-
ity shows (local) peaks at m = 4 while in the third period,
m = 3 is optimal. As a result, for this experiment we used
the update algorithm described in Theorem 4. Second, in
Table 2 we list the top authors in the three communities de-
tected by FacetNet in the third period (2003–2006). Here the
rank is determined by the value xik, i.e., pk→i. Recall that
pk→i indicates to what level the k-th community involves the
i-th node. So from our framework, we can directly infer who
are the important members in each community. However,
notice that by important, we are not judging the quality or
quantity of papers by an author. Instead, in our framework
the importance of a node in a community is determined by

Table 2: Top members in the three communities
during 2003–2006, sorted by xik, i.e., pk→i

Data Mining

Database

Artiﬁcial Intelligence

Philip S. Yu
Jiawei Han
Wei Wang

Jian Pei

Divesh Srivastava
Surajit Chaudhuri

Nick Koudas

Elke A. Rundensteiner

Divyakant Agrawal

Jennifer Widom

Kian-Lee Tan
Beng Chin Ooi

Stanley B. Zdonik
Nikos Mamoulis
Walid G. Aref

Raghu Ramakrishnan
Jeﬀrey F. Naughton

David J. DeWitt
Rajeev Motwani
H. V. Jagadish

Hans-Peter Kriegel

William C. Regli
Maxim Peysakhov
Vincent A. Cicirello

Evan Sultanik

Gustave Anderson
Andrew Burnheimer

David Dorsey
Moshe Kam

Joseph Kopena

its contribution to the community structure. For example,
in Table 2, some of the top authors in the AI area are ranked
high partially because they participated in a series of papers
with up to 20 co-authors and these large co-author cliques
heavily inﬂuenced the community structure of the AI com-
munity in our dataset.

5. CONCLUSION

The analysis of communities and their evolutions in dy-
namic temporal networks is a challenging research prob-
lem with broad applications.
In this paper, we proposed
a framework, FacetNet, to solve this problem. Unlike tradi-
tional two-stage techniques that separate the task of com-
munity extraction and the task of evolution extraction, the
FacetNet framework combines these two tasks in a uniﬁed
process. Therefore, not only community structures deter-
mine the evolutions, but also the historic evolution patterns
regularize current community structure. As a result, it is
less likely for the current community structure to deviate
too dramatically from the most recent history. In addition
to the basic framework, we also proposed to use soft commu-
nity membership and we introduced several novel concepts
such as Community Net, Evolution Net, and Soft Modular-
ity, to measure and to visualize the resulting communities
and their evolutions. Extensive experimental studies demon-
strated that our framework provide communities and evolu-
tions that are more accurate and more robust to data noise.

Acknowledgments
We thank Kai Yu for providing us with the SNMF source
code and for the helpful discussion; thank Junichi Tatemura
and Koji Hino for helping prepare the blog dataset; thank
Sitaram Asur and Srinivasan Parthasarathy for providing us
with the DBLP dataset.

6. REFERENCES

[1] S. Asur, S. Parthasarathy, and D. Ucar. An

event-based framework for characterizing the
evolutionary behavior of interaction graphs. In Proc.
of the 13th ACM SIGKDD Conference, 2007.
[2] D. Chakrabarti, R. Kumar, and A. Tomkins.

Evolutionary clustering. In Proc. of the 12th ACM
SIGKDD Conference, 2006.

[3] Y. Chi, X. Song, D. Zhou, K. Hino, and B. L. Tseng.

Evolutionary spectral clustering by incorporating
temporal smoothness. In Proc. of the 13th ACM
SIGKDD Conference, 2007.

693WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of Communities[4] F. R. K. Chung. Spectral Graph Theory. American

Mathematical Society, 1997.

Methods and Applications. Cambridge University
Press, 1994.

[5] I. S. Dhillon, Y. Guan, and B. Kulis. Kernel k-means:

[23] S. White and P. Smyth. A spectral clustering approach

spectral clustering and normalized cuts. In Proc. of
the 10th ACM SIGKDD Conference, 2004.

to ﬁnding communities in graph. In SDM, 2005.

[24] K. Yu, S. Yu, and V. Tresp. Soft clustering on graphs.

[6] G. Flake, S. Lawrence, and C. Giles. Eﬃcient

In NIPS, 2005.

identiﬁcation of web communities. In Proc. of the 6th
ACM SIGKDD Conference, 2000.

[7] J. M. Kleinberg. Authoritative sources in a

hyperlinked environment. J. of the ACM, 46(5), 1999.

[8] R. Kumar, J. Novak, P. Raghavan, and A. Tomkins.
On the bursty evolution of blogspace. In Proc. of the
12th WWW Conference, 2003.

[9] R. Kumar, J. Novak, and A. Tomkins. Structure and

evolution of online social networks. In Proc. of the
12th ACM SIGKDD Conference, 2006.

[10] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs

over time: densiﬁcation laws, shrinking diameters and
possible explanations. In Proc. of the 11th ACM
SIGKDD Conference, 2005.

[11] Y. Lin, H. Sundaram, Y. Chi, J. Tatemura, and B. L.
Tseng. Blog community discovery and evolution based
on mutual awareness expansion. In Proc. of the Int.
Conf. on Web Intelligence, 2007.

[12] Q. Mei and C. Zhai. Discovering evolutionary theme
patterns from text: an exploration of temporal text
mining. In Proc. of the 11th ACM SIGKDD
Conference, 2005.

[13] M. E. J. Newman and M. Girvan. Finding and

evaluating community structure in networks. Phys.
Rev. E, 2004.

[14] H. Ning, W. Xu, Y. Chi, Y. Gong, and T. Huang.
Incremental spectral clustering with application to
monitoring of evolving blog communities. In SIAM
Int. Conf. on Data Mining, 2007.

[15] L. Page, S. Brin, R. Motwani, and T. Winograd. The

PageRank citation ranking: Bringing order to the
web. In Technical report, Stanford Digital Library
Technologies Project, Stanford University, Stanford,
CA, USA, 1998.

[16] G. Palla, A.-L. Barabasi, and T. Vicsek. Quantifying

social group evolution. Nature, 446, 2007.

[17] P. Sarkar and A. W. Moore. Dynamic social network
analysis using latent space models. SIGKDD Explor.
Newsl., 7(2), 2005.

[18] J. Shi and J. Malik. Normalized cuts and image

segmentation. IEEE Trans. on Pattern Analysis and
Machine Intelligence, 22(8), 2000.

[19] M. Spiliopoulou, I. Ntoutsi, Y. Theodoridis, and

R. Schult. Monic: modeling and monitoring cluster
transitions. In Proc. of the 12th ACM SIGKDD
Conference, 2006.

[20] J. Sun, C. Faloutsos, S. Papadimitriou, and P. S. Yu.

GraphScope: parameter-free mining of large
time-evolving graphs. In Proc. of the 13th ACM
SIGKDD Conference, 2007.

[21] M. Toyoda and M. Kitsuregawa. Extracting evolution
of web communities from a series of web archives. In
HYPERTEXT ’03: Proc. of the 14th ACM conference
on hypertext and hypermedia, 2003.

[22] S. Wasserman and K. Faust. Social Network Analysis:

[25] H. Zha, X. He, C. H. Q. Ding, M. Gu, and H. D.

Simon. Spectral relaxation for k-means clustering. In
NIPS, 2001.

APPENDIX
Proof for Theorem 1

Proof. Given that Xt ∈ Rn×m

, each column of which
sums up to one, and Λt is an m-by-m diagonal matrix and
sum to one, we have

+

P (Ut|Ut−1) = P (Yt|Ut−1),

where Yt = XtΛt. Because of the constraint, for any given
Yt, there is a unique pair of Xt and Λt such that Yt = XtΛt,
and Xt and Λt satisfy the constraint. Thus, Yt uniquely
determines Ut, which implies

P (Ut|Ut−1) = P (Yt|Ut−1).

The logarithm of MAP is

L(Ut) = log P (Wt|Ut)P (Ut|Ut−1)

= log P (Wt|Ut)P (XtΛt|Ut−1)
= log multinom(vec (Wt) ; θt)

+ log Dirichlet(vec (XtΛt) ; φt)

= log

(Pij Wt;ij)!
Qij Wt;ij! Yij
B(φ)Yik

Y

1

+ log

θ

Wt;ij
t;ij

νYt−1;ik
t;ik

=Xij

Wt;ij log θt;ij +Xik

νYt−1;ik log Yt;ik + const.

Since Pij θt;ij =Pk Λt;kk = 1 and Pik Yt;ik =Pk Λt;kk =

1, we can further derive

L(Ut) = − D(Wtkθt;ij) − νD(Yt−1kYt) + const.

= −

1
α

[αD(WtkXtΛtX T
t )

+ (1 − α)D(Yt−1kXtΛt)] + const.

Thus, maximizing L(Ut) is equivalent to minimizing the cost
function in Eq. (2).

Proof for Theorem 3

Proof. In the standard Q formula Eq. (6), the ﬁrst term
is the empirical probability that a randomly se-
lected edge has both ends in community k. For our case,

A(Vk ,Vk )
A(V,V )

this empirical probability should be Pi,j wij P (k|i)P (k|j).

For the second term in Eq. (6), A(Vk ,V )
is the empirical
A(V,V )
probability that a randomly selected edge is related to (i.e.,
has at least one end in) community k. For our case, this

empirical probability should be Pi P (k|i)Pj wij . By sum-

ming these two terms over all k’s and noticing that P (k|i) =
(D−1XΛ)ik, we get formula Eq. (7). In addition, it is straight-
forward to verify that Qs is equal to Q when D−1XΛ be-
comes a 0/1 indicator matrix.

694WWW 2008 / Refereed Track: Social Networks & Web 2.0 - Discovery and Evolution of Communities