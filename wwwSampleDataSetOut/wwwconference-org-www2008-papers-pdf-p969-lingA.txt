Can Chinese Web Pages be Classiﬁed with English Data

Source?

Xiao Ling† Gui-Rong Xue†∗

Wenyuan Dai† Yun Jiang† Qiang Yang‡ Yong Yu†

†Shanghai Jiao Tong University, 800 Dongchuan Road, Shanghai 200240, China

{shawnling, grxue, dwyak, yunjiang, yyu}@apex.sjtu.edu.cn

‡Hong Kong University of Science and Technology, Clearway Bay, Kowloon, Hong Kong

qyang@cs.ust.hk

ABSTRACT
As the World Wide Web in China grows rapidly, mining
knowledge in Chinese Web pages becomes more and more
important. Mining Web information usually relies on the
machine learning techniques which require a large amount of
labeled data to train credible models. Although the number
of Chinese Web pages increases quite fast, it still lacks Chi-
nese labeled data. However, there are relatively suﬃcient
English labeled Web pages. These labeled data, though
in diﬀerent linguistic representations, share a substantial
amount of semantic information with Chinese ones, and can
be utilized to help classify Chinese Web pages. In this pa-
per, we propose an information bottleneck based approach
to address this cross-language classiﬁcation problem. Our
algorithm ﬁrst translates all the Chinese Web pages to En-
glish. Then, all the Web pages, including Chinese and En-
glish ones, are encoded through an information bottleneck
which can allow only limited information to pass. Therefore,
in order to retain as much useful information as possible, the
common part between Chinese and English Web pages is in-
clined to be encoded to the same code (i.e. class label),
which makes the cross-language classiﬁcation accurate. We
evaluated our approach using the Web pages collected from
Open Directory Project (ODP). The experimental results
show that our method signiﬁcantly improves several exist-
ing supervised and semi-supervised classiﬁers.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

General Terms
Algorithms, Experimentation

Keywords
Cross-Language Classiﬁcation, Information Bottleneck

1.

INTRODUCTION

A dramatic development of Internet in China has been
witnessed in the recent years. The number of Internet users
∗

Gui-Rong Xue is the corresponding author.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2008, April 21–25, 2008, Beijing, China.
ACM 978-1-60558-085-2/08/04.

in China now exceeds 160 millions and the Chinese Web
pages are numbered in billions1. As the most commonly
used language only second to English, Chinese is expected
to enjoy such a rocketing increase in scale. Because the Web
pages written in Chinese is becoming a major information
source on the Internet, more research eﬀorts are now devoted
to organizing and mining the Chinese Web pages via Web
mining techniques, such as Chinese blog mining [20] and
query log analysis [19].

A potential problem in mining the Chinese Web pages
is the lack of suﬃcient labeled data. As we know, classi-
ﬁcation requires a large amount of labeled training data.
Generally speaking, the more labeled training data one can
obtain, the better the classiﬁcation accuracy and robust-
ness are. Fortunately, due to many reasons, there exists a
lot of labeled Web-page information in English, in particu-
lar in the machine learning community. Examples of these
resources are Reuters-21578 [16], 20 Newsgroups [15], and
Open Document Project [22]. It is thus useful and intrigu-
ing to fully utilize the labeled documents in English to help
classify the Web pages in Chinese. This problem is called
cross-language Web-page classiﬁcation.
In this paper, we
address this important problem using a novel information
theory based technique.

Although the training and test documents are in diﬀerent
languages, one can use a translation tool to help translate
the test data sets in the English language, before a classi-
ﬁer trained on English pages can be applied. While such a
method may be feasible, we observe that a simple-minded
application of this method may result in serious problems
because of the following reasons:

• First, due to the diﬀerence in language and culture,
there exists a topic drift when we move from the En-
glish Web pages to the Chinese Web pages. This corre-
sponds to the situation in machine learning where the
training and test data have diﬀerent distributions in
terms of the class labels. This topic-imbalanced prob-
lem needs to be overcome in our research.

• Second, due to the errors introduced in the translation
process, there may be diﬀerent kinds of errors in the
translated text. For example, some errors may result
from Chinese phrase segmentation, others are due to
ambiguities introduced by a dictionary. This transla-
tion noise problem must be addressed eﬀectively.

1According to the report by CNNIC in January 2007:
http://www.cnnic.net.cn/uploadﬁles/pdf/2007/2/13/95522.pdf

969WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, ChinaEnglish Web Pages

common part

Chinese Web Pages

coding

output

(cid:20)

information
bottleneck

Figure 1: The model of our information bottleneck
cross-language classiﬁer.

• Finally, the feature spaces of the English and Chinese
Web pages may be diﬀerent, resulting in a situation
where the training and test data may have diﬀerent
feature sets. We therefore must be innovative in our
solution to this problem by carefully extracting the
common-semantic parts of the two data sets, and use
these parts as a bridge to propagate the class labels.

To solve the above problems, we develop a novel approach
for classifying the Web pages in Chinese using the training
documents in English. Our key observation is that despite
the above listed problems, linguistically, the pages in Chi-
nese and English may share the same semantic information,
although they are in diﬀerent representation forms, i.e., Chi-
nese characters and English words, respectively. This is rea-
sonable, because people with good command of both English
and Chinese can convey the same information in both lan-
guages. Also, it is noted that the same meaning might be
expressed in diﬀerent ways due to the cultural and linguistic
diﬀerences.

Based on the observations, we propose to tackle the cross-
language classiﬁcation problem using information bottleneck
theory [29]. Figure 1 illustrates our idea intuitively. The
training and translated target texts are encoded together,
allowing all the information to be put through a “bottle-
neck” and represented by a limited number of codewords
(i.e.
labels in the classiﬁcation problem). Information bot-
tleneck based approach can maintain most of the common
information and disregard the irrelevant information. Thus
we can approximate the ideal situation where similar train-
ing and translated test pages, which is the common part,
are encoded into the same codewords.

In the experimentation, we collect the Web pages in En-
glish and Chinese from Open Directory Project for the data
sets. Five binary and three multi-class tasks have been set
up. Our method gives signiﬁcant improvement against sev-
eral existing classiﬁers, and converges very well.

In summary, in this paper we make the following contri-

butions:

• In addressing the cross-language Web page classiﬁca-
tion problem, we observe that there is a common part
of Chinese and English documents and develop a novel
method for addressing the problem of topic drifts in
Chinese and English documents, thus improving the
classiﬁcation performance.

• We propose to handle noisy features and diﬀerent fea-
tures problem in cross-language Web-page classiﬁca-
tion by the information bottleneck technique. This
method allows the common part in the two languages

to be extracted and used for classiﬁcation, despite their
diﬀerences. We show experiments on real English and
Chinese Web documents. Our method is shown to im-
prove other classiﬁcation algorithms.

The rest of our paper is organized as follows: In Section
2 we brieﬂy discuss the related work. Following the basic
concepts reviewed in Section 3, we introduce the informa-
tion bottleneck theory in Section 4. Section 5 describes our
proposed method in details. The experiments and results
are presented in Section 6. In the end, we conclude this pa-
per with future work discussion in Section 7. The detailed
proofs to the lemmas and theorems in this paper will be
given in Appendix.

2. RELATED WORK

In this section, we review several prior researches mostly
related to our work, including traditional classiﬁcation, cross-
language classiﬁcation and information theoretic learning.
2.1 Traditional Classiﬁcation

The traditional classiﬁcation formulation is built on the
foundation of statistical learning theory. Two schemes are
generally considered, where one is supervised classiﬁcation
and the other is semi-supervised classiﬁcation. Supervised
classiﬁcation focuses on the case where the labeled data are
suﬃcient, and where the learning objective is to estimate
a function that maps examples to class labels using the la-
beled training instances. Examples of supervised classiﬁca-
tion algorithms include decision trees [25], K nearest neigh-
bor methods [6], naive Bayes classiﬁers [17], support vector
machines [5], and so on.

Semi-supervised classiﬁcation [32] addresses the problem
that the labeled data are too few to build a good classiﬁer.
It makes use of a large amount of unlabeled data, together
with a small amount of the labeled data to enhance the
classiﬁers. Many semi-supervised learning techniques have
been proposed, e.g., co-training [4], EM-based methods [21],
transductive learning [13] etc.

As we claimed, there are two main diﬃculties in the cross-
language classiﬁcation, namely errors by translation and bias
by topic drifts, which traditional classiﬁers cannot handle
well. Our proposed method tries to tackle these diﬃculties
via the information bottleneck technique.
2.2 Cross-Language Text Classiﬁcation

There are several research works addressing the cross-
language classiﬁcation problem. Bel et al. [3] studied English-
Spanish cross-language classiﬁcation problem. Two scenar-
ios are considered in their work. One scenario assumes to
have training documents in both languages. The other sce-
nario is to learn a model from the text in one language and
classify the data in another language by translation. In our
work, we focus on the second scenario.
[26] gave good em-
pirical results on English-Italian cross-language text cate-
gorization using an EM-based learning method. Note that
to avoid trivial partitions, it applies feature selection before
each iteration. [23] employed a general probabilistic English-
Czech dictionary to translate Czech text into English and
then classiﬁed Czech documents using the classiﬁer built on
English training data. Other cross-language text classiﬁca-
tion research include [11] (English-Spanish), [18] (English-
Japanese) etc, to be mentioned. In addition to text catego-

970WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, Chinarization, there are some other speciﬁc cross-language appli-
cations: Named Entity Recognition [30], Question Answer-
ing [8], etc.

However, most existing algorithms are based on tradi-
tional supervised or semi-supervised classiﬁcation techniques.
As we stated, there are two diﬃculties in the cross-language
classiﬁcation, the translation error and topic drift, which
lead to diﬀerence in distributions between the Web pages
in two languages. Since traditional supervised classiﬁcation
techniques assume identical distribution for training and test
data and in the cross-language setting this assumption is
hardly met, most existing algorithms will not cope with
the cross-language text classiﬁcation well. In this work, our
method tries to handle the Chinese-English cross-language
categorization problem by information bottleneck. We will
show that our algorithm can better alleviate the impact of
translation error and topic drift, and improve the (English to
Chinese) cross-language classiﬁcation performance against
existing methods.

2.3 Information Theoretic Learning

Another related research is information theory based learn-
ing. Information theory is widely used in machine learning,
e.g. decision tree [25], feature selection [31], etc.

The information bottleneck theory (IB) was ﬁrst proposed
by Tishby et al.
[29]. They constructed a model that uses
information theory to solve the clustering problem. In their
work, a rate distortion function is introduced as a loss func-
tion. They also presented a converging iterative algorithm
for this self-consistent determination problem. After that, a
lot of interesting works have been conducted, c.f.
[27]. As
known, IB is an information theoretic formulation for clus-
tering problem while maximum likelihood of mixture models
is a standard statistical method to clustering. Interestingly,
Slonim and Weiss [28] have proved that under a certain map-
ping, these two approaches are strongly related. Moreover,
when input data is large enough, they are statistically equiv-
alent.

Several extensions to information bottleneck method have
been investigated recently.
[9] proposed a word clustering
method which minimizes the loss in mutual information be-
tween words and class-labels, before and after clustering.
Using similar strategy, mutual information based [10] and
Bregman divergence based [2] co-clustering were proposed.
In contrast to these works, we focus on solving the cross-
language classiﬁcation problem via an information theoretic
approach. More speciﬁcally, the IB technique is used to
mine the common part of the pages in diﬀerent languages
for classiﬁcation.

3. PRELIMINARY

In this section, some preliminary knowledge in the in-
formation theory is brieﬂy introduced, including informa-
tion entropy, mutual information and Kullback-Leibler di-
vergence [14]. For more details, please refer to [7].

The term entropy is used to measure the uncertainty as-

sociated with a random variable X. Formally,

Z

H(X) = −

p(x) log(p(x))dx,

(1)

x

where x enumerates each value X may take. In the com-
munication system, the entropy quantiﬁes the information

X

encoding

X~

Figure 2: The information bottleneck. Here, X is
the signals to be encoded, and ˜X is the codewords.
In classiﬁcation, X is the set of instances, and ˜X is
the prediction labels.

contained in a piece of data, i.e. its minimum average mes-
sage length in bits. This means the best possible lossless
data compression is limited to this measure.

Let X and Y be random variable sets with a joint distri-
bution p(X, Y ) and marginal distributions p(X) and p(Y ).
The mutual information I(X; Y ) is deﬁned as

Z

Z

I(X; Y ) =

p(x, y) log

x

y

p(x, y)
p(x)p(y)

dxdy.

(2)

The mutual information is a measure of the dependency be-
tween random variables. It is always non-negative, and it is
zero if and only if the variables are statistically independent.
Higher mutual information values indicate more certainty
that one random variable depends on another.

The mutual information is related to the Kullback-Leibler
(KL) divergence or relative entropy measures, deﬁned for
two probability mass functions p(x) and q(x),

Z

D(p||q) =

p(x) log

x

p(x)
q(x)

dx,

(3)

where q(x) is a reference distribution. The KL-divergence
can be considered as a kind of a distance between the two
probability distributions, although it is not a real distance
measure because it is not symmetric.
In addition, KL-
divergence is always non-negative due to the Gibbs’ inequal-
ity [7].

4.

INFORMATION BOTTLENECK

In this section, we present the basic concepts for informa-
tion bottleneck, and show how it can be applied to cross-
language classiﬁcation.
4.1 Basic Concepts

The information bottleneck (IB) method is a distributional
learning algorithm proposed by Tishby et al.
[29]. In this
theory, the clustering and classiﬁcation problems can be
treated as a coding process. Let X be the signals to be
encoded, and ˜X be the set of codewords. In classiﬁcation,
the codewords ˜X is deﬁned as class labels, and then classi-
fying X can be seen as using ˜X to encode X. Usually ˜X is
not able to contain as much information as X. Therefore,
when the signals X is encoded to codewords ˜X, part of the
information contained by X will be lost. This can be im-
aged as the information in X passing through a bottleneck
˜X, as shown in Figure 2, and thus ˜X is called information
bottleneck.

971WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, ChinaA good clustering should guarantee the encoding eﬀec-
tiveness (the lower rate the better) as well as meaningful
information, which can be formulated as a trade-oﬀ objec-
tive I( ˜X; X)−βI( ˜X; Y ) [29], where Y is the feature set with
respect to X. Note that the coding rate I( ˜X; X) in classi-
ﬁcation is no so important as in clustering problems, since
classiﬁcation focuses on prediction accuracy. Therefore, in
this task, we need to mainly concentrate on improving the
classiﬁcation accuracy. So that, −I( ˜X; Y ) is optimized in-
stead of I( ˜X; X) − βI( ˜X; Y ), as the coding rate I( ˜X; X) is
ignored. Moreover, in order to make the optimization eas-
ier, in this work, we optimize I(X; Y ) − I( ˜X; Y ) instead of
−I( ˜X; Y ). We will show the optimization details in the next
section. Note that, I(X; Y ) is a constant, when X and Y are
ﬁxed, and thus optimizing I(X; Y ) − I( ˜X; Y ) is equivalent
to optimizing −I( ˜X; Y ).
The meaning of objective function I(X; Y )− I( ˜X; Y ) can
be also understood in another way. In classiﬁcation, the in-
stances are described by the features, and thus there should
be mutual information between data instances and their fea-
tures, i.e. I(X; Y ) > 0. In addition, the category informa-
tion is also described by the features, and thus I( ˜X; Y ) > 0.
Therefore, the information in X and ˜X is contained in forms
of I(X; Y ) and I( ˜X; Y ). Note that I(X; Y ) is always greater
than or equal to I( ˜X; Y ), which will be derived in Lemma
I(X; Y ) − I( ˜X; Y ) > 0 means there is
1 in Section 5.2.
some loss in mutual information after categorization. To
sum up, a good categorization should keep the mutual in-
formation between data and features, and minimize the in-
formation loss. In other words, I( ˜X; Y ) should be close to
I(X; Y ). Therefore, in the information bottleneck classiﬁ-
cation setting, the quality of the categorization should be
judged by the loss in mutual information between the orig-
inal instances and categorized instances. The following re-
mark lays our the objective function formally.

Remark 1. In the information bottleneck (IB) classiﬁca-
tion setting, a qualiﬁed hypothesis h : X (cid:3)→ ˜X approximately
satisﬁes:

”

“

h = arg min
h∗

I(X; Y ) − I( ˜X; Y )

.

(4)

4.2 Applying to Cross-Language Classiﬁer

Before the formal problem formulation, we would like to
present a brief idea to address the cross-language classiﬁca-
tion problem by information bottleneck. Suppose we have
the union set X of English and Chinese Web pages, Y is
the set of words contained in X, and ˜X stands for the class
labels.

It is observed that there is a common part of English and
Chinese web pages, which share the similar semantic infor-
mation. This observation inspired our work.
If the texts
are put through the “bottleneck”, the labeled data (English
Web pages) will, to some extent, guide the classiﬁcation on
Chinese pages by encoding the common part into the same
codewords. It is because that during the information theo-
retic compression, IB tends to encode the similar pages into
the same code (label) in that it can reduce the code length
without loss of much information. If one Chinese page is in
the common part, i.e. similar to a labeled English page, this
page will be classiﬁed into the same category as that of the
English one.

Figure 3: The cross-language classiﬁcation problem.
Here, Xe is the set of the Web pages in English and
Xc is the set of the Web pages in Chinese.
It is
assumed that there is some common part between
English and Chinese Web pages.

To summarize, it is noted that cross-language Web pages
are carrying a common part of semantic information. Ac-
cording to the information bottleneck theory, this part of
information is expected to help encode similar Web pages in
diﬀerent languages since it is highly relevant information to
class labels and also is contained in the Web pages in both
languages. Therefore, it is clear that the information bot-
tleneck technique is suitable to address the cross-language
classiﬁcation problem.

5. CROSS-LANGUAGE CLASSIFIER VIA

INFORMATION BOTTLENECK

In this section, the problem is carefully formulated and
an objective function is proposed to build a classiﬁcation
model. The classiﬁcation algorithm (IB) is then presented.
Also, the convergence and time complexity are theoretically
analyzed.
5.1 Problem Formulation

Let Xe be the set of the Web pages in English with class
labels and Xc be the set of the Web pages in Chinese without
labels. Usually, it is assumed that the English Web pages Xe
and Chinese Web pages Xc share some common information
with each other, as shown in Figure 3. The feature space
for Xe is the English words Ye and for Xc is the Chinese
words Yc. The objective is, we are trying to classify the
pages in Xc into C, the predeﬁned class label set, which is
the same for the pages in Xe. To sum up, labeled training
documents are available only in one language, and we want
to estimate a hypothesis h : Xc (cid:3)→ C which classiﬁes
documents written in another language. This is called cross-
language text classiﬁcation.

In contrast to traditional text categorization, where the
training and test pages are in the same language, cross-
language text classiﬁcation requires that the training and
test data should be uniﬁed into one single feature space.
Otherwise, it is not possible for existing machine learning
techniques to get the results. The most common way is to
translate the pages in one language into the other one. How-
ever, it is noticed that this common approach will bring the
error and bias for further classiﬁcation. Linguistically speak-
ing, machine translation technique is far from satisfactory.
What is worse, the simple translation preprocessing does not
give the accurate information. The topics of original data
may drift under translation. Empirically, these claims were
justiﬁed. The experimental details are presented in Section
6.1.2.

972WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, China5.2 Objective Function

As stated in Section 4.2, we propose to address the prob-
lems via the information bottleneck technique. The test
Web page set is translated to English, denoted as X T
c . Let
X = Xe ∪ X T
c , as the original signal for the bottleneck. The
class label set is the output of the bottleneck ˜X. Y is re-
ferred to the features of all the documents. To fully utilize
the common part for classiﬁcation, we deﬁned the objective
function as

I(X; Y ) − I( ˜X; Y ),

(5)
which is exactly the objective function in Remark 1. Note
that I(X; Y ) − I( ˜X; Y ) is always non-negative, which will
be derived by Lemma 1. Based on Remark 1, the objective
function value should be minimized, since we aim to draw
I( ˜X; Y ) close to I(X; Y ).

Before proposing the optimization approach for minimiz-
ing the objective function, we ﬁrst deﬁne some notations
used in subsequent analysis.
Definition 1. We use ˜X = {˜x} to denote a categoriza-
tion of X for the hypothesis h, where ˜x = {x(cid:2)|h(x(cid:2)
) = h(x)}.
Clearly, | ˜X| is equal to |C|, since h maps the instances in X
to the class-labels in C.

Definition 2. The joint probability distribution of X and
Y under the categorization ˜X is denoted by ˜p(X, Y ), where

˜p(x, y) = p(˜x, y)p(x|˜x) = p(˜x, y)

p(x)
p(˜x)

,

(6)

where x ∈ ˜x, and p(x|˜x) = p(x)
˜x.

p(˜x) since x totally depends on

In the following, we will transform the objective func-
tion in Equation (5) into another representation by KL-
divergence [14].

Lemma 1. For a ﬁxed categorization ˜X, we can write the

objective function in Equation (5) as

I(X; Y ) − I( ˜X; Y ) = D(p(X, Y )||˜p(X, Y )),

(7)
where D(·||·) is the KL-divergence deﬁned as Equation (3).
Note that, based on the non-negativity of KL-divergence,
the objective function I(X; Y ) − I( ˜X; Y ) should always be
non-negative.
5.3 Optimization

From Equation (7), it is found that the loss in mutual in-

formation in the objective function equals to the KL-divergence
between p(X, Y ) and ˜p(X, Y ). To minimize the objective
function in Equation (5), we need only to ﬁnd a categoriza-
tion ˜X which minimizes the KL-divergence value

D(p(X, Y )||˜p(X, Y )) .

(8)

However, the objective function in Equation (7) is in the
joint probability form that is diﬃcult to be optimized. Now,
we are to rewrite it into a conditional probability form,
which will facilitate our algorithm to reduce the objective
function value.

Lemma 2. The objective function in Equation (7) can be

expressed by a conditional probability form as
D(p(X, Y )||˜p(X, Y )) =

p(x)D(p(Y |x)||˜p(Y |˜x)). (9)

X

X

˜x∈ ˜X

x∈˜x

Lemma 2 gives a straightforward explanation for cross-
language text classiﬁcation via the information bottleneck
technique. If one Chinese page is more similar to the English
pages of one class ˜x, i.e. the distance D(p(Y |x)||˜p(Y |˜x)) is
the smallest, assigning this page to ˜x will lead to a lower
value of the objective function. Then it is desirable during
the optimization process, which means the common part
between English and Chinese Web pages work as stated in
Section 4.2.

Also, Lemma 2 provides an alternative way to reduce the
objective function value. From Equation (9), we know that
minimizing D(p(Y |x)||˜p(Y |˜x)) for a single instance x could
reduce the global objective function D(p(X, Y )||˜p(X, Y )).
As a result,
if we iteratively optimize the corresponding
D(p(Y |x)||˜p(Y |˜x)) for each instance x, the objective func-
tion will decrease monotonically. Thus, based on Lemma 2,
the information bottleneck cross-language text classiﬁcation
(IB) is derived as in Algorithm 1.

Algorithm 1 The Cross-Language Text Classiﬁcation (IB)
Algorithm
Input: English Web pages Xe; Chinese Web pages Xc; an
existing translator T ; the number of iterations N .
Output: the ﬁnal hypothesis hf : Xc ∪ Xe (cid:3)→ C.
1: Translate Xc into English: X T

c = T (Xc). Let X =

Xe ∪ X T
c .

2: Train an initial hypothesis h(0) based on Xe by super-
vised learning method (e.g. naive Bayes classiﬁers [17]).
3: Initialize the probability distribution ˜p(0) based on h(0)

D(p(Y |x)||˜p(t−1)(Y |˜x))

c do

h(t)(x) = arg min˜x∈ ˜X

end for
for each x ∈ Xe do

and Equation (6).
4: for t = 1, . . . , N do
for each x ∈ X T
5:
6:
7:
8:
9:
10:
11:
12: end for
13: Return h(N) as the ﬁnal hypothesis hf .

h(t)(x) = h(t−1)(x)

end for
Update ˜p(t) based on h(t) and Equation (6).

In Algorithm 1, in each iteration, the algorithm keeps the
prediction labels for the English Web pages Xe unchanged
since their true labels are already known, while choosing the
best category ˜X for each data instance x in X T
c to minimize
the function D(p(Y |x)||˜p(t−1)(Y |˜x)). As we have discussed
above, this process is able to decrease the objective function
in Equation (7). The whole algorithm is illustrated in Figure
4.
5.4 Convergence

Since our algorithm IB is iterative, it is necessary to dis-
cuss its property of convergence. The following theorem
shows that the objective function in our algorithm monoton-
ically decreases, which establishes that the algorithm con-
verges eventually.

Theorem 1. The objective function in Equation (7) mono-

tonically decreases in each iteration of Algorithm IB.
D(p(X, Y )||˜p(t)
Note that, although the algorithm is able to minimize the
objective function value in Equation (5), it is only able to

(X, Y )) ≥ D(p(X, Y )||˜p(t+1)

(X, Y )).

(10)

973WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, ChinaOptimize the objective 

function and give new labels 

for Chinese Web Pages

Unlabeled 
Chinese Web 

Pages

Translator

Unlabeled
Chinese Web 

Pages in 
English

Basic

Classifier

New Labels for 
Chinese Web 

pages

N times

Labeled 

English Web 

Pages

Output the labels 
for Chinese Web 

pages

Figure 4: The scheme of the IB-based cross-language
classiﬁcation algorithm.

ﬁnd a locally minimal one. Finding the global optimal solu-
tion is NP-hard. From Theorem 1, we can straightforwardly
derived that the algorithm IB converges in a ﬁnite number
of iterations, since the hypothesis space is ﬁnite.
5.5 Computational Complexity

Regarding the computational cost for IB, suppose the non-
zeros in p(X, Y ) is N . In each iteration, IB needs to calcu-
late h(t) in O(|C| · N ) and update ˜p(t)(Y | ˜X) in O(|C| · |Y |).
Therefore, the time complexity of IB is O(|C|· (|Y | + N )) as
a result. Usually, |C| is not large and could be considered
as a constant, while |Y | is usually not larger than N . Thus,
the time complexity of IB is O(N ) in general. Thus, our
algorithm IB has good scalability, and is capable for large
data sets.

6. EXPERIMENTS

In this section, we evaluate our cross-language classiﬁca-
tion algorithm based on information bottleneck, and com-
pare our algorithm with several state-of-art supervised and
semi-supervised classiﬁers.
6.1 Data Sets

We conduct our evaluation on the Web pages crawled from
the Open Directory Project (ODP) [22] during August 2006.
Each Web page in ODP was classiﬁed by human experts
into 17 top level categories (Arts, Business, Computers,
Games, Health, Home, Kids and Teens, News, Recreation,
Reference, Science, Shopping, Society, Sports, Regional,
Adult and World). We removed the Regional category be-
cause the Web pages in the Regional category are also in
other categories. The Web pages in the Adult have not been
crawled by our crawler, because most of them are banned by
our internet service provider, and thus the Adult category
is not included in our data collection. Moreover, the Web
pages in the World category are in the languages other than
English. We selected all the Chinese pages from the World
category as Chinese test data. For Chinese Web pages, there
are also 14 top categories each of which can be mapped to
a top category in the English ODP. Therefore, we have 14
categories for both Chinese and English Web pages in this
experiments. Figure 1 represents the detailed description for
our data collection. From the table, it can be seen that, the
number of English labeled Web pages is much larger than
that of Chinese ones in ODP, which indicates English la-

Category
Arts
Business
Computers
Games
Health
Home
Kids and Teens
News
Recreation
Reference
Science
Shopping
Society
Sports
Total

Chinese Web Pages English Web Pages
186,307
203,569
102,571
39,269
47,607
23,117
27,323
96,510
77,901
48,231
75,434
86,736
185,466
71,065
1,271,106

1,942
6,503
1,907
296
518
203
292
359
681
2,338
914
488
1,481
321
18,243

Table 1: The descriptions for all the categories in
ODP, including Chinese and English ones. Note
that, all the Chinese Web pages as well as their
category labels were translated into English using
Google Translator.

Categories
Games, News
Arts, Computers
Recreation, Science
Computers, Sports

Data Sets
Games vs News
Arts vs Computers
Recreation vs Science
Computers vs Sports
Reference vs Shopping Reference, Shopping
3 Categories
4 Categories
5 Categories

Arts, Computer, Society
Business, Health, News, Sports
Games, Home, News, Shopping, Sports

Table 2: The composition for each data sets.

beled Web pages (1,271,106) is much more abundant than
Chinese ones (18,243).

6.1.1 Data Preparation

Data preprocessing has been applied to the raw data.
First, all the Chinese Web pages were translated by Google
Translator [1]. Then, we converted all the letters to lower
cases, and stemmed the words using the Porter’s stemmer
[24]. After that, stop words were removed.
In order to
reduce the size of the feature space, we used a simple fea-
ture selection method, document frequency (DF) threshold-
ing [31], to cut down the number of features, and speed up
the classiﬁcation. Based on [31], DF thresholding, which
has comparable performance with information gain (IG) or
CHI, is suggested since it is simplest with lowest cost in
computation. In our experiments, we set the DF threshold
to 3. After feature selection, the vocabulary size becomes
512,896.

In order to evaluate our cross-language classiﬁer, we set
up eight cross-language classiﬁcation tasks. Five of them are
binary classiﬁcation tasks, and others are for multiple-class
classiﬁcation. Table 2 presents the detailed composition for
each classiﬁcation task.

6.1.2 Cross-Language Topic Drift

We extracted the most frequent features in the Chinese
and English Web pages for each of the 14 ODP categories,
and found the frequent features in the Chinese and English
Web pages are quite diﬀerent, although they share some

974WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, China800

700

600

500

400

300

200

100

s
e
g
a
P
b
e
W

 

0

0

2000

4000

6000

8000
Features

10000 12000 14000 16000

Figure 5: The instance-feature co-occurrence den-
sity for the Games vs News data set.

part. Table 3 presents the top 5 frequent features in the
Chinese and English Web pages for each of the 14 ODP
categories. We believe there is topic drift between Chinese
and English Web pages. For example, there are several Chi-
nese words which are frequently appears in the Chinese Web
pages, such as “qiyuan”, “mufurong”, “pingqiu” and so on. In
the Games, “qiyuan”, one of the famous online game in China,
is the most frequent keyword, while it hardly appears in the
English Web pages. This is due to the diﬀerence in cul-
ture between the Chinese and western societies. “pingqiu”,
which means “draw” in English, hardly appears in English
Web pages, because the translator fails to provide a mapping
between “draw” and it. The observations demonstrate the
claim we made previously that there are two main obstacles
for the cross-language classiﬁcation: one is the diﬀerence
in topic focus between the two languages; the other is the
translation error.

6.1.3 Density Analysis

Figure 5 shows the instance-feature co-occurrence distri-
bution on the Games vs News data set. In this ﬁgure, docu-
ments 1 to 484 are from Xe, while documents 485 to 853 are
from Xc. Within a data set, Xe or Xc, the documents are
ordered by their categories (Games or News). The words are
sorted by ng(w)/nn(w), where ng(w) and nn(w) represent
the number of word positions w appears in Games and News
documents, respectively. From Figure 5, it can be found
that the distributions of English and Chinese Web pages
are somewhat diﬀerent, however the ﬁgure also shows large
commonness exists between the two data sets. The den-
sity divergence between two data sets in the ﬁgure makes
the cross-language classiﬁcation diﬃcult, because most clas-
siﬁcation techniques rely on the basic assumption that the
training data should be drawn from the same distribution
as the test data. However, the common part between the
two data sets can help increase the feasibility of the classiﬁ-
cation.
6.2 Comparison Methods

In this experiments, we compare our information bottle-
neck cross-language classiﬁer (IB) with several state-of-art

classiﬁcation algorithms to show the advantages of our algo-
rithm.

We take the supervised classiﬁcation algorithms to be the
baseline methods. Naive Bayes classiﬁers (NBC) [17] and
support vector machines (SVM) [5] are evaluated in the
experiments. They are trained on Xe and tested on X T
c .
Transductive support vector machines (TSVM) [13] is also
introduced as comparison semi-supervised learning methods,
which take both labeled Xe and unlabeled X T
c for training
and X T

c for testing.

For implementation details, TF-IDF is used for feature
weighting when training support vector machines (SVM)
[5] and transductive support vector machines (TSVM) [13].
TF is used for feature weighting when training naive Bayes
classiﬁer (NBC) [17] and our information bottleneck based
cross-language classiﬁcation algorithm (IB).

SVM and TSVM are implemented by SVMlight [12] with
default parameters (linear kernel). For more details about
SVM and TSVM, please refer to [5] and [13]. NBC and IB
are implemented by ourselves. The initial categorizations
for IB are given by NBC.
6.3 Classiﬁcation Performance

We now present the classiﬁcation performance for each
comparison methods, and show advantages of our informa-
tion bottleneck cross-language classiﬁer IB.

6.3.1 Evaluation Metrics

The metrics used in this experiments are macro-average
precision, recall and F1-measure. Let f be the function
which maps from document d to its true class label c = f (d),
and h be the function which maps from document d to its
prediction label c = h(d) given by the classiﬁers. The macro-
average precision P and recall R are deﬁned as
|{d|d ∈ Xc ∧ h(d) = f (d) = c}|

|{d|d ∈ Xc ∧ h(d) = c}|

|{d|d ∈ Xc ∧ h(d) = f (d) = c}|

|{d|d ∈ Xc ∧ f (d) = c}|

,

(11)

.

(12)

X
X

c∈C

c∈C

P =

1|C|

R =

1|C|

F1-measure is a harmonic mean of precision and recall de-
ﬁned as follows

F1 =

2P R
P + R

.

(13)

6.3.2 Experimental Results

Table 4 presents the performance on each binary classiﬁca-
tion data set given by NBC, SVM, TSVM and our algorithm
IB. The implementation details of the algorithms have al-
ready been presented in the last subsection. The evaluation
metrics are macro-average precision, recall and F1-measure,
of which we have just given the deﬁnitions. From the table,
we can see that IB signiﬁcantly improves the other three
methods. Although SVM and TSVM is slightly better than
IB on the Arts vs Computers data set, IB is still compara-
ble. But, on some of the other data sets, e.g. Computers vs
Sports and Reference vs Shopping, both SVM and TSVM
fail, while IB is much better than the two discriminative
methods.
In addition, NBC is always worse than IB, but
never fails a lot. In average, IB gives the best performance
in all the three evaluation metrics.

Table 5 presents the performance on each multiple-class
classiﬁcation data set given by NBC and our algorithm IB.

975WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, ChinaCategory
Arts
Business
Computers
Games
Health
Home
Kids and Teens
News
Recreation
Reference
Science
Shopping
Society
Sports

Chinese Web Pages
giotto, tugen, penchant, ashima, banzai
congeni, nanci, decre, wallk, darshan
volp, uptim, screenshot, malcolm, datastorag
qiyuan, vierni, vernier, ﬁrstyeargirl, kangderong
neurosyphili, maximowicziana, carboyhdr, podophyllin, interpol
banlan, xero, bcsahin, mufurong, prestonwood
head, yangpu, ashaar, geetanjali, urdupoetri
uppercut, muham, readjust, pulverul, dovic
frauenhof, fatehpur, xingyuncao, nakedpoetri, orchha
ﬁlmcent, pessim, cold, seed, farm
applaud, zhouyulin, ﬂask, middlepillar, modarr
lcjzl, lashel, aubrac, roozi, ebullit
cass, indispens, buddhist, tahm, trod
parama, cow, pingqiu, nesi, shiduotangbei

English Web Pages
paean, base, dvdlaser, crew, taglin
natstat, kazaa, bcm, aanspreken, wct
volp, easyb, letterhack, grundriss, wsmcafe
accident, enix, impress, riﬂ, freeenergynew
ﬁnespun, stadium, linear, shyamalan, ryder
machist, evita, beradino, bakk, fudoh
pact, isch, argo, quem, melanesia
narr, hume, mujer, dude, gif
behoof, heepster, bonaﬁd, tiltrecord, kapil
platitudin, waggon, blankli, dfee, quotearch
frobozzica, exploratori, forbrydelsen, kashyyk, pallot
scherick, tricia, strewn, caryn, glenda
wallpap, hornadai, lafort, obstat, duranczyk
shinobi, jumbl, shirt, invert, sould

Table 3: The most frequent (stemmed) features in the Chinese and English Web pages for each ODP category.
All the Chinese Web pages have already been translated into English using Google Translator.

Data Set

Games vs News

Arts vs Computers

Recreation vs Science
Computers vs Sports
Reference vs Shopping

Average

Precision

NBC SVM TSVM
0.747
0.749
0.768
0.731
0.836
0.883
0.611
0.783
0.650
0.911
0.802
0.732

0.737
0.783
0.874
0.669
0.743
0.761

IB

0.798
0.767
0.903
0.844
0.929
0.848

Recall

NBC SVM TSVM
0.779
0.747
0.785
0.728
0.832
0.891
0.759
0.800
0.766
0.827
0.787
0.796

0.739
0.801
0.877
0.840
0.858
0.823

IB

0.817
0.782
0.906
0.873
0.859
0.847

F1-Measure
NBC SVM TSVM
0.762
0.748
0.776
0.730
0.834
0.887
0.677
0.792
0.703
0.867
0.794
0.761

0.738
0.792
0.876
0.745
0.797
0.790

IB

0.807
0.774
0.905
0.858
0.893
0.847

Table 4: Macro-average precision, recall and F1-measure for each classiﬁer on each binary classiﬁcation data
set. The training documents for NBC, SVM and IB are Xe and the test data for them are X T
c . TSVM is
trained on labeled Xe and unlabeled X T

c , and tested on X T
c .

Data Set

3 Categories
4 Categories
5 Categories

Average

NBC
0.647
0.445
0.550
0.547

Precision
IB

0.661
0.592
0.608
0.620

Recall

NBC
0.630
0.570
0.488
0.563

IB

0.665
0.648
0.582
0.632

F1-Measure
NBC
IB
0.638
0.500
0.517
0.552

0.663
0.619
0.627
0.636

Table 5: Macro-average precision, recall and F1-
measure for each classiﬁer on each multiple-class
classiﬁcation data set. The training documents for
NBC and IB are Xe and the test data for them are
X T
c . Note that, SVM and TSVM are not included
here, because they are designed for binary classiﬁ-
cation.

SVM and TSVM are not included here because they are de-
signed for binary classiﬁcation, and cannot cope well with
the multiple-class classiﬁcation problem. In this table, IB
still gives signiﬁcant improvements against the baseline method
NBC. Therefore, we believe our algorithm IB is not only ef-
fective for English-Chinese cross-language classiﬁcation, but
also extensible for multiple-class classiﬁcation.

 

Arts vs Computers
Recreation vs Science
3 Categories

1.00

0.95

0.90

0.85

0.80

0.75

0.70

0.65

e
r
u
s
a
e
m
−

F

1

 
0

5

10

15

20

Number of Iterations

25

30

Figure 6: The F1-measure curves after each iter-
ations on three data sets Arts vs Computers, Recre-
ation vs Science and 3 Categories respectively.

6.4 Convergence

Since our algorithm IB is an iterative algorithm, an impor-
tant issue for IB is the convergence property. Theorem 1 has
already proven the convergence of IB theoretically. Now, let
us empirically show the convergence property of IB. Figure
6 shows the test error rate curves as functions for each itera-
tion on three data sets, Arts vs Computers, Recreation vs
Science and 3 Categories. From the ﬁgure, it can be seen

that IB always achieves almost convergence points within 10
iterations. This indicates that IB converges very fast. We
believe that 10 iterations is empirically enough for IB.

7. CONCLUSIONS AND FUTURE WORK

The tremendous growth of the World Wide Web in China
has raised the need for classifying and organizing Chinese
Web space via classiﬁcation techniques.
In this paper we

976WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, Chinaput forward a technique for the Chinese Web mining task
to exploit the abundant labelled information in English. In
particular, we have developed a novel method known as the
information bottleneck technique to address the topic drift
and diﬀerent feature-space problems across two languages.
Our method brings out a common part between the Chinese
and English Web pages, which can be used to encode similar
pages in diﬀerent languages into the same codewords (class
labels). An iterative algorithm is presented to optimize the
objective function and therefore solve this problem. The
experimental results show that our method can eﬀectively
improve existing methods in general, including ﬁve binary
and three multi-class problems.

To extend our work, we wish to modify our method to
achieve a global optimal value. It is also interesting to con-
duct more experiments in other language pair (e.g. French vs
English, which does not suﬀer the word segmentation prob-
lem). Moreover, our method has the potential to be eﬀective
for the cross-language information retrieval problem.

8. ACKNOWLEDGEMENTS

Qiang Yang would like to thank the support of Hong Kong
RGC Grant 621307. We also thank the anonymous reviewers
for their great helpful comments.

9. REFERENCES
[1] Google translator.

http://www.google.com/language_tools.

[2] A. Banerjee, I. Dhillon, J. Ghosh, S. Merugu, and

D. S. Modha. A generalized maximum entropy
approach to bregman co-clustering and matrix
approximation. In Proceedings of the Tenth ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining, pages 509–514, 2004.

[3] N. Bel, C. Koster, and M. Villegas. Cross-Lingual Text
Categorization. Proceedings ECDL, 200:126–139, 2003.

[4] A. Blum and T. Mitchell. Combining labeled and

unlabeled data with co-training. In Proceedings of the
Eleventh Annual Conference on Computational
Learning Theory, pages 92–100, 1998.

[5] B. E. Boser, I. Guyon, and V. Vapnik. A training

algorithm for optimal margin classiﬁers. In
Proceedings of the Fifth Annual Workshop on
Computational Learning Theory, pages 144–152, 1992.
[6] T. M. Cover and P. E. Hart. Nearest neighbor pattern

classiﬁcation. IEEE Transactions on Information
Theory, 13:21–27, 1967.

[7] T. M. Cover and J. A. Thomas. Elements of

information theory. Wiley-Interscience, New York,
NY, USA, 1991.

[10] I. S. Dhillon, S. Mallela, and D. S. Modha.

Information-theoretic co-clustering. In Proceedings of
the Ninth ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, 2003.

[11] A. Gliozzo and C. Strapparava. Cross language Text

Categorization by acquiring Multilingual Domain
Models from Comparable Corpora. Proc. of the ACL
Workshop on Building and Using Parallel Texts (in
conjunction of ACL-05), 2005.

[12] T. Joachims. SVM light. Software available at

http://svmlight.joachims.org.

[13] T. Joachims. Transductive inference for text

classiﬁcation using support vector machines. In
Proceedings of the Sixteenth International Conference
on Machine Learning, pages 200–209, 1999.

[14] S. Kullback and R. A. Leibler. On information and

suﬃciency. Annals of Mathematical Statistics,
22(1):79–86, 1951.

[15] K. Lang. Newsweeder: Learning to ﬁlter netnews. In
Proceedings of the Twelfth International Conference
on Machine Learning, pages 331–339, 1995.
[16] D. D. Lewis. Reuters-21578 test collection.

http://www.daviddlewis.com/.

[17] D. D. Lewis. Representation and learning in

information retrieval. PhD thesis, Amherst, MA,
USA, 1992.

[18] Y. Li and J. Shawe-Taylor. Advanced learning

algorithms for cross-language patent retrieval and
classiﬁcation. Information Processing and
Management, 43(5):1183–1199, 2007.

[19] Y. Liu, Y. Fu, M. Zhang, S. Ma, and L. Ru.

Automatic search engine performance evaluation with
click-through data analysis. Proceedings of the 16th
international conference on World Wide Web, pages
1133–1134, 2007.

[20] X. Ni, G. Xue, X. Ling, Y. Yu, and Q. Yang. Exploring

in the weblog space by detecting informative and
aﬀective articles. Proceedings of the 16th international
conference on World Wide Web, pages 281–290, 2007.

[21] K. Nigam, A. K. McCallum, S. Thrun, and

T. Mitchell. Text classiﬁcation from labeled and
unlabeled documents using em. Machine Learning,
39(2-3):103–134, 2000.

[22] ODP. Open directory project. http://www.dmoz.com/.
[23] J. Olsson, D. Oard, and J. Hajiˇc. Cross-language text

classiﬁcation. Proceedings of the 28th annual
international ACM SIGIR conference on Research and
development in information retrieval, pages 645–646,
2005.

[24] M. F. Porter. An algorithm for suﬃx stripping.

Program, 14(3):130–137, 1980.

[8] M. Day, C. Ong, and W. Hsu. Question Classiﬁcation

[25] J. R. Quinlan. C4.5: Programs for Machine Learning.

in English-Chinese Cross-Language Question
Answering: An Integrated Genetic Algorithm and
Machine Learning Approach. In Proceedings of the
2007 IEEE International Conference on Information
Reuse and Integration, pages 203–208, 2007.

[9] I. S. Dhillon, S. Mallela, and R. Kumar. Enhanced

word clustering for hierarchical text classiﬁcation. In
Proceedings of the Eighth ACM SIGKDD
International Conference on Knowledge Discovery and
Data Mining, pages 191–200, 2002.

Morgan Kaufmann, 1993.

[26] L. Rigutini, M. Maggini, and B. Liu. An em based

training algorithm for cross-language text
categorization. In Proceedings of the 2005
IEEE/WIC/ACM International Conference on Web
Intelligence, pages 529–535, 2005.

[27] N. Slonim. The Information Bottleneck: Theory and

Applications. Unpublished doctoral dissertation,
Hebrew University, Jerusalem, Israel, 2002.

977WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, China[28] N. Slonim and Y. Weiss. Maximum likelihood and the

information bottleneck. Advances in Neural
Information Processing Systems, 15, 2002.

[29] N. Tishby, F. C. Pereira, and W. Bialek. The

information bottleneck method. In Proceedings of the
Thirty-seventh Annual Allerton Conference on
Communication, Control and Computing, pages
368–377, 1999.

[30] Y.-C. Wu, K.-C. Tsai, and J.-C. Yang. Two-pass

named entity classiﬁcation for cross language question
answering. In Proceedings of NTCIR-6 Workshop
Meeting, pages 168–174, 2007.

[31] Y. Yang and J. O. Pedersen. A comparative study on
feature selection in text categorization. In Proceedings
of Fourteenth International Conference on Machine
Learning, pages 144–152, 1997.

[32] X. Zhu. Semi-supervised learning literature survey.

Technical Report 1530, University of
Wisconsin–Madison, 2006.

APPENDIX
In this appendix, we provide the detailed proof to Lemmas
1 and 2, and Theorem 1.

A. PROOF TO LEMMA 1

Proof.

X
I(X; Y ) − I( ˜X; Y )
 X

y∈Y

p(x, y) log

X
X
X
X

˜x∈ ˜X

x∈˜x

X
X
X
X

y∈Y

x∈˜x

y∈Y

=

=

˜x∈ ˜X
−
X
X

˜x∈ ˜X

p(x, y) log

p(x, y) log
=
=D(p(X, Y )||˜p(X, Y )) .

˜x∈ ˜X

y∈Y

x∈˜x

p(x, y)
p(x)p(y)

!

p(x, y)

p(˜x, y) p(x)
p(˜x)
p(x, y)
˜p(x, y)

p(x, y)

log

p(˜x, y)
p(˜x)p(y)

x∈˜x

B. PROOF TO LEMMA 2
X
X

Proof.
D(p(X, Y )||˜p(X, Y )) =

X

˜x∈ ˜X

y∈Y

x∈˜x

p(x, y) log

p(x, y)
˜p(x, y)

.

Since

we have

˜p(x, y) = p(˜x, y)p(x|˜x) = p(˜x, y)

p(x)
p(˜x)
= p(x)p(y|˜x) = p(x)˜p(y|˜x) ,

D(p(X, Y )||˜p(X, Y )) =

=

=

X

x∈˜x

p(x)p(y|x) log
X

p(x)p(y|x)
p(x)˜p(y|˜x)
p(y|x)
˜p(y|˜x)
p(x)D(p(Y |x)||˜p(Y |˜x)) .

p(y|x) log

p(x)

y∈Y

X
X
X

˜x∈ ˜X

˜x∈ ˜X

y∈Y

X
X
X

x∈˜x

˜x∈ ˜X

x∈˜x

C. PROOF TO THEOREM 1
X
Proof. Based on Lemma 2, we have

X

X

D(p(X, Y )||˜p(t)

(X, Y )) =

p(x)

(t)

˜x:h

x∈˜x

y∈Y

From the Steps 6 and 9 in Algorithm 1,

p(y|x) log

p(y|x)
˜p(t)(y|˜x)

.

D(p(Y |x)||˜p(t−1)(Y |˜x))

arg min˜x∈ ˜X
h(t)(x) = h(t−1)(x)

x ∈ Xo
x ∈ Xi

.

j

h(t)

(x) =

Thus,

«

.

1

˜p(t)(y|˜x)

p(x)

(X, Y ))

X
X
D(p(X, Y )||˜p(t)
p(y|x) log
X
X
X
X

X
X
X

p(x)

y∈Y

y∈Y

x∈˜x

x∈˜x

(t+1)

˜x:h

˜x:h

(t)

p(y|x)

˜p(t)(y|h(t+1)(x))
p(y|x) log
„

p(y|x)
˜p(t)(y|˜x)
log p(y|x) + log

≥

=

=

(t+1)

˜x:h

˜x:h

Here, X
X
X
X

˜x:h

˜x:h

=

=

≥

p(x)

x∈˜x

y∈Y

p(y|x)
X
X

X
 X

x∈˜x

p(x)

(t+1)

(t+1)

x∈˜x

y∈Y

(t+1)

˜p(t+1)

˜p(t+1)

(˜x)

(˜x)

(t+1)

˜x:h

y∈Y

p(y|x) log
!

y∈Y
p(x)p(y|x)
X
X

˜p(t+1)

y∈Y

1

˜p(t)(y|˜x)

log

(y|˜x) log

1

˜p(t)(y|˜x)
1

˜p(t)(y|˜x)

˜p(t+1)

(y|˜x) log

1

˜p(t+1)(y|˜x)

.

Note that, the last inequality follows by the non-negativity
of the Kullback-Leibler divergence, that

X

y∈Y

˜p(t+1)

(y|˜x) log

1

˜p(t)(y|˜x)

−

X

y∈Y

˜p(t+1)

(y|˜x) log
(Y |˜x)||˜p(t)

= D(˜p(t+1)

Thus,

≥

D(p(X, Y )||˜p(t)
X
X

X
X

x∈˜x

(t+1)

p(x)

˜x:h

X
X

y∈Y

p(x)
=
y∈Y
=D(p(X, Y )||˜p(t+1)

x∈˜x

(t+1)

˜x:h

(X, Y ))

p(y|x)

„

log p(y|x) + log

p(y|x) log

p(y|x)

˜p(t+1)(y|˜x)

(X, Y )) .

1

˜p(t+1)(y|˜x)
(Y |˜x)) ≥ 0 .
«

1

˜p(t+1)(y|˜x)

978WWW 2008 / Alternate Track: WWW in China - Mining the Chinese WebApril 21-25, 2008 · Beijing, China