StatSnowball: a Statistical Approach to Extracting Entity

Relationships∗

Xiaojing Liu§

Bo Zhang †⋆

Ji-Rong Wen‡

Jun Zhu†⋆
†Dept. of Comp. Sci. & Tech.

Zaiqing Nie‡

Tsinghua University

Beijing, 100084 P.R China

{jun-zhu@mails,

dcszb@mail}.thu.edu.cn

‡Microsoft Research Asia

No. 49 Zhichun Road

Beijing, 100080 P.R China

{znie,jrwen}@microsoft.com

§Dept. of EEIS

University of Sci. & Tech. of

China

Hefei, 230027 P.R China

xiaojiangliu84@hotmail.com

ABSTRACT
Traditional relation extraction methods require pre-speciﬁed
relations and relation-speciﬁc human-tagged examples. Boot-
strapping systems signiﬁcantly reduce the number of train-
ing examples, but they usually apply heuristic-based meth-
ods to combine a set of strict hard rules, which limit the
ability to generalize and thus generate a low recall. Further-
more, existing bootstrapping methods do not perform open
information extraction (Open IE), which can identify var-
ious types of relations without requiring pre-speciﬁcations.
In this paper, we propose a statistical extraction framework
called Statistical Snowball (StatSnowball), which is a boot-
strapping system and can perform both traditional relation
extraction and Open IE.

StatSnowball uses the discriminative Markov logic net-

works (MLNs) and softens hard rules by learning their weights
in a maximum likelihood estimate sense. MLN is a general
model, and can be conﬁgured to perform diﬀerent levels of
relation extraction.
In StatSnwoball, pattern selection is
performed by solving an ℓ1-norm penalized maximum like-
lihood estimation, which enjoys well-founded theories and
eﬃcient solvers. We extensively evaluate the performance of
StatSnowball in diﬀerent conﬁgurations on both a small but
fully labeled data set and large-scale Web data. Empirical
results show that StatSnowball can achieve a signiﬁcantly
higher recall without sacriﬁcing the high precision during it-
erations with a small number of seeds, and the joint inference
of MLN can improve the performance. Finally, StatSnowball
is eﬃcient and we have developed a working entity relation
search engine called Renlifang based on it.

Categories and Subject Descriptors
I.5.1 [Pattern Recognition]: Models - Statistical

General Terms
Algorithms, Experimentation
∗This work was done when Jun Zhu and Xiaojiang Liu were
visiting Microsoft Research Asia.
⋆Jun and Bo are also with the State Key Laboratory of Intel-
ligent Technology and Systems; and the Tsinghua National
Laboratory for Information Science and Technology.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

Keywords
Relation extraction, statistical model, Markov logic networks

1.

INTRODUCTION

The World Wide Web has been growing rapidly as a huge
information repository, which contains various kinds of valu-
able semantic information about real-world entities, such as
people, organizations, and locations. We have been work-
ing on object-level search engines, which automatically ex-
tract and integrate the semantic information about entities
and return a list of ranked entities instead of webpages to
answer user queries [18]. In object-level search engines, it
is particularly important to mine entity relations from the
Web to automatically build an entity relationship graph to
link all the extracted information together. With the en-
tity relationship graph, users will be able to easily navigate
through their interested entities just like the way they nav-
igate through hyperlinked webpages. This paper focuses on
entity relation mining from the Web.
1.1 Motivating Example

We have deployed an entity relationship search engine in
Chinese search market called Renlifang1. Renlifang is a dif-
ferent kind of search engine we have been building, one that
explores relationships between entities. In Renlifang, users
can query the system about people, locations, and organi-
zations and explore their relationships. Currently Renlifang
only serves in the Chinese language domain. These entities
and their relationships are automatically mined from billions
of crawled Chinese webpages. For each crawled webpage in
Renlifang, the system extracts entity information and de-
tects relationships, covering a spectrum of everyday indi-
viduals and well-known people, locations, or organizations.
Below we list the key features of Renlifang:

Entity Relationship Mining and Navigation. Renli-
fang enables users to explore highly relevant information
during searches to discover interesting relationships about
entities associated with their queries.
Finding Expertise. Renlifang can return a ranked list of
people known for dancing or any other topic.
Web-Prominence Ranking. Renlifang detects the pop-
ularity of an entity and enables users to browse entities in
diﬀerent categories ranked by their prominence on the Web
during a given time period.
1http://renlifang.msra.cn

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods101it is crucial to select good patterns and good new seed tuples
to make sure the system will not be drifted by errors.

Although the bootstrapping architecture is promising, Snow-

ball has at least two obvious limitations, which make it
unsuitable for the Web-scale relation extraction as moti-
vated by Renlifang. First, since the target of Snowball is
to extract a speciﬁc type of relation (e.g., companies and
their headquarters) the extraction patterns in Snowball are
mainly based on strict keyword-matching. Although these
patterns can identify highly accurate results, the recall will
be limited. Second, Snowball does not have an elegant evalu-
ation measure, such as the probability/likelihood of a prob-
abilistic model, to evaluate generated patterns. The care-
fully crafted measures and pattern selection criteria are not
directly adaptable to general patterns (e.g., POS tag se-
quences), which can signiﬁcantly improve the recall as shown
in our empirical studies. This is because many tuples ex-
tracted by a general pattern are more likely not to be the
target relations of Snowball, although they can be other
types of relations.
In this case, the conﬁdence scores will
be very small, and it is inappropriate to use the criteria as
used in Snowball to select these patterns.

In this paper, we address these issues as suﬀered by Snow-
ball to improve the recall while keeping a high precision. We
present a system called Statistical Snowball (StatSnowball).
StatSnowball adopts the bootstrapping architecture and ap-
plies the recently developed feature selection method using
ℓ1-norm [25, 11] to select extraction patterns—both keyword
matching and general patterns. Starting with a handful set
of initial seeds, it iteratively generates new extraction pat-
terns; performs an ℓ1-norm regularized maximum likelihood
estimation (MLE) to select good patterns; and extracts new
relation tuples. StatSnowball is a general framework and the
statistical model can be any probabilistic model. StatSnow-
ball uses the general discriminative Markov logic networks
(MLN) [21], which subsume logistic regression (LR) and con-
ditional random ﬁelds (CRF) [15]. Discriminative models
can incorporate arbitrary useful features without strong in-
dependence assumptions as made in generative models, like
na¨ıve Bayes (NB) and Hidden Markov Models (HMM).

By incorporating general patterns, StatSnowball can per-
form both traditional relation extraction like Snowball to ex-
tract pre-speciﬁed relations and open information extraction
(Open IE) [3] to identify general types of relations. Open IE
is a novel domain-independent extraction paradigm, which
has been studied in both the natural language document
corpus [22] and the Web environment [3]. Although the ex-
isting Open IE systems are self-supervised, they require a
set of human-selected features in order to learn a good ex-
tractor. In contrast, StatSnowball automatically generates
and selects the extraction patterns. Moreover, the Open IE
systems require expensive deep linguistic parsing techniques
to correctly label training samples, while StatSnwoball only
uses cheaper and more robust shallow parsing techniques
to generate its patterns. Finally, by using the MLN model,
StatSnowball can perform joint inference, while the O-CRFs
[4] treat sentences independently. Our empirical studies
demonstrate the promise of using joint inference.

To the best of our knowledge, StatSnwoball is the ﬁrst
working system that takes a bootstrapping architecture and
applies the well-developed ℓ1-norm regularized MLE to in-
crementally identify entity relations. Speciﬁcally, we make
the following contributions:

Figure 1: An entity relationship graph for the query
“Bill Gates” generated by EntityCube (i.e. the En-
glish version of Renlifang).

People Bio Ranking. Renlifang ranks text blocks from
webpages by the likelihood of their being biography blocks.

Renlifang has been well received by Chinese Internet users

and mainstream media in China (including CCTV and Phoenix
TV) with positive comments and millions of daily page-views
during the peak days. The English version of Renlifang is
called EntityCube, and it is currently under development2.
In Figure 1, we show an automatically generated entity re-
lationship graph using our English Renlifang prototype.

Based on the overwhelming response from Chinese In-
ternet users of the Renlifang entity relationship search, we
found that automatically extracting a large number of highly
accurate entity relations is important to improve perfor-
mance. However, existing work on entity relation extrac-
tion in the literature could not meet the requirements of a
Web-scale entity relationship search engine.

Relation extraction has been promoted by the Message
Understanding Conference (MUCs) and Automatic Content
Extraction (ACE) program. The task has been tradition-
ally studied so as to extract predeﬁned semantic relations
between pairs of entities in text, e.g., in supervised learn-
ing methods [27, 8, 9, 26] and bootstrapping systems [5, 1].
Supervised methods require a set of relation-speciﬁc human
tagged examples to learn an extractor. Labeling training
examples is tedious and labor intensive, thus, it makes su-
pervised methods diﬃcult to apply to Web-scale applications
like Renlifang. Bootstrapping methods [5, 1, 7] signiﬁcantly
reduce the number of training examples by iteratively dis-
covering extraction patterns and identifying entity relations
with a small number of seeds, either target relation tuples [1]
or general extraction templates [7]. Take the well-known
Snowball [1], which serves as the basis of our proposed ap-
proach, as an example. Snowball takes a small set of seed
tuples as inputs, and employs the pattern-entity duality [5]
to iteratively generate extraction patterns and identify new
relation tuples. From the generated patterns and identiﬁed
tuples, some conﬁdence measures are carefully crafted to se-
lect good ones and add them to Snowball as new knowledge.
Evaluating patterns and tuples is one key component, since

2www.entitycube.com

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods102(a) We present a novel framework called StatSnowball by
using ℓ1-regularized feature selection to incrementally
discover extraction patterns and identify relation tuples.
Compared to the closely related Snowball, StatSnowball
contains the following advantages:

i StatSnowball can perform both traditional relation

extraction as in Snowball and Open IE.

ii The probabilistic foundation provides StatSnowball
a principled approach to evaluating and selecting
patterns. In Snowball, however, the conﬁdence mea-
sures lack an elegant interpretation and they are dif-
ﬁcult to be applied to general patterns.

iii StatSnowball automatically learns the weights of gen-
erated patterns, which are represented as formulae
in MLN, while Snowball applies some heuristic rules
to assign the weights.

iv StatSnowball can be easily extended. In current im-
plementation, StatSnowball takes the same strategy
as Snowball to separately identify named entities and
entity relations. StatSnowball can easily integrate
these two tasks into one probabilistic model and thus
can achieve a higher performance by exploring their
mutual enhancements. The promise of integrated
extraction has been shown in diﬀerent applications
[20, 28]. But the heuristic-based Snowball is hard
to be coherently integrated with the state-of-the-art
statistical named entity extraction systems.

(b) We extensively evaluate StatSnowball and empirically
show that StatSnowball can achieve a signiﬁcantly higher
precision and recall on large scale Web data.

(c) StatSnowball is eﬃcient and we have developed a work-

ing Entity Relation Search Engine based on it.

The rest of the paper is structured as follows. Section 2
brieﬂy overviews the StatSnowball system. Section 3 presents
the statistical model (i.e., Markov logic networks), includ-
ing some speeding up techniques. Section 4 presents how to
generate and select good patterns in StatSnowball. Section
5 presents our empirical results. Section 6 discusses some
related work, and Section 7 concludes this paper, with some
future work discussed.

2. OVERVIEW OF STATSNOWBALL

In this section, we brieﬂy overview the framework of Stat-
Snowball. Diﬀerent components will be explained in incom-
ing sections.

The task of StatSnowball is to identify relation tuples.
Each relation tuple can be among several entities. Here, we
only focus on the binary relationship, and an extraction is a
tuple (ei, ej, key) i 6= j, where ei and ej are two entities and
key is a set of keywords that indicate the relationship. Like
many other relation extraction systems [1, 8, 9], we assume
that the entities are given and focus on how to detect (i.e.,
decide whether a relationship exists between two entities)
and categorize (i.e., assign relation keywords to a detected
relationship) the relationships.

Figure 2 shows the architecture of StatSnowball. Gener-
ally, StatSnowball has three parts. The ﬁrst part P1 is the
input, which contains a set of seeds and an initial model.
The seeds are not required to contain relation keywords that

Initial Model

P1

P2

(e1, e2, key)
(e3, e4, ? )

...

augment seeds

(on-line)

learn model

select patterns

(on-line)

inference/extraction

generate patterns

P3

relation clustering

(e5, e6, key1)
(e3, e4, key2)

...

Figure 2: The framework of StatSnowball, with
three parts – P1 (input), P2 (statistical extraction
model), and P3 (output).

indicate the relationship. Thus, we have two types of seeds,
i.e., seeds with relation keywords like (e1, e2, key) or seeds
without relation keywords like (e3, e4, ?). If the initial model
is empty, we will ﬁrst use the seeds to generate extraction
patterns in order to start the process.

The second part P2 is the statistical extraction model.
To start the iterative extraction process, StatSnowball takes
the input seeds and the initial model (can be empty) in P1
to learn an extractor. We apply the ℓ2-norm regularized
maximum likelihood estimation (MLE) at this step. On-
line learning is an alternative if batch learning is expensive.
Then, StatSnowball uses the learned model to extract new
relation tuples on the data corpus. The third step in P2
is to generate extraction patterns with the newly identiﬁed
relation tuples. These patterns are used to compose formu-
lae of MLN. Finally, it selects good formulae to add to the
probabilistic model and re-train the model.
In this step,
we ﬁrst do ℓ1-norm regularized MLE, which will set some
formulae’s weights to zeros. Then, we remove these zero-
weighted formulae and send the resultant model to the next
step for re-training. StatSnowball iteratively performs these
four steps until no new extraction tuples are identiﬁed or
no new patterns are generated.
In this part, an optional
component is the augmenting seeds, which can be used to
ﬁnd more seeds to start the process. In order to get high
quality training seeds, this component applies strict keyword
matching rules. We do not use it in the current system.

The third part P3 is the output, which is necessary only
when StatSnowball is conﬁgured to do Open IE [3]. When
StatSnowball performs Open IE, the extraction results in P2
are general relation tuples. To make the results more read-
able, we can apply clustering methods to group the relation
tuples and assign relation keywords to them. The missing
keywords of the seeds can be ﬁlled in this part. Currently,
we treat it as a post-processing step. Recent work on re-
lational clustering with MLN in [14] suggests that we can

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods103move P3 into P2 to do joint Open IE. We will discuss this
more later.

Before going into the full exposition of the system, let’s
end this section with a strict mathematical formulation of
StatSnowball. Formally, StatSnowball iteratively solves an
ℓ1-norm regularized optimization problem:

P :

w

⋆ = arg min

w

LL(D, R, w) + λkwk1.

where LL(D, R, w) is the loss deﬁned on the corpus D given
a set of patterns (which are represented as formulae in the
probabilistic model as we shall see) R and the model weights
w; and k.k1 is the ℓ1-norm. The data corpus D and the
pattern set R are updated at each iteration. For D, by
changing, we mean that new relation tuples are identiﬁed.
For R, the change is in the sense that new patterns are
added. In the problem P, the loss can be the log-loss as used
in probabilistic models or the hinge loss as used in support
vector machines [6].
In this paper, we focus on the log-
loss. This ℓ1-norm regularized MLE problem yields a sparse
estimate by setting some components of w to exact zeros
[24, 11] and has eﬃcient solvers, such as the Orthant-Wise
Limited-memory Quasi-Newton (OWL-QN) method [2].

3. THE STATISTICAL MODEL

In this section, we deﬁne the task of entity relationship
identiﬁcation and present the probabilistic models we ap-
plied in StatSnowball, including the training and inference
(extraction) parts in P2.
3.1 Extraction Task

The task of StatSnowball is to identify related entity pairs
and detect the keywords that indicate the relationships. Like
many other relation extraction systems [1, 8, 9], we as-
sume that entities are given.
In probabilistic models, the
task of relation extraction is to predict whether two enti-
ties ei and ej have a relation R based on the probability
p(R(ei, ej )|O). For relation keyword detection, the task is to
predict whether a token is a relation keyword. In StatSnow-
ball, we deﬁne three ﬁelds (labels) that a token can belong
to, namely, REL-S: the start of a relation; REL-C: a contin-
uation of a relation; and NULL: not a relation keyword. We
assume that each token can belong to one ﬁeld. Then, re-
lation keyword detection is to predict in which ﬁeld (label)
f the token t is most likely to be based on the probabil-
ity p(InF ield(t, f )|O), where f ∈ {REL-S, RES-C, NULL},
and O denotes the observations that are available to make
the prediction. In discriminative models, O can be arbitrary
features of the inputs, e.g., the text content of a token or its
neighboring tokens.

Based on the power of available probabilistic models, we

can deﬁne the task at three diﬀerent levels:

a. Entity-Level: this is the simplest extraction model with
a strong independence assumption that whether two en-
tities have some relationship is independent of other enti-
ties and is also independent of relation keyword detection.
Logistic regression (LR) model is for this task.

b. Sentence-Level: since in human languages, the words
in a sentence are not independent of each other to express
a speciﬁc meaning, the independence assumption of the
Entity-Level model is too strong. A Sentence-Level model
relaxes this assumption and treats a sentence as a whole

input and jointly detects whether a pair of entities (if any)
in that sentence have some relationship and whether the
tokens around the entities indicate the relation type. One
example is presented in [4], where entities are assumed to
be at the ends of a sentence and the tokens in-between are
classiﬁed to be relation keywords or not by a linear-chain
CRF [15].

c. Page-Level or Corpus-Level: since the sentences in a
webpage or a text document are not completely indepen-
dent, it may be desirable to jointly extract these related
sentences. Joint inference has been shown to be eﬀective
to get globally consistent extraction results, such as [17,
28, 20]. Markov logic network (MLN) has the full power
to jointly model correlated data. We provide this alter-
native and will empirically demonstrate the advantages
of joint inference in StatSnowball.

As we have stated, we can use any probabilistic model
in StatSnowball. In order to accommodate the above three
levels of relationship extraction, StatSnowball adopts the
most general MLN model, which can be conﬁgured to do the
LR-based Entity-Level and the CRF-based Sentence-Level
relation extraction, as we shall see.
3.2 Markov Logic Networks

A ﬁrst-order knowledge base contains a set of formulae,
which are constructed using constants, variables, functions,
and predicates. Constants are the objects (e.g., entities and
tokens) in the interested domain and variables range over
the objects. For example, “Bob” and “Jim” are two people
entities, and “killed” is a token. e and t are variables which
denote an entity and a token, respectively. A function is a
mapping from a set of objects to objects (e.g., MotherOf(ei))
and a predicate represents a relation among objects (e.g.,
HasRelation(ei, ej) or some attributes (e.g., IsPeople(ei)).
An atom is a predicate applied to a set of arguments, which
are constants or variables. If an atom’s arguments are all
constants, it is a ground atom. A world is an assignment of
truth values to all possible ground atoms.

If a world violates one formula, it is impossible. Thus,
the formulae in a ﬁrst-order logic can be viewed as a set of
hard constraints on the possible worlds. Markov logic is a
probabilistic extension and softens the hard constraints by
assigning a weight to each formula. The weight indicates
how strong the corresponding formula is. When a world
violates some formulae it is less impossible, but not impos-
sible. For the task of entity relation extraction, we know
the query predicates and the evidence predicates a prior.
Thus, we partition the ground atoms into two sets—the set
of evidence atoms X and the set of query atoms Q, and de-
ﬁne a discriminative MLN [23]. Discriminative models have
shown great promise as compared to generative models in
many applications [15, 23]. In StatSnowball, X can be all
the possible features we can extract from the inputs, and Q
can be all the relationship queries R(ei, ej), ∀i 6= j and key-
word detection queries InF ield(t, f ) ∀t, f . Given an input
x (e.g., a sentence and its features), the discriminative MLN
deﬁnes a conditional distribution p(q|x) as follows:
wigj(q, x)(cid:17),

exp(cid:16) X

p(q|x) =

X

(1)

1

Z(w, x)

i∈FQ

j∈Gi

where FQ is the set of formulae with at least one grounding
involving a query atom, Gi is the set of ground formulae of

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods104the ith ﬁrst-order formula, and Z(w, x) is a normalization
factor, also known as partition function in physics. gj(q, x)
is a binary function and equals to 1 if the jth ground formula
is true and 0 otherwise.

Markov Logic Networks have the power of ﬁrst-order logic
to model complex relational databases. In the experiments,
we will show examples of using MLN to do joint inference in
StatSnowball. In StatSnowball, we apply the discriminative
learning algorithm [23, 10] to learn the model weights with a
sphere Gaussian prior, or equivalently the ℓ2-norm penalized
MLE, to avoid over-ﬁtting.

3.2.1 Special Case 1: Logistic Regression

As we have stated, logistic regression (LR) is the sim-
plest Entity-Level extraction model. It makes a strong in-
dependence assumption that entity pairs are independent
of each other to have some relationship. Also, the exis-
tence of a relationship is independent of relation keyword
detection. By restricting all the formulae in MLN to be
the ones in which the query predicates can appear ONLY
ONCE, the resultant MLN reduces to an LR model, and the
distribution in Eq. (1) has the factorized form: p(q|x) =
Qij p(R(ei, ej )|xij)Qt p(InF ield(t, ft)|xt), of which each com-
ponent is an exponential family distribution. For example,
p(R(ei, ej )|xij) has the exponential form: p(R(ei, ej)|xij ) ∝
exp(cid:0) Pi∈FR Pj∈Gi
wigj(R(ei, ej ), xij)(cid:1), where FR are the
formulas in which the query predicate R appears. The ob-
servations are the inputs xij related to the entities ei and
ej . For relation keyword detection, p(InF ield(t, f )|xt) has
the similar distribution form.

3.2.2 Special Case 2: CRFs

In a Sentence-Level extraction model, entities and the
tokens in the same sentence are not independent. With-
out context tokens, we cannot decide whether two entities
in a sentence have some relationship. On the other hand,
whether a token is a relation keyword is dependent on its
surrounding tokens. For example, for the sentence “Google
forced to buy YouTube.”, which contains the entities “Google”
and “YouTube”, the verb “buy” indicates an acquirement re-
lationship between the two entities and the verb “forced” is
not a relation keyword because the following “buy” is more
likely to be. The LR model cannot consider this mutual de-
pendence information.
Instead, for Sentence-Level extrac-
tion, we need to apply the linear-chain conditional random
ﬁelds (CRFs) [15]. The MLN reduces to a linear-chain CRF
by deﬁning the following ﬁrst-order formulae:

InField(ti, REL-S) ∧ Verb(ti+1) => InField(ti+1, REL-C),

which means when a token is the start of a relation (REL-S),
then the following verb is more likely to be a continuation of
the relation (REL-C). One application of CRFs to identify
relation keywords is presented in [4].
3.3 Formulating Extraction Queries

The second step of the part P2 is to extract new rela-
tion tuples, which is an inference problem in probabilis-
tic models. Suppose the current MLN model is M. For
each pair of entities (ei, ej), we use M to predict whether
a relationship exists between ei and ej with the probability
p(R(ei, ej )|xij, M). For each token t, we use M to predict
whether t is a relation keyword. Here, the query R(ei, ej)
is a binary predicate and equals to 1 if a relationship ex-

ists between ei and ej and 0 otherwise. Thus, it is nat-
ural to use the probability p(R(ei, ej )|xij, M) as a conﬁ-
dence measure of the identiﬁed new tuple. We can choose a
threshold c and keep the candidate extraction (ei, ej) only
if p(R(ei, ej)|xij, M) > c. The higher the c, the stricter the
decision rule is. If a high c is chosen during the iterations of
StatSnowball, only high-quality relation tuples are selected
and passed to the next step for generating patterns. For re-
lation keyword detection, the query InF ield(t, f ) is ternary.
We predict each token t to the label f which has the highest
probability, that is, f ⋆ = arg maxf p(InField(t, f )|xt, M).
Similar to the use of p(R(ei, ej)|M), we can use the proba-
bility as a conﬁdence measure of the extraction.

3.3.1 Speeding Up Techniques

For the probabilistic models we are using in StatSnow-
ball, the computational cost of both training and inference
mainly depends on two factors—the number of queries and
the complexity of the model. Since the number of relation
keyword detection queries is linear to the number of tokens,
we only consider the relation query R. For logistic regres-
sion, the model is very simple and the cost depends on how
many relation queries are formulated. For the linear-chain
structured CRF [15],
it is also very eﬃcient to do infer-
ence and learning by using dynamic programming methods.
Moreover, as a Sentence-Level extraction model, the number
of relation queries in CRFs is linear to the number of sen-
tences. For the general MLN, its complexity depends on the
number of formulae and their formulations. As we shall see,
StatSnowball only generates very simple formulae. Thus,
the cost mainly depends on the number of relation queries.
Na¨ıvely formulating all possible relation queries for ev-
ery combination of two entities, as in the current Alchemy3,
the whole number of queries is quadratic to the number of
entities in a corpus for both LR and MLN. In our appli-
cation of relation extraction, only when the entities appear
within a short range, they could have enough evidence to
indicate some relation between them. For two isolated en-
tities, even human readers could have diﬃculty in deciding
whether they have a relationship. Thus, we make some gen-
tle assumptions in StatSnowball. For example, in Page-Level
extraction models, we can assume that only the entities ap-
pearing in the same webpage/document are likely to have
some relationship. When formulating the relation queries,
entities in diﬀerent pages/documents are not considered as
a candidate. Similarly, for Sentence-Level extraction mod-
els, we can assume that only entities appearing in the same
sentences are likely to have relations; otherwise, they do
not. These assumptions can signiﬁcantly reduce the num-
ber of queries. For example, suppose we have 200 entities
in a corpus of 20 webpages and uniformly each page has 10
entities. Without any assumptions, the number of possible
queries will be 200 × 200 (4 × 104) for all the combinations
of two entities. If we make the assumption that only the en-
tities in the same page are possible to be related, then only
20 × 10 × 10 (2 × 103 or 5 percent) queries are possible to
be relation tuples. All the other queries are discarded and
consume no resources.

With the above independence assumption, an on-line learn-
ing method can be used for the learning of MLN. We imple-
mented this technique for the learning of MLN too.

3http://alchemy.cs.washington.edu.

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods1054. GENERATE AND SELECT PATTERNS

In this section, we present how to generate and select good

extraction patterns in StatSnowball.
4.1 Pattern Generation

Generating new extraction patterns, which are used to
compose the formulae of MLNs, is a key component of Stat-
Snowball. A good pattern should achieve a good balance
between two competitive criteria—speciﬁcity and coverage.
Speciﬁcity means the pattern is able to identify high-quality
relation tuples; while coverage means the pattern can iden-
tify a statistically non-trivial number of good relation tu-
ples. In Snowball, the generated patterns are mainly based
on keyword matching. These strict patterns can have very
high precision, but the coverage (i.e., recall) is very low. As
we have stated, there are two reasons why Snowball cannot
eﬀectively incorporate general patterns, which can signiﬁ-
cantly improve the recall as we shall see. First, Snowball was
originally proposed to extract a speciﬁc type of relationship,
for example, companies and their headquarters [1]. In this
case, general patterns can yield many invalid extractions,
although these extractions could be other types of valid re-
lation tuples. Second, Snowball deﬁnes some measures and
criteria which are not applicable to general patterns. For
pattern evaluation, Snowball deﬁnes a conﬁdence measure
as the ratio of positive extractions of that pattern. For gen-
eral patterns, the conﬁdence scores could be very small, and
it is diﬃcult to select these patterns by using a threshold.

Instead of deﬁning some heuristic measurements, Stat-
Snowball applies probabilistic models and renders the pat-
tern selection as the ℓ1-norm regularized optimization prob-
lem P. Under this framework, we can treat strict keyword
matching patterns and general patterns identically. Also,
by using general patterns, StatSnowball can be conﬁgured
to perform open information extraction, as we have stated.
In our experiments, we evaluate both the Open IE and
Snowball-like extraction with StatSnowball.

4.1.1 Keyword-matching Patterns

In our system, the keywords are from two parts. The
ﬁrst part is from the initial seeds. As shown in Figure 2,
users can provide seeds with some keywords to indicate the
relationships. We take these keywords to deﬁne candidate
patterns, e.g., a candidate pattern should contain at least
one of these keywords. The second parts of the keywords
are those that are automatically discovered during the Stat-
Snowball extraction process. To make the patterns more
informative, we only consider three types of keywords as in
Table 1 according to the part-of-speech (POS) tags, where
MIN OCCUR is pre-speciﬁed number, e.g., 20. Here, we use
the same naming system as the Penn Treebank Project 4.

4.1.2 General Patterns

Our general extraction patterns are all based on a shal-
low natural language processing (NLP) technique—part-of-
speech tagging (POS). Much work has been done to inves-
tigate the usability of shallow or deep linguistic structures
for various application tasks such as named entity extrac-
tion [7], and relationship identiﬁcation [9, 8]. In contrast to
deep natural language processing, shallow NLP techniques

4http://www.ling.upenn.edu/courses/Fall 2003/ling001/pe
nn treebank pos.html

are more robust and more eﬃcient. This is a very impor-
tant factor for Web-scale relation extraction as in Renlifang.
Thus, StatSnowball only uses the part-of-speech tagging re-
sults. All the sentences in our data sets are parsed using a
part-of-speech tagger. Our general patterns are the POS-tag
sequences appearing between entities.

Note that the above two types of patterns are not neces-
sarily independent of each other. For example, the general
pattern “POS+NP/NN” can be seen as a keyword matching
pattern too because only one token is tagged as POS (i.e.,
possessive ending), that is, “’s”.
4.2 Pattern Selection

Selecting patterns is a feature induction problem of Markov
random ﬁelds or Markov networks [19, 16].
In MLN, the
problem is called structure learning [12]. Alchemy uses a
generative approach to learning the structure of MLN by
using beam search to generate candidate formulae and se-
lecting good candidates according to the gain in (weighted)
pseudo-likelihood. In StatSnowball, we apply the ℓ1-norm
regularized MLE as deﬁned in the problem P and do dis-
criminative structure learning [10]. As we have stated, the
ℓ1-norm penalty encourages a sparse estimate [25].

Speciﬁcally, we ﬁrst use the generated patterns to formu-
late a set of candidate formulae of MLN. Then, we apply
the algorithm [2] to optimize the ℓ1-norm penalized condi-
tional likelihood function as in the problem P, which yields
a sparse model by setting some formulae’s weights to zeros.
The zero-weighted formulae are discarded and the resultant
model is passed to the next step for re-training.

Our method can be viewed as a simpliﬁed variant of the
discriminative structure learning [10]. Since our patterns
(i.e., predicates) have been generated, we can generate the
candidate formulae easily instead of applying an ILP system
such as Aleph to do this from scratch. Here, we generate the
formulae with the N -nary (e.g., binary or ternary) combi-
nation of the patterns. As in [10], we restrict the formulae
to be non-recursive deﬁnite clauses, in which query predi-
cates only appear once. Under this constraint, the model is
equivalent to a logistic regression model with a set of auto-
matically generated features (i.e., extraction patterns). For
complex formulae, which contain multiple query predicates
and can be used for joint inference in MLN, we do not au-
tomatically generate them because these formulae are very
general and the number of these patterns is very small, as
we shall see in the experiments. We manually design these
formulae and add them to the model in each iteration of
StatSnowball.

To compare with, we also use a heuristic-based method
in our experiments to select patterns. Speciﬁcally, we use
the generated patterns and formulate a set of candidate for-
mulas. Then, we apply some heuristic rules to select these
formulas and learn the resultant model’s weights. For exam-
ple, a formula will be selected if the number of its covered
instances is above a certain threshold (e.g., 10).

5. EXPERIMENTS

In this section, we report some empirical results of Stat-
Snowball with diﬀerent conﬁgurations. We compare Stat-
Snowball with O-CRFs [4] for Open IE and show the advan-
tages of joint inference by using MLN in StatSnowball. We
also compare StatSnowball with Snowball on a large Web
data corpus for traditional relation extraction. We show that

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods106Table 1: Types of keywords, their requirements, and examples in pattern generation

Types Requirements

VB
IN
POS

not stop word and occur more than MIN OCCUR times
if the token appear more than MIN OCCUR times and the previous token is a noun phrase
the following token is a noun phrase

Example
(e1, killed, e2)
(e1, mother of, e2)
(e1, ’s mother, e2)

by elegantly incorporating general patterns, StatSnowball
achieves signiﬁcantly higher precision and recall. Finally,
StatSnowball is eﬃcient and has been applied to Renlifang.

5.1 Data Sets

Our experiments are performed on two data sets. The
ﬁrst one is the published corpus [4] and will be referred
to as Sent500. This data set contains 500 sentences and
each sentence has one pair of entities (noun phrases).
In
[4], CRFs are used to do sequence labeling and identify the
words that represent a relationship between the two entities.
The second corpus is built from the MSN news crawler. To
remove noise, such as page heads, navigation bars, etc., we
ﬁrst partition the crawled webpages into blocks using a vi-
sual parser [28]. The blocks in the center of a webpage are
selected to compose our data set. All the text sentences in
the blocks are parsed using a part-of-speech tagger to get
the POS tagging results. We collect 1 million such blocks
and will refer to this data set as Web1M.

5.2 Methods and Results

We report the experiments and results on two data sets

separately as follows.

On Sent500, we perform two types of experiments. The
ﬁrst experiment is to demonstrate the advantages of MLNs
over CRFs. In [4], CRFs are used to label the words between
two entities (noun phrases) as a sequence labeling problem.
In this experiment, we apply the MLN to do the similar se-
quence labeling task but with joint inference and show its
advantages. The second experiment is to use StatSnowball
to do Open IE and identify the unknown entity relation-
ships. We compare StatSnowball with O-CRFs [4]. We also
compare two StatSnowball systems with diﬀerent pattern se-
lection methods, i.e., the ℓ1-norm regularized pattern selec-
tion and heuristic-based pattern selection. We will refer to
these two StatSnowball systems as ℓ1StatSnowball and heS-
tatSnowball, respectively. As in [4], we evaluate on four cat-
egories of relations, that is, Verb, Noun+Prep, Verb+Prep,
and Inﬁnitive.

On Web1M, we conﬁgure StatSnowball to do the tradi-

tional relation extraction and compare it with Snowball.

5.2.1 Joint Inference with MLNs on Sent500

We compare MLNs and CRFs on Sent500 to do sequence
labeling on sentences and label tokens to be REL-B, REL-
C, or NULL. The set of features used in this experiment are
similar to the features as used in O-CRFs [4], including POS
tags, token relative position and context features. In CRFs,
sentences are labeled independently. To do joint inference in
MLN, we ﬁrst group the sentences according to the similar-
ity between their tokens. In total, 76 groups are identiﬁed in
Sent500. For similar tokens (i.e., tokens in the same group),
we deﬁne the following formula to do collective labeling:

SimiToken(t1, t2) ∧ F1(t1) ∧ F2(t2) ∧ InField(t1, +f )
⇒ InField(t2, +f ),

Table 2: Evaluation results of MLNs with joint in-
ference and the basic CRFs on the Sent500 data set

Categories

P 0.978
CRF R 0.776
F1 0.865
P
0.963
MLN R 0.768
0.854

F1

verb noun+prep verb+prep inﬁnitive overall
0.882
0.755
0.813
0.929
0.816
0.869

0.962
0.855
0.905
0.960
0.911
0.935

0.751
0.719
0.734
0.922
0.901
0.911

0.836
0.670
0.744
0.870
0.684
0.766

where the predicate SimiT oken(ti, tj) is true if ti is similar
to tj, false otherwise. Basically, this formula says that simi-
lar tokens (grouped together) should have the same label if
they also have some token-level features Fi.

We will refer to the above two methods as CRF and MLN
respectively. Table 2 shows the average results over 10 runs.
In each run of the basic CRF, we randomly select 50 percent
of the sentences as training and test on the rest (diﬀerent
from the experiments in [4]). For the joint MLN, we ran-
domly select a half of the groups as training data and test
on the rest. From the results, we can see that the joint infer-
ence in MLN performs much better, almost on all the four
categories, than the CRF model, which treats the sentences
independently. The performance of MLN on Verb is slightly
worse than that of CRF.

5.2.2 StatSnowball on Sent500 for Open IE

As we have stated, StatSnowball can be conﬁgured to do
Open IE. Here, we compare StatSnowball on the Sent500
with the state-of-the-art Open IE system, that is, O-CRFs
[4]. All the patterns used in StatSnowball are the general
POS tag sequences, except that we use the preposition key-
words (like “in” and “of”) to distinguish the tokens that are
tagged as “IN” by the POS tagger. We randomly select 30
sentences as initial seeds for the two StatSnowball systems
that use diﬀerent pattern selection methods (i.e., ℓ1-norm
regularized and heuristic based methods). The results are
shown in Table 3, where the results of O-CRFs are from the
original paper [4], and the results of StatSnowball systems
are the average results over 10 runs. For the ℓ1StatSnowball,
using diﬀerent regularization constants (i.e., λ) during the
iterations could improve the performance. In all the exper-
iments, we do not tune the parameter but set λ at 0.5.

From the results, we can see that the O-CRFs generally
achieve higher precisions, especially on “Verb+Prep” and
“Inﬁnitive”.
In contrast, StatSnowball systems achieve a
better balance between recall and precision. Thus, the over-
all F1 of both StatSnowball systems are signiﬁcantly bet-
ter than that of the O-CRFs. Also, we can see that the
heuristic-based pattern selection method works much worse
than the ℓ1-norm regularized pattern selection method in
StatSnowball.

Figure 3 shows the performance of the two StatSnowball
systems with respect to the number of iterations. The re-
sults are from one run. We do not take the average over 10

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods107Table 3: Evaluation results of diﬀerent models on the Sent500 data set

Categories

O-CRFs [4]

F1

Recall

Precision 0.939
0.651
0.769
Precision 0.956
0.810
0.875
Precision 0.929
0.846
0.886

F1

Verb Noun+Prep Verb+Prep Inﬁnitive Overall
0.883
0.452
0.598
0.790
0.581
0.669
0.798
0.733
0.764

0.957
0.468
0.629
0.456
0.192
0.233
0.418
0.320
0.362

0.952
0.500
0.656
0.583
0.344
0.397
0.617
0.575
0.595

0.891
0.360
0.513
0.704
0.495
0.538
0.815
0.782
0.799

F1

heStatSnowball Recall

ℓ1StatSnowball Recall

i

i

n
o
s
c
e
r
P

1

0.95

0.9

0.85

0.8

0.75

0.7

0.65

0.6

 
1

 

l
l

a
c
e
R

0.8

0.75

0.7

0.65

0.6

0.55

0.5

0.45

4

0.4

 
1

 

0.8

0.75

0.7

0.65

1
F

0.6

0.55

0.5

0.45

4

0.4

 
1

 

4

L1−norm
Heuristic

2

3

Iteration

L1−norm
Heuristic

2

3

Iteration

L1−norm
Heuristic

2

3

Iteration

Figure 3: The performance (precision, recall, and
F1) of the two StatSnowball systems with diﬀerent
pattern selection methods during the iteration.

runs because diﬀerent runs can have various iteration num-
bers, e.g., from 4 to 10. We can see that during the iteration,
both systems can ﬁnd more relation tuples. Moreover, the
precision of heStatSnowball decreases a lot, while the preci-
sion of ℓ1StatSnowball does not change much, although with
a slight decrease. Overall, the F1 curve of ℓ1StatSnowball is
consistently above that of heStatSnowball. Also, the former
is increasing and the latter decreases a little.

5.2.3 Joint Inference in StatSnowball

Similar to the ﬁrst experiment using MLN to do joint
inference, we incorporate the joint inference to StatSnow-
ball. We do not automatically generate these joint inference
formulae. This is because the joint inference formulae are
general and the number is very small (only 1 as shown in
Section 5.2.1). Thus, it would be much harder to automati-
cally generate these formulae and also it may cause diﬃculty
in selecting them. Instead, we apply a simple strategy here.
We manually deﬁne these joint formulae as in Section 5.2.1.
During the iterations of StatSnowball, we automatically gen-
erate and select the simpler formulae, each of which contain
only one query predicate, and add the joint formula to the
resultant model to learn an MLN for joint inference.

For the joint StatSnowball, the sentences in Sent500 are
grouped as in Section 5.2.1. We randomly select 10, 15, and
25 groups as starting seeds, and take the average over 10 runs
as the ﬁnal results. Table 4 shows the overall performance of
the ℓ1StatSnowball with joint inference, the heStatSnowball
with joint inference, and the ℓ1StatSnowball without joint
inference.

From the results, we can see that the ℓ1StatSnowball with
joint inference always performs the best compared to the
other two systems. Also, for all the three systems, the per-
formance consistently gets better when more seeds are pro-
vided. Similar to Figure 3, Figure 4 shows the performance
of the two StatSnowball systems with joint inference with

Table 4: Overall performance of diﬀerent systems
with diﬀerent number of initial seeds.

# groups

10

15

25

ℓ1StatSnowball

P 0.735 0.806 0.806
R 0.635 0.717 0.755
(no joint inference) F1 0.681 0.758 0.779
P 0.769 0.788 0.828
heStatSnowball
R 0.691 0.696 0.748
(joint inference) F1 0.728 0.739 0.786
P 0.822 0.816 0.873
R 0.772 0.784 0.804
ℓ1StatSnowball
(joint inference) F1 0.796 0.800 0.837

1

0.95

0.9

0.85

0.8

0.75

0.7

0.65

0.6

 
1

 

l
l

a
c
e
R

0.8

0.75

0.7

0.65

0.6

0.55

0.5

0.45

4

0.4

 
1

 

0.8

0.75

0.7

0.65

1
F

0.6

0.55

0.5

0.45

4

0.4

 
1

 

4

L1−norm
Heuristic

2

3

Iteration

L1−norm
Heuristic

2

3

Iteration

L1−norm
Heuristic

2

3

Iteration

i

i

n
o
s
c
e
r
P

Figure 4: The performance (precision, recall, and
F1) of the two StatSnowball systems with joint in-
ference during the iteration.

respect to the number of iterations, and the results are from
one of the ten runs. We can see that the ℓ1-norm regular-
ized pattern selection method consistently outperforms the
heuristic-based method, especially on recall and F1.

5.2.4 Results on Web1M

Since for the large data corpus Web1M, labeling all the
relations is impractical, it is diﬃcult to quantitatively eval-
uate the Open IE as in [4]. To give a quantitative analysis of
StatSnwoball, we conﬁgure it to extract predeﬁned relations,
as in the traditional use of Snowball. Here, we focus on the
“Wife” and “Husband” relationships. We want to identify all
the entity pairs (ei, ej), where ei is the wife or husband of
ej.

Similar to the previous evaluations, the relation extrac-
tion is a sequence labeling problem. But in this task, we
predict the tokens between each entity pair as either REL-R
(i.e., a relation keyword) or NULL. Our extraction patterns
are based on both the general POS tags and the strict key-
word matching. For example, we use the POS tag sequence
between the entity pairs as a candidate extraction pattern.

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods108To get a high precision, in all the systems we will evaluate
we only generate the patterns that contain at least one of
the relation keywords provided with the initial seeds.

As we have stated, the MLN model in StatSnowball has
the great ﬂexibility to do joint inference. Here, we provide
another example of using StatSnowball to perform joint re-
lation extraction. In this experiment, the two types of rela-
tionships we are concerned with are strongly correlated. For
example, if e1 is the husband of e2, then e2 is more likely to
be the wife of e1 if we ignore the issue that multiple entities
can have the same name. We incorporate this prior knowl-
edge of dependency into the MLN model in StatSnowball by
deﬁning the following formula:

IsHusband(e1, e2) ⇒ IsWife(e2, e1).

Using this formula, the MLN can jointly extract the two
types of relations. We refer to this system as StatSnowball
(Joint) and refer to the StatSnowball without the above for-
mula as StatSnowball (Basic). Similar to the previous use of
StatSnowball for joint inference (see Section 5.2.3), we only
generate formulae that contain only one query predicate and
manually add the above formula during the iterations.

The original Snowball system [1] uses strict keyword match-
ing patterns. To see how the performance changes with gen-
eral patterns, we conﬁgure another Snowball system with
additional general patterns based on POS tags. We refer to
this Snowball system as PosSnowball. The evaluation crite-
ria of patterns and extraction tuples in PosSnowball are the
same as those in the original Snowball.

To start the iteration process, StatSnowball (Joint) uses
30 seeds (15 wife seeds and 15 husband seeds). All the other
systems perform the extraction of “Wife” and “Husband”
separately with the corresponding seeds. All the extracted
tuples are sent to human readers to judge whether they are
correct extractions. Figure 5 shows the number of correct
tuples and the precision of the identiﬁed tuples with respect
to the number of iterations. From the results, we can see
that StatSnwoball systems identify much more correct rela-
tion tuples with a signiﬁcantly higher precision on all the
identiﬁed tuples than the Snowball systems, especially the
Snowball using only keyword-matching patterns.
It is in-
teresting to note that by using the simple joint inference
formula as deﬁned above in StatSnowball, we can ﬁnd more
accurate tuples, but with a slightly lower precision compared
to the StatSnowball without this formula. The results of
PosSnowball show that using general POS tag-based pat-
terns can signiﬁcantly improve the recall. Finally, during
the iterations, although the number of correct tuples grows
in Snowball systems, the precision decreases very quickly.
In StatSnowball, however, we can get more correct tuples
without sacriﬁcing the high precision.

The StatSnowball is eﬃcient. It takes about 50 minutes
to ﬁnish the experiments on Web1M with a standard single-
core desktop computer. That means 1 billion Web blocks
can be processed by StatSnowball within 1 day by using
9 quad-core desktop computers. We have built an entity
relation search engine, as shown in the introduction, which
indexes the entities (people, locations, and organizations)
and their relationships extracted from 10M Web blocks.

6. RELATED WORK

Relation extraction has been promoted by the Message
Understanding Conference and Automatic Content Extrac-

l

 

s
e
p
u
T
d
o
o
G
#

 

550

500

450

400

350

300

250

200

150

100

 

Snowball
PosSnowball
StatSnowball (Basic)
StatSnowball (Joint)

50

 
1

2

3

4

Iteration

5

6

i

i

n
o
s
c
e
r
P

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

 
1

 

Snowball
PosSnowball
StatSnowball (Basic)
StatSnowball (Joint)

2

3

4

5

6

Iteration

Figure 5: The number of correct relation tuples (left
plot) and the precision of the extracted results by
diﬀerent methods.

tion program. The task has been traditionally studied as
to extract predeﬁned semantic relations between pairs of en-
tities in text. The supervised methods [27, 8, 9, 26] re-
quire a set of human-tagged examples of the predeﬁned re-
lations. Bootstrapping methods [5, 1, 7] signiﬁcantly reduce
the number of training examples by iteratively discovering
new extraction patterns and identifying entity relations with
a small set of seeds, either target relation tuples [1] or gen-
eral extraction templates [7]. However, the system [1] only
generates patterns that are mainly based on keyword match-
ing and its evaluation criteria are also speciﬁc to these strict
high-precision but low-recall patterns. Another bootstrap-
ping system—KnowItAll [7] requires large numbers of search
engine queries and webpage downloads.

Open information extraction (Open IE) [3] is a domain
independent extraction paradigm and has been studied in
both the natural language document corpus [22] and the
Web environment [3] to extract relation tuples. Open IE
can extract unknown relations from heterogeneous corpora.
As we have stated, StatSnowball diﬀers from the Open IE
methods in several aspects. For example, Open IE systems
require human-selected features to learn a good extractor,
while StatSnowball automatically generates and selects the
extraction patterns; Open IE systems require the use of deep
linguistic parsing techniques to correctly label training sam-
ples, while StatSnwoball only uses cheaper and more robust
shallow parsing techniques to generate its patterns; and the
start-of-the-art Open IE system—O-CRFs [3] use CRFs to
label each sentences independently, but StatSnowball can
perform joint inference, which can yield better extraction
results.

Pattern selection in StatSnowball is the problem of struc-
ture learning in Markov logic networks [12] or the prob-
lem of feature induction in Markov random ﬁelds [19, 16].
Similar to the feature induction of MRFs, where features
are assumed to be composed from basic features, structure
learning [12] is studied under the assumption that candi-
date formulas can be constructed from predicates via some
operators like addition and ﬂipping. Statistic predicate in-
vention in Markov logic networks, also known as hidden vari-
able discovery in statistical learning, is studied in [13], which
can generate and select new predicates that are expressed in
terms of existing ones via iterative clustering. Both struc-
ture learning and statistical predicate invention can be too
expensive to be applied to a large data set. The discrimina-
tive structure learning of MLN [10] applies ℓ1-norm regular-
ized MLE to select candidate formulas generated by a ﬁrst-

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods109order logic induction system. In StatSnowball, we generate
the candidate formulas iteratively from extracted relation
tuples.

[8] C. Giuliano, A. Lavelli, and L. Romano. Exploiting
shallow linguistic information for relation extraction
from biomedical literature. In EACL, 2006.

7. CONCLUSIONS AND DISCUSSIONS

This paper presents a statistical entity relation extraction
system called StatSnowball. By adopting a bootstrapping ar-
chitecture, StatSnowball signiﬁcantly reduces the number of
human-tagged examples. By elegantly incorporating general
extraction patterns, StatSnowball can signiﬁcantly improve
the recall and can be conﬁgured to perform open informa-
tion extraction (Open IE). StatSnowball uses the general re-
lational model—Markov logic networks (MLNs), which can
be conﬁgured to perform diﬀerent levels of relation extrac-
tion and can perform joint inference. Our empirical studies
show that by using joint inference in MLN and StatSnow-
ball, performance can be improved. Finally, by applying the
ℓ1-norm regularized maximum likelihood estimation, which
enjoys well-founded theories and eﬃcient solvers, StatSnow-
ball is eﬃcient and can perform well on large scale Web
data. We have built an entity relationship search engine
called Renlifang based on it.

The statistical StatSnowball opens broad ways for future
improvements and extensions. Currently, we apply a named
entity extraction method to process the data sets to get
the entities. It is interesting to integrate StatSnowball with
named entity extraction methods and build a self-contained
extraction system. This tightly integrated approach allows
information ﬂow between two tasks and can obtain better
performance by using joint inference [28, 17, 20]. Similarly,
the optional P3 part in StatSnowball can be integrated into
P2 as suggested by the relational clustering methods [14].

8. ACKNOWLEDGMENTS

The authors Jun and Bo are supported by Chinese Nature
Science Foundation Grant 60621062 and 60605003; National
Key Foundation R&D Projects 2003CB317007, 2004CB318108
and 2007CB311003; and Basic Research Foundation of Ts-
inghua National Lab for Info Sci & Tech. Jun is also sup-
ported by a Microsoft Fellowship.

9. REFERENCES
[1] E. Agichtein and L. Gravano. Snowball: Extracting

relations from large plain-text collections. In
International Conference on Digital Libraries, 2000.

[2] G. Andrew and J. Gao. Scalable training of

l1-regularized log-linear models. In ICML, 2007.

[3] M. Banko, M. Cafarella, S. Soderland, M. Broadhead,
and O. Etzioni. Open information extraction from the
web. In IJCAI, 2007.

[4] M. Banko and O. Etzioni. The tradeoﬀs between open

and traditional relation extraction. In ACL, 2008.

[5] S. Brin. Extracting patterns and relations from the
world wide web. In International Workshop on the
Web and Databases, 1998.

[6] C. Cortes and V. Vapnik. Support-vector networks.

Machine Learing, 20:273–297, 1995.

[7] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu,

T. Shaked, S. Soderland, D. S. Weld, and A. Yates.
Unsupervised named-entity extraction from the web:
An experimental study. Artiﬁcial Intelligence,
165(1):91–134, 2005.

[9] A. Harabagiu, C. A. Bejan, and P. Morˇarescu. Shallow

semantics for relation extraction. In IJCAI, 2005.

[10] T. N. Huynh and R. J. Mooney. Dsicriminative

structure and parameter learning for markov logic
networks. In ICML, 2008.

[11] A. Kaban. On Bayesian classiﬁcation with laplace

priors. Pattern Recognition Letters, 28(10):1271–1282,
2007.

[12] S. Kok and P. Domingos. Learning the structure of

markov logic networks. In ICML, 2005.

[13] S. Kok and P. Domingos. Statistical predicate

invention. In ICML, 2007.

[14] S. Kok and P. Domingos. Extracting semantic

networks from text via relational clustering. In ECML,
2008.

[15] J. Laﬀerty, A. McCallum, and F. Pereira. Conditional

random ﬁelds: Probabilistic models for segmenting
and labeling sequence data. In ICML, 2001.

[16] A. McCallum. Eﬃciently inducing features of

conditional random ﬁelds. In UAI, 2003.

[17] A. McCallum and D. Jensen. A note on the uniﬁcation

of information extraction and data mining using
conditional probability, relational models. In
IJCAI-2003 Workshop on Learning Statistical Models
from Relational Data, 2003.

[18] Z. Nie, J.-R. Wen, and W.-Y. Ma. Object-level

vertical search. In CIDR, 2007.

[19] S. D. Pietra, V. D. Pietra, and J. Laﬀerty. Inducing

features of random ﬁelds. IEEE Trans. on PAMI,
1997.

[20] H. Poon and P. Domingos. Joint inference in

information extraction. In AAAI, 2007.

[21] M. Richardson and P. Domingos. Markov logic

networks. Machine Learing, 62(1-2):107–136, 2006.

[22] Y. Shinyama and S. Sekine. Preemptive information

extraction using unrestricted relation discovery. In
HLT/NAACL, 2006.

[23] P. Singla and P. Domingos. Discriminative training of

markov logic networks. In AAAI, 2005.

[24] C. H. Teo, Q. Le, A. Smola, and S. Vishwanathan. A

scalable modular convex solver for regularized risk
minimization. In SIGKDD, 2007.

[25] R. Tibshirani. Regression shrinkage and selection via

the LASSO. J. Royal. Statist. Soc., B(58):267–288,
1996.

[26] D. Zelenko, C. AoneE, and A. Richardella. Kernel

methods for relation extraction. Journal of Machine
Learning Research, (3):1083–1106, 2003.

[27] G. Zhou, M. Zhang, D. H. Ji, and Q. Zhu. Tree

kernel-based relation extraction with context-sensitive
structured parse tree information. In EMNLP-CoNLL,
2005.

[28] J. Zhu, Z. Nie, J.-R. Wen, B. Zhang, and W.-Y. Ma.
Simultaneous record detection and attribute labeling
in web data extraction. In SIGKDD, 2006.

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods110