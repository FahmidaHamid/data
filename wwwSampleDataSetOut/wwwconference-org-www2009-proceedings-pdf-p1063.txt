Interactive Search in XML Data

Department of Computer Science and Technology, Tsinghua National Laboratory for Information

Lizhu Zhou
Guoliang Li
Science and Technology, Tsinghua University, Beijing 100084, China

Jianhua Feng

{liguoliang,fengjh,dcszlz}@tsinghua.edu.cn

ABSTRACT
In a traditional keyword-search system in XML data, a user
composes a keyword query, submits it to the system, and
retrieves relevant subtrees. In the case where the user has
limited knowledge about the data, often the user feels “left
in the dark” when issuing queries, and has to use a try-
and-see approach for ﬁnding information. In this paper, we
study a new information-access paradigm for XML data,
called “Inks,” in which the system searches on the underly-
ing data “on the ﬂy” as the user types in query keywords.
Inks extends existing XML keyword search methods by in-
teractively answering keyword queries. We propose eﬀective
indices, early-termination techniques, and eﬃcient search al-
gorithms to achieve a high interactive speed. We have imple-
mented our algorithm. The experimental results show that
Inks achieves high search eﬃciency and result quality.
Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval—query formulation, search process
General Terms
Algorithms, Experimentation, Performance
Keywords
XML, Keyword Search, Interactive Search, Autocomplete
1.

INTRODUCTION

Keyword search provides a simple and user-friendly query
interface to access XML data in web and scientiﬁc appli-
cations [4, 2, 8, 7, 5, 6].
In an existing XML keyword
search system, a user composes a query, submits it to the
system, and retrieves relevant answers. This information-
access paradigm requires the user to have certain knowledge
about the content of the underlying data. In the case where
the user has limited knowledge about the data, often the
user feels “left in the dark” when issuing queries, and has to
use a try-and-see approach for ﬁnding information. Many
systems are introducing various features to solve this prob-
lem. One of the commonly used methods is autocomplete,
which predicts a word or phrase that the user may type in
based on the partial string the user has typed.

In this paper, we extend autocomplete and propose an in-
teractive keyword-search method in XML data, called Inks.
Inks searches XML data on the ﬂy as users type in queries

Copyright is held by the author/owner(s).
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

Inks can signiﬁcantly save users typing eﬀort.

and provides a friendly interface for users exploring XML
data.
In
contrast, one limitation of autocomplete is that the system
treats a query with multiple keywords as a single string, thus
it does not allow keywords to appear at diﬀerent places. For
instance, consider the search box on Apple.com. Although
a query “itunes” can ﬁnd a record “itunes wi-ﬁ music store,”
a query “itunes music” cannot ﬁnd this record, because the
two keywords appear at diﬀerent places. CompleteSearch [1]
interactively searches on a set of documents. Inks extends
autocomplete and CompleteSearch to ﬁnd relevant subtrees
in XML data by supporting multiple keywords.

We give an example to show how Inks works. Assume
there is an XML document that resides on a server. A user
accesses and searches the data through a Web browser. Each
keystroke that the user types invokes a query, which includes
the current string the user has typed. The browser sends the
query to the server, which computes and returns to the user
the best answers ranked by their relevancy to the query.

Assume a user types in a query “db mic” letter by letter
on the XML data in Figure 1. The string is tokenized to
keywords using delimiters. The keywords are assumed as
partial keywords, as the user may have not ﬁnished typing
the complete keyword. For the partial keywords, we would
like to know the possible words the user intends to type. We
identify a set of words with this partial keyword as a preﬁx.
This set of keywords are called the predicted words. For
instance, for the partial keyword “mic,” its predicted word
could be “mices,” “mich,” etc. Then based on the predicted
words, we identify the relevant subtrees in XML data that
contain the predicted words. We call these relevant subtrees
predicted answers. Apparently, Inks can signiﬁcantly save
users time and eﬀorts, since they can ﬁnd answers even if
they have not ﬁnished typing all complete keywords.
2. LCA-BASED INTERACTIVE SEARCH

We propose a lowest common ancestor(LCA) based interactive-

search method. We use the semantics of exclusive LCA
(ELCA) [4] to identify relevant answers for predicted words.
We use a trie to index the tokenized words in XML data.

For a query with a single keyword, we ﬁrst ﬁnd the cor-
responding trie node. Then we locate the leaf descendants
of this node, and retrieve the corresponding predicted words
and the predicted XML elements on their inverted lists. For
a query with multiple keywords, we ﬁrst tokenize the query
string into keywords, k1, k2, . . . , k(cid:2). For each keyword ki
(1 ≤ i ≤ (cid:2)), there are multiple predicted words. Suppose
there are qi predicted words for ki, and their correspond-
ing XML element lists are Ii1 , Ii2 , . . . , Iiqi . We ﬁst com-

WWW 2009 MADRID!Poster Sessions: Wednesday, April 22, 200910631

bib

2
conf

20
jour

3
name

4
year

5

paper

15
paper

19
chair

21
name

22
year

23
paper

27
chair

WWW 2009

Lucy

TOIS

6
title

8

7
author bib

16
title

17
author author

18

2008

24
title

Mary
26

25

author author

XML IR

Bob

10
name

9
conf

11
year

IR DB Tom Smith Tohn Mich

XML IR

Tohn Smith

Lucy Mich

12
paper

S I G M O D

2008

13
title

14
author

DB

Tom Mices

Figure 1: An XML document

pute the predicted XML element lists of the partial keyword,
i.e., the union of these lists Ui = ∪qi
j=1Iij . Then, we com-
pute the predicted answers, i.e., the subtrees of ELCAs on
U1, U2,··· , U(cid:2). We use the binary search based method to
compute ELCAs and corresponding answers [8]. We use the
tf*idf based ranking functions [4] to rank the answers.

Assume a user types in a query “db mic” letter by letter.
For query “d,” we locate the trie node for “d” and identify
predicted word “db” and predicted XML elements 13 and
16 on its leaf descendants. For query “db m,” we identify
predicted words “mices” and “mich” for“m” and predicted el-
ements 14, 18, and 26. Finally, we compute ELCAs on {13,
16} and {14, 18, 26} and get XML elements 12 and 15.
3. PROGRESSIVE SEARCH

Existing XML keyword-search algorithms [4] have two
main limitations. First, they use the default “AND” seman-
tics between input keywords. Second, they ﬁnd candidate
nodes ﬁrst before ranking them, and this approach is not
eﬃcient for computing the best answers.

To address these limitations, we develop novel ranking
techniques and eﬃcient search algorithms. In our approach,
each node on the XML tree could be potentially relevant to
a keyword query. For each keyword in the tree, we index
not only the content nodes containing the keyword, but also
those quasi content nodes whose descendants contain the
keyword. Given a keyword and node n, a pivotal node is a
content node for the keyword, which has a minimal distance
to n. The path from node n to this node is called the pivotal
path. We introduce the notion of minimal-cost tree (MCT
for short) to deﬁne the answer to the query for node n. The
minimal-cost tree is the subtree rooted at n that includes all
pivotal paths for input keywords and node n.

For example, for “DB,” we index nodes 13, 16, 12, 15, 9, 2,
8, 1, and 5, sorted by relevance. For “Tom,” we index nodes
14, 17, 12, 15, 9, 2, 8, 1, and 5. Node 13 is the pivotal
node for node 12 and “DB,” and its pivotal path is 12-13.
Node 14 is the pivotal node for node 12 and “Tom,” and its
pivotal path is 12-14. For query “DB Tom,” to identify the
top-2 answers, we ﬁrst ﬁnd nodes 12 and 15 based on the
index and then construct MCTs based on pivotal paths.

Now we discuss how to rank an MCT. Intuitively, we ﬁrst
evaluate the relevance between node n and each input key-
word, and then combine these relevance scores as the overall
score of the MCT. We can use the idea of tf*idf to score the
relevance of the content nodes, but cannot rank a quasi con-
tent node. Given a quasi content node, we combine its piv-
otal node’s tf*idf score and the distance between the quasi
content node and its pivotal node for eﬀective ranking.

We propose how to do progressive search in considering
“OR” predicate. In the trie index, for leaf nodes, we keep
content nodes and quasi content nodes, and corresponding
scores and pivotal paths, sorted by their scores. For each

internal node, we cache top-n relevant ones among (quasi)
content nodes in its subtree. Given a query, for each key-
word, we ﬁrst locate the corresponding node on the trie.
Then, we retrieve top-n (cached) relevant elements. We use
the threshold-based algorithm [3] to identify the top-k an-
If we can guarantee that we have found the top-k
swers.
answers using the cached elements, we can do early termi-
nation; otherwise, we retrieve the predicted XML elements
and use the threshold-based method to ﬁnd top-k answers.
4. EXPERIMENTAL STUDY

We have implemented our method on real dataset DBLP
with the size of 470 MB. We set up a server using Apache and
FastCgi. The server was running a program implemented in
C++ using a GNU compiler. We conducted the evaluation
on a PC running a Ubuntu Linux with an Intel(R) Xeon(R)
CPU X5450@3.00 GHz CPU and 4 GB RAM. We selected
ten queries on the dataset. We ﬁrst evaluate result qual-
ity by human judgement. Answer relevance of the selected
queries was judged from discussions of twenty randomly se-
lected person. Figure 2 shows the top-10 precision. We
observe that the progressive method achieves higher result
quality than LCA based methods (We implemented XRank
to generate answers for LCA based methods). This is at-
tributed to our eﬀective ranking functions. We then evalu-
ate the server running time. Figure 3 gives the total server
time for diﬀerent queries. We observe that our progressive
method achieves higher eﬃciency.

)

%

(
 
n
o
i
s
i
c
e
r
P
0
1
-
p
o
T

 

)
s

m

 

i

(
 
e
m
T
d
e
s
p
a
l
E

 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0

LCA
Progressive

 1

 2

 3

 4

 5

 6

 7

 8

 9

 10

Figure 2: Top-10 precision

Queries

 400
 350
 300
 250
 200
 150
 100
 50
 0

LCA
Progressive

 1

 2

 3

 4

 5

 6

 7

 8

 9

 10

Figure 3: Elapsed server time

Queries

5. ACKNOWLEDGEMENT

This work is partly supported by the National High Tech-
nology Development 863 Program of China under Grant
No.2007AA01Z152, the National Grand Fundamental Re-
search 973 Program of China under Grant No.2006CB303103,
and 2008 HP Labs Innovation Research Program.
6. REFERENCES

[1] H. Bast and I. Weber. Type less, ﬁnd more: fast autocompletion

search with a succinct index. In SIGIR, pages 364–371, 2006.

[2] S. Cohen, J. Mamou, Y. Kanza, and Y. Sagiv. Xsearch: A

semantic search engine for xml. In VLDB, pages 45–56, 2003.

[3] R. Fagin. Fuzzy queries in multimedia database systems. In

PODS, pages 1–10, 1998.

[4] L. Guo, F. Shao, C. Botev, and J. Shanmugasundaram. Xrank:

Ranked keyword search over xml documents. In SIGMOD
Conference, pages 16–27, 2003.

[5] G. Li, J. Feng, J. Wang, and L. Zhou. Eﬀective keyword search

for valuable lcas over xml documents. In CIKM, pages 31–40,
2007.

[6] Z. Liu and Y. Chen. Identifying meaningful return information

for xml keyword search. In SIGMOD Conference, pages
329–340, 2007.

[7] C. Sun, C. Y. Chan, and A. K. Goenka. Multiway slca-based

keyword search in xml data. In WWW, pages 1043–1052, 2007.

[8] Y. Xu and Y. Papakonstantinou. Eﬃcient keyword search for

smallest lcas in xml databases. In SIGMOD Conference, pages
537–538, 2005.

WWW 2009 MADRID!Poster Sessions: Wednesday, April 22, 20091064