Click Chain Model in Web Search

∗

Fan Guo1

, Chao Liu2, Anitha Kannan3, Tom Minka4, Michael Taylor4, Yi-Min Wang2,

Christos Faloutsos1

fanguo@cs.cmu.edu,

(cid:2)

@microsoft.com,

1Carnegie Mellon University, Pittsburgh PA 15213, USA
2Microsoft Research Redmond, WA 98052, USA
3Microsoft Research Search Labs, Mountain View CA 94043, USA
4Microsoft Research Cambridge, CB3 0FB, UK

(cid:3)
chaoliu,ankannan, minka, mitaylor, ymwang

christos@cs.cmu.edu

ABSTRACT
Given a terabyte click log, can we build an eﬃcient and ef-
fective click model? It is commonly believed that web search
click logs are a gold mine for search business, because they
reﬂect users’ preference over web documents presented by
the search engine. Click models provide a principled ap-
proach to inferring user-perceived relevance of web docu-
ments, which can be leveraged in numerous applications in
search businesses. Due to the huge volume of click data,
scalability is a must.

We present the click chain model (CCM), which is based
on a solid, Bayesian framework. It is both scalable and in-
cremental, perfectly meeting the computational challenges
imposed by the voluminous click logs that constantly grow.
We conduct an extensive experimental study on a data set
containing 8.8 million query sessions obtained in July 2008
from a commercial search engine. CCM consistently outper-
forms two state-of-the-art competitors in a number of met-
rics, with over 9.7% better log-likelihood, over 6.2% better
click perplexity and much more robust (up to 30%) predic-
tion of the ﬁrst and the last clicked position.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval—retrieval models

General Terms
Algorithms, Experimentation

1.

INTRODUCTION

Billions of queries are submitted to search engines on the
Important attributes of these search ac-
web every day.
tivities are automatically logged as implicit user feedbacks.
These attributes include, for each query session, the query
string, the time-stamp, the list of web documents shown in
the search result and whether each document is clicked or
not. Web search click logs are probably the most extensive,
albeit indirect, surveys on user experience, which can be
∗
summer internship with Microsoft Research.

Part of this work was done when the ﬁrst author was on a

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009,  A pril  20–24,  2009,  Madrid,  S pain.
ACM 978-1-60558-487-4/09/04.

aggregated over weeks, months and even years. Extracting
key statistics or patterns from these tera-byte logs is of much
interest to both search engine providers, who could obtain
objective measures of user experience and useful features to
improve their services, and to world wide web researchers,
who could better understand user behavior and calibrate
their hypotheses and models. For example, the topic of uti-
lizing click data to optimize search ranker has been well ex-
plored and evaluated by quite a few academic and industrial
researchers since the beginning of this century (e.g. , [2, 8,
14, 15, 17]).

A number of studies have been conducted previously on
analyzing user behavior in web search and their relationship
to click data. Joachims et al. [9, 10] carried out eye-tracking
experiments to study participants’ decision process as they
scan through search results, and further compared implicit
click feedback against explicit relevance judgments. They
found that clicks are accurate enough as relative judgement
to indicate user’s preferences for certain pairs of documents,
but they are not reliable as absolute relevance judgement,
i.e. ,“clicks are informative but biased”. A particular ex-
ample is that users tend to click more on web documents in
higher positions even if the ranking is reversed [10]. Richard-
son et al. [16] proposed the examination hypothesis to ex-
plain the position-bias of clicks. Under this hypothesis, a
web document must be examined before being clicked, and
user-perceived document relevance is deﬁned as the con-
ditional probability of being clicked after being examined.
Top ranked documents may have more chance to be exam-
ined than those ranked below, regardless of their relevance.
Craswell et al. [4] further proposed the cascade model for de-
scribing mathematically how the ﬁrst click arises when users
linearly scan through search results. However, the cascade
model assumes that users abandon the query session after
the ﬁrst click and hence does not provide a complete picture
of how multiple clicks arise in a query session and how to
estimate document relevance from such data.

Click models provide a principled way of integrating knowl-
edge of user search behaviors to infer user-perceived rele-
vance of web documents, which can be leveraged in a number
of search-related applications, including:

• Automated ranking alterations: The top-part of
ranking can be adjusted based on the inferred rele-
vance so that they are aligned with users’ preference.
• Search quality metrics: The inferred relevance and
user examination probabilities can be used to compose

WWW 2009 MADRID!Track: Data Mining / Session: Click Models11search quality metrics, which correlate with user sat-
isfaction [6].
• Adaptive search: When the meaning of a query
changes over time, so do user click patterns. Based
on the inferred relevance that shifts with click data,
the search engine can be adaptive.
• Judge of the judges: The inferred ﬁrst-party rele-
vance judgement could be contrasted/reconciled with
well-trained human judges for improved quality.
• Online advertising: The user interaction model can
be adapted to a number of sponsored search applica-
tions such as ad auctions [1, 11].

idr

i(cid:79)

Examine(cid:3)Next(cid:3)

Document

Click(cid:3)

Through?

Yes

See(cid:3)More(cid:3)
Results?

No

Done

No

Yes

No

Reach(cid:3)the(cid:3)

End?

Yes

Done

An ideal model of clicks should, in addition to enabling
reliable relevance inference, have two other important prop-
erties - scalability and incremental computation; Scalability
enables processing of large amounts (typically, terabytes) of
clicklogs data and the incremental computation enables up-
dating the model as new data are recorded.

Two click models are recently proposed which are based
on the same examination hypothesis but with diﬀerent as-
sumptions about user behaviors. The user browsing model
(UBM) proposed by Dupret and Piwowarski [5] is demon-
strated to outperform the cascade model in predicting click
probabilities. However, the iterative nature of the inference
algorithm of UBM requires multiple scans of the data, which
not only increases the computation cost but renders incre-
mental update obscure as well. The dependent click model
(DCM) which appears in our previous work [7] is naturally
incremental, and is an order of magnitude more eﬃcient than
UBM, but its performance on tail queries could be further
improved.

In this paper, we propose the click chain model (CCM),

that has the following desirable properties:

• Foundation: It is based on a solid, Bayesian frame-
work. A closed-form representation of the relevance
posterior can be derived from the proposed approxi-
mation inference scheme.
• Scalability: It is fast and nimble, with excellent scala-
bility with respect to both time and space; it can also
work in an incremental fashion.
• Eﬀectiveness: It performs well in practice. CCM con-
sistently shows performance improvements over two of
the state-of-the-art competitors in a number of eval-
uation metrics such as log-likelihood, click perplexity
and click prediction robustness.

The rest of this paper is organized as follows. We ﬁrst sur-
vey existing click models in Section 2, and then present CCM
in Section 3. Algorithms for relevance inference, parameter
estimation and incremental computation are detailed in Sec-
tion 4. Section 5 is devoted to experimental studies. The
paper is concluded in Section 6.

2. BACKGROUND

We ﬁrst introduce deﬁnitions and notations that will be
used throughout the paper. A web search user initializes a
query session by submitting a query to the search engine.
We regard re-submissions and reformulations of the same
query as distinct query sessions. We use document impres-
sion to refer to the web documents (or URLs) presented in
the ﬁrst result page, and discard other page elements such as
sponsored ads and related search. The document impression

Figure 1: The user model of DCM, in which rdi is
the relevance for document di at position i, and λi
is the conditional probability of examining the next
position after a click at position i.
can be represented as D = {d1, . . . , dM} (usually M = 10),
where di is an index into a set of documents for the query.
A document is in a higher position (or rank) if it appears
before those in lower positions.

Examination and clicks are treated as probabilistic events.
In particular, for a given query session, we use binary ran-
dom variables Ei and Ci to represent the examination and
click events of the document at position i,respectively. The
corresponding, examination and click probabilities for posi-
tion i are denoted by P (Ei = 1) and P (Ci = 1), respectively.
The examination hypothesis [16] can be summarized as

follows: for i = 1, . . . , M ,

P (Ci = 1|Ei = 0) = 0,
P (Ci = 1|Ei = 1) = rdi ,

where rdi , deﬁned as the document relevance, is the condi-
tional probability of click after examination. Given Ei, Ci is
conditionally independent of previous examine/click events
E1:i−1, C1:i−1. It helps to disentangle clickthroughs of var-
ious documents as being caused by position and relevance.
Click models based on the examination hypothesis share this
deﬁnition but diﬀer in the speciﬁcation of P (Ei).

The cascade hypothesis in [4] states that users always start
the examination at the ﬁrst document. The examination is
strictly linear to the position, and a document is examined
only if all documents in higher positions are examined:

P (E1 = 1) = 1,
P (Ei+1 = 1|Ei = 0) = 0.

Given Ei, Ei+1 is conditionally independent of all exam-
ine/click events above i, but may depend on the click Ci.

The cascade model [4] puts together previous two hypothe-

ses and further constrain that

P (Ei+1 = 1|Ei = 1, Ci) = 1 − Ci,

(1)

which implies that a user keeps examining the next docu-
ment until reaching the ﬁrst click, after which the user sim-
ply stops the examination and abandons the query session.
We ﬁrst introduce the dependent click model (DCM) [7].
Its user model is illustrated in Figure 1. It generalizes the
cascade model to multiple clicks by putting position-dependent
parameters as conditional probabilities of examining the next

WWW 2009 MADRID!Track: Data Mining / Session: Click Models12document after a click, i.e. , Eq. 1 is replaced by

P (Ei+1 = 1|Ei = 1, Ci = 1) = λi
P (Ei+1 = 1|Ei = 1, Ci = 0) = 1,

(2)
(3)
where {λi|1 ≤ i ≤ M − 1} are the user behavior parameters
in the model and are shared across query sessions. The
probability of a query session is therefore

P (C1:M ) =

(rdi λi)

Ci (1 − rdi )1−Ci

(cid:6)

·

l(cid:4)

(cid:5)

i=1

(cid:5)

M(cid:4)

(cid:6)

,

(4)

1 − λl + λl

(1 − rdj )

M(cid:4)

j=l+1

where l = arg max1≤i≤M{Ci = 1} is the last clicked position
in the query session. If there is no click, l is set to 0 in the
equation above. This suggests that the user would scan the
entire list of search results, which is a major limitation in
the modeling assumption of DCM.

The user browsing model (UBM) [5] is also based on the
examination hypothesis, but does not follow the cascade hy-
pothesis.
Instead, it assumes that the examination prob-
ability Ei depends only on the previous clicked position
li = arg maxl<i{Cl = 1} as well as the distance i − li:

P (Ei = 1|C1:i−1) = γli,i−li .

(5)

Given click observations C1:i−1, Ei is conditionally indepen-
dent of all previous examination events E1:i−1. If there is no
click before i, li is set to 0. Since 0 ≤ li < i ≤ M , there are
a total of M (M + 1)/2 user behavior parameters γ, which
are again shared among all query sessions. The probability
of a query session under UBM is

P (C1:M ) =

(rdi γli,i−li )

Ci (1 − rdi γli,i−li )1−Ci .

(6)

i=1

Maximium likelihood (ML) learning of UBM is an order of
magnitude more expensive than DCM in terms of time and
space cost. Under DCM, we could keep 3 suﬃcient statis-
tics, or counts, for each query-document pair, and an addi-
tional 3(M − 1) counts for global parameter estimation [6].
However, for UBM with a more complicated user behavior
assumption, we should keep at least (1+M (M +1)/2) counts
for each query-document pair and an additional (1+M (M +
1)/2) counts for global parameter estimation. In addition,
under our implementation (detailed in Appendix A), the al-
gorithm usually takes dozens of iterations until convergence.
A most recent related work is a DBN click model pro-
posed by Chapelle and Zhang [3], which appears as an-
other paper in this proceeding. The model still satisﬁes the
examination and cascade hypotheses as DCM does. The
diﬀerence is the speciﬁcation of examine-next probability
P (Ei+1 = 1|Ei = 1, Ci). Under this DBN model, (1) the
only user behavior parameter in the model is denoted by γ,
and P (Ei+1 = 1|Ei = 1, Ci = 0) = γ; (2) two values are as-
sociated with each query-document pair. For one of them,
denoted by sdi , P (Ei+1 = 1|Ei = 1, Ci = 1) = γ(1 − sdi ),
whereas the other one, denoted by adi is equivalent to doc-
ument relevance under the examination hypothesis: P (Ci =
1|Ei = 1) = adi . These two values are estimated under ap-

proximate ML learning algorithms. Details about the mod-
eling assumption and algorithmic design are available in [3].

Examine(cid:3)Next(cid:3)

Document

Click(cid:3)

Through?

Yes

iR

See(cid:3)More(cid:3)
Results?

No
Done

No

Yes
1(cid:68)

See(cid:3)More(cid:3)
Results?

No

Done

Yes
R
i

(cid:68)
2

(cid:11)
1

(cid:16)

(cid:12)

(cid:14)

(cid:68)
3

R
i

Figure 2: The user model of CCM, in which Ri is the
relevance variable of di at position i, and α’s form
the set of user behavior parameters.

R1

E1

C1

R2

E2

C2

R3

E3

C3

R4

E4

C4

…

…

…

Figure 3: The graphical model representation of
CCM. Shaded nodes are observed click variables.

3. CLICK CHAIN MODEL

The CCM model is based on generative process for the
users interaction with the search engine results, illustrated
as a ﬂow chart in Figure 2, and as a generative model in
Figure 3. User starts the examination of the search result
from the top ranked document. At each position i, the user
can choose to click or skip the document di according to the
perceived relevance. Either way, the user can choose to con-
tinue the examination or abandon the current query session.
The probability of continuing to examine di+1 depends on
her action at the current position i. Speciﬁcally, if the user
skips di, this probability is α1; on the other hand, if the
user clicks di, the probability to examine di+1 depends on
the relevance Ri of di and range between α3 and α2.

CCM shares the following assumptions with the cascade
model and DCM: (1) users are homogeneous: their informa-
tion needs are similar given the same query; (2) decoupled
examination and click events: click probability is solely de-
termined by the examination probability and the document
relevance at a given position; (3) cascade examination: ex-
amination is in strictly sequential order with no breaks.

CCM distinguishes itself from other click models by do-
ing a proper Bayesian inference to infer the posterior dis-
tribution of the document relevance.
In CCM, document
relevance Ri is a random variable between 0 and 1. Model
training of CCM therefore includes inferring the posterior
distribution of Ri and estimating user-behavior parameters
α’s. The posterior distribution may be particularly helpful
for applications such as automated ranking alterations be-
cause it is possible to derive conﬁdence measures and other
useful features using standard statistical techniques.

In the graphical model of CCM shown in Figure 3, there

WWW 2009 MADRID!Track: Data Mining / Session: Click Models13are three layers of random variables: for each position i, Ei
and Ci denote binary examination and click events as usual,
where Ri is the user-perceived relevance of di. The click
layer is fully observed from the click log. CCM is named
after the chain structure of variables representing the se-
quential examination and clicks through each position in the
search result.

The following conditional probabilities are deﬁned in Fig-

ure 3 according to the model assumption:
P (Ci = 1|Ei = 0) = 0
(7)
P (C1 = 1|Ei = 1, Ri) = Ri
(8)
P (Ei+1 = 1|Ei = 0) = 0
(9)
P (Ei+1 = 1|Ei = 1, Ci = 0) = α1
(10)
P (Ei+1 = 1|Ei = 1, Ci = 1, Ri) = α2(1 − Ri) + α3Ri (11)
To complete the model speciﬁcation we let P (E1 = 1) = 1
and document relevances Ri’s are iid and uniformly dis-
tributed within [0, 1], i.e. , p(Ri) = 1 for 0 ≤ Ri ≤ 1. Note
that in the model speciﬁcation, we did not put a limit on
the length of the chain structure. Instead we allow the chain
to go to inﬁnite, with the examination probability diminish-
ing exponentially. We will discuss, in the next section, that
this choice simpliﬁes the inference algorithm and oﬀers more
scalability. An alternative is to truncate the click chain to
a ﬁnite length of M . The inference and learning algorithms
could be adapted to this truncated CCM, with an order
of magnitude higher space, but it still needs only one pass
through the click data. Its performance of improvement over
CCM would depend on the tail of the distribution of last
clicked position. Details are to be presented in an extended
version of this paper.

4. ALGORITHMS

This section describes algorithms for the CCM. We start
with the algorithm for computing the posterior distribution
over the relevance of each document. Then we describe how
to estimate the α parameters. Finally, we discuss how to
incrementally update the relevance posteriors and α param-
eters with more data.

Given the click data C 1:U from U query sessions for a
query, we want to compute the posterior distribution for
the relevance of a document i, i.e. P (Ri|C 1:U ). For a single
query session, this posterior is simple to compute and store
due to the chain structure of the graphical model (ﬁgure 3).
However, for multiple query sessions, the graph may have
loops due to sharing of relevance variables between query
sessions. For example, if documents i and j both appear
in two sessions, then the graph including both sessions will
have a loop. This signiﬁcantly complicates the posterior.
One possibility is to use an iterative algorithm such as ex-
pectation propagation [13] that traverses and approximates
the loops. However, for this application we propose a faster
method that simply cuts the loops.

The approximation is that, when computing the poste-
rior for Ri, we do not link the relevance variables for other
documents across sessions. In other words, we approximate
clicks in query sessions as conditionally independent random
variables given Ri:

p(Ri|C 1:U

) ≈ (constant) × p(Ri)

P (C u|Ri).

(12)

U(cid:4)

u=1

Case(cid:3)1

Case(cid:3)2

Case(cid:3)3

Case(cid:3)4

C2

C3

C4

C5

…

C6

C1

Case(cid:3)5

C1

C2

C3

C4

C5

…

C6

Case

1

2

3

4

5

Conditions
i < l, Ci = 0
i < l, Ci = 1

i = l

i > l

No Click

Results
1 − Ri

(cid:5)

(cid:6)
Ri(1 − (1 − α3/α2)Ri)
Ri

1 + α2−α3
2−α1−α2

Ri

1 −

1+

2
6−3α1−α2−2α3
(1−α1)(α2+2α3) (2/α1)
1 −
1+(2/α1)i−1 Ri

2

(i−l)−1

Ri

Figure 4: Diﬀerent cases for computing P (C|Ri) up
to a constant where l is the last clicked position.
Darker nodes in the ﬁgure above indicate clicks.

Since the prior p(Ri) is already known, we only need to
ﬁgure out P ( C u| Ri) for each session u. Once P ( C u| Ri) is
calculated up to a constant w.r.t. Ri, Eq. 12 immediately
gives an un-normalized version of the posterior. Section 4.1
will elaborate on the computation of P ( C u| Ri), and the
superscript u is discarded in the following as we focus on a
single query session.
Before diving into the details of deriving P (C|Ri), we ﬁrst
highlight the following three properties of CCM, which will
greatly simplify the variable elimination procedure as we
take sum or integration over all hidden variables other than
Ri:

1. If Cj = 1 for some j, then ∀i ≤ j, Ei = 1.
2. If Ej = 0 for some j, then ∀i ≥ j, Ei = 0, Ci = 0.
3. If Ei = 1, Ci = 0, then P (Ei+1|Ei, Ci, Ri) = αEi+1

α1)1−Ei+1 does not depend on Ri.

1

(1−

Property (1) states that every document before the last click
position is examined, so for these documents, we only need
take care of diﬀerent values of random variables within its
Markov blanket in Figure 3, which is Ci, Ei and Ei+1. Prop-
erty (2) comes from the cascade hypothesis, and it reduces
the cost of eliminating E variables from exponential time to
linear time using branch-and-conquer techniques. Property
(3) is a corollary from Eq. 11, and it enables re-arrangement
of the sum operation over E and R variables to minimize
computational eﬀort.
4.1 Deriving the Conditional Probabilities

Calculating P (C|Ri) requires summing over all the hidden
variables other than Ri in Figure 3, which is generally in-
tractable. But with the above three properties, closed-form
solutions can be derived.
Speciﬁcally, from property 1, we know that the last clicked
position l = arg maxj{Cj = 1} plays an important role. Fig-
ure 4 lists the complete results separated to two categories,
depending on whether the last click position l exists or not.

WWW 2009 MADRID!Track: Data Mining / Session: Click Models14Due to the space limit, we here present the derivation for
cases 1∼3. The derivation of case 3 is illuminating to the
other two cases.

Case 1: i < l, Ci = 0

By property 1 and 3, Ei = 1, Ei+1 = 1 and P (Ei+1 =
1|Ei = 1, Ci = 0, Ri) = α1 does not depend on Ri.
Since any constant w.r.t. Ri can be ignored, we have

P (C|Ri) ∝ P (Ci = 0|Ei = 1, Ri) = 1 − Ri

(13)

Case 2: i < l, Ci = 1

By property 1, Ei = 1, Ei+1 = 1, the Markov blanket
of Ri consists of Ci, Ei and Ei+1.

P (C|Ri)

∝ P (Ci = 1|Ei = 1, Ri)P (Ei+1 = 1|Ei = 1, Ci = 1, Ri)
∝ Ri(1 − (1 − α3/α2)Ri)
(14)

Case 3: i = l

By property 1, the Markov blanket of Ri does not con-
tain any variable before position i, and we also know
that Ci = 1, Ei = 1 and ∀j > i, Cj = 0. We need to
take sum/integration over all the E>i, R>i variables
and it can be performed as follows:

P (C|Ri)
∝ P (Ci = 1|Ei = 1, Ri) ·
(cid:5)

(cid:8)

(cid:7)

(cid:4)

Ej>i

Rj>i

j>i

(cid:6)

(cid:9)
P (Ej|Ej−1, Cj−1, Rj−1) · p(Rj ) · P (Cj|Ej, Rj )

1

0

= Ri ·
P (Ei+1 = 0|Ei = 1, Ci = 1, Ri) · 1
(cid:10)(cid:8)
+ P (Ei+1 = 1|Ei = 1, Ci = 1, Ri)·
p(Ri+1) P (Ci+1 = 0|Ei+1 = 1, Ri+1)dRi+1
(cid:12)
P (Ei+2 = 0|Ei+1 = 1, Ci+1 = 0) · 1
(cid:10)(cid:8)
+ P (Ei+2 = 1|Ei+1 = 1, Ci+1 = 0)·
(cid:13)

p(Ri+2) P (Ci+2 = 0|Ei+2 = 1, Ri+2)dRi+2
(cid:14)(cid:15)(cid:16)

(cid:11)

·

0

1

. . .

(cid:10)
(1 − α2(1 − Ri) − α3Ri) + (α2(1 − Ri) + α3Ri)·
(cid:5)
(1 − α1) + α1 · 1
(cid:10)
2
α2 − α3
2 − α1 − α2

(cid:18)(cid:6)(cid:11)

·(cid:17)
(cid:11)

(15)

1 +

. . .

Ri

= Ri

·

1
2
∝ Ri

(cid:11)

·

Both case 4 and case 5 need to take sum over the hidden
variables after the current position i. The result of case 4
and 5 depend on the distance from the last clicked position.
Therefore the total number of distinct results for computing
P (C|Ri) in these 5 cases when 1 ≤ i ≤ M are 1 + 1 + 1 +
(M − 1) + M = 2M + 2. If we impose a ﬁnite chain length
M on CCM and let P (EM +1) = 0 in Figure 3, then the

Table 1: The algorithm for computing a factorized
representation of relevance posterior.
Alg. 1: Computing the Un-normalized Posterior
Input: Click Data C (M × U matrix);

Cm,u = 1 if user u clicks the mth page abstract

Impression Data I (M × U matrix);

Im,u is the document index shown to user u
at position m which ranges between 1 and D

Parameters α
Output: Coeﬃcients β ((2M + 2)-dim vector)
Exponents P (D × (2M + 2) matrix)

Compute β using the results in Figure 4.
Initialize P by setting all the elements to 0.
for 1 ≤ u ≤ U

Identify the linear factors using the click data C·u,
obtain a M -dim vector b, such that βbm is the
corresponding coeﬃcient for position m.
for 1 ≤ m ≤ M

PImu,bm = PImu,bm + 1

Time Complexity: O(M U ).
Space Complexity: O(M D + M U ).
(Usually U > D >> M = 10.)

number of distinct results would be M (M + 3)/2 + 2, which
is an order of magnitude higher than the current design, and
further increases the cost of subsequent step of inference and
parameter estimation.
4.2 Computing the Un-normalized Posterior
All the conditional probabilities in Figure 4 for a single
i (1 − βjRi)
query session can be written in the form of RCi
where βj is a case-dependent coeﬃcient dependent on the
user behavior parameters α’s. Let M be the number of web
documents in the ﬁrst result page and it usually equals 10.
There are at most 2M + 3 such β coeﬃcients from the 5
cases as discussed above. From Eq. 12, we know that the
un-normalized posterior of any web page is a polynomial,
which consists of at most (2M + 2) + 1 distinct linear fac-
tors of Ri (including Ri itself) and (2M + 2) independent
exponents as suﬃcient statistics. The detailed algorithm for
parsing through the data and updating the counting statis-
tics is listed in Table 1. Given the output exponents P as
well as coeﬃcients β from Alg. 1, the un-normalized rele-
vance posterior of a document d is

˜pRd (r) ∝ rPd,2+Pd,3

(1 − βmr)

Pd,m

(16)

m=1

4.3 Numerical Integration for Posteriors

Standard polynomial integration of ˜p(r) is straightforward
but is subject to the dimensional curse: the rounding error
will dominate as the order of the polynomial goes up to
100 or more. Thus we propose the numerical integration
procedure for computing posterior moments in Table 2 using
the midpoint rule with B equal-size bins.The jth moment
for document d is therefore

1

rj

˜p(r)dr ≈ 1
B

rPd,2+Pd,3+j
b

(1 + βmrb)

Pd,m

for j ≥ 1 divided by the normalizing constant c. Although
the number of bins can be adaptively set, usually we ﬁnd

2M +1(cid:4)

m=1

B(cid:7)

b=1

(cid:8)

0

2M +2(cid:4)

WWW 2009 MADRID!Track: Data Mining / Session: Click Models15for 1 ≤ d ≤ D

log(rb) +

2M +2
m=1

Pd,m log(1 + βmrb)

.

5. EXPERIMENTS

Eqs. 18 and 19 leave a degree of freedom in choosing the
value α2 and α3 introduced by applying the iid uniform pri-
ors over all documents. We can assign a value to α2/α3
according to the context of the model application (more on
this in experiments). Parameter values do not depend on
N4 when the chain length is inﬁnite.
4.5 Incremental Computation

When new click data are available, we can run Alg. 1
(Table 1) to update exponents stored in P by increasing the
counts. The computational time is thus O(M U(cid:3)
), where U(cid:3)
is the number of users in the new data. Extra storage other
than input is needed only when there are previously unseen
web document of interest. If necessary, we can update the
posterior relevancy estimates using Alg. 2 (Table 2). We can
also update α using the same counts.

In this section, we report on the experimental evalua-
tion and comparison based on a data set with 8.8 million
query sessions that are uniformly sampled from a commer-
cial search engine. We measure the performance of three
click models with a number of evaluation metrics, and the
experimental results show that CCM consistently outper-
forms UBM and DCM: over 9.7% better log-likelihood (Sec-
tion 5.2), over 6.2% improvement in click perplexity (Sec-
tion 5.3) and much more robust (up to 30%) click statis-
tics prediction (Section 5.4) As these widely used metrics
measure the model quality from diﬀerent aspects, the con-
sistently better results indicate that CCM robustly captures
the clicks in a number of contexts. Finally, in Section 5.5, we
present the empirical examine and click distribution curves,
which help illustrate the diﬀerences in modeling assump-
tions.
5.1 Experimental Setup

The experiment data set is uniformly sampled from a com-
mercial search engine in July 2008. Only query sessions with
at least one click are kept for performance evaluation, be-
cause those discarded sessions tend to correlate with clicks
on other search elements, e.g. , ads and query suggestions.
For each query, we sort all of its query sessions in ascend-
ing order of the time stamps, and split them evenly into the
training set and the test set. The number of query sessions in
the training set is 4,804,633. Moreover, in order to prevent
evaluations from being biased by highly frequent queries for
which even the simplest model could do well, 178 (0.16%)
queries with more than 103.5 sessions are excluded from the
test set. Performances of diﬀerent click models on these top
queries are consistent with less frequent queries but with a
much smaller margin. The ﬁnal test set consists of 110,630
distinct queries and 4,028,209 query sessions. In order to in-
vestigate the performance variations across diﬀerent query
frequencies, queries in the test set are categorized according
to the query frequency into the 6 groups as listed in Table 3.
For each query, we compute document relevance and po-
sition relevance based on each of the three models, respec-
tively. Position relevance is computed by treating each po-
sition as a pseudo-document. The position relevance can
substitute the document relevance estimates for documents
that appear zero or very few times in the training set but
do appear in the test set. This essentially smooths the pre-
dictive model and improves the performance on the test set.

Table 2: The algorithm for computing posterior mo-
ments using numerical integration.
Alg. 2: Numerical Integration for Posteriors
Input: Exponents P (D × (2M + 2) matrix)
Coeﬃcients β ((2M + 2)-dim vector)
Number of bins B

Output: Normalizing Constants c (D-dim vector)

Posterior Mean μ (D-dim vector)
Posterior Second Moment ξ (D-dim vector)

Create a D × 3 matrix T for intermediate results.
Create a B-dimensional vector r to keep the center
of each bin: rb = (b − 0.5)/B for 1 ≤ b ≤ B
for 0 ≤ j ≤ 2
(cid:19)B
for 1 ≤ d ≤ D
(cid:6)
b=1 exp (− log(B) + (Pd,2 + Pd,3 + j)·
Md,j =

(cid:19)

cd = Md,0, μd = Md,1/Md,0,

ξd = Md,2/Md,0

Time Complexity: O(M DB).
Space Complexity: O(M D + DB + M B).

that B = 100 is suﬃcient. To avoid numerical problems in
implementation, we usually take sum of log values for the
linear factors instead of multiplying them directly. In gen-
eral, for posterior point estimates Ep(r)[f (r)], we can simply
replace the term rj
b in the pervious equation by f (rb) and
divide the result by the normalization constant c.
4.4 Parameter Estimation

To estimate the model parameters α from the data, we
employ approximate maximum likelihood estimation. Ide-
ally, we want to maximize the likelihood p(C 1:U|α), in which
the relevance variables Ri are integrated out. However, as
discussed earlier in section 4, the graph of relevance vari-
ables has loops, preventing exact integration. Therefore we
approximate the integral by cutting all edges between query
sessions. In other words, the clicks are approximated as con-
p(C u|α).
For a single query session, the likelihood p(C|α) is com-
puted by integrating out the Ri (with uniform priors) and
the examination variables Ei. The exact derivation is sim-
ilar to (15) and is omitted. Summing over query sessions,
the resulting approximate log-likelihood function is

ditionally independent given α: p(C 1:U|α) ≈(cid:20)U

u=1

(cid:7)(α) = N1 log α1 + N2 log α4 + N3 log(6 − 3α1 − α4)

+ N5 log(1 − α1) − (N3 + N5) log(2 − α1)
− N1 log 2 − (N2 + N3) log 6

(17)

where

α4 (cid:2) α2 + 2α3

is an auxiliary variable and Ni is the total number of times
documents fall into case i in Figure 4 in the click data. By
maximizing this approximate log-likelihood w.r.t. α’s, we
have
(3N1 + N2 + N5)2 − 8N1(N1 + N2)
2(N1 + N2)

3N1 + N2 + N5 −(cid:21)

α1 =

and

α4 =

3N2(2 − α1)
N2 + N3

(18)

(19)

WWW 2009 MADRID!Track: Data Mining / Session: Click Models16Table 3: Summary of Test Data Set

# Sessions

Avg # Clk

Query Freq # Queries

59,442
30,980
13,667
4,465
1,523
553

1∼9
10∼31
32∼99
100∼316
317∼999
1000∼3162
The cutoﬀ is set adaptively as (cid:9)2 log10(Query Frequency)(cid:10).
For CCM, the number of bins B is set to 100 which provides
adequate level of accuracy.

216,653 (5.4%)
543,537 (13.5%)
731,972 (17.7%)
759,661 (18.9%)
811,331 (20.1%)
965,055 (24.0%)

1.310
1.239
1.169
1.125
1.093
1.072

To account for heterogeneous browsing patterns for diﬀer-
ent queries, we ﬁt diﬀerent models for navigational queries
and informational queries and learn two sets of parameters
for each model according to the median of click distribu-
tion over positions [6, 12]. In particular, CCM sets the ratio
α2/α3 equal to 2.5 for navigational queries and 1.5 for in-
formational queries, because a larger ratio implies a smaller
examination probability after a click. The value of α1 equals
1 as a result of discarding query sessions with no clicks
(N5 = 0 in Eq. 18). For navigational queries, α2 = 0.10
and α3 = 0.04; for informational queries, α2 = 0.40 and
α3 = 0.27. Parameter estimation results for DCM and UBM
will be available at the author’s web site.

For performance evaluation on test data, we compute the
log-likelihood and other statistics needed for each query ses-
sion using the document relevance and user behavior param-
eter estimates learned/inferred from training data. In par-
ticular, by assuming independent document relevance priors
in CCM, all the necessary statistics can be derived in close
form, which is summarized in Appendix B. Finally, to avoid
inﬁnite values in log-likelihood, a lower bound of 0.01 and
a upper bound of 0.99 are applied to document relevance
estimates for DCM and UBM.

All of the experiments were carried out with MATLAB
R2008b on a 64-bit server with 32GB RAM and eight 2.8GHz
cores. The total time of model training for UBM, DCM
and CCM is 333 minutes, 5.4 minutes and 9.8 minutes, re-
spectively. For CCM, obtaining suﬃcient statistics (Alg. 1),
parameter estimation, and posterior computation (Alg. 2)
accounted for 54%, 2.0% and 44% of the total time, respec-
tively. For UBM, the algorithm converged in 34 iterations.
5.2 Results on Log-Likelihood

Log-likelihood (LL) is widely used to measure model ﬁt-
ness. Given the document impression for each query ses-
sion in the test data, LL is deﬁned as the log probability
of observed click events computed under the trained model.
A larger LL indicates better performance, and the optimal
value is 0. The improvement of LL value (cid:7)1 over (cid:7)2 is com-
puted as (exp((cid:7)1 − (cid:7)2) − 1) × 100%. We report average LL
over multiple query sessions using arithmetic mean.

Figure 5 presents LL curves for the three models over dif-
ferent frequencies. The average LL over all query sessions is
-1.171 for CCM, which means that with 31% chance, CCM
predicts the correct user clicks out of the 210 possibilities on
the top 10 results for a query session in the test data. The
average LL is -1.264 for UBM and -1.302 for DCM, with im-
provement ratios to be 9.7% and 14% respectively. Thanks
to the Bayesian modeling of the relevance, CCM outper-
forms the other models more signiﬁcantly on less-frequent

 

UBM
DCM
CCM

−0.5

−1

−1.5

−2

−2.5

−3

−3.5

d
o
o
h

i
l

i

e
k
L
−
g
o
L

−4
 
100

101

101.5

102

102.5

103

103.5

Query Frequency

Figure 5: Log-likelihood per query session on the
test data for diﬀerent query frequencies. The overall
average for CCM is -1.171, 9.7% better than UBM
(-1.264) and 14% better than DCM (-1.302).

queries than on frequent ones, as indicated in Figure 5.
Fitting diﬀerent models for navigational and informational
queries leads to 2.5% better LL for DCM compared with a
previous implementation in [7] on the same data set (average
LL = -1.327).
5.3 Results on Click Perplexity

Click perplexity was used as the evaluation metric in [5].
It is computed for binary click events at each position in
a query session independently rather than the whole click
sequence as in the log-likelihood computation. For a set
of query sessions indexed by n = 1, . . . , N , if we use qn
i to
denote the probability of click derived from the click model
on position i and C n
i to denote the corresponding binary
click event, then the click perplexity
i +(1−Cn

i ) log2(1−qn

i log2 qn

n=1(Cn

(cid:19) N

− 1

pi = 2

N

i )).

(20)

A smaller perplexity value indicates higher prediction qual-
ity, and the optimal value is 1. The improvement of perplex-
ity value p1 over p2 is given by (p2 − p1)/(p2 − 1) × 100%.
The average click perplexity over all query sessions and
positions is 1.1479 for CCM, which is a 6.2% improvement
per position over UBM (1.1577) and a 7.0% improvement
over DCM (1.1590). Again, CCM outperforms the other
two models more signiﬁcantly on less frequent queries than
on more frequent queries. As shown in Figure 6(a), the
improvement ratio is over 26% when compared with DCM
and UBM for the least frequent query category. Figure 6(b)
demonstrates that click prediction quality of CCM is the
best of the three models for every position, whereas DCM
and UBM are almost comparable. Perplexity value for CCM
on position 1 and 10 is comparable to the perplexity of pre-
dicting the outcome of throwing a biased coin of with known
p(Head) = 0.099 and p(Head) = 0.0117 respectively.
5.4 Predicting First and Last Clicks

Root-mean-square (RMS) error on click statistics predic-
tion was used as an evaluation metric in [7]. It is calculated

WWW 2009 MADRID!Track: Data Mining / Session: Click Models17 

UBM
DCM
CCM

1.5

1.45

1.4

1.35

1.3

1.25

1.2

1.15

1.1

l

y
t
i
x
e
p
r
e
P

1.05

 
100

101

101.5

102

102.5

103

103.5

Query Frequency

(a)

l

y
t
i
x
e
p
r
e
P

1.4

1.35

1.3

1.25

1.2

1.15

1.1

1.05

 

 

UBM
DCM
CCM

1

2

3

4

5

6
Position

(b)

7

8

9

10

Figure 6: Perplexity results on the test data for (a) for diﬀerent query frequencies or (b) diﬀerent positions.
Average click perplexity over all positions for CCM is 1.1479, 6.2% improvement over UBM (1.1577) and
7.0% over DCM (1.1590).

by comparing the observation statistics such as the ﬁrst click
position or the last clicked position in a query session with
the model predicted position. Predicting the last click po-
sition is particularly challenging for click models while pre-
dicting the ﬁrst click position is a relatively easy task. We
evaluate the performance of these predictions on the test
data under two settings.

First, given the impression data, we compute the distri-
bution of the ﬁrst/last clicked position in closed form, and
compare the expected value with the observed statistics to
compute the RMS error. The optimal RMS value under this
setting is approximately the standard deviation of ﬁrst/last
clicked positions over all query sessions for a given query,
and it is included in Figure 7 as the “optimal-exp” curve.
We expect that a model that gives consistently good ﬁt of
click data would have a small margin with respect to the op-
timal error. The improvement of RMS error e1 over e2 w.r.t.
) ∗ 100%.
the optimal value e∗
We report average error by taking the RMS mean over all
query sessions.

is given by (e2 − e1)/(e2 − e∗

The optimal RMS error under this setting for ﬁrst clicked
position is 1.198, whereas the error of CCM is 1.264. Com-
pared with the RMS value of 1.271 for DCM and 1.278
for UBM, the improvement ratios are 10% and 18%, re-
spectively. The optimal RMS error under this setting for
last clicked position is 1.443, whereas the error of CCM is
1.548, which is 9.8% improvement for DCM (1.560) but only
slightly better than UBM (0.2%).

Under the second setting, we simulate query session clicks
from the model, collect those samples with clicks, compare
the ﬁrst/last clicked position against the ground truth in
the test data and compute the RMS error, in the same way
as [7]. The number of samples in the simulation is set to
10. The optimal RMS error is the same as the ﬁrst setting,
but it is much more diﬃcult to achieve than in the ﬁrst
setting, because errors from simulations reﬂect both biases
and variances of the prediction. So we report the RMS error
margin for the same model between the two settings. And

 

100

10−1

10−2

y
t
i
l
i

b
a
b
o
r
P
 
k
c

i
l

i

C
/
e
n
m
a
x
E

UBM Examine
DCM Examine
CCM Examine
UBM Click
DCM Click
CCM Click
Empirical Click

 

1

2

3

4

5

6
Position

7

8

9

10

Figure 8: Examination and click probability distri-
butions over the top 10 positions.

we believe that a more robust click model should have a
smaller margin. This margin on ﬁrst click prediction is 0.366
for CCM, compared with 0.384 for DCM (4.8% larger) and
0.436 for UBM (19% larger). Similarly, on prediction of the
last click position, the margin is 0.460 for CCM, compared
with 0.566 for DCM (23% larger) and 0.599 for UBM (30%
larger). In summary, CCM is the best of the three model
in this experiment, to predict the ﬁrst and the last click
position eﬀectively and robustly.
5.5 Position-bias of Examination and Click

Model click distribution over positions are the averaged
click probabilities derived from click models based on the
document impression in the test data. It reﬂects the position-
bias implied by the click model and can be compared with

WWW 2009 MADRID!Track: Data Mining / Session: Click Models182.75

2.5

2.25

2

1.75

1.5

1.25

1

r
o
r
r

 

E
n
o

i

i
t
c
d
e
r
P
 
k
c

i
l

C

 
t
s
r
i
F

0.75

 
100

101

UBM−SIM
DCM−SIM
CCM−SIM
UBM−EXP
DCM−EXP
CCM−EXP
OPTIMAL−EXP

 

3.5

r
o
r
r

 

E
n
o

i

i
t
c
d
e
r
P
 
k
c

i
l

C

 
t
s
a
L

3

2.5

2

1.5

103

103.5

1
 
100

101

 

UBM−SIM
DCM−SIM
CCM−SIM
UBM−EXP
DCM−EXP
CCM−EXP
OPTIMAL−EXP

103

103.5

101.5

102

102.5

Query Frequency

101.5

102

102.5

Query Frequency

(a)

(b)

Figure 7: Root-mean-square (RMS) errors for predicting (a) ﬁrst clicked position and (b) last clicked position.
Prediction is based on the SIMulation for solid curves and EXPectation for dashed curves.

the objective ground truth–the empirical click distribution
over the test set. Any deviation of model click distribution
from the ground truth would suggest the existing modeling
bias in clicks. Note that on the other side, a close match
does not necessarily indicate excellent click prediction, for
example, prediction of clicks {00, 11} as {01, 10} would still
have a perfect empirical distribution. Model examination
distribution over positions can be computed in a similar way
to the click distribution. But there is no ground truth to
be contrasted with. Under the examination hypothesis, the
gap between examination and click curves of the same model
reﬂects the average document relevance.

Figure 8 illustrates the model examination and click dis-
tribution derived from CCM, DCM and UBM as well as
the empirical click distribution on the test data. All three
models underestimate the click probabilities in the last few
positions. CCM has a larger bias due to the approximation
of inﬁnite-length in inference and estimation. This approx-
imation is immaterial as CCM gives the best results in the
above experiments. A truncated version of CCM could be
applied here for improved quality, but the time and space
cost would be an order of magnitude higher, based on some
ongoing experiments not reported here. Therefore, we be-
lieve that this bias is acceptable unless certain applications
require very accurate modeling of the last few positions.

The examination curves of CCM and DCM decrease with
a similar exponential rate. Both models are based on the
cascade assumption, under which examination is a linear
traverse through the rank. The examination probability de-
rived by UBM is much larger, and this suggests that the ab-
solute value of document relevance derived from UBM is not
directly comparable to that from DCM and CCM. Relevance
judgments from click models is still a relative measure.

6. CONCLUSION

In this paper, we propose the click chain model (CCM),
which includes Bayesian modeling and inference of user-
perceived relevance. Using an approximate closed-form rep-
resentation of the relevance posterior, CCM is both scal-

able and incremental, perfectly meeting the challenges posed
by real world practice. We carry out a set of extensive
experiments with various evaluation metrics, and the re-
sults clearly evidence the advancement of the state-of-the-
art. Similar Bayesian techniques could also be applied to
models such as DCM and UBM.

7. ACKNOWLEDGMENTS

We would like to thank Ethan Tu and Li-Wei He for their
help and eﬀort, and anonymous reviewers for their construc-
tive comments on this paper. Fan Guo and Christos Falout-
sos are supported in part by the National Science Foundation
under Grant No. DBI-0640543. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this material
are those of the author(s) and do not necessarily reﬂect the
views of the National Science Foundation.

8. REFERENCES
[1] G. Aggarwal, J. Feldman, S. Muthukrishnan, and

M. P´al. Sponsored search auctions with markovian
users. In WINE ’08, pages 621–628, 2008.

[2] E. Agichtein, E. Brill, and S. Dumais. Improving web

search ranking by incorporating user behavior
information. In SIGIR ’06, pages 19–26, 2006.

[3] O. Chapelle and Y. Zhang. A dynamic bayesian

network click model for web search ranking. In WWW
’09, 2009.

[4] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An
experimental comparison of click position-bias models.
In WSDM ’08, pages 87–94, 2008.

[5] G. E. Dupret and B. Piwowarski. A user browsing

model to predict search engine click data from past
observations. In SIGIR ’08, pages 331–338, 2008.

[6] F. Guo, L. Li, and C. Faloutsos. Tailoring click models

to user goals. In WSDM ’09 workshop on Web search
click data, pages 88–92, 2009.

[7] F. Guo, C. Liu, and Y.-M. Wang. Eﬃcient

multiple-click models in web search. In WSDM ’09,
pages 124–131, 2009.

WWW 2009 MADRID!Track: Data Mining / Session: Click Models19[8] T. Joachims. Optimizing search engines using

clickthrough data. In KDD ’02, pages 133–142, 2002.
[9] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and
G. Gay. Accurately interpreting clickthrough data as
implicit feedback. In SIGIR ’05, pages 154–161, 2005.

[10] T. Joachims, L. Granka, B. Pan, H. Hembrooke,

F. Radlinski, and G. Gay. Evaluating the accuracy of
implicit feedback from clicks and query reformulations
in web search. ACM Trans. Inf. Syst., 25(2):7, 2007.

[11] D. Kempe and M. Mahdian. A cascade model for

externalities in sponsored search. In WINE ’08, pages
585–596, 2008.

[12] U. Lee, Z. Liu, and J. Cho. Automatic identiﬁcation of

user goals in web search. In WWW ’05, pages
391–400, 2005.

[13] T. Minka. Expectation propagation for approximate
bayesian inference. In UAI ’01, pages 362–369, 2001.
[14] B. Piwowarski, G. Dupret, and R. Jones. Mining user
web search activity with layered bayesian networks or
how to capture a click in its context. In WSDM ’09,
pages 162–171, 2009.

[15] F. Radlinski and T. Joachims. Query chains: learning

to rank from implicit feedback. In KDD ’05, pages
239–248, 2005.

[16] M. Richardson, E. Dominowska, and R. Ragno.

Predicting clicks: estimating the click-through rate for
new ads. In WWW ’07, pages 521–530, 2007.

[17] G.-R. Xue, H.-J. Zeng, Z. Chen, Y. Yu, W.-Y. Ma,

W. Xi, and W. Fan. Optimizing web search using web
click-through data. In CIKM ’04, pages 118–126, 2004.

APPENDIX
A. Algorithms for Learning UBM
For UBM, the log-likelihood for each query session is

(cid:7) =

Ci(log rdi + log γli,i−li ) + (1− Ci) log(1− rdi γli,i−li )

M(cid:7)

i=1

The coupling of relevance r and parameter γ introduced in
the second term makes exact computation intractable. The
algorithm could alternative be carried out in an iterative,
coordinate-ascent fashion. However, we found that the ﬁx-
point equation update proposed in [5] does not have conver-
gence guarantee and is sub-optimal in certain cases. Instead,
we designed the following update scheme which usually leads
to very fast convergence.
Given a query for each document d, we keep its count of
click Kd and non-click Ld,j where 1 ≤ j ≤ M (M + 1)/2,
and they map one-to-one with all possible γ indices, and
1 ≤ d ≤ D maps one-to-one to all query-document pair.
Similarly, for each γj, we keep its count of click Kj. Then
given the initial value of γ = γ0, optimization of relevance
can be carried out iteratively,

(cid:13)
(cid:13)

Kd log r +

rt+1
d = arg max
0<r<1

γt+1
j = arg max
0<γ<1

(cid:14)

Ld,j log(1 − rγt
j)
(cid:14)

M (M +1)/2(cid:7)
D(cid:7)

j=1

d=1

Kj log γ +

Ld,j log(1 − rt+1

d γ)

for all possible d and j respectively. The “arg-max” opera-
tion can be carried out by evaluating the objective function
for a sequential scan of r or γ values. And we suggest a
granularity of 0.01 for both scans.
B. LL and Other Statistics of CCM
Given a query session in test data, let ri and si denote the
ﬁrst and second moment of the document relevance poste-
rior for the web document at position i, and α1, α2, α3 de-
note the user behavior parameter. These values are obtained
during model training. We iteratively deﬁne the following
constants:

ζ0 = 1
ζi+1 = (1 − rM−i)(1 − α1 + α1ζi)

Let C i denote the actual click event at test data, then de-
pending on the value of last clicked position l, we have the
following two cases:
• l = 0 (no click),

(cid:8)

LL =

S

p(S1)P (C1 = 0|E1 = 1, S1)

(cid:7)

(cid:4)

E

j>1

P (Ej|Ej−1, Cj−1 = 0)p(Sj)P (Cj = 0|Ej, Sj) = ζM
(cid:22)
(cid:23)
• 1 ≤ l ≤ M
l−1(cid:4)
(cid:5)

(α1(1 − ri))1−Ci (α2ri + (α3 − α2)si)

(1 − α2(1 − ζM−l))rl + (α2 − α3)(1 − ζM−l)sl

LL =

(cid:6)

i=1

Ci

·

We also deﬁne the following constants:

ϕi = (1 − ri)α1 + (ri − si)α2 + siα3
ξM = 0
ξi−1 = φi−1ξi + ri

Then we have

Examination Probability P (Ei = 1) =

i−1(cid:4)

ϕj

j=1

i−1(cid:4)

Examination Depth P (LEP = i) = (1 − ϕi)P (Ei = 1)

Click Probability P (Ci = 1) = riP (Ei = 1)

α1(1 − rj)
First Clicked Position P (F CP = i) = ri
(cid:6)
(cid:18)
Last Clicked Position P (LCP = i) = P (Ei = 1)·
ξi

ri −(cid:17)

ϕi−α1(1 − ri)

(cid:5)

j=1

To draw sample from CCM for performance test:
Initialize C1:M = 0,E1 = 1, i = 1
while (i ≤ M ) and (Ei (cid:11)= 0)

Ci ∼ Bernoulli(ri)
Ei+1 ∼ Bernoulli(α1(1 − Ci) + (α2ri + (α3 − α2)si)Ci)
i = i + 1

Detailed derivations for this subsection will be available at
the author’s web site and included in an extended version
of this work.

WWW 2009 MADRID!Track: Data Mining / Session: Click Models20