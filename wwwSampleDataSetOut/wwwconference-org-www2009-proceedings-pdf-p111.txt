Matchbox: Large Scale Online Bayesian

Recommendations

David Stern

dstern@microsoft.com

Microsoft Research Ltd.

Cambridge, UK

Ralf Herbrich

Microsoft Research Ltd.

Cambridge, UK

rherb@microsoft.com

Thore Graepel

Microsoft Research Ltd.

Cambridge, UK

thoreg@microsoft.com

ABSTRACT
We present a probabilistic model for generating personalised
recommendations of items to users of a web service. The
Matchbox system makes use of content information in the
form of user and item meta data in combination with col-
laborative ﬁltering information from previous user behavior
in order to predict the value of an item for a user. Users and
items are represented by feature vectors which are mapped
into a low-dimensional ‘trait space’ in which similarity is
measured in terms of inner products. The model can be
trained from diﬀerent types of feedback in order to learn
user-item preferences. Here we present three alternatives:
direct observation of an absolute rating each user gives to
some items, observation of a binary preference (like/ don’t
like) and observation of a set of ordinal ratings on a user-
speciﬁc scale. Eﬃcient inference is achieved by approxi-
mate message passing involving a combination of Expecta-
tion Propagation (EP) and Variational Message Passing. We
also include a dynamics model which allows an item’s popu-
larity, a user’s taste or a user’s personal rating scale to drift
over time. By using Assumed-Density Filtering (ADF) for
training, the model requires only a single pass through the
training data. This is an on-line learning algorithm capable
of incrementally taking account of new data so the system
can immediately reﬂect the latest user preferences. We eval-
uate the performance of the algorithm on the MovieLens and
Netﬂix data sets consisting of approximately 1,000,000 and
100,000,000 ratings respectively. This demonstrates that
training the model using the on-line ADF approach yields
state-of-the-art performance with the option of improving
performance further if computational resources are available
by performing multiple EP passes over the training data.

Categories and Subject Descriptors
G.3 [Mathematics of Computing]: Probability and Statis-
tics; H.3.3 [Information Storage and Retrieval]: Infor-
mation Search and Retrieval—Information Filtering; H.3.5
[Information Storage and Retrieval]: Online Informa-
tion Services

General Terms
Algorithms, Experimentation, Performance

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009,  A pril  20–24,  2009,  Madrid,  S pain.
ACM 978-1-60558-487-4/09/04.

1.

INTRODUCTION

One of the great promises of the Web is to connect all the
participating people, products, companies and institutions.
For these connections to be useful it is necessary to select the
few fruitful connections and disregard the many worthless
connections. Automatic recommender systems can aid users
in this selection [7, 19], some of the best known being found
at Amazon, [18], Netﬂix [1], and Yahoo!. The task at hand
is to predict, for a particular user, which items they will be
interested in. There are two sources of information which
are typically used to achieve this.

• Content (Meta-Data) The content-based approach
makes use of descriptions (feature vectors) of both
users and items. Users may be described by properties
such as age and gender and items may be described by
properties such as author and manufacturer. Typical
examples of content based recommendation systems
include web search engines and social matchmaking
sites.

• Collaborative Filtering The collaborative ﬁltering
approach uses only the identities (IDs) of users and
items. Implicit descriptions of the user and items are
obtained from a (sparse) matrix of ratings of items by
users [3]. We can learn about a user by the items they
have previously rated and the users who have rated
items in common with them.

Typically both of these types of information are available
and ideally we would like to use both of them to make pre-
dictions. When a user is relatively new to the system, predic-
tions should be improved by making use of extra information
about the user, thus addressing the well known ‘cold-start’
problem [11]. However, once we have observed suﬃcient user
ratings we want to be able to make fully personalized pre-
dictions for the user based on their speciﬁc ratings rather
than their features.

In addition it is desirable that a recommender system can
be applied ﬂexibly in a wide variety of scenarios. Frequently,
data on user preferences is in the form of ratings on an or-
dinal scale (for example Netﬂix [1]) where each user’s inter-
pretation of this scale may be diﬀerent. In other cases we
may only have data showing which items were clicked on
by a user, where we assume that a user clicking on an item
provides implicit evidence that it is interesting to them (for
example the Google news recommender system [6]).

In order to provide up-to-date recommendations and react
rapidly to a user’s evolving tastes we need the system to be

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods111able to be trained rapidly, ideally incrementally, as new data
arrives. It is crucial that the system is scalable, with memory
and processor requirements increasing in proportion to the
number of users and items and not in proportion to the total
number of previous ratings.

In this work we present a model based on a compressed
representation of the matrix of the values of items for users.
In the literature the prototypical method of this kind is
based on a singular value decomposition (see, for example
[12]). We represent each user and item by a vector of fea-
tures.
In order to take account of user-speciﬁc and item-
speciﬁc tastes we can include a binary feature for every user
ID and item ID in the set of features (only one of which is
active for each user and item). Each feature is associated
with a latent ‘trait’ vector and the linear combination of the
trait vectors for a particular user or item, weighted by the
feature values for that user or item, provides a total trait
vector for the user or item. We model the value that an
item has for a user as the inner product between the trait
vector for the item and the trait vector for the user. Key
contributions of this work are:

1. User and item metadata are integrated to produce
good recommendations in a cold-start situation which
will automatically become more personalised for longer
term users (Section 2.1).

2. The model for user feedback is ﬂexible. We present
three alternatives: direct observation of an absolute
rating each user gives to some items, observation of a
binary preference (like/ don’t like) and observation of
a set of ordinal ratings on a user-speciﬁc scale (Section
2.3).

3. A dynamics model which allows an item’s popularity,
a user’s taste or a user’s personal rating scale to drift
over time (Section 2.4).

4. Eﬃcient inference is performed with a novel combina-
tion of Variational Message Passing (VMP) and Ex-
pectation Propagation (EP) (Section 3.1).

5. Assumed-Density Filtering (ADF) can be used to give
an on-line training method that can incrementally take
account of new data so the system can immediately
reﬂect the latest user preferences (Section 3.3).

In Sections 4.1 and 4.2 we present experimental results for
the Netﬂix and MovieLens data sets.

2. A PROBABILISTIC RATING MODEL

2.1 The Bi-linear Rating Model
Initially, let us assume that the recommender system re-
ceives tuples (x, y, Φ, r) of user descriptions x ∈ (cid:0)
n , item
descriptions y ∈ (cid:0)
m , other features describing the context
of this rating Φ ∈ (cid:0)
f and ratings r ∈ (cid:0). We deﬁne the K
dimensional user trait vector as s = Ux where U is a K × n
matrix of latent user traits where each element uki is the
contribution of feature i to user trait dimension k. Similarly
we deﬁne the K dimensional item trait vector as t = Vy for
an K × m item trait matrix, V. In general we also model a
bias, b = Φ
w where w is a latent set of weights. Frequently
the features Φ will be a combination of the user description

(cid:2)

features x and the item description features y only so in
these cases we may write b = x
v where u and v are
the latent user and item biases.

u + y

(cid:2)

(cid:2)

Now, the rating, r, is modeled as
p(r|s, t, b) = N (r|s
(cid:2)

t + b, β2

)

where β is the standard deviation of the observation noise.
Thus we adopt a bi-linear form in which the similarity be-
tween a user and an item is given by the inner product of
a vector of user traits and a vector of item traits. The ex-
pected rating is proportional to the lengths ||s|| and ||t|| of
the trait vectors as well as the cosine of the angle between
them. The parameter K is chosen such that K (cid:3) n and
K (cid:3) m so computational resource requirements (in time
and memory) should scale as m + n rather than mn.

An important special case of this model is the case when
only the identity of each user and item is known and no
additional properties. In this case, the model reduces to a
collaborative ﬁltering approach if we represent user i by the
feature vector x := ei and item j by y := ej, where ei de-
notes the ith unit vector, i.e., the vector with 1 in position i
and 0 everywhere else. If the bias is zero then the expression
(cid:2)
for the expected rating simpliﬁes to E[r] = u
i vj. Here ui
and vj are the ith and jth column of U and V respectively.
In other words, each user and each item is represented by a
K-dimensional vector in trait space directly. To make the
connection to standard methods, suppose we have a com-
plete matrix R of ratings for n users and m items. Then
the singular-value decomposition (SVD) yields the optimal
solution for the matrices U and V in the least-squares sense,
that is

(USVD, VSVD) := argmin
(U,V)

i vj − rij)
(cid:2)

(u

2.

n

(cid:0)i=1

m

(cid:0)j=1

This function can be directly minimized but due to the large
sparsity of the matrix R in real-world tasks (for example,
1.2% for the Netﬂix data set [1]) regularization needs to be
employed [17, 12, 2].

2.2 Factorizing Prior

The model parameters to be learned are the variables U
and V which determine how users and items are mapped
to the K dimensional trait space and w, the value of bias
features for the rating. We represent our prior beliefs about
the values of these parameters by independent Gaussian dis-
tributions on each of the components of the matrices U and
V and the vector w. For example we have

p(U) =

K

(cid:2)k=1

n

(cid:2)i=1

N (uki; μki, σ2

ki).

We choose this factorizing prior because it reduces mem-
ory requirements to two parameters (a mean and standard
deviation) for each component and it allows us to perform
eﬃcient inference (see Section 3.1).

2.3 Feedback Models

One advantage of the approach described in this paper is
that it allows us to model diﬀerent types of user-item rating
data in a ﬂexible way. Up to this point we have assumed
that the rating, r, is observed directly, however this need
not be the case.

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods1122.3.1 Ordinal Regression

A common scenario is that users provide feedback about
which items they like or dislike via an ordinal scale. For
example, on Netﬂix, users are asked to rate movies from one
to ﬁve stars. These ranks can only be compared, but not
subtracted from one another. In addition, each user’s inter-
pretation of the scale may be diﬀerent and the mapping from
rank to latent rating may not be linear. We assume that for
each user-item pair for which data is available we observe a
rank l ∈ 1,·· · , L. We relate the latent rating r to ranks l via
a cumulative threshold model [4]. For each user, u, we main-
tain user-speciﬁc thresholds bu ∈ (cid:0)
L−1 which divide the la-
tent rating axis into L consecutive intervals (bu(i−1), bu(i))
of varying length each of which representing the region in
which this user gives the same rank to an item. Formally,
we deﬁne a generative model of a ranking as p(l = a|bu, r) =
	a−1
i=1 (r > ˜bu(i−1))	L−1

i=a (r < ˜bu(i−1))

if 1 < a < L

if a = 1
if a = L

i=1 (r < ˜bu(i−1))
i=1 (r > ˜bu(i−1))

	L−1
	L−1
p(˜bui|bui, τ ) = N (˜bui; bui, τ 2

(cid:3)(cid:4)
(cid:5)

where

(1)

)

and we place an independent Gaussian prior on the thresh-
olds so p(bui) = N (bui; μi, σ2
i ). The indicator function (·)
is equal to 1 if the proposition in the argument is true and
0 if it is false.

2.3.2 Binary (‘click’) Probit Model

A special case of the ordinal regression feedback model is
for L = 1, τ = 0, σ2
0 = 0 and μ0 = 0. This corresponds to
observing a binary variable c ∈ {TRUE, FALSE} which is
related to the latent rating by,

p(c = TRUE) = p(r > 0).

This is useful in the situation where we are only provided
with binary information about whether or not a user likes a
particular item. For example, a user may provide feedback
to a news recommender service by which stories they click
on [6].

2.4 Dynamics

Ideally a recommender system needs to be able to track
non-stationary data. A user’s tastes will drift with time
and an item’s popularity may rise and fall with changing
trends.
In addition, if we use the user-speciﬁc threshold
model discussed in Section 2.3.1 a user’s individual rating
scale may also drift with time. One well known phenomenon
where this may occur is ‘anchoring’ where a user tends to
be more likely to give an item a high rating if they have
recently given other items a high rating.

We model these dynamics by assuming that the latent
variables U, V and w (and b if we use the ordinal regression
feedback model) drift with time by the addition of Gaus-
sian noise each time step. For the example of the thresh-
old model we have p(b(t+1)
, γ2) where
t is an index over time steps. At time t0 we use the prior
p(b(0)
i ). Analogous models may be used for
each of the other latent variables.

|b(t)
l ) = N (b(t+1)

) = N (bi; μi, σ2

; b(t)

i

l

l

l

i = 1 · · · n

xi

uki

N



8

1

7

2

tk



1

8

j = 1 · · · m

yj

vkj

N

k = 1, . . . , K

Φd

1



b

3

wd

N
d = 1 · · · f

8

N (τ ; ˜τ , β2)
4

7

∗

sk

zk

˜r

r

6



5

observation belief

Figure 1: Factor Graph for Bi-linear Rating Model.
The large rectangles or plates indicate parts of the
graph which are repeated with repetition indexed
by the variable in the corner of the plate. The fac-
tors labeled Σ are sum factors of the form [z = x+y].
The numbered arrows correspond to messages. Mes-
sages (1) are from the sum factors mapping from
the user/ item/ bias descriptions to the latent trait
space, mΣ→sk (sk), mΣ→tk (tk), and mΣ→b(b). Message
(2) is m∗→zk (zk), from the product factor. Message
(3) is mΣ→˜r(˜r), the message from the total sum fac-
tor to the latent rating ˜r. Message (4) is the mes-
sage from the Gaussian noise factor N (τ ; ˜τ , β2) to the
noisy latent rating r. The rest of the messages are
the reverse messages back to the prior.

3.

INFERENCE

Given a stream of rating tuples (x, y, Φ, r) we train the
model in order to learn posterior distributions over the val-
ues of the parameters U, V, and w. This can be accom-
plished eﬃciently by message passing. The algorithm sketched
below involves computing a sequence of messages. We used
the Infer.net library to perform these computations [15].

3.1 Message Passing for the Core Model

The model described in Section 2.1 can be further factor-
ized by introducing some intermediate latent variables zk to
represent the result of each component, sktk of the inner
product. That is, p(zk|sk, tk) = (zk = sktk). Now the la-
tent rating (before adding noise) is given by p(˜r|z, b) = (˜r =

k zk + b). From Section 2.1 we can see that p(sk|U, x) =
(sk = i ukixi) and p(tk|V, y) = (tk = j vkj yj) and
p(b|w, Φ) = (b =i Φiwi).

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods113Therefore the joint distribution of all the variables factor-

izes as p(s, t, U, V, w, z, ˜r, r|x, y, Φ) =

p(r|˜r)p(˜r|z, b)p(b|w, Φ)p(U)p(V)p(w)

p(zk|sk, tk)p(sk|U, x)p(tk|V, y).

· K
(cid:2)k=1

The posterior distribution over the U V and w variables
given an observed rating tuple, (x, y, Φ, r), is given by sum-
ming out the latent variables: p(U, V, w|r, x, y, Φ) ∝
p(s, t, U, V, w, z, ˜r, r|x, y, f )dsdtdzd˜r.

(2)

(cid:8)s(cid:8)t(cid:8)z(cid:8)˜r

The factor graph for this model is shown in Figure 1. A
factor graph is a bipartite graph with (square) factor nodes
corresponding to factors in a function and (circular) variable
nodes representing variables in the function. The edges of
the graph reveal the dependencies of factors on variables
[10].

Message passing is used to compute the marginal of a
joint distribution by assuming a full factorization of the joint
distribution and in this way approximating each factor as
follows (for an example distribution p(v) of a set of variables
v):

p (v) ∝(cid:2)f

f (v) ≈(cid:2)ˆf (cid:2)i∈V ( ˆf)

m ˆf→i (vi)

m ˆf→i (vi)
,

=(cid:2)i (cid:2)ˆf∈ ˆF (i)

(cid:9)

ˆf (v)

(cid:10)(cid:11)

(cid:12)

(cid:9)

ˆp(vi)

(cid:10)(cid:11)

(cid:12)

where V ( ˆf ) is the set of all variable indices involved in the
approximate factor ˆf and ˆF (i) is the set of all approximate
factors in which variable vi is involved. Message passing is
about best approximating each factor f by a factor ˆf . This
optimization is achieved by minimizing an α-divergence (a
generalization of the Kullback-Leibler divergence) between
ˆp(v) · f (v)/ ˆf (v) (see [14] for details). We approximate all
factors by Gaussian densities so all messages have the func-
tional form of a Gaussian density.
For all of the factors in the model (Figure 1) apart from
the product factor ((zk = sk · tk), labeled * in the dia-
gram) we choose to minimise the Kullback-Leibler (KL) di-
vergence KL(f|| ˆf ) between the true and approximate fac-
tors (alpha-divergence with α → 0). This corresponds to
the Sum-Product algorithm (for exact messages) and Ex-
pectation Propagation (for approximate messages) [10, 16].
For the exact factors we compute factor to variable messages
according to the general update equation for a message from
a factor f to a variable v:

mf→v(v) =(cid:8) f (v) (cid:2)vj∈V (f )\v

mvj→f (v)(vj )dv

(3)

(which follows directly from the distributive law of sums and
products). The messages are denoted on the factor graph
by arrows and the numbers indicate the order in which we
compute them. Since all messages are Gaussian these com-
putations are exact for all factors in the model apart from
the product factor.

3.1.1 Pre-Processing

Firstly we pre-compute the sums for the linear Gaussian
input models. For example for the user model we have (from

equation 3), mΣ→sk (sk) =

n

ukixi)

(cid:8) (sk =(cid:0)i
= N(cid:13)sk;(cid:0)i

N (uki; μki, σ2
(cid:2)i=1
kixi(cid:14) .
μkixi,(cid:0)i

σ2

ki)dU

(4)

(5)

This is also computed for the item model and the bias model
and are labeled ‘1’ in Figure 1.

3.1.2 Iterative Message Passing Schedule

Next we compute the message from the product factor
(labeled ‘2’ in Figure 1). This factor presents us with a
diﬃculty because if we were to use the EP approximation
here the variance of the message would always grow. To see
this, note that given mzk→∗(zk) = N (zk; μk, σ2
k) the most
likely value for sk is sk = μk/tk. This gives rise to a true
bi-modal hyperbolic message density on both sk and tk (one
mode for tk > 0 and one mode for tk < 0). Since the
Kullback–Leibler distance attempts to capture the support
of the distribution, the variance of the approximation mes-
sages m∗→sk and m∗→tk will grow to cover both modes of
the distribution.

(cid:8)mz→∗(cid:9) (cid:8)t(cid:9)

Covering both modes is undesirable, we just need to make
sure that the model chooses a single mode locally to break
the symmetry. Therefore, for this factor we choose to mini-
mize the KL divergence with the arguments swapped, KL( ˆf||f ),
which is equivalent to a local variational approximation [20,
14] (α → 0). The variational update equations for the mes-
sages to and from the product factor f (s, t, z) = (z = s · t)
m∗→z(z) = N z;(cid:8)s(cid:9)(cid:8)t(cid:9) ,(cid:16)s2(cid:17)(cid:16)t2(cid:17) − (cid:8)s(cid:9)2 (cid:8)t(cid:9)2 ,
z→∗(cid:17) − (cid:8)mz→∗(cid:9)2
(cid:14)(6)
m∗→s(s) = N(cid:13)s;
corresponding to messages (2) and (7) in Figure 1 respec-
tively. Here, (cid:8)t(cid:9) denotes the mean of the approximate (Gaus-
sian) marginal distribution p(t) and (cid:8)t2(cid:9) denotes the non-
centered second moment of the marginal p(t) (the message
for m∗→t is obtained from m∗→s by swapping the roles of s
and t). These messages have the undesirable property that
the variance of m∗→s scales according to the precision of
mt→∗ and not the variance. In other words, a large uncer-
tainty in mt→∗ leads to a large reduction in uncertainty in
m∗→s. The approximate inference algorithm reduces uncer-
tainty every time that these messages get updated.

,(cid:16)m2

(cid:8)t2(cid:9)

(cid:8)t2(cid:9)

Note that the inputs to the computation of m∗→z are
the current estimates of the marginal distributions p(t) and
p(s). The marginal distributions are given by the product
of the incoming messages to the variable (labeled 7 and 1 in
Figure 1), for example p(tk) = m∗→tk (tk)· mtk→∗(tk). Since
message m∗→tk is initially unavailable we initialize it to a
uniform distribution and as we iterate the message passing
schedule (2..7) we can obtain better estimates of the value
of this message until eventual convergence.

Message (3) from the total sum factor is calculated by an
analogous equation to equation (4) (belief propagation) and
message (4) corresponds to simply adding β2 to the variance
of message (3) (this also corresponds to standard belief prop-
agation). See [8] for more details on these computations.

Message (5) is the message from the observation factor.
For a direct observation of the value of the rating this mes-
sage would be a delta function centered on the observed

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods114message from bi-linear model

r

[di = r − ˜bi]

[dj = r − ˜bj ]

di

[di > 0]

dj

[dj > 0]

N ( ˜bi; bi, τ 2)

˜bi

bi

N ( ˜bj; bj , τ 2)

˜bj

bj

i = 0 · · · a − 2

p(bi)

p(bj)

j = a − 1 · · · L − 2

Figure 2: Factor graph for user-speciﬁc ordinal re-
gression output model. This represents the model
given in equation 1. Inference is performed by mes-
sage passing.

value, a, that is, (r = a). If another output model is used
then this message will result from performing a message
passing schedule on that model and will be a function of
the downward message (4).

Message (6) is the Gaussian sum-product algorithm mes-
sage from a sum factor to its summonds (derived from equa-
tion 3, see [8]) and messages (7) are calculated using equa-
tion (6).

The message passing schedule (2...7) is iterated until the
marginal distribution of the predicted rating, p(r), no longer
changes.

3.1.3 Post-Processing

Finally messages (8) (for example mΣ→vkj ) are calculated
and the posterior distribution in each case is obtained by
multiplying this message by the prior. For example, for the
variables vkj with prior N (vkj ; μkj , σ2
kj) the posterior is up-
dated as p(vkj ) := mΣ→vkj (vkj) · N (vkj; μkj , σ2
3.2 Feedback Models

kj).

Inference for the ordinal regression observation model is
performed by approximate Gaussian EP message passing on
the factor graph (Figure 2). The message update equations
are described in [8] (and can be computed with Infer.net).
This calculation is performed for each iteration of the sched-
ule described in section 3.1. Note that now the marginal
distribution for each user threshold must be stored.

The binary probit model is a special case of the ordinal

regression model (see Section 2.3.2) [8].
3.3 Assumed-Density Filtering and EP

Once the posterior marginals for the variables U, V and w
have been calculated as described in section 3.1 then we can

discard all of the messages and continue, using this posterior
as the prior for the variables for the next rating. In this way
we pass once through the data, in an on-line fashion, incre-
mentally incorporating each additional rating into the model
beliefs. This method is a form of Assumed-Density Filter-
ing (ADF) [16]. There are several advantages of adopting
this approach. Firstly, the memory overhead is small as no
messages need to be stored. Secondly, the on-line algorithm
can immediately take account of new data when it becomes
available, which may be desirable if we wish to produce up-
to-date recommendations in practice.

The approximation can be improved by passing over the
data several times, using the full EP message passing sched-
ule. In this case we must store the messages into the U, V,
w variables: mΣ→uki (uki), mΣ→vkj (vkj ) and mΣ→wn (wn) in
addition to the posterior marginal distributions p(U), p(V)
and p(w) (equal to the product of these messages with the
priors). The ﬁrst time we pass through the data the updates
are exactly the same as ADF except that we now store these
messages. In subsequent passes through the data we obtain
the messages from the marginals by dividing out the stored
incoming messages. For example for the user messages:

muki→Σ(uki) =

p(uki)

mΣ→uki (uki)

.

Since all messages and marginals are Gaussian distributions
this is a straightforward computation. Once these messages
are obtained for the data point in question we perform the it-
erative procedure of section 3.1 in order to compute updated
messages (labeled 8 in Figure 1) to the user and item vari-
ables: m(cid:6)
Σ→wn (wn). Then
we update the marginal distribution to be the product of
the outgoing and incoming messages. For example for the
user messages:
p(cid:6)

Σ→vkj (vkj ) and m(cid:6)

Σ→uki (uki), m(cid:6)

(uki) = m(cid:6)

Σ→uki (uki)muki→Σ(uki),
Σ→uki (uki), m(cid:6)

and store the latest messages m(cid:6)
and m(cid:6)
for more details of this approach.

Σ→vkj (vkj )
Σ→wn (wn) in place of the previous versions. See [5]

One downside of the full EP method is that the memory
requirements scale in proportion to the number of ratings
in the data set. This means that for large data sets the full
forward backward approach may not be feasible, unless the
data is broken into batches which are trained in sequence.
However, we show in Section 4.1 that performance is still
competitive even if on line ADF is performed. Also, if we
assume a continuous stream of data is arriving (eﬀectively
an inﬁnite data set) then an on-line approach makes even
more sense from a practical point of view.
3.4 Dynamics

When using ADF for training, dynamics is trivial to imple-
ment: with each time step add the variance of the dynamics
factor to the variance of the variable for which dynamics
is being modeled. For example with the threshold model,
after each day we update the variance of threshold beliefs
by σ2(t+1)
is the variance of the
marginal belief for threshold level l for user u at time step t.
In a practical system ADF would probably be used so this
is the method by which dynamics would be applied.

ul + γ2 where σ2(t)

:= σ2(t)

ul

ul

For full EP with dynamics, we divide each variable into
separate copies, one for each time step in which it is in-
volved with an observation. In this case we must cache the

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods115forward and backward messages into each copy of each vari-
able as well as the marginal distributions for the copies. Af-
ter each sweep forwards through the data we must perform a
backward pass when the backward messages and marginals
are updated from future observations, thus smoothing back-
wards in time. For a variable, say b, the backward messages
from the noise factor, f (b(t−1), b(t)) = N (b(t); b(t−1), γ2), are
calculated by m

f (b(t−1),b(t) )→b(t−1) (b(t−1)) =

(cid:2)

(cid:8) N (b(t)

; b(t−1), γ2

)

p(b(t))

mf (b(t−1),b(t) )→b(t) (b(t))

db(t),

and the marginal distribution for the variable b(t−1) is up-
dated by

EP Convergence.  Thresholds and MetaData enabled.

 

K=0
K=2
K=5
K=10
K=20
Lam et al.

0.7

0.68

E
A
M

0.66

0.64

0.62

p(cid:6)

(b(t−1)

) = p(b(t−1)

) ∗ m

(cid:2)
f→b(t−1)
mf→b(t−1)

.

0.6

 

2

4

6

EP Iterations

8

10

The procedure is described in more detail in [5].

3.5 Parallel Inference

In general, fully factorised message passing algorithms (as
described in [14]) can be parallelised as long as we take care
that messages and cached marginals are always consistent.
Frequently one would cache the marginal, p(vi), and calcu-
late messages from a variable to a factor, mi→f , by dividing
a cache of p(vi) by the message mf→i. As long as both the
cache p(vi) and the incoming messages mf→i are updated
in one atomic step, computations of messages can be paral-
lelised. We exploited parallelism in training on the Netﬂix
data set (see Section 4.2). For an X core machine we divided
the movies into X partitions and processed the sequences of
ratings for each of these partitions in parallel. We used a
monitor to ensure that two ratings by the same user are al-
ways processed in sequence to avoid a race condition. This
method gave a 4× speedup on an 8 core machine, allowing
us to process the 100,000,000 Netﬂix ratings in 2 hours with
K = 30.

4. EXPERIMENTS

4.1 MovieLens

Firstly we investigate the predictive performance on the
MovieLens data set. The data set contains 1,000,206 ratings
of 3,952 movies by 6,040 users. Ratings are on an ordinal
scale from 1 to 5. The data is 95.7% sparse.
In addition
to the ID for each user and item some meta data is also
provided for 88% of the users and 98% of the items. The
meta data provided is shown in Table 1.

In order to measure accuracy in a cold start situation we
adopt the methodology of [11] and [13]. We randomly divide
the users into two sets: a test set containing 10% of the
users and a training set containing the rest of the users.
First the model is trained on all the ratings by the training
users according to the procedure outlined in Section 3.1.
For each of the test users we train the model on a random
subset of T % of their ratings for T = 5% and 75%. Then
we use the model to predict the rest of the ratings for that
user. Following [11] we report the Mean Absolute Error
i=1 | ˆri − ri|, where ri is the true rating and
(MAE), 1
ˆri is the predicted rating. We compare to their best result
(MAE=0.6927 for T = 75%) in each of the ﬁgures in this

N N

EP Convergence.  Thresholds and MetaData disabled (IDs only).
0.73

 

K=0
K=2
K=5
K=10
K=20
Lam et al.

0.72

0.71

E
A
M

0.7

0.69

0.68

0.67

 

2

4

6

EP Iterations

8

10

Figure 3: MovieLens Test MAE as a function of
number of EP iterations, T = 75%. The best result
presented by [11] is included for comparison.

section. Note that we include the result of [11] on our plots
for T = 5% although their training procedure had T = 75%.
The x and y vectors are sparse binary, with a 1 present
for each true feature. The bias uses the same features as the
latent embedding so b = x

u + y

v.

(cid:2)

(cid:2)

We perform experiments using both the ordinal regression
observation model and the direct observation model. Where
the ordinal regression observation model is used we use the
median of the predictive distribution p(l|x, y, Φ) in order to
make the optimal decision to minimize MAE error measure.
If the direct observation model is used then we use the mean
of the predictive distribution p(r|x, y, Φ).

Figure 3 shows the eﬀect of performing additional forward-
backward passes of EP. The best result from [11] is included
for comparison. Firstly we can note that more EP iterations
help improve performance, and the larger the number of la-
tent dimensions, K, the more forward-backward passes are
needed in order to achieve convergence.
In this ﬁgure we
also compare the vanilla version of the model with no meta
data (only user ID and item ID and the direct observation
model - no ordinal regression) with the full model including
all meta data features (Table 1) and user-speciﬁc ordinal

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods1160
1
2
3
4
5
6
7
8
9
10

0
1
2
3

other or none speciﬁed

academic/educator

artist

clerical/admin

college / grad student

customer service

doctor / health care

executive / managerial

farmer

homemaker

student

Age< 18

18 ≤ Age < 25
25 ≤ Age < 34
35 ≤ Age < 44

4
5
6

Job

11
12
13
14
15
16
17
18
19
20

lawyer

programmer

retired

sales / marketing

scientist

self-employed

technician / engineer
tradesman / craftsman

unemployed

writer

45 ≤ Age < 49
50 ≤ Age < 55

Age > 55

Gender
0 Male
1 Female

Movie Genre

11 Musical
12 Mystery
13 Romance
14
Thriller
Sci-Fi
15
16
War
17 Western

Action

Adventure
Animation
Children’s
Comedy
Crime

0
1
2
3
4
5
6 Documentary
7
8
9
10

Drama
Fantasy
Film Noir

Horror

Table 1: Meta data provided by the MovieLens data set, left: user meta data, right:
item meta data. In
addition to these features we also use the IDs of the users and the IDs of the items. The x and y vectors are
sparse binary, with a 1 present for each true feature.

regression threshold model. The full model strongly out-
performs the vanilla model. In addition the vanilla model
beneﬁts more each additional EP iteration, taking more it-
erations before achieving best performance. Each sweep
through the 1,000,000 ratings takes approximately 5 min-
utes on a 3.6GHz Pentium 4, for K = 20.

Figure 4 compares the performance of the model with and
without the user-speciﬁc threshold model. The thresholds
appear to help enormously to improve performance. Note
that the threshold model outperforms [11] even with ADF
(one EP iteration) and K=0 (zero latent dimensions!). For
the case where K=0 the model is a simple linear model of
the features in combination with the user-speciﬁc threshold
model. To understand why the model performs so well, even
with K=0 consider Figure 5. This shows a histogram of
rating frequency for some randomly chosen users from the
MovieLens data set. Note how each user seems to mainly use
only a few rating levels each so accuracy is greatly improved
by using the user-speciﬁc threshold model.

Figure 6 compares the performance of the model with and
without the additional meta data features. We compare
performance for T = 5% and T = 75%. The meta data
features seem to improve performance, especially for higher
values of K. The threshold features are especially helpful
in the case where T = 5% as here we face a severe cold
start challenge - making predictions having seen only 5% of
a user’s ratings. In this case the meta data features push
the performance above that of of [12] even though they used
T = 75% for training and we only used T = 5%.

4.2 Netﬂix

In October 2006, Netﬂix released a large movie rating data
set and challenged the data mining, machine learning and
computer science communities to develop systems that could
beat the accuracy of their internal system Cinematch by a
certain amount. The data were collected between October
1998 and December 2005 and represent the distribution of all
ratings Netﬂix obtained during this time period. The train-
ing data set consists of 100,480,507 ratings from 480,189
randomly-chosen, anonymous users on 17,770 movie titles.

K

ADF
EP3

2

0.944
0.941

Lim & Teh (2007)

-

5

0.936
0.93
0.937

10
0.93
0.924
0.924

20

0.927
0.916
0.917

30

0.926
0.914
0.914

Table 2: Netﬂix RMSE scores for diﬀerent settings.
ADF is a single EP pass through the data. The
EP3 run involves splitting the data into batches
of 2,000,000 ratings and passing over each batch 3
times using EP before discarding the messages and
moving on to the next batch (necessary to avoid run-
ning out of memory). With only ID features, as
is the case for Netﬂix, the model is similar to the
approach of [12] and their results are included for
comparison. By using K = 50 and performing 20 EP
iterations on 5,000,000 ratings, and then incorporat-
ing the rest of the ratings by ADF gives an RMSE
of 0.910.

As part of the training data, Netﬂix also provides test data
(the ‘probe’ set), containing 1,408,395 ratings. Since there is
no information available per user and movie other than their
IDs, we use unit vectors x := ei and y := ej to represent
a user i and a movie j. We report root mean squared er-
ror (RMSE) scores according to convention for this data set.
We use the ordinal regression prediction model and our pre-
diction for each test data point is the expected rating value

under the distribution over ratings5

Table 2 shows the performance of the model for various
settings. ADF corresponds to a single EP pass through the
data. The EP3 run was performed by splitting the data into
batches of 2,000,000 ratings and passing over each batch 3
times using EP before discarding the messages mΣ→uki (uki),
mΣ→vkj (vkj ) and mΣ→wn (wn) and moving on to the next
batch (to avoid running out of memory). Note that we
achieve comparable results to [12] with the EP3 approach.
It is interesting to visualize the learned embedding of some
users and movies into trait space for K = 2 (see Figure
7). In this plot the means of the ﬁrst trait dimension are

a=1 a· p(l = a|x, y, Φ).

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods117E
A
M

0.7

0.68

0.66

0.64

0.62

0.6

 

0.7

0.68

E
A
M

0.66

0.64

0.62

0.6

 

ADF, T=75%, thresholds on

MetaData Off
MetaData On
Lam et al.

0

2

5
K

10

20

EP10, T=75%, thresholds on

MetaData Off
MetaData On
Lam et al.

0

2

5
K

10

20

 

 

E
A
M

0.7

0.68

0.66

0.64

0.62

0.6

 

0.7

0.68

E
A
M

0.66

0.64

0.62

0.6

 

 

 

ADF, T=5%, thresholds on

MetaData Off
MetaData On
Lam et al.

0

2

5
K

10

20

EP10, T=5%, thresholds on

MetaData Off
MetaData On
Lam et al.

0

2

5
K

10

20

Figure 6: Movielens Test MAE, left:T =75%, right: T =5%. Comparing performance with and without meta
data features.
‘Meta data oﬀ ’ means only ID features are included. The top plot is produced by training
the model by ADF (a single EP iteration) and the bottom plot is produced by training the model on 10 EP
iterations.

plotted against the means for the second trait dimension for
each user and each item. Note that the learned embedding
separates drama movies as much as possible from action
moves in inner product distance. For any given user i in this
space, movies j in the ‘preference cone’ {tj : s
i tj + b > c}
(cid:2)
are preferred. We have depicted such a cone in the graph.
Pictorially, a high ranking of a movie by a user leads to both
a shift and rotation of the user towards the movie vector as
well as a shift and rotation of the movie towards the user.
This will bring other movies into the preference cone. This
plot was produced by training with ADF. As further EP
iterations are performed the users and movies become more
evenly distributed in a ball in trait space allowing the model
to separate more categories of movies.

One training procedure which boosts performance while
retaining an incremental training method for incorporating
new ratings was to ﬁrst perform a number of full EP itera-
tions on the ratings of a random subset of 5% of the users
(5,000,000 ratings), called the ‘seed’ users. Since we have a
large amount of training data per movie, even 5% of the data
is enough to learn a good embedding of the movies in trait
space. Then we incorporate the ratings of the rest of the
users incrementally using ADF. For 20 iterations of EP on
the seed users and K = 50 we achieve an RMSE of 0.910 on

the probe set. It is worth pointing out that by the standards
of many real world applications even the Netﬂix dataset is
tiny.
In a practical on-line setting where new ratings are
arriving continuously we eﬀectively have an inﬁnite amount
of data and, as the amount of data becomes very large, ADF
could approach the same performance as full EP.

4.3 Advert Click Prediction for AdCenter

Finally, to illustrate a diﬀerent type of application of a
recommender system, we applied the model to the analysis of
logs of clicks on adverts displayed above the search results on
Live.com. The data consisted of 8,000,000 page views, each
corresponding to a single user search query. At each page
view three adverts are displayed (‘impressions’). For each
of the 24,000,000 impressions we know whether or not the
advert was clicked on. We also have a large amount of meta
data for the advert such as the ad title, advertiser account
number and so on. Besides the advert information, the only
information we have about the user is their query. We also
have a number of features which are related to both the
user and advert, for example, the ‘matchtype’ feature which
indicates the degree of match between the advert and query,
depending on what keywords the advertiser has selected as
being relevant to their products and services.

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods118E
A
M

E
A
M

0.72

0.7

0.68

0.66

0.64

0.62

0.6

 

0.72

0.7

0.68

0.66

0.64

0.62

0.6

 

 

 

ADF, T=75%, MetaData on

No Thresholds
With Thresholds
Lam et al.

0

2

5
K

10

20

EP10, T=75%, MetaData on

No Thresholds
With Thresholds
Lam et al.

0

2

5
K

10

20

Figure 4: Movielens Test MAE, T =75%. The
ordinal regression observation model (thresholds)
is compared to the direct observation model (no
thresholds). The top plot is produced by training
the model by ADF (a single EP iteration) and the
bottom plot is produced by training the model with
10 EP iterations.

There are a large number of features available, including
ones which indicate the degree of correspondence between an
advert and a user, so a simple linear model (K = 0) performs
strongly. Therefore most of the features were only used for
the bias (the Φ vector). For K > 0 we used user and item
features derived from the words in the query and the ad title.
The x vector was chosen to be a sparse binary vector of the
occurrence of words in the query from a lexicon of popular
words and the y vector was chosen to be a vector indicating
the occurrence of popular words in the advert title. The
feedback model is the binary probit model (Section 2.3.2)
where ‘click’ means positive feedback (c = TRUE) and ‘no
click’ means negative feedback (c = FALSE). Figure 8 shows
an embedding of query words and ad title words for K = 2
and training with ADF on a subset of the data. With two
latent dimensions, the model appears to learn to separate
navigational queries in one dimension from other queries by
putting words like ‘com’ and ‘Site’ in one direction. After
further EP iterations the adverts and queries become more
distributed in trait space, leading to better performance.

l

a

t

o
T

 
f

o

 

n
o

i
t
c
a
r
F

l

a

t

o
T

 
f

o

 

n
o

i
t
c
a
r
F

0.5

0.4

0.3

0.2

0.1

0

0.5

0.4

0.3

0.2

0.1

0

User A

4

5

1

2

3

Rating
User C

1

2

3

Rating

4

5

l

a

t

o
T

 
f

o

 

n
o

i
t
c
a
r
F

l

a

t

o
T

 
f

o

 

n
o

i
t
c
a
r
F

0.5

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

User B

4

5

1

2

3

Rating
User D

1

2

3

Rating

4

5

Figure 5: Relative frequency of use of each rat-
ing level for four users chosen at random from the
Movielens data set. Notice that user A never uses
rating 5 but users C and D both ﬁnd 5 their most
popular rating. None of the users frequently use
rating 1.

5. CONCLUSIONS AND FUTURE WORK

We have presented a large scale recommender system in
which user and item meta data are integrated. Experiments
on the MovieLens data set show that meta data features are
helpful, particularly for dealing with the cold-start problem
with users new to the system. The user feedback model
is ﬂexible and results show that an ordinal regression model
for user feedback can greatly improve accuracy. For training,
inference is achieved by a novel combination of Variational
Message Passing and EP. We can achieve state-of-the-art
performance if we use ADF for training which is an on-line,
incremental method so recommendations can always be up
to date. Results are improved further by using full EP for
training but in practice we anticipate using ADF as new
data will continuously be arriving and the performance of
ADF will approach that of full EP.

In order to predict what items may be of interest to a user
we potentially have to consider all available items. In order
to make this process more eﬃcient we are investigating two
approaches: hashing [6] and Kd trees [9] and this is the main
focus of future work. The system presented here is being
developed for deployment in a commercial on-line service.

6. REFERENCES
[1] Netﬂix Cinematch: http://www.netﬂix.com.
[2] R. M. Bell and Y. Koren. Lessons from the Netﬂix

prize challenge. ACM SIGKDD Explorations
Newsletter, 9:75–79, 2007.

[3] J. S. Breese, D. Heckerman, and C. Kadie. Empirical

analysis of predictive algorithms for collaborative
ﬁltering. In Proceedings of the 14th ACM Conference
on Uncertainty in Artiﬁcial Intelligence, pages 34–52,
1998.

[4] W. Chu and Z. Ghahramani. Gaussian processes for

ordinal regression. pages 1019–1041, 2005.

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods1192.5

2

Lost in Translation

The Big Lebowski

0.02

0.015

net

Hotels

0.01

Ad Title Words

Query Words

Item
User

-2.5

-1.5

Pearl Harbor

1.5

1

0.5

0

-0.5

-0.5

-1

-1.5

-2

-2.5

0.5

1.5

2.5

-0.03

-0.02

-0.01

Behind Enemy Lines

0.005

0
0

0

-0.005

-0.01

Puzzles

-0.015

-0.02

COM

Site

0.01

0.02

0.03

Figure 7: An embedding of 100 users and 500 movies
into a 2-dimensional trait space (for a run with K =
2). The mean of the ﬁrst user trait (u(0)i) is plotted
against the mean of the second user trait (u(1)j ) to
produce the red dots. The mean of the ﬁrst movie
trait (v(0)i) is plotted against the mean of the second
movie trait (v(1)j ) to produce the blue dots. Some
movie titles are labeled. The triangle suggests the
region within which user 2114400 (the dot in the
bottom left) would like movies because similarity
between users and moves is measured by the inner
product. Note how the learned embedding separates
drama movies (top-right corner) as much as possible
from action movies (bottom-left corner).

Figure 8: An embedding of 190 query words and 339
advert title words into a 2-dimensional trait space
(for a run with K = 2). The mean of the ﬁrst query
word trait (u(0)i) is plotted against the mean of the
second query word trait (u(1)j ) to produce the red
dots. The mean of the ﬁrst advert word trait (v(0)i) is
plotted against the mean of the second advert word
trait (v(1)j ) to produce the blue dots. Some words
are labeled.

systems. In Proceedings of the 2nd international
conference on Ubiquitous information management
and communication, pages 208–211, 2008.

[12] Y. J. Lim and Y. W. Teh. Variational Bayesian

approach to movie rating prediction. In Proceedings of
KDD Cup and Workshop, 2007.

[5] P. Dangauthier, R. Herbrich, T. Minka, and

[13] Benjamin Marlin. Collaborative ﬁltering: A machine

T. Graepel. Trueskill through time: Revisiting the
history of chess. In Advances in Neural Information
Processing Systems 20, pages 337–344, 2008.

[6] Abhinandan S. Das, Mayur Datar, Ashutosh Garg,
and Shyam Rajaram. Google news personalization:
scalable online collaborative ﬁltering. In WWW ’07:
Proceedings of the 16th international conference on
World Wide Web, pages 271–280, New York, NY,
USA, 2007. ACM Press.

[7] D. N. Goldberg, B. M. Oki, and D. Terry. Using

collaborative ﬁltering to weave an information
tapestry. Communications of the ACM, 35:61–70,
1992.

[8] R. Herbrich, T. Minka, and T. Graepel.

TrueSkill(TM): A Bayesian skill rating system. In
Advances in Neural Information Processing Systems
20, pages 569–576, 2007.

[9] M. K. Hughey and M. W. Berry. Improved query

matching using kd-trees: A latent semantic indexing
enhancement. Information Retrieval, 2:287–302, 2004.
[10] F. R. Kschischang, B. Frey, and H.-A. Loeliger. Factor

graphs and the sum-product algorithm. IEEE Trans.
Inform. Theory, 47(2):498–519, 2001.

[11] X. N. Lam, T. Vu, T. D. Le, and A. D. Duong.

Addressing cold-start problem in recommendation

learning perspective. Master’s thesis, University of
Toronto, 2004.

[14] T. Minka. Divergence measures and message passing.

Technical Report MSR-TR-2007-173, Microsoft
Research Ltd., 2005.

[15] T. Minka, J.M. Winn, J.P. Guiver, and A. Kannan.
Infer.NET 2.2, 2009. Microsoft Research Cambridge.
http://research.microsoft.com/infernet.

[16] Thomas Minka. A family of algorithms for

approximate Bayesian inference. PhD thesis, MIT,
2001.

[17] A. Mnih R. Salakhutdinov and G. Hinton. Restricted

Boltzmann machines for collaborative ﬁltering. In
Proceedings of the 24th Annual International
Conference on Machine Learning, pages 791–798,
2007.

[18] J. B. Schafer, J. Konstan, and J. Riedi. Recommender

systems in E–commerce. In Proceedings of the 1st
ACM conference on Electronic commerce, pages
158–166, 1999.

[19] H. R. Varian and P. Resnick. Recommender systems.

Communications of the ACM, 40:56–58, 1997.

[20] J. M. Winn. Variational message passing and its
application. PhD thesis, Department of Physics,
University of Cambridge, 2003.

WWW 2009 MADRID!Track: Data Mining / Session: Statistical Methods120