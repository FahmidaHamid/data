Inferring Private Information Using Social Network Data

Jack Lindamood

Facebook

cep221@gmail.com

Raymond Heatherly

University of Texas at Dallas
rdh061000@utdallas.edu
Bhavani Thuraisingham
University of Texas at Dallas
bxt043000@utdallas.edu

Murat Kantarcioglu

University of Texas at Dallas
muratk@utdallas.edu

ABSTRACT
On-line social networks, such as Facebook, are increasingly
utilized by many users. These networks allow people to pub-
lish details about themselves and connect to their friends.
Some of the information revealed inside these networks is
private and it is possible that corporations could use learn-
ing algorithms on the released data to predict undisclosed
private information. In this paper, we explore how to launch
inference attacks using released social networking data to
predict undisclosed private information about individuals.
We then explore the eﬀectiveness of possible sanitization
techniques that can be used to combat such inference at-
tacks under diﬀerent scenarios.

Categories and Subject Descriptors
I.5.1 [Pattern Recognition]: Models; I.2.6 [Artiﬁcial In-
telligence]: Learning

General Terms
Algorithms, Experimentation

Keywords
Social networks, privacy, inference

1.

INTRODUCTION

Social networks are platforms that allow people to publish
details about themselves and to connect to other members of
the network through friendship links. Recently, the popular-
ity of such on-line social networks is increasing signiﬁcantly.
For example, Facebook now claims to have more than 110
million active users.1 The existence of on-line social net-
works that can be easily mined for various reasons creates
both interesting opportunities and challenges. For example,
social network data could be used for marketing products to
the right customers. At the same time, privacy concerns can
prevent such eﬀorts in practice [1]. Therefore, for future so-
cial network applications, privacy emerges as an important
concern.

In this paper, we focus on the problem of individual pri-
vate information leakage due to being part of an on-line so-
cial network. More speciﬁcally, we explore how the on-line

1http://www.facebook.com/press/info.php?statistics

Copyright is held by the author/owner(s).
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

social network data could be used to predict some individual
private trait that a user is not willing to disclose (e.g., polit-
ical or religious aﬃliation) and explore the eﬀect of possible
data sanitization alternatives on preventing such private in-
formation leakage.

To our knowledge this is the ﬁrst comprehensive paper
that discusses the problem of inferring private traits us-
ing real-life social network data and possible sanitization
approaches to prevent such inference. First, we present a
modiﬁcation of Na¨ıve Bayes classiﬁcation that is suitable for
classifying large amount of social network data. Our mod-
iﬁed Na¨ıve Bayes algorithm predicts privacy sensitive trait
information using both node traits and link structure. We
compare the accuracy of our learning method based on link
structure against the accuracy of our learning method based
on node traits. Please see extended version of this paper [3]
for further details of our modiﬁed Naive Bayes classiﬁer.

In order to protect privacy, we sanitize both trait (e.g.,
deleting some information from a user’s on-line proﬁle) and
link details (e.g., deleting links between friends) and explore
the eﬀect they have on combating possible inference attacks.
Our initial results indicate that just sanitizing trait infor-
mation or link information may not be enough to prevent
inference attacks and comprehensive sanitization techniques
that involve both aspects are needed in practice.

Similar to our paper, in [2], authors consider ways to in-
fer private information via friendship links by creating a
Bayesian Network from the links inside a social network.
A similar privacy problem for online social networks is dis-
cussed in [4]. Compared to [2] and [4], we provide techniques
that help in choosing the most eﬀective traits or links that
need to be removed for protecting privacy.

2. EXPERIMENTS

We wrote a program to crawl the Facebook network to
gather data for our research. Because of the size of Face-
book’s social network, we limited crawling to proﬁles inside
the Dallas/Forth Worth (DFW) network. This means that if
two people share a common friend that is outside the DFW
network, this is not reﬂected inside the database. Also, some
people have enabled privacy restrictions on their proﬁle and
prevented the crawler from seeing their proﬁle details.
Our total crawl resulted in over 167,000 proﬁles, almost 4.5
million proﬁle details, and over 3 million friendship links.
All but 22 of the people crawled were inside one, large com-
ponent of diameter 16.

2

2The default privacy setting for Facebook users is to have all
proﬁle information revealed to others inside their network.

WWW 2009 MADRID!Poster Sessions: Thursday, April 23, 20091145Classiﬁer
Na¨ıve Bayes
Details Only
Links Only
Average

0t, 0l
0.7533
0.7942
0.7163
0.7970

0t, 10l
0.7157
0.7942
0.5855
0.7799

10t, 0l
0.6838
0.7003
0.6977
0.7184

10t, 10l
0.6790
0.7003
0.6066
0.7069

Table 1: Comparison of local classiﬁcation methods

For our experiments, we consider only the subset of the
graph for which we know the expressed political aﬃliation as
either “Conservative” or “Liberal”. This reduces our overall
set size from approximately 160,000 to approximately 35,000
nodes.

To compare our methods to a traditional Na¨ıve Bayes clas-
siﬁer, we implemented our own version of a traditional Na¨ıve
Bayes classiﬁer. Then, we use the ideas discussed in [3] to
create a list of the most representative traits in the graph,
which we use to remove the 10 most predictive traits from
the graph. That is, when we say that we remove K traits,
we calculate which K traits are globally the most likely to
reveal your true political aﬃliation and then remove those
traits from every node that originally had them. Similarly,
we use the ideas discussed in [3] to remove the 10 most telling
links from every node in the graph. Unlike removing traits,
which is done globally, removal of links is done locally. Fi-
nally, we combine the two methods and generate test sets
with both 10 traits and 10 links removed from the graph. We
refer to these sets as 0t, 0l; 10t, 0l; 0t, 10l; 10t, 10l removed,
respectively. Following this, we randomly divide our nodes
to form sets of 50% of the nodes in the training and 50% in
the test sets. We repeated the previous process ﬁve times,
and run each experiment independently. We then take the
average of each of these ﬁve runs as the overall accuracy.

Our results, as shown in Table 1, indicate that the Aver-
age algorithm substantially outperformed traditional Na¨ıve
Bayes and the Links algorithm. Additionally, the Average
algorithm generally performed better than the Details Only
algorithm with the exception of the (0 traits, 10 links) ex-
periments. An examination of the Links results for that
experiment shows that the drop in Average accuracy can be
accounted for by the exceptionally low performance of the
Links classiﬁer and the consistent Details Only performance
for that point.

Also, as a veriﬁcation of expected results, the Details clas-
siﬁcation accuracy only decreased when we removed traits
from nodes, and the (0t, *) accuracies are approximately
equivalent. Similarly, the Links accuracies were mostly af-
fected by the removal of links between nodes, and the (*, 0l)
points of interest are approximately equal. The diﬀerence of
in accuracy between (0t, 0l) and (10t, 0l) can be accounted
for by the weighting portion of the Links calculations, that
depend on the similarity between two nodes.

Next, we examine the speciﬁc aﬀects of removing traits.
We ﬁrst test the local classiﬁcation accuracies after removing
K traits, where K ∈ [0, 10]. After removing the K traits,
we randomize our collection of nodes and create a test set of
50% of the nodes in the training and test sets. We then test
the accuracy of the local classiﬁer on this test set. We repeat
5 times and average the results for the overall accuracy for
K, at each classiﬁer. The results of this are shown in Figure
1. As evident from the results, after removing one trait, the
classiﬁcation accuracy immediately decreases signiﬁcantly.

Average
Details Only
Links Only

 0.84

 0.82

 0.8

 0.78

 0.76

 0.74

 0.72

 0.7

 0.68

 0.66

)

%

(
 
y
c
a
r
u
c
c
A

 0.64

 0

 2

 4

 6

Number of Traits Removed

 8

 10

Figure 1: Local Classiﬁcation accuracy by number
of traits removed

After removing an additional trait, the classiﬁcation returns
to its prior accuracy, and for each subsequent trait removed
we see a slight downward trend in classiﬁcation accuracies.
The sudden downward spike can be easily explained by
looking at the trait removal lists. The highest-ranked trait
is evidence for the trait value of “Liberal”. Removing this
trait makes the probability of being “Conservative” outweigh
the probability of a trait being “Liberal”. This is why the De-
tails accuracy is approximately the same as merely guessing
the majority class for each node. However, when we remove
the second trait, which is representative of being “Conserva-
tive” the probabilities again balance. None of the remaining
traits are as highly indicative as the initial two, so we in-
stead see a gradual decrease in the accuracy over the tested
parameters. Unsurprisingly, the Links Only classiﬁer is only
slightly aﬀected by the removal of traits.

In [3], we report additional experimental results that show
the impact of link removal, collective inference and varying
labeled vs unlabeled nodes ratios.

3. CONCLUSION AND FUTURE WORK

We addressed various issues related to private information
leakage in social networks. Especially, we explored the eﬀect
of removing traits and links in preventing sensitive informa-
tion leakage. Our results indicate that removing trait details
and friendship links together is the best way to reduce clas-
siﬁer accuracy, but this is probably infeasible in maintaining
the use of social networks. However, we also show that by
removing only traits, we greatly reduce the accuracy of lo-
cal classiﬁers, which is the maximum accuracy that we were
able to achieve through any combination of methods.

4. REFERENCES
[1] Facebook Beacon, 2007.

http://blog.facebook.com/blog.php?post=7584397130.

[2] J. He, W. Chu, and V. Liu. Inferring privacy

information from social networks. In Mehrotra, editor,
Proceedings of Intelligence and Security Informatics,
volume LNCS 3975, 2006.

[3] R. Heatherly, M. Kantarcioglu, J. Lindamood, and
B. Thuraisingham. Preventing private information
inference attacks on social networks. Technical Report
UTDCS-03-09, University of Texas at Dallas, 2009.

[4] E. Zheleva and L. Getoor. To join or not to join: the

illusion of privacy in social networks with mixed public
and private user proﬁles. In WWW, 2009.

WWW 2009 MADRID!Poster Sessions: Thursday, April 23, 20091146