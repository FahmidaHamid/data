Web Image Retrieval ReRanking with Multi-view Clustering

Mingmin Chi
Fudan University

Peiwu Zhang
Fudan University

School of Computer Science,

School of Computer Science,

220 Han Dan Road, Shanghai,

China

mmchi@fudan.edu.cn

220 Han Dan Road, Shanghai,
06300720175@fudan.edu.cn

China

School of Computer Science,

School of Computer Science,

Yingbin Zhao
Fudan University

220 Han Dan Road, Shanghai,
zhaoyingbin@fudan.edu.cn

China

Rui Feng

Fudan University

China

School of Computer Science,

Xiangyang Xue
Fudan University

220 Han Dan Road, Shanghai,

220 Han Dan Road, Shanghai,

fengrui@fudan.edu.cn

xyxue@fudan.edu.cn

China

ABSTRACT
General image retrieval is often carried out by a text-based
search engine, such as Google Image Search. In this case,
natural language queries are used as input to the search en-
gine. Usually, the user queries are quite ambiguous and the
returned results are not well-organized as the ranking often
done by the popularity of an image. In order to address these
problems, we propose to use both textual and visual contents
of retrieved images to reRank web retrieved results. In par-
ticular, a machine learning technique, a multi-view cluster-
ing algorithm is proposed to reorganize the original results
provided by the text-based search engine. Preliminary re-
sults validate the eﬀectiveness of the proposed framework.

Categories and Subject Descriptors
H.3.3 [Information Systems]: INFORMATION STOR-
AGE AND RETRIEVAL—Information Search and Retrieval

General Terms
Algorithms, Design

Keywords
Web image retrieval, reRanking, multi-view clustering

1.

INTRODUCTION

Usually, there are two ways for image retrieval: (1)image-
based search engine: high-dimensional, diﬃcult for image
understanding, and (2)text-based search engine: popular,
easy to access and describe. For the former, content-based
image retrieval (CBIR) is quite popular and successful in the
last two decades [3]. However, it suﬀers from a so-called “se-
mantic gap” problem between visual low-level features and
semantic high-level ones.

Most of web image retrieval engines focus on the text-
based index, where text queries are input to an existing

Copyright is held by the author/owner(s).
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

web search engine, e.g., Google Image Search 1. A huge
amount of images in diﬀerent classes are stored in the in-
dexed web image database by search engine companies with
labeling work. The text information usually includes the
ﬁlename of a document, the block with tagging, informa-
tion surrounding. However, the textual representations of
images often are ambiguous and non-informative of image
contents. Moreover, the query provided by user is usually
short consisting of one or two terms and so the short query
is more likely to be ambiguous. Therefore, returned images
can include signiﬁcant diﬀerent semantic meanings with dis-
organized results.

In the poster, a web image retrieval reRanking frame-
work is proposed to reorganize returned results with disam-
biguated semantic meanings. The heterogenetic contextual
information is used for data analysis including both textual
and visual features. In particular, multi-view clustering al-
gorithm is proposed to reorder the initial image retrieval
results provided by a text-based search engine. Preliminary
results validate the eﬀectiveness of the proposed approach.
The rest of the poster is organized as follows. A web image
reRanking framework and a multi-view clustering algorithm
are described in Section 2. Section 3 reports reRanking re-
sults. Finally, conclusions are given in Section 4.

2. PROPOSED FRAMEWORK

Due to disorganization and ambiguous results, it is neces-
sary to reorganize the original retrieved images provided by
the text-based search engine. In the poster, two sources of
contents are integrated to reRank the original results.
2.1 Feature Extraction

In a text-based image search engine, only a single view,
textual features are used for indexing.
In the proposed
framework, a hybrid of both textual and visual low-level
features are used for data analysis.

Textual features: With image tag, webpage ﬁlename,
and texts surrounding image, textual features are obtained
based on a commonly used statistical measure: Term Frequency–
Inverse Document Frequency(tﬁdf). Due to space limita-
tions, reader is referred to [1] for details.
1http://images.google.com.

WWW 2009 MADRID!Poster Sessions: Friday, April 24, 20091189Visual features: We used the color features. Scalable
color descriptor is a color histogram in the YCrCb color
space, which is encoded by a Haar transform.
2.2 Multi-View Clustering Algorithm

Two sources of contents, i.e., textual and visual features,
are extracted to design the so-called multi-view clustering
algorithm. In [2], each view (set) of features is separately
used for clustering, and then the clustering results are com-
bined in the end. When doing so, the clustering results by
diﬀerent views only have few common data points. To ad-
dress this problem, we deﬁne a new similarity measure by
considering both views of the features.

For textual features, the cosine similarity cos (xi, xj) is
used. In order to get the same scale for visual features as
that for textual ones, a normalized Euclidean distance is
adopted in form,

nEuc(xi, xj) = (cid:2) xi − xj (cid:2) / ((cid:2) xi (cid:2) + (cid:2) xj (cid:2)).

To integrate the two sources of contents, a hybrid distance
measure is deﬁned as:

α · cos(x

(1)
i

, x

(1)

j ) + (1 − α) · nEuc(x

(2)
i

, x

(2)
j )

(1)
i

(2)
i

is the ith pattern with textual features, x

where x
is the
ith pattern with visual features and α is a constant, which
controls the contribution of textual features. If α = 0/1 ,
only the visual/textual features are considered and so the
algorithm is reduced to a single-view clustering algorithm;
otherwise, two-view features are integrated for clustering.
2.3 Web Image reRanking

After grouping the original results based on two-view fea-
tures, a keyword for each cluster is obtained for reRanking
according to the tﬁdf weight value in a given cluster. In this
case, the tf weight of each word is the total frequency in the
cluster instead of that in each document for text categoriza-
tion. In the poster, we only use one word for the semantic
meaning of an image cluster.

3. EXPERIMENTS

It is well-known that “Apple” has many semantic mean-
ings. Thus in the experiment, the query “Apple” was used
to validate the eﬀectiveness of the proposed strategy. By
Google Image Search, we obtained the results shown in Fig. 1(a)
on Sept. 9, 2008. To ﬁt the interface we deﬁned, the left
column shows the original retrieved results by Google Im-
age Search, and the right column is a hierarchy provided by
the proposed strategy, which shows the categories of diﬀer-
ent items related to “Apple”, i.e., apple nano (iphone), apple
store, apple tv, apple safari (browser), apple fruit (most re-
lated to recipe), apple patent, and others. From the results
provided by the Google Image Search engine, if user is in-
terested in the logo related to “patent”, it is necessary for
her/him to turn over too many pages to ﬁnd the interest-
ing one from the original results. However, by the proposed
framework, s/he can directly click the button of “patent”
shown in the hierarchical menu to ﬁnd all the interesting
ones. For the space limitations, only the browser (safari)
is shown in Fig. 1(b) when α = 0.4. From the results, one
can see that it is much more friendly and easy for user to
identify the images that s/he wants.

(a) Google

(b) Safari

Figure 1: Image reRanking results with the query
“Apple” by the proposed framework, (a) the original
retrieved images by Google Image Search, and (b)
the reRanking images by the proposed framework.
4. CONCLUSIONS

In the poster, a web image retrieval reRanking strategy
is proposed, where the images retrieved by the text-based
search engine are reorganized for better visualization.
In
particular, a multi-view clustering algorithm is proposed to
integrate two-view contents, i.e., textual and visual features
extracted from web images. Experiment with the query “Ap-
ple” shows the eﬀectiveness of the proposed framework.

5. ACKNOWLEDGMENTS

This work was supported in part by Natural Science Foun-
dation of China under contracts 60705008 and 60873178,
Shanghai Municipal R&D Foundation under contract 075107006,
and Ph.D. Programs Foundation of Ministry of Education
of China under contract 20070246132.

6. REFERENCES
[1] R. Baeza-Yates and B. Ribeiro-Neto. Modern
Information Retrieval. Addison Wesley, 1999.

[2] S. Bickel and T. Scheﬀer. Multi-view clustering. In

ICDM ’04: Proceedings of the Fourth IEEE
International Conference on Data Mining, pages 19–26,
2004.

[3] X. S. Zhou and T. S. Huang. Relevance feedback in

image retrieval: A comprehensive review. Multimedia
Systems, 8(6):536–544, 2003.

WWW 2009 MADRID!Poster Sessions: Friday, April 24, 20091190