Exploiting Web Search to Generate Synonyms for Entities

Surajit Chaudhuri

Venkatesh Ganti

Dong Xin

Microsoft Research
Redmond, WA 98052

{surajitc, vganti, dongxin}@microsoft.com

ABSTRACT
Tasks recognizing named entities such as products, people
names, or locations from documents have recently received
signiﬁcant attention in the literature. Many solutions to
these tasks assume the existence of reference entity tables.
An important challenge that needs to be addressed in the
entity extraction task is that of ascertaining whether or not
a candidate string approximately matches with a named en-
tity in a given reference table. Prior approaches have relied
on string-based similarity which only compare a candidate
string and an entity it matches with. In this paper, we ex-
ploit web search engines in order to deﬁne new similarity
functions. We then develop eﬃcient techniques to facilitate
approximate matching in the context of our proposed simi-
larity functions. In an extensive experimental evaluation, we
demonstrate the accuracy and eﬃciency of our techniques.

Categories and Subject Descriptors
H.2.8 [Database Applications]: Data Mining

General Terms
Algorithms

Keywords
Synonym Generation, Entity Extraction, Similarity Mea-
sure, Web Search

1.

INTRODUCTION

Tasks relying on recognizing entities have recently received
signiﬁcant attention in the literature [10, 12, 2, 14, 11, 9].
Many solutions to these tasks assume the existence of exten-
sive reference entity tables. For instance, extracting named
entities such as products and locations from a reference en-
tity table is important for several applications. A typical
application is the business analytics and reporting system
which analyzes user sentiment of products. The system peri-
odically obtains a few review articles (e.g., feeds from review
website and online forums), and aggregates user reviews for
a reference list of products (e.g., products from certain man-
ufacturers, or products in certain categories). Such a report-
ing application requires us to eﬀectively identify mentions of
those reference products in the review articles.
Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

Consider another application. The entity matching task
identiﬁes entity pairs, one from a reference entity table and
the other from an external entity list, matching with each
other. An example application is the oﬀer matching sys-
tem which consolidates oﬀers (e.g., listed price for products)
from multiple retailers. This application needs to accurately
match product names from various sources to those in the
system’s reference table, and to provide a uniﬁed view for
each product.

At the core of the above two applications, the task is to
check whether or not a candidate string (a sub-string from
a review article or an entry from an oﬀer list) matches with
a member of a reference table. This problem is challenge
because users often like to use phrases, which are not mem-
ber of the reference table, to refer to some entities. These
phrases can be an individual’s preferred description of an en-
tity, and the description is diﬀerent from the entity’s conven-
tional name included in a reference table. For instance, con-
sider a product entity “Lenovo ThinkPad X61 Notebook”.
In many reviews, users may just refer to “Lenovo ThinkPad
X61 Notebook” by writing “Lenovo X61”, or simply “X61”.
Exact match techniques, which insist that sub-strings in re-
view articles match exactly with entity names in the refer-
ence table, drastically limit their applicability in our scenar-
ios.

To characterize whether or not a candidate string matches
with a reference entity string, an alternative approach is
to compute the string similarity score between the candi-
date and the reference strings [10, 6]. For example, the
(unweighted) Jaccard similarity1 function comparing a can-
didate string “X61” and the entity “Lenovo ThinkPad X61
Notebook” would observe that one out of four distinct tokens
(using a typical white space delimited tokenizer) are com-
mon between the two strings and thus measures similarity
to be quite low at 1
4 . On the other hand, a candidate string
“Lenovo ThinkPad Notebook” has three tokens which are
shared with “Lenovo ThinkPad X61 Notebook”, and thus
the Jaccard similarity between them is 3
4 . However, from
the common knowledge, we all know that “X61” does refer to
“Lenovo ThinkPad X61 Notebook”, and “Lenovo ThinkPad
Notebook” does not because there are many models in the
ThinkPad series. We observe a similar problem with other
similarity functions as well. Therefore, the string-based sim-
ilarity does not often reﬂect the “common knowledge” that
users generally have for the candidate string in question.

1These similarity functions also use token weights, say IDF
weights, which may in turn depend on token frequencies in
a corpus or a reference table.

WWW 2009 MADRID!Track: Data Mining / Session: Web Mining151In this paper, we address the above limitation. We ob-
serve that the “common knowledge” is often incorporated
in documents within which a candidate string is mentioned.
For instance, the candidate string “X61” is very highly cor-
related with the tokens in the entity “Lenovo ThinkPad X61
Notebook”. And, many documents which contain the tokens
“X61” also mention within its vicinity the remaining tokens
in the entity. This provides a stronger evidence that “X61”
matches with “Lenovo ThinkPad X61 Notebook”. In this pa-
per, we observe that such “correlation” between a candidate
string τ and an entity e is seen across multiple documents
and exploit it. We propose new document-based similarity
measures to quantify the similarity in the context of multi-
ple documents containing τ . However, the challenge is that
it is quite hard to obtain a large number of documents con-
taining a string τ unless a large portion of the web is crawled
and indexed as done by search engines. Most of us do not
have access to such crawled document collections from the
web. Therefore, we exploit a web search engine and iden-
tify a small set of very relevant documents (or even just
their snippets returned by a web search engine) containing
the given candidate string τ . We rely on these small set
of highly relevant documents to measure the correlation be-
tween τ and the target entity e.

Note that our criteria matching τ and e needs the web
search results for τ to obtain a highly relevant set of docu-
ments or snippets containing τ . Hence, evaluating the simi-
larity between a candidate string with entities in a reference
table in general may not be applicable. Our approach here
is to ﬁrst identify a set of “synonyms” for each entity in the
reference table. Once such synonyms are identiﬁed, our task
of approximately matching a candidate string with a refer-
ence entity is now reduced to match exactly with synonym
or original entity names, i.e., the (sub)set of tokens in the
candidate string is equal to the token set of either a syn-
onym or of an original entity name. Methods which only
support exact match between candidate strings and entities
in a reference table are signiﬁcantly faster (e.g., [3]).

In this paper, we focus on a class of synonyms where each
synonym for an entity e is an identifying set of tokens, which
when mentioned contiguously (or within a small window) re-
fer to e with high probability. We refer to these identifying
token sets as IDTokenSets. We only consider IDTokenSets
for an entity e which consist of a subset of the tokens in e
for two reasons. First, the reference entity tables are often
provided by authoritative sources; hence, each entity name
generally does contain the most important tokens required
to identify an entity exactly but may also contain redun-
dant tokens which are not required for identifying the entity.
Therefore, it is suﬃcient to isolate the identifying subset of
tokens for each entity as an IDTokenSet. The IDTokenSets
of an entity can be considered as keys that uniquely refer
to the original entity. Second, our target applications are
mainly entity extraction from documents. These documents
are mainly drawn from the web such as blogs, forums, re-
views, queries, etc, where it is often observed that users like
to represent a possibly long entity name by a subset of iden-
tifying tokens (e.g., 1-3 keywords).

The main technical challenge in identifying IDTokenSets
for an entity e is that the number of all token subsets of e
could be fairly large. For example, the entity “Canon EOS
Digital Rebel XTI SLR Camera” has 127 subsets. Directly
evaluating whether or not each subset τe of e matches with

In other words, if τe ⊂ τ(cid:48)

e would require a web search query to be issued. Therefore,
the main challenge is to reduce the number of web search
queries issued to identify IDTokenSets for an entity. Our
main insight in addressing this challenge is that for most
entities, if the set τe ⊂ e of tokens identify an entity e then
e where τe ⊂ τ(cid:48)
e ⊂ e also identiﬁes e (i.e., subset-
a set τ(cid:48)
e ⊂ e,
superset monotonicity).
then τ(cid:48)
e is more correlated to e. This is reminiscent of the
“apriori” property in the frequent itemset mining [1, 13],
where a superset is frequent only if its subsets are frequent.
We assume that the subset-superset monotonicity is true
in general and develop techniques which signiﬁcantly reduce
the number of web search queries issued. For example, sup-
pose “Canon XTI” identiﬁes “Canon EOS Digital Rebel XTI
SLR Camera” uniquely. Hence we assume that any superset
say “Canon EOS XTI” also identiﬁes e1 uniquely. There-
fore, if we eﬃciently determine the “border” of IDTokenSets
whose supersets are all IDTokenSets and whose subsets are
not, then we can often signiﬁcantly reduce the number of
web search queries per entity. In this paper, we develop ef-
ﬁcient techniques to determine the border eﬃciently. We
further extend these techniques for multiple entities by tak-
ing advantage of entities which are structurally similar.

In summary, our contributions in this paper are as follows.

1. We consider a new class of similarity functions be-
tween candidate strings and reference entities. These
similarity functions are more accurate than previous
string-based similarity functions because they aggre-
gate evidence from multiple documents, and exploit
web search engines in order to measure similarity.

2. We develop eﬃcient algorithms for generating IDTo-

kenSets of entities in a reference table.

3. We thoroughly evaluate our techniques on real datasets

and demonstrate their accuracy and eﬃciency.

The remainder of the paper is organized as follows. We
deﬁne problem in Section 2. We develop several eﬃcient al-
gorithms for generating IDTokenSets in Section 3, and dis-
cuss some extensions in Section 4. We present a case study
that uses IDTokenSets for entity extraction in Section 5. In
Section 6, we discuss the experimental results. In Section 7,
we review the related work. Finally, we conclude in Section
8.

2. PROBLEM DEFINITION
We ﬁrst deﬁne the notation used in the paper. Let E
denote the set of entities in a reference table. For each e ∈ E,
let T ok(e) denote the set of tokens in e. For simplicity, we
use e to denote T ok(e). We use the notation τe to denote a
subset of tokens of e. That is, τe ⊆ e.

Recall that we focus on identifying token sets which are
subsets of the token set of the entity. That is, an IDTokenSet
of an entity e consists of a subset τe of tokens in e.
In
the following, we formally deﬁne IDTokenSets. As discussed
earlier in Section 1, to characterize an IDTokenSet, we rely
on a set of documents and analyze correlations between the
candidate subset τe and the target entity e.
If a subset
τe identiﬁes e, then a large fraction, say θ, of documents
mentioning τe is likely to contain the remaining tokens in
e − τe. We ﬁrst deﬁne the notion of a document mentioning
a token subset.

WWW 2009 MADRID!Track: Data Mining / Session: Web Mining152Definition 1. Let d be a document and τe be a set of
tokens. We say that d mentions τe if there exists a sub-
string s of d such that T ok(s) = τe.

We are now ready to deﬁne the aggregated correlation be-
tween τe and e with respect to a document set W (τe). Infor-
mally, the aggregated correlation is the aggregated evidence
that τe refers to e from all documents mentioning τe.

ID Document
d1 The All-New, 2009 Ford F150 takes on ...
d2
Sony Vaio F150 is...business notebook...
d3 An overview of the Ford F150 Pickup...

Table 1: A set of documents

corr(τe, e, W (τe)) =

Example 1. For instance, the document d2 in Table 1
mentions the subset {V aio, F 150}, and the documents d1
and d3 mention the subset {F ord, F 150}

For each document that mentions a subset τe, we check
whether the document also contains the remaining tokens in
e− τe. In the ideal case, a large fraction of these documents
mention tokens in e− τe next to the mention of τe. However,
this may be too constraining. Hence, we relax this notion
in two ways. First, we want to parameterize the context
window size p within which we expect to observe all tokens
in e−τe. Second, it may be good enough to ﬁnd a signiﬁcant
fraction of tokens in e− τe within the context window of the
mention of τe; the size of the fraction quantiﬁes the evidence
that τe refers to e.

Definition 2. (p-window context) Let M = {m} be a
set of mentions of τe in a document d = t1, . . . , tn. For each
mention m, let c(m, p) be the sequence of tokens by including
(at most) p tokens before and after m. The p-window context
of τe in d is C(τe, d, p) =

(cid:83)

m∈M c(m, p).

Example 2. For example, the 1-window context of “F150”
in document d2 of Table 1 is {Vaio, F150, is} and that in d1
and d3 are {Ford, F150, takes} and {F ord, F 150, P ickup},
respectively.

We now deﬁne the measure to quantify the evidence that
τe refers to e in a document d. We ﬁrst deﬁne the stricter
notion of evidence g1, where all tokens in e− τe are required
to be present in the p-window context of τe.

(cid:189)

g1(τe, e, d) =

if e ⊆ C(τe, d, p)
otherwise

1
0

We now deﬁne a relaxed notion of evidence g2 of a doc-
ument referring to an entity e, which is quantiﬁed by the
fraction of tokens in e− τe that are present in the p-window
context of τe.

(cid:80)

(cid:80)

g2(τe, e, d) =

t∈C(τe,d,p)∩e w(t)

t∈e w(t)

(2)

where w(t) is the weight (e.g., IDF weight [5]) of the token
t.

The IDTokenSets problem is to generate for a given entity
e all its IDTokenSets with respect to a document collection
D. In the ideal case, this set corresponds to a large collection
of documents on the web which requires us to have access
to a crawled repository of the web. Since this is hard to
have access to in the scenarios we focus on, we exploit the
web search engines to provide us a small set W (τe) of very
relevant document snippets which are highly relevant for τe.

Definition 3. (Correlation) Given e, τe, a search en-

gine W , we deﬁne the aggregated correlation corr(τe, e, W (τe))
as follows.

(cid:80)

g(τe, e, d)
d∈W (τe),d mentions τe
|{d|d ∈ W (τe), d mentions τe}|

Given a correlation threshold θ, we say that τe is an ID-

TokenSet of e if corr(τe, e, W (τe)) ≥ θ.

Example 3. Let e =“Sony Vaio F150 Laptop” be the tar-
get entity, and τe = {F 150} be the candidate subset. Sup-
pose documents in Table 1 are obtained snippets from W (τe).
Each document mentions {F 150}. In order to validate whether
τe = {F 150} is an IDTokenSet of e, we compute:
g1(τe, e, d1) = 0, g1(τe, e, d2) = 1, g1(τe, e, d3) = 0.
Thus, corr(τe, e, W (τe)) = 1
Suppose the token weights of {Sony, V aio, F 150, Laptop} are
{6.8, 9.5, 10.5, 6.5}. Using g2, we have:
g2(τe, e, d1) = 0.29, g2(τe, e, d2) = 0.80, g2(τe, e, d3) = 0.29.
Thus, corr(τe, e, W (τe)) = 1.38

3 = 0.33.

3 = 0.46.

Definition 4. (IDTokenSets Problem) Given an en-
tity e, a search engine W , and the correlation threshold θ,
the IDTokenSets problem is to identify the set Se of all sub-
sets such that for each τe ∈ Se, corr(τe, e, W (τe)) ≥ θ.

Using the above similarity function, adapting techniques
which measure similarity between candidate strings and en-
tities from reference tables directly is an expensive approach.
Therefore, we pre-process the reference entity table and ex-
pand the original entities with their IDTokenSets. By gen-
erating accurate IDTokenSets oﬀ-line, we transform the ap-
proximate match against the reference entity table problem
to an exact match over the set of IDTokenSets, thus signiﬁ-
cantly improving the eﬃciency and accuracy of the approx-
imate lookup task.

(1)

3. GENERATING IDTOKENSETS

We now describe our techniques for eﬃciently generating
IDTokenSets of a given set of entities. We ﬁrst discuss the
optimization criterion and the complexity of the optimal so-
lution for generating IDTokenSets of a single entity. We then
outline an algorithmic framework, under which, we develop
two algorithms. We then extend these techniques to gen-
erate IDTokenSets for a set of entities, and take advantage
of entities which are structurally similar. We show that one
of the discussed algorithms is within a factor of the optimal
solution.
3.1 Optimization Criterion

The input to our system is a set E of entities, and a search
interface W . For each entity e, all subsets of e consist of the
candidate space. For each subset τe of entity e, we want to
validate whether τe is an IDTokenSet of e, using the mea-
sure in Deﬁnition 3. Speciﬁcally, the general framework to
process an entity e is to validate each of its subsets τe, which
consists of the following two steps:

WWW 2009 MADRID!Track: Data Mining / Session: Web Mining1531. Send τe as a query term to W , and retrieve W (τe)
(title, URL and snippets) as the relevant documents;

2. Evaluate corr(τe, e, W (τe)), and report τe is an IDTo-

kenSet if corr(τe, e, W (τe)) ≥ θ;

We consider the whole process to validate τe as an atomic
operator, and notate it as validate(τe). Furthermore, we as-
sume the cost of validate(τe) for diﬀerent τe is roughly same
since the most expensive part of validate(τe) is sending τe
to W . Thus, in order to eﬃciently generate all IDTokenSets
of an entity e, we need to reduce the number of web search
queries we issued. The optimization is mainly based on the
intuition that removing some tokens from a subset τe weak-
ens the correlation between τe and e. On the other hand,
adding more tokens (belong to e) to τe enhances the corre-
lation between τe and e. This is formally characterized as
the subset-superset monotonicity in Deﬁnition 5.

Definition 5. (subset-superset monotonicity) Given
e be two subsets of e, and τe ⊂ τ(cid:48)
e.
e is also an IDTokenSet

an entity e, let τe and τ(cid:48)
If τe is an IDTokenSet of e, then τ(cid:48)
of e.

e (τe ⊂ τ(cid:48)
e (τ(cid:48)

Based on the subset-superset monotonicity, if τe is an ID-
e ⊆ e) are IDTokenSets
TokenSet of e, all subsets τ(cid:48)
of e, and thus can be pruned for validation.
If τe is not
e ⊂ τe) are not IDTo-
an IDTokenSet of e, all subsets τ(cid:48)
kenSets of e, and thus can be pruned for validation. There-
fore, by appropriately schedule the order in which subsets
τe are submitted for validation, we can reduce the number
of web search queries. Before we present the detailed algo-
rithms, we ﬁrst discuss the optimal solution.
3.2 Complexity of the Optimal Algorithm

In order to exploit the subset-superset monotonicity, we
use the lattice structure to model the partial order between
all subsets. An example of subset-lattice of entity “Sony
Vaio F150 Laptop” is shown in Figure 1.

Figure 1: Subset-lattice of “Sony Vaio F150 Laptop”

The optimal algorithm is built upon the notion of mini-
mal positive subset and maximal negative subset, as deﬁned
below.

Definition 6. Given an entity e, a subset τe is a mini-
mal positive subset if validate(τe) = true and for all subsets
e ⊂ τe, validate(τ(cid:48)
τ(cid:48)
e) = f alse. Similarly, a subset τe is a
maximal negative subset if validate(τe) = f alse and for all
subsets τ(cid:48)

e such that τe ⊂ τ(cid:48)

e ⊆ e, validate(τ(cid:48)

e) = true.

We use the notation Cut(e) to denote the set of all min-
imal positive and maximal negative subsets. We now illus-
trate it with an example.

Example 4. Given the entity “Sony Vaio F150 Laptop”,
e = {sony, vaio, laptop} is not an IDTokenSet
the subset τ 1
since there are models other than F150 in the vaio series.
Consequently, all subsets of {sony, vaio, laptop} are not ID-
TokenSets. Because F150 is a popular ford truck, τ 2
e =
{F 150} is not an IDTokenSet either. However, τ 3
e = {sony,
e = {F 150, laptop} are all
F 150}, τ 4
IDTokenSets. These ﬁve subsets constitute the cut. One
can easily verify that all other subsets are either supersets of
τ 3
e , τ 4

e = {vaio, F 150} and τ 5

e or subsets of τ 1

e , τ 2
e .

e , τ 5

Consider a special case where all subsets with

|e|
2 tokens
(suppose |e| is even) are not IDTokenSets and all subsets
|e|
with
2 + 1 tokens are IDTokenSets. One can easily verify
|e|
2 + 1 tokens constitute Cut(e),
that all subsets with
and |Cut(e)| is exponential to |e|. For a given entity, a
scheduling algorithm is optimal if it validates the minimal
number of subsets. One can easily verify that any subset in
the cut can not be pruned by other subsets, and thus has
to be validated. The following lemma shows the connection
between optimal solution and Cut(e).

|e|
2 or

Lemma 1. Given an entity e, the optimal scheduling algo-
rithm validates and only validates subsets in Cut(e). In the
worst case, the number of subsets in Cut(e) is exponential
to |e|.
3.3 Algorithmic Framework

As shown in the previous subsection, given an entity e,
it is suﬃcient to validate those subsets that are in Cut(e).
However, both the maximal negative and minimal positive
subsets are not known beforehand.
In this paper, we use
a greedy algorithmic framework that iteratively probes a
subset, validates it and prunes other subsets (if applicable).
The algorithm stops when no subset is left undetermined.
The framework is outlined in Algorithm 1. Let Pe be the
set of all subsets of e. Our task is to determine for all subsets
in Pe, whether they are IDTokenSets of e. The algorithm
maintains a set of candidate subsets in Le. Initially, Le =
Pe. As soon as a subset τe ∈ Le is validated or pruned, τe is
removed from Le. The algorithm repeats the following two
steps until Le = φ.

1. validate-and-prune (Line 4 to Line 9): It validates a
If τe is an IDTokenSet, all τe’s supersets
subset τe.
are determined to be IDTokenSets, and will be pruned
from Le for further validation. If τe is not an IDTo-
kenSet, all τe’s subsets are determined to be not ID-
TokenSets, and will be pruned from Le as well.

2. getnext (Line 3): It determines which subset to visit
next. We discuss various strategies for implementing
getnext in this section.

3.4 Single-Entity Scheduling

We now describe two strategies to implement getnext. The
depth-ﬁrst scheduling starts with the maximal (or minimal)
subset, and schedules subsets for validation by following the
edges on the lattice structure. The max-beneﬁt scheduling
considers all subsets simultaneously: for each remaining sub-
set, it computes the potential beneﬁt for each subset, and
picks the one with the maximal beneﬁt.

 	
 	
  	
 	
   	
  	
 	
    	
 WWW 2009 MADRID!Track: Data Mining / Session: Web Mining154Algorithm 1 Generating IDTokenSets for an Entity

Input: An entity: e, Search interface: W
the size of the context window: p,
number of top documents: k,
threshold for IDTokenSet: θ
1: Let Le = Pe; //all subsets of e;
2: while (Le is not empty)
3:
4:
5:
6:
7:
8:
9:
10: return

τe = getnext(Le);
Submit τe to W , and retrieve W (τe);
if (corr(τe, e, W (τe)) ≥ θ) // τe is an IDTokenSet
Report τe and all its supersets as IDTokenSets;
Remove τe and all its supersets from Le;
Remove τe and its subsets from Le;

else//τe is not an IDTokenSet

3.4.1 Depth-ﬁrst Scheduling
Given an entity e, all its subsets constitute a lattice (see
Figure 1). The main idea of depth-ﬁrst strategy is to start
with a top root node (it can start at the bottom node as
well) and recursively traverse the lattice structure. Suppose
the algorithm reaches a node corresponding to a subset τe
at some stage. The getnext step determines which subset to
validate next. It consists of three steps:

1. Let τ c

e be a child of τe. If ∃τ(cid:48)

e could be τ c

e (note τ(cid:48)
τ c
scheduling. That is, there is a descendent τ(cid:48)
status is unknown;

e itself), τ c

e ∈ Le such that τ(cid:48)

e ⊆
e is a candidate for
e whose

2. If step 1 did not ﬁnd a candidate τ c
e ∈ Le such that τ(cid:48)

the algorithm looks for the siblings of τe. Let τ s
sibling of τe. If ∃τ(cid:48)
e , τ s
candidate for scheduling;

e for scheduling,
e be a
e ⊆ τ s
e is a

3. If neither step 1 nor step 2 ﬁnd a candidate for schedul-
e , and

ing, the algorithm goes back to τe’s parent τ p
restarts the step 1 on τ p
e .

When multiple subsets (such as multiple children of τe or
multiple siblings of τe) are available for scheduling, we rely
on the intuition that the higher string similarity between the
subset and e, the higher the possibility that this subset is an
IDTokenSet. Since the depth-ﬁrst scheduling starts from e,
we expect to quickly ﬁnd a subset that is not an IDTokenSet
in order to prune all its descendent subsets. Therefore, we
pick the candidate subset with the lowest string similarity
(e.g., the Jaccard similarity as deﬁned in Section 2). Simi-
larly, if the traversal starts from the bottom node, we will
pick the candidate subset with the highest string similarity.
Theorem 1 gives a performance guarantee by the depth-
ﬁrst scheduling algorithm. The main insight is that using
the depth-ﬁrst scheduling, we will validate at most |e| − 1
subsets before we hit a subset belonging to the cut. We omit
the detailed proof here.

Theorem 1. Given an entity e, let DF S(e) be the num-
ber of validations (e.g., web search queries) performed by
the depth-ﬁrst scheduling, and let OP T (e) be the number of
validation performed by the optimal scheduling. We have
DF S(e) ≤ |e|OP T (e).

3.4.2 Max-Beneﬁt Scheduling
Diﬀerent from the depth-ﬁrst scheduling, the max-beneﬁt
scheduling does not conﬁne to the lattice structure. Instead,
at any stage, all subsets in Le are under consideration, and
the one with the maximum estimated beneﬁt will be picked.
The getnext step in the max-beneﬁt scheduling works as
follows. For each subset τe ∈ Le, we can beneﬁt in two ways
from validating τe: pos benef it(τe) if validate(τe) = true
or neg benef it(τe) if validate(τe) = f alse. The beneﬁt is
simply computed by the number of subsets in Le that are
expected to be pruned. If validate(τe) = true, the beneﬁt
of validating τe is deﬁned as follows.

pos benef it(τe) = |{τ

e|τe ⊆ τ
(cid:48)

e ⊆ e and τ
(cid:48)

e ∈ Le}|
(cid:48)

(3)

If validate(τe) = f alse, the beneﬁt of validating τe is

deﬁned as follows.

neg benef it(τe) = |{τ

e|τ
(cid:48)

e ⊆ τe and τ
(cid:48)

e ∈ Le}|
(cid:48)

(4)

We consider three aggregate beneﬁt formulation: max,

min and avg, as deﬁned as follows.

max(τe) = max{pos benef it(τe), neg benef it(τe)}
min(τe) = min{pos benef it(τe), neg benef it(τe)}
avg(τe) = 1
2 (pos benef it(τe) + neg benef it(τe))

Intuitively, max is an aggressive aggregate which always
aims for the best; min is a conservative aggregate which
guarantees for the worst scenario; and avg is in between the
above two. For each of the aggregate option, the getnext
step picks a τe with the maximum aggregated beneﬁt.
3.5 Multiple-Entity Scheduling

In this subsection, we discuss the techniques for scheduling
subset validation when the input consists of multiple enti-
ties, and our goal is to generate IDTokenSets for all entities.
We ﬁrst note that our techniques in this section improve
the eﬃciency and the results are still correct. That is, the
result would be the same as that of processing each entity
independently, and taking the union of the results.

The intuition is as follows. Often, names of entities follow
an implicit structure. The IDTokenSets of such structurally
similar entities are also likely to follow the implicit structure.
By exploring such structured information across entities, our
scheduling strategy can be more eﬃcient. Suppose there is a
group of entities e1, e2, . . . , en, which are structurally similar
to each other. After the ﬁrst i entities are processed, we may
have a better idea on which subsets of ei+1 are IDTokenSets
and which are not. For instance, both “lenovo thinkpad
T41” and “lenovo thinkpad T60” belong to the thinkpad se-
ries from Lenovo. After processing “lenovo thinkpad T41”,
one may identify that {T 41} is an IDTokenSet of “lenovo
thinkpad T41”, and {T 41} belongs to the cut. By observing
the structural similarity across entities, we may ﬁrst validate
{T 60} in its lattice structure. Depending on the outcome
of validation, the scheduling algorithm may terminate early
or proceed further.

In order to build the connection across multiple entities,
we ﬁrst group together entities that are structurally similar.
For each group, we create a group proﬁle, which aggregates
statistics from entities in the group processed so far. Our
new beneﬁt estimation function for any subset exploits the
the statistics on the group proﬁle. We continue to apply

WWW 2009 MADRID!Track: Data Mining / Session: Web Mining155Algorithm 1 on each individual entity with a new getnext
that leverages the group proﬁle statistics.
3.5.1 Proﬁle Grouping
Observe that our single entity scheduling algorithms op-
erate on the subset lattice structure obtained by tokenizing
an input entity.
In order to share statistics for improved
scheduling across entities, the statistics also have to be on
the same subset lattice structure. Otherwise, it would be
much harder to exploit them. Therefore, the main constraint
on grouping multiple entities together for statistics collection
is that we should be able to easily aggregate statistics across
entity lattices.

In this paper, we take an approach of normalizing entity
names based on “token level” regular expressions. That is,
each of these normalization rules takes as input a single to-
ken and maps it to a more general class, all of which are
accepted by the regular expression. The outcome is that
entities which share the same normal form (characterized
by a sequence of token level regular expressions) may all be
grouped together. More importantly, they would share the
same subset lattice structure. We further denote the nor-
malized form shared by all entities in the group as group
proﬁle. Some example token level regular expressions are as
follows.

• Regular expressions: [0 − 9]+ → P U RE N U M BER,

[A − Z][0 − 9]+ → CHAR N U M BER

• Synonyms: {red, green, blue, white, . . .} → COLOR,
{standard, prof essional, enterprise} → V ERSION

Formally, we deﬁne the group and its proﬁle as follows.

An example is given in Example 5.

Definition 7. Let e1, e2, . . . , en be n entities. Let N =
{rule1, rule2, . . . , ruler} be a set of single token normaliza-
tion rules. We denote ei as the normalized form of ei after
applying rules in N . A set {e1, e2, . . . , en} form a group if
e1 = e2 = . . . = en. The group proﬁle is the normalized
entity ei (i = 1, . . . , n).

Example 5. Suppose the normalization rule is [A−Z][0−
9]+ → CHAR N U M BER. Given two entities e1=“lenovo
thinkpad T41” and e2=“lenovo thinkpad T60”, their normal-
ized forms are both e1 = e2=“lenovo thinkpad CHAR NU-
MBER”. Therefore, e1 and e2 form a group, and the group
proﬁle is “lenovo thinkpad CHAR NUMBER”.

Based on the normalized rules, all input entities are parti-
tioned into disjoint groups. Note that the normalized form
of some entities may be the same as the original entity.
This occurs when no normalization rules apply on the en-
tity. Each entity where no normalization rules apply forms
its own group and the multi-entity scheduling reduces to
single-entity scheduling strategy.
3.5.2 Proﬁle-Based Scheduling
After grouping entities into multiple partitions, we process
entities one group at a time.
In each group, we process
entities one by one. Let e1, e2, . . . , en be entities in a group,
and let ep be the group proﬁle. For any subset τei from ei,
there is a corresponding subset τep from ep.

Assume the entities are processed in the order of e1, . . . , en.
In the beginning, there are no statistics on ep. We will use

the single-entity scheduling algorithm (as shown in the pre-
vious subsection) to process e1. Suppose the ﬁrst i entities
have been processed, and the next entity is ei+1. The algo-
rithm ﬁrst updates the statistics on ep using the validation
results of ei. For each subset τep in ep, we keep two coun-
ters: τep .positive and τep .negative. For each subset τei in
ei, if τei is an IDTokenSet of ei, we increment τep .positive
by 1. Otherwise, we increment τep .negative by 1. After ep
has accumulated statistics over a number of entities (e.g.,
i > 1), we use the proﬁle information to process ei+1.
Similar to the max-beneﬁt search, among all remaining
subsets τei+1 in Lei+1 , we will pick the one with the maxi-
mum beneﬁt. The idea is that if a subset τei+1 has higher
probability to be an IDTokenSet of ei+1, that is, τep .positive >
τep .negative, we estimate its beneﬁt using pos benef it(τei+1 )
(e.g., Equation 3). If τei+1 has higher probability to be in-
valid, we estimate its beneﬁt using neg benef it(τei+1 ) (e.g.,
Equation 4).
If there is a tie between positive count and
negative count, we do not consider τei+1 . If all subsets tie
on the positive and negative counts, we switch to the single
entity scheduling algorithm as we did for the ﬁrst entity e1.
The beneﬁt of a subset τei+1 is formally deﬁned as follows.



benef it(τei+1 ) =

pos benef it(τei+1 )

if τep .postive > τep .negative

neg benef it(τei+1 )

if τep .postive < τep .negative

0 Otherwise

Observe that if for any entity ei+1, where (i > 0), if the
proﬁle ep correctly accumulates the statistics such that for
any τei+1 , τei+1 is an IDTokenSet of ei+1 iﬀ τep .positive >
τep .negative, then the proﬁle-based scheduling algorithm for
ei+1 is optimal. That is, we directly validate the subsets on
the Cut(ei+1), thus mimicking the optimal algorithm would.
In our experiments, we observe that the simple beneﬁt func-
tion as deﬁned above works well. Our algorithmic frame-
work is able to take other beneﬁt functions, and we intend
to further explore them in the future.

4. EXTENSIONS

In this section, we discuss two extensions to our approach.
In the ﬁrst extension, we show how to incorporate additional
constraints to prune candidate subsets for generating IDTo-
kenSet. Such constraints are especially meaningful for enti-
ties with a large number of tokens. In the second extension,
we relax the deﬁnition of mention (Deﬁnition 1) to further
enrich the applicability of our techniques.
4.1 Constrained IDTokenSet Generation

In the above section, we assume all subsets are candidates
for generating IDTokenSet.
In some scenarios, users may
have additional constraints that can be applied to prune
some subset candidates.
It is especially beneﬁcial if the
constraint can be evaluated before the subset is validated.
Thus, we can save the cost of validation. To incorporate
constraints into Algorithm 1, we simply replace Le (the can-
didate space) by the set of candidates which satisfy the con-
straints. The rest of the algorithm remains the same.
4.2 Gap Mentions

In Example 3, {Sony, F 150} is an IDTokenSet of “Sony
Vaio F150 Laptop”. However, a document may mention

WWW 2009 MADRID!Track: Data Mining / Session: Web Mining156“Sony PCG F150” instead of “Sony F150”. In Deﬁnition 1,
we require that all tokens in a mention be contiguous within
a document. Therefore, we would not identify the mention
“Sony PCG F150”. We now relax the deﬁnition of document
mentioning a candidate by relaxing the requirement that a
document sub-string consist of a contiguous set of tokens
in a document. Instead, we may consider all sets of tokens
which are “close” to each other within a window. Informally,
we consider w-gap token sets from the document where the
maximum gap (i.e., number of intervening tokens) between
neighboring tokens in the subset is no more than w. A w-gap
token set that exactly matches with an IDTokenSet is called
w-gap mention. w controls the proximity of the tokens, w =
0 means that the token set is a contiguous token set in the
document d, w = ∞ means any subsets of tokens in d may
be a valid mention. Typically, one may set w = 0 for longer
documents such as web pages, and set w = ∞ for short
documents such as queries, titles or snippets.

5. CASE STUDY: ENTITY EXTRACTION

Here we describe a case study that uses IDTokenSets to
facilitate fast and accurate entity extraction. We assume
the extraction task is based on a reference entity table, as
demonstrated by the example applications in Section 1. The
system architecture, which is outlined in Figure 2, consists
of two phases: the oﬄine phase and the online phase.

Figure 2: System Framework for Entity Extraction

The oﬄine phase generates the IDTokenSets for each ref-
erence entity and constructs an exact lookup structure over
the IDTokenSets. The online phase extracts sub-strings as
candidates from query documents and checks them against
the lookup structure for exact match. We observe that users
often use diﬀerent token order in mentioning an entity. For
instance, both “sony F150 notebook” and “sony notebook
F150” refer to the same entity. Therefore, we apply the set-
based exact match criterion (or, the Jaccard similarity with
threshold 1) between candidates from query documents and
IDTokenSets. In doing this, we re-order tokens in each ID-
TokenSet according to a global order (say, lexicographic).
The tokens in the candidates are also re-ordered according
to the same order.

In order to eﬃciently extract candidates from query doc-
uments, we apply the optimization techniques used in [6].
First, we create a token table which keeps all distinct tokens
appearing in the generated IDTokenSets. Given a query
document, we ﬁrst check each token against the token ta-
ble, and only keep those hit-tokens (i.e., tokens appearing in

the table). We denote a set of contiguous hit-tokens as hit-
sequence. Suppose we derive h hit-sequences from a query
document. The second optimization exploits the concept of
strong-token. From each IDTokenSet, we identify the token
with the least frequency over the corpus. For instance, from
the IDTokenSet {sony, F 150, notebook}, one may extract
F 150 as the strong-token. Since we enforce exact match, a
strong-token has to be matched between any candidate and
its matched IDTokenSet. We put strong-tokens from all ID-
TokenSets into a strong-token table. For each hit-sequence
derived from the ﬁrst step, we check whether it contains
a strong token. A hit-sequence is pruned immediately if it
does not contain a strong-token. For all the remaining hit-
sequences, we will enumerate sub-strings with length up to
L (suppose the longest IDTokenSet has L tokens), while en-
suring that each of which contains at least one strong-token.
We then lookup each of these sub-strings against the lookup
structure.

6. PERFORMANCE STUDY

We now present the results of an extensive empirical study
to evaluate the techniques described in this paper. We use
real data sets for the experiments. The reference entity table
is a collection of 200k product names (e.g., consumer and
electronics, bicycles, shoes, etc). The number of tokens in
the product names varies from 2 to 10, with 3.6 tokens on
average.

The major ﬁndings of our study can be summarized as

follows:

1. High quality IDTokenSets:

the document-based
measure performs signiﬁcantly better than the tradi-
tional string-based similarity measure in determining
IDTokenSets;

2. Manageable size: the number of IDTokenSets that
we generated is within reasonable size (i.e., generally
2-4 times of the original entity number);

3. Eﬃcient generation: our proposed algorithms are
able to prune more than 80% of the web queries in
generating IDTokenSet;

4. Fast entity extraction: the case study on entity ex-
traction shows that using IDTokenSets, our system is
able to process 200 documents per second, where each
document contains 3, 689 tokens on average;

In the remaining of this section, we show the experimental
results in terms of quality of IDTokenSets, cost of material-
izing IDTokenSets and the number of IDTokenSets. We also
report the performance of the entity extraction application.
We use Live Search API 2 to retrieve web documents.
6.1 Quality of IDTokenSets

To examine the quality of the IDTokenSets, we compare
our proposed document-based measures with the traditional
string-based similarity measure (e.g., weighted Jaccard sim-
ilarity). We use Live Search to retrieve top-10 results. Since
we only consider title, url and snippets, which are succinct in
general, we set w = ∞ in determining w-gap mentions (Sec-
tion 4.2), and p = ∞ in determining p-window context (Def-
inition 2). We notate Corr1 for the document-based mea-
sure with g1 (Equation 1), Corr2 for the document-based
2http://dev.live.com/livesearch/

 	
Pre-Compute !"#$	%	
&Exact Set-based MatchPre-ComputeIDTokenSetsOnline Lookup'((()&&&(')*&*)'((()&&DocumentsEntity Mentions&&WWW 2009 MADRID!Track: Data Mining / Session: Web Mining157Figure 3: Precision-Recall on Bicycle
Synonyms

Figure 4: Precision-Recall on Laptop
Synonyms

Figure 5: Precision-Recall on Shoe
Synonyms

Figure 6: Generating IDTokenSet for
10k Product Names

Figure 7: Generating IDTokenSet for
10k Product Names

Figure 8: Number of Web Queries
w.r.t. Entity Number

measure with g2 (Equation 2), and Jaccard for the string-
based weighted Jaccard Similarity. The experiments are
conducted on three diﬀerence categories: bicycles, shoes and
laptops.
In each category, we sample 100 product names,
and manually label all subsets which are IDTokenSets. By
varying the threshold in (0.3, 0.5, 0.7, 0.9) for Corr1, (0.6,
0.7, 0.8, 0.9) for both Corr2 and Jaccard, we plot the precision-
recall curves in Figures 3-5.

We observe that in all three categories, the document-
based measures are signiﬁcantly better than the string-based
measure. Among two variants of document-based measures,
Corr1 performs better than Corr2. We notice that Corr1
is a fairly strict measure since it requires all tokens (in the
original entity) to be presenting in at least 50% of the doc-
uments (assuming threshold is 0.5). When the threshold is
0.5, it achieves 80% recall and more than 97% precision.

The recall drops when we increase the threshold. This is
expected since not all documents mention all tokens in the
context. To improve the recall, we found it is important
to recognize token-synonyms in matching tokens. For in-
stance, the token in the product title may be ”bicycle”, and
in the document, users may write ”bike”. Given the prior
knowledge that we are processing bicycle names, ”bike” can
be matched to ”bicycle”.
In this experiment, we only use
the exact token matching, and the preliminary results is al-
ready very promising. We leave the robust token matching
as future work.

6.2 Cost of Materializing IDTokenSets

Here we compare the computational performance using
various strategies for generating IDTokenSets, as discussed
in Section 3. The computation time is roughly proportional
to the number of web queries. Since the time needed for
a web query relies on network traﬃc condition and server
loading status, we compare the number of web queries in-
stead.

We use Corr1 as the measure, and ﬁx the threshold to
0.5. The reference entity table consists of 10k electronic and
consumer product names. Figure 6 shows the number of web
queries used by the following methods: dfs-topdown (DT),
the depth-ﬁrst scheduling starting from e for all entities e
in the reference table; dfs-bottomup (DB), the depth-ﬁrst
scheduling starting from φ for all e; max-max (MAX), the
max-beneﬁt scheduling using max beneﬁt function; max-
min (MIN): the max-beneﬁt scheduling using min beneﬁt
function; max-avg (AVG), the max-beneﬁt scheduling using
avg beneﬁt function; multi-entity (ME): the multiple entity
scheduling algorithm; upper-bound (UB), the total number
of subsets; and lower-bound (LB), the total number of sub-
sets in the cut (deﬁned in Section 3.2).

We observe that multi-entity performs the best. It is close
to the optimal scheduling in that the number of web queries
is only 1.34 times of that in the lower bound. Compar-
ing to the upper bound, it prunes more than 80% of web
queries. Within the single entity scheduling, the depth-ﬁrst

 0.4 0.6 0.8 1 0.4 0.6 0.8 1PrecisionRecallCorr1Corr2Jaccard 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1PrecisionRecallCorr1Corr2Jaccard 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1PrecisionRecallCorr1Corr2Jaccard 50000 100000 150000 200000 250000 300000 350000UBLBMEDTDBMAXMINAVG#Web QueriesMethods#queries(cid:10) 10000 20000 30000 40000 50000 60000 70000 80000 90000 100000UBMEDTDBMAXMINAVG#Web QueriesMethods#queries(cid:10) 100 200 300 400 50020406080100#Web Queries (K)Entity Number (K)multi-entitybfs-topdown(cid:10)WWW 2009 MADRID!Track: Data Mining / Session: Web Mining158Figure 9: Number of IDTokenSet
w.r.t. Entity Size

Figure 10: Number of IDTokenSet
w.r.t. Entity Number

Figure 11: Query Performance

scheduling performs better than the max-beneﬁt scheduling.
Within the depth-ﬁrst scheduling, the top-down scheduling
strategy is better than the bottom-up scheduling strategy.
This matches the intuition that IDTokenSets generally share
more tokens with the original entities.

We also impose an additional constraint that each subset
has to appear as a contiguous substring in some documents
(as we discussed in Section 4.1). In order to evaluate the con-
straint, we still leverage the web search engine to retrieve
the relevant documents. However, sending each subset to
the web search engine is equally expensive as validating the
subset. Instead, we using the following heuristic to evalu-
ate the constraint. For each entity e, we will ﬁrst send e as
a query to the web search engine, and retrieve top-K doc-
uments (i.e., title, url and snippets), where K could be a
large number. We then evaluate the constraint by checking
whether a subsets of e appears contiguously in at least one
of these documents.

Figure 7 shows the performance by diﬀerent methods,
which is similar to that in the complete lattice case. Notice
that diﬀerent from the complete lattice case where we can
compute the lower-bound of the web API calls, we are not
able to obtain the lower-bound in the constrained case where
candidate subsets form a partial lattice structure. This is be-
cause the optimal solution may pick any subsets in the com-
plete lattice in order to prune subsets in the partial lattice.
The optimal solution is essentially a set covering problem,
which is NP-hard.

The last experiment in this subsection is to show the scal-
ability of the algorithms. We ﬁx a mixed strategy such that
for all entities with no more than 5 tokens, we apply the
complete lattice model; and for entities with more than 5
tokens, we enforce the same constraint in Figure 7. Figure
8 shows the number of web queries by multi-entity and dfs-
topdown, with respect to diﬀerent number of input entities.
We observe that both methods are linearly scalable to the
number of input entities. The performance gain of multi-
entity is not signiﬁcant in our experiment. This is because
our entity database is rather diversiﬁed. However, it shows
a clear trend that multi-entity beneﬁts more by increasing
the entity number. By increasing the number of entities, the
grouping method is able to identify more entities which have
similar structure to each other. Hence, the multi-entity has
better chance to locate subsets in the Cut in scheduling.

6.3 Number of IDTokenSets

We pre-compute the IDTokenSet to support eﬃcient ap-
proximate match on-the-ﬂy.
It is important to show that
the IDTokenSets are within the manageable size. Figure 9
reports the average number of IDTokenSets per entity with
respect to diﬀerent entity size (e.g., number of tokens in the
entity). In each size group, we compute the number of IDTo-
kenSets for both the complete lattice case and partial lattice
case (using the same constraint in Figure 7). We observe
that the constraint is quite eﬀective in reducing the number
of IDTokenSets. Actually, the constraint is also meaningful
since not all IDTokenSets are conventionally used by users.
Figure 10 shows the number of IDTokenSets by increasing
the number of entities, using the same experimental conﬁg-
uration in Figure 8. In general, the number of IDTokenSets
is about 2-4 times of the entity number.
6.4 Performance on Entity Extraction

In the last experiment, we brieﬂy show the performance
on entity extraction, using the generated IDTokenSets. The
input string is a collection of 10, 000 documents. On aver-
age, each document contains 3, 689 tokens. The reference
entity table includes 200k entities, from which, we gener-
ate 592k IDTokenSets. We extract all substrings from docu-
ments with length up to 10, and apply set based exact match
(using a hash-table) over the IDTokenSets. We use the ﬁlter
ideas discussed in Section 5 to prune non-interested sub-
strings. The experiments are conducted on a 2.4GHz Intel
Core 2 Duo PC with 4GB RAM, and the execution time is
reported in Figure 11. Our system is fairly eﬃcient in that
it is able to process around 200 documents per second.

7. RELATED WORK

A number of techniques have been proposed for using dic-
tionary information in entity extraction. Cohen and Sarawagi
[10] exploited external dictionaries to improve the accuracy
of named entity recognition. Agrawal et al. [2] introduced
the “ad-hoc” entity extraction task where entities of interest
are constrained to be from a list of entities that is speciﬁc to
the task, and have also considered approximate match based
on similarity functions.

Approximate-match based dictionary lookup was stud-
ied under the context of string similarity search in appli-
cation scenarios such as data cleaning and entity extraction

 1 10 1002-45-78-10IDToken NumberEntity Size (#token)completepartial(cid:10) 50 100 150 200 250 30020406080100IDToken Number (K)Entity Number (K)synonym 0.01 0.1 1 10 10010100100010000Execution Time (Seconds)Document NumberLookupTime(cid:10)WWW 2009 MADRID!Track: Data Mining / Session: Web Mining159(e.g., [7, 8, 4]). All these techniques rely on similarity func-
tions which only use information from the input string and
the target entity it is supposed to match. In contrast, we de-
velop a new similarity scheme which exploits evidence from
a collection of documents.

Our work is related to synonym detection, which is the
problem of identifying when diﬀerent references (i.e., sets of
attribute values) in a dataset correspond to the same real
entity. Synonym detection has received signiﬁcant attention
in the literature [14]. Most previous literature assumed ref-
erences having a fair number of attributes. While additional
attributes or linkage structures may help provide extra evi-
dence, in this paper, we assume we are only given the list of
entity names which is usually the case.

An alternative approach for generating IDTokenSets could
be to segment the original entities into attributes. Con-
sider the entity “Lenovo ThinkPad X61 Notebook”, where
the tokens can be tagged as follows: Lenovo (Brand Name),
ThinkPad (Product Line), X61 (Product Model) and Note-
book (Product Type). A rule based approach then may sug-
gest that Product Model is speciﬁc enough to refer to a prod-
uct, and hence “X61” is a valid IDTokenSet. This rule based
approach has two limitations. First, not all entities have a
clear schema for segmentation. For instance, one may not
be able to segment a movie name. Second, even for some en-
tities that can be segmented, the rule based approach is not
robust. Consider another product entity “Sony Vaio F150
Laptop”, F150 will be tagged as product model. Hence the
rule based approach may conclude that “F150” is an IDTo-
kenSet of “Sony Vaio F150 Laptop”. While actually, from
the common knowledge, “F150” is better known as a Ford
vehicle. In contrast, our techniques do not assume that each
entity is segmentable into attribute values, and we do not
assume the availability of a robust segmentation technique.
Turney [15] introduced a simple unsupervised learning al-
gorithm that exploits web documents for recognizing syn-
onyms. Given a problem word and a set of alternative words,
the task is to choose the member from the set of alternative
words that is most similar in meaning to the problem word.
In this paper, we focus on eﬃciently generating IDTokenSets
for a large collection of entities. The search space is signif-
icantly larger than that in [15], and we focus on methods
that minimize the generation cost.

The subset-superset monotonicity exploited in this paper
is related to the “apriori” property used in many frequent
itemset mining algorithms [1, 13]. The diﬀerence is that the
subset-superset monotonicity prunes computation in two di-
rections. That is, if τ is a valid IDTokenSet, all τ ’s supersets
are pruned for validation; if τ is not a valid IDTokenSet,
all τ ’s subsets are pruned for validation. While in frequent
itemset mining, the “apriori” property only prunes compu-
tation in one direction (e.g., if an itemset τ is not frequent,
only its supersets are pruned).

8. DISCUSSION AND CONCLUSIONS

In order to support fast and accurate approximate entity
match, we propose a new solution by exploiting IDTokenSet.
Our approach diﬀers from many previous methods in two
folders: ﬁrst, we pre-compute a list of IDTokenSets for each
entity. Speciﬁcally, we use the document-based similarity
measure to validate IDTokenSets, and leverage web search
to retrieve related documents; and Second, we apply exact
set-based match over the IDTokenSets at matching phase.

This paper mainly focuses on the quality of the IDTokenSets,
as well as eﬃcient algorithms in generating IDTokenSets.
We show the document-based measure is signiﬁcantly better
than the traditional string-based similarity measure. Several
algorithms are proposed to eﬃciently generate IDTokenSets
by pruning majority number of web queries.

We plan to explore several directions in future work. First,
we studied a document-based similarity measure in this pa-
per. One extension is to build a classiﬁer with features de-
rived from multiple documents.
Second, we will consider
an alternative computation model where the evidence doc-
uments are available for direct access (e.g., scan all docu-
ments). Speciﬁcally, we will exploit batched processing by
simultaneously generating IDTokenSets for all entities.

9. REFERENCES
[1] R. Agrawal, T. Imielinski, and A. Swami. Mining

association rules between sets of items in large
databases. In SIGMOD Conference, pages 207–216,
1993.

[2] S. Agrawal, K. Chakrabarti, S. Chaudhuri, and

V. Ganti. Scalable ad-hoc entity extraction from text
collections. In VLDB, 2008.

[3] A. V. Aho and M. J. Corasick. Eﬃcient string

matching: An aid to bibliographic search. Commun.
ACM, 18(6):333–340, 1975.

[4] A. Arasu, V. Ganti, and R. Kaushik. Eﬃcient exact
set-similarity joins. In VLDB, pages 918–929, 2006.
[5] R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern
Information Retrieval. ACM Press/Addison-Wesley,
1999.

[6] K. Chakrabarti, S. Chaudhuri, V. Ganti, and D. Xin.

An eﬃcient ﬁlter for approximate membership
checking. In SIGMOD Conference, pages 805–818,
2008.

[7] A. Chandel, P. C. Nagesh, and S. Sarawagi. Eﬃcient

batch top-k search for dictionary-based entity
recognition. In ICDE, page 28, 2006.

[8] S. Chaudhuri, V. Ganti, and R. Kaushik. A primitive

operator for similarity joins in data cleaning. In ICDE,
page 5, 2006.

[9] T. Cheng, X. Yan, and K. C.-C. Chang. Entityrank:
Searching entities directly and holistically. In VLDB,
pages 387–398, 2007.

[10] W. W. Cohen and S. Sarawagi. Exploiting dictionaries

in named entity extraction: combining semi-markov
extraction processes and data integration methods. In
KDD, pages 89–98, 2004.

[11] X. Dong, A. Y. Halevy, and J. Madhavan. Reference

reconciliation in complex information spaces. In
SIGMOD Conference, pages 85–96, 2005.

[12] V. Ganti, A. C. K¨onig, and R. Vernica. Entity

categorization over large document collections. In
KDD, pages 274–282, 2008.

[13] J. Han and M. Kamber. Data Mining: Concepts and

Techniques. Morgan Kaufmann, 2001.

[14] N. Koudas, S. Sarawagi, and D. Srivastava. Record

linkage: similarity measures and algorithms. In
SIGMOD Conference, pages 802–803, 2006.

[15] P. D. Turney. Mining the web for synonyms: Pmi-ir

versus lsa on toeﬂ. CoRR, cs.LG/0212033, 2002.

WWW 2009 MADRID!Track: Data Mining / Session: Web Mining160