Adaptive Bidding for Display Advertising

Arpita Ghosh
Yahoo! Research

2821 Mission College Blvd.
arpita@yahoo-inc.com

Santa Clara, CA 95054

Sergei Vassilvitskii

Yahoo! Research

111 West 40th St., 17th Floor
sergei@yahoo-inc.com

New York, NY 10018

ABSTRACT
Motivated by the emergence of auction-based marketplaces
for display ads such as the Right Media Exchange, we study
the design of a bidding agent that implements a display ad-
vertising campaign by bidding in such a marketplace. The
bidding agent must acquire a given number of impressions
with a given target spend, when the highest external bid in
the marketplace is drawn from an unknown distribution P.
The quantity and spend constraints arise from the fact that
display ads are usually sold on a CPM basis. We consider
both the full information setting, where the winning price
in each auction is announced publicly, and the partially ob-
servable setting where only the winner obtains information
about the distribution; these diﬀer in the penalty incurred
by the agent while attempting to learn the distribution. We
provide algorithms for both settings, and prove performance
guarantees using bounds on uniform closeness from statis-
tics, and techniques from online learning. We experimen-
tally evaluate these algorithms: both algorithms perform
very well with respect to both target quantity and spend;
further, our algorithm for the partially observable case per-
forms nearly as well as that for the fully observable setting
despite the higher penalty incurred during learning.

Categories and Subject Descriptors
F.2.0 [Analysis of Algorithms and Problem Complex-
ity]: General; J.4 [Social and Behavioral Sciences]: Eco-
nomics; I.2.6 [Artiﬁcial Intelligence]: Learning

General Terms
Algorithms, Economics, Theory

Keywords
Display advertising, guaranteed delivery, adaptive bidding,
guess-then-double algorithms, concentration bounds

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

Benjamin I. P. Rubinstein
Computer Science Division

University of California, Berkeley

Berkeley, CA 94720

benr@cs.berkeley.edu

Martin Zinkevich
Yahoo! Research

2821 Mission College Blvd.
Santa Clara, CA 95054
maz@yahoo-inc.com

1.

INTRODUCTION

A bidding agent is an entity that implements an online
advertising campaign by bidding in ad auctions on behalf
of an advertiser. A recent development in Web advertising
is the emergence of an auction-based marketplace for dis-
play ads, where advertisers can bid on individual display
advertising opportunities in real time auctions, as in spon-
sored search. Such a marketplace allows advertisers greater
ﬂexibility in the design and implementation of their display
advertising campaigns, which were previously restricted to
contracts with publishers at pre-negotiated prices. In this
paper, we study the design of bidding agents for display ad-
vertising, which implement an ad campaign by bidding in
such an auction-based marketplace. The bidding agent in
question could either be an advertiser herself, or an inter-
mediary acting on behalf of the advertiser.

Since display advertising is usually sold on a per impres-
sion (CPM) basis, a campaign for display advertising has
diﬀerent goals and metrics than one for sponsored search [2].
A CPM-based campaign typically has a target quantity of
impressions that need to be acquired over a certain duration
with certain targeting characteristics (the targeting can in-
clude information both about the webpage on which the ad
will appear, as well as the user viewing the page). In addi-
tion to the target quantity, a typical constraint in a CPM
campaign is a budget constraint on the total spend, since
payment is made on a CPM rather than a per click (CPC)
basis. We will assume that the bidding agent wants to ex-
haust, rather than simply stay within, the allocated budget,
for the following reason. Diﬀerent advertisers often have dif-
ferent pieces of information regarding how valuable a partic-
ular user might be, and often a high bid for an impression
reﬂects this information; thus a high price might indicate
high value1. This also agrees with anecdotal observations
that advertisers prefer to exhaust their budgets.

Consider a bidding agent that needs to win d impressions
and has a total budget T . We assume that the bidding agent
knows the total supply n of impressions satisfying the tar-

1We assume that an intermediary implementing a campaign
on behalf of an advertiser would also like to deliver high-
value impressions subject to the chosen budget. Since our al-
gorithms target supply over budget when they are not simul-
taneously feasible, the intermediary can deliver the cheapest
impressions if desired by choosing a small enough budget.

WWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization251geting requirements (this is clearly not true in practice, but
a lower bound on the supply can be used instead). Deﬁne
f = d/n to be the fraction of the supply that the agent
needs to win, and deﬁne t = T /d to be target spend per im-
pression won. We suppose that the highest bids from other
bidders are drawn i.i.d.2 from a distribution with CDF P,
and that each impression is sold using a second price auction.
In general, a given target quantity and spend need not be
simultaneously feasible for the distribution P—if this hap-
pens, we always choose in favor of quantity (our algorithms
can be modiﬁed to make the opposite choice).
If the distribution P is known to the bidding agent, then
the problem is simple (under weak conditions described in
Section 2). Let z(cid:63) = P−1(f ) be the bid that would win frac-
tion f of the supply. Deﬁne p(cid:63) such that EP [X | X ≤ p(cid:63) ] = t,
that is, p(cid:63) is the bid that achieves the target spend t in
If z(cid:63) ≤ p(cid:63) then bidding p(cid:63) with probability
expectation.
A = f /P(p(cid:63)) independently on each available impression
achieves both the supply and spend targets in expectation.
Otherwise, prioritizing supply, we bid z(cid:63) achieving the de-
sired fraction of supply in expectation.
In practice, of course, the distribution P is not known to
the bidding agent. Our problem is therefore one of learn-
ing the unknown distribution P in order to meet the target
quantity and spend constraints. However, learning incurs a
penalty, leading to an explore-exploit tradeoﬀ. The nature
of the penalty depends on the assumptions made about the
extent of information available to the bidding agent. We
consider two settings:

• Fully Observable Exchange. Here, the winning bid
in each auction is announced publicly, so that the bid-
ding agent can learn without placing any bids and
therefore expending any budget. The only tradeoﬀ
here is between accuracy and length of exploration,
which could aﬀect feasibility during exploitation.

• Partially Observable Exchange. A harder problem
is when the winning bid is not announced publicly—
only the winner receives information about the price
and therefore the distribution (a realistic setting in
online advertising). Thus the bidding agent can infer
information about P only by bidding high enough to
win, i.e., it must pay for every sample it observes from
the distribution.

We begin in Section 2 with algorithm Learn-Then-Bid for
the fully observable case, and provide performance guaran-
tees using non-asymptotic uniform convergence results for
empirical processes. While the algorithm is simple—it ob-
serves and then bids according to the empirical distribution,
the analysis is a useful ﬁrst step for the partially observable
case. A natural improvement is to continue to learn while
exploiting; this algorithm indeed outperforms Learn-Then-
Bid as shown experimentally in Section 4.

In Section 3 we move on to the partially observable case,
which is harder since a cost must be paid for every bid that
is observed from the distribution. We give an algorithm
Guess-Double-Panic that explores the distribution gradually
based on a guess-then-double pattern, in order to control the
spend in the learning phase. A simple guess-then-double
algorithm does not suﬃce since the distribution may have
mass concentrated right above a guess, leading to severe

2See Section 5 for a discussion.

overspending upon doubling. We introduce a panic phase
to the algorithm to deal with this problem, which limits the
overspending and admits performance guarantees.

In Section 4 we experimentally evaluate these algorithms,
as well as some additional heuristics, on realistic data de-
rived from the Right Media Exchange. Both Learn-Then-
Bid (and its improved version Learn-While-Bid ) and Guess-
Double-Panic perform very well for a wide range of target
fractions and spends. The experiments also demonstrate
that natural heuristics for the partially observable case are
indeed inadequate, and are well outperformed by Guess-
Double-Panic. Most interestingly, the lack of full infor-
mation is not a severe handicap: Guess-Double-Panic does
nearly as well as Learn-Then-Bid despite access to only par-
tial information.

Related work: Although there are many commercial
ventures that optimize campaigns on behalf of advertisers,
the design and analysis of bidding agents for online adver-
tising has not received much attention in the research lit-
erature. The focus has largely been on bidding agents for
sponsored search keyword auctions—for instance, Cary et
al. [2] propose and analyze a pragmatic bidding agent for
sponsored search. Unlike display advertising, the goal there
is to choose the optimal (utility maximizing) slot to bid on
for each keyword; the authors show that there is a greedy
bidding strategy that leads to convergence to equilibrium
when all advertisers use the same strategy.

In this paper, we consider approaches inspired by online
learning (cf. [3] for a survey).
In particular, our results
are similar to those on the multi-armed bandit algorithm
UCB1 [1] where there is an unknown stationary distribu-
tion over events from round to round; we do almost as well
asymptotically as we would had the distribution been known
in advance. However, although this work has been extended
to uncountably inﬁnite action spaces [5], it diﬀers in two ma-
jor factors: we try to get the correct average behavior (i.e.,
to behave correctly on average). Regret is inappropriate for
this setting: bids going over budget result in a payoﬀ of −∞.
Second, the expected price obtained on a given round as a
function of the bid (roughly analogous to cost in [6]) is not
only non-convex, but there is also no pre-determined Lips-
chitz constant K, making discretization of the action space
unboundedly ineﬃcient as a method of approximation. As
an alternative, we focus on the speciﬁc properties of the
problem to more eﬃciently explore and exploit.

2. FULLY OBSERVABLE EXCHANGE

We ﬁrst consider a fully observable exchange where the
winning bid is revealed after every auction. After describing
the algorithm we use the DKW inequality to bound the error
on our estimates and the suboptimality of our performance.
Learn-Then-Bid takes as input a target fraction f , spend
t, supply n and exploration length m. It explores for m steps
by bidding 0, that is, simply waiting and forms the empirical
CDF Pm from the observations Ei ∼ P. It then computes
bid value3 P (cid:63)
m that would achieve the target spend t, and
Z (cid:63)
m that would achieve the necessary fraction, and bids P (cid:63)
m
with probability Am if is feasible to achieve both targets on
Pm, else it bids Z (cid:63)
m.

We prove that the expected future fraction of impressions
won and amount spent per impression by Learn-Then-Bid
3We follow the convention that inf ∅ := +∞.

WWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization2522: Pm(x) ← m−1(cid:80)m

Algorithm Learn-Then-Bid (f, t, n, m)
1: Bid 0 for the ﬁrst m opportunities;
m ← inf {p : EPm [X | X ≤ p ] ≥ t}

i=1 1 [Ei ≤ x];
(cid:111)

f n

(n−m)Pm(P (cid:63)
m)

(cid:110)

3: P (cid:63)
4: Am ←
5: Z (cid:63)
6: if P (cid:63)
7:
8:
9: else
10:
11: end if

m ← inf
m ≥ Z (cid:63)
for opportunities i ∈ {m + 1, . . . , n} do

z : Pm(z) ≥ f n
n−m
m then

Bid P (cid:63)

m with probability Am, and 0 otherwise.
for opportunities i ∈ {m + 1, . . . , n} do Bid Z (cid:63)
m.

converge in probability with rates exponential in the learning
phase length.
We assume that the distribution P is continuous, strictly
monotonic, has support on [a, b] where 0 ≤ a < b < ∞ and
P(a) = 0. This implies that g(y) = EP [X | X ≤ y ] is well-
deﬁned, continuous and strictly increasing over [a, b], and so
P−1 and g−1 are well-deﬁned also.

Many of the results we obtain depend upon the problem
being feasible after exploration. In Section 4 we show ex-
perimentally that m can be chosen small enough so that
the problem remains feasible for most f and t. Moreover in
normal scenarios, one needs a small number of impressions
and has a small budget, and the total number of impressions
tends to be large.

Definition 1. Deﬁne γ = f n

n−m . If t ≤ EP [X], deﬁne
p(cid:63) = g−1(t). A problem is feasible after exploration if
t ≤ EP [X] and P(p(cid:63)) ≥ γ.
Note that this also implies γ ≤ 1. We will refer to γ and p(cid:63)
throughout this section as deﬁned above.
2.1 Measurement Errors

The performance of the algorithm depends primarily upon

the accuracy of the exploration phase measurements.

Definition 2. For a given  > 0, the algorithm has -

accurate observations if for all x ∈ [a, b]:

|P(x) − Pm(x)| ≤  .

(1)

The following is a restatement of the DKW inequality [4].
For the remainder of the analysis, we will condition our re-
sults on the observations being -accurate.

Corollary 3. For  > 0, the probability of the algorithm
having -accurate observations is greater than or equal to

1 − 2 exp(cid:0)−2m2(cid:1).

We next link -accuracy to the expected fraction of supply

won when bidding Z (cid:63)
m.

Lemma 4. Given  > 0, if the problem is feasible after ex-
ploration, and the Learn-Then-Bid algorithm has -accurate
observations then

m) − γ| ≤  .
Proof. We ﬁrst consider bidding Z (cid:63)

|P(Z (cid:63)

m on each round of
the bidding phase; our goal is to prove that the expected
fraction won P(Z (cid:63)
m) is close to the target fraction γ w.h.p. If

(2)

γ ≤ , then P(Z (cid:63)
m) ≥ 0 ≥ γ − . If γ > , then (0, γ − ] (cid:54)= ∅,
and for any (cid:48) ∈ (0, γ − ], deﬁne z(cid:63)− = P−1(γ −  − (cid:48)).
Because the algorithm has -accurate observations:

(cid:0)z(cid:63)−(cid:1) ≤ P(cid:0)z(cid:63)−(cid:1) +  = γ − 

Pm

(cid:48)

< γ ≤ Pm (Z (cid:63)

m) ,

and so z(cid:63)− < Z (cid:63)
for all (cid:48) ∈ (0, γ − ], P(Z (cid:63)
P(Z (cid:63)

m by the monotonicity4 of Pm. Therefore,
m) > P(z(cid:63)−) = γ − − (cid:48), implying

m) ≥ γ − . By a similar argument, P(Z (cid:63)

m) ≤ γ + .
2.2 Approximation of Target Supply Won

Our ﬁrst main result states that Learn-Then-Bid wins
close to f n opportunities, if the algorithm has -accurate
observations and the problem is feasible after exploration.
The following lemma is a consequence of a positive partial
derivative.

Lemma 5. For γ,  > 0, xγ(x+)−1 is strictly increasing,

and xγ(x − )−1 is strictly decreasing.

Theorem 6. Given  > 0, and j > m, let Bj be the
jth bid of the Learn-Then-Bid algorithm. If the problem is
feasible after exploration and the algorithm has -accurate
observations, then:

m and therefore Bj = Z (cid:63)

γ −  ≤ E[P(Bj)|E1 . . . Em] ≤ γ − 
γ − 2
γ .
(3)
Proof. From Lemma 4, we know that |P(Z (cid:63)
m) − γ| ≤ .
m ≥ P (cid:63)
m, then γ −  ≤ P(Bj) ≤
If Z (cid:63)
γ +  ≤ γ−
γ−2 γ. Therefore for the remainder of the proof we
assume that P(P (cid:63)
m with probability Am, and zero
otherwise (P(0) = 0). The conditional probability of win-
ning bid j given the outcome of the exploration phase is
P(P (cid:63)
it is this value we wish to show is close to the
target γ:
P(P (cid:63)

In this case, Bj = P (cid:63)

γ ≥ γ − 

m) ≥ P(Z (cid:63)

m) ≥ γ − .

m)Am:

γ .

m)

m)Am =

γ ≥ P(P (cid:63)
P(P (cid:63)

P(P (cid:63)
m)
Pm(P (cid:63)
m)

m) + 

γ

The ﬁrst equality follows by deﬁnition of Am, the ﬁrst in-
equality follows due to the -accurate observations, and the
ﬁnal inequality is a consequence of Lemma 5 and the in-
equality P(P (cid:63)
m) ≥ γ − . We upper-bound the
expected fraction won in a similar fashion:

m) ≥ P(Z (cid:63)

P(P (cid:63)
m)
Pm(P (cid:63)
m)

γ ≤ P(P (cid:63)
P(P (cid:63)

m)
m) − 

γ ≤ γ − 
γ − 2

γ .

2.3 Approximation of Target Spend

Our second theorem establishes that Learn-Then-Bid
spends close to budget if the observations are -accurate and
the problem is feasible after exploration. To prove this, we
ﬁrst convert DKW-type uniform closeness of true and em-
pirical CDFs to uniform closeness of expected spend. This
“uniformity” is gained by focusing only on the area of inter-
est, bids that obtain at least γ −  impressions.
(γ−)(γ−2) + (b−a)
γ−2 ,

For a given  ∈ (0, γ/2), deﬁne − =

b

γ(γ−) + (b−a)

γ

and + = b
4It is important that Pm(z(cid:63)−) is strictly less than Pm(Z (cid:63)
m)
because Pm is weakly monotonic, thus the need for (cid:48) > 0.

.

WWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization253Lemma 7. Given  ∈ (0, γ/2), let z(cid:63)− = P−1(γ − ) and
deﬁne the function gm(y) = EPm [X | X ≤ y ]. If the algo-
rithm has -accurate observations , then if Y ≥ z(cid:63)−:

gm(Y ) − 

− ≤ g(Y ) ≤ gm(Y ) + + .

Proof. Because the algorithm has -accurate observa-
tions, both of the following relations hold5 for all y ∈ [a, b]:

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90) y

a

(1 − P(x)) dx −

(cid:90) y

a

|P(y) − Pm(y)| ≤ 
(1 − Pm(x)) dx

(cid:12)(cid:12)(cid:12)(cid:12) ≤ (b − a) .

Lower-bounding gm(Y ) with the above relations, identity
c+ = d

c(c+) , and P(Y ) ≥ P(z(cid:63)−) = γ − :

c − d

d

gm(Y ) =

a (1 − Pm(x)) dx

Pm(Y )

a +(cid:82) Y
≥ a +(cid:82) Y
= g(Y ) − (a +(cid:82) Y

a (1 − P(x)) dx
P(Y ) + 

− (b − a)
P(Y ) + 
a (1 − P(x)) dx)
P(Y )(P(Y ) + )
− (b − a)
b

.

γ(γ − )

γ

≥ g(Y ) −

− (b − a)
P(Y ) + 

(4)

Upper-bounding gm(Y ) proceeds by the same arguments

and identity d

c− = d

c + d

c(c−) .

Theorem 8. Given the problem is feasible and  ∈ (0, γ/2),
if the algorithm has -accurate observations, j > m and Bj
is the jth bid and Bj > 0, then: t − − ≤ g(Bj) ≤ t + +.

Proof.

t − 

− ≤ g(max(Z (cid:63)

m, P (cid:63)

m)) ≤ t + + .

(5)

m, P (cid:63)

Note that if j > m and Bj > 0 then Bj = g(max(Z (cid:63)
m)).
As with Lemma 4, we need to analyze values that bracket
the value of interest. In particular, the ﬁrst value of interest
is z(cid:63)− = P−1(γ − ). If g(z(cid:63)−) ≥ t − −, then by Lemma 4,
m ≥ z(cid:63)−, and by the monotonicity of
max(Z (cid:63)
m, P (cid:63)
m)) ≥ g(z(cid:63)−) ≥ t − −. Therefore, we can
g, g(max(Z (cid:63)
assume that g(z(cid:63)−) < t− −. Since t > t− − > g(z(cid:63)−) ≥ a,
t − − is in the range of g and g−1(t − −) ≥ z(cid:63)−. For
(cid:48) ∈ (0, t − − − a], deﬁne p(cid:63)− = g−1(t − − − (cid:48)).

m) ≥ Z (cid:63)
m, P (cid:63)

gm(p(cid:63)−

) −  = t − 
(cid:48)

) ≤ g(p(cid:63)−
< t ≤ gm(P (cid:63)

m) ,

m, P (cid:63)

so p(cid:63)− ≤ P (cid:63)
creasing, for any (cid:48) > 0, t − − − (cid:48) ≤ g(P (cid:63)
t − − ≤ g(P (cid:63)
t + + ≥ g(P (cid:63)
From Corollary 3 the algorithm has -accurate observations

m. Therefore, because g is monotonically in-
m), implying
m) ≤ g(max(Z (cid:63)
m)). By a similar argument,
m).

with probability 1 − 2 exp(cid:0)−2n2(cid:1). Combining this with
ration. If  ∈ (0, γ/2): With probability 1 − 2 exp(cid:0)−2n2(cid:1):

Theorems 6 and 8 proves that Learn-Then-Bid ’s performance
converges to the targets in probability with fast rates:

Theorem 9. Given a problem that is feasible after explo-

t − 

− ≤ g(Bj) ≤ t + + if Bj > 0

(6)

γ −  ≤ E[P(Bj)|e1 . . . em] ≤ γ − 
γ − 2

(7)
5The integrals are well-deﬁned because P and Pm are
bounded, monotonic functions.

γ .

3. PARTIALLY OBSERVABLE EXCHANGE
We now move on to the partially observable case, where
information is revealed only to an auction’s winner. This
problem is more diﬃcult because the bidder must pay a cost
in order to obtain information; speciﬁcally, we cannot simply
learn about the auction by bidding zero for a while. The
most brute force approach is to bid ∞ for an exploration
period, but that can cause overspending by almost b/t when
the target fraction is small. In this section, we will try to
be approximately optimal. If b/t is small then we can bid b:
however, we also want to handle the case where b/t is large.
Consider a simple algorithm that works rather well: bid 2t
blindly until the correct number of impressions are obtained.
Observe that since the minimum bid to get f n impressions
is less than the bid that gets an expected price of t, then the
expected price paid when a bid is made which obtains f n is
less than or equal to t. Therefore, by Markov’s inequality,
the number of the lowest f n impressions below 2t is f n/2.
Moreover, the most that one can spend is 2tf n, and since
the budget is tf n, this is only twice the budget. Therefore,
this algorithm will not dramatically overspend and it will
obtain half the required impressions.

Instead of either of these extremes (bidding 2t blindly or
aggressively exploring with b), we will apply the guess-then-
double pattern. This approach is used in a variety of do-
mains. For instance, if we want to create an array of items
but do not know how many elements it will contain, we make
a guess, and if we need more space, we double the size of the
array. Thus, the number of new allocations is logarithmic in
the number of elements entered, and the number of copies
is linear, and the size may be oﬀ by no more than a factor
of two. Of course, doubling is only one possibility:
in the
case of the array, multiplying by a factor φ smaller than 2
will result in more copies but greater eﬃciency in space.

In the Guess-Double-Panic algorithm, we apply a modi-
ﬁcation of this technique to bids in the exploration phase.
We will refer to a bid being used during exploration as an
exploration bid. A “safe” bid6 is t, the target spend, since
there is no danger of going over budget. From this point, we
exponentially increase our exploration bid, exploring enough
with each new bid to learn the distribution below this bid.
At some point we notice our exploration bid exceeds p(cid:63).

A na¨ıve approach is to simply test for this condition at
each iteration, and then react to our experience at the end
of each phase of the exploration (i.e., remove lines 8-9). How-
ever, this can result in a large amount of overspending, as
the following example shows.7 The target price is 10 cents
and we need to obtain 10% of the 1000 impressions. There-
fore, we are searching for 100 impressions for $10.00 total.
The distribution of bids is: 9.9% are at 1 cent. 0.1% are
at $9.01. Finally, the remaining 90% of the bids are at
$10.00. An ideal bid is $9.01. However, it is diﬃcult to
say whether this one bid will be observed. Unless there is a
very slow exploration, the bids will likely exceed $10.00 dur-
ing exploration. Thus, there will be a high penalty where
the algorithm will most likely pay 10 times its budget.

Instead, if we start overspending during the exploration
phase, we go to the Panic() subroutine, where we move into

6There is also the possibility that we underspend. This can
happen if we get many opportunities while we are bidding
too low. However, this is not a problem so long as the ex-
ploration period is suﬃciently short with respect to γn.
7A similar continuous distribution is easy to construct.

WWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization254a new phase of “cautious exploration”. Eﬀectively, if we are
overspending, then we momentarily ignore the budget, and
target solely the number of impressions obtained. As before,
we continue to increase the bids, but if we realize that we
can get enough impressions in the exploitation phase, we
immediately move on to the exploitation phase.

The algorithm continues to explore (or panic) until it ﬁnds
a price Bi(cid:63) where it estimates its budget can be exhausted
and it can win enough impressions (or it has explored at
b or above). As with the observable case, we have a good
approximation of the outcome of bidding any price below
Bi(cid:63) as we leave the exploration phase.

In particular, there are now three modes of operation.
The ﬁrst mode is exploration: the algorithm explores until
it either gets enough information or the budget becomes
tight. The second (optional) mode is panic: the budget is
tight, but the algorithm does not have enough information
to obtain the right number of impressions, so it aggressively
grabs impressions until it reaches a more stable scenario.
The third stage is exploitation.
In the exploitation stage,
if there is suﬃcient budget to obtain the right number of
impressions, then the algorithm tries to exhaust the budget.
Otherwise, it is thrifty and tries to get the right number of
impressions at a discount price.

For the following algorithm, all variables are global.

Algorithm Guess-Double-Panic(f, t, n, m, φ)
1: Initialize: gremain ← f n; budget ← tgremain
2: Initialize: P0 ← 0; T0 ← 0; B0 ← 0; i ← 0; j ← 0
3: while (Tigremain < budget or Pi(n − j) < gremain) and

Bi < b do
i ← i + 1.
Si ← ∅ to be a multiset.
for k = 1 to m do

4:
5: Bi ← t(φ)i−1.
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:

end if
end for

if Si (cid:54)= ∅ then Ti ← 1|Si|
Pi ← |Si|
21:
m .
22: end while
23: i(cid:63) ← i.
24: return Exploit().

return Panic()

if (gremain − 1)Ti−1 + Bi−1 > budget then
j ← j + 1.
if gremain = 0 then Terminate.
Bid Bi.
if Bid wins then

Deﬁne pj ← price won.
gremain ← gremain − 1.
budget ← budget − pj.
Add pj to Si.

(cid:80)

p else Ti ← 0.

p∈Si

The ﬁrst danger of using any exploration technique is
that the problem may be unsolvable if one spends too much
time exploring. Note that there will be no more than r =
(cid:100)logφ(b/t)(cid:101) + 1 rounds of exploration, because then the bid
will be above b. In each round, there are m bids, so mr is
the maximum number of steps of exploration.

Definition 10. Deﬁne γ = f n

n−mr . If t ≤ EP [X], deﬁne
p(cid:63) = g−1(t). A problem is feasible after exploration if
t ≤ EP [X] and P(p(cid:63)) ≥ γ. (Again, this implies γ ≤ 1.)

if gremain < Pi−1(n − j) then

Deﬁne pj ← price won.
gremain ← gremain − 1.
budget ← budget − pj.
Add pj to Si.

end if
j ← j + 1.
Bid Bi.
if Bid wins then

Subroutine Panic
25: while Bi−1 < b do
26: while k ≤ m do
27:
i(cid:63) ← i − 1.
28:
29:
return Exploit().
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:

end if
k ← k + 1.

end while
k ← 1.
if Si (cid:54)= ∅ then Ti ← 1|Si|
Pi ← |Si|
m .
i ← i + 1.
Si ← ∅ to be a multiset.

43:
44:
45: Bi = t(φ)i−1.
46:
47: end while
48: i(cid:63) ← i − 1.
49: return Exploit().

(cid:80)

p∈Si

p else Ti ← 0.

Let us consider the period that generated Si. Deﬁne S(cid:63)
i
to be the multiset of all prices (observed and unobserved)
during this period (clearly not an observed set). As in the
observed case, there are several observations we could make
about this distribution (although in this case only theoreti-
cally). Formally, deﬁne:

P i
m(x) = m

−1|{y ∈ S(cid:63)

i |y ≤ x}| .

(8)

Moreover, we can look at these independently from the al-
gorithm itself.

Definition 11. The algorithm has -accurate observa-
m(x)−P(x)| ≤

tions if for each i ∈ {1 . . . r}, argmaxx∈[a,b] |P i
.

servations is at most 2((cid:100)logφ(b/t)(cid:101) + 1) exp(cid:0)−2m2(cid:1).

Lemma 12. The probability of not having -accurate ob-

The probability of -accurate observations can be deter-
mined by applying the DKW inequality to each round of
exploration/panicking, and then applying a union bound.

Deﬁne Cexplore, Cpanic and Cexploit to be the spend dur-
ing exploration, panic and exploitation, respectively. Deﬁne
nexplore, npanic and nexploit to be the number of impressions
won during exploration, panic and exploitation phases, re-
spectively. Deﬁne m(cid:48) to be the number of opportunities
during the exploration and panic phases combined. De-
ﬁne n(cid:63)
exploit to be the target number of impressions that
remain after the exploration and panic phases. Note that
this is equal to gremain at the beginning of the exploitation
phase. Instead of targeting γ as we did before, we are tar-
exploit ≤ f n
geting γ(cid:48) =
and m(cid:48) ≤ mr, implying that γ(cid:48) ≤ 1. Because the number
of impressions obtained is a priority, the proof that this is
achieved is fairly straightforward. The spend we will bound
is C = Cexplore + Cpanic + E[Cexploit|E1 . . . Em(cid:48) ].

, where γ(cid:48) ≤ γ because n(cid:63)

n(cid:63)
exploit
n−m(cid:48)

WWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization255Subroutine Exploit
50: If gremain ≤ 0 or j ≥ n then Terminate.
51: Bﬁnal ← Bi(cid:63) .
52: A ← gremain
Pi(cid:63) (n−j) .
53: if Pi(cid:63) (n − j) > gremain and Ti(cid:63) gremain > budget then
Sort p ∈ Si(cid:63) : deﬁne qk to be the kth smallest p in Si(cid:63) .
54:
55:

ks ←(cid:108) gremain

(cid:109)

n−j m

(cid:80)k

.

k

gremain

i=1 qi.

for k = 1 to |Si(cid:63)| do gk ← 1
t(cid:63) ← budget
kp ← mink:gk≥t(cid:63) k.
k(cid:63) ← max(ks, kp).

56:
57:
58:
59:
60: Bﬁnal ← qk(cid:63) .
61: A ← k(cid:63)
m .
62: A ← gremain
A(n−j) .
63: end if
64: while More rounds and gremain > 0 do
65:
66:
67: end while

Bid Bﬁnal with probability A, 0 otherwise.
If Bid won then gremain ← gremain − 1.

Theorem 13. If the problem is feasible after exploration,

and the algorithm has -accurate observations, then:
f n ≥ nexplore + npanic + (n − m
where Bﬁnal and A are as in Line 65.

)P(Bﬁnal)A ≥ f n −  ,

(cid:48)

m, and qkp is analogous to P (cid:63)

Proof. The upper bound is true because there is always
a check that gremain > 0 before any bid is made. The proof
of the lower bound has the same rough outline as Theorem 6.
qks is analogous to Z (cid:63)
m. Now
the target fraction of impressions to win during exploitation
may be lower than γ, due to some being won during the ex-
ploration and panic. However, it is still easy to prove that
|P(qks ) − γ(cid:48)| ≤  using techniques similar to Lemma 4, be-
cause the proof does not depend upon the target. The most
serious issue is when kp ≥ ks (analogous to P (cid:63)
m), there
is no implicit lower bound on P(qkp ) outside of γ(cid:48). This
makes the upper bounds that we obtained in Theorem 6
impossible to obtain, and why we explicitly bound the num-
ber of impressions obtained from above. However, the lower
bounds on AP(qkp ) work out just as in Theorem 6.
3.1 Bounding the Amount Spent

m ≥ Z (cid:63)

We prove an upper bound on the spend of the algorithm.

Theorem 14. If the algorithm has -accurate observa-
tions and the problem is feasible after exploration, then C ≤
φtf n + (1/3 + 2/3)nb.

Proof. With Lemmas 15-21, we cover overspending based
upon every outcome of exploration and panic, as well as the
relationship between ks and kp. In particular:

1. If the algorithm exits exploration on Line 24, then
Lemma 15 applies if kp ≥ ks, and Lemma 21 applies if
kp < ks.

2. If the algorithm exits exploration on Line 11, then

Lemma 16 applies.

3. If the algorithm exits exploration on Line 9, then
Lemma 17 applies if no panic bids are made, Lemma 18
applies if a panic bid of Bi(cid:63)+1 is made, Lemma 20 ap-
plies if the largest panic bid is Bi(cid:63) and kp ≤ ks, and
Lemma 19 applies if kp > ks.

Lemma 15. If the algorithm exits the exploration phase
at Line 24, the algorithm has -accurate observations, the
problem is feasible after exploration, and kp ≥ ks, then the
amount overspent is less than C ≤ tf n + (1/3 + 2/3)bn.

Proof. As before, if a large fraction of the impressions
remains, then the estimates will be accurate. On the other
hand, if many of the impressions are already gone, the im-
pact of making a mistake is less.
We choose a point, γ(cid:63) = 1/3+, as a threshold: if γ(cid:48) > γ(cid:63),
we can bound the spend normally. If γ(cid:48) ≤ γ(cid:63), then the most
we can spend is γ(cid:63)b.

As we consider the bound proven in Lemma 7, if we replace

γ with γ(cid:63) in Equation 4, then we get:

gm(Y ) ≥ g(Y ) −

b

γ(cid:63)(γ(cid:63) − )
b

− (b − a)

γ(cid:63)

− (b − a)

1/3

( + 1/3)(1/3)

= g(Y ) −
≥ g(Y ) − 1/3b − 2/3(b − a)
≥ g(Y ) − 1/3b − 2/3b .

(9)

(10)

(11)

(12)

Equation 12 follows because decreasing the denominator
(replacing +1/3 with ) makes the term larger, but making
a negative term larger makes the overall expression smaller.
Also, since  ≤ 1, 2/3 ≥ , implying γ(cid:48)b ≤ 1/3b + 2/3b.

Lemma 16. If exploration exits due to Line 11, then C ≤

φtf n .

Proof. Deﬁne B(cid:63) to be equal to budget at the last time
Line 8 was visited. This is the ideal amount to bid on the
last bid such that the budget is exactly met. The maximum
amount that could be bid would be Bi. Before the last bid
was made, gremain = 1 and (due to Line 8), Bi−1 ≤ B(cid:63).
Therefore, Bi ≤ φB(cid:63). The maximum amount overspent
would be Bi − B(cid:63) ≤ (φ − 1). Since B(cid:63) ≤ tf n, the result
follows.

Lemma 17. If exploration exits on Line 9, and no panic
bids (Line 32) are made, then C ≤ φtf n + (1/3 + 2/3)nb.
Proof. During the middle of an exploration phase, an
impression is won (which we will call the overpriced im-
pression) and Line 8 is true. Deﬁne pop to be the price of
this bid. At the time when the expression in Line 8 is true:

tf n − budget = Cexplore + Cpanic

gremain = n(cid:63)

exploit .

(13)

(14)

Consider the last time that Line 8 is false, i.e.when one less
impression was won and pop less was spent.

tf n − budget = Cexplore + Cpanic − pop (15)
gremain − 1 = n(cid:63)
(16)

exploit

(gremain − 1)Ti−1 + Bi−1 ≤ budget
(n(cid:63)

exploit)Ti−1 + Bi−1

(17)

≤ tf n + pop − (Cexplore + Cpanic) .

(18)
In this case, since we go through panic, at this time i−1 = i(cid:63),
we can reframe this as a bound on the “spend”:

Cexplore + Cpanic + (n(cid:63)

exploit)Ti(cid:63) ≤ tf n + pop − Bi(cid:63) .

Because pop − Bi(cid:63) ≤ (φ − 1)Bi(cid:63) ≤ (φ − 1)tf n:

Cexplore + Cpanic + (n(cid:63)

exploit)Ti(cid:63) ≤ φtf n .

(19)

WWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization256The ﬁnal issue is that Ti(cid:63) is not necessarily equal to g(Bi(cid:63) )
(even though Ti(cid:63) is an estimate of g(Bi(cid:63) )). The remainder is
similar to Lemma 15. There are two scenarios: either Pi(cid:63) is
small, and therefore few impressions are left to obtain, or Pi(cid:63)
is large and Ti(cid:63) is accurate. Formally, consider γ(cid:63) = +1/3.
If Pi(cid:63) ≤ γ(cid:63), then because the expression in Line 27 is true,
exploit ≤ nγ(cid:63). If Pi(cid:63) ≥ γ(cid:63), then P(Bi(cid:63) ) ≥ γ(cid:63) − , then
n(cid:63)
substituting γ(cid:63) for γ in Lemma 7:

g(Bi(cid:63) ) ≤ Ti(cid:63) +

(b − a)

γ(cid:63)

+

b

γ(cid:63)(γ(cid:63) − )
b

(b − a)
 + 1/3

(1/3 + )(1/3)

= Ti(cid:63) +
+
≤ Ti(cid:63) + 1/3b + 2/3(b − a)
≤ Ti(cid:63) + 1/3b + 2/3b .

(20)

(21)

(22)

(23)

Summarizing:

exploit) ≤ max(γ(cid:63)nb, (Ti(cid:63) + 1/3b + 2/3b)f n)

g(Bi(cid:63) )(n(cid:63)
Cexplore + Cpanic + n(cid:63)

exploitg(Bi(cid:63) ) ≤

φtf n + max(γ(cid:63)nb, (1/3b + 2/3b)f n) .

Because γ(cid:63) =  + 1/3, and f ≤ 1, the result follows.

Lemma 18. If, during the Panic() algorithm, a bid of
Bi(cid:63)+1 is the highest bid that is actually made, the problem is
feasible after exploration, and the algorithm has -accurate
observations, then C ≤ f n(tφ + b).

Proof. During exploitation, the algorithm bids no more
than Bi(cid:63) , so the expected price per impression is at most
g(Bi(cid:63) ). This is the easy part; the hard part is bound-
ing the spend during exploration and panic. Deﬁne b(cid:63) =
min(Bi(cid:63)+1, b), the largest eﬀective bid during panicking. How
many impressions need to obtained before the algorithm re-
alizes it can bid Bi(cid:63) for the remainder? Formally:
max #big bids won = f n − (P(Bi(cid:63) ) − )(n − mr)

= f n

= f n

= f n

Cpanic + Cexploit ≤ f n

(cid:19)

f n

(cid:18)
1 − (P(Bi(cid:63) ) − )(n − mr)
(cid:18)
1 − (P(Bi(cid:63) ) − )
(cid:18) γ − (P(Bi(cid:63) ) − )
(cid:18) γ − (P(Bi(cid:63) ) − )

(cid:19)
(cid:19)
(cid:19)

γ

γ

b(cid:63) .

γ

In other words, the maximum fraction of bids won during
exploration and panic is ( + γ − P(Bi(cid:63) )) γ−1. Note that if
the algorithm were to bid P−1(γ) ≤ p(cid:63), then in expectation
(γ − P(Bi(cid:63) )) γ−1 bids would be Bi(cid:63) or above. Therefore, if
the problem is feasible after exploration:

t = g(p(cid:63))
≥ g(P−1(γ))
≥ γ − P(Bi(cid:63) )

γ

Bi(cid:63) +

P(Bi(cid:63) )

γ

g(Bi(cid:63) )

γ

tφ ≥ γ − P(Bi(cid:63) )
≥ γ − P(Bi(cid:63) )
tφ + b(cid:63) ≥ γ − P(Bi(cid:63) )

γ

P(Bi(cid:63) )

Bi(cid:63) φ +

g(Bi(cid:63) )

γ
P(Bi(cid:63) )

b(cid:63) +

γ

g(Bi(cid:63) )
P(Bi(cid:63) )

γ
P(Bi(cid:63) )

γ

g(Bi(cid:63) )

b(cid:63) + b(cid:63) +

g(Bi(cid:63) )

≥  + γ − P(Bi(cid:63) )

b(cid:63) +

γ

γ

f n(tφ + b) ≥ Cexplore + Cpanic + E[Cexploit|E1 . . . Em(cid:48) ]] .
The last line is due to the fact that b(cid:63) is a bound on the
price during exploration and panic, g(Bi(cid:63) ) is a bound on
the expected price during exploitation, and the worst-case
scenario is to have the maximum number of bids during the
exploration and panic phases.

Lemma 19. If the largest panic bid is Bi(cid:63) , during ex-
ploitation ks < kp (such that the bid during exploitation is
based upon the target spend t), the problem is feasible after
exploration, and the algorithm has -accurate observations,
then C ≤ tf n + (1/3 + 2/3)bn.
Proof Sketch. This scenario is rare, in that it implies
that the algorithm panicked, but then somehow the budget
recovered. One possibility is that a very high but unlikely
bid was obtained, followed by small but unlikely bids.

Since the last round is -accurate, the argument is similar

to Lemma 15.

Lemma 20. If the largest panic bid is Bi(cid:63) , during ex-
ploitation ks ≥ kp (such that the bid during exploitation is
based upon the target number of impressions), the problem is
feasible after exploration, and the algorithm has -accurate
observations, then C ≤ φtf n + nb.
In this case, we know that P(Bi(cid:63)−1) ≤
Proof Sketch.
γ + , and for however long we are exploring and panick-
ing, we know that Bi(cid:63)−1 is not expected to give us enough
impressions, just as with Bi(cid:63) in Lemma 18. If the exploita-
tion bid B was less than or equal to Bi(cid:63)−1 (e.g., due to
a change in the estimation from Si(cid:63)−1 to Si(cid:63) ), then the
analysis from Lemma 18 holds, with i(cid:63) − 1 replacing i(cid:63). If
B > Bi(cid:63)−1, we know that all the bids we obtained during
exploration and panicking were not enough, and during ex-
ploitation, we choose a bid such that we get just enough im-
pressions above Bi(cid:63)−1. Thus, these impressions above Bi(cid:63)−1
during exploitation and the impressions during exploration
and panicking are almost exactly enough such that bidding
Bi(cid:63)−1 during exploitation would have won the remainder.
Therefore, Lemma 18’s argument completes the result.

Lemma 21. If the algorithm exits the exploration phase
at Line 24, the algorithm has -accurate observations, the
problem is feasible after exploration, and kp < ks, then C ≤
φtf n + (1/3 + 2/3)nb.

Proof. This is similar to Lemma 17, in that the algo-
rithm does not have more than one impression that is over-
priced (note that the last impression won during exploration
may be overpriced). Therefore, with the exception that
i(cid:63) = i, a variant of Equation 19 holds here.

Cexplore + Cpanic + (n(cid:63)

(24)
If Bﬁnal ≤ Bi(cid:63)−1, then the argument from Lemma 17 holds,
in that the algorithm might has well of panicked.

exploit)Ti(cid:63)−1 ≤ φtf n .

WWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization257If Bﬁnal > Bi(cid:63)−1, then the algorithm might as well have
panicked: the key condition (that it needs more impressions
that it believes will be obtained by Bi(cid:63)−1) is satisﬁed at
the end of the exploration phase, which is loosely what is
required in Lemma 20. Note that the bound in Lemma 17
is looser than the bound in Lemma 20.

Unfortunately, there are cases where the algorithm can
underspend. For instance, suppose that the objective is to
obtain a very small number of impressions at a very high
price. For instance, 10% of the impressions are at $11.00,
and 90% are at $1.00, and the target spend is $2.00, and the
algorithm wants 1% of the impressions. Therefore, bidding
$11.00 is ideal. However, if the algorithm starts by bidding
$2.00, it is possible that before exploration is over, the algo-
rithm obtains enough impressions, but has only spent half
the budget. Of course, in this case, the algorithm which
starts by bidding b to explore is doing just the right thing.

Figure 1: The observed and modeled distribution of
the winning bid on the Right Media Exchange.

4. EXPERIMENTS

In this section we evaluate our algorithms on syntheti-
cally derived data drawn from a log-normal distribution,
which ﬁts data observed from the Right Media Exchange.
Algorithms for the fully observable case are evaluated in
Section 4.2, and the partially observable case in Section 4.3.
4.1 Methodology and Data

To evaluate our algorithms, we collected winning bids
from live auctions run on the Right Media Exchange, which
has over 50,000 buyers and sellers and processes over 6 bil-
lion impressions daily. The bids we collected represent a
1% uniform sample across a variety of individual publish-
ers. Focusing on a single publisher, we plot the CDF of the
empirical distribution of the bids in Figure 1.

While it is diﬃcult to predict the winning bid on any par-
ticular impression, for a ﬁxed publisher the data can be ﬁtted
with a log-normal distribution with the appropriate mean
and variance. In Figure 1 we provide such a ﬁt for a single
publisher (350,000 auctions total). While the exact vari-
ance changes from publisher to publisher, on all instances
the data can be ﬁtted well with a log-normal distribution.

Based on the above ﬁt, we sample i.i.d. from a log-normal

distribution with mean and variance one.8 While very large
prices are never observed on the exchange, the log-normal
distribution supports arbitrarily large prices. We deal with
this by discarding samples larger than an upper-limit b, cho-
sen to be the 99.7th percentile. That is, we sample from the
log-normal distribution conditioned on {X ≤ b}.

We set the supply to be n = 10, 000 impressions. To eval-
uate each algorithm we choose 16 evenly spaced values of
target f and target t from the interval (0, 1), and measure
the actual fraction and spend against the targets (we in-
clude only 4 data points each for clarity). For each of the
256 parameter settings, we run each algorithm on 500 i.i.d.
samples to average out eﬀects of sampling.
4.2 Results: Fully Observable Exchange

m, Am and Z (cid:63)

The Learn-Then-Bid algorithm waits for a signiﬁcant ex-
ploration period before bidding. An obvious improvement
is the Learn-While-Bid algorithm which continues to learn
during exploitation: Pm, P (cid:63)
m are updated after
each bid, as in Learn-Then-Bid lines 2–5 but with adaptive
targets. Although harder to analyze, this has the advantage
of a possibly shorter exploration phase without compromis-
ing estimation accuracy. We compare the performance of
these two algorithms experimentally: on average both algo-
rithms perform very close to ideal. However, Learn-While-
Bid spending is more tightly concentrated around the ideal
than Learn-Then-Bid for the same exploration-only phase.
Figures 2 and 3 show the spending of Learn-Then-Bid
and Learn-While-Bid respectively. The dotted lines depict
the minimum spending necessary to achieve the target frac-
tion of supply as given by max{E [X | X ≤ z(cid:63)] , t}: when the
fraction and spend goals cannot simultaneously be satisﬁed,
both algorithms prioritize the former while minimizing over
spending. The distribution of each algorithm’s spending, for
each (f, t) pair, is summarized by a box-and-whisker plot:
each box depicts the 25%, 50% (the median) and 75% quan-
tiles representing the spread of spending. As is evident in the
ﬁgures, more runs of Learn-While-Bid have spend close to
the ideal. To achieve comparable concentration with Learn-
Then-Bid, m must be increased. However this can lead to
infeasibility for high f (e.g. for m = 1, 000 and f = 0.94 the
problem becomes infeasible leading to underdelivery). Fig-
ure 4 plots the performance of the algorithms with respect
to supply. Both algorithms win close to the target fraction
of supply for a wide range of target spending goals.

Figure 5 compares theory and practice, depicting our bou-
nds on the concentration of the fraction of supply won and
the spending per impression won, with respect to increasing
exploration length. As exploration increases, the bounds
become tighter but at the same time the problem becomes
harder to satisfy until it becomes infeasible (occurring at
the maximum m shown). Also shown are empirical results
for running Learn-Then-Bid. In particular for each m value
(exploration phase length), Learn-Then-Bid was run 1, 000
times. For each run the fraction won during exploitation,
and the spend per impression won, were calculated and the
95% two-sided quantiles were computed and overlayed. In
this case the distribution-free theory matches the empirical
results well, particularly for concentration of fraction won.

8We note that increasing the variance of the log-normal
distribution does not aﬀect our algorithms’ behavior; they
deliver the same supply and actually overspend less (since
there is a larger fraction of lower-priced impressions).

00.10.20.30.40.50.60.70.80.91  Empirical CDFLog Normal Model CDFWWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization258Figure 2: Actual & ideal spend per impression won
by Learn-Then-Bid with m = 100 for 4 values of f .

Figure 3: Actual & ideal spend per impression won
by Learn-While-Bid with m = 100 for 4 values of f .

Figure 4: Fraction of supply won by Learn-Then-Bid
and Learn-While-Bid with m = 100 for 4 values of t.

Figure 5: Learn-Then-Bid supply and spend 95%
conﬁdence bands given by:
the concentration
bounds, and 1,000-sample empirical quantiles.

4.3 Results: Partially Observable Exchange

In this section we evaluate algorithms for bidding in a par-
tially observable exchange. The Guess-Double-Panic algo-
rithm outperforms the strawman bidders in terms of target
spend for a wide range of target supply fractions. More in-
terestingly, the lack of full information does not handicap
the Guess-Double-Panic algorithm: the accuracy of supply
and spend are very close to those for full information.

Figures 6 and 7 plot the supply and spend for Guess-
Double-Panic as well as two strawman algorithms, Max-
Then-Bid and Bid-Two-t. Given that Learn-Then-Bid per-
forms well even for very short exploration phases, it is natu-

ral to apply the same idea in the partially observable setting:
Max-Then-Bid bids b in the length m exploration phase and
then exploits based on the empirical distribution.9

While Max-Then-Bid performs well on supply it is an in-
ferior strategy for target spend, since the spending during
exploration can be very high: speciﬁcally when f and t are
both small the algorithm must acquire the right number of

9Max-Then-Bid dominates Learn-Then-Bid in number of
impressions acquired despite partial
information: Max-
Then-Bid wins every impression during exploration in con-
trast to Learn-Then-Bid which wins zero. Also, if the prob-
lem is feasible after Learn-Then-Bid ’s exploration then it
will be feasible for Max-Then-Bid.

0.00.20.40.60.81.00.00.20.40.60.81.0Target Spend Per Impression Won  tActual Spend Per Impression Wonllllllllllllllllidealf = 0.059f = 0.353f = 0.647f = 0.941l0.00.20.40.60.81.00.00.20.40.60.81.0Target Spend Per Impression Won  tActual Spend Per Impression Wonllllllllllllllllidealf = 0.059f = 0.353f = 0.647f = 0.941l0.00.20.40.60.81.00.00.20.40.60.81.0Target Fraction of Impressions  fAttained Fraction of ImpressionsLTBLWBt = 0.059t = 0.353t = 0.647t = 0.941ideal100020003000400001234567Exploration Duration mSpending Per Impression Won0.00.20.40.60.81.0Fraction Won During ExploitationIdealTheoryExperimentSupplySpendWWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization259Figure 6: Fraction of supply won by Bid-Two-t, Max-
Then-Bid and Guess-Double-Panic with m = 100 for
4 values of t.

Figure 7: Spend per impression won by Bid-Two-
t, Max-Then-Bid and Guess-Double-Panic with m =
100 for 4 values of f .

impressions at a low price, and Max-Then-Bid is very likely
to overspend. Guess-Double-Panic will perform well pre-
cisely in this setting due to its more cautious exploration
starting with a bid of t as opposed to b. This comparison
is borne out in Figure 7 where Max-Then-Bid overspends
most dramatically relative to Guess-Double-Panic for the
lowest target fraction f = 0.059; overspending is evident for
higher values up to f = 0.59. The Bid-Two-t strawman al-
gorithm does not perform much better than expected from
theory, which predicts supply and spend within only a loose
multiplicative factor of the targets.

5. CONCLUSIONS

We study the problem of acquiring a given number of im-
pressions with a given budget constraint by bidding against
an unknown distribution. Our approach consists of learn-
ing the distribution in an exploration phase, and then bid-
ding according to the empirical distribution of observations
from exploration. We consider both the fully observable and
the harder partially observable case, and present algorithms
with theoretical performance guarantees that also perform
very well in experimental evaluations against realistic data.
The experiments indicate that in addition to performing well
with respect to both constraints, our algorithm for partial
information does nearly as well as algorithms in the full in-
formation setting despite the fact that a cost must be paid
for every sample during exploration. The performance of the
algorithms improves as the supply increases, and is asymp-
totically optimal since a longer exploration phase can be
used for higher accuracy; also, the actual number of impres-
sions won and the total spend are more tightly concentrated
around their means as n increases.

The most interesting direction for further research is re-
moving the i.i.d. assumption, and considering a game theo-
retic perspective: we assume that every other bidder in each
individual auction has unit demand and therefore bids his

value; one can instead consider best response and equilib-
rium analysis when a number of bidding agents compete in
such a marketplace.
Acknowledgements
We gratefully acknowledge the support of the NSF through
grant DMS-0707060.

6. REFERENCES
[1] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time
analysis of the multi-armed bandit problem. Machine
Learning, 47:235–256, 2002.

[2] M. Cary, A. Das, B. Edelman, I. Giotis, K. Heimerl,

A. Karlin, C. Mathieu, and M. Schwarz. Greedy
bidding strategies for keyword auctions. In EC ’07:
Proceedings of the 8th ACM Conference on Electronic
Commerce, pages 262–271, 2007.

[3] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning,

and Games. Cambridge University Press, 2006.

[4] A. Dvoretzky, J. Kiefer, and J. Wolfowitz. Asymptotic
minimax character of the sample distribution function
and of the classical multinomial estimator. Annals of
Mathematical Statistics, 27(3):642–669, 1956.

[5] N. Littlestone and M. K. Warmuth. The weighted
majority algorithm. Information and Computation,
108(2):212–261, February 1994.

[6] M. Zinkevich. Online convex programming and

generalized inﬁnitesimal gradient ascent. In Proceedings
of the Twentieth International Conference on Machine
Learning, pages 928–936, 2003.

0.00.20.40.60.81.00.00.20.40.60.81.0Target Fraction of Impressions  fAttained Fraction of Impressionslllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllt = 0.059t = 0.353t = 0.647t = 0.941BTTMTBGDPideal0.00.20.40.60.81.00.00.20.40.60.81.0Target Spend Per Impression Won  tAttained Spend Per Impression Wonlllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllf = 0.059f = 0.353f = 0.647f = 0.941BTTMTBGDPidealWWW 2009 MADRID!Track: Internet Monetization / Session: Web Monetization260