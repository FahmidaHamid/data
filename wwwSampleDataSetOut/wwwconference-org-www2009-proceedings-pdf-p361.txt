∗
Lei Wu

MOE-MS KeyLab of MCC
University of Science and

Technology of China
leiwu@live.com

Learning to Tag

Linjun Yang

Microsoft Research Asia
49 Zhichun Road,Beijing
linjuny@microsoft.com

100190, China

Xian-Sheng Hua

Microsoft Research Asia
49 Zhichun Road,Beijing
xshua@microsoft.com

100190, China

Nenghai Yu

MOE-MS KeyLab of MCC
University of Science and

Technology of China
ynh@ustc.edu.cn

ABSTRACT
Social tagging provides valuable and crucial information for
large-scale web image retrieval. It is ontology-free and easy
to obtain; however, irrelevant tags frequently appear, and
users typically will not tag all semantic objects in the im-
age, which is also called semantic loss. To avoid noises and
compensate for the semantic loss, tag recommendation is
proposed in literature. However, current recommendation
simply ranks the related tags based on the single modality of
tag co-occurrence on the whole dataset, which ignores other
modalities, such as visual correlation. This paper proposes
a multi-modality recommendation based on both tag and
visual correlation, and formulates the tag recommendation
as a learning problem. Each modality is used to generate a
ranking feature, and Rankboost algorithm is applied to learn
an optimal combination of these ranking features from dif-
ferent modalities. Experiments on Flickr data demonstrate
the eﬀectiveness of this learning-based multi-modality rec-
ommendation strategy.

Categories and Subject Descriptors
H.3.1 [Information Storage and Retrieval]: Content
Analysis and Indexing-indexing methods; H.2.8 [Database
Applications]: Image databases

General Terms
Algorithms, Theory, Experimentation

Keywords
Tag recommendation; Learning to tag; multi-modality Rank-
boost; social tagging

1.

INTRODUCTION

With the advance of Web2.0 technology, multimedia con-
tent creation and distribution are much easier than ever

∗This work was performed when Lei Wu was visiting Mi-

crosoft Research Asia as a research intern.

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

before [6]. Along with the proliferation of images on the
World-Wide-Web, eﬀective image search approaches to ob-
tain targeted images have gradually become an urgent de-
mand. Currently, the performance of Web image search
mainly depends on the quality of the image annotations
or keywords (tags). Some methods automatically generate
metadata by analyzing the image content, or the surround-
ing text on the webpages; while others generate these textual
metadata by manual tagging. Most recently, social tagging
has become a popular means to annotate Web images.

Although the automatic creation of metadata costs lit-
tle human eﬀort, the result of these statistical model based
automatic methods are generally unsatisfying [14][1]. Espe-
cially on web images, which are quite noisy. To improve the
performance of the automatic annotation, some approaches
combine both image content analysis and the surrounding
text on the image’s webpages, e.g., [11][20][16][19]. These
methods obtain some improvements over the purely content
based methods, but they are still unacceptable for practical
use.

The manual metadata generation is relatively more ac-
curate and practical than the automatic annotation. The
manual metadata generation is mainly based on the idea
of ontology based labeling, which ﬁrstly deﬁnes an ontol-
ogy and then let users label the web resources using the se-
mantic markups in the ontology. There are also some work
to mitigate the manually labeling work by semi-automatic
annotation [5]. Although these ontology based annotation
work is successful in some applications, e.g. bioinformatics
and knowledge management, there are several limitations.
Firstly, to build a semantic ontology that covers suﬃcient
descriptions for multimedia content itself is expensive, time
consuming and often requires domain knowledge [15]. Sec-
ondly, ontology based annotation usually requires users fa-
miliar with the ontology, which is too complicated for anyone
without specialized training and knowledge.

Recently, a promising approach for manual metadata gen-
eration is social tagging, which requires all the users in the
social network label the web resources with their own key-
words and share with others. This labeling operation is
named “tagging”. Diﬀerent from ontology based annotation;
there is no pre-deﬁned ontology or taxonomy in social tag-
ging. Thus this task is more convenient for ordinary users.
Social tagging has currently attracted huge amount of web

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering361of the alternative tags and it can also help clarify the true
semantic of the images. For example, when the user tags an
image with word “sea”, the recommendation system will list
more rich and precise tags based on the input tags, such as
“ocean”, “water”, “wave”, etc. These recommendations will
help users clarify the image content as well as reminding
them of related semantics which may otherwise be ignored.
The quality of tag recommendation is quite important
to social tagging and the consequent performance of im-
age search. Firstly, high quality tag recommendation will
motivate users to contribute more useful tags to an image
[13]. The average number of tags for each image on Flickr
is relatively small [2]. One of the reasons for that the users
did not make large amount of tags is that they generally
cannot think of too many words [17] in a short moment and
few people would like to spend much time thinking about
the alternative tags or more precise tags. With the help of
high quality tag recommendation, users can provide a lot
of useful tags in a short time. Also the spelling errors can
be eﬀectively avoided. Thus the average number of correct
tags for each image is expected to increase. Secondly, tag
recommendation will remind the users of more rich and spe-
ciﬁc tags. The distribution of tags on Flickr follows a power
law distribution (1). Most of the users only use the popular
keywords, which are only 5.82% of the whole tag collection.
These tags are popular because they are common vocabu-
lary and easily come to mind. Another 33.21% of the tags
which appear 50-5,000 times are also informative while gen-
erally ignored by most users, because these words are more
professional terms or only used for speciﬁc object or situa-
tions. The tag recommendation will help remind the user to
use both popular and speciﬁc tags for social tagging. This
reminder also helps create more precise tags. Thirdly, tag
recommendation can depress the noise in social tagging sys-
tem. It shows in the tag distribution that there are around
60% of tags in the tag corpus are misspelling or meaningless
words. With the help of tag recommendation, users can tag
an image by choosing rather than typing, which eﬀectively
avoids these spelling errors.

Existing tag recommendation approaches are performed
by ranking the related tags based on the tag co-occurrence
information. Much information is ignored in these meth-
ods, such as the visual correlation between tags, and the
image content. A better choice is to use correlation from
multi-modalities, such as tag co-occurrence, correlation be-
tween tag related images, the content of the target image,
etc. However, it is not easy to combine these multi-modality
correlations, since these modalities should be weighted dif-
ferently for diﬀerent samples. The basic idea of this paper
is to learn an optimal combination of the multi-modality
correlations to generate a ranking function for tag recom-
mendation. Given the image and one or more initial tags,
the algorithm will rank and sort the rest of the tags based
on the tag correlation from each modality. Each is taken as
a weak ranker. Then Rankboost[7] is adopted to combine
weak rankers and form a better ranking function. Users
can click the tags on the ranking list to annotate the im-
age. After each click, the algorithm will update the ranking
function as well as the tag recommendation function. Since
the recommendation is based on the multi-modality corre-
lations and is dependent on the ever-increasing tags in the
database, it seems the users are using an selected ontology
for tagging. The proposed method actually regularizes the

Figure 1: Tag distribution over a collection of 640
million images from Flickr.com. There are totally
1,300 million tags. Around 1% of the tags appearing
more than 20,000 times, which contain little infor-
mation. Around 5.82% of the tags have appeared
more than 5,000 in the collection, which are consid-
ered as popular tags. 33.21% of the tags appears
more than 50 and less than 5,000 times, which are
deﬁned as speciﬁc tags. 60% of the tags have ap-
peared less than 50 times

users and eﬀectively helps the organization of web resources.
This strategy is adopted by some famous websites (e.g. De-
licious, Flickr). This organic system of organization is also
called “folksonomy”.

Although social tagging is easy to perform, there are also
some drawbacks. Firstly, it suﬀers polysemy and synonyms
problem. As the users can use their own words to tag the
images, diﬀerent users may tag similar images with diﬀerent
words. So when querying “sea”, one may not ﬁnd images
tagged “ocean” which represents the same concept. On the
other hand, it is diﬃcult for the users to input all the tags
of the equivalent meaning. For this reason, lots of images
may not be eﬀectively retrieved. Secondly, ambiguity is also
a problem. Users may use a general tag to represent diﬀer-
ent things. For example, when an image is tagged “apple”,
maybe it refers to the fruit “apple”, or it could refer to the
corporation or the product. In general, it is also quite diﬃ-
cult for the web users to realize the existence of ambiguity
when tagging if they did not think of or even know the other
meanings of the query. With these ambiguous tags, lots of
irrelevant images may be retrieved.

To tackle the above problems, some researchers proposed
the query expansion and suggestion [9][23], which extend
the query to some related words to make the intention more
clear. However, it does not completely eliminate the syn-
onymy and tag ambiguity problems. The information in the
query is limited, and the query expansion frequently can-
not compensate the semantic loss in the tagging process,
when users may ignore some semantic objects in the im-
ages. Recently, Xirong et al.
[10] proposed the neighbor
voting algorithm for image retrieval, which tried to predict
the relevance of the user contributed tags. However the
similarity between individual images is itself an open and
complex problem. In this paper, we propose to tackle the
semantic loss problem during the tagging process by com-
bining both visual correlation in concept level and tag co-
occurrence information. The semantically or visually related
tags are recommended to the users to improve the tagging
quality. The recommendation system will remind the users

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering362likely to tag the images with semantically related words,
like“ipod” together with “apple”. Based on this assumption,
this semantic relationship can be somewhat captured by the
tag co-occurrence in a large online photo sharing website
with great number of independent users. However, it does
not capture all relations between tags, such as the “tyre”
in a photo of car, or the “eye” in a photo of “face”. The
photos containing both “tyre” and “car” may be tagged “car”
only, and it is the same with “eye” and “face”. To tackle
these problems, visual correlation of the tags are applied.
We build a visual language model (VLM) [22] for each tag
and then use the inverse of the distance between these visual
language models to measure the tag visual similarity. These
two kinds of correlations only use the relation between tags,
and the content of the target image is ignored. Further more,
the image conditioned tag correlation is proposed to capture
the tag similarity with respect to the target image.

We also formulate the recommendation as a learning to
rank problem and combine these three kinds of correlation
to generate the ranking. Since diﬀerent types of correlation
are independent measurements, it does not make sense to
linearly combine them. In this paper, we consider these dif-
ferent correlations as diﬀerent ranking features and combine
them in the Rankboost framework, which uses the order of
instances rather than the absolute distance. The ﬂowchart
of the system is shown in Fig. 2.

4. TAG CO-OCCURRENCE (TC)

Concept co-occurrence in daily life contains useful infor-
mation to measure their similarity in the semantic domain.
The semantic about the concepts is related to human cogni-
tion. Since 80% of the human cognition is formed from the
visual information in daily life, the occurrence of concepts
in daily life contributes a lot to their semantics. For exam-
ple, the “monkey” is semantically related to “trees” because
we often see monkeys living on the trees. This visual co-
occurrence information contribute in forming the “monkey -
tree” semantic relationship. It is also the same with lots of
other kinds of semantic relationships, such as “ﬂower - fruit”,
“ﬁsh - sea”, “football - soccer”,“bird - sky” etc.

Tag co-occurrence (TC) on Flickr can partially capture
the conceptual relationship in daily life. We assume that if
two tags are frequently assigned to the same image, the cor-
responding concepts also have a high probability to co-occur
in daily life. This statement makes sense for the following
points. First, the Flickr dataset contains a huge amount of
daily life photos generated by individual users. It seems that
there are hundreds of millions of cameras capturing the ob-
ject co-occurrence in daily life. Secondly, users are supposed
to label the images according to their content with good rea-
sons. There are studies [2], which show that the motivation
of the users to tag the images is for social incentives.
In
other words, the users would like to make themselves known
by contributing to the tagging task. Based on this conclu-
sion, the users would more likely to tag the images truly
according to the content rather than making noises.

The calculation of the tag co-occurrence on Flickr has al-
ready been investigated by the recent work [18]. Here we
adopt the similar method to calculate the tag co-occurrence
over a large dataset of 6 million images from Flickr. This
dataset is suﬃciently large for generating the statistics about
the tag co-occurrence. Generally, according to diﬀerent ap-
plications, the tag relevance is normalized into asymmetric

Figure 2: The ﬂowchart of the social tagging recom-
mendation system.

folksonomy with this dynamic ontology and makes the tag-
ging converge to the underlying taxonomy.

The rest of the paper is organized as follows. Section 2
brieﬂy introduces the related work on tag recommendation.
Section 3 gives an overview of the annotation recommenda-
tion framework. Section 4 discusses the tag co-occurrence
measurement. Section 5 discusses the tag content correla-
tion measurement. 6 elaborates on the image content condi-
tioned tag correlation. The hybrid information based Rank-
Boost algorithm is discussed in Section 7. The experimental
results and discussion are given in Section 8. Section 9 con-
cludes this paper.

2. RELATED WORK

Recently, the tag recommendation based on the collective
knowledge [18] is proposed. The authors measured the simi-
larity between tags by their co-occurrence information in the
data collection, and used the top similar tags as recommen-
dations. This work has achieved some exciting results on the
Flickr data, however, this kind of similarity measurement
is greatly inﬂuenced by the synonyms and polysemy tags.
For example, the similarity between “player” and “football”
may be underestimated, since the co-occurrence of “player”
and “soccer” should also have been taken into account to
calculate the similarity between “player” and “football”. In
the other case, the similarity between “apple” and “ipod” is
overestimated, since the “apple” here only indicates the cor-
poration, and the cases where it represents the fruit should
not be taken into account. While these problems can be bet-
ter handled if the multi-modality visual similarity between
the tags is used.

3. OVERVIEW OF THE TAG RECOMMEN-

DATION FRAMEWORK

Given an image and one or several initial tags, we would
like to recommend more tags which may have a semantical or
visual correlation to the image. We rank these tags by their
correlation to the target image, and list the top N keywords
as the recommendation for further tagging.

We use a combination of three kinds of correlations to
rank the tags: tag co-occurrence, tag visual correlation, and
image conditioned tag correlation. The web users are very

 Tag SelectionTag Invert TableVisual Language Model Visual CorrelationTag + contentRankBoost recommen-dationTagImageSocialTaggingTagCo-occurrenceWWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering363and symmetric forms, which are brieﬂy represented as fol-
lows.

Asymmetric relevance measure. The relevance measure-

ment between two tags is deﬁned as follows.

Ra

tag(ti, tj) =

(1)
|ti| rep-
where ti and tj are any two tags in the database.
resents the number of times of the tag ti that appears in
the database.This relevance measure is asymmetric, which
makes sense. Given tag ti the probability of tag tj may not
be the same from that given tag tj the probability of tag ti.
Symmetric relevance measure. Although the Asymmetric
relevance measure makes sense for tag recommendation, in
some cases, the symmetric relevance measurement is more
convenient to use.

(cid:84) tj|

|ti|

|ti

(cid:84) tj|
(cid:83) tj|

|ti
|ti

Rs

tag(ti, tj) =

(2)

5. TAG CONTENT CORRELATION (TCC)
Tag co-occurrence ignores some kinds of correlation. For
if a user has tagged the image with “football”,
example,
he/she may not tag it with “soccer”.
In other words, the
correlation between synonym tags is not well estimated by
tag co-occurrence. For another case, like the previously men-
tioned “tyre - car” and “eye - face” cases, users usually ignore
some appearing concepts unconsciously. This drawback can
be compensated by calculating the tag content correlation
(TCC).

To represent the content correlation of the tags, visual
language model is adopted to model each tag. For the ith
tag ti, we collected a set of images marked with the tag.
Then we build VLM based on these images to represent the
content of the tag, and the diﬀerences of these quantiﬁed
models are used to measure the tag visual correlation.
5.1 Data Source

In multimedia domain, the content of the images gener-
ally contain the semantic information of the tag. We intend
to use the images as the tag content. Since a single im-
age contains insuﬃcient information to describe the tag, we
collected a set of images to represent a tag. We aim to gener-
ate a semantic representation for the tags using these sets of
images. In order to sample suﬃcient images to describe the
tag, we generated a large image pool consisting of 1,000,000
images related to more than 50,000 popular tags by random
walk sampling [4] from the popular photo sharing website
Flickr.
5.2 Visual Representation

Visual language model (VLM) [22] is adopted to model
the content of the tags in visual domain. This type of model
can be generated very fast, which is appropriate for large
scale datasets. It captures both the frequency of the visual
features related to the tag, but also considers the spatial
relationship between the neighboring features. This addi-
tional spatial information used in this model makes it more
discriminative to characterize diﬀerent tags.

The generation of the VLM is brieﬂy described as fol-
lows. Each image is ﬁrstly divided into uniformly distributed
equal-sized patches. Then some type of local appearance
features, such as the texture histogram, color moment, etc,

are generated for each patch. To depress the noise as well
as the consequent training process, these local appearance
features are sometimes coded into a visual word by k-means
clustering or hash coding method. Afterwards, the VLM
assumes that there are some visual grammar constraints on
the arrangement of these visual words. According to diﬀer-
ent constraints, the VLM can be divided into unigram, bi-
gram and trigram models. The unigram model assumes that
the visual words are independent to each other, the output
of the unigram model is the conditional distribution of the
visual words given the tag. The bigram model assumes that
the visual words are related to one of its neighboring words
(usually left neighbor), and the output of the bigram model
is the conditional distribution of the visual words given both
the tag and one of their neighboring words. Accordingly, the
trigram model assumes that the visual words are correlated
to two of its neighboring words. So the output of the trigram
model is the conditional distribution given the tag and two
of the neighboring words. The dependency assumption can
be described in the following equations.

P (x) = Πn−1
P (x) =P (w00)Πn−1

P (x) = ΠijP (wij)
i=1 P (wi0)Πn−1
j=1 P (w0j|w0,j−1)Πn−1

j=1 P (wij|wi,j−1)

i=1 P (wi0|wi−1,0)

i,j=1P (wij|wi−1,jwi,j−1)
Πn−1

(3)

(4)

(5)

where x is an image, and wi,j is the visual word of the i, jth
patch in the image.

The commonly used back-oﬀ and smoothing methods in
the statistical language model are also adopted to estimate
the conditional distribution of P (wij), P (wij|wi,j−1), and
P (wi0|wi−1,0). More details about this modeling method
are discussed in previous work [22].
For the unigram model, the VLM is the visual word distri-
bution over each tag. P (wi), wi ∈ V, i = 1,··· ,|V | where V
is the vocabulary of size |V |. For bigram and trigram mod-
els, the VLM are the conditional distribution of visual words,
P (wi|wj),wi, wj ∈ V, i, j = 1,··· ,|V | and P (wi|wj, wk),
wi, wj, wk ∈ V, i, j, k = 1,··· ,|V |. In summary, in all types
of VLM, the content representation of a tag is a conditional
distribution.
5.3 Similarity Measurement

Similarity measurement is critical in many applications
[24]. It is also true in the tag recommendation system, where
the core is the measurement of the visual relationship be-
tween tags. This similarity measurement directly inﬂuences
the recommendation results. The direct measurement of the
tag relationship is hard to achieve. As a result, we intend
to represent the tags with the related images by context
modeling and dictionary learning, which are successful in
object category recognition [3][25][12]. The tag similarity is
measured by the diﬀerences between the VLM of these tags,
which is easily calculated using a generalized Flickr Distance
[21].
If two tags are semantically correlated, their images
are more probably to share some objects or scenes. Since
the VLM captures the visual statistics of the tags and each
VLM is a type of conditional distribution, we can calculate
the square root of JS divergence between these distributions
to measure the visual distance among the tags. Although
there are some other kinds of distance measurements [8],
the measurement is simple and eﬀective.

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering364The content correlation is divided into symmetric and
asymmetric measurements. The symmetric measurement
considers the two tags are equally important in the mea-
surement. However, sometimes the two tags are not equally
considered, i.e. given the tag “apple tree” the concept “ap-
ple” is more probably to appear than given the tag “apple”
there exists an “apple tree”, since “apple” have many other
meanings and may exist in many occasions. Thus the asym-
metric relevance measurement makes sense. Generally, these
two kinds of measurements makes tiny diﬀerent. Since the
symmetric relevance can reduce half of the computational
burden, it is widely used in common cases.

Asymmetric relevance measure.

T CC (ti, tj) = KL(L(ti)||L(tj))
Da

(6)

1

Ra

T CC (ti, tj) =

(7)
where L(ti) represents the VLM for tag ti and KL(·) is the
KL distance between two visual language models. Da
T CC is
deﬁned as the asymmetric tag correlation measurement.

T CC (ti, tj)

Da

Symmetric relevance measure.

Ds

T CC (ti, tj) =

1
2

[KL(L(ti)||M ) + KL(L(tj)||M )]

M =

1
2

[L(ti) + L(tj)]

Rs

T CC (ti, tj) =

1

Ds

T CC (ti, tj)

(8)

(9)

(10)

where M is the average language model between the two
tags. Ds
T CC is the symmetric content distance between the
two tags.
In fact considering the VLM as a probabilistic
distribution, this distance equals to the well-known Jensen-
Shannon divergence, the square of which is demonstrated
to be a strict metric. The symmetric relevance measure
between the content of the tags Ra
T CC (ti, tj) is deﬁned as
the reciprocal of their symmetric visual distance.

6.

IMAGE CONDITIONED TAG CORRELA-
TION MEASUREMENT (ITC)

Although the tag visual similarity adopted the visual in-
formation of the images related to the respective tag to cal-
culate the relevance, it does not use the information about
the test image. We believe that for diﬀerent test images,
the similarity measurement should be diﬀerent. For exam-
ple, the tag “apple” and “pear” is of high relevance, however,
given the test image of an ipod, the “pear” should not be
a proper recommendation. In order to explore this kind of
conditional correlation, the image conditioned tag correla-
tion (ITC) measurement is proposed.

We assume that if the two tags are similar to each other,
the likelihood of generating the target image should be simi-
lar. We represent the tag by the likelihood of generating the
target image given unigram, bigram and trigram models re-
spectively. These three likelihoods can be taken as location
of the tag in the likelihood space.
Let x be a novel test image (for user to tag), and xk, k =
1,··· , L be L related images to a tag t ∈ T , where T is
the tag corpus. First, we measure the similarity between
the target image x and all the tag associated images. To
achieve this task, the target image x is also represented in

Figure 3: The target image conditioned tag distance
measurement. Given diﬀerent target image x1,x2,
the distance between tags ti,tj is diﬀerent.

Figure 4: The geometric interpretation of the asym-
metric relevance measurement.

the matrix of visual words x = [wij]i,j=1,··· ,n representation
as discussed in Section 5. Then the similarity is deﬁned by
the likelihood L.

Lm
t (x) ∝ P (x|V LM m
t )

(11)

Also we apply the visual context constraints, the similar-
ity measurement can be further represented in the unigram,
bigram and trigram forms.

Lm
t (x) ∝ ΠijP (wij|V LM m
t )

Lm
t (x)
∝ Πn−1

i=1 P (wi0|V LM m

t )Πn−1

j=1 P (wij|wi,j−1, V LM m
t )

(12)

(13)

Lm
t (x)
∝ P (w00|V LM m
i=1 P (wi0|wi−1,0, V LM m
Πn−1

t )Πn−1

j=1 P (w0j|w0,j−1, V LM m
t )

t )Πn−1

i,j=1P (wij|wi−1,jwi,j−1, V LM m
t )
(14)

where V LM m
t

is the m-gram visual language model for the
tth tag. It is worth noting that the m-gram used here could
be the unigram model, the bigram model, or the trigram
model. For simplicity, we denote these three kinds of likeli-
hood functions with the brief index m = 1, 2, 3 respectively,
where m = 1 corresponds to the unigram model; m = 2 is
the bigram model; m = 3 denotes the trigram model.

Given the image x, each tag t is represented by three
likelihood values corresponding to the unigram, bigram and
trigram models respectively, as shown in Fig. 3. Thus the
distance between the two tags ti and tj can be deﬁned in this
likelihood space as the inter product of the two likelihood
vectors. This kind of distance also consists of symmetric
and asymmetric forms, which are formulated in Eq.
(15)

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering365and (16) respectively.

Ds

IT C (ti, tj, x) =

Lti (x) · Ltj (x)
(cid:107)Lti (x)(cid:107)(cid:107)Ltj (x)(cid:107)
ti ,L2

ti ,L3
ti ]
and the asymmetric distance is deﬁned as

Lti (x) = [L1

IT C (ti, tj, x) = (cid:107) Lti (x) · Ltj (x)
(cid:107)Lti (x)(cid:107)

Da

− Lti (x)(cid:107)

(15)

(16)

(17)

where ti is usually the initial tag related to the target image
and tj is the novel tag.

Correspondingly, the similarity measurement between tags
given the target image is the inverse of the distance metric.

Rs

IT C (ti, tj, x) =

1

Ds

IT C (ti, tj, x)

Ra

IT C (ti, tj) =

1

Ds

IT C (ti, tj, x)

(18)

(19)

This asymmetric distance measurement (Eq. (17)) is revis-
ited here.
In another aspect, this relevance measurement
can also be interpreted from the relevance decomposition
view, which is illustrated as Fig.4. In the likelihood space,
the novel tag tj is represented as a 3-dimensional vector,
which is further decomposed into two components, the rel-
evant component tjh that is parallel to the initial tag ti,
and irrelevant component tjv which is vertical to the initial
tag ti. The correlation is inverse to the distance between
relevant component tjh and the initial tag ti.

In the target image conditioned tag similarity measure-
ment, the relevance between both the initial tag and the
target image is considered, which makes sense for image tag-
ging recommendation.

7. MULTI-DOMAIN RELEVANCE FOR TAG

RECOMMENDATION

In this section, we discuss to combine multi-domain rel-
evance for tag recommendation (MRR). Here the multi-
domain relevance refers to the tag co-occurrence, tag con-
tent correlation, and image conditioned tag correlation. The
basic idea is to produce an accurate ranking function by
combining many “weak” learners. Diﬀerent from traditional
training procedure, these “weak” learners are trained based
on cross domain relevance of the semantic targets.
7.1 Recommendation framework

Given an image and one or more tags, the task is to rec-
ommend more related tags to label the image. This recom-
mendation is performed by ranking based on the three types
of similarity, tag co-occurrence, tag to tag similarity, and im-
age conditioned tag similarity. The tag co-occurrence (TC)
measures how likely two diﬀerent tags are labeled together.
The tags are generated by web users, and their co-occurrence
can reﬂect the tag relationship in human cognition. The tag
to tag similarity (TTS) measures the correlation of the vi-
sual content of the tags. In this sense, we can also measure
the similarity of the tags by their VLMs. The image based
tag similarity (ITS) measures the similarity between the tags
conditioned on the target image.

These diﬀerent types of correlation can be combined to-
gether to generate a more robust recommender. However,

as these similarity metrics are generated from diﬀerent do-
mains, the linear combination of these similarity measure-
ments does not make sense. To tackle the multi-domain
measurement problem, we propose to combine these multi-
domain metrics into the Rankboost framework to generate a
reasonable combined recommender. Since the Rankboost al-
gorithm only considers the relative order of the samples and
it does not actually use the distance metric, it can generate
a fair ranking based on the multi-domain information.
7.2 Rankboost

In this framework, each sample tag is considered as an
instance. All the tags in the dataset form the instance space
X . For each weak ranker, we aim to generate a function fi,
which maps an instance xi from the instance space X to the
preference space or ranking space R. These given rankings
of the instances are called ranking feature, which is taken
as a kind of feature to train the weak rankers. In fact, the
ranking feature is any kinds of measurement indicating the
relative order between two instances. This measure does
not have to be metric, since only the relative order is useful
and the distance is not used. For example, the fi(x1) >
fi(x2) means the ranking feature of x1 is superior to that
of x2. The distance fi(x1) − fi(x2) > fi(x2) − fi(x3) is
meaningless. Based on this property, the ranking features
can be generated using diﬀerent kinds of information or from
diﬀerent domains. The requirement is that they can be used
to measure the relative order between any two instances. In
this paper, these ranking features are generated from both
the textual domain and visual domain. So the weak rankers
are also called multi-domain weak rankers.

In order to learn the ranking, we deﬁne the ranking loss

as follows.

rlossD(H) =

(cid:88)

D(x0, x1)δ(H(x1) ≤ H(x0))

x0,x1

D(x0, x1) = c · max(0, Φ(x0, x1))

(20)

(21)

where Hi is the sum combination of all weak rankers, and
δ(π) is 1 if π holds and 0 otherwise. Φ(·) is the feedback
function, Φ : X × X → R.
If x1 is more relevant to the
tag than x0, then Φ(x0, x1) > 0. This feedback function is
usually generated by user interaction.

As is demonstrated in [7], the upper-bound for this rank-

ing loss is Zt

(cid:88)

Zt =

Dt(x0, x1)exp(αt(ht(x0) − ht(x1)))

(22)

x0,x1

where ht is the output of the tth weak ranker. The weak
learner is only needed to minimize this upper-bound.
7.3 Learning to tag

Given the image and some of its initial user created tags,
we would like to recommend a list of related tags which may
be also applicable to the image. We denote the set of ini-
tial tags as OT , and the set of remaining tags as UT . The
relevance of the tags is represented in two domains. The
average tag co-occurrence on other Flickr images is deemed
as one domain, and their content correlation as another do-
main. Then for these domains, we generate several ranking
features {fl}3n
l=1 (n is the number of initial tags). The ﬁrst n
ranking features are generated based on tag co-occurrence;

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering366Algorithm 1 Cross domain Rankboost training process

Input: Given tags t1,··· , tn ∈ OT , and t1,··· , tm ∈ UT ,
and distribution D over UT × UT .
whereOT is the set of the initial tags.
UT is the set of the remaining tags in the database.
l=1; ∀ti ∈ UT , tl ∈ OT

Initialize D1 = D.
Generate ranking features {fl}3n

T C (ti, tl), l = 1,··· , n

for k = 1,··· , K. do

T CC (ti, t), l = 1,··· , n
IT C (ti, t), l = 1,··· , n

fl(ti, tl) = Rs
fn+l(ti, tl) = Rs
fn+l(ti, tl) = Rs
where ti ∈ UT , tl ∈ OT
• Select pair (ti, tj) ∈ UT × UT with distribution D.
• Get weak ranking hk from ranking features of selected
pairs
• Update: αk = 1

2 ln( 1+r
ti,tj

1−r ),
Dk(hk(ti) − hk(tj))

• Update: Dk+1(ti, tj) = Dk(ti,tj ) exp(αk(hk(ti)−hk(tj )))
Dk(ti, tj) exp(αk(hk(ti) − hk(tj)))

where Zk is a normalization factor.

Output the ﬁnal ranking: H(t) =(cid:80)K

end for

ti,tj

Zk

k=1 αkhk(t).

.

where r =(cid:80)
Zk =(cid:80)

the next n ranking features are generated by TTS; and the
last n are generated by ITS.

fl(ti, tl) = Rs

T C (ti, tl), tl ∈ OT , ti ∈ UT , l = 1,··· , n

fn+l(ti, tl) = Rs

f2n+l(ti, tl) = Rs

(23)
T CC (ti, tl), tl ∈ OT , ti ∈ UT , l = 1,··· , n
(24)
IT C (ti, tl), tl ∈ OT , ti ∈ UT , l = 1,··· , n
(25)
These ranking features of the two domains are combined
in the Rankboost framework. Eq. 22 shows that the weak
ranker depends only on the relative ordering information
of the samples rather than the speciﬁc scoring information.
Since here we adopted similarity measurements from multi-
ple domains, and the score may represent diﬀerent seman-
tics, it does not make sense to use the scoring information
directly. For these reasons, it is reasonable to adopt the
Rankboost framework as described in [7] in this paper.
In the training process, the algorithm generates some ran-
dom pairs over UT × UT with the distribution D. Then
based on these random pairs, some weak learners are trained
using both the tag co-occurrence relevance and the content
correlation between the tags in each pair. The distribution
D is also updated to minimize the ranking loss. A high
weight α is assigned to the pairs indicating importance of
making that pair correct.

We adopt the same type of weak ranker as [7]. In the rec-
ommendation process, the top N relevant tags, according to
the ranking result, are recommended to the user for further
tagging.

8. EXPERIMENT

In this section, we compare the proposed approach with
the commonly used tag co-occurrence based recommenda-
tion approach in the real world image tagging task.

8.1 Setting

We have collected 1,000,000 images and associated 200,000
tags from Flickr as the database. Since these photos are
uploaded by large amount of independent users, there are
diverse categories of topics and can reﬂect the real situation
of web images. We randomly select 500 images to perform
the manually tagging task. The rest of the images with tags
are used to train the tag co-occurrence measurement as well
as the content correlation measurement.

Some frequency ﬁltering methods are adopted to remove
the noise in tag co-occurrence. In the real world, the web
users may make mistakes during the tagging process. Some
of the tags may be misspelled. They will be low frequent
tags. To depress this kind of noise, we adopt a simple and
eﬀective method by removing the tags that appear less than
50 times in the dataset. There are also some high frequency
stop words, such as “bravo”, “image”, “photo”, etc. These
tags contain little information. We also consider them as
irrelevant tags, which can be suppressed by removing the
tags that appear more than 10,000 times in the dataset.

To initialize the feedback function D for the Rankboost al-
gorithm, we adopt the pseudo feedback function generated
from WordNet, which contains the human created knowl-
edge about word correlations. Using WordNet for initializa-
tion is less expensive than the human labeling. However,
since there are lots of tags out of the scope of WordNet,
we can just generate the feedback function among the tags
within the WordNet corpus. To extend the coverage of the
feedback function, human interaction is unavoidable. Given
some initial tags, if tag x1 gets a higher similarity score to
the initial tags than tag x0 in the WordNet, the feedback
function Φ(x0, x1) > 0; otherwise Φ(x0, x1) < 0.

For each test image, we give 5 initial tags generated by
users on Flickr. For the baseline method, we adopt the com-
monly used recommendation by tag co-occurrence. For the
second method, we use only tag co-occurrence as the rank-
ing feature for the Rankboost recommendation. For the
third method, we use both tag co-occurrence and content
correlation in the Rankboost recommendation. To provide
real-time recommendation, we calculate the co-occurrence
similarity and content similarity of all tags in the database
oﬄine, and the Rankboost algorithm is only performed on
the top 100 relevant tags for each image.

8.2 Evaluation

Each recommendation approach will generate an ordered
list of relevant tags for each image. Then a volunteer is
required to evaluate these recommended tags.
If a tag is
it will be marked true; otherwise
relevant to the image,
false. The average precision of the topN (N=5) recommen-
dations and the coverage over all correct recommendations
are adopted to qualitatively measure the performance of
each recommendation method. The coverage is deﬁned as
the proportion of correct tags (including all correct tags by
both methods and initial tags) that are recommended by
the speciﬁc method. We adopt the coverage rather than the
recall, because the recall is unapplicable for the recommen-
dation task.

(cid:80)
(cid:80)
(cid:80)
x∈T opN δ(x|mi)
x∈T opN δ(x|mi)

i

Coverage(mi) =

(26)

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering367(cid:26) 1, given method i, x is related tag;

0, otherwise.

(27)

δ(x|mi) =

8.3 Experiment A: Multi-domain relevance V.S.

tag cooccurrence

In this experiment, we aim to compare the Multi-domain
Relevance based Rankboost recommendation (MRR) with
the Tag Co-occurrence based tag recommendation (TC). For
the MRR method, one weak ranker is trained based on the
tag co-occurrence information; another one is trained by the
tag content correlation; and a third one is trained by the im-
age conditioned tag correlaion. These weak rankers are com-
bined together into the Rankboost framework. The compar-
ison between MRR and TC shows how much of the improve-
ment is gained by incorporating the tag content correlation
and image conditioned tag correlation. To reveal how much
is gained by the multi-domain features, we further compared
the MRR method with the Tag Co-occurrence based Rank-
boost (TCR).

We randomly choose 20% of sample images as test data,
and the rest images and associated tags are used as the
training data. To train the TCR model, we count the co-
occurrence frequency between every pair of tags from the
collection, and then normalize them into range 0 to 1. For
the MRR method, we train the tag based weak ranker the
same way as the purely tag co-occurrence based method. In
the visual domain, we generate the ranking features based
on the visual similarity of these tags, which are discussed in
the previous sections. Then we combine these weak rankers
with the Rankboost algorithm.

Figure 5 and Figure 6 compare the performance of the
two methods under 5 initial tags. In Figure 5, the left ﬁg-
ure shows average precision at top 10 tags. “M1” represents
the TC method [18]. “M2” denotes the TCR. “M3” denotes
the MRR method. Comparing M2 and M1, we ﬁnd the
supervised recommendation outperforms the unsupervised
method by 3.3% in precision and 8.8% in coverage. Com-
parison of M3 with M2 shows that after the combination
of content correlation, the precision and coverage gain 5.5%
and 10.5% separately. In total, the proposed hybrid infor-
mation based Rankboost has gained 9.0% in precision and
20.3% in coverage over the commonly used tag co-occurrence
approach. These results demonstrate the eﬀectiveness of the
supervised recommendation as well as the usefulness of the
correlation of the image content.

(a) Precision@5

(b) Coverage@5

Figure 5: Performance of diﬀerent methods.

Figure 6: Tag recommendation examples.

Figure 6 gives an illustration of the tag recommendation
results. The texts below each image are its tags. The ﬁrst
row is the initial tags assigned by the Flickr users. The
second row is the results of the simple tag co-occurrence
method [18]. The third row is the result for tag domain
Rankboost method, and the last row is multi-domain Rank-
boost method. The proposed method provides more relevant
tags.
8.4 Experiment B: Rankboost V.S. linear com-

bination

To combine the visual correlation with the tag cooccur-
rence, we can also use the linear combination rather than the
Rankboost algorithm. For the multi-domain relevance linear
combination method (MRL), we generate a new similarity
score in the following form.

Rs

linear = Rs

T C + η1Rs

T CC + η2Rs

IT C

Ra

linear = Ra

T C + ζ1Ra

T CC + ζ2Ra

IT C

(28)

(29)

where Rs
linear is the combination of the symmetric similarity
measurement, and Ra
linear is the combination for asymmet-
ric similarity. η1, η2, ζ1, ζ2 are the combination coeﬃcients,
which are determined by experiments.

This kind of linear combination also takes multi-domain
correlation information, but there are two disadvantages for
this simple method. Firstly, the combinational coeﬃcients
is diﬃcult to determine automatically. Secondly, the linear
combination method combines the similarity score in diﬀer-
ent domains, which is not reasonable.
In the Rankboost
method, we combine the results of the weak rankers rather
than the similarity scores.

In this experiment, we intend to demonstrate the ad-
vantage of Rankboost based multi-domain recommendation
over the linear combination. For each test data, we give K
(K=1,3,5,8) initial tags, and a ranking of the rest tags are
generated by both Rankboost and the linear combination
method. For the linear combination method, the set both
η1, η2 and ζ1, ζ2 to 1. Then the precision at top 10 tags are
evaluated manually. The results are shown in Fig. 7.

From these comparisons, we ﬁnd that both precision@10
and coverage@10 rise with increasing the number of initial
tags. The Rankboost algorithm outperforms the simple lin-

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering368(a)

(b)

Figure 7: Comparison with linear combinations

Figure 9: precision@N with KN irrelevant tags

8.6 Experiment D: Noise resistance

Noise exists in the real world data. We can not assume
that the tags on the web are all correct. For the real applica-
tion, noise resistance is a critical feature. In this experiment,
we would like to show this property of the proposed recom-
mendation approach. 5 initial correct tags are given for each
test image. In this experiment, we also generate some noise
(irrelevant tags), which are combined with the correct tags.
For a detailed analysis of the inﬂuence of noise on the rec-
ommendation results, we gradually increase the number of
irrelevant tags KN from 1 up to 5. The ﬁnal precisions at
topN (N=1,5,10) under each irrelevant rate are shown in
Figure 9.

From the ﬁgure, we ﬁnd the precision of the recommenda-
tion drops when the number of irrelevant tags increase. The
reason is that the irrelevant tags have mislead the rank-
ing function. The irrelevant tags may not relate to each
other, while the correct tags of the same image are seman-
tically related to each other. Thus the ranking algorithm
will still take more consideration on tags related to the cor-
rect ones. This is also reﬂected in the result. Even with
5 irrelevant tags, that is 50% of the number of tags, the
precision@1,5,10 still remain above 75%,73% and 53% re-
spectively. This means the algorithm is applicable with 50%
of irrelevant tags, which is actually worse than the real world
situation. By sampling 10,000 images from Flickr, the statis-
tic shows that on average, there are about 24% of tags for
each image are irrelevant.
8.7 Experiment E: Computational cost

Computational cost is also one of the main considerations
for the web scenarios. The main computational time for the
proposed methods lies on the visual similarity measurement
between tags. Fortunately, this process can be generated of-
ﬂine. We ﬁrst generate a dictionary of tags, and then gener-
ate both co-occurrence based similarity measurement as well
as the content based tag similarity measurement oﬄine. For
the online recommendation, we only need to rank the tags
according to the initially labeled tags. This process is very
fast. The details of the computational time for each sam-
ple under diﬀerent number of initial tags are shown in the
following table. This experiment is performed by Intel(R)
Core(TM)2 Duo CPU@2.00GHz, 1G memory. For each im-
age, the multi-domain Rankboost method takes only 0.02
second.

Figure 8: precision@N with KI initial tags.

ear combination of the ranking features. This advantage is
more obvious when the number of initial tags is larger. This
is because given more initial tags, the Rankboost algorithm
will have more information for ranking as well as more in-
formation to determine how to more eﬀectively combine the
two kinds of ranking features. While for the linear combina-
tion algorithm, since the combination coeﬃcients are ﬁxed,
it is not likely for this method to optimize the combination.
The increase of performance in the linear algorithm is purely
based on more information for ranking.
8.5 Experiment C: Parameter inﬂuence

In this experiment, we would like to study the inﬂuence of
the number of initial tags KI . In the real world, there may
not be large amount of tags for each image. The number of
initial tags may greatly limit the application of the method.
In this study, we selected a collection of images which have
more than 10 initial tags. Then we set KI from 1 to 8, and
calculate the precision@1,5,10 under respective initial tag
setting. The results are shown in the following ﬁgure.

From this results, we ﬁnd the precision of the recommen-
dation is improved with the increasing of KI . This is because
with more initial tags, the algorithm can use more informa-
tion to predict the content of the image. It is also found that
the precision with 5 initial tags is already acceptable for a
common recommendation system. Fortunately, with respect
to the statistic generated from the 10,000 random sampling
from Flickr, the average number of correct tags for an image
is above 5. This means that in general cases the users can
label more than 5 correct tags, and then it is possible to
apply this recommendation scheme on Flickr to help users
tagging more.

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering369Table 1: Computational cost between diﬀerent
methods.

Training

Test

TC
0.178
0.001

TCR MRL MRR
2.195
0.183
0.002
0.002

2.190
0.001

In Table 8.7, the training time shows the cost for calcu-
lating the similarity between each concept pair. For recom-
mendation, the time shows the cost for generating a recom-
mendation list for each target image. From this comparison,
we ﬁnd the computational cost for the proposed method lies
mainly on the computation of the visual information. How-
ever, the building of VLM can be performed oﬄine in the
training process. So the computational time for the online
recommendation process is almost the same for all the meth-
ods.

9. CONCLUSIONS

In this paper, we have introduced the learning based tag
recommendation approach.
It generates ranking features
from multi-modality correlations, and learns an optimal com-
bination of these ranking features by the Rankboost algo-
rithm. This recommendation will update each time when a
new tag is added, the eﬃciency makes this recommendation
method suitable for real time applications. With this learn-
ing based recommendation, better quality of recommenda-
tions is achieved, and the users are reminded of more diverse
and correlated tags. Experiments also demonstrate that this
learning to tag framework is more eﬀective than current ap-
proaches and the combination of multi-modality relevance is
helpful to tag recommendation.

10. ACKNOWLEDGMENTS

The research is supported in part by the National Nat-
ural Science Foundation of China (60672056), the 863 Pro-
gram (2008AA01Z117), and USTC Postgraduate Innovation
Foundation (KD2007049).

11. REFERENCES
[1] E. Akbas and F. Yarman Vural. Automatic image

annotation by ensemble of visual descriptors. CVPR
’07., June 2007.

[2] M. Ames and M. Naaman. Why we tag: motivations

for annotation in mobile and online media. In CHI
’07, 2007.

[3] J. Amores, N. Sebe, and P. Radeva. Context-based
object-class recognition and retrieval by generalized
correlograms. IEEE Trans. Pattern Anal. Mach.
Intell., 29(10):1818–1833, 2007.

[4] Z. Bar-Yossef and M. Gurevich. Random sampling

from a search engine’s index. In WWW ’06
Proceedings, 2006.

[5] J. Blythe and Y. Gil. Incremental formalization of

document annotations through ontology-based
paraphrasing. In WWW ’04, 2004.

[6] S. Boll, P. Sandhaus, A. Scherp, and U. Westermann.

Semantics, content, and structure of many for the
creation of personal photo albums. In Proceedings of
ACM Multimedia ’07, 2007.

[7] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An
eﬃcient boosting algorithm for combining preferences.
In Proceedings of ICML’98,, 1998.

[8] G. Koloniari, Y. Petrakis, E. Pitoura, and T. Tsotsos.

Query workload-aware overlay construction using
histograms. In Proceedings of CIKM ’05, 2005.

[9] H. Li, Y. Wang, D. Zhang, M. Zhang, and E. Y.

Chang. Pfp: Parallel fp-growth for query
recommendation. In ACM Recommendation Systems,
Lausanne,, 2008.

[10] X. Li, C. G. Snoek, and M. Worring. Learning tag

relevance by neighbor voting for social image retrieval.
In Proceedings of MIR ’08, 2008.

[11] J. Liu, B. Wang, M. Li, Z. Li, W. Ma, H. Lu, and

S. Ma. Dual cross-media relevance model for image
annotation. In Multimedia’07, 2007.

[12] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and

A. Zisserman. Supervised dictionary learning, 2008.

[13] M. Naaman and R. Nair. Zonetag’s collaborative tag
suggestions: What is this person doing in my phone?
In IEEE Multimedia,, 2008.

[14] G.-J. Qi, X.-S. Hua, Y. Rui, J. Tang, T. Mei, and

H.-J. Zhang. Correlative multi-label video annotation.
In Proceedings of ACM Multimedia’07, 2007.

[15] Y. Qi, K. S. Candan, J. Tatemura, S. Chen, and

F. Liao. Supporting olap operations over imperfectly
integrated taxonomies. In SIGMOD’08 Conference,
2008.

[16] X. Rui, M. Li, Z. Li, W.-Y. Ma, and N. Yu. Bipartite
graph reinforcement model for web image annotation.
In Multimedia’07, 2007.

[17] S. Sen, S. K. Lam, A. M. Rashid, D. Cosley,

D. Frankowski, J. Osterhouse, F. M. Harper, and
J. Riedl. tagging, communities, vocabulary, evolution.
In CSCW ’06, 2006.

[18] B. Sigurbj¨ornsson and R. van Zwol. Flickr tag

recommendation based on collective knowledge. In
WWW ’08, 2008.

[19] C. G. M. Snoek, B. Huurnink, L. Hollink, M. D. Rijke,

G. Schreiber, and M. Worring. Adding semantics to
detectors for video retrieval. IEEE Transactions on
Multimedia, 9, 2007.

[20] C. Wang, F. Jing, L. Zhang, and H.-J. Zhang.

Content-based image annotation reﬁnement.
Proceedings of CVPR ’07, 2007.

[21] L. Wu, X.-S. Hua, N. Yu, W.-Y. Ma, and S. Li. Flickr

distance. Proceedings of ACM Multimedia’08, 2008.
[22] L. Wu, M. Li, Z. Li, W.-Y. Ma, and N. Yu. Visual

language modeling for image classiﬁcation. Proceedings
of MIR’07, 2007.

[23] R. Yan and A. Hauprmann. Query expansion using

probabilistic local feedback with application to
multimedia retrieval. In Proceedings of CIKM ’07,
2007.

[24] J. Yu, J. Amores, N. Sebe, P. Radeva, and Q. Tian.

Distance learning for similarity estimation. IEEE
Trans. Pattern Anal. Mach. Intell., 30(3):451–462,
2008.

[25] Y.-T. Zheng, S.-Y. Neo, T.-S. Chua, and Q. Tian.

Visual synset: towards a higher-level visual
representation. In Proceedings of CVPR’08, 2008.

WWW 2009 MADRID!Track: Rich Media / Session: Tagging and Clustering370