Efﬁcient Interactive Fuzzy Keyword Search

Shengyue Ji

University of California, Irvine
Irvine, California 92697, USA
shengyuj@ics.uci.edu

Guoliang Li

Tsinghua University
Beijing 100084, China

liguoliang@tsinghua.edu.cn

Chen Li

University of California, Irvine
Irvine, California 92697, USA

chenli@ics.uci.edu

Jianhua Feng

Tsinghua University
Beijing 100084, China

fengjh@tsinghua.edu.cn

ABSTRACT
Traditional information systems return answers after a user
submits a complete query. Users often feel “left in the dark”
when they have limited knowledge about the underlying
data, and have to use a try-and-see approach for ﬁnding
information. A recent trend of supporting autocomplete in
these systems is a ﬁrst step towards solving this problem.
In this paper, we study a new information-access paradigm,
called “interactive, fuzzy search,” in which the system searches
the underlying data “on the ﬂy” as the user types in query
keywords. It extends autocomplete interfaces by (1) allow-
ing keywords to appear in multiple attributes (in an arbi-
trary order) of the underlying data; and (2) ﬁnding relevant
records that have keywords matching query keywords ap-
proximately. This framework allows users to explore data as
they type, even in the presence of minor errors. We study
research challenges in this framework for large amounts of
data. Since each keystroke of the user could invoke a query
on the backend, we need eﬃcient algorithms to process each
query within milliseconds. We develop various incremental-
search algorithms using previously computed and cached re-
sults in order to achieve an interactive speed. We have de-
ployed several real prototypes using these techniques. One
of them has been deployed to support interactive search on
the UC Irvine people directory, which has been used regu-
larly and well received by users due to its friendly interface
and high eﬃciency.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval—query formulation, search process

General Terms
Algorithms, Experimentation, Performance

Keywords
Interactive Search, Fuzzy Search, Autocomplete

1.

INTRODUCTION

In a traditional information system, a user composes a
query, submits it to the system, which retrieves relevant

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

answers. This information-access paradigm requires the user
to have certain knowledge about the structure and content
of the underlying data repository. In the case where the user
has limited knowledge about the data, often the user feels
“left in the dark” when issuing queries, and has to use a try-
and-see approach for ﬁnding information, as illustrated by
the following example.

At a conference venue, an attendee named John met a
person from a university. After the conference he wanted
to get more information about this person, such as his re-
search projects. All John knows about the person is that
he is a professor from that university, and he only remem-
bers the name roughly. In order to search for this person,
John goes to the directory page of the university. Figure 1
shows such an interface. John needs to ﬁll in the form by
providing information for multiple attributes, such as name,
phone, department, and title. Given his limited information
about the person, especially since he does not know the ex-
act spelling of the person’s name, John needs to try a few
possible keywords, go through the returned results, modify
the keywords, and reissue a new query. He needs to repeat
this step multiple times to ﬁnd the person, if lucky enough.
This search interface is neither eﬃcient nor user friendly.

Figure 1: A typical directory-search form.

Many systems are introducing various features to solve
this problem. One of the commonly used methods is au-
tocomplete, which predicts a word or phrase that the user
may type based on the partial query the user has entered.
As an example, almost all the major search engines nowa-
days automatically suggest possible keyword queries as a
user types in partial keywords. Both Google Finance and
Yahoo! Finance support searching for stock information in-
teractively as users type in keywords. More and more Web
sites are having this feature, due to recent advances in high-
speed networks and browser-based programming languages
and tools such as JavaScript and AJAX.

In this paper, we study a new computing paradigm, called
“interactive, fuzzy search.” It has two unique features: (1)

WWW 2009 MADRID!Track: Search / Session: Search UI371Figure 2: Interactive fuzzy search on the UC Irvine people directory (http://psearch.ics.uci.edu).

Interactive: The system searches for the best answers “on the
ﬂy” as the user types in a keyword query; (2) Fuzzy: When
searching for relevant records, the system also tries to ﬁnd
those records that include words similar to the keywords in
the query, even if they do not match exactly.

We have developed several prototypes using this paradigm.
The ﬁrst one supports search on the UC Irvine people direc-
tory. A screenshot is shown in Figure 2. In the ﬁgure, a user
has typed in a query string “professor smyt”. Even though
the user has not typed in the second keyword completely,
the system can already ﬁnd person records that might be
of interest to the user. Notice that the two keywords in
the query string (including a partial keyword “smyt”) can
appear in diﬀerent attributes of the records. In particular,
in the ﬁrst record, the keyword “professor” appears in the
“title” attribute, and the partial keyword “smyt” appears in
the “name” attribute. The matched preﬁxes are highlighted.
The system can also ﬁnd records with words that are sim-
ilar to the query keywords, such as a person name “smith”.
The feature of supporting fuzzy search is especially impor-
tant when the user has limited knowledge about the under-
lying data or the entities he or she is looking for. As the user
types in more letters, the system interactively searches on
the data, and updates the list of relevant records. The sys-
tem also utilizes a-priori knowledge such as synonyms. For
instance, given the fact that “william” and “bill” are syn-
onyms, the system can ﬁnd a person called “William Kropp”
when the user has typed in “bill crop”. This search proto-
type has been used regularly by many people at UCI, and
received positive feedback due to the friendly user inter-
face and high eﬃciency. Another prototype, available at
http://dblp.ics.uci.edu, supports search on a DBLP dataset
(http//www.informatik.uni-trier.de/∼ley/db/) with about
1 million publication records. A third prototype, available at
http://pubmed.ics.uci.edu, supports search on 3.95 million
MEDLINE records (http://www.ncbi.nlm.nih.gov/pubmed).
In this paper we study research challenges that arise nat-
urally in this computing paradigm. The main challenge is
the requirement of a high eﬃciency. To make search re-
ally interactive, for each keystroke on the client browser,
from the time the user presses the key to the time the re-
sults computed from the server are displayed on the browser,
the delay should be as small as possible. An interactive
speed requires this delay be within milliseconds. Notice that
this time includes the network transfer delay, execution time
on the server, and the time for the browser to execute its
javascript (which tends to be slow). Providing a high eﬃ-

ciency on a large amount of data is especially challenging
because of two reasons. First, we allow the query keywords
to appear in diﬀerent attributes with an arbitrary order,
and the “on-the-ﬂy join” nature of the problem can be com-
putationally expensive. Second, we want to support fuzzy
search by ﬁnding records with keywords that match query
keywords approximately.

We develop novel solutions to these problems. We present
several incremental-search algorithms for answering a query
by using cached results of earlier queries. In this way, the
computation of the answers to a query can spread across
multiple keystrokes of the user, thus we can achieve a high
speed. Speciﬁcally, we make the following contributions.
(1) We ﬁrst study the case of queries with a single keyword,
and present an incremental algorithm for computing key-
word preﬁxes similar to a preﬁx keyword (Section 3). (2)
For queries with multiple keywords, we study various tech-
niques for computing the intersection of the inverted lists
of query keywords, and develop a novel algorithm for com-
puting the results eﬃciently (Section 4.1).
Its main idea
is to use forward lists of keyword IDs for checking whether
a record matches query keyword conditions (even approxi-
mately). (3) We develop a novel on-demand caching tech-
nique for incremental search. Its idea is to cache only part
of the results of a query. For subsequent queries, unﬁn-
ished computation will be resumed if the previously cached
results are not suﬃcient. In this way, we can eﬃciently com-
pute and cache a small amount of results (Section 4.2). (4)
We study various features in this paradigm, such as how to
rank results properly, how to highlight keywords in the re-
sults, and how to utilize domain-speciﬁc information such
as synonyms to improve search (Section 5). (5) In addition
to deploying several real prototypes, we conducted a thor-
ough experimental evaluation of the developed techniques
on real data sets, and show the practicality of this new com-
puting paradigm. All experiments were done using a single
desktop machine, which can still achieve response times of
milliseconds on millions of records.

1.1 Related Work
Prediction and Autocomplete:1 There have been many
studies on predicting queries and user actions [17, 14, 9, 19,
18]. With these techniques, a system predicts a word or

1The word “autocomplete” could have diﬀerent meanings.
Here we use it to refer to the case where a query (possibly
with multiple keywords) is treated as a single preﬁx.

WWW 2009 MADRID!Track: Search / Session: Search UI372a phrase the user may type in next based on the sequence
of partial input the user has already typed. Many predic-
tion and autocomplete systems treat a query with multiple
keywords as a single string, thus they do not allow these
keywords to appear at diﬀerent places. For instance, con-
sider the search box on the home page of Apple.com, which
allows autocomplete search on Apple products. Although
a keyword query “itunes” can ﬁnd a record “itunes wi-fi
music store,” a query with keywords “itunes music” can-
not ﬁnd this record (as of November 2008), simply because
these two keywords appear at diﬀerent places in the record.
The techniques presented in this paper focus on “search on
the ﬂy,” and they allow query keywords to appear at diﬀer-
ent places. As a consequence, we cannot answer a query by
simply traversing a trie index. Instead, the backend inter-
section (or “join”) operation of multiple lists requires more
eﬃcient indexes and algorithms.

CompleteSearch: Bast et al. proposed techniques to sup-
port “CompleteSearch,” in which a user types in keywords
letter by letter, and the system ﬁnds records that include
these keywords (possibly at diﬀerent places) [4, 5, 2, 3].
Our work diﬀers from theirs as follows. (1) CompleteSearch
mainly focused on compression of index structures, espe-
cially in disk-based settings. Our work focuses on eﬃcient
query processing using in-memory indexes in order to achieve
a high interactive speed. (2) Our work allows fuzzy search,
making the computation more challenging. (3) For a query
with multiple keywords, CompleteSearch mainly caches the
results of the query excluding the last keyword, which may
require computing and caching a large amount of interme-
diate results. Our incremental caching technique described
in Section 4.2 achieves a higher eﬃciency.

Gram-Based Fuzzy Search: There have been recent stud-
ies to support eﬃcient fuzzy string search using grams [7, 1,
8, 10, 15, 16, 13, 12, 11, 20, 6]. A gram of a string is a sub-
string that can be used as a signature for eﬃcient search.
These algorithms answer a fuzzy query on a collection of
strings using the following observation: if a string r in the
collection is similar to the query string, then r should share
a certain number of common grams with the query string.
This “count ﬁlter” can be used to construct gram inverted
lists for string ids to support eﬃcient search. In Section 6
we evaluated some of the representative algorithms. The re-
sults showed that, not surprisingly, they are not as eﬃcient
as trie-based incremental-search algorithms, mainly because
it is not easy to do incremental computation on gram lists,
especially when a user types in a relatively short preﬁx, and
count ﬁltering does not give enough pruning power to elim-
inate false positives.

2. PRELIMINARIES

Problem Formulation: We formalize the problem of in-
teractive, fuzzy search on a relational table, and our method
can be adapted to textual documents, XML documents, and
relational databases. Consider a relational table T with m
attributes and n records. Let A = {a1, a2, . . . , am} denote
the attribute set, R = {r1, r2, . . . , rn} denote the record set,
and W = {w1, w2, . . . , wp} denote the distinct-word set in
T . Given two words wi and wj, “wi (cid:3) wj ” denotes that wi
is a preﬁx string of wj .

A query consists of a set of preﬁxes Q = {p1, p2, . . . , pl}.
For each preﬁx pi, we want to ﬁnd the set of preﬁxes from
the data set that are similar to pi.2
In this work we use
edit distance to measure the similarity between two strings.
The edit distance between two strings s1 and s2, denoted
by ed(s1, s2), is the minimum number of edit operations
(i.e., insertion, deletion, and substitution) of single char-
acters needed to transform the ﬁrst one to the second. For
example, ed(smith, smyth) = 1.

Definition 1

(Interactive Fuzzy Search). Given a
set of records R, let W be the set of words in R. Consider
a query Q = {p1, p2, . . . , p(cid:2)} and an edit-distance thresh-
old δ. For each pi, let Pi be {p
i (cid:3) w and
(cid:2)
i, pi) ≤ δ}. Let the set of candidate records RQ be
(cid:2)
ed(p
{r|r ∈ R, ∀1 ≤ i ≤ (cid:3), ∃p
i ∈ Pi and wi appears in r,
(cid:2)
i (cid:3) wi}. The problem is to compute the best records in
(cid:2)
p
RQ ranked by their relevancy to Q. These records are com-
puted incrementally as the user modiﬁes the query, e.g., by
typing in more letters.

i|∃w ∈ W, p
(cid:2)

Indexing: We use a trie to index the words in the relational
table. Each word w in the table corresponds to a unique path
from the root of the trie to a leaf node. Each node on the
path has a label of a character in w. For simplicity, a node is
mentioned interchangeably with its corresponding string in
the remainder of the paper. Each leaf node has an inverted
list of IDs of records that contain the corresponding word,
with additional information such as the attribute in which
the keyword appears and its position. For instance, Figure 3
shows a partial index structure for publication records. The
word “vldb” has a trie node ID of 15, and its inverted list
includes record IDs 6, 7, and 8. For simplicity, the ﬁgure
only shows the record ids, without showing the additional
information about attributes and positions.

d
a
t
a

l

u

5

i

1

n

3 4 6

1 2 3 6

u
i
s

4

4

v
l
d
b

6 7 8

Figure 3: Trie with inverted lists at leaf nodes.

3. SINGLE KEYWORD

In this section we study interactive, fuzzy search on a
single keyword preﬁx. For the case of exact preﬁx search
using the trie index, the approach is straightforward:
for
each preﬁx, there exists only one corresponding trie node
(if any). The inverted lists of its descendant leaf nodes are
accessed to retrieve candidate records.

The solution to the problem of fuzzy search is trickier since
one preﬁx can have multiple similar preﬁxes (called “active
2Clearly our techniques can be used to answer queries when
only the last keyword is treated as a partial preﬁx, and the
other are treated as completed keywords.

WWW 2009 MADRID!Track: Search / Session: Search UI373ED = 0

ED = 1

ED = 2

0

10

l

0

10

l

0

10

l

0

10

l

0

10

l

11

i

14

u

4

11

i

14

u

4

11

i

14

u

4

11

i

14

u

4

11

i

14

u

4

1

n

u

12

13

3 4

5

15

16

i

s

7

1

n

u

12

13

3 4

5

15

16

i

s

7

1

n

u

12

13

3 4

5

15

16

i

s

7

1

n

u

12

13

3 4

5

15

16

i

s

7

1

n

u

12

13

3 4

5

15

16

i

s

7

(a) Initialize

(b) query “n”

(c) query “nl”

(d) query “nli”

(e) query “nlis”

Figure 4: Fuzzy search of preﬁx queries of “nlis” (threshold δ = 2).

nodes”), and we need to compute them eﬃciently. The leaf
descendants of the active nodes are called the predicted key-
words of the preﬁx. For example, consider the trie in Fig-
ure 4. Suppose the edit-distance threshold δ = 2, and a user
types in a preﬁx p = “nlis”. Preﬁxes “li”, “lin”, “liu”,
and “luis” are all similar to p, since their edit distances to
“nlis” are within δ. Thus nodes 11, 12, 13, and 16 are active
nodes for p (Figure 4 (e)). The predicted keywords for the
preﬁx are “li”, “lin”, “liu”, and “luis”.

We develop a caching-based algorithm for incrementally
computing active nodes for a keyword as the user types it
in letter by letter. Given an input preﬁx p, we compute and
store the set of active nodes Φp = {(cid:8)n, ξn(cid:9)}, in which n is
an active node, and ξn = ed(p, n) ≤ δ. The idea behind our
algorithm is to use preﬁx-ﬁltering: when the user types in
one more letter after p, the active nodes of p can be used to
compute the active nodes of the new query.
The algorithm works as follows. First, an active-node set
is initialized for the empty query , i.e., Φ = {(cid:8)n, ξn(cid:9) |
ξn = |n| ≤ δ}. That is, it includes all trie nodes n whose
corresponding string has a length |n| within the edit-distance
threshold δ. These nodes are active nodes for  since their
edit distances to  are within δ.

As the user types in a query string px = c1c2 . . . cx letter
by letter, the active-node set Φpx is computed and cached
for px. When the user types in a new character cx+1 and
submits a new query px+1, the server computes the active-
node set Φpx+1 for px+1 by using Φpx . For each (cid:8)n, ξn(cid:9)
in Φpx , the descendants of n are examined as active-node
candidates for px+1, as illustrated in Figure 5. For the node
n, if ξn + 1 ≤ δ, then n is an active node for px+1, and
(cid:8)n, ξn + 1(cid:9) is added into Φpx+1 . This case corresponds to
deleting the last character cx+1 from the new query string
px+1. Notice even if ξn + 1 ≤ δ is not true, node n could still
potentially become an active node of the new string, due to
operations described below on other active nodes in Φpx .

For each child nc of node n, there are two possible cases.
Case 1: the child node nc has a character diﬀerent from
cx+1. Figure 5 shows a node ns for such a child node, where
“s” stands for “substitution,” the meaning of which will be-
come clear shortly. We have ed(ns, px+1) ≤ ed(n, px) + 1 =
If ξn + 1 ≤ δ, then ns is an active node for the
ξn + 1.
new string, and (cid:8)ns, ξn + 1(cid:9) is added into Φpx+1 . This case
corresponds to substituting the label of ns for the letter
cx+1. Case 2: the child node nc has a label cx+1. Figure 5
shows the node nm for such a child node, where “m” stands

for “matching.” In this case, ed(nm, px+1) ≤ ed(n, px) =
ξn ≤ δ. Thus, nm is an active node of the new string, so we
add (cid:8)nm, ξn(cid:9) into Φpx+1 . This case corresponds to the match
between the character cx+1 and the label of nm. One sub-
tlety here is that, if the distance for the node nm is smaller
than δ, i.e., ξn < δ, the following operation is also required:
for each nm’s descendant d that is at most δ − ξn letters
away from nm, we need to add (cid:8)d, ξd(cid:9) to the active-node set
for the new string px+1, where ξd = ξn + |d| − |nm|. This
operation corresponds to inserting several letters after node
nm.3

… …

n, n

… …

px+1

… …
+1

n , n
ns ,
n+1

nm ,

n
cx+1

px

c1
c2
c3
.
.
.
cx
cx+1

… …

n

d ,

n+|d|-|nm|

… …

Deletion

Match

Substitution

Insersion

Figure 5: Incrementally computing the active-node
set Φpx+1 from the active-node set Φpx . We consider
an active node (cid:8)n, ξn(cid:9) in Φpx .

During the computation of set Φpx+1 , it is possible to add
multiple pairs (cid:8)v, ξ1(cid:9), (cid:8)v, ξ2(cid:9), . . . for the same trie node v.
In this case, only the one with the smallest edit operation is
kept in Φpx+1 . The reason is that, by deﬁnition, for the same
trie node v, only the pair with the edit distance between the
node v and the query string px+1 should be kept in Φpx+1 ,
which means the minimum number of edit operations to
transform the string of v to the string of px+1.
3Descendants of node ns do not need to be considered for
insertions, because if these descendants are active nodes of
Φpx+1 , their parents must appear in Φpx , and they can be
processed by substitutions on their parents.

WWW 2009 MADRID!Track: Search / Session: Search UI374The following lemma shows the correctness of this algo-

4. MULTIPLE KEYWORDS

rithm.

Lemma 1. For a query string px = c1c2 . . . cx, let Φpx
be its active-node set. Consider a new query string px+1 =
c1c2 . . . cxcx+1. (1) Soundness: Each node computed by the
algorithm described above is an active node of the new query
string px+1. (2) Completeness: Every active node of the new
query string px+1 will be computed by the algorithm above.

For example, assume a user types in a query “nlis” let-
ter by letter, and the threshold δ is 2. Figure 4 illustrates
how the algorithm processes the preﬁx queries invoked by
keystrokes. Table 1 shows the details of how to compute the
active-node sets incrementally. The ﬁrst step is to initialize
Φ = {(cid:8)0, 0, (cid:8)10, 1(cid:9), (cid:8)11, 2(cid:9), (cid:8)14, 2(cid:9)} (Figure 4(a) and Ta-
ble 1(a)). When the user types in the ﬁrst character “n”, for
the string s = “n”, its active-node set Φs is computed based
on Φ as follows. For (cid:8)0, 0(cid:9) ∈ Φ, we add (cid:8)0, 1(cid:9) into Φs, since
letter “n” can be deleted. For node 10, a child of node 0 with
a letter “l”, (cid:8)10, 1(cid:9) is added into Φs, as “l” can be substi-
tuted for “n”. There are no match and insertion operations
as node 1 does not have a child with label “n”. Φs is com-
puted in this way (Figure 4 (b) and Table 1 (b)). Similarly,
preﬁx queries of “nlis” can be answered incrementally.

For each active node, the keywords corresponding to its
leaf descendants are predicted keywords. Consider the active-
node set for the preﬁx query “nl” as shown in Figure 4(c).
For (cid:8)11, 2(cid:9), “li, “lin”, and “liu” are predicted keywords ac-
cordingly. We retrieve the records on the inverted lists of
predicted words to compute answers to the query.

Table 1: Active-node sets for processing preﬁx
queries of “nlis” (edit distance threshold δ = 2)
(a) Query “n”

(b) Query “nl”

(c) Query “nli”

Φ
Delete
Substitute
Match
Insert
Φn

Φn
Delete
Substitute
Match
Insert
Φnl

Φnl
Delete
Substitute
Match
Insert
Φnli

Φnli
Delete
Substitute
Match
Insert
Φnlis

(d) Query “nlis”

(cid:2)11,2(cid:3)

(cid:2)14,2(cid:3)

(cid:2)0,0(cid:3)
(cid:2)0,1(cid:3)
(cid:2)10,1(cid:3)

(cid:2)10,1(cid:3)
(cid:2)10,2(cid:3)

–
–

(cid:2)11,2(cid:3);(cid:2)14,2(cid:3)

–
–
–
–
–
–
(cid:2)0,1(cid:3); (cid:2)10,1(cid:3); (cid:2)11,2(cid:3); (cid:2)12,2(cid:3); (cid:2)14,2(cid:3)

(cid:2)12,2(cid:3)

–
–

–

(cid:2)0,1(cid:3)
(cid:2)10,1(cid:3)
(cid:2)0,2(cid:3)
(cid:2)10,2(cid:3)
(cid:2)11,2(cid:3);(cid:2)14,2(cid:3)
–
(cid:2)10,1(cid:3)
–
(cid:2)11,2(cid:3);(cid:2)14,2(cid:3) –

–
–
–
–
(cid:2)10,1(cid:3); (cid:2)0,2(cid:3); (cid:2)11,2(cid:3); (cid:2)14,2(cid:3)

(cid:2)11,2(cid:3) (cid:2)12,2(cid:3) (cid:2)14,2(cid:3)
–
–
–
–

–
–
–
–

(cid:2)10,1(cid:3)
(cid:2)10,2(cid:3)
(cid:2)14,2(cid:3)
(cid:2)11,1(cid:3)

(cid:2)0,2(cid:3)
–
–
–
–

–
–
–
–

(cid:2)11,2(cid:3)

(cid:2)14,2(cid:3)

–
–

(cid:2)15,2(cid:3)

–

(cid:2)12,2(cid:3);(cid:2)13,2(cid:3)
(cid:2)11,1(cid:3); (cid:2)10,2(cid:3); (cid:2)12,2(cid:3); (cid:2)13,2(cid:3); (cid:2)14,2(cid:3); (cid:2)15,2(cid:3)
(cid:2)11,1(cid:3)
(cid:2)10,2(cid:3) (cid:2)12,2(cid:3) (cid:2)13,2(cid:3) (cid:2)14,2(cid:3) (cid:2)15,2(cid:3)
(cid:2)11,2(cid:3)
–
(cid:2)12,2(cid:3);(cid:2)13,2(cid:3) –
–
–
–
–

–
–
–
–
(cid:2)11,2(cid:3); (cid:2)12,2(cid:3); (cid:2)13,2(cid:3); (cid:2)16,2(cid:3)

–
–
(cid:2)16,2(cid:3)
–

–
–
–
–

–
–
–
–

In this section we study answering interactive fuzzy search
when a user types in multiple keywords. The goal is to ef-
ﬁciently and incrementally compute the records with key-
words whose preﬁxes are similar to those query keywords.
(1) Inter-
We focus on several challenges in this setting.
section of multiple lists of keywords: Each query keyword
(treated as a preﬁx) has multiple predicted complete key-
words, and the union of the lists of these predicted keywords
includes potential answers. The union lists of multiple query
keywords need to be intersected in order to compute the an-
swers to the query. These operations can be computation-
ally costly, especially when each query keyword can have
multiple similar preﬁxes.
In Section 4.1 we study various
algorithms for computing the answers eﬃciently. (2) Cache-
based incremental intersection: In most cases, the user types
the query letter by letter, and subsequent queries append ad-
ditional letters to previous ones. Based on this observation,
we study how to use the cached results of earlier queries to
answer a query incrementally (Section 4.2).
4.1 Intersecting Union Lists of Preﬁxes

For simplicity, we ﬁrst consider exact search, and then
extend the results to fuzzy search. Given a query Q =
{p1, p2, . . . , p(cid:2)}, suppose {ki1 , ki2 , . . .} is the set of keywords
that share the preﬁx pi. Let Lij denote the inverted list of
kij , and Ui =
j Lij be the union of the lists for pi. We
i Ui.
study how to compute the answer to the query, i.e.,

S

T

P

i,j |Lij|). The shorter the keyword preﬁx is, the slower

Simple Methods: One method is the following. For each
preﬁx pi, we compute the corresponding union list Ui on-
the-ﬂy and intersect the union lists of diﬀerent keywords.
The time complexity for computing the unions could be
O(
the query could be, as inverted lists of more predicted key-
words need to be traversed to generate the union list. This
approach only requires the inverted lists of trie leaf nodes,
and the space complexity of the inverted lists is O(n × L),
where n is the number of records and L is the average num-
ber of distinct keywords of each record.

Alternatively, we can pre-compute and store the union list
of each preﬁx, and intersect the union lists of query keywords
when a query comes. The main issue of this approach is
that the precomputed union lists require a large amount of
space, especially since each record occurrence on an inverted
list needs to be stored many times. The space complexity of
all the union lists is O(n × L × w), where w is the average
keyword length. Compression techniques can be used to
reduce the space requirement.

There have been other approaches for answering preﬁx
intersection. For instance, Bast et al. [4] proposed a method
that groups ranges of keywords and builds document lists
separately for each range. Intersection is performed between
an existing document list and several ranges called “HYB
blocks.” The limitation of this approach is that, for most
queries, the ranges can include many irrelevant documents,
which require a lot of time to process. We will show our
experimental results of this method in Section 6.

Eﬃcient Preﬁx Intersection Using Forward Lists: We
develop a new solution based on the following ideas. Among
the union lists U1,U2, . . . ,U(cid:2), we identify the shortest union
list. Each record ID on the shortest list is veriﬁed by check-

WWW 2009 MADRID!Track: Search / Session: Search UI375ing if it exists on all the other union lists (following the
ascending order of their lengths). Notice that these union
lists are not materialized in the computation. The shortest
union list can be traversed by accessing the leaf nodes of the
corresponding preﬁx. The length of each union list can be
pre-computed and stored in the trie, or estimated on-the-ﬂy.
To verify record occurrences eﬃciently, a forward list can be
maintained for each record r, which is a sorted list of IDs of
keywords in r, denoted as Fr. A unique property of the key-
word IDs is that they are encoded using their alphabetical
order. Therefore, each preﬁx pi has a range of keyword IDs
[M inIdi, M axIdi], so that if pi is a preﬁx of another string
s, then the ID of s should be within this range.

An interesting observation is, for a record r on the short-
est union list, the problem of verifying whether r appears
on (non-materialized) union list Uk of a query preﬁx pk, is
equivalent to testing if pk appears in the forward list Fr as
a preﬁx. We can do a binary search for M inIdk on the for-
ward list Fr to get a lower bound Idlb, and check if Idlb is no
larger than M axIdk. The probing succeeds if the condition
`
´
holds, and fails otherwise. The time complexity for process-
((cid:3) − 1)logL
, where (cid:3) is the
ing each single record r is O
number of keywords in the query, and L is the average num-
ber of distinct keywords in each record. A good property of
this approach is that the time complexity of each probing
does not depend on the lengths of inverted lists, but on the
number of unique keywords in a record (logarithmically).

Figure 6 shows an example when a user types in a query
“vldb li”. The predicted keywords for “li” are “li”, “lin”,
“line”, and “linux”. The keyword-ID range of each query
keyword is shown in brackets. For instance, the keyword-
ID range for preﬁx “li” is [3, 5], which covers the ranges of
“lin” and “liu”. To intersect the union list of “vldb” with
that of “li”, we ﬁrst identify “vldb” as the one with the
shorter union list. The record IDs (6, 7, 8, . . .) on the list
are probed one by one. Take record 6 as an example. Its
forward list contains keyword IDs 2, 4, 8, . . .. We use the
range of “li” to probe the forward list. By doing a binary
search for the keyword ID 3, we ﬁnd keyword with ID 4 on
the forward list, which is then veriﬁed to be no larger than
MaxID = 6. Therefore, record 6 is an answer to the query,
and the keyword with ID 4 (which appears in record 6) has
“li” as a preﬁx.

vldb[8,8] li[3,6]

li
lin
line
linux
vldb

[3,6]
[4,6]
[5,5]
[6,6]
[8,8]

6

7

8

…

Shortest 
Inverted 

List

2 4 9 …

Probing

1 2 7 8 …

1 2 3 9 …

Forward Lists

Figure 6: Preﬁx intersection using forward lists.
(Numbers with underlines are keyword IDs, and
numbers without underlines are record IDs.)

Extension to Fuzzy Search: The algorithm described
above naturally extends to the case of fuzzy search. Since
each query keyword has multiple active nodes of similar pre-
ﬁxes, instead of considering the union of the leaf nodes of

one preﬁx node, now we need to consider the unions of the
leaf nodes for all active nodes of a preﬁx keyword. The
lengths of these union lists can be estimated in order to ﬁnd
a shortest one. For each record r on the shortest union list,
for each of the other query keywords, for each of its active
nodes, we test if the corresponding similar preﬁx can appear
in the record r as a preﬁx using the forward list of r.

4.2 Cache-Based Intersection of Preﬁxes

In Section 3 we presented an algorithm for incrementally
computing similar preﬁxes for a query keyword, as the user
types the keyword letter by letter. Now we show that pre-
ﬁx intersection can also be performed incrementally using
previously cached results.

We use an example to illustrate how to cache query results
and use them to answer subsequent queries. Suppose a user
types in a keyword query Q1 = “cs co”. All the records
in the answers to Q1 are computed and cached. For a new
query Q2 = “cs conf” that appends two letters to the end
of Q1, we can use the cached results of Q1 to answer Q2,
because the second keyword “conf” in Q2 is more restrictive
than the corresponding keyword “co” in Q1. Each record in
the cached results of Q1 is veriﬁed to check if “conf” can
appear in the record as a preﬁx. In this way, Q2 does not
need to be answered from scratch. As in this example, in the
following discussion, we use “Q1” to refer to a query whose
results have been cached, and “Q2” to refer to a new query
whose results we want to compute using those of Q1.

Cache Miss: Often the more keywords the user types in,
the more typos and mismatches the query could have. Thus
we may want to dynamically increase the edit-distance thresh-
old δ as the query string is getting longer. Then it is possi-
ble that the threshold for the new query Q2 is strictly larger
than that of the original query Q1. In this case, the active
nodes of keywords in Q1 might not include all those of key-
words in Q2. As a consequence, we cannot use the cached
results of Q1 (active nodes and answers) to compute those
of Q2. This case is a cache miss, and we need to compute
the answers of Q2 from scratch.

Reducing Cached Results: The cached results of query
Q1 could be large, which could require a large amount of
time to compute and space to store. There are several cases
where we can reduce the size. The ﬁrst case is when we
want to use pagination, i.e., we show the results in diﬀerent
pages. In this case, we can traverse the shortest list partially,
until we have enough results for the ﬁrst page. As the user
browses the results by clicking “Previous” and “Next” links,
we can continue traversing the shortest list to compute more
results and cache them.

The second case is when the user is only interested in
the best results, say, the top-k records according a ranking
function, for a predeﬁned constant k. Such a function could
allow us to compute the answers to the query Q1 without
traversing the entire shortest list, assuming we are sure that
all the remaining records on the list cannot be better than
the results already computed.
In other words, the rank-
ing function allows us to do early termination during the
traversal. When using the top-k results of Q1 to compute
the top-k results of Q2, it is possible that the cached results
are not enough, since Q2 has a more restrictive keyword. In
this case, we can continue the unﬁnished traversal on the

WWW 2009 MADRID!Track: Search / Session: Search UI376shortest list, assuming we have remembered the place where
the traversal stopped on the shortest list for query Q1.

Figure 7 shows an example of incrementally computing
top-k answers using cached results. A user types in a query
“cs conf vanc” letter by letter, and the server receives queries
“cs co”, “cs conf”, and “cs conf vanc” in order. (Notice
that it is possible that some of the preﬁx queries were not
received by the server due to the network overhead and the
server delay.) The ﬁrst query “cs co” is answered from
scratch. Assuming the union list of keyword “cs” is the
shorter one. The traversal stops at the ﬁrst vertical bar.
Each record accessed in the traversal is veriﬁed by probing
the keyword range of “co” using the forward list of the record.
Records that pass the veriﬁcation are cached. When we want
to answer the query “cs conf” incrementally, we ﬁrst verify
each record in the cached result of the previous query by
probing the keyword range of “conf”. Some of these results
will become results of the new query. If the results from the
cache is insuﬃcient to compute the new top-k, we resume
the traversal on the list of “cs”, starting from the stopping
point of the previous query, until we have enough top-k re-
sults for the new query. The next query “cs conf vanc” is
answers similarly.

cs co

cs conf

Stopping point

Compute

Traversal list

Cached results

Verify

Compute

Traversal list

cs conf vanc

Cached results

Verify

Compute

Traversal list

Cached results

Figure 7: Computing top-k results using cached an-
swers and resuming unﬁnished traversal on a list.

In the case of cache miss, i.e., earlier cached results cannot
be used to compute the answers of a new query, we may need
to answer the new query from scratch. We may choose a
diﬀerent list as the shortest one to traverse, and subsequent
queries can be computed incrementally similarly.

5. ADDITIONAL FEATURES

5.1 Ranking

A ranking function considers various factors to compute
an overall relevance score of a record to a query. The fol-
lowing are several important factors. (1) Matching preﬁxes:
We consider the similarity between a query keyword and its
best matching preﬁx. The more similar a record’s matching
keywords are to the query keywords, the higher this record
should be ranked. The similarity is also related to keyword
length. For example, when a user types in a keyword “circ”,
the word “circle” is closer to the query keyword than “cir-
cumstance”, therefore records containing the word “circle”

could be ranked higher.
In most cases exact matches on
the query should have a higher priority than fuzzy matches.
(2) Predicted keywords: Diﬀerent predicted keywords for the
same preﬁx can have diﬀerent weights. One way to assign
a score to a keyword is based on its inverted document fre-
quency (IDF). (3) Record weights: Diﬀerent records could
have diﬀerent weights. For example, a publication record
with many citations could be ranked higher than a less cited
publication.

As an example, the following is a scoring function that
combines the above factors. Suppose the query is Q =
{p1, p2, . . .}, p
(cid:2)
i is the best matching preﬁx for pi, and ki
(cid:2)
is the best predicted keyword for p
i) be an
(cid:2)
i and pi. The score of a record r
edit similarity between p
for Q can be deﬁned as:

(cid:2)
i. Let sim(pi, p

X

Score(r, Q) =

[sim(pi, p

i

i)+α·(|p
(cid:2)

i|−|ki|)+β·score(r, ki)],
(cid:2)

where α and β are weights (0 < β < α < 1), and score(r, ki)
is a score of record r for keyword ki.
5.2 Highlighting Best Preﬁxes

When displaying records to the user, the most similar pre-
ﬁxes for an input preﬁx should be highlighted. This high-
lighting is straightforward for the exact-match case. For
fuzzy search, a query preﬁx could be similar to several pre-
ﬁxes of the same predicted keyword. Thus, there could be
multiple ways to highlight the predicted keyword. For exam-
ple, suppose a user types in “lus”, and there is a predicted
keyword “luis”. Both preﬁxes “lui” and “luis” are similar
to “lus”, and there are several ways to highlight them, such
as “luis” or “luis”. To address this issue, we use the concept
of normalized edit distance. Formally, given two preﬁxes pi
and pj, their normalized edit distance is:

ed(pi, pj)

max(|pi|,|pj|)

,

ned(pi, pj) =

(1)
where |pi| denotes the length of pi. Given an input preﬁx
and one of its predicted keywords, the preﬁx of the predicted
keyword with the minimum ned to the query is highlighted.
We call such a preﬁx a best matched preﬁx, and call the
corresponding normalized edit distance the “minimal nor-
malized edit distance,” denoted as “mned”. This preﬁx is
considered to be most similar to the input. For example, for
the keyword “lus” and its predicted word “luis”, we have
ned(“lus”, “l”) = 2
3 , ned(“lus”, “lui”)
= 1
4 . Since mned(“lus”, “luis”)
= ned(“lus”, “luis”), “luis” will be highlighted.

3 , and ned(“lus”, “luis”) = 1

3 , ned(“lus”, “lu”) = 1

5.3 Using Synonyms

We can utilize a-priori knowledge about synonyms to ﬁnd
relevant records. For example, “William = Bill” is a com-
mon synonym in the domain of person names. Suppose in
the underlying data, there is a person called “Bill Gates”.
If a user types in “William Gates”, we can also ﬁnd this
person. To this end, on the trie, the node corresponding to
“Bill” has a link to the node corresponding to “William”,
and vise versa. When a user types in “Bill”, in addition
to retrieving the records for “Bill”, we also identify those
of “William” following the link. In this way, our techniques
can be extended to utilize synonyms.

WWW 2009 MADRID!Track: Search / Session: Search UI3776. EXPERIMENTS

We deployed several prototypes in diﬀerent domains to
support interactive, fuzzy search. We conducted a thorough
experimental evaluation of the developed techniques on real
data sets, such as publications and people directories. Here
we report the results on the following two data sets mainly
because of their relative large sizes. (1) DBLP: It included
about one million computer science publication records, with
six attributes: authors, title, conference or journal name,
year, page numbers, and URL. (2) MEDLINE: It had about
4 million latest publication records related to life sciences
and biomedical information. We used ﬁve attributes: au-
thors, their aﬃliations, article title, journal name, and jour-
nal issue. Table 2 shows the sizes of the data sets, index
sizes, and index-construction times.

Table 2: Data sets and index costs

Data Set

DBLP

Record Number

Original Data Size

# of Distinct Keywords
Index-Construction Time

Trie Size

Inverted-List Size
Forward-List Size

1 million
190 MB

392K
50 secs
36 MB
52 MB
54 MB

MEDLINE
4 million
1.25 GB

1.79 million

588 secs
165 MB
445 MB
454 MB

Two prototypes are available at http://dblp.ics.uci.edu/
and http://pubmed.ics.uci.edu/. For each of them, we set
up a Web server using Apache2 on a Linux machine with an
Intel Core 2 Quad processor Q6600 (2.40GHz, 8M, 1066MHz
FSB) and 8G DDR2-800 memory. We implemented the
backend as a FastCGI server process, which was written in
C++, compiled with a GNU compiler. To make sure our
experiments did not aﬀect the deployed systems, we did the
experiments on another Linux machine with an Intel Core
2 Duo processor E6600 (2.40GHz, 4M, 1066MHz FSB) and
3G DDR2-667 memory.
6.1 Efﬁciency of Computing Similar Preﬁxes
We evaluated the eﬃciency of computing the preﬁxes on
the trie that are similar to a query keyword. For each data
set, we generated 1,000 single-keyword queries by randomly
selecting keywords in the data set, and applying a random
number of edit changes (0 to 2) on the keyword. The average
length (number of letters) of keywords was 9.9 for the DBLP
data set, and 10.2 for the MEDLINE data set. For each
preﬁx of each query, we measured the time to ﬁnd similar
preﬁxes within an edit distance of 2, not including the time
to retrieve records. We computed the average time for the
preﬁx queries with the same length.

We implemented three methods to compute similar pre-
ﬁxes. (1) Incremental/Cache: We computed the active nodes
of a query using the cached active nodes of previous preﬁx
queries, using the incremental algorithm presented in Sec-
tion 3. This algorithm is applicable when the user types a
query letter by letter. (2) Incremental/NoCache: We used
the incremental algorithm, but assuming no earlier active
nodes have been cached, and the computation started from
scratch. This case happens when a user copies and pastes
a long query, and none of the active nodes of any preﬁx
queries has been computed. It also corresponds to the tra-
ditional non-interactive-search case, where a user submits a

query and clicks the “Search” button. (3) Gram-Based: We
built gram inverted lists on all preﬁxes with at least three
letters using the method described in [15]. We used the im-
plementation in the Flamingo release4, using a gram length
of 3 and a length ﬁlter. The total number of such preﬁxes
was 1.1 millions for the DBLP data set and 5 millions for
the MEDLINE data set. The index structure can be used
to compute similar preﬁxes for keywords with at least four
letters.

Figure 8 shows the performance results of these three
methods. The method Incremental/Cache was most eﬃcient.
As the user types in letters, its response time ﬁrst increased
slightly (less than 5 ms), and then started decreasing quickly
after the fourth letter. The main reason is that the number
of active nodes decreased, and the cached results made the
computation eﬃcient. The method Incremental/NoCache re-
quired longer time since each query needed to be answered
from scratch, without using any cached active nodes. The
method Gram-Based performed eﬃciently when the query
keyword had at least seven letters. But it had a very poor
performance for shorter keywords, since the count ﬁlter had
a weak power to prune false positives.

Incremental/Cache
Incremental/NoCache
Gram-Based

)
s
m

 1000

(
 

i

 

e
m
T
h
c
r
a
e
S
g
v
A

 

 100

 10

 1

 0.1

 0.01

)
s
m

 1000

(
 

i

 

e
m
T
h
c
r
a
e
S
g
v
A

 

 100

 10

 1

 0.1

 0.01

Incremental/Cache
Incremental/NoCache
Gram-Based

 2

 4

 6

 8

 10  12  14

Prefix Length

(a) DBLP

 2

 4

 6

 8

 10  12  14

Prefix Length
(b) MEDLINE

Figure 8: Computing preﬁxes similar to a keyword.

6.2 Efﬁciency of List Intersection of Multiple

Keywords

We evaluated several methods for intersecting union lists
of multiple keywords, as described in Section 4.1. For each
data set, we generated 1,000 queries by randomly selecting
records from the data set, and choosing keywords from each
record. We implemented the following methods to intersect
the union lists of the keywords. (1) ForwardLists: It is the al-
gorithm presented in Section 4.1, which traverses the short-
est union list and uses the other query keywords to probe
the forward lists of records on the shortest list. The union
list was traversed on the ﬂy without being materialized. (2)
HashProbe: The shortest union list was materialized as a
hash table at query time. Each record ID on the other union
lists was searched on the hash table. (3) MaterializedUnions:
We materialized the union lists of all the query keywords
and their preﬁxes, and computed an intersection by using
the record IDs of the shortest list to probe the other union
lists. We measured the intersection time only. (4) HYB: We
implemented a structure called “HYB” as described in [4].
We used an in-memory implementation, and all IDs were
stored without any encoding and compression, since decod-
ing and decompression will introduce additional time over-
head during query answering. The number of HYB blocks

4http://ﬂamingo.ics.uci.edu/releases/2.0

WWW 2009 MADRID!Track: Search / Session: Search UI378cases, since it can stop early during the traversal of the list,
and a new query can be incrementally computed using ear-
lier results. All these methods required a relative long time
when the preﬁx had 6 letters due to the cache miss.

 16

 12

)
s
m

(
 

i

 

e
m
T
h
c
r
a
e
S
g
v
A

 

68.7

38.7

32.8

NoCache
CompleteTraversal
PartialTraversal

 8

 4

 0

 2

 3

 4

 6

 5
 7
Prefix Length

 8

 9

 10

Figure 10: Performance of preﬁx intersection
(DBLP).

6.4 Scalability

We evaluated the scalability of our algorithms. As an ex-
ample, we used the MEDLINE dataset. Figure 11(a) shows
how the index size increased as the number of records in-
creased. It shows that all the sizes of trie, inverted lists, and
forward lists increased linearly.

ForwardLists
HashProbe
MaterializedUnions
HYB

(
 

i

e
z
S
 
x
e
d
n

I

 1200

 1000

)

B
M

Forward Lists
Inverted Lists
Trie

 800

 600

 400

 200

 0

 0.5  1  1.5  2  2.5  3  3.5  4

Record Number (million)
(a) Index Size

 3

 4

 5

 6

 7

 8

 9  10

Prefix Length
(b) MEDLINE

Queries with errors
Queries with no errors

was 162 for the DBLP dataset and 285 for the MEDLINE
data set, using the parameters recommended in [4].

We evaluated these methods on queries with two key-
words, assuming no previous query results were cached. Fig-
ure 9 shows the average time of each method as the length
of the second keyword increased. The intersection opera-
tion was very time consuming when the second keyword
had no more than two letters, since the union lists of the
preﬁxes were long. The HashProbe method performed rel-
atively poorly due to the cost of building the hash table
for the shorter list and traversing the other list. The HYB
method’s performance was even worse for most cases. The
main reason is that this method was designed to have a pre-
ﬁx overlapping with few HYB blocks (usually one or two)
to avoid merging too many answer lists. However, it has a
side eﬀect that an HYB block could include too many key-
words compared to the query preﬁx, forcing the method to
process long lists. This drawback was not a main issue in
a disk-based setting, as the algorithm can beneﬁt from list
compression and sequential disk IOs time. The Materialize-
dUnions method performed well, but with a high memory
cost as discussed in Section 4.1. The ForwardLists algorithm
achieved an excellent performance, at the cost of storing
the forward lists. An interesting ﬁnding in the results is
that ForwardLists even outperformed MaterializedUnions on
the MEDLINE data set. This is because as the data set be-
came larger, the average time of each binary search on the
union lists increased, while the average time of each binary
probe on the forward lists did not change much.

i

 

(
 

 4
)
s
m
 3
e
m
T
 2
h
c
r
a
e
 1
S
g
v
A
 0

 

 2

 3

ForwardLists
HashProbe
MaterializedUnions
HYB

 4

 5

 6

 7

 8

 9

 10

Prefix Length
(a) DBLP

)
s
m

 120

(
 

i

 

e
m
T
h
c
r
a
e
S
g
v
A

 

 90

 60

 30

 0

 2

Figure 9: List intersection of multiple keywords.

6.3 Performance of Cache-Based Intersection
We evaluated the performance of diﬀerent methods of
cache-based preﬁx intersection, as described in Section 4.2.
We allowed at most one typo for each preﬁx with at most
ﬁve letters, and two errors for preﬁxes with more than ﬁve
letters. As a consequence, for a query with two keywords,
when the sixth letter of the second keyword was typed in, a
cache miss occurred. We implemented the following meth-
ods. (1) NoCache: No query results are cached. A query
is computed without using any cached query results. Early
termination is enabled. (2) CompleteTraversal: It traverses
the shortest union list completely to compute the results
of the current query. (3) PartialTraversal: It traverses the
shortest union list partially until it ﬁnds the top 10 results
for the current query (as discussed in Section 4.2).

Figure 10 shows the query time of the methods on the
DBLP data set. CompleteTraversal outperformed the No-
Cache method for relatively long preﬁxes (with more than 6
letters) mainly due to the smaller set of cached results. The
PartialTraversal method was the most eﬃcient one in most

)
s
m

(
 

i

 

e
m
T
h
c
r
a
e
S
g
v
A

 

 4
 3.5
 3
 2.5
 2
 1.5
 1
 0.5
 0

 0.5

Queries with errors
Queries with no errors

 1.5

 1
 3.5
Record Number (million)

 2.5

 2

 3

 4

(b) Single Keyword

 50

 40

 30

 20

 10

)
s
m

(
 

i

 

e
m
T
h
c
r
a
e
S
g
v
A

 

 0

 0.5

 2

 2.5

 1.5

 1
 3.5
Record Number (million)
(c) Multiple Keywords

 3

 4

Figure 11: Scalability (MEDLINE).

We measured the query performance as the data size in-
creased. We ﬁrst evaluated queries with a single keyword.
We considered two types of queries: the ﬁrst type was gen-
erated by randomly selecting keywords in the data set; the
second type was obtained by modifying the ﬁrst type by
adding edit errors (0 to 2). Each query asked for the 10 best
records. For each type, we measured the query response time
for each keystroke. Figure 11(b) shows the results for the
MEDLINE data set as we increased the number of records.
It shows that the algorithms can answer a single-keyword
query eﬃciently (within 3 ms), for both types of queries.

We next evaluated the algorithms for queries with multi-
ple keywords, which asked for 10 best records. We gener-
ated queries with two keywords, and measured the average

WWW 2009 MADRID!Track: Search / Session: Search UI379query time of each keystroke on the second keyword. Fig-
ure 11(c) shows that our algorithms can process such queries
very eﬃciently. For instance, when the data set had 4 mil-
lion records, a query without errors was processed within 20
ms, while a query with errors was answered within 55 ms.
6.5 Round-Trip Time

The round-trip time of interactive fuzzy search consists
of three components: server processing time, network time,
and JavaScript running time. Diﬀerent locations in the
world could have diﬀerent network delays to our servers in
southern California. We measured the time cost for a sample
query “divsh srivstava search” on the DBLP prototype
from ﬁve locations around the world: US west, US east,
China, Israel, and Australia. Figure 12 shows the results.
We can see that the server running time was less than 1/5 of
the total round-trip time. JavaScript took around 40 to 60
ms to execute. The relative low speed at some locations was
mainly due to the network delay. For example, it took about
4/5 of the total round-trip time when our system was tested
from China. For all the users from diﬀerent locations, the
total round-trip time for a query was always below 300 ms,
and all of them experienced an interactive interface. For
large-scale systems processing queries from diﬀerent coun-
tries, we can solve the possible network-delay problem by
using distributed servers.

)
s
m

(
 

i

 

e
m
T
p
i
r
T
-
d
n
u
o
R

Network
Javascript
Server

 300

 200

 100

 0
US/West US/East China

Israel Australia

Location

Figure 12: Round-trip time for diﬀerent locations.

6.6 Saved Typing Effort

Interactive search can also save user typing eﬀorts, since
results can be found before the user types in complete key-
words. To evaluate the saving of typing eﬀort, we con-
structed six queries on the DBLP data set as shown in Ta-
ble 3. The keywords in italic font are mistyped keywords.
Each query was typed in letter by letter, until the system
found the expected records. We measured how much letter-
typing eﬀort the system can save for the user. For each
query Qi, let N (Qi) be the number of letters the user typed
before the relevant answers are found. We use 1 − N(Qi)
|Qi|
to
quantify the relative saved eﬀort. For example, for query
Q6, the user could ﬁnd relevant answers right after typing
in “divsh sri sea”. The saved eﬀort of Q6 is 1− 13
22 = 41%,
as the user only needed to type in 13 letters, instead of 22
letters in the full query. Table 3 shows that this paradigm
can save the user 40% to 60% typing eﬀort on average.

7. CONCLUSIONS

We studied a new information-access paradigm that sup-
ports interactive, fuzzy search. We proposed an eﬃcient in-
cremental algorithm to answer single-keyword fuzzy queries.

Table 3: Queries and saved typing eﬀort.

Query

Saved typing eﬀort

sunta sarawgi

surajit chuardhuri

nick kodas approxmate

flostsos icde similarity

similarty search icde
divsh srivstava search

42%
50%
41%
38%
55%
41%

ID
Q1
Q2
Q3
Q4
Q5
Q6

We studied various algorithms for computing the answers to
a query with multiple keywords that are treated as fuzzy,
preﬁx conditions. We developed eﬃcient algorithms for in-
crementally computing answers to queries by using cached
results of previous queries in order to achieve an interactive
speed on large data sets. We studied several useful features
such as ranking answers, highlighting results, and utilizing
synonyms. We deployed several real systems to test the
techniques, and conducted an thorough experimental study
of the algorithms. The results proved the practicality of this
new computing paradigm.

8. REFERENCES
[1] A. Arasu, V. Ganti, and R. Kaushik. Eﬃcient exact
set-similarity joins. In VLDB, pages 918–929, 2006.

[2] H. Bast, A. Chitea, F. M. Suchanek, and I. Weber. Ester:

eﬃcient search on text, entities, and relations. In SIGIR, pages
671–678, 2007.

[3] H. Bast, C. W. Mortensen, and I. Weber. Output-sensitive

autocompletion search. In SPIRE, pages 150–162, 2006.

[4] H. Bast and I. Weber. Type less, ﬁnd more: fast autocompletion

search with a succinct index. In SIGIR, pages 364–371, 2006.

[5] H. Bast and I. Weber. The completesearch engine: Interactive,

eﬃcient, and towards ir& db integration. In CIDR, pages
88–95, 2007.

[6] A. Behm, S. Ji, C. Li, and J. Lu. Space-constrained gram-based
indexing for eﬃcient approximate string search. In ICDE, 2009.

[7] K. Chakrabarti, S. Chaudhuri, V. Ganti, and D. Xin. An

eﬃcient ﬁlter for approximate membership checking. In
SIGMOD Conference, pages 805–818, 2008.

[8] S. Chaudhuri, V. Ganti, and R. Motwani. Robust identiﬁcation

of fuzzy duplicates. In ICDE, pages 865–876, 2005.

[9] K. Grabski and T. Scheﬀer. Sentence completion. In SIGIR,

pages 433–439, 2004.

[10] M. Hadjieleftheriou, A. Chandel, N. Koudas, and D. Srivastava.
Fast indexes and algorithms for set similarity selection queries.
In ICDE, pages 267–276, 2008.

[11] L. Jin, N. Koudas, C. Li, and A. K. H. Tung. Indexing mixed

types for approximate retrieval. In VLDB, pages 793–804, 2005.

[12] L. Jin and C. Li. Selectivity estimation for fuzzy string

predicates in large data sets. In VLDB, pages 397–408, 2005.

[13] N. Koudas, C. Li, A. K. H. Tung, and R. Vernica. Relaxing join

and selection queries. In VLDB, pages 199–210, 2006.

[14] K. Kukich. Techniques for automatically correcting words in

text. ACM Comput. Surv., 24(4):377–439, 1992.

[15] C. Li, J. Lu, and Y. Lu. Eﬃcient merging and ﬁltering

algorithms for approximate string searches. In ICDE, pages
257–266, 2008.

[16] C. Li, B. Wang, and X. Yang. VGRAM: Improving performance

of approximate queries on string collections using
variable-length grams. In VLDB, pages 303–314, 2007.

[17] H. Motoda and K. Yoshida. Machine learning techniques to

make computers easier to use. Artif. Intell., 103(1-2):295–321,
1998.

[18] A. Nandi and H. V. Jagadish. Eﬀective phrase prediction. In

VLDB, pages 219–230, 2007.

[19] H. E. Williams, J. Zobel, and D. Bahle. Fast phrase querying

with combined indexes. ACM Trans. Inf. Syst., 22(4):573–594,
2004.

[20] C. Xiao, W. Wang, X. Lin, and J. X. Yu. Eﬃcient similarity
joins for near duplicate detection. In WWW, pages 131–140,
2008.

WWW 2009 MADRID!Track: Search / Session: Search UI380