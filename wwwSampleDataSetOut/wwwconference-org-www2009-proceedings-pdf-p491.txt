A Search-based Method for

Forecasting Ad Impression in Contextual Advertising

Xuerui Wang

University of Massachusetts
xuerui@cs.umass.edu

Amherst, MA

Andrei Broder
Yahoo! Research
Santa Clara, CA

broder@yahoo-inc.com

Marcus Fontoura
Yahoo! Research
Santa Clara, CA

marcusf@yahoo-inc.com

Vanja Josifovski
Yahoo! Research
Santa Clara, CA

vanjaj@yahoo-inc.com

ABSTRACT
Contextual advertising (also called content match) refers to
the placement of small textual ads within the content of
a generic web page. It has become a signiﬁcant source of
revenue for publishers ranging from individual bloggers to
major newspapers. At the same time it is an important
way for advertisers to reach their intended audience. This
reach depends on the total number of exposures of the ad
(impressions) and its click-through-rate (CTR) that can be
viewed as the probability of an end-user clicking on the ad
when shown. These two orthogonal, critical factors are both
diﬃcult to estimate and even individually can still be very
informative and useful in planning and budgeting advertis-
ing campaigns.

In this paper, we address the problem of forecasting the
number of impressions for new or changed ads in the system.
Producing such forecasts, even within large margins of error,
is quite challenging: 1) ad selection in contextual advertising
is a complicated process based on tens or even hundreds of
page and ad features; 2) the publishers’ content and traﬃc
vary over time; and 3) the scale of the problem is daunting:
over a course of a week it involves billions of impressions,
hundreds of millions of distinct pages, hundreds of millions
of ads, and varying bids of other competing advertisers. We
tackle these complexities by simulating the presence of a
given ad with its associated bid over weeks of historical data.
We obtain an impression estimate by counting how many
times the ad would have been displayed if it were in the
system over that period of time. We estimate this count
by an eﬃcient two-level search algorithm over the distinct
pages in the data set. Experimental results show that our
approach can accurately forecast the expected number of
impressions of contextual ads in real time. We also show
how this method can be used in tools for bid selection and
ad evaluation.

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications—
data mining; H.3.3 [Information Storage and Retrieval]:
Information Search and Retrieval
Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

General Terms
Algorithms, Experimentation, Measurement, Performance

Keywords
Online advertising, contextual advertising, content match,
impression forecasting, WAND

1.

INTRODUCTION

Web advertising has become a major industry: accord-
ing to a recent study by the Interactive Advertising Bureau
and PricewaterhouseCoopers International, online advertis-
ing spending in 2007 reached over 21 billion US dollars, an
increase of 26% from the previous year [12]. This is the ﬁrst
time that online advertising spending was larger than each
of the traditional advertising media: radio, cable and broad-
cast TV. A signiﬁcant part of this market consists of textual
ads, the ubiquitous short text messages usually marked as
“sponsored links” or similar. The main advertising channels
used to distribute textual ads are:

1. Sponsored Search (SS) or Paid Search Advertising which
consists in placing ads on the result pages from a web
search engine, with ads driven by the originating query.
All major current web search engines (Google, Yahoo!,
Microsoft, etc.) support such ads and act simultane-
ously as a search engine and an ad agency.

2. Contextual Advertising (CA) or Content Match which
refers to the placement of commercial ads within the
content of a generic web page. In contextual advertis-
ing, usually there is a commercial intermediary, called
an ad-network, in charge of optimizing the ad selection
with the twin goal of increasing revenue (shared be-
tween publisher and ad-network) and improving user
experience. Again, all major current web search en-
gines provide such ad-networking services but there
are also many smaller players.

The prevalent pricing model for textual ads is that the
advertisers pay a certain amount for every click on the ad-
vertisement (pay-per-click or PPC). There are also other
models: pay-per-impression where the advertisers pay for
the number of exposures of an ad, and pay-per-action where
the advertisers pay only if the ad leads to a sale or similar
transaction. For simplicity, in this paper, we consider only

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion491the PPC model. In this model, the total amount paid by
an advertiser (and hence the revenue of the search engine
or ad-network) is related to the total number of exposures
of the ad (impressions) and the click-through-rate (CTR)
which can be viewed as the probability that an end-user
would click on the ad when shown. Both impressions and
CTR are diﬃcult to estimate due to various factors such as
traﬃc ﬂuctuation and sparsity, but they are orthogonal. An
ad with a high CTR might not be shown enough to generate
revenue, and on the other hand, ads with low CTRs could
get tons of impressions and waste expensive traﬃc. However
any of them individually can still be very informative and
extremely useful in planning and budgeting advertising cam-
paigns. We focus on impression forecasting in this paper.

In the SS market, textual ads are characterized by bid

phrases representing those queries where the advertisers would
like to have their ads displayed. The amount paid by the
advertiser for each ad click is determined by an auction
process [7]. Very simpliﬁed, in this process each advertiser
enters a bid for the phrase of interest; the search engines
choose among the ads competing on that phrase those ads
that have high bids and high CTRs, thus attempting to
maximize the search engines’ total revenue. Of course CTR
is not known a priori; however it can be determined, e.g.,
by historical observation, or approximately estimated .

The situation is more complicated in contextual advertis-
ing. Here the bid phrase has no direct bearing on the ad
placement: the ad network has to ﬁnd ads that will have
high CTRs for the given context. Given a page, rather
than placing generic ads, it seems preferable to have ads
related to the content to match the user interest and thus to
increase the probability of clicks. This intuition is supported
by the analogy to conventional publishing where there are
very successful magazines (e.g., Vogue) where a majority
of the content is topical advertising (fashion in the case of
Vogue) and by user studies that have conﬁrmed that higher
relevance increases the number of clicks [6, 18].

The majority of the approaches proposed so far for es-
timating the relevance of a given ad to a given content,
and thus indirectly CTR, are based on the co-occurrence
of words or phrases within ads and pages [13, 16, 20] or on
a combination of semantic and syntactic factors [4].

At the core, most of these approaches can be viewed as
computing a similarity score Sima,p between a vector of
features characterizing the ad a and a vector of features
characterizing the page p. For the ad a such features could
include the bid phrase, the title words (usually displayed in
a bold font in the presentation), synonyms of these words,
the displayed abstract, the target URL, the target web site,
the semantic category, etc. Similarly, for the page p such fea-
tures might include words on page, words in title, URL, cate-
gory, synonyms, etc. In this paper, for simplicity, we assume
that given a page p and a set of available ads {a1, a2,···},
the ad network places the ads that maximize the product

Scorea,p

def= Sima,p × Bida,

(1)

where Bida is the bid amount of ad a in the PPC model. As
we discussed, note that Sima,p can be regarded roughly as an
unnormalized approximation of CTR [6, 18]. In other words,
ad placement discussed here indeed takes CTR indirectly
into consideration.

Given the model above, advertisers eager to reach as many
customers as possible, have two possibilities: they can ei-

ther craft their ads to better match more opportunities or
they can increase their bids. In either case, the advertisers
are probably interested to know what is the eﬀect of these
changes. A simple approach is to try a test ad and/or a test
bid in real traﬃc and analyze the eﬀect after a number of
days. This is of course very expensive, ineﬃcient, and has
a very long turn-around and a huge variance. The need for
forecasting is actually well recognized: existing SS systems
provide such facilities,1 but none of the available CA systems
provides forecasting, to the best of our knowledge. Such a
forecasting system has obvious applications for ad selection,
campaign budgeting, and advertising strategy.

The main goal of this paper is to propose a method to
forecast the future performance of new and modiﬁed ads
accurately, in a real-time manner, based on replaying past
impression data. The past data is composed of actual page
views with the associated ads (there are multiple ads shown
on the page). To estimate the impression count, given an ad
a and a bid Bida, we consider all content match opportuni-
ties over, say, the last four weeks, and check how often the
ad a would have been shown if it were in the system with the
given bid. That is, how often Scorea,p would have exceeded
the score of the lowest scoring ad actually shown on the page
p. The impression rate is then used in an obvious manner
to predict the impression volume over, say, the next week.

At ﬁrst blush this task seems daunting: for a real system
we would need to check billions of past CA opportunities. To
address this problem the eﬃciency of our algorithm depends
only on the number of distinct pages, which is a relatively
small number when compared to the total number of im-
presssions. Secondly, our search procedure greatly reduces
the number of pages that need to be considered for full
evaluation.

We veriﬁed our approach using a set of 700M actual CA
opportunities over around 375K distinct pages obtained from
a certain random set of hosts participating in Yahoo! ad
network. The ad database used for our experiments con-
sisted of about 10M actual ads and their bids. The ranking
function is given by Formula (1), and the similarity score
by a formula related to the approach presented in [4]. With
this data, and using a standard PC with 2GB memory, the
time required to forecast the volume of impressions for a
ﬁxed ad and a single bid is around 10 milliseconds; plotting
a curve forecasting the ad volume for 100 diﬀerent bid levels
takes less than 400 milliseconds. While it can be argued
that a real system needs to be hundreds of times larger, our
system is trivially parallelizable, and its performance de-
pends only on the number of distinct pages in the historical
data. Furthermore, as long as the page index ﬁts in memory,
the forecasting time increases very slowly—our index is less
than 10MB and thus we estimate that a single 8GB box can
handle 25 million distinct pages in 15 milliseconds. Last but
not least, infrequent pages can be ignored.

In this paper we focus on ad selection based on similarity
score. Real-world matching systems involve many ad selec-
tion mechanisms such as business rules, behavioral targeting
(diﬀerent users might get diﬀerent ads), advertiser budgets,
pricing based on a generalized second price auction, traﬃc
quality discounts, positional eﬀects (same ad exhibits diﬀer-
ent CTRs in diﬀerent positions), anti-fraud measures, and
so on. Some of these could be easily included in our model

1e.g., http://searchmarketing.yahoo.com/srch/features.php

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion492(e.g., behavioral targeting), and some can be captured in the
training data (e.g., anti-fraud measures). The approach of
replaying ads can in principle accomodate any ad selection
technique as long as we can eﬃciently invert the selection
process from selecting ads for a given page, to counting the
pages where the ad would have been shown if it were present
in the system.

2. OVERVIEW OF OUR APPROACH

Given a new ad a and a bid Bida, we consider all impres-
sions over some training period, and check how often the ad
a would have been shown if it were present in the system
with the bid. In other words we count how often Scorea,p
exceeds the score of the lowest scoring ad that the system
would assign to page p absent ad a. This minimum score is
denoted as minScorep and is discussed further below.
The abstract problem that we need to solve is as follows:
given a feature vector u, and a stream of events {Xi} each
having an associated feature vector vi and a threshold ti,
In our case, u represents
the features associated with the test ad a, vi represents the
features of the page pi, the threshold ti is minScorepi , and
(u, vi) is Scorea,pi .

we want to computeP

(u,vi)>ti

1.

In contextual advertising, the number of ads shown on a
page typically varies between 1 and 20. For a page pi, the ad
ranking system chooses the top ki ranking ads according to
Formula (1). The score of the lowest ranking ad among these
ki ads shown on pi deﬁnes minScorepi . If the test ad a would
have been available when pi was displayed, then a would
have been shown if and only if Scorea,pi > minScorepi .2
Naively, we can go over every page in the training set and we
can calculate how many times the test ad would have been
shown. Since the ad database might include hundreds of
millions of ads, and the training set possibly include billions
of impressions, linear scanning is completely impractical.

To reduce the size of the problem, we assume that Scorea,p
is constant over all occurrences of the page p. However
minScorep might vary from occurrence to occurrence be-
cause ads are continuously added and deleted from the sys-
tem and bids change as well. Assume that the page was
shown n times. There are several possible approaches to
circumventing the multiple minima problem:

1. We keep, for each page p, the distribution of minimum
scores, that is, we keep a list of minima m1 ≤ m2 ≤
··· ≤ mr and of weights 0 < w1 ≤ w2 ≤ ··· ≤ wr =
Impp, where Impp is the number of impressions of page
p . The interpretation is that there were a total of w1
occurrences of p with minScorep = m1, there were a to-
tal of w2 occurrences of p with minScorep = m1 or m2,
etc. Thus if Scorea,p falls between mj and mj+1, the
ad a would have been shown wj times.

2. We set minScorep to the median value of the minimum

ad scores for the page impressions.

3. We ignore the historical minScorep and recompute it
considering only the currently available ads and their
bids. This has the advantage that it captures the most
recent picture of the marketplace but it does not reﬂect
the historical bid variation.

2When Scorea,pi = minScorepi , which is extremely rare, we
assume the test ad would not have been shown.

Figure 1: The system architecture for forecasting
ad impressions. The part inside the dotted line runs
oﬄine and prepares the data for the online forecast-
ing. The output can be the number of forecasted
impressions or an impression vs. bid curve.

Preliminary experiments show that there is no signiﬁcant
diﬀerence between diﬀerent approaches. In our experiments,
we used the last approach, but the algorithms can be easily
modiﬁed to use approach 1 or 2.

By collapsing all occurrences of one page to one record
we achieve a huge improvement (by a factor of about 2000
in our experiments); nevertheless, even a linear scan of all
distinct pages is prohibitively time consuming. For further
improvement, we reduce this scanning process to a two-level
search process over the collection of distinct web pages.

At the ﬁrst level, an inexpensive approximate evaluation is
conducted to identify the set of pages on which the ad could
have been shown. The pages in this set are called candi-
dates. At the second level, a full evaluation is performed for
each candidate page by comparing the score of the ad being
considered against minScorep of the candidate p. If the score
is larger, then the forecast counter is increased accordingly.
Our system architecture is presented in Figure 1. The up-
per part of the picture depicts oﬄine processing that consists

Feature ExtractionInput AdFeature ExtractionIndexing EngineInverted Index of AdsInverted Index of PagesHistorical Impression DataImpp1, minScorep1p1Impp2, minScorep2p2ImppN, minScorepNPage Statistics CollectorpNOffline stepsbid valuenumber of impressionsDesign adBest Prices on DVD ...Specify bid amount OKCancelAd Impression ForecastingQueriesAdsWWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion493of analyzing the pages, building a page inverted index, and
creating a page statistics ﬁle. The page analysis module
extracts, for each page p, the features needed to compute
Sima,p. Since we are using the approach 3 above, these
features are used to obtain the top k ads from the ads cur-
rently active in the system and thus compute minScorep.
The inverted index is a mapping from features to the pages
that contain these features (a description of inverted indexes
is given in Section 3.1). The page statistics ﬁle contains, for
each page p, the number of its impressions in the training
set and minScorep.

In the online component of the system we use the inverted
page index and the page statistics ﬁle to forecast the number
of impressions of a given ad. When an advertiser submits
a new ad, we extract features from this ad and use these
features to query the page index via the two-level search
process described above. Advertisers can either provide a
bid value for the ad being tested and get back the number of
expected impressions for this speciﬁc ad/bid combination, or
they can ask for an impression vs. bid curve, as illustrated in
Figure 1. An advertiser can also use this interface to change
the wording of its ad and then check the expected number
of impressions with a diﬀerent ad description.

3. FORECASTING AD IMPRESSIONS AS

A SEARCH PROCESS

To reduce the cost of the search over the past impressions
we use a document-at-a-time (DAAT) strategy [17] and a
two-level evaluation approach. Here, we ﬁrst go over all the
web pages and identify candidates by inexpensive approx-
imate evaluation. Full evaluation is performed only over
the candidates by checking if the given test ad would have
been shown if it were present in the ad database. The check
calculates the score that the test ad would have had if it were
present in the ad database at the time of the page impres-
sion. Then the score is compared to the minimal score of the
ads actually shown on the candidate page minScorep. We
have adapted the WAND [3] procedure to avoid examining
every page in the data set.

For reference, Table 1 summarizes all the notation used in

this paper.
3.1 Background

Here we brieﬂy review some basic concepts in information

retrieval (IR) and terminology used in this paper.

Inverted Index. Most information retrieval (IR) systems
use inverted indexes as the main data structure for full-text
indexing [19]. There is a considerable body of literature on
eﬃcient ways of building inverted indexes (e.g., [1, 2, 9, 11,
15, 19]) and using them to evaluate full-text queries (e.g., [3,
14, 19]).

In this paper, we use an inverted index structure where
each occurrence of a feature f within a web page p is repre-
sented by a posting of a form hPID, wf,pi. PID is the page
identiﬁer which in this paper we assume that ranges from 1
to the number of unique pages N . wf,p is called weight and
is used to store arbitrary information about the occurrence
of f within p. The postings associated with the same feature
are grouped into a posting list. Each posting list is sorted
in increasing order of PID. Often, skip lists or B-trees [10]
are used to index the posting lists [9, 15] to allow for quick
ﬁnding of postings given a PID.

Table 1: Notation used in this paper

SYMBOL
N
pi
fj
wf,p
Impp
Sima,p
Bida
Scorea,p
maxWeightf
minScorep

DESCRIPTION
the total number of distinct web pages
the ith web page
the jth feature, such as a unigram term
the weight of feature f in page or ad p
the number of impressions of web page p
the similarity between ad a and page p
the bid amount of ad a
the ranking score for ad a on page p
the largest weight of feature f in any page
the lowest ranking score of previously
shown ads on page p

Joining Posting Lists Typically, to evaluate the query,
we need to perform a join over the pre-sorted posting lists.
One of the common approaches to performing this join is
to use a document-at-the-time (DAAT) evaluation. Most
of the DAAT algorithms in the literature are merge-joins
with improved eﬃciency [10]. To evaluate a free-text query
using a DAAT algorithm, a cursor Cf is created for each
feature f in the query, and is used to access f ’s posting
list. During the join, the cursors are moved in a coordinated
fashion forward over the posting lists. Almost all posting list
join algorithms are based on the Cf .beyond(PID p) primitive
that advances the Cf cursor to the ﬁrst posting such that
PID is greater than or equal to p, returning the PID of
the new position. If p is beyond the end of the posting list,
beyond() returns a special posting element with an identiﬁer
LastID which is the smallest integer (N + 1) larger than all
existing PIDs in the index.

Scoring. The join algorithm evaluates the query over a
subset of candidate pages by calculating the scores between
the query and the pages. The match between the query
and the page is mostly quantiﬁed by a query dependent or
dynamic score. Usually, there is also a query-independent
component which is based on the static rank of the web
page. In most IR systems, the query-dependent component
of the score follows an additive scoring model for each fea-
ture, whereas the static component can be based on the
connectivity of web pages, as in PageRank [2], or on other
factors such as source, length, creation date, etc.
In this
work, we do not use static scores for pages. The similarity
score between page p and ad a, Sima,p is decided by summing
contributions over all common features of a and p as follows:

X

f∈a∩p

Sima,p

def=

wf,a × wf,p,

(2)

where the weights wf,p and wf,a measure the importance of
the feature f on the ad and the page side correspondingly.
The features used in our implementation include tf×idf weight-
ing for unigrams, compounds based on a dictionary (e.g.,
“New York Times”) and class labels corresponding to ad and
page classiﬁcation in a commercial taxonomy of about 6000
nodes, as described in [4].
3.2 Two-Level Process

Many diﬀerent approaches have been proposed in the lit-
erature to speed up the search process [3, 8, 5], and we adopt
a two-level procedure similar to [3] here.

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion494At the ﬁrst level of the search process, we check if the ads
could be shown on the given page by comparing an upper
bound of the ad score with minScorep:

wf,a × maxWeightf > minScorep.

(3)

Bida × X

f∈a∩p

In this formula, maxWeightf represents the maximum weight
of the feature f in any page. The value of maxWeightf is
pre-calculated during index building for each feature f and
stored in the meta-data section of the posting list.

Using the maximal weights, the sum expression in For-
mula 3 is an upper bound of Sima,p. Thus, following from
the score deﬁnition in Formula 1, the left-hand side of For-
mula 3 is an upper bound of Scorea,p. Using a single value
for the page-side weights allows us to avoid accessing the
posting lists to obtain the actual weight, as described in the
following sections. The tightness of the bound depends on
the variance of the weights and impacts the ﬁltering rate at
the ﬁrst level of the search process. The ﬁrst phase ﬁltering
does not alter the ﬁnal results—we would obtain exactly the
same results even if this phase is not applied.

The pages that satisfy the ﬁrst level ﬁltering are further
evaluated at the second level. Here a full evaluation is per-
formed where instead of using maxWeightf for the page fea-
ture weights, the actual page weights are retrieved from the
index: we check if Scorea,p > minScorep, and we increase the
number of forecasted impressions for ad a if the inequality
holds.
3.3 WAND Operator

In this work we implement the two-level search process us-
ing a variation of the WAND operator [3]. WAND, stand-
ing for Weak AND, or Weighted AND, has been proposed
to eﬃciently implement the two-level search process over
large document collections. The algorithm takes as argu-
ments a list of Boolean indicator variables X1, X2,··· , Xk,
a list of associated positive weights, w1, w2,··· , wk, and a
threshold h. By deﬁnition, WAND(X1, w1,··· , Xk, wk, h)
is true iﬀ

X

1≤i≤k

Xiwi ≥ h.

h does not change at all no matter how the cursors move.
A new WAND iterator needs to be devised to accommodate
this particularity of our application.

To take advantage of the diﬀerence among lowest ranking
scores of diﬀerent pages, we index the pages in increasing
order of minScorep (i.e., pages with smaller PIDs have lower
minScorep) so that it becomes more diﬃcult to have the test
ad shown when the posting list cursors move to larger PIDs,
i.e., more pages that do not qualify Formula (3) are skipped,
as demonstrated in our experimental results (Table 4).

Figure 2 describes our implementation of the new WAND
iterator, showing the basic procedure to calculate the ex-
pected number of impressions for a test ad. The two meth-
ods in Figure 2, initializeCursors() and nextCandidate(), are
described in detail in Figure 3 and Figure 4, respectively.

nImpressions ← 0
initializeCursors() (see Figure 3)

1. Function forecastImpressions(a)
2.
3.
4. while (p ← nextCandidate() < LastID) (see Figure 4)
5.
6.
7.
8.
9.

nImpressions ← nImpressions + Impp

Calculate Sima,p by Formula (2)
if (Scorea,p > minScorep)

end while
return nImpressions

Figure 2: Main function that forecasts the number
of impressions for test ad a. The ad features are
used as a query to the inverted index of pages.

The new WAND iterator is initialized by calling the method
initializeCursors() depicted in the pseudo-code shown in Fig-
ure 3. The method receives as input the array of features
extracted for the query ad.
It sets the current web page
to be considered (currentPage) to zero and for each query
feature, f , it initializes its current posting cursor to be the
ﬁrst posting element in its posting list.

1. Function initializeCursors(features)
2.
3.
4.

currentPage ← 0
for each f ∈ features

Cf .beyond(0)

Given this setup, our preliminary evaluation in Formula

(3) consists of evaluating for each web page p

WAND(Xf1 , wf1,a × maxWeightf1 , Xf2 , wf2,a × maxWeightf2 ,

··· , Xf|a| , wf|a|,a × maxWeightf|a| ,

minScorep

Bida

),

where Xfi is an indicator variable for the presence of query
feature fi in web page p and |a| is the number of features
for ad a. If WAND evaluates to be true, then the web page
p undergoes a full evaluation.
3.4 Forecasting Ad Impressions

The original WAND iterator [3] is used to obtain a ranked
list of documents relevant to a query. To do ordinary web
search using WAND, the threshold is set dynamically to the
minimum score of the top results found so far as the cursors
of the posting lists advance.
In addition, the threshold is
ﬁxed for pages between two consecutive full evaluations.
However, in ad impression forecasting, the threshold h is
page dependent since the lowest ranking score of shown ads,
minScorep, is diﬀerent for each page and, for a given page,

Figure 3: The initializeCursors() method of the
WAND iterator

Similar to the original WAND iterator, our implementa-

tion also maintains two invariants during its execution:

1. All web pages with PID ≤ currentPage have already

been considered as candidates.

2. For any feature f , any web page containing f , with
PID < Cf .PID, has already been considered as a can-
didate.

Note that initializeCursors() establishes these invariants.

After calling initializeCursors(), the algorithm repeatedly
calls nextCandidate() to get the next candidate for full eval-
uation. The nextCandidate() method returns the next web
page whose approximate score satisﬁes Formula (3). Web
pages whose approximate scores do not satisfy Formula (3)
are skipped. Figure 4 contains the pseudo-code for nextCan-
didate(), which repeatedly advances the individual feature
cursors until it ﬁnds a candidate web page to return.

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion495repeat

1. Function nextCandidate()
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.

end repeat

else

sort(features)
pivotFeature ← ﬁndPivotFeature(features)
if (pivotFeature = null) return (LastID)
pivotPID ← CpivotF eature.PID
if (pivotPID = LastID) return (LastID)
if (pivotPID = currentPage) //pivotPID tested?
f ← pickFeature(features[1, · · · , pivotFeature])
Cf .beyond(pivotPID + 1)

if (C0.PID= pivotPID) //Formula (3) satisﬁed?

currentPage ← pivotPID
return (currentPage)
f ← pickFeature(features[1, · · · , pivotFeature])
Cf .beyond(pivotPID)

else

Figure 5: A (counter) example of randomly in-
dexed web pages ( minScorep1
minScorep2

> wf1,a×maxWeightf1 >

). The nextCandidate() method in Figure

Bida

4 would miss p2 as a valid candidate web page.

Bida

Figure 4: The nextCandidate() method of the
WAND iterator

The nextCandidate() method invokes three helper meth-
ods, sort(), ﬁndPivotFeature() and pickFeature(). The ﬁrst
helper, sort(), sorts the features in non-decreasing order
of their current PIDs.
And, ﬁndPivotFeature() returns
pivotFeature—the ﬁrst feature in the sorted order for which
the accumulated (weighted by wf,a) upper bounds of all
features preceding it, including it, exceed the corresponding
threshold, minScorep/Bida. The last helper, pickFeature(),
receives as input a set of features and selects the feature
whose cursor is to be advanced.

The nextCandidate() method ﬁrst sorts the query features
in non-decreasing order of the PID’s of their current postings
using sort(). Next, calling ﬁndPivotFeature(), it computes
the pivotFeature. If there is no such feature (meaning the
sum of all features’ (weighted by wf,a) upper bounds is less
than the threshold), the iterator stops and returns the con-
stant LastID.

Then the pivotPID variable is set to the PID correspond-
ing to the current posting of pivotFeature. If pivotPID is
equal to the PID of the last web page considered (current-
Page), WAND picks a feature preceding the pivot term and
advances its iterator past currentPage by calling pickFea-
ture() (Lines 8-10), the reason being that all web pages
preceding currentPage have already been considered (by In-
variant 1) and therefore the system should next consider a
web page with a larger PID. Note that this move preserves
Invariant 2.

We need to check whether indeed the sum of approxi-
mated contributions to pivotPID is greater than its thresh-
old. There are two cases: if the current posting PID of all
features preceding pivotFeature is equal to pivotPID, then
pivotPID contains a set of query features with an accu-
mulated (weighted by wf,a) upper bound larger than the
threshold and hence nextCandidate() sets currentPage to
pivotPID, and returns this web page as a candidate for
full evaluation (Lines 12-14). Otherwise, pivotPID might or
might not contain all the preceding features, that is, it might
or might not have enough contributions, hence WAND picks
one of these features and advances its cursor to a location
≥ pivotPID (Lines 15-17).

The nextCandidate() method also maintains Invariant 1.
Because we index web pages in increasing order of minScorep,
it is not possible for another web page whose PID is smaller

than pivotPID to be a valid candidate since pivotFeature
by deﬁnition is the ﬁrst feature in the PID order for which
the accumulated (weighted by wf,a) upper bound exceeds
the corresponding threshold. Hence, all web pages with a
smaller PID than pivotPID can only contain features which
precede pivotFeature, and the upper bound (weighted by
wf,a) on their scores are strictly less than the corresponding
threshold (otherwise we would have a diﬀerent pivotFea-
ture). It follows that nextCandidate() maintains the invari-
ant since currentPage is only advanced to pivotPID in the
cases of success, i.e., ﬁnding a new valid candidate who is
the ﬁrst in the order.

Note that if we indexed the web pages not in increasing
order of minScorep, the threshold for a page with a larger
PID could be actually smaller than the one for a page with
a smaller PID and Invariant 1 would not be held any more.
An example of randomly indexed web pages is illustrated
in Figure 5, where minScorep1
minScorep2
pivotFeature as a feature other than f1 since minScorep1
wf1,a× maxWeightf1 , and then miss p2 as a valid candidate.
4. EXPERIMENTAL RESULTS

> wf1,a × maxWeightf1 >

. The nextCandidate() method would discover

Bida

Bida

Bida

>

In this section, we discuss the experiments we conducted

to validate our approach.
4.1 Data Set

We collected two weeks of actual impression events from
a certain random set of hosts participating in Yahoo!’s ad
network, for a total of about 1.3 billion impressions. Our
evaluation uses a set of 10 million textual ads, again chosen
at random from Yahoo!’s database of ads. For each distinct
page p in the set of impressions, we counted its total number
of occurrences and determined minScorep by selecting the
best matching ads as discussed in Section 2. After feature
extraction, all the pages were indexed in an inverted ﬁle of
features—each feature being associated with a posting list
of pages where it appears.

We split the collected data set into a training set of 614
million impressions involving 318,317 distinct web pages,
obtained from August 12–18, 2007, and a testing set of 699
million impressions involving 375,507 distinct web pages,
obtained from August 19–25, 2007. Thus, in our experi-
ments we forecast one week worth of impressions based on
the previous week. Naturally, many pages appear both in
the training set and in the test set. However, due to the

Posting list of f1Posting list of f2p1p2p3Cf1Cf2PagesWWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion496Table 2: Average absolute relative error of fore-
casted impressions of a week at diﬀerent impression
levels, with the corresponding 90% conﬁdence inter-
val.

Table 3: Average absolute relative error of fore-
casted impressions of two days at diﬀerent impres-
sion levels, with the corresponding 90% conﬁdence
interval.

#Impressions
0-2000
2001-5000
5001-10000
10001-20000
20001-50000
50001-100000
100001-200000
200001-500000
500001-1000000
1000001-10000000

#Ads
2307
759
768
406
708
287
186
185
102
156

Error

90% Interval

26364.2% [-100%,1e5%]
157.7% [-100%,498%]
69.7% [-99.7%,196%]
61.0% [-79.7%,156%]
54.6% [-60.4%,140%]
48.0% [-54.5%,112%]
32.0% [-62.6%,69.8%]
32.8% [-60.3%,75.4%]
28.6% [-53.3%,55.4%]
15.7% [-31.3%,28.8%]

#Impressions
0-2000
2001-5000
5001-10000
10001-20000
20001-50000
50001-100000
100001-200000
200001-500000
500001-1000000
1000001-10000000

#Ads
3522
664
417
501
288
137
133
102
54
46

Error

90% Interval

26212.6% [-100%,600%]
117.3% [-99.9%,196%]
108.1% [-75.8%,121%]
58.3% [-71.1%,228%]
68.3% [-87.2%,174%]
81.7% [-65.5%,126%]
60.3% [-92.4%,91.7%]
50.1% [-64.5%,117%]
27.1% [-46.5%,41.8%]
23.2% [-20.3%,41.0%]

dynamic nature of the Web and to traﬃc variations, the
sets are not identical and they diﬀer both with respect to
composition and to impression counts.

We evaluated our system by randomly picking approxi-
mately 6000 sample test ads. To evaluate the system on
both new ads and existing ads we picked half of the sam-
ple from the 10 million set used in the training stage and
the other half from another, disjoint set of ads. Note that
estimating volumes for ads not previously seen is not more
diﬃcult than estimating existing ads. Preliminary results on
new and existing ads separately do not show any signiﬁcant
diﬀerence, and we report the results on the mixed ads.
4.2 Effectiveness

To demonstrate the eﬀectiveness of our approach, we com-
pare the forecasted impressions based on the training set
with the actual impressions from the test set. We split the
test ads according to the forecasted impression level and
report the number of sample ads at that level, the average
absolute relative error and the corresponding 90% conﬁdence
interval in Table 2. The relative error is deﬁned as
#Actual − #Forecasted

Relative Error =

#Forecasted

,

and the 90% interval is a range such that 90% of the test ads
have a relative error in that range. (We remark in passing,
that, not unexpectedly, the distribution of impressions at
various levels seems to follow roughly a power law.) The
average absolute relative error becomes smaller when the
number of impressions becomes larger, and the conﬁdence
interval becomes tighter.

At the ﬁrst glance, the errors in Table 2 seem big. How-
ever, ﬁrst of all, when the traﬃc in the training set is iden-
tical to the test set, our method gives correct forecasting
without any error. The errors come from traﬃc ﬂuctuation.
We conjecture that with larger periods, better forecasting
could be obtained, due to less traﬃc ﬂuctuation. Second,
producing this forecast, even within large margins of error
(which is acceptable in campaign budgeting and advertising
strategy), is extremely challenging, and there is no previ-
ously published work reporting results close to ours, to the
best of our knowledge. Third, one might argue that our
method is only accurate for a small fraction of ads, the ones
with highest volume which could be accurately estimated
oﬀ-line and cached. But this is only true when the bids
of those ads are ﬁxed. When the bids change signiﬁcantly,

their volume would change dramatically as well. It is very
common and vitally important for advertisers to optimize
their investment by exploring the most cost-eﬀective bids
via methods like ours.

There is a general belief that it is easier to forecast long-
term traﬃc rather than short-term traﬃc. For comparison,
we show the similar results for a two day forecast in Table
3. The error indeed seem somewhat larger for short-term
forecasting.

As we discussed earlier, our approach is also able to present
advertisers with an impression volume vs. bid curve to help
them make the most cost-eﬀective decision on bids. To this
end, note that we do not need to evaluate the same test
ad repeatedly with diﬀerent bid levels — instead we can
evaluate the test ad once as follows: for each page, we get
the minimum bid that would ensure that the test ad will
be shown. We then compare these minimum bids against
diﬀerent bid levels to collect the forecasted impressions in
a more eﬃcient way. Several randomly selected examples
of such curves (with comparison to the actual impression
curves) are shown in Figure 6. Note that, as expected, the
number of impressions increases monotonically as advertis-
ers bid higher.

In Figure 6, the top row curves demonstrate that our
approach can forecast impressions accurately for diﬀerent
shapes of curves. The curves at the bottom do not match the
actual impression curves very well due to page traﬃc ﬂuctu-
ation, but share roughly the same trend or shape with the
actual curves. Therefore, these curves are still very valuable
in assisting advertisers to make cost-eﬀective decisions, e.g.,
one advertiser might prefer to invest in an ad with a smooth
bid curve, while another advertiser might prefer to bid above
a “cliﬀ” that would keep the competition away. When all
the advertisers make reasonable cost-eﬀective decisions, the
traﬃc in ad servers could be better utilized and lead to more
revenue at the end.
4.3 Efﬁciency

In order to ﬁne-tune their bids and check the impact of
wording changes, advertisers need real-time feedback.
In
our experiments, our approach is demonstrated to respond
in sub-seconds. On an Intel Xeon 3GHz PC with 2GB RAM,
with the inverted page index and the page statistics ﬁle kept
in memory, the average evaluation time for a (test ad, bid)
pair is 10.1 milliseconds and we require 377.1 milliseconds
for curve plotting with 100 diﬀerent bid levels.

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion497Figure 6: The number of impression vs. bid curves (solid) of several test ads, with comparison to the actual
impression curves (dashed). These curves are randomly selected from our test ads and arranged into two
rows. The top row curves demonstrate that our approach can forecast impressions accurately. The curves at
the bottom do not match the actual impressions very well due to page traﬃc ﬂuctuation, but share roughly
the same trend or shape with the actual impression curves. Thus, these curves are still very valuable to assist
advertisers to make cost-eﬀective decisions on bids.

In Section 3, we claimed that our search skips more and
more web pages as the posting list cursors advance, due to
our storing of pages in increasing order of minScorep. We
numerically evaluate the skipping behavior here. The skip-
ping distance is deﬁned as the diﬀerence of PIDs of two web
pages that are consecutively fully evaluated, or the diﬀerence
between LastID and the PID of the last fully evaluated web
page. For each test ad, we calculate average relative skipping
distance with respect to the average skipping distance in the
ﬁrst decile of the web page index we have built. We report
the mean of these statistics over all test ads for diﬀerent
deciles in Table 4, in which the skips are signiﬁcantly larger
as the cursors move towards larger PIDs. In other words, we
process the last 10% of the index at rate 3000 faster than the
ﬁrst 10%, which means that, as long as the page index ﬁts
in memory, the forecasting time increases very slowly—our
index is less than 10MB and thus we estimate that a single
8GB box can handle 25 million pages in 15 milliseconds.

4.4 Effectiveness vs. Efﬁciency Tradeoff

The usage of the upper bounds of page-to-ad scores guar-
antees that the proposed algorithm will ﬁnd the precise
count of pages p such that minScorep < Scorea,p.
In our
applications, due to traﬃc variations, precise counts are not
practically usable. In this section we explore if we can trade
count precision for better evaluation performance.

The performance of the two-level process depends on the
tightness of the upper-bounds in the page-to-ad score es-

Table 4: Mean average normalized skipping distance
with respect to the average skipping distance in the
ﬁrst decile of the web page inverted index.

Skips
Decile
1.00
0%-10%
15.93
10%-20%
32.54
20%-30%
41.48
30%-40%
60.35
40%-50%
110.23
50%-60%
252.97
60%-70%
297.68
70%-80%
80%-90%
616.31
90%-100% 3084.45

timation. This in turn depends on how well maxWeightf
bounds the weight of an index posting during the scoring.
Since maxWeightf is the maximum weight in the posting
list, in a case of a skewed weight distribution, few postings
with relatively higher weights can result in loose bounds and
many unnecessary candidates passing the ﬁlter of the ﬁrst
phase.

To shrink the subset of web pages that are passed to full
evaluation, we can enforce a stricter ﬁrst level ﬁltering at
the price of allowing a few true candidates to be ﬁltered
out. This would be acceptable in our application as long as

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion498Figure 7: (Eﬃciency) The average percentage de-
crease (with respect to θ = 1) in number of full
evaluations vs. θ, with unit standard deviation bars.
The number of full evaluations decreases quickly as
the value of θ increases.

Figure 8: (Accuracy) The average percentage de-
crease (with respect to θ = 1) in number of fore-
casted impressions vs.
θ, with unit standard de-
viation bars. The forecasted impressions decrease
quickly as the value of θ increases.

the overall forecasting quality does not decrease signiﬁcantly.
One way to achieve this eﬀect is to introduce an adjusting
factor θ ≥ 1 to oﬀset the overestimation of maxWeightf ,
and update Formula (3) as

wf,a × maxWeightf > θ × minScorep,

(4)

Bida × X

f∈a∩p

The term θ is related to how much increase in the forecasting
error we can tolerate. When θ = 1, Formula (4) becomes
Formula (3). If we increase the value of θ, we get a smaller
candidate pool in the second phase. Simultaneously we may
miss more web pages on which the test ad could actually
have been shown. In other words, stricter ﬁltering (larger θ)
leads to less accurate estimation but faster response. There-
fore, the selection of the value of θ is indeed a tradeoﬀ be-
tween accuracy and eﬃciency, as demonstrated in Figure 7
and Figure 8. As θ increases, the number of full evaluations
decreases, so does the forecasted impressions. A relatively
smooth curve could be ﬁt for both Figure 7 and Figure 8.
Note that even with this lossy estimation, our system is still
capable to suggest bids since it captures the general trends
over bid value reasonably well.
4.5 Evaluating Ads

To further demonstrate how our system can be used as
a tool for advertisers to design and manage new ads, we
manually created several ads with subtle diﬀerences3, shown
in Table 5 with their corresponding forecasted impressions.
The other attributes of all the ads in Table 5 are identical,
for example, they use the same description and have the
same landing page (same URLs) and same bid amount.

As we can see, although most of the attributes are iden-
tical, the subtle diﬀerences make a big impact in number of
impressions. It is interesting to see that the usage of terms
like “cheap” and “free” reduces the number of forecasted
impressions: the underlying system correctly predicts that

3We could have used real ads for this experiment, but for
privacy and copyright issues, we would not have been able
to show the ad contents and their diﬀerences.

such ads have lower CTRs and hence their score is adjusted
downward, that is Sima,p becomes lower for all pages.

5. RELATED WORK

Current ad networks do have certain forecasting function-
alities, however, unfortunately, they are not publicly acces-
sible. One simple approach to estimating ad impressions is
to run real systems with the test ads for a while to get the
estimate of their performance. However, the running cost
in ad servers is prohibitive, and running free test ads for
a long time to alleviate sparseness is ﬁnancially infeasible.
Furthermore, in this naive way, advertisers have to wait a
long while to get performance report of their test ads.

Another alternative to the replaying approach presented
in the paper is to estimate the impressions of a new ad
based on the impressions of the ads currently in the system.
A machine learning framework can be built that extracts
features from the ads and predicts the impressions based on
ads that are similar to the test ad. While we have found
no prior work on impression forecasting using this method,
we believe the search based method presented in this paper
has two main advantages. First, in the method proposed in
this paper we use an ad-to-page matching that is the same
as with the ad selection. The complexity of the ad selection
mechanism can be diﬃcult to capture by a machine learning
model over the ad features. Second, an ad-to-ad comparison
introduces an indirection in the data use, as the ad selection
is performed between ads and pages. This additional step
might introduce noise in the prediction, e.g., considering the
extreme case: when the traﬃc in the future is identical to
the past, search-based methods will give exact number of
impressions without any error, and learning-based methods
will highly possibly give noisy predictions.

6. CONCLUSIONS AND DISCUSSIONS

We presented a search-based method for ad impression
forecasting of new ads (or old ads with new bids) in contex-
tual advertising. The salient feature of our approach is that
it replays the ad selection process over a log of past page

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion499Table 5: Several manually created DVD ads have very subtle diﬀerence in content (the other ad attributes
not shown below are the same for all four ads), but the impressions of the ads diﬀer a lot.

Ads Titles

Bid Phrases # of Impressions
1,905,455
cheap DVDs
2,398,928
1,638,735
2,423,988

free DVDs
DVD

1
2
3
4

Buy cheap DVDs
Buy great DVDs at low price DVD
Free DVDs
DVDs for less

impressions and counts how many times the new ad would
have been shown if it were present in the system. In this way,
during forecasting, we can employ exactly the same page-to-
ad scoring as during ad serving. Ad selection is usually done
based on complicated, highly tuned formulae. The proposed
approach enables us to factor the scoring into the forecasting
process as a black-box.

To make the search feasible, we ﬁrst reduce the search over
the past page impressions into a search over the unique web
pages in those impressions. Then we search the space of web
pages using a two-level search process: at the ﬁrst level an
inexpensive approximate evaluation is performed to identify
candidate web pages on which a test ad could possibly have
been shown; at the second level the candidates are fully
evaluated and their contributions are counted.

Experimentally, we demonstrate that our approach can
accurately forecast impressions of ads in the higher range of
views per day. As such, it can be used by mid-size and
large advertisers that run campaigns with millions of ad
views per day. Besides forecasting impression counts, the
approach proposed in this paper can also be used for bid
suggestion, and ad evaluation.
In our current work, we
are exploring how to improve our estimates by combining
machine learning-based methods.

7. REFERENCES
[1] R. Baeza-Yates and B. Ribeiro-Neto. Modern
Information Retrieval. Addison Wesley, 1999.

[2] S. Brin and L. Page. The anatomy of a large-scale

hypertextual Web search engine. Computer Networks,
30(1-7):107–117, 1998.

[3] A. Broder, D. Carmel, M. Herscovici, A. Soﬀer, and
J. Zien. Eﬃcient query evaluation using a two-level
retrieval process. In Proceedings of the 12th
International Conference on Information and
Knowledge Management, pages 426–434, 2003.

[4] A. Broder, M. Fontoura, V. Josifovski, and L. Riedel.

A semantic approach to contextual advertising. In
Proceedings of the 30th Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval, pages 559–566, 2007.

[5] D. Carmel, D. Cohen, R. Fagin, E. Farchi,

M. Herscovici, Y. Maarek, and A. Soﬀer. Static index
pruning for information retrieval systems, 2001.
[6] P. Chatterjee, D. L. Hoﬀman, and T. P. Novak.

Modeling the clickstream: Implications for web-based
advertising eﬀorts. Marketing Science, 22(4):520–541,
2003.

[7] B. Edelman, M. Ostrovsky, and M. Schwarz. Internet
advertising and the generalized second price auction:
Selling billions of dollars worth of keywords. American
Economic Review, 97(1):242–259, 2007.

[8] R. Fagin, A. Lotem, and M. Naor. Optimal

aggregation algorithms for middleware. Journal of
Computer and System Sciences, 66(4):614–656, 2003.

[9] M. Fontoura, E. J. Shekita, J. Y. Zien,

S. Rajagopalan, and A. Neumann. High performance
index build algorithms for intranet search engines. In
Proceedings of the 30th Very Large Data Bases
Conference, pages 1158–1169, 2004.

[10] H. Garcia-Molina, J. Ullman, and J. Widom. Database

System Implementation. Prentice Hall, 2000.

[11] S. Heinz and J. Zobel. Eﬃcient single-pass index

construction for text databases. Journal of the
American Society for Information Science and
Technology, 54(8):713–729, 2003.

[12] Interactive Advertising Bureau. Internet advertising
revenue top $21 billion in ’07, reaching record high.
http://www.iab.net/insights research/iab news article/
299656?o12499=, May 2008.

[13] A. Lacerda, M. Cristo, M. A. G., W. Fan, N. Ziviani,

and B. Ribeiro-Neto. Learning to advertise. In
Proceedings of the 29th Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval, pages 549–556, 2006.

[14] X. Long and T. Suel. Optimized query execution in

large search engines with global page ordering. In
Proceedings of the 29th Very Large Data Bases
Conference, pages 129–140, 2003.

[15] S. Melnik, S. Raghavan, B. Yang, and

H. Garcia-Molina. Building a distributed full-text
index for the web. ACM Transactions on Information
Systems, 19(3):217–241, 2001.

[16] B. Ribeiro-Neto, M. Cristo, P. B. Golgher, and E. S.

de Moura. Impedance coupling in content-targeted
advertising. In Proceedings of the 28th Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, pages
496–503, 2005.

[17] H. Turtle and J. Flood. Query evaluation: Strategies

and optimizations. Information Processing and
Management, 31(6):831–850, 1995.

[18] C. Wang, P. Zhang, R. Choi, and M. D. Eredita.

Understanding consumers attitude toward advertising.
In Proceedings of the 8th Americas Conference on
Information System, pages 1143–1148, 2002.
[19] I. Witten, A. Moﬀat, and T. Bell. Managing

Gigabytes. Morgan Kaufmann, 1999.

[20] W. Yih, J. Goodman, and V. R. Carvalho. Finding

advertising keywords on web pages. In Proceedings of
the 15th International World Wide Web Conference,
pages 213–222, 2006.

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion500