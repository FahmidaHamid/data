Online Expansion of Rare Queries for Sponsored Search

Andrei Broder, Peter Ciccolo, Evgeniy Gabrilovich,

Vanja Josifovski, Donald Metzler, Lance Riedel, Jeffrey Yuan

Yahoo! Research

{broder,ciccolo,gabr,vanjaj,metzler,riedell,yuanjef}@yahoo-inc.com

2821 Mission College Blvd.

Santa Clara, CA 95054

ABSTRACT
Sponsored search systems are tasked with matching queries
to relevant advertisements. The current state-of-the-art mat-
ching algorithms expand the user’s query using a variety
of external resources, such as Web search results. While
these expansion-based algorithms are highly eﬀective, they
are largely ineﬃcient and cannot be applied in real-time.
In practice, such algorithms are applied oﬄine to popular
queries, with the results of the expensive operations cached
for fast access at query time. In this paper, we describe an
eﬃcient and eﬀective approach for matching ads against rare
queries that were not processed oﬄine. The approach builds
an expanded query representation by leveraging oﬄine pro-
cessing done for related popular queries. Our experimental
results show that our approach signiﬁcantly improves the
eﬀectiveness of advertising on rare queries with only a neg-
ligible increase in computational cost.

Categories and Subject Descriptors
H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval

General Terms
Algorithms, Experimentation

Keywords
sponsored search, query expansion, tail queries

1.

INTRODUCTION

Search engines provide a gateway to the Web for most In-
ternet users. They also support the Web ecosystem by pro-
viding much needed traﬃc to many Web sites. Each query
submitted to a commercial search engine results into two
searches. The ﬁrst search is over the corpus of Web pages
crawled by the search engine. The Web crawl performed by
the search engine can be viewed as a pull mechanism used
to obtain documents. The second search is over the corpus
of advertisements provided to the search engine through an
interface or a feed from advertisers. We can view this as a
search over pushed content. The ad search provides traﬃc
to (mostly) commercial Web sites that might otherwise not
show up in the top Web search results for the query. Since
Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

advertisers pay for the placement of their ads on the result
page, the search of the ad space is commonly called spon-
sored search. The two main scenarios of sponsored search
advertising are exact match, where advertisers specify the
exact query (bid phrase) for which the ad is to be shown,
and broad match where queries are matched against ads us-
ing a broader criterion. This typically includes matching the
query against the ad text, target Web site (landing page),
or other information related to the user, ad, or advertiser.

It is a well known fact that the volume distribution of Web
search queries follows the power law [28]. The most frequent
queries compose the head and torso of the curve, while the
low volume, rarer queries make up the tail of the curve.
While individually rare, tail queries make up a signiﬁcant
portion of the query volume. For this reason, tail queries
have signiﬁcant potential for advertising revenue.

Web search engines return results for most queries, in-
cluding those in the tail of the curve. However, this is not
the case for sponsored search. Our evaluation of two major
search engines has shown that only about 30%-40% of the
query volume is covered by ad results. The main reason for
this is that tail queries are harder to interpret. In most cases
there are no ads that are explicitly associated with them by
advertisers who speciﬁcally bid on the query. Furthermore,
ad matching based on analyzing historical click data is also
diﬃcult, since due to the low volume it is harder to accumu-
late enough ad clicks to use statistical and explore-exploit
methods to identify good ads. Search engines normally avoid
displaying irrelevant ads in order not to degrade user expe-
rience [30], and so the current practice is not to advertise on
most of the tail queries.

In this paper we propose a method for online rewriting
of tail queries for sponsored search. In our system, we pre-
process a large number of head and torso queries oﬄine by
expanding them with features extracted from Web search
results and store the results in a lookup table. We have
shown in our previous work that such expanded queries can
be eﬀectively be used to produce query rewrites for broad
match [5]. At runtime, we look queries up in the table,
and if the query is present, we use the expanded query to
search the ad space. While this approach is eﬃcient for head
and torso queries, tail queries are too rare and cannot be
expanded ahead of time. Expanding them online with Web
results would require the sponsored search to wait for the
Web search to ﬁnish prior to performing ad selection, which
in many cases would result in unacceptable latency. To solve
this problem, we use the data of the pre-processed queries in
a diﬀerent way. Instead of an exact match lookup, we build

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion511an inverted index of the expanded query vectors, where each
‘document’ represents a query and its features. At runtime,
when the direct lookup into the query table fails, we use
the inverted index to perform a similarity search between
the user’s query and the pre-processed queries. We then
use the features of the top-k most similar queries returned
by this procedure to construct an enriched query, which is
subsequently used to search over the ad space.

Although our primary focus is sponsored search, our pro-
posed approach is rather general. Indeed, the method can
easily be applied to a variety of other search tasks that re-
quire expanding rare queries with external knowledge to im-
prove textual matching by overcoming the vocabulary mis-
match problem. Other potential applications include web
search, enterprise search, and social media search.

The primary contributions of this paper are fourfold. First,
we present an eﬃcient online query expansion approach for
tail queries. Second, we describe a novel approach for di-
rectly indexing query expansions for fast computation of
query-to-query similarity. Third, we propose a formalism for
expanding queries with features derived from pre-expanded
related queries. Finally, we describe a ranking and scor-
ing method that adapts standard information retrieval tech-
niques to the structure of the ads by modifying a unit of
retrieval.

The remainder of this paper is laid out as follows. We be-
gin with an introduction to sponsored search in Section 2 and
describe related work in Section 3. Next, Section 4 explains
the general architecture of our system and its various com-
ponents. In Section 5 we describe our online ad matching
algorithm that leverages oﬄine processing. Section 6 details
our empirical evaluation over a large sponsored search data
set. Finally, Section 7 concludes the paper.

2. BACKGROUND: TEXTUAL ADVERTIS-

ING ON THE WEB

Textual ads, which are the ubiquitous short text mes-
sages typically marked as “sponsored links”, make up a large
portion of the Web advertising market. Such ads are com-
monly distributed through one of the following two adver-
tising channels:

1. Sponsored Search or Paid Search Advertising places ads
on the search result pages of a Web search engine, with
ads being targeted to a user’s query. All major Web
search engines support sponsored search, thereby act-
ing both as a Web search engine and an ad search
engine.

2. Content Match or Contextual Advertising places com-
mercial ads on Web pages. Nearly all of the for-proﬁt
non-transactional Web sites rely, at least to some ex-
tent, on revenue from contextual advertising. Content
match supports a wide range of Web sites, ranging
from individual bloggers and small niche communities
to large publishers such as major newspapers.

The primary focus of this paper is sponsored search, which

is an interplay of the following three entities:

1. Advertisers supply the textual ads. The activity
of the advertisers is typically organized around cam-
paigns, which are a set of ads with a speciﬁc temporal
and thematic goal (e.g., sale of vacation packages dur-
ing peak vacation times). The goal of the advertisers,

as with traditional advertising, can broadly be deﬁned
as promotion of products or services.

2. Search engines provide “real estate” for placing ads
(i.e., space on search result pages). The goal of the
search engine is to select ads that are relevant to the
user’s query.

3. Users interact with the advertisements. Typical in-
teractions include viewing, and potentially, clicking on
advertisements. Clicks typically result in the user be-
ing redirected to the Web pages of the advertiser.

Sponsored search is usually used as a form of direct mar-
keting, as opposed to brand advertising that seeks to promote
brand awareness in general. Direct marketing advertising
aims for a “direct response,” where the eﬀect of a campaign
can be measured by the user reaction, which may include
purchasing advertised goods and services. One of the ad-
vantages of online advertising, compared to traditional me-
dia, is that it is relatively easy to measure user response.
The desired reaction to a sponsored search advertisement is
for the user to click on the ad and follow the link to the
advertiser’s Web site.

When a user clicks an ad, the advertiser pays a certain
amount of money. This is known as the pay-per-click or PPC
pricing model. Other pricing models exist, including pay-
per-impression, where an advertiser pays every time their
ad is displayed, and pay-per-action, where advertisers only
pay if the ad results in a sale or similar type of transaction.
Throughout the remainder of this paper we will assume a
PPC model, although the pricing model does not directly
eﬀect the usefulness of our underlying model.

The amount paid by the advertiser for each click is typ-
ically determined by an auction process [11]. Advertisers
place bids on a search phrase, and their position on the
search result page is determined by their own bid as well as
the bids of other advertisers. Each sponsored search ad has
one or more bid phrases associated with it. In addition to
bid phrases, ads also have a title usually displayed in bold
font, and an abstract or creative, which is the few lines of
text, usually shorter than 120 characters, displayed on the
page. Each ad also contains a URL to the advertised Web
page, which is called the landing page.

The set of all the ads available in the system can be
viewed as structured hierarchically. Each advertiser has one
or more accounts, which in turn have several ad campaigns
that usually aggregate ads in the same promotional cam-
paign. Each campaign may have several ad groups, which
cluster a smaller number of similar ads. Each ad group is
composed of an ad creative, which is the visible part of the
ad displayed to the user, and of one or more bid phrases
associated with the ad.

Bid phrases serve two purposes. First, they explicitly
specify queries that the ad should be displayed for. Second,
they put a price tag on a click event. These price tags could
be diﬀerent for diﬀerent queries. For example, a contractor
advertising his services on the Internet may be willing to pay
very little when his ads are clicked from general queries such
as “remodeling”. However, the contractor may be willing to
pay more for focused queries such as “hardwood ﬂoors” or
“laminate ﬂooring”. Ads are most often shown for queries
that are listed among the bid phrases for the ad, thus result-
ing in an exact match between the query and the bid phrase.
However, it might be diﬃcult, or even impossible, for the
advertiser to explicitly list all the relevant queries ahead of

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion512time. For this reason, search engines also have the ability to
analyze, and slightly modify queries in an attempt to match
the pre-deﬁned bid phrases. This approach, which is called
broad or advanced match, allows more ﬂexible matching of
queries to ads, but can be error-prone, which is why not all
advertisers opt to use it.

This paper focuses almost exclusively on broad match.
Since advertisers tend to be most interested in high vol-
ume queries, most bid phrases correspond to head and torso
queries. Therefore, most rare queries can only be matched
against ads if broad match is employed.
Indeed, our pro-
posed algorithm essentially maps rare queries to more com-
mon queries and uses information we have gathered oﬄine
about the common queries to perform an eﬃcient and eﬀec-
tive broad match.

3. RELATED WORK

The techniques presented in this paper are related to the
information retrieval research areas of query expansion and
query rewriting. The classical work on query expansion by
Rocchio [26] shows how to craft the best query for given sets
of relevant and irrelevant documents. The most common ap-
plication of Rocchio’s query expansion technique composes
an expanded query that is a linear combination of the orig-
inal query and the relevant/irrelevant documents vectors.
Relevant document vectors are added to the query, while ir-
relevant document vectors are subtracted from the original
query.

The literature on query rewriting can be divided into two
major directions: 1) incremental rewrites and 2) rewrite into
a completely diﬀerent query. A simple example of the former
is stemming, which removes suﬃxes from query words, so for
example, the query “cameras” would match documents with
the word “camera” [20, 16, 19]. Other examples of incre-
mental changes include removing one or more query words
to improve recall [14], correcting the spelling of words [7] or
using a dictionary and thesaurus to ﬁnd synonyms of query
words [29]. Yet another example is pseudo-relevance feed-
back, which initially retrieves a set of top-ranked documents
and uses them for query augmentation [17, 32, 18, 24, 31].
Common methods for completely transforming queries in-
clude Latent Semantic Indexing (LSI) [9], which maps all
queries and documents to a latent feature space, as well as
rewriting queries into related, previously observed queries
[3, 8].

Query rewriting is a common technique for performing
broad match in sponsored search. Most of the prior work
reported in the literature describes oﬄine query rewriting by
using various sources of external knowledge, and can thus be
applied only to repeating queries from the head and the torso
of the query volume curve. In our previous work [21], we pro-
posed query rewriting by using pseudo-relevance feedback to
expand ad search queries with features from the algorithmic
search results. We used the expanded queries to select an
initial set of ads. The bid phrases in the selected ads were
considered as candidate rewrites of the original query. A ma-
chine learning framework was then used to determine the
quality of the candidate rewrites using various lexical and
bid-based features. This process was done oﬄine for a large
number of queries, and the results were stored in a database
for eﬃcient lookup at query time. Using Web search results
as a source of external expansion has also been explored by
other researchers in the past [10, 27].

Query rewriting for sponsored search reported by Jones et
al. [15] employed user session information from search engine
query logs to produce alternative queries for ad selection.
The ﬁrst step in this method is to generate candidate sub-
stitutions by examining pairs of successive queries issued by
the user within the same session. These candidates are then
examined to ﬁnd common transformations. For example,
by examining multiple sessions, one can conclude that the
word “maps” could be substituted with the word “directions”.
Thus, when an user issues a query as “new york maps”, the
system could select ads with “new york directions” as a bid
phrase.

To the best of our knowledge, all previous approaches to
query expansion for sponsored search used some form of of-
ﬂine processing and simply cached the results for a large
number of queries. This allows eﬃcient lookup at query
time and tends to result in good ad matching quality. How-
ever, the biggest limitation of these approaches is that they
cannot handle queries that have not been processed oﬄine
ahead of time. For this reason, these approaches are not
amenable to handling tail queries, which are very unlikely
to have cached results. This results in poor ad matching for
tail queries. This is precisely the problem that we address in
this paper, namely, how to eﬃciently and eﬀectively expand
tail queries online, in real-time, by leveraging the previous
work on oﬄine query processing.

4. SYSTEM ARCHITECTURE

In this section we give a high-level overview of our system,
and then the next section presents a more detailed view of
the proposed methodology. Figure 1 shows a diagram of the
overall system architecture.

The oﬄine processing module pre-computes query expan-
sions for a large number of queries, and then builds an in-
verted index from the expanded query features. The in-
verted index maps features of expanded queries into the
queries they characterize. In the online phase, when a new
query arrives that has not been previously expanded in the
oﬄine phase, it is this inverted index that maps the query
into related previously-seen queries. This is performed by
matching the features of the incoming query against the fea-
tures of previously expanded queries.

We selected approximately 100 million queries from a Web
search log to process oﬄine. The selection of queries was per-
formed based on query volume and how often the query is
bidded on in a database of sponsored search advertisements.
For each selected query, we expanded it using search results,
query logs and click logs as sources of external knowledge.
Our approach to query expansion using Web search results
is described in [5]. In essence, we retrieve the top-scoring
Web search results for each query, extract features from the
individual result pages, and then select the most salient fea-
tures based on the frequency in the result set. In addition
to the Web search results, we also use query rewrites gener-
ated based on information from query log session as another
source of features. The rewrites are selected based on the
approach described in [15]. Finally, click log features, which
only have a modest impact on the results reported in this pa-
per, are based on proprietary technology whose publication
is forthcoming.

At runtime, when a Web query is issued, we ﬁrst check if it
is present in the table of processed queries. If so, we simply
retrieve the corresponding expanded query and call the ad

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion513Figure 1: Overview of our system architecture. The bottom box represents the grid cluster that performs
all of the oﬄine processing and the top box represents the serving cluster that handles incoming queries.

selection mechanism to retrieve the ads. However, in this
paper we focus on the case when the incoming Web query
have not been preprocessed beforehand. This corresponds
to the cache miss path in Figure 1.

Eﬃciently matching such unseen queries online is chal-
lenging. If we attempt to match just the text of the query
against the ad database, then the resulting matches are
likely to be of low quality, primarily due to the so-called
vocabulary mismatch problem [22]. To alleviate this prob-
lem, we ﬁrst run the incoming query against the inverted
index of expanded queries and retrieve the top k expanded
queries. We then process the retrieved queries to gener-
ate an ad query, which is subsequently used to retrieve ads.
This results in an expanded version of the original query,
even though we have not explicitly pre-processed it oﬄine.
This ad query is then passed to the ad selection sub-system
to retrieve a set of ads. As we show in Section 6, this
computationally-eﬃcient expansion process can signiﬁcantly
improve the ad quality for rare queries. The actual ad selec-
tion for rare queries described in this paper is done online
in real time, with only a negligible increase in computation
compared to running the original, unexpanded query against
the ad database.

5. AD MATCHING ALGORITHM

In this section, we describe our proposed approach for
matching rare queries to ads in more detail. We focus on
several aspects of the query evaluation process. We ﬁrst

describe the features used in the related query selection and
examine the scoring mechanisms for this retrieval. Then we
describe how to compose the ad query from the results of
this retrieval and shortly overview the ad selection.
5.1 Query Feature Extraction

In order to obtain an expressive query representation, we
extract three diﬀerent types of features from each query,
including unigrams, phrases, and semantic classes.

For unigrams, terms are stemmed and a small set of stop
words are dropped. Phrases are extracted using a phrase dic-
tionary that consists of approximately 10 million statistical
phrases gathered from query logs and Web pages [1]. While
unigram and phrase features represent a query’s syntax, they
fail to accurately represent its semantics. Therefore, we also
extract a set of semantic classes from each query. This is
done by classifying each query into a large hierarchical tax-
onomy of semantic classes. The taxonomy consists of about
6,000 nodes and has a median depth of 5. We annotate
each query with its ﬁve most likely semantic classes within
the hierarchy. Further details on the classiﬁer can be found
in [6].

Table 1 shows an example of the features that may be
extracted for the query “low sodium tomato soup recipes”.
Five unigram features are extracted corresponding to the
query terms. Three phrase features corresponding to the
phrases “low sodium”, “tomato soup”, and “soup recipe” are
also extracted. Finally, ﬁve semantic classes, mostly related
to health and cooking are extracted.

ServingGridQuerylogsAd query lookup tableClick dataQuery expansionAdsWebpages...Ad selectionQuery featureindexerQuery featureindexWeb queryAd QueryHitMissQuerylogAd query generationWWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion514Query: low sodium tomato soup recipes

Unigrams

Phrases

low sodium
tomato soup
soup recipe

low

sodium
tomato

soup
recipe

Classes
health

health/diet

health/diet/recipes

cooking

cooking/soup

feature types. That is, we ensure that the sub-vector of un-
igram features has length 1, and similarly for phrase and
semantic class features. Although queries are represented as
single vectors, they can be conceptualized as three normal-
ized vectors, one corresponding to each feature type.

We deﬁne the similarity between two vectors, with respect

to a given feature type F , as follows:

X

w(f, X) · w(f, Y )

Table 1: Example query features extracted from the
query “low sodium tomato soup recipes”.

simF (X, Y ) =

f∈F (X)∩F (Y )

5.2 Related Query Retrieval

The unigram, phrase, and class features extracted from
the original query act as a pseudo-query made up of features
rather than terms. This pseudo-query is then run against
our inverted index of queries that have been expanded and
pre-processed oﬄine.

We employ a simple, yet eﬀective, vector space-based re-
trieval approach for retrieving related queries. Within the
vector space model, queries and documents are represented
as high dimensional vectors. Each vector dimension typi-
cally corresponds to a single term, or, in our case, a feature,
such as a unigram, phrase, or a semantic class. In our sys-
tem, features from the original query are weighted as follows:

w(f, Q) = (1 + log #(f, Q)) · idf (f )

(1)

where #(f, Q) is the number of times feature f occurs in
query Q and idf (f ) is the inverse document frequency for
feature f . Here, idf (f ) captures the global importance of a
feature. It is computed as idf (f ) = log N
where N is the
Nf
total number of ads in our corpus and Nf is the number of
ads that feature f occurs in. Although we compute idf based
on the ad corpus, it is also possible to compute it based
on a query log or a large sample of the Web. Under this
weighting, terms that occur in the query and are relatively
rare in the ad corpus are given the highest weights, whereas
more frequent terms, such as “the” are given considerably
lower weights.

The weights for the expanded queries that are stored in the
inverted index are computed in a similar manner. However,
since the queries in the inverted index are expanded, oﬄine,
with Web search results, the weights associated with them
have been aggregated over a set of Web search results. In
this representation, features are weighted as follows:

0@1 + log

X

1A · idf (f ) (2)

w(f, E(Q)) =

#(f, D)

D∈Results(Q)

where E(Q) is the Web expanded version of Q, Results(Q)
is the set of top Web search results for query Q, #(f, D) is
the number of times that feature f occurs in search result D,
and idf (f ) is computed based on the ad corpus. In practice,
we retrieve the top 40 search results from the Yahoo! search
engine and only consider the 50 highest weighted unigrams,
50 highest weighted phrases, and 5 highest weighted classes
for each query when building the inverted index. This fea-
ture pruning is done to reduce the size of the inverted index
and minimize the number of noisy or non-useful features.

For the Web query and expanded query vectors, we adopt
the common technique of normalizing the vectors to length
1 (under an l2 norm). However, rather than normalize vec-
tors across feature types, we only normalize within a given

where F speciﬁes a feature type and F (X) is the set of
features extracted from X of type F . For example, if Fu is
the set of unigram features, then Fu(X) is the set of unigram
features extracted from X. Thus, F (X)∩ F (Y ) is the set of
features of type F that occur (i.e., have non-zero weight) in
both X and Y . It should be easy to see that simF (X, Y ) is
just the dot product between features of type F in X and
features of type F in Y .

In order to produce a ﬁnal score, the per-feature type
similarities are combined via a simple weighted sum. Hence,
our scoring function has the following form:

0
sim(Q, E(Q

)) =

λF · simF (Q, E(Q
0

))

(3)

X

F∈{Fu,Fp,Fc}

where E(Q0) is the Web expanded representation of Q0,
Fu, Fp, and Fc are the sets of unigram, phrase, and class
features, and λF signiﬁes the weight associated with each
set. Furthermore, in the computation of simF (Q, E(Q0)),
w(f, Q) and w(f, E(Q0)) are deﬁned according to Equations 1
and 2, respectively. Thus, our scoring function ﬁrst com-
putes a dot product for each feature type between the origi-
nal query and the oﬄine expanded query. The dot products
are then combined via a weighted sum (weighted according
to λF ). This formulation provides us the ﬂexibility of assign-
ing diﬀerent weights to the unigram, phrase, and semantic
class feature types, based on the conﬁdence we have in the
sources of the external knowledge as the query classiﬁer and
the phrase extraction. One issue that can arise from this
type of scoring is that the unigram, phrase and class feature
vectors could vary in length and thus their normalized com-
ponents can have diﬀerent relative impact. For example, as
the class vector is of length 3, the components of this vec-
tor would have much higher values than the components of
the unigram vector that is of length 50 in our experimental
setup. We mitigate this vector length diﬀerence by taking
the vector lengths in account when choosing the λF param-
eters.

Using this ranking algorithm, we retrieve a ranked list
of queries that have been processed oﬄine that are related
to the incoming (rare) query. As we will now show, these
queries can be used to construct an enriched representation
of the original query.
5.3 Query Expansion

After the most related queries have been retrieved, we
must construct an expanded version of the original rare
query, which we will call Q∗. There are many ways to con-
struct Q∗. However, since we are generally working within
the vector space model, we use Rocchio’s query expansion
algorithm, which is known to be eﬀective [26].

Given the original query, represented as a feature vector,
and a set of related queries, each also represented as feature
vectors, Rocchio’s algorithm shifts the original query vector

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion515X

towards the centroid of the related query vectors. This is
a form of pseudo-relevance feedback, where we assume that
the related query vectors are relevant and try to push the
original query vector in their general direction. This process
can be described mathematically as follows:

w(f, Q0)

∗
w(f, Q

) = (1 − λ) · w(f, Q) + λ

Q0∈Related(Q)

|Related(Q)|
where w(f, Q∗) is the weight of feature f in the expanded
query vector, Related(Q) is the set of related queries re-
trieved using Equation 3, |Related(Q)| is the number of re-
lated queries retrieved, w(f, Q0) is the weight of feature f
with respect to Q0, and λ is a free parameter that allows us
to control the weighting between the original query and the
centroid of related queries.

It is important to note the diﬀerences between this ap-
proach and standard query expansion using pseudo-relevance
feedback. First, our approach expands against a small, spe-
cialized database of queries, rather than a potentially large,
general purpose database (e.g., Web search). As we will
show, this can be done very eﬃciently, unlike querying the
Web, which would have to be done oﬄine. Second, rather
than expanding using documents directly (query → docu-
ments → expanded query), we expand using the search re-
sults of related queries (query → related queries → doc-
uments → expanded query). This additional level of in-
direction results in a more diverse set of expansion terms,
although it may also result in noisy or spurious expansion
features, as well. Since the mapping from related queries
to documents has been done oﬄine, the only cost incurred
is a lookup, as opposed to the cost of parsing, weight com-
putation, sorting, etc. The end result of the process is an
eﬃcient online approximation to standard, ineﬃcient, query
expansion approaches.
5.4 Ad Retrieval

We are now ready to explain how ads are scored with re-
spect to the expanded version of a rare query. The approach
is similar to how we scored related queries, with a few slight
deviations to account for the unique characteristics of ads.
Furthermore, it is important to note that our prototype
uses a diﬀerent ad indexing strategy than what was de-
scribed in our previous work [5]. In order to overcome the
shortness of the ads and allow for more information in the
matching process, we use as an entire ad group as a retrieval
unit, with all of the bid phrases attached to it. While ex-
amining the tradeoﬀs of this indexing scheme is beyond the
scope of this paper, we explain it here since it has a signif-
icant impact on how we weight ad features, as we will now
discuss.
5.4.1 Ad Feature Weighting
The weighting scheme we used to weight queries is not
appropriate for weighting ads. Ads have very diﬀerent char-
acteristics and must be treated diﬀerently. As we just ex-
plained, our ad indexing unit supports multiple bid phrases
per creative. Advertisements for large advertisers may con-
tain hundreds of bid phrases, while other ads may only have
a single bid phrase. Therefore, ad lengths, with respect to
the number of unigram, phrase, and class features extracted,
have very high variance. Using standard l2 vector normal-
ization in these cases will cause short ads to be preferred over
long ads, which is undesirable. For this reason, we weight ad

features using the well-studied BM25 weighting scheme [23,
24], which robustly handles document length normalization
and term frequency saturation. The speciﬁc form of BM25
weighting that we use is:

k ·“

(k + 1) · #(f, A)

(1 − b) + b ·

|A|
|A|avg

”

· idf (f )

+ #(f, A)

w(f, A) =

where |A| is the length of the ad, |A|avg is the average ad
length, and #w(f, A) is a weighted count of the number
of times that feature f occurs in ad A. Occurrences are
weighted according to which section of the ad they occur
in, with bid phrase and title occurrences being weighted
higher than description and display URL occurrences. This
method of combining evidence from multiple ﬁelds into a
single weighting function has been shown to be eﬀective in
the past [25]. In addition, k and b are free parameters that
control for term frequency saturation and document length
normalization. As before, idf (f ) is computed over the entire
ad corpus.

5.4.2 Title Match Boosting
Another unique characteristic of ads is their structure.
For this reason, we wish to boost the score of ads that have
titles that match the query well. To achieve this, we use the
following boost factor:

qP
qP

f∈F (T ) w(f, Q) · w(f, A)

f∈F (Q) w(f, Q)2

proxF (Q, A) =

where F (T ) are the features of type F extracted from the
title. For example, Fu(T ) and Fp(T ) are the unigram and
phrase features extracted from the title. This boost factor
acts as a very rudimentary form of term proximity that con-
siders query feature co-occurrences in the title. This serves
as a good proximity score approximation, given that no fea-
ture position information is stored in our index.

Since we are only interested in matching the text of the
titles, we deﬁne proxFc (Q, A), the title match boost for the
semantic class features, to be 0.

Scoring Function

5.4.3
Our ﬁnal ad scoring function is a weighted sum of dot
products between features types along with the title match
boost. More formally, the scoring function is:

S(Q, Q

∗

, A) =

λF·simF (Q
∗

, A)·(1+proxF (Q, A))

X

F∈{Fu,Fp,Fc}

where Q is the original query and Q∗ is the expanded query.
Notice that the scoring function takes both the original query
and the expanded query as arguments. This is necessary be-
cause the title match boost is based on the original query
features, not the expanded query features.

Under this scoring function, the best ads are those that
have many (highly weighted) features in common with the
expanded query Q∗ and have a title that exactly match the
original query Q.

6. EMPIRICAL EVALUATION

This section describes the results of our empirical evalua-

tion of ad matching strategies for tail queries.

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion5166.1 Data

Our oﬄine, pre-processed query lookup table consists of
100 million queries. The set was composed as an union of
the top 8 deciles of the queries submitted to the US Yahoo!
search engine by volume and the queries that have been used
as bid phrases in Yahoo!’s textual ad corpus.

For evaluation purposes, we randomly sampled a set of 400
rare queries from the web search query logs. Of these, 121
were found in the lookup table while the remaining 279 were
not. We chose to sample queries in this way so that we could
directly evaluate the usefulness of rare queries being found
in the lookup table versus our online expansion approach.

For each query, human editors judged the relevance of the
top 3 ads returned using several variants of our proposed ad
matching algorithms, resulting in a total of 3,556 judgments.
Editors labeled the relevance of each ad with respect to a
given query on an integral scale from 1 to 5, with a rating
of 1 corresponding to a highly attractive ad and and rating
of 5 corresponding to a poor ad.

The collection of ads that we matched queries against con-

sists of the entire Yahoo! textual ad corpus.
6.2 Methodology

To evaluate the quality of our proposed ad matching algo-
rithms, we employ discounted cumulative gain (DCG) and
precision-recall curves.

The DCG metric is commonly used to evaluate ranking
algorithms when there are graded relevance judgments [13].
Since our judgments are on a scale of 1 to 5, this metric is an
appropriate choice. The DCG for a single query is deﬁned
as as follows:

KX

DCG@K(Q) =

g(i)

log(1 + i)

i=1

where g(i) is the gain associated with the rating of result at
rank i and K is maximum depth result to consider. Each
gain is discounted, giving less weight to relevant items that
appear farther down the ranked list, so the ordering of the
results is important. The (arithmetic) average of the per-
query DCG@K values, also known as mean DCG@k is used
to evaluate an algorithm for an entire set of queries. Since
we retrieve three ads per query, we will primarily evaluate
our algorithms according to mean DCG@1, DCG@2, and
DCG@3. For our experiments, we use gain values of 10, 7, 3,
0.5, and 0 for judgment grades 1, 2, 3, 4, and 5, respectively.

In addition to DCG, we also consider precision-recall curves,

which allow us to visualize the tradeoﬀ between recall (frac-
tion of relevant results returned) and precision (fraction of
results returned that are relevant). Since precision and re-
call are deﬁned for binary judgments, we must binarize our
judgment grades. For these experiments, we assume that
judgment grades 1, 2, and 3 are relevant, while grades 4
and 5 are non-relevant. Furthermore, since we only retrieve
three ads per query, plotting classical 11-point interpolated
macroaveraged curves makes little sense. Instead, we plot
interpolated microaveraged curves [2].

To be rigorous, we often test whether the diﬀerence ob-
served between two algorithms is statistically signiﬁcant or
not. We use a paired, one-tailed non-parametric bootstrap
test for this purpose [12]. The dagger (†) and double dagger
(‡) represent signiﬁcant improvements with respect to the
baseline at the p < 0.05 and p < 0.10 levels, respectively.

DCG@1
DCG@2
DCG@3

Baseline Online Expansion
1.07 (+8.1%)†
1.66 (+5.7%)†
2.10 (+6.6%)‡

0.99
1.57
1.97

Table 2: Comparison of ad matching eﬀective-
ness for tail queries not found in the pre-processed
lookup table.

6.3 Ad Matching Evaluation

In this section, we evaluate the retrieval quality of our
proposed ad matching algorithms. We divide the evaluation
into three parts. First, we evaluate queries that are not
found in the lookup table of pre-processed queries. Next,
we show how eﬀective our method is for queries that are
found in the table. Finally, we put it all together and show
that we can consistently and signiﬁcantly improve retrieval
quality across the entire spectrum of tail queries by using a
hybrid online and oﬄine expansion approach.

We evaluate four diﬀerent ad matching algorithms, each
of which corresponds to a diﬀerent possible path through the
system architecture shown in Figure 1. The ﬁrst algorithm is
Baseline, which ranks results using the original, unexpanded
version of the query vector. The second algorithm, Oﬄine
Expansion, looks the query up in the lookup table and runs
the expanded version of the query, if it exists. Otherwise,
it simply uses the original, unexpanded query vector. The
third algorithm is Online Expansion and corresponds to our
proposed algorithm for expanding queries online using oﬄine
processing. The details of the algorithm were described in
detail in Section 5. For this algorithm, we expand the orig-
inal query with 3 related queries from the inverted index.
Finally, we refer to the last algorithm as Online+Oﬄine Ex-
pansion. As the name suggests, it is a combination of the
Online Expansion and Oﬄine Expansion approaches. The
algorithm forms an ad vector from a weighted combination
of the Online Expansion ad vector and the Oﬄine Expan-
sion ad vector. In our experiments using this algorithm, we
give the Online Expansion ad vector a weight of 1 and the
Oﬄine Expansion ad vector a weight of 2.

In all of our experiments, we set λFu , λFp , and λFc , the
unigram, phrase, and class feature weights, to 1, 1, and 0.1,
respectively. These weights were found to produce good re-
sults in previous evaluations. Furthermore, the b, k, and
ﬁeld weight parameters used for BM25 weighting are set to
previously tuned values that were shown to be eﬀective for
sponsored search retrieval.

6.3.1 Queries not Found in Lookup Table
Our primary evaluation concerns those queries that are
not found in the lookup table of oﬄine processed queries.
These are the queries that we would like to expand, online,
to improve the quality of ad matches. For this purpose, we
compare the eﬀectiveness of the Baseline and Online Ex-
pansion algorithms. We believe our baseline is reasonable
and appropriate because the queries that are not found in
the lookup table are very rare and there is little that can
be done using existing query expansion techniques on these
queries, especially online, in real-time.

The results of this evaluation are given in Table 2 and
Figure 2. First, the DCG results in Table 2 show that our
Online Expansion algorithm consistently and signiﬁcantly

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion517Figure 2: Interpolated precision-recall curve for tail
queries not found in the pre-processed lookup table.

Figure 3: Interpolated precision-recall curve for tail
queries found in the pre-processed lookup table.

Baseline

Online Expansion
Oﬄine Expansion

Online+Oﬄine Expansion

DCG@1 DCG@2 DCG@3

2.89
2.83
3.07‡
2.91

4.56
4.43
4.75
4.44

5.75
5.54
5.87
5.59

Table 3: Comparison of ad matching eﬀectiveness
for tail queries found in the pre-processed lookup
table.

improves DCG@1, DCG@2, and DCG@3. Indeed, the On-
line Expansion improves DCG@1 by over 8%. The precision-
recall curves in Figure 2 show similar results, with the Online
Expansion curve dominating the Baseline curve at all lev-
els of recall. This is an important characteristic, because
practical systems often aim for recall levels well below 100%
in order to produce higher quality ads. Our results show
that our Online Expansion technique is more eﬀective than
the Baseline regardless of the level of recall, making it very
useful from a practical point of view. These results clearly
show that we are able to eﬀectively and eﬃciently enrich
tail queries by leveraging large-scale oﬄine processing, which
was the primary goal of this paper.

It is important to note that the absolute DCG values for
these queries is somewhat low, primarily due to the very na-
ture of the queries under consideration. As we show in Sec-
tion 6.4, many of these queries contain misspellings, URLs,
and proper names. It is typically diﬃcult to ﬁnd relevant
ads for such queries. It may be possible to use automatic
classiﬁcation techniques, such as the one recently proposed
by Broder et al. [4], to determine the quality of a given set
of ads. Such methods can be used to improve overall ad
quality and reduce the number of times ads are shown for
queries with embarrassingly low DCG.

6.3.2 Queries Found in Lookup Table
Next, we evaluate the eﬀectiveness of the Baseline, Online
Expansion, Oﬄine Expansion, and Online+Oﬄine Expan-
sion approaches on the set of tail queries that are found in
the lookup table. The results of our evaluation are shown in
Table 3 and Figure 3.

The ﬁrst thing to notice is that the Oﬄine Expansion ap-
proach is consistently better than the other approaches in

Baseline

Online Expansion
Oﬄine Expansion

Online+Oﬄine Expansion

Hybrid

DCG@1 DCG@2 DCG@3
1.61
1.71‡
1.66
1.76‡
1.79†

3.23
3.32
3.25
3.37
3.43†

2.58
2.68
2.63
2.69
2.78†

Table 4: Comparison of ad matching eﬀectiveness
for all tail queries.

terms of DCG. This result is not unexpected, however, since
we expect oﬄine expansion to be superior to online expan-
sion. Our proposed online expansion approach is really a
last resort algorithm that should only be applied to queries
that are not found in the lookup table. Thus, since online
expansion is really just an approximation for the oﬄine ex-
pansion, we expect it to produce better results for queries
in the lookup table. The results also show that the com-
bined method, Online+Oﬄine Expansion, is slightly worse
than Oﬄine Expansion, but the diﬀerence is not statisti-
cally signiﬁcant. Finally, it is interesting to note that the
Oﬄine Expansion approach is only signiﬁcantly better than
the Baseline in terms of DCG@1. This is likely due to the
fact that the Oﬄine Expansion approach was largely tuned
for head and torso queries, and since our evaluation is only
done over tail queries, the approach ends up being consis-
tently better than the baseline, but not always signiﬁcantly
better.

The precision-recall curve in Figure 3 clearly shows that
the Baseline and Online Expansion approaches are inferior
to the Online+Oﬄine Expansion and Oﬄine Expansion ap-
proaches. Despite the DCG results, the precision-recall curves
suggest that the diﬀerence between the Online Expansion
and Online+Oﬄine Expansion approaches is not very large.
Therefore, our results for tail queries found in the lookup
table suggest that using Oﬄine Expansion is the best strat-
egy and that the Online+Oﬄine Expansion approach is also
a valid option.

6.3.3 Putting It All Together
We now describe how to put together a highly eﬀective,
eﬃcient sponsored search ad matching algorithm for tail
queries. Our results up until this point have suggested the

 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1PrecisionRecallBaselineOnline Expansion 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1PrecisionRecallBaselineOffline ExpansionOnline ExpansionOffline+Online ExpansionWWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion518Characteristic Percentage

Misspelled

Domain/URL
Proper name

Foreign

21%
18%
14%
10%

Table 5: Characteristics of rare query.

Online Expansion approach works the best for tail queries
not found in the lookup table and the Oﬄine Expansion ap-
proach is the most eﬀective for the tail queries that do hap-
pen to appear in the lookup table. Given this, we propose
the Hybrid approach that combines the Online Expansion
and Oﬄine Expansion methods. The Hybrid approach is
very simple, yet, as we will show, very eﬀective, as well. Un-
der the approach, queries that are found in the lookup table
are processed using the Oﬄine Expansion method, whereas
queries that are not found in the lookup table are processed
using the Online Expansion method. Since both of these
approaches can be done online, the Hybrid method can also
be implemented very eﬃciently. The underlying rationale
behind this approach is to combine the best ranking ap-
proaches for both of the query types into a superior ranking
function.

We evaluate the eﬀectiveness of the Baseline, Online Ex-
pansion, Oﬄine Expansion, Online+Oﬄine Expansion, and
Hybrid approaches across the entire set of tail queries in
Table 4. The results show that the Online Expansion and
Online+Oﬄine Expansion approaches are signiﬁcantly bet-
ter than the Baseline according to DCG@1. However, the
clearly superior approach for handling all tail queries is the
Hybrid approach, which improves over the Baseline by 11.2%,
7.8%, and 6.2% in terms of DCG@1, DCG@2, and DCG@3,
respectively. The improvements of the Hybrid approach over
the Online+Oﬄine Expansion approach for the same met-
rics are 1.7%, 3.3% (‡), and 1.8%, respectively. Thus, even
though our goal was to develop an eﬀective ad matching
algorithm for tail queries not found in our lookup table,
our proposed Hybrid approach shows consistent and signif-
icant improvements in DCG across the entire spectrum of
tail queries.
6.4 Characteristics of Rare Queries

To develop a better understanding of rare queries and to
help us improve the performance of the system, we analyzed
a large set of rare queries to ﬁnd out the most common cause
of mismatched ads. Table 6.4 lists the most common classes
we observed. Over a ﬁfth of the tail queries contained at
least one misspelled word.

Although the queries were selected from US logs, there
is still around 10% of foreign queries. We eliminated these
queries from our evaluation. Another common type of a
rare query are URLs, as for example when the user types
“sendpictureshome.com”. Such queries can be processed by
parsing the URL and extracting features. However, as these
were not the focus of our evaluation, we treat the URL as
a single feature. We also noted that a signiﬁcant portion
(14%) of the rare queries contained proper names of people,
places or organizations.
6.5 Efﬁciency

One of our primary claims throughout this paper is that
our proposed online query expansion method is computa-

tionally eﬃciently. The table lookup can be implemented
very eﬃciently (approximately 1 ms), resulting in negligi-
ble overhead for every incoming query. The more expen-
sive code path is exercised when the incoming query is not
found in the lookup table. In this case, a query must be run
against the inverted index of expanded queries. The eﬃ-
ciency of this step largely depends on the underlying search
infrastructures. Finally, regardless of whether the query was
found in the lookup table or not, an expanded query must
be run against the database of ads. The eﬃciency of this,
again, depends on the eﬃciency of the search infrastructure.
Experiments using our prototype system revealed that on-
line query expansion adds approximately 50% overhead, on
average, to the query execution time. Assuming that our
lookup table covers approximately 75% of the query volume,
this results in an overhead of just 12.5% when averaged over
the entire query stream.

Therefore, the amount of overhead can be minimized by
improving query execution time against the inverted index
of expanded queries, increasing the computational power, or
increasing the number of queries stored in the initial lookup
table. These three factors can be balanced to trade oﬀ be-
tween eﬀectiveness and eﬃciency.

7. CONCLUSIONS

This paper has focused on eﬃcient and eﬀective methods
for matching ads to tail queries. We proposed an online
query expansion approach that leverages large-scale oﬄine
processing of queries.
In our approach, we build a large
inverted index of queries, and their expanded ad vectors,
that we run incoming tail queries against. We then use the
results to enrich the representation of the original tail query
Our evaluation shows consistent and signiﬁcant improve-
ments in retrieval eﬀectiveness can be achieved using our
proposed approach for tail queries that we have not done
pre-processing for, both in terms of DCG and precision-
recall analysis. Furthermore, we show that an approach
that combines online and oﬄine processing can be eﬀective
for tail queries that we have some oﬄine processing infor-
mation for. Finally, we proposed a hybrid ranking strategy
that leverages the best of online and oﬄine query expansion.
The hybrid approach shows signiﬁcant improvements in ad
matching quality over the entire spectrum of tail queries.

Acknowledgments
We thank Ann Hsieh and her editorial team for judging the
ad relevance under a very tight schedule. We also thank the
anonymous reviewers for their comments and suggestions.

8. REFERENCES
[1] P. Anick. Using terminological feedback for web search
reﬁnement: a log-based study. In Proc. 26th Ann. Intl.
ACM SIGIR Conf. on Research and Development in
Information Retrieval, pages 88–95, 2003.

[2] R. A. Baeza-Yates and B. Ribeiro-Neto. Modern
Information Retrieval. Addison-Wesley Longman
Publishing Co., Inc., Boston, MA, USA, 1999.

[3] B. Billerbeck, F. Scholer, H. Williams, and J. Zobel.

Query expansion using associated queries. In Proc.
12th Intl. Conf. on Information and Knowledge
Management, pages 2–9, 2003.

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion519[4] A. Broder, M. Ciaramita, M. Fontoura,

E. Gabrilovich, V. Josifovski, D. Metzler, V. Murdock,
and V. Plachouras. To swing or not to swing:
Learning when (not) to advertise. In Proc 17th. Intl.
Conf. on Information and Knowledge Management,
pages 1003–1012, 2008.

[5] A. Broder, P. Ciccolo, M. Fontoura, E. Gabrilovich,

V. Josifovski, and L. Riedel. Search advertising using
web relevance feedback. In Proc 17th. Intl. Conf. on
Information and Knowledge Management, pages
1013–1022, 2008.

[6] A. Broder, M. Fontoura, V. Josifovski, and L. Riedel.

A semantic approach to contextual advertising. In
Proc 30th . Ann. Intl. ACM SIGIR Conf. on Research
and Development in Information Retrieval, pages
559–566, 2007.

[18] M. Mitra, A. Singhal, and C. Buckley. Improving
automatic query expansion. In Proceedings of the
ACM Conference on Research and Development in
Information Retrieval (SIGIR), pages 206–214, 1998.

[19] F. Peng, N. Ahmed, X. Li, and Y. Lu. Context

sensitive stemming for web search. In Proc. 30th Ann.
Intl. ACM SIGIR Conf. on Research and Development
in Information Retrieval, pages 639–646, 2007.

[20] M. Porter. An algorithm for suﬃx stripping. Program,

14(3):130–137, 1980.

[21] F. Radlinski, A. Broder, P. Ciccolo, E. Gabrilovich,

V. Josifovski, and L. Riedel. Optimizing relevance and
revenue in ad search: a query substitution approach.
In Proc. 31st Ann. Intl. ACM SIGIR Conf. on
Research and Development in Information Retrieval,
pages 403–410, 2008.

[7] S. Cucerzan and E. Brill. Spelling correction as an

[22] B. Ribeiro-Neto, M. Cristo, P. B. Golgher, and E. S.

iterative process that exploits the collective knowledge
of web users. In Proceedings of Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 293–300, 2004.

[8] H. Cui, J.-R. Wen, J.-Y. Nie, and W.-Y. Ma.

Probabilistic query expansion using query logs. In
Proc 11th Intl. Conf. on World Wide Web, pages
325–332, 2002.

[9] S. C. Deerwester, S. T. Dumais, T. K. Landauer,
G. W. Furnas, and R. A. Harshman. Indexing by
latent semantic analysis. Journal of the American
Society of Information Science, 41(6):391–407, 1990.
[10] F. Diaz and D. Metzler. Improving the estimation of

relevance models using large external corpora. In Proc.
29th Ann. Intl. ACM SIGIR Conf. on Research and
Development in Information Retrieval, pages 154–161,
2006.

[11] B. Edelman, M. Ostrovsky, and M. Schwarz. Internet
advertising and the generalized second price auction:
Selling billions of dollars worth of keywords. American
Economic Review, 97(1):242–259, 2007.

[12] B. Efron and R. J. Tibshirani. An introduction to the

Bootstrap., volume 57 of Monographs on Statistics and
Applied Probability. Chapman and Hall, 1993.

[13] K. J¨arvelin and J. Kek¨al¨ainen. Cumulated gain-based

evaluation of ir techniques. ACM Trans. Inf. Syst.,
20(4):422–446, 2002.

[14] R. Jones and D. C. Fain. Query word deletion
prediction. In Ann. Intl. ACM SIGIR Conf. on
Research and Development in Information Retrieval,
pages 435–436, 2003.

[15] R. Jones, B. Rey, O. Madani, and W. Greiner.

Generating query substitutions. In Proc. 15th Intl.
Conf. on World Wide Web, pages 387–396, 2006.
[16] R. Krovetz. Viewing morphology as an inference

process. In Proc 16th Ann. Intl. ACM SIGIR Conf. on
Research and Development in Information Retrieval,
pages 191–202, 1993.

[17] V. Lavrenko and W. B. Croft. Relevance-based

language models. In Ann. Intl. ACM SIGIR Conf. on
Research and Development in Information Retrieval,
pages 120–127, 2001.

de Moura. Impedance coupling in content-targeted
advertising. In SIGIR’05, 2005.

[23] S. Robertson and S. Walker. Some simple eﬀective

approximations to the 2-poisson model for
probabilistic weighted retrieval. In Proc. 17th Ann.
Intl. ACM SIGIR Conf. on Research and Development
in Information Retrieval, pages 232–241, 1994.

[24] S. Robertson, S. Walker, S. Jones, M. M.

Hancock-Beaulieu, and M. Gatford. Okapi at
TREC-3. In Proc. 3rd Text REtrieval Conference,
pages 109–126, 1994.

[25] S. Robertson, H. Zaragoza, and M. Taylor. Simple

bm25 extension to multiple weighted ﬁelds. In Proc.
13th Intl. Conf. on Information and Knowledge
Management, pages 42–49, 2004.

[26] J. J. Rocchio. Relevance Feedback in Information

Retrieval, pages 313–323. Prentice-Hall, 1971.

[27] M. Sahami and T. D. Heilman. A web-based kernel

function for measuring the similarity of short text
snippets. In WWW, 2006.

[28] A. Spink, D. Wolfram, B. Jansen, and T. Saracevic.

Searching the web: The public and their queries.
Journal of the American Society for Information
Science and Technology, 53(3):226–234, 2001.

[29] E. M. Voorhees. Query expansion using

lexical-semantic relations. In Ann. Intl. ACM SIGIR
Conf. on Research and Development in Information
Retrieval, pages 61–69, 1994.

[30] C. Wang, P. Zhang, R. Choi, and M. D. Eredita.

Understanding consumers attitude toward advertising.
In Proceedings of Americas Conference on Information
Systems, pages 1143–1148, 2002.

[31] J. Xu and W. B. Croft. Improving the eﬀectiveness of
information retrieval with local context analysis. ACM
Transactions on Information Science (TOIS),
18(1):79–112, 2000.

[32] C. Zhai and J. D. Laﬀerty. Model-based feedback in

the language modeling approach to information
retrieval. In Intl. Conf. on Information and Knowledge
Management, pages 403–410, 2001.

WWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion520