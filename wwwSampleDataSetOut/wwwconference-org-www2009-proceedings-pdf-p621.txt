Triplify – Light-Weight Linked Data Publication from

Relational Databases

Sören Auer, Sebastian Dietzold, Jens Lehmann,

Sebastian Hellmann, David Aumueller

Universität Leipzig, Postfach 100920, 04009 Leipzig, Germany

{auer|dietzold|lehmann|hellmann|aumueller}@informatik.uni-leipzig.de

ABSTRACT
In this paper we present Triplify – a simplistic but eﬀective
approach to publish Linked Data from relational databases.
Triplify is based on mapping HTTP-URI requests onto re-
lational database queries. Triplify transforms the result-
ing relations into RDF statements and publishes the data
on the Web in various RDF serializations, in particular as
Linked Data. The rationale for developing Triplify is that
the largest part of information on the Web is already stored
in structured form, often as data contained in relational
databases, but usually published by Web applications only
as HTML mixing structure, layout and content.
In order
to reveal the pure structured information behind the cur-
rent Web, we have implemented Triplify as a light-weight
software component, which can be easily integrated into
and deployed by the numerous, widely installed Web ap-
plications. Our approach includes a method for publishing
update logs to enable incremental crawling of linked data
sources. Triplify is complemented by a library of conﬁgura-
tions for common relational schemata and a REST-enabled
data source registry. Triplify conﬁgurations containing map-
pings are provided for many popular Web applications, in-
cluding osCommerce, WordPress, Drupal, Gallery, and ph-
pBB. We will show that despite its light-weight architec-
ture Triplify is usable to publish very large datasets, such as
160GB of geo data from the OpenStreetMap project.

Categories and Subject Descriptors
H.3.4 [Systems and Software]: Distributed systems; H.3.5
[Online Information Services]: Data sharing

General Terms
Algorithms, Languages

Keywords
Data Web, Databases, Geo data, Linked Data, RDF, SQL,
Semantic Web, Web application

1.

INTRODUCTION

Even though signiﬁcant research and development eﬀorts
have been undertaken, the vision of an ubiquitous Semantic
Web has not yet become reality. The growth of semantic
Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

representations is (as we will show in the next section) still
outpaced by the growth of traditional Web pages and one
might remain skeptical about the potential success of the Se-
mantic Web in general. The missing spark for expanding the
Semantic Web is to overcome the chicken-and-egg dilemma
between missing semantic representations and search facili-
ties on the Web.

In this paper we, therefore, present Triplify – an approach
to leverage relational representations behind existing Web
applications. The vast majority of Web content is already
generated by database-driven Web applications. These ap-
plications are often implemented in scripting languages such
as PHP, Perl, Python, or Ruby. Almost always relational
databases are used to store data persistently. The most
popular DBMS for Web applications is MySQL. However,
the structure and semantics encoded in relational database
schemes are unfortunately often neither accessible to Web
search engines and mashups nor available for Web data in-
tegration.

Aiming at a larger deployment of semantic technologies

on the Web with Triplify, we speciﬁcally intend to:

• enable Web developers to publish easily RDF triples,
Linked Data, JSON, or CSV from existing Web appli-
cations,

• oﬀer pre-conﬁgured mappings to a variety of popu-
lar Web applications such as WordPress, Gallery, and
Drupal,

• allow data harvesters to retrieve selectively updates
to published content without the need to re-crawl un-
changed content,

• showcase the ﬂexibility and scalability of the approach
with the example of 160 GB of semantically annotated
geo data that is published from the OpenStreetMap
project.

The importance of revealing relational data and making it
available as RDF and, more recently, as Linked Data [2, 3]
has been recognized already. Most notably, Virtuoso RDF
views [5, 9] and D2RQ [4] are production-ready tools for gen-
erating RDF representations from relational database con-
tent. A variety of other approaches has been presented re-
cently (cf. Section 6). Some of them even aim at automat-
ing partially the generation of suitable mappings from rela-
tions to RDF vocabularies. However, the growth of semantic
representations on the Web still lacks suﬃcient momentum.
From our point of view, a major reason for the lack of de-
ployment of these tools and approaches lies in the complexity

WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data621Area
discussion forum
photo gallery

Project
phpBB
Gallery
Liferay Portal Portal
Coppermine
XOOPS
Typo3
eGroupWare
PHP-Fusion
Alfresco
e107
Lifetype
WebCalendar
Compiere
Tikiwiki
Nucleus

photo gallery
CMS
CMS
group ware
CMS
CMS
CMS
Blogging
Calendar
ERP + CRM
Wiki
Blogging

Downloads
170,484
115,966
82,442
76,702
69,404
58,651
28,370
27,090
19,851
19,420
16,867
11,776
11,522
10,092
5,490

Table 1: The 15 most popular database-backed web
application projects as hosted at Sourceforge.net
and ordered by download count in September 2008.

of generating mappings. Tools which automate the genera-
tion of mappings fail frequently in creating production-ready
mappings. Obstacles, for example, include:

• Identiﬁcation of private and public data. Web appli-
cations always contain information which should not
be made public on the Web such as passwords, email
addresses or technical parameters and conﬁgurations.
Automatically distinguishing between strictly conﬁden-
tial, important and less relevant information is very
hard, if not impossible.

• Proper reuse of existing vocabularies. Even the most
elaborated approaches to ontology mapping fail in gen-
erating certain mappings between the database entities
(table and column names) and existing RDF vocabu-
laries, due to lacking machine-readable descriptions of
the domain semantics in the database schema.

• Missing database schema descriptions. Many database
schemas used in Web applications lack comprehensive
deﬁnitions for foreign keys or constraints, for example.
Syntactic approaches for detecting these are likely to
fail, since database schemas are often grown evolution-
ary and naming conventions are often not enforced.

Taking these obstacles into account, the entrance bar-
rier for publishing database content as RDF appears to be
very high. On the other hand, Web applications are often
deployed a thousand (if not a million) times on the Web
(cf. Table 1) and database schemas of Web applications
are signiﬁcantly simpler than those of ERP systems, for in-
stance. Likewise, Web application developers and adminis-
trators usually have decent knowledge of relational database
technologies, in particular of SQL.

The rationale behind Triplify is to provide for a speciﬁ-
cally tailored RDB-to-RDF mapping solution for Web ap-
plications. The ultimate aim of the approach is to lower the
entrance barrier for Web application developers as much as
possible. In order to do so, Triplify neither deﬁnes nor re-
quires to use a new mapping language, but exploits and
extends certain SQL notions with suitable conventions for

transforming database query results (or views) into RDF
and Linked Data.

Once a large number of relational data is published on
the Web, the problem of tracing updates of this data be-
comes paramount for crawlers and indexes. Hence, Triplify
is complemented by an approach for publishing update logs
of relational databases as Linked Data, essentially employ-
ing the same mechanisms. Triplify is also accompanied with
a repository for Triplify conﬁgurations in order to facilitate
reuse and deployment, and with a light-weight registry for
Triplify and Linked Data endpoints. We tested and evalu-
ated Triplify by integrating it into a number of popular Web
applications. Additionally, we employed Triplify to pub-
lish the 160GB of geo data collected by the OpenStreetMap
project.

The paper is structured as follows: We motivate the need
for a simple RDB-to-RDF mapping solution in Section 2 by
comparing indicators for the growth of the Semantic Web
with those for the Web. We present the technical concept
behind Triplify in Section 3. Our implementation is intro-
duced in Section 4. We discuss the evaluation of Triplify
in small- and large-scale scenarios in Section 5, present a
comprehensive overview on related work in Section 6, and
conclude with an outlook on future work in Section 7.

2. CURRENT GROWTH OF THE SEMAN-

TIC WEB

One of the ideas behind Triplify is to enable a large num-
ber of applications and people to take part in the Semantic
Web. We argue that the number of diﬀerent stakeholders
needs to increase in order to realise the vision of the Seman-
tic Web. This means in particular that we need not only
large knowledge bases, but also data created by many small
data publishers. Although it is diﬃcult to give a rigorous
proof for such a claim, we observed a few interesting facts,
when analysing the growth of the Semantic Web, in partic-
ular in relation to the World Wide Web.

Some statistics are summarized in Figure 2. The red line
in the ﬁgure depicts the growth of the WWW measured
by the number of indexed pages on major search engines.
This estimate is computed by extrapolating the total num-
ber of pages in a search engines index from known or com-
puted word frequencies of common words1. Along the line of
similar studies, the statistics suggest an exponential growth
of pages on the WWW. The number of hosts2 (green line)
grows slower, while still being roughly exponential3.

We tried to relate this to the growth of the Semantic Web.
The currently most complete index of Semantic Web data is
probably Sindice4. It stores 37.72 million documents, which
accounts for slightly more than 0.1% of all WWW docu-
ments. Since the growth of documents in Sindice was closely
related to upgrades in their technical infrastructure in the
past, we cannot reliably use their growth rate. However, the
absolute number indicates that semantic representations are
not yet common in today’s Web.

Another semantic search engine is Swoogle5. The blue

1see http://www.worldwidewebsize.com
2statistics from http://isc.org
3see http://www.isc.org/ops/ds/hosts.png for a long term
analysis
4http://sindice.com
5http://swoogle.umbc.edu/

WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data622for

Figure 1: Temporal compari-
son of diﬀerent growth indica-
tors for the traditional WWW
and the Semantic Data Web.
The ﬁrst and second lines
show statistics
indexed
(obtained from
web pages
WorldWideWebSize.com) and
hosts (obtained from isc.org)
for
the WWW. The third
and fourth lines are counts
of Semantic Web documents
from Swoogle (obtained from
Swoogle
and
swoogle.umbc.edu) and Ping
The Semantic Web (obtained
by log ﬁle analysis). Please
note the diﬀerent order of
magnitude for each line.

publications

indexed WWW pages in billions (109)
WWW hosts in 100 millions (108)
Swoogle SWDs millions (106)
PTSW documents in 100 thousands (105)

40

35

30

25

20

15

10

5

0

07/05

01/06

07/06

01/07

07/07

01/08

07/08

year

line in Figure 2 illustrates the growth in Semantic Web doc-
uments (SWDs) in the Swoogle index. It indexed 1.5 million
documents from the start of Swoogle early in 2005 until the
middle of 2006. Currently (October 2008), 2.7 million docu-
ments are indexed. Note that Swoogle, unlike Sindice, does
not crawl large ontologies as present in the Linking Open
Data (LOD) cloud. If we take this aspect into account, the
Semantic Web growth curve would be steeper. However,
the LOD data sets are usually very large data sets extracted
from single sources. A growth of the LOD cloud does not
indicate that the number of diﬀerent participants in the Se-
mantic Web would itself be high.

We also analysed Ping the Semantic Web (PTSW)6 log
ﬁles since they started logging (last line). Apart from the
startup phase (i.e. all documents collected so far fall in the
ﬁrst months), we observed an approximately linear growth
of about 15.000 new resources pinged each month over the
following 14 months. Overall, our observations – while they
have to be interpreted very carefully – indicate that the num-
ber of data publishers in the Semantic Web is still some
orders of magnitudes lower than those in the WWW. Fur-
thermore, its relatively low (estimated) growth rate shows
that simple ways need to be found for a larger number of
web applications to take part in the Semantic Web.

A recent study [7] analysed how terms (classes and prop-
erties) depend on each other in the current Semantic Web.
They used a large data set collected by the Falcons seman-
tic search engine7 consisting of more than 1.2 million terms
and 3.000 vocabularies. By analysing the term dependency
graph, they concluded that the “schema-level of the Seman-
tic Web is still far away from a Web of interlinked ontologies,
which indicates that ontologies are rarely reused and it will
lead to diﬃculties for data integration.”. Along similar lines,
[8] analysed a corpus of 1.7 million Semantic Web documents
with more than 300 million triples. They found that 95%
of the terms are not used on an instance level. Most terms

6http://pingthesemanticweb.com/
7http://iws.seu.edu.cn/services/falcons/

are from meta-level (RDF, RDFS, OWL) or a few popular
(FOAF, DC, RSS) ontologies. By enabling users to map on
existing vocabularies, Triplify encourages the re-use of terms
and will thereby contribute positively to data integration on
the Semantic Web even on the schema level.

3. THE CONCEPT

Triplify is based on the deﬁnition of relational database
views for a speciﬁc Web application (or more general for
a speciﬁc relational database schema) in order to retrieve
valuable information and to convert the results of these
queries into RDF, JSON and Linked Data. Our experiences
showed that for most Web applications a relatively small
number of simple queries (usually between 5 to 20) is suﬃ-
cient to extract the important public information contained
in a database. After generating such views, the Triplify tool
is used to convert them into an RDF, JSON or Linked Data
representation (explained in more detail later), which can be
shared and accessed on the Web. The generation of these
semantic representations can be performed on demand or in
advance (ETL). An overview of Triplify in the context of
current Web technologies is depicted in Figure 2.
3.1 Triplify Conﬁguration

At the core of the Triplify concept is the deﬁnition of
a conﬁguration adapted for a certain database schema. A
conﬁguration contains all the information the Triplify im-
plementation needs in order to generate sets of RDF triples
which are returned on a URI requests it receives via HTTP.
The Triplify conﬁguration is deﬁned as follows:

Deﬁnition 1 (Triplify conﬁguration) A Triplify conﬁg-
uration is a triple (s, φ, µ) where:

• s is a default schema namespace,
• φ is a mapping of namespace preﬁxes to namespace

URIs,

WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data623requires any additional knowledge and allows users to
employ semantic technologies, while working in a fa-
miliar environment.

3.2 Relational View Structure

For converting SQL query results into the RDF data model,
Triplify follows a multiple-table-to-class approach preceded
by a relational data transformation. Hence, the results of
the relational data transformation require a certain struc-
ture in order to be representable in RDF:

• The ﬁrst column of each view must contain an identi-
ﬁer which will be used to generate instance URIs. This
identiﬁer can be, for example, the primary key of the
database table.

• Column names of the resulting views will be used to

generate property URIs.

• Individual cells of the query result contain data val-
ues or references to other instances and will eventually
constitute the objects of resulting triples.

In order to be able to convert the SQL views deﬁned in the
Triplify conﬁguration into the RDF data model, the views
can be annotated inline using some extensions to SQL, which
remain transparent to the SQL processor, but inﬂuence the
query result, in particular the column names of the returned
relations.

When renaming query result column names, the following
extensions to SQL can be used to direct Triplify to employ
existing RDF vocabularies and to export characteristics of
the triple objects obtained from the respective column:

• Mapping to existing vocabularies. By renaming the
columns of the query result, properties from existing
vocabularies can be easily reused. To facilitate read-
ability, the namespace preﬁxes deﬁned in the Triplify
conﬁguration in φ can be used. In the following query,
for example, values from the name column from a users
table are mapped to the name property of the FOAF
namespace:
SELECT id, name AS ’foaf:name’ FROM users

• Object properties. By default all properties are con-
sidered to be datatype properties and cells from the
result set are converted into RDF literals. By append-
ing a reference to another instance set separated with
’->’ to the column name, Triplify will use the column
values to generate URIs (i.e. RDF links).

• Datatypes. Triplify uses SQL introspection to retrieve
automatically the datatype of a certain column and
create RDF literals with matching XSD datatypes. In
order to tweak this behaviour, the same technique of
appending hints to column names can be used for in-
structing Triplify to generate RDF literals of a certain
datatype. The used separator is ’^^’.

• Language tags. All string literals resulting from a re-
sult set column can be tagged with a language tag that
is appended to the column name separated with ’@’.

The use of these SQL extensions is illustrated in the fol-

lowing example:

Figure 2: Triplify overview: the Triplify script is
accompanied with a conﬁguration repository and an
endpoint registry.

• µ is a mapping of URL patterns to sets of SQL queries;
individual queries can optionally contain placeholders
referring to parenthesized sub-patterns in the corre-
sponding URL pattern.

The default schema namespace s is used for creating URI
identiﬁers for database view columns, which are not mapped
to existing vocabularies. Since the same Triplify conﬁgura-
tion can be used for all installations of Web applications with
the same database storage layout, data from across these dif-
ferent installations can be already integrated even without
a mapping to existing vocabularies. The namespace preﬁx
to URI map φ in the Triplify conﬁguration deﬁnes shortcuts
for frequently used namespaces. The mapping µ maps de-
referencable RDF resources to sets of SQL views describing
these resources. The patterns in the domain of µ will be
evaluated against URI requests Triplify receives via HTTP.
The Triplify extraction algorithm replaces placeholders in
the SQL queries with matches of parenthesized sub-patterns
in the URL patterns of µ. For the purpose of simplicity, our
implementation (which we discuss in more detail later) does
not require the use of patterns and placeholders at all, and
is still suﬃcient for the vast majority of usage scenarios. A
simple example of µ for the WordPress blogging system is
displayed in Figure 3.

The use of SQL as a mapping language has many advan-
tages compared with employing newly developed mapping
languages:

• SQL is a mature language, which was speciﬁcally de-
veloped to transform between relational structures (re-
sults of queries are also relational structures). Hence,
SQL supports many features, which are currently not
available in other DB to RDF mapping approaches.
Examples are aggregation and grouping functions or
complex joins.

• Being based on SQL views allows Triplify to push al-
most all expensive operations down to the database.
Databases are heavily optimized for data indexing and
retrieval, thus positively aﬀecting the overall scalabil-
ity of Triplify.

• Nearly all software developers and many server admin-
istrators are proﬁcient in SQL. Using Triplify barely

WebBrowserKeyword-basedSemanticbasedWeb BrowserSearch EnginesSemantic-basedSearchEnginesHTML pagesRDFtriple-baseddescriptionsRDF triplebaseddescriptions(LinkedData, RDF, JSON)WebserverWeb ApplicationTriplifyscriptEndpointregistryTriplifyRelationalConfigurationrepositoryRelational DatabaseWWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data624$triplify[’queries’]=array(

’post’=>array(

"SELECT id, post_author AS ’sioc:has_creator->user’, post_date AS ’dcterms:created’, post_title AS ’dc:title’,

post_content AS ’sioc:content’, post_modified AS ’dcterms:modified’

FROM posts WHERE post_status=’publish’",

"SELECT post_id AS id, tag_id AS ’tag:taggedWithTag->tag’ FROM post2tag",
"SELECT post_id AS id, category_id AS ’belongsToCategory->category’ FROM post2cat",

),
’tag’=>"SELECT tag_ID AS id, tag AS ’tag:tagName’ FROM tags",
’category’=>"SELECT cat_ID AS id, cat_name AS ’skos:prefLabel’, category_parent AS ’skos:narrower->category’

FROM categories",

’user’=>array(

"SELECT id, user_login AS ’foaf:accountName’, user_url AS ’foaf:homepage’,

SHA(CONCAT(’mailto:’,user_email)) AS ’foaf:mbox_sha1sum’, display_name AS ’foaf:name’

FROM users",

"SELECT user_id AS id, meta_value AS ’foaf:firstName’ FROM usermeta WHERE meta_key=’first_name’",
"SELECT user_id AS id, meta_value AS ’foaf:family_name’ FROM usermeta WHERE meta_key=’last_name’",

),
’comment’=>"SELECT comment_ID AS id, comment_post_id AS ’sioc:reply_of->user’, comment_author AS ’foaf:name’,

comment_author_url AS ’foaf:homepage’, SHA(CONCAT(’mailto:’,comment_author_email)) AS ’foaf:mbox_sha1sum’,
comment_type, comment_date AS ’dcterms:created’, comment_content AS ’sioc:content’, comment_karma,

FROM comments WHERE comment_approved=’1’",

);

Figure 3: Mapping µ from URL patterns to SQL query (sets) in the Triplify conﬁguration for the WordPress
blogging system (PHP code).

Example 1 (SQL extensions) The following query, illus-
trating the Triplify SQL extensions, selects information from
a products table. The used Triplify column naming exten-
sions will result in the creation of literals of type xsd:decimal
for the price column, in the mapping of the values in the
desc column to literals with ’en’ language tag attached to
rdfs:label properties and in object property instances of
the property belongsToCategory referring to category in-
stances for values in the cat column.

SELECT id,

price AS ’price^^xsd:decimal’,
desc AS ’rdfs:label@en’,
cat AS ’belongsToCategory->category’

FROM products

3.3 Triple Extraction

The conversion of database content into RDF triples can
be performed on demand (i.e. when a URL in the Triplify
namespace is accessed) or in advance, according to the ETL
paradigm (Extract-Transform-Load). In the ﬁrst case, the
Triplify script searches a matching URL pattern for the re-
quested URL, replaces potential placeholders in the associ-
ated SQL queries with matching parts in the request URL,
issues the queries and transforms the returned results into
RDF (cf. Algorithm 1). The processing steps of the algo-
rithm are depicted in Figure 4, using the example of the
WordPress Triplify conﬁguration from Figure 3.

Linked Data Generation. The Linked Data paradigm
is based on the idea of making URIs used in RDF documents
de-referencable – i.e. accessible via the HTTP protocol. The
result of such an HTTP request delivers a description of
the resource identiﬁed by the URI, i.e. a collection of all
relevant information about the resource. The Linked Data
paradigm of publishing RDF solves several important issues:
(a) the provenance of facts expressed in RDF can be easily
veriﬁed, since the used URIs always contain authoritative
information in terms of the publishing server’s domain name,
(b) the (continuing) validity of facts can be easily veriﬁed
by (re-)retrieving the RDF description, (c) Web crawlers can

obtain information in small chunks and follow RDF links to
gather additional, linked information.

Triplify generates Linked Data with the possibility to pub-
lish data on diﬀerent levels of a URL hierarchy. On the top
level Triplify publishes only links to classes (endpoint re-
quest). An URI of an endpoint request usually looks as
follows: http://myblog.de/triplify/. From the class de-
scriptions RDF links point to individual instances (class re-
quest). An URI of a class request would then look like this:
http://myblog.de/triplify/posts.
Individual instances
from the classes could be ﬁnally accessed by appending the
id of the instance, e.g. :
http://myblog.de/triplify/posts/13.

In order to simplify this process of generating Linked Data,
Triplify allows to use the class names as URL patterns in
the Triplify conﬁguration. From the SQL queries associated
with those class names (base SQL queries) in the conﬁgura-
tion, Triplify derives queries for retrieving lists of instances
and for retrieving individual instance descriptions. The base
SQL view just selects all relevant information about all in-
stances. In order to obtain a query returning a list of in-
stances, the base view is projected onto the ﬁrst column
(i.e. the id column). In order to obtain a query retrieving
all relevant information about one individual instance, an
SQL-where-clause restricting the query to the id of the re-
quested instance is appended. In most cases this simpliﬁes
the creation of Triplify conﬁgurations enormously.
3.4 Linked Data Update Logs

When data is published on the Web, for example as Linked
Data, it is important to keep track of data (and hence RDF)
updates so that crawlers know what has changed (after the
last crawl) and should be re-retrieved from that endpoint.
A centralized registry (such as implemented by PingThe-
SemanticWeb service8) does not seem to be feasible, when
Linked Data becomes more popular. A centralized service,

8http://pingthesemanticweb.com/

WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data625Algorithm 1: Triple Extraction Algorithm
Input: request URL, Triplify conﬁguration
Output: set T of triples
foreach URL pattern from Triplify conﬁguration do
if request URL represents endpoint request then
T = T ∪ {RDF link to class request for URL
pattern}

else

if request URL matches URL pattern then

foreach SQL query template associated with
URL pattern do

Query = replacePlaceholder(URL
pattern, SQL query template, request
URL);
if request URL represents class request
then

Query = projectToFirstColumn
(Query);

else

if request URL represents instance
request then

Query = addWhereClause
(Query,instanceId);

Result = execute(Query);
T = T ∪ convert(Result);

1
2
3

4
5
6

7

8

9

10
11

12

13
14

15

return T

which also constitutes a Single Point of Failure, will hardly
be able to handle millions of Linked Data endpoints pinging
such a registry each time a small change occurs.

The approach Triplify follows are Linked Data Update
Logs. Each Linked Data endpoint provides information about
updates performed in a certain timespan as a special Linked
Data source. Updates occurring within a certain timespan
are grouped into nested update collections. The coarsest
update collections cover years, which in turn contain up-
date collections covering months, which again contain daily
update collections and this process of nesting collections is
continued until we reach update collections covering seconds
in time. Update collections covering seconds are the most
ﬁne-grained update collections and contain RDF links to
all Linked Data resources updated within this period of
time. For very frequently updated LOD endpoints (e.g.
Wikipedia) this interval of one second will be small enough,
so the related update information can still be easily re-
trieved. For rarely updated LOD endpoints (e.g. a per-
sonal Weblog) links should only point to non-empty update
collections in order to prevent crawlers from performing un-
necessary HTTP requests. Individual updates are identiﬁed
by a sequential identiﬁer. Arbitrary metadata can be at-
tached to these updates, such as the time of the update or
a certain person who performed the update.

Example 2 (Nested Linked Data Update Log) Let us
assume myBlog.de is a popular WordPress blog. The Triplify
endpoint is reachable via http://myBlog.de/lod/. New
blog posts, comments, and updates of existing ones are pub-
lished in the special namespace below http://myBlog.de/
lod/updates. Retrieving http://myBlog.de/lod/update,

Figure 4: Triple generation from database views.
The numbered query result relations correspond to
the queries deﬁned for the post URL pattern in the
WordPress example conﬁguration in Figure 3.

for example, will return the following RDF:

http://myBlog.de/lod/update/2007

rdf:type

update:UpdateCollection .

http://myBlog.de/lod/update/2008

rdf:type

update:UpdateCollection .

Each update collection should be additionally annotated
with the timeframe it covers (which we omit here for reasons
of brevity), to avoid the need for an interpretation of the
URI structure. The following RDF could then be returned
for http://example.com/lod/update/2008:

http://myBlog.de/lod/update/2008/Jan

rdf:type

update:UpdateCollection .

http://myBlog.de/lod/update/2008/Feb

rdf:type

update:UpdateCollection .

This nesting continues until we ﬁnally reach an URL which
exposes all blog updates performed in a certain second in
time. The resource http://myBlog.de/lod/update/2008/
Jan/01/17/58/06 then would, for example, contain RDF
links (and additional metadata) to the Linked Data doc-
uments updated on Jan 1st, 2008 at 17:58:06:

http://myBlog.de/lod/update/2008/Jan/01/17/58/06/user123
update:updatedResource http://myBlog.de/lod/user/John;
"20080101T17:58:06"^<xsd:dateTime>;
update:updatedAt
update:updatedBy
http://myBlog.de/lod/user/John .

Invocation. Triplify automatically generates all the re-
sources in the update URI space, when the mapping µ in the
Triplify conﬁguration contains the URL pattern ”update”.
Queries belonging to this URL pattern have to return at
least two columns. The ﬁrst column contains the date when
to update occurred, the second column contains the id of
the updated resource. Additional columns can contain ad-
ditional metadata. An example query publishing updates of
a WordPress blog is given below:

SELECT post_modified,id AS ’update:updatedResource->post’
FROM post

HTTP Request: http://blog.aksw.org/triplify/post/1SQL generationidsioc:has_creatordc:titlesioc:contentdcterms:createddcterms:modified15DBpedia releaseToday we released …2008102016352008102016351idtag:taggedWithTag1DBpedia1ReleaseidbelongsToCategory134…23http://blog.aksw.org/triplify/post/1sioc:has_creatorhttp://blog.aksw.org/triplify/user/5..Triple generationhttp://blog.aksw.org/triplify/post/1dc:title“New DBpedia release”http://blog.aksw.org/triplify/post/1sioc:content“Today we released …”http://blog.aksw.org/triplify/post/1dcterms:modified“20081020T1635”^^xsd:dateTimehttp://blog.aksw.org/triplify/post/1dcterms:created“20081020T1635”^^xsd:dateTimehttp://blogaksworg/triplify/post/1tag:taggedWithTag“DBpedia”23.10.08Linked Data Web7http://blog.aksw.org/triplify/post/1tag:taggedWithTagDBpediahttp://blog.aksw.org/triplify/post/1tag:taggedWithTag“Release”http://blog.aksw.org/triplify/post/1belongsToCategoryhttp://blog.aksw.org/triplify/category/34WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data6264.

IMPLEMENTATION

The Triplify concept has currently been implemented only
in PHP, but implementations in other popular Web appli-
cation languages are planned. The Triplify implementation
was performed with the aim of producing a small, light-
weight plugin for existing Web applications. The core of the
implementation contains barely more than 300 lines of code,
which simpliﬁes integration into Web applications to a great
extent. The Triplify implementation needs direct access to
the relational database by means of either a PDO object
(the standard database abstraction layer in PHP) or the
MySQL driver. The Web applications into which Triplify
is integrated may, however, use any other database abstrac-
tion framework. Triplify works with all relational databases
accessible from PHP, since the only database vendor speciﬁc
SQL code is contained in the actual Triplify conﬁguration’s
SQL views. When available, Triplify also uses URL rewrit-
ing, in order to produce concise RDF URIs. When SQL
functions are insuﬃcient or inconvinient for modifying data,
user-deﬁned call-back functions (implemented in PHP) allow
to process data before values are exported to RDF literals.
In some cases database schemas contain tables which have
a property-value or even a subject-property-value structure.
Triplify is able to deal with these cases by dynamically de-
riving the property name from a preceeding column value
instead of the current column name. Triplify allows to add
arbitrary metadata (such as provenance or licensing infor-
mation) to all generated RDF output.

The deployment of Triplify in conjunction with an existing

Web application can be performed in two simple steps:

1. copying the Triplify script into the Web application’s

directory.

2. a conﬁguration matching the Web application’s data-
base schema can be either downloaded from the Triplify
conﬁguration repository or has to be created manually.

Performance. Triplify was developed primarily for small
to medium Web applications (i.e. less than 100MB database
content). However, since Triplify’s application logic is sim-
ple and since nearly all workload is pushed down to the
database, Triplify can also be used with very large databases
(as we detail in Section 5). Furthermore, Triplify supports
caching of the processed results in order to increase perfor-
mance.

Privacy. Web developers who integrate Triplify into their
applications should be cautious not to reveal any sensitive
information. For example, email addresses should be SHA1
hashed and password hashes as well as information which is
not publicly accessible should be omitted in the Triplify SQL
queries. As a rule of thumb, only such information should
be made available through Triplify, which is also publicly
readable on Web pages.

Triplify is licensed under the terms of the GNU Lesser
General Public License; everybody is free to copy, modify
or redistribute it, even together with commercial software.
4.1 Conﬁguration Repository

Most web applications are deployed many times with iden-
tical database schemas. Table 1 summarizes the most pop-
ular Web applications available at sourceforge.net and their
monthly download ﬁgures. This data suggests that a rela-
tively small amount of Web applications is deployed many

hundred-thousand times on the Web.
In order to reuse
Triplify conﬁgurations for diﬀerent deployments of the same
database schema, conﬁgurations for popular Web applica-
tions are collected on the Triplify Wiki at http://triplify.org.
Currently, most of these conﬁgurations still have to be in-
stalled manually, but our ultimate aim is to make Triplify a
direct part of popular Web application distributions.
4.2 Endpoint Registry

Triplify just tackles one side of the chicken-and-egg prob-
lem of the Semantic Data Web – the availability of a critical
mass of machine-readable data on the Web. The other side
is to showcase how this data can be used to improve the
user experience on the Web (in particular search, brows-
ing and information integration). To facilitate such appli-
cations which incorporate Triplify data sources, we devel-
oped a light-weight endpoint registry. A new Linked Data
endpoint can be conveniently registered by making a single
HTTP request and appending the URL of the endpoint as
a request parameter. This registry itself is available as a
Triplify Linked Data endpoint at http://triplify.org/triplify.

5. EVALUATION

Our evaluation aims at demonstrating that Triplify is suited

for the two application scenarios: (a) the semantiﬁcation of
existing small and medium Web applications such as Blogs,
Wikis, online shops, Web forums or picture galleries and (b)
the publication of large relational databases on the Web.
5.1 Integration into Web Applications

In order to evaluate our approach, we integrated Triplify
into a number of diﬀerent Web applications. The Triplify
Web site9 includes a repository of these and other third-
party contributed Triplify conﬁgurations for popular Web
applications. General experiences are that creating a Triplify
conﬁguration for an average Web application (containing ap-
proximately 10-20 relations) takes around 2-3 hours includ-
ing the search for existing vocabularies. We also noticed
that existing vocabularies already cover the majority of the
required cases. Of particular importance are the Friend-of-
a-Friend (FOAF)10, Semantically Interlinked Online Com-
munities (SIOC)11 and Dublin Core (DC)12 vocabularies.
In the remainder of this subsection we will report our ex-
periences in creating Triplify conﬁgurations for the three
Web applications osCommerce (online shop), phpBB (Web
forum) and Gallery (Web photo album).

osCommerce. osCommerce Online Merchant is one of
the most popular open-source online shop e-commerce so-
lutions. The database schema of osCommerce contains al-
most 50 tables of which just 12 contain valuable public in-
formation. The osCommerce Triplify conﬁguration consists
of eight query sets (which are mapped to RDFS classes) and
13 queries. The following data structures are, in particular,
exposed by Triplify: (1) a hierarchy of product categories,
which uses vocabulary elements from the Simple Knowledge
Organization System (SKOS) and Dublin Core, (2) a list of
products and manufacturers based on the GoodRelations on-

9http://Triplify.org
10http://www.foaf-project.org
11http://www.sioc-project.org
12http://www.dublincore.org

WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data627tology13, but complemented with additional attributes that
are deﬁned in a separate Triplify osCommerce namespace,
and (3) a list of reviews for products represented as SIOC
posts.

phpBB. According to download ﬁgures at Sourceforge.net,
phpBB is the most popular open source Web forum solution.
While the whole database schema consists of over 60 tables,
the most relevant information about users, groups, and posts
is located in just a few tables. The phpBB Triplify conﬁg-
uration consists of six query sets with one to two queries
each. Given their good coverage, vocabulary elements from
the SIOC and FOAF namespace are suﬃcient. The re-
sulting RDF graph contains information about forum users
(sioc:User) and groups (sioc:Usergoup) and the commu-
nity content produced by the users (sioc:Forum and sioc:
Post). In order to preserve the privacy of phpBB users, the
Triplify conﬁguration uses MySQL’s SHA function to encrypt
users’ email addresses for storage in the sioc:email_sha1
attribute (cf. also the ﬁrst query of the ’user’ block in Fig-
ure 3).

Gallery. Gallery is a Web application allowing to publish
and organize photos in albums. Metadata such as title and
location can be attached to photos as well as community-
supplied comments and ratings. Gallery’s database schema
consists of over 40 tables out of which just six are used by
Triplify. The Triplify conﬁguration of Gallery consists of ﬁve
query sets with one or two queries each. The resulting RDF
graph uses vocabulary elements from the SIOC (both core
and types module), FOAF and Dublin Core namespaces as
well as some custom-deﬁned ones. The latter include speciﬁc
attributes for images and the number of views of an image
in a gallery.
5.2 Publishing OpenStreetMap Geo Data

In addition to using Triplify for publishing RDF from the
long tail of million of Web applications deployed, we evalu-
ated the software with the very large datasets produced by
the OpenStreetMap project14. The OpenStreetMap project
has successfully applied the Wiki approach to geo data.
Thousands of users worldwide upload GPS traces from their
navigation systems, mobile phones or GPS trackers to the
OpenStreetMap.org Web site. Once uploaded, everybody
can annotate, categorize and correct the data. The data
structures to capture this information are points and ways
to connect these points. By annotation or tagging points,
the project in particular produces a vast amount of point-
of-interest descriptions – hotels, gas stations, traﬃc lights,
shops, base transceiver stations, to name a few. Overall, the
project had produced a 160GB database of geo data until
July 2008, in some regions surpassing commercial geo data
providers in terms of precision and detail.

In order to publish the OpenStreetMap data, we per-
formed some preprocessing of the data structures. Point
annotations, for example, are originally stored as comma
separated property-values assignments in a BLOB column
within the database. These were decoded and stored in a
separate table. We also created a stripped-down version
of the points’ table, containing only points with annota-
tions and eliminating those which are just used as hanging
points for ways. As a result, we obtained 192 million points-
of-interest, which are annotated with roughly 800 million

13http://www.heppnetz.de/projects/goodrelations/
14http://www.openstreetmap.org

property-value combinations. Table 2 summarizes the most
popular point-of-interest annotations currently found in the
OpenStreetMap data. Overall, our OpenStreetMap data
tripliﬁcation resulted in roughly 1 billion triples constituting
one of the largest available datasets on the Semantic Web
and by far surpassing the DBpedia [1] eﬀort.

Property Usage Values Value examples
name
place

1.066k
443k

704k
287

amenity

277k

1433

is in
highway

postal code
railway

natural

shop

tourism

190k
188k

140k
53k

28k

27k

27k

14k
310

63.135
111

149

803

519

airport, attraction, building,
continent, island, village, city
airline oﬃce, airport, alm hut,
ambulance, amusement park,
art gallery, atm, pub, church

access, bench, bridge, bus stop,
traﬃc signals

station, bridge, construction,
junction
bay, beach, bog, cairn, caldera,
cave, caves, cave entrance, cliﬀ,
coastline
dry cleaning, patisserie, super-
market, technology, airline
accommodation,
alpine hut,
apartments, art gallery, attrac-
tion, bar, boat rental

Table 2: Examples of frequently used properties and
values in the OpenStreetMap data.

The resulting database schema can be easily published by
using Triplify. However, in order to retrieve information, the
point or way identiﬁers (i.e. primary keys from the respec-
tive columns) have to be known, which is usually not the
case. A natural entrypoint for retrieving geo data, however,
is the neighborhood around a particular point, possibly ﬁl-
tered by points adhering to certain categories or being of a
certain type. To support this usage scenario, we developed a
spatial Linked Data extension, which allows to retrieve geo
data of a particular circular region. The structure of the
URIs used looks as follows:

The linked geo data extension is implemented in Triplify
by using a conﬁguration with regular expression URL pat-
terns which extract the geo coordinates, radius and option-
ally a property with associated value and insert this informa-
tion into an SQL query for retrieving corresponding points
of interest. The SQL query is optimized so as to retrieve
ﬁrst points in the smallest rectangle covering the requested
circular area and then cutting the result set into a circular
area by using the Haversine Formula. Performance results
for retrieving points-of-interest in diﬀerent areas are sum-
marized in Table 3.

The publication of the OpenStreetMap data using Triplify
adds a completely new dimension to the Data Web: spatial
data can be retrieved and interlinked on an unprecedented
level of granularity. This enhancement enables a variety
of new Linked Data applications such as geo data syndi-
cation or semantic-spatial searches. The dynamic of the
OpenStreetMap project will ensure a steady growth of the
dataset. Usage instructions and further information can be
also found at http://LinkedGeoData.org.

TriplifySpatialExtensionTriplify Spatial ExtensionHow to publish geo‐data using Triplify?OpenStreetMaps–160 GB Geo Datalots of POIs –hotels, gas stations, universities …http://LinkedGeoData.org/near/48.213,16.359/1000/amenity=pubLongitudeLatitudeRadiusPropertyhttp://LinkedGeoData.org/point/212331http://LinkedGeoData.org/point/944523http://LinkedGeoData.org/point/23409123.10.08Linked Data Web11WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data628Location
Leipzig
Leipzig
London
London
Amsterdam
Amsterdam

Property

Radius
1km
5km amenity=pub
1km
5km amenity=pub
1km
5km amenity=pub

-

-

-

Results Time
0.05s
0.54s
0.28s
0.74s
0.31s
1.25s

291
41
259
495
1811
64

Table 3: Performance results for retrieving points-
of-interest in diﬀerent areas.

6. RELATED WORK

The amount of work related to transformations between
relational and RDF data models is extensive and an ex-
haustive overview cannot be given here. Nevertheless, we
will give an overview of the major approaches. The W3C
RDB2RDF Incubator Group15 has taken an eﬀort to classify
existing approaches16. Other overviews and classiﬁcations
can be found in [10] and [14]17.

The following classiﬁcation criteria can be identiﬁed:

(a) Degree of mapping creation automation (automatic,

semi-automatic, manual approaches).

(b) Some approaches are tailored to model a domain, some-
times with the help of existing ontologies, while oth-
ers attempt to extract domain information primarily
from the given database schema with few other re-
sources used (domain or database semantics-driven).
The latter often results in a table-to-class, column-to-
predicate mapping. Some approaches also use a (semi)
automatic approach based on the database, but allow
manual customization to model domain semantics.

(c) Resulting access paradigm (ETL, Linked Data, SPARQL

access). Note that the access paradigm also determines
whether the resulting RDF model updates automati-
cally. ETL means a one time conversion, while Linked
Data and SPARQL always process queries versus the
original database.

(d) The used mapping language as an important factor for

reusability and initial learning cost.

(e) Domain reliance (general or domain-dependent): re-
quiring a pre-deﬁned ontology is a clear indicator of
domain dependency.

A general overview is given in Table 4. We have identiﬁed

four classes of diﬀerent approaches:

Alignment. Dartgrid [17] uses a visual mapping tool to
manually align the database to an existing ontology. Queries
are only allowed based on forms that are generated from
the ontology. Hu [11] is one of the latest representants of
this class of approaches where databases are automatically
aligned to a reference ontology. The major drawback is the
need for an existing domain ontology which has to be deﬁned
a priori and independently from the database. Evaluation
of alignment quality also remains an open issue.

Database Mining. Four similar approaches which use
the database semantics as starting point are Tirmizi [16],

15http://www.w3.org/2005/Incubator/rdb2rdf/
16http://esw.w3.org/topic/Rdb2RdfXG/StateOfTheArt
17http://www2006.org/programme/ﬁles/pdf/p160-slides.pdf

Li [12], DB2OWL [10], and RDBToOnto [6]. Tirmizi has
a formal system to capture the complete information con-
tained in the database which is based on the idea that all
domain semantics is already contained in the database. Li,
DB2OWL and RDBToOnto use less complete extraction
rules. Li and RDBToOnto also aim at reﬁning the result-
ing ontology. RDBToOnto provides a visual interface for
manual changes. DB2OWL creates a local ontology from a
database which is later aligned to a reference ontology. The
ontologies created in these approaches reﬂect the database
semantics. Problems are likely to arise, when several dif-
ferent databases need to be integrated due to the lack of
database-independent domain semantics.

Integration. A typical integration project is described
in [15]. A custom-tailored mapping is created on the basis of
XSLT. Although the project delivers no technical methods
for mapping, it clearly shows how much expertise is needed
from domain experts to capture semantics correctly.

Languages/Servers. R2O [13] and D2RQ [4] are map-
ping languages, but follow diﬀerent goals. While R2O pro-
vides more ﬂexibility and expressiveness, it also needs a ref-
erence ontology. D2RQ directly exposes the database as
Linked Data and SPARQL with D2R server. Both map-
ping languages require an initial learning of the language as
well as knowledge about modelling. Virtuoso RDF Views
[5, 9] stores mappings in a quad storage. While D2RQ and
RDF Views follow the table-to-class, column-to-predicate
approach, RDF Views has some more methods to incor-
porate DB semantics. None of the approaches provide a
methodology for users as such, but rather give an ontologi-
cal representation of the database. The mapping languages
used have about the same complexity and ﬂexibility as SQL.
(SQL has more ﬂexible selection capabilities, while the lan-
guages concentrate on expressing the ontology mapping.)

7. CONCLUSIONS

Turning the Semantic Data Web into reality still poses a
signiﬁcant challenge, although standards, technologies, and
tools are already in place. In order to overcome the chicken-
and-egg problem between semantic representations and search
facilities on the Web, we developed the Triplify approach
which primarily tackles the ‘reaching a critical mass of se-
mantics’ side of the problem. We hope that Triplify will con-
tribute a strong impulse for achieving a larger deployment of
semantic technologies on the Web. Triplify provides direct
beneﬁts to the developers and users of a Web application:
• Installations of Web applications are easier to ﬁnd and

search engines can better evaluate their data.

• The usage of Triplify is minimally invasive by only re-
quiring few application changes. Approaches which
integrate data representations into the HTML out-
put (such as RDFa and GRDDL), in contrast, require
larger modiﬁcations.

• Diﬀerent installations of the same Web application can
easily syndicate arbitrary content without the need to
adopt interfaces, content representations or protocols.
• Triplify facilitates the creation of custom-tailored search
engines targeted at certain niches, e.g. searching for
speciﬁc content in various blogs, wikis, or forums.

WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data629Approach

Dartgrid [17]
Hu et al. [11]
Tirmizi et al. [16]
Li et al. [12]
DB2OWL[10]
RDBToOnto [6]
Sahoo et al. [15]
R2O[13]
D2RQ[4]
Virtuoso RDF View [5, 9]
Triplify

Automation Domain or database Access
(a)
Manual
Auto
Auto
Semi
Semi
Semi
Manual
Manual
Auto
Semi
Manual

semantics-driven (b) paradigm (c)
Domain
Both
DB
DB
DB
DB+M
Domain
DB+M
DB+M
DB+M
Domain

Mapping
language (d)
Visual Tool
intern
FOL
n/a
R2O
Visual Tool
XSLT
R2O

SPARQL
ETL
ETL
ETL
SPARQL
ETL
ETL
SPARQL
LD, SPARQL D2RQ
SPARQL
LD

own
SQL

Domain reliance
(e)
dependent
dependent
general
general
general/dependent
general
dependent
dependent
general
general
general

Table 4: An integrated overview of mapping approaches. Criteria for classiﬁcation were merged, some
removed, ﬁelds were completed, when missing. DB+M means that the semi-automatic approach can later
be customized manually

Ultimately, a more widespread use of Data Web technolo-
gies will counteract the centralization we faced through the
erection of huge data silos of the Web 2.0 and will lead to
an increased democratization of the Web.

Future Work. Triplify deliberately does not support
SPARQL queries. Adding SPARQL support to Triplify would
raise questions about security and scalability among Web
application developers and administrators. On the other
hand, we think that employing SQL as a mapping language
to RDF and ontologies is a very powerful approach and it will
be hard for newly developed mapping languages to achieve
similar ﬂexibility. Hence, we envision some extensions to
Triplify such as a more external annotation of the SQL views
in order to allow optionally SPARQL processing on Triplify
endpoints. We also aim at improving the OpenStreetMap
data usage scenario, e.g. by better interlinking the data with
other Linked Data datasets and providing a proper ontology
for querying.
8. ACKNOWLEDGMENTS

We thank Elias Theodorou for contributing to the Triplify
integrations. We thank the members of the W3C RDB2RDF
XG for numerous discussions – in particular Satya Sahoo and
Wolfgang Halb for editing the literature survey, providing
valuable input for the related work section.
9. REFERENCES
[1] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann,

R. Cyganiak, and Z. G. Ives. DBpedia: A nucleus for
a web of open data. In ISWC/ASWC (2007), LNCS
(4825), pages 722–735. Springer, 2007.

[2] T. Berners-Lee. Design issues: Linked data, 2006.

http://www.w3.org/DesignIssues/LinkedData.html.

[3] C. Bizer, R. Cyganiak, and T. Heath. How to publish

linked data on the web, 2007. http://sites.wiwiss.fu-
berlin.de/suhl/bizer/pub/LinkedDataTutorial/.

[7] G. Cheng and Y. Qu. Term dependance on the

semantic web. In Proceedings of the International
Semantic Web Conference (ISWC), 2008.

[8] L. Ding and T. Finin. Characterizing the semantic

web on the web. In Proceedings of ISWC 2006,
Athens, GA, USA, November 5-9, 2006, volume 4273
of LNCS, pages 242–257. Springer, 2006.

[9] O. Erling and I. Mikhailov. RDF support in the

Virtuoso DBMS. In Proceedings of the 1st Conference
on Social Semantic Web, volume P-113 of GI-Edition
- Lecture Notes in Informatics (LNI), ISSN
1617-5468. Bonner K¨ollen Verlag, September 2007.

[10] R. Ghawi and N. Cullot. Database-to-ontology

mapping generation for semantic interoperability,
2007. Third International Workshop on Database
Interoperability (InterDB), 2007

[11] W. Hu and Y. Qu. Discovering simple mappings

between relational database schemas and ontologies.
In Proceedings of ISWC/ASWC2007, Busan, South
Korea, volume 4825 of LNCS, pages 225–238, 2007

[12] M. Li, X. Du, and S. Wang. A semi-automatic

ontology acquisition method for the semantic web. In
W. Fan, Z. Wu, and J. Yang, editors, WAIM, volume
3739 of LNCS, pages 209–220. Springer, 2005.

[13] J. B. Rodr´ıguez, ´Oscar Corcho, and A. G´omez-P´erez.

R2o, an extensible and semantically based
database-to-ontology mapping language. SWDB, 2004.

[14] J. B. Rodr´ıguez and A. G´omez-P´erez. Upgrading

relational legacy data to the semantic web. In L. Carr,
D. D. Roure, A. Iyengar, C. A. Goble, and M. Dahlin,
editors, WWW, pages 1069–1070. ACM, 2006.

[15] S. S. Sahoo, O. Bodenreider, J. L. Rutter, K. J.

Skinner, and A. P. Sheth. An ontology-driven semantic
mashup of gene and biological pathway information:
Application to the domain of nicotine dependence.
Journal of biomedical informatics, February 2008.

[4] C. Bizer and A. Seaborne. D2RQ - treating non-RDF

[16] S. H. Tirmizi, J. Sequeda, and D. P. Miranker.

databases as virtual RDF graphs. In ISWC2004
(posters), November 2004.

Translating sql applications to the semantic web. In
DEXA, volume 5181 of LNCS, pages 450–464. 2008

[5] C. Blakeley. Rdf views of sql data (declarative sql

[17] Z. Wu, H. Chen, H. Wang, Y. Wang, Y. Mao, J. Tang,

schema to rdf mapping), 2007.

[6] F. Cerbah. Learning highly structured semantic

repositories from relational databases. In ESWC,
volume 5021 of LNCS, pages 777–781. Springer, 2008.

and C. Zhou. Dartgrid: a semantic web toolkit for
integrating heterogeneous relational databases. In
Semantic Web Challenge at 4th International
Semantic Web Conference, Athens, USA, NOV 2006.

WWW 2009 MADRID!Track: Semantic/Data Web / Session: Linked Data630