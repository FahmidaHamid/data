Personalized Recommendation on Dynamic Content

Using Predictive Bilinear Models

Wei Chu
Yahoo! Labs.

2821 Mission College Blvd

Santa Clara, CA 95054

chuwei@yahoo-inc.com

Seung-Taek Park

Yahoo! Labs.

2821 Mission College Blvd

Santa Clara, CA 95054

parkst@yahoo-inc.com

ABSTRACT
In Web-based services of dynamic content (such as news arti-
cles), recommender systems face the diﬃculty of timely iden-
tifying new items of high-quality and providing recommen-
dations for new users. We propose a feature-based machine
learning approach to personalized recommendation that is
capable of handling the cold-start issue eﬀectively. We main-
tain proﬁles of content of interest, in which temporal charac-
teristics of the content, e.g. popularity and freshness, are up-
dated in real-time manner. We also maintain proﬁles of users
including demographic information and a summary of user
activities within Yahoo! properties. Based on all features
in user and content proﬁles, we develop predictive bilinear
regression models to provide accurate personalized recom-
mendations of new items for both existing and new users.
This approach results in an oﬄine model with light computa-
tional overhead compared with other recommender systems
that require online re-training. The proposed framework is
general and ﬂexible for other personalized tasks. The supe-
rior performance of our approach is veriﬁed on a large-scale
data set collected from the Today-Module on Yahoo! Front
Page, with comparison against six competitive approaches.

Categories and Subject Descriptors
H.1.0 [Models and Principles]: General; H.3.3 [Information
Search and Retrieval]: Information ﬁltering; H.3.5 [Online
Information Services]: Web-based services

General Terms
Algorithms, Experimentation, Design, Performance

Keywords
Personalization, Dynamic Features, Bilinear, Regression, Rank-
ing, User and Content Proﬁles, Recommender Systems

1.

INTRODUCTION

The Internet provides an unparalleled opportunity for or-
ganizations to deliver digital content to their visitors instan-
taneously. Content consumers usually have short attention
span, while possibly a large number of content venders. The

Copyright is held by the International World Wide Web Conference Com-
mittee (IW3C2). Distribution of these papers is limited to classroom use,
and personal use by others.
WWW 2009, April 20–24, 2009, Madrid, Spain.
ACM 978-1-60558-487-4/09/04.

biggest challenge most organizations face is not lack of con-
tent, but how to optimize the content they already own by
identifying the most appropriate customers at the right time.
Personalized recommendation has become a desirable fea-
ture of e-business Web sites to improve customer satisfaction
and customer retention [8], by tailoring content presentation
to suit an individual’s needs rather than take the traditional
“one-size-ﬁts-all” approach.

Personalized recommendation involves a process of gath-
ering and storing information about site visitors, managing
the content assets, analyzing current and past user inter-
active behavior, and, based on the analysis, delivering the
right content to each visitor [31]. Search engines help in-
dex available content assets and return relevant information
to users, if the users are looking for something speciﬁc that
can be summarized as a keyword query. However, in many
cases, users are looking for things might interest them, but
do not have concrete desideration in mind when browsing a
Web site. In such cases, it is a recommendation engine that
presents the most plausible content that the user may want,
based on her interests as demonstrated by her past activities.
Traditional recommendation engines could be distinguished
into three diﬀerent approaches: rule-based ﬁltering, content-
based ﬁltering, and collaborative ﬁltering [32]. Rule-based
ﬁltering creates a user-speciﬁc utility function and then ap-
plies it to the items under consideration. This approach
is closely related to customization, which requires users to
identify themselves, conﬁgure their individual settings, and
maintain their personalized environment over time [21]. It
is easy to fail since the burden of responsibility falls on the
users. Content-based ﬁltering generates a proﬁle for a user
based on the content descriptions of the items previously
rated by the user. The main drawback of this approach is
the recommended items are similar to the items previously
seen by the user. Mladenic [30] provided a survey of the com-
monly used text-learning techniques in the context of con-
tent ﬁltering. Collaborative ﬁltering (CF) is one of the most
successful and widely used recommender system technology
[37]. CF analyzes users’ ratings to recognize commonalities
between users on the basis of their historical ratings, and
then generates new recommendations based on like-minded
users’ preferences. CF provides a good solution to “a closed
world”, where overlaps in ratings across users are relatively
high and the universe of content items is almost static.

In many scenarios, such as news ﬁltering [15], where the
content universe changes rapidly and signiﬁcant portion of
users are new users, CF will suﬀer from the cold-start prob-
lem. Several hybrid recommender systems have been devel-

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems691oped to tackle the cold-start problem by combining two or
more recommendation techniques. The inability of CF to
recommend new items is commonly leveraged by coupling
with a content-based ﬁltering, such as in Fab [3], a recom-
mender system for the Web content. Burke [10] provided a
comprehensive analysis of approaches to generating hybrid
recommendation engines.

Although hybridization can alleviate some of the weak-
nesses associated with CF and other recommendation tech-
niques, there are still a few important issues that haven’t
been well studied in literature:

• Dynamic Content: We consider not only the item set
undergoes insertions and deletions frequently, but also
the content value and then the appraisement from users
are changing rapidly as well. For example, the lifetime
of breaking news on the Internet is usually a couple of
hours, and the value of the news (such as click through
rate) is decaying temporally as people get to know it,
see Figure 3(a) for an example. Traditional recom-
mender systems usually treat users’ feedback static, so
that feedback on the same items given at diﬀerent time
stamps is still comparable. This assumption doesn’t
hold on dynamic content. Rebuilding the model on
very recent data is typically an expensive task, and
tends to lose long-term interests of users. On dynamic
content, recommender systems always face the cold-
start problem for new items.

• Users with Open Proﬁles: A typical user proﬁle in a
CF system is a list of ratings on items of interest. In
practice, we can legally collect user information to de-
velop a general proﬁle for a site visitor [19], which is
not limited to the content universe only. The gen-
eral proﬁle may include declared demographic informa-
tion, activities on relevant sites, consumption history,
etc. The objective is to provide valuable insight into
users’ preferences, interests and wants. Clearly, the
general proﬁle can help tackle the cold-start problem
on new users. Demographic recommender systems, e.g.
[34], aim to segment users based on personal attributes
and make recommendations according to demographic
classes. However, the history of user ratings and con-
tent features haven’t been jointly exploited to form
“people-to-people” correlation.

In this paper, we propose a machine learning approach
to handling both issues in personalized recommendation.
The key idea is to maintain proﬁles for both content and
users, and build a feature-based bilinear regression model
to quantify the associations between heterogeneous features
by ﬁtting the historical interactive data. The feature-based
predictive model can then be applied to recommending new
and existing items for both new and existing users.

The goodness of dynamic content over time is a crucial
ingredient in content management. We insert dynamic fea-
tures, such as instantaneous click-through rate (CTR) to in-
dicate temporal popularity, into the content feature set. We
continuously update these dynamic features in the delivery
phase by aggregating users’ interactions over content items
in a real-time manner. We demonstrate that maintaining
content proﬁles with dynamic features is an eﬀective strat-
egy to overcome the cold-start problem on dynamic content.

Figure 1: An illustration of unfolding a multi-
dimensional event.

The open proﬁles of users provide valuable information
about user preferences and interests that helps in recom-
mending content for new users. Historical feedback given by
users on content of interest, such as ratings or click stream,
directly reveals users’ opinion on the content universe. The
bilinear regression models we proposed can discover associa-
tion patterns between the general user proﬁles and the con-
tent features by exploiting the interactive data (the typical
user proﬁle in traditional CF). The established associations
are then applied to evaluating individualized appraisement
over currently available items for accurate and prompt per-
sonalized recommendations in real time.

This work is motivated by a personalized content opti-
mization task for the Today-Module on Yahoo! Front Page.
The eﬀectiveness of the bilinear models is veriﬁed on a large-
scale real-world data set collected in the application. This
approach results in an oﬄine model except online tracked
dynamic features in content proﬁles. The computational
overhead in online recommendation is minor compared with
recommender systems that require online re-training. The
framework is general and ﬂexible, which can be adapted to
other personalized tasks.

The paper is organized as follows: We introduce data rep-
resentation in Section 2, which includes content proﬁling,
user proﬁling and interactive feedback; In Section 3 we de-
scribe a family of probabilistic bilinear models in detail that
covers training algorithms and further discussions on poten-
tial capabilities; We review related work in Section 4; We re-
port the experimental results on the data set collected from
the Today-Module with comparison against six competitive
alternatives in Section 5 and conclude in Section 6.

2. DATA REPRESENTATION

The observational data is naturally recorded in multi-
dimensional format. A logistic event is associated with at
least three types of objects, user × content × timestamp.
These multi-dimensional events can always be ﬂattened into
two-way form without loss of generality, see Figure 1 for an
illustration. In personalization on dynamic content, we can
treat content×timestamp as items of interest. Note that the
dimension of timestamp is usually not considered in tradi-
tional recommender systems. The ﬂattened dimensions form
a new content item space, in which features are extracted
for proﬁling. We generate and maintain three sets of data:
content proﬁles, user proﬁles, and interactive feedback on
content items of interest.
2.1 Content Proﬁles

When a content is either created or acquired, the informa-

User(cid:13)Item(cid:13)Timestamp(cid:13)User(cid:13)Item at(cid:13)timestamp(cid:13)WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems692tion related to the content, such as manufacturer, product
name and categories etc., constitutes an initial part of the
proﬁle. Continuous reﬁnement of the content proﬁle helps to
optimize the use of the content assets. In the delivery phase,
the content is delivered to users and interactions on the con-
tent are logged and analyzed, providing the ability to assess
the content popularity in a real-time manner. The content
popularity over time is a crucial ingredient in content man-
agement, since the commercial value of most content is vary-
ing or decaying temporally, especially for breaking news.

We consider generalized content items here, which are re-
deﬁned with both temporal characteristics and other condi-
tions. In a content proﬁle, there are at least two groups of
features:

• Static descriptors: Such as categories, manufacturer

name, title, bag of words of textual content etc.

• Temporal characteristics: Such as popularity, click-
through rate (CTR) and price at current time stamp
or the hours elapsed after content acquisition.

We can collect any features related to the content items.
For example, in search the items become webpages fused
with a query, and then joint features, such as contextual
co-occurrences, can be constructed.

Each content is represented as a vertical vector, denoted

by z, where z ∈ 4C and C is the number of content features.
2.2 User Proﬁles

The objective of collecting visitor information is to de-
velop a user proﬁle that describes a site visitor’s interests,
consumption history, and other descriptors important to the
site owner. A review of various user proﬁling techniques is
provided in [19]. Explicit proﬁling requests each visitor to
declare personal information, such as age, gender and occu-
pation, or to ﬁll out questionnaires that explicitly state their
preferences. Implicit proﬁling tracks the visitors’ behavior
and it is generally transparent to the visitor. Browsing and
purchasing patterns are the behaviors most often assessed.
The proﬁle combined with demographic, transaction, and
navigation data implicitly represents a user’s preferences and
recent interests.

The user feature space is spanned by legally usable fea-
tures. Each user is represented as a vertical vector, denoted

by x, where x ∈ 4D and D is the dimensionality of the user

feature space.

2.3

Interactive Feedback

In traditional collaborative ﬁltering (CF), the feedback
given by users on content of interest are used as user proﬁles
to evaluate commonalities between users. In our regression
approach, we separate the feedback from user proﬁles. The
feedback on content of interest is utilized as targets that
relate patterns in user features to content features.

Although the interactions between the users and the avail-
able items vary depending on the types of items involved,
we can always observe or measure some feedback from user
side. For example, a user may purchase a product or a ser-
vice after review, and even rate it later. For a content posted
on a Web page, a user may click to see more details. The
ratings and actions (click or not, purchase or not) provide

explicit feedback.1 There are a range of eﬀorts attempted to
measure various kinds of implicit feedback indicators from
linger time [13] to eye movements [36]. We focus on two
types of feedback in this paper:

• Continuous scores: most implicit feedback and ratings

can be converted as continuous scores.

• Binary actions: such as click or not, purchase or not

after reviewing an item.

We have collected three sets of data, including content
features, user proﬁles and interactive data between users and
items. Let index the i-th user as xi and the j-th content item
as zj, and denote by rij the interaction between the user xi
and the item zj. We only observe interactions on a small
subset of all possible user/item pairs, and denote by  the
set of observations {rij}.

3. BILINEAR REGRESSION MODELS

The user and content proﬁles provide timely descriptions
of users and items respectively. As the two feature spaces
are usually dichotomous, it is hard to apply the contextual
data mining techniques [9] here. However, the interactive
feedback reveals the correlations between user patterns and
content features. In this section, we describe a family of pre-
dictive bilinear models to discover pattern aﬃnities between
heterogeneous features. A set of weight coeﬃcients is in-
troduced to capture the pairwise associations between user
and content features. The parametric model is optimized by
ﬁtting the observed interactive feedback.
3.1 Bilinear Indicator

The bilinear models can be regarded as a special case in
the Tucker family [14], which have been widely applied in
machine learning applications. For example, Tenenbaum
and Freeman [39] developed a bilinear model for separat-
ing “style” and “content” in images, and recently Chu and
Ghahramani [11] derived a probabilistic framework of the
Tucker family for modeling structural dependency from par-
tially observed high-dimensional array data.

We deﬁne an indicator as a bilinear function of xi and zj

in the following:

sij =

xi,bzj,awab,

(1)

C:a=1

D:b=1

where D and C are the dimensionality of user and content
features respectively, zj,a denotes the a-th feature of zj and
xi,b denotes the b-th feature of xi. The weight variable wab is
independent of user and content features and quantiﬁes the
aﬃnity of these two factors xi,b and zj,a in interactions.2

The scalar sij is generated by mixing these basis vectors
with coeﬃcients given by the Kronecker product of xi and
zj. The indicator can be equivalently rewritten as

sij = w

(cid:62)

(zj ⊗ xi),

1Clicks and user purchase history are often considered as im-
plicit feedback in other collaborative ﬁltering literature since
these may not reﬂect real user preferences. For example, a
user may ﬁnd that an article is uninteresting after clicking
and reading it. However, we refer these actions as explicit
feedback since the user intentions of these actions are clearer
than those of other implicit feedback such as linger time and
eye movement.
2In practice, we also insert an individual-speciﬁc oﬀset for

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems693where w is a column vector of entries {wab}, and zj ⊗ xi
denotes the Kronecker product of xi and zj, a column vector
of entries {xi,bzj,a}. In matrix form, eq(1) can be rewritten
as

sij = x

(cid:62)
i W zj,

(cid:62)

(2)

(cid:62)
i,dzj,d,

(cid:62)
i Ws, x

a=1 ˜xi,azj,a.

(cid:62)
i,szj,s + ˜x

zj,d  = ˜x

where W denotes a D× C matrix with entries {wab}, which
describes a linear projection from the user feature space onto
the item feature space. The projected user proﬁle W(cid:62)xi
is aligned to the item features, denoted by ˜xi, which can
be explained as users’ preferences on item characteristics
accordingly. Then the indicator becomes a dot product, i.e.
sij = ˜x(cid:62)

To further examine the feature functions, let us distin-
guish dynamic features in the item feature vector as zj =

i zj =2C
 zj,s
zj,d , where zj,s denotes static features and zj,d denotes
sij =Dx

dynamic features that vary along time. The indicator sij
can then be rewritten as follows,

i WdE zj,s

where Ws and Wd denote the columns in W associated
with the static and dynamic item features respectively, and
˜xi,s and ˜xi,d denote the i-th user’s preferences on the static
and dynamic item features respectively.
Note that a user’s score sij on an item is composed of
three parts: ˜x(cid:62)
i,szj,s reﬂects long-term personal preferences
on content features learnt from historical activities; zj,d is
of dynamic characteristics, in our work which include tem-
poral popularity over the whole user population, i.e. article
quality; the tradeoﬀ between static personal preferences and
article quality is determined by ˜xi,d.
On cold-start with new items, the user’s preferences on
static item features ˜x(cid:62)
i,szj,s play an important role, as the
dynamic features couldn’t be accurately estimated at the
beginning stage. Similarly, on cold-start with new users,
recommendations are fully determined by the users’ pref-
erences on content features ˜xi, which are projected from
the user proﬁle xi.3 As we will show in the following, the
projection W can be learnt from the historical interactive
feedback.
3.2 Probabilistic Framework

We employ appropriate likelihood functions to relate the

indicator sij to diﬀerent types of observed interactions.

• Continuous scores with Gaussian measurement noise:

p(rij|sij) =

1√
2πσ

exp− (rij − sij)2

2σ2

 ,

where σ stands for the noise level.4
each user. The ﬁnal scalar is evaluated as

sij =

C:a=1

D:b=1

where µi ∈ 4 denotes a user-speciﬁc oﬀset. Here µi is used to

tradeoﬀ the user’s activity level, since some users are active
clickers while some are casual users.
3There is an implicit assumption that the user proﬁle is rich
enough to be transformed into preferences on item charac-
teristics. This condition can be easily satisﬁed in practice.
4In practice, the noise level could be preﬁxed at an appro-
priate value based on the signal/noise ratio.

xi,bzj,awab + µi,

∂L(w)
∂wab

=

∂ log p(rij|sij)

∂sij

xi,bzj,a,

(7)

• Binary actions with rij ∈ {−1, 1}. The logistic func-
tion is widely used as the likelihood function, which is
deﬁned as

p(rij|sij) =

1

1 + exp(−rijsij + γ)

,

where γ denotes a bias term, usually set at 1.

Given a set of w, the likelihood of observing the interac-

tive data can be evaluated by

p(rij|sij),

(3)

p(|w) =;ij

(4)

(5)

where the index ij runs over the observational set .
weight variables as a priori,

We also specify a standard Gaussian distribution over the

p(w) =

1√
2πς

where ς 2 is the variance.

exp−2ab w2
2ς 2  ,

ab

Based on the Bayes’ theorem, the posterior distribution
of w is proportional to the product of the likelihood and the
prior,

where p(w) is the prior distribution deﬁned as in eq(4) and

p(w|) ∝ p(|w) p(w).
p(|w) is the likelihood deﬁned as in eq(3).
3.3 Ofﬂine Modeling

In this section, we describe a training algorithm in batch
mode to estimate the posterior distribution of the weight

coeﬃcients p(w|) as in eq(5). For continuous scores with

Gaussian noise, the posterior distribution is still a Gaussian
due to the conjugate property. With non-Gaussian like-
lihood functions, the posterior distribution becomes non-
Gaussian. However we can always approximate the true
distribution by a Gaussian distribution. One of the most
popular techniques is the Laplace approximation [26], which
ﬁnds the mode of the true posterior as the approximate mean
and approximates the inverse covariance matrix by the Hes-
sian matrix, the second order derivatives with respect to the
weights at the mode point.

The mode, also known as the maximum-a-posteriori (MAP)

estimate, can be found by maximizing the joint probabil-

ity p(|w)p(w). The optimization problem is equivalent to

minimizing the negative logarithm of the joint probability,
i.e.

min

w

L(w) =

log p(rij|sij),

(6)

where ς 2 plays a role of tradeoﬀ. The gradient with respect
to wab can be computed as follows,

w2

ab −:ij

1

2ς 2:ab
ς 2 −:ij

wab

and gradient-decent packages can then be employed to ﬁnd
the minimum. Note that the objective functional is convex
and the minimum is unique. The detailed formulations are
given in Table 1 and the gradient-descent algorithm is sum-
marized as in Table 2. Each objective/gradient evaluation
costs O(N CD), where CD is the size of w and N is the
size of the observed set . Note that matrix inverse can

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems694Table 1: The logarithm likelihood functions and the
ﬁrst-order derivatives.
∂ log p(rij|sij )

log p(rij|sij)

Target

Continuous

Binary

− (rij−sij )2
2 log(2πσ)
− log(1 + exp(−rijsij + γ))

− 1

2σ2

∂sij
sij−rij

σ2

rijp(−rij|sij)

Table 2: The gradient-descent algorithm for MAP.
1.
2. While objective/gradient evaluation at w is requested:

Initialize w = 0, given σ2 and ς 2

Compute the objective as in eq(6);
Compute the gradients for w as in eq(7);
Return the objective/gradients to the package.

3. Until the optimization package returns the ﬁnal w.

be applied directly to the case of continuous targets for an
solution, but the computational cost is O(N C 2D2 + C 3D3).
It is very expensive for the cases having a large number of
features.
3.4 Prediction

The MAP estimate, denoted as wMAP, is then applied to
new user/item pairs for prediction. For any pair of xi and
zj in test, the best guess of the indicator sij is determined
as follow,

ˆsij =

xi,bzj,awMAP

ab

,

(8)

C:a=1

D:b=1

is an entry of the MAP estimate wMAP.

ab

where wMAP
3.5 Discussions

In this section, we discuss model selection and some poten-
tials of the framework we proposed, such as online learning
and active learning.

3.5.1 Model Selection

The prior variance ς 2 is an important model parameter in
the regression framework. The most common approach in
practice to determine the best model setting is cross valida-
tion. In k-fold cross validation, the original training data is
randomly partitioned into several folds, whereas in our ap-
plication having time series of dynamical features we have
to split the training data by a temporal point into two folds,
usually with size ratio 2 : 1. Given a particular set of model
parameters, we run the training algorithm on the fold of
earlier data to estimate the weight coeﬃcients, and test the
resulting model on the left-out fold to obtain the validation
error. The predictive performance indicates the goodness
of the model parameter setting. We try grid search over a
set of parameter values to ﬁnd the optimal one on which we
observe the best performance on the validation data. The
optimal weight coeﬃcients in the regression model are ﬁ-
nally obtained by training on the whole training data set
using the best set of model parameters.

3.5.2 Online Learning and Active Learning

In this work we only focus on training an oﬄine model cou-
pled with dynamic features, whereas the probabilistic frame-
work we employed provides the capacity of online learning
as well. Assumed-density ﬁltering (ADF) is a one-pass, se-
quential method for computing an approximate posterior

distribution [17].
In ADF, observations are processed one
by one, updating the posterior distribution which is usually
approximated as a Gaussian before processing the next ob-
servation. The approximate posterior is found by minimiz-
ing KL-divergence to preserve a speciﬁc set of posterior ex-
pectations. Recently, Expectation Propagation [29] extends
ADF to incorporate iterative reﬁnement of the approxima-
tions, which iterates additional passes over the observations
and does not require corresponding with time of arrival as
in time series.

Learning could be made more eﬃcient if we can actively
select salient data points. Within the probabilistic regres-
sion framework, the expected informativeness of a new ob-
servation can be measured by the change in entropy of the
posterior distribution of the weight coeﬃcients after inclu-
sion of the candidate [24]. The new posterior distribution
with the inclusion of the unused sample can be approx-
imated as a Gaussian by ADF-like online learning algo-
rithms. Based on information-theoretical principles, the en-
tropy gain on the posterior distribution of weight variables
can then be applied as the criterion for candidate election.

4. RELATED WORK

Our work is closely related to adaptive news systems, one
of the most popular types of personalized Web-based service
[6]. The most relevant previous work to our study would
be the Google News recommender system [15], a content-
agnostic system which combines three diﬀerent algorithms
using a linear model to generate recommendations in News
domain. However, since the proposed approach is a pure
collaborative ﬁltering, it does not solve the cold-start prob-
lem for new users. Even though ratings from new users can
be updated in near real-time by gridifying their algorithm,
it still needs to wait until new users provide ratings or clicks
before making recommendations. Also, the reported results
are based on two heavy user data sets (top 5K heavy users
with 370K clicks and 500K users with 10M clicks), where
eﬀects of new and casual users haven’t been considered. In
our application of the Today-Module on Yahoo! Front Page,
40% of clickers are new clickers with no historical clicks, 82%
of clickers have less or equal to 5 historical clicks, 92% of
clickers have no more than 10 historical clicks as shown in
the Figure 3(b). Another key diﬀerence lies in that Google
News [15] is a content-agnostic system which doesn’t resort
to either content features or user information. YourNews
[2] allows users to customize their interest proﬁles through
a user model interface. The study on user behavior shows
the beneﬁt from customization but also cautions the down-
side on system performance. In our application, we build up
user and content proﬁles without any solicitation on users.
Newsjunkie [18] provided personalized news feeds for users
by measuring news novelty in the context of stories the users
have already read. Our content proﬁles can also maintain
dynamic features in addition to context novelty, such as pop-
ularity and freshness. Our model also leverages user proﬁles
to facilitate cold-start on new users.

Our work is also related to personalized search, though
the tasks are quite diﬀerent. Micarelli et al. [28] gave a nice
review on this direction. Personalized search builds models
of short-term and long-term user needs based on observed
user actions, which is able to satisfy the users better than
standard search engines based on traditional Information
Retrieval (IR) techniques. Speretta and Gauch [38] devel-

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems695oped user proﬁles from their query histories and used these
proﬁles to re-rank the results returned by an independent
search engine by giving more importance to the documents
related to topics contained in the user proﬁle. Ahn et al.
[2] designed the TaskSieve system that utilizes a relevance
feedback-based proﬁle for personalized search. Both systems
employ the traditional linear approach to combine personal
preferences and query relevance. The combined score is cal-
culated as αf (xi, zj)+(1−α) r(zj), where xi is a user proﬁle,
zj is a content item fused with the query and α is the trade-
oﬀ. There is a strong correspondence to the terms in eq(2).
By replacing the dynamic features of zj by the query rele-
vance r(zj) and implement f (xi, zj) in the parametric form
of the long-term preferences as in eq(2), our bilinear model
provides a ﬂexible framework to learn the personal prefer-
ence function and the tradeoﬀ term from the click stream in
a principled manner.

A personalized service may not be exactly based on in-
dividual user behaviors. The content of a website can be
tailored for a predeﬁned audience, based on oﬄine research
of conjoint analysis, without online gathering knowledge on
individuals for service. Conjoint analysis is one of the most
popular market research methodologies for assessing how
customers with heterogeneous preferences appraise various
objective characteristics in products or services. Analysis
of tradeoﬀs driven by heterogeneous preferences on bene-
ﬁts derived from product attributes provides critical inputs
for many marketing decisions, e.g. optimal design of new
products, target market selection, and pricing a product. In
very early studies [40], homogeneous groups of consumers
are entailed by the use of a priori segmentation. For ex-
ample, consumers are assigned to groups on the basis of
demographic and socioeconomic variables, and the conjoint
models are estimated within each of those groups. This is
closely related to demographic recommender systems [23,
34], in which recommendations are based on demographic
classes categorized by users’ personal attributes. However,
the criteria in the two steps are not necessarily related: one
is the homogeneity of customers in terms of their descrip-
tor variables and another is the conjoint preferences within
segments. Traditionally, conjoint analysis procedures are of
two-stage: 1) estimating a parametric function which rep-
resents customers’ preference at individual-level in terms of
user proﬁles, e.g. hierarchical Bayesian methods [25]; 2)
through clustering algorithms, grouping users into segments
where users share similar individual-level preferences. Jiang
and Tuzhilin [22] experimentally demonstrated both 1-to-
1 personalization and segmentation approaches signiﬁcantly
outperform aggregate modeling.

In the extreme cold-start setting with dynamic content
and a large amount of new users, traditional collaborative ﬁl-
tering methods cannot provide recommendation eﬀectively.
A number of hybrid methods, which combine information
ﬁltering and other collaborative ﬁltering techniques, have
been proposed, such as [12] of an online newspaper and the
Fab system [3]. Good et al.
[20] improved accuracy by
introducing personal agents, and Park et al.
[33] further
improved its performance in cold-start situations by adding
small number of artiﬁcial users who have rated all items.
However, this approach performs better only if a user has
rated a few items but does not solve the cold-start problem
[5] utilized social infor-
directly for new users. Basu et al.
mation in content-based ﬁltering. Melville et al.
[27] em-

Figure 2: A snapshot of the default “Featured” tab
in the Today Module on Yahoo! Front Page. There
are four articles displayed at footer positions. One of
the four articles is highlighted at the story position.

ployed a content-based predictor to enhance existing user
data, and then provided personalized suggestions through
collaborative ﬁltering. Basilico and Hofmann [4] developed
a framework that incorporates all available information by
using a suitable kernel or similarity function between user-
item pairs. Hybrid methods are especially useful when data
is sparse, for example in cold-start situations [35], but to
our best knowledge none of previous work has been inte-
grated with continuous online attributes, such as popularity
or freshness.

5. CASE STUDIES

In this section, we verify the capacity of the proposed bi-
linear models on a real-world application. We start with
an introduction of the problem settings in Yahoo! Today-
Module and describe the attributes we collected in user/content
proﬁling. We also deﬁne performance metrics to evaluate
predictive results and report experimental results with com-
parison to competitive approaches.
5.1 Yahoo! Today Module

Today-Module is the most prominent panel on Yahoo!
Front Page, which is also one of the most visited pages on the
Internet, see a snapshot in Figure 2. The default “Featured”
tab in Today Module highlights one of four high-quality ar-
ticles, mainly news, while the four articles are selected from
a daily-refreshed article pool curated by human editors. As
illustrated in Figure 2, there are four articles at footer po-
sitions, indexed by F1, F2, F3 and F4 respectively. Each
article is represented by a small picture and a title. One of
the four articles is highlighted at the story position, which
is featured by a large picture, a title and a short summary
along with related links. At default, the article at F1 is
highlighted at the story position. A user can click on the
highlighted article at the story position to read more details
if she is interested in the article. The event is recorded as
a story click. If a user is interested in an article at F2∼F4
positions, she can highlight the article at the story position
by clicking on the footer position. To draw visitors’ atten-
tion, we would like to rank available articles according to
visitors’ interests, and highlight the most attractive article
at F1 position.

It is diﬃcult to adopt a traditional collaborative ﬁlter-
ing algorithm such as user-user [7] or item-based [16] in the

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems696Today-Module. Retrieving historical ratings of users for sim-
ilarity evaluation in the online service is hard. Lifetime of an
article is very short (only a few hours) and old articles will
be pulled out of content pool regularly. Another diﬃculty is
that we always need to recommend new items and signiﬁcant
portion of users is taken by new users. As shown in Figure
3(b) and (c), 40% clickers in the test data are the ﬁrst time
clickers without any historical clicks, and on average 60%
articles are new everyday. Thus, traditional collaborative
ﬁltering methods suﬀer from the cold-start problem. Fur-
thermore, the article popularity is temporally decaying, see
Figure 3(a) for an example where CTR decreases to 1/6 of
its peak value at the end of the article’s lifetime. It is diﬃ-
cult to compare users’ feedback on the same article received
at diﬀerent time slots.
5.2 Data Collection

We collected events from a random bucket in July 2008.
In the random bucket, articles are randomly selected from
the content pool to serve users. An event records a user’s
action on the article at the story position, which is either
“view” or “click” encoded as −1 and 1 respectively. Note
that a user may click on the same article multiple times
but at diﬀerent time slots.5 In our approach, these binary
events are distinguishable, because a content item is deﬁned
by both the article and the time slot of the event of interest,
see Figure 1. This is a conceptual diﬀerence from traditional
approaches.

We collected about 40 million click/view events by about
5 million users from the random bucket before a certain time
stamp for training. We also collected about 0.6 million click
events after that time stamp for test.

The features of users and items were selected by “support”.
The “support” of a feature means the number of users hav-
ing the feature. We only selected the features of high sup-
port above a preﬁxed threshold, e.g. 10% of the population.
Then each user is represented by a vector of more than one
thousand categorical features, which include:

• Demographic information: gender (2 classes) and age

discretized into ten classes;

• Geographic features: about two hundred locations of

countries or U.S. States;

• Behavioral categories: about one thousand binary cat-
egories that summarize the user’s consumption behav-
ior within Yahoo! properties;

Each article is proﬁled by a vector of about one hundred
static features and a dynamic feature. The static features
include:

• URL categories: tens of classes inferred from the URL

of the article resource;

• Editor categories: tens of topics tagged by human ed-

itors to summarize the article content;

The dynamic feature is of estimated click-through rate (CTR)
at events of interest, which diﬀerentiates the same article at
diﬀerent time slots. We adapted the Kalman ﬁlter designed

5For anti-robot purpose, the number of clicks generated by
one user on the same article could be at most 1 within a
single time slot (e.g. 5 minutes).

Figure 3: (a) A typical pattern of article CTR; (b)
Historical click counts of clickers in test; (c) New
article percentage per day in test.

and implemented by our team [1] for CTR tracking, which
yields a good indicator of article quality and popularity tem-
porally. Note that other dynamic features, e.g.
freshness,
can be added into the content proﬁles as well.

√

Categorical features are encoded as binary vectors with
non-zero indicators. For example, “gender” of two classes is
translated into two binary features, i.e., “male” is encoded as
[0, 1], “female” is encoded as [1, 0] and “unknown” is [0, 0].6
As the number of non-zero entries in these binary feature
vectors varies, we further normalized each vector into unit
length, i.e., non-zero entries in the normalized vector are
replaced by 1/
k, where k is the number of non-zero en-
tries. For user features, we normalized behavioral categories
and the remaining features (age, gender and location) sepa-
rately, due to the variable length of behavioral categories per
user. For article features, we normalized URL and Editor
categories together, and kept the CTR term (a real value) in-
tact. Following conventional treatment, we also augmented
each feature vector by a constant term 1. Each content item
is represented by a feature vector of 83 entries, while each
user is represented by a feature vector of 1193 entries.
5.3 Performance Metric

For each user in test, we computed predictive scores as in
eq(8) for all available articles at the time stamp of the event,
and ranked these articles in descending order according to
the scores. On click events, we measured the rank position
of the article being clicked by the user.

The ﬁrst metric we use is the number of clicks in each rank
position. A good predictive model should have more clicks
on the top-ranked positions and lesser clicks on the lower-
ranked position. In our application, we mainly concern the
performance on the top 4 positions.

We also proposed a simple utility function to quantify the

predictive performance, which is deﬁned as follows:

4:r=1

6The “unknown” category coded with zero entries has little
contribution to our linear models.

U =

Ur
2r−1 ,

(9)

20406080100120140160180Time Index (5 Minutes)CTR01 2 3 4 5 6 7 8 9 1000.10.20.30.40.5Number of ClicksNumber of Users (%)12345678900.20.40.60.8Time Index (One Day)New Articles (%)(a) (b) (c) WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems697where Ur denotes the percentage of clicks at the rank posi-
tion r in the whole test clicks.

5.4 Competitive Approaches

We implemented three sets of competitive approaches for

comparison purpose.

5.4.1 Aggregate Level (EMP)

As a baseline, we aggregated clicks and views per article
along time over the whole population, and ranked articles
by the global CTR only. The CTR online tracking was im-
plemented with the Kalman ﬁlter designed in [1], which has
yielded very strong performance in the product. In this ap-
proach, denoted by EMP, users are served with the same
content (the estimated most popular article) at the same
time stamp.

5.4.2

Segmentation Level (GM and SEG5)

Presupposing the existence of heterogeneity in users’ pref-
erences on articles, we carried out two conjoint analysis
methods on the Today-Module data: a) GM: We simply
grouped users into 6 clusters based on rules of their demo-
graphic variables (age and gender); b) SEG5: We estimated
users’ preferences on article features ﬁrst following the hier-
archical Bayes approach discussed by [25] and then clustered
homogeneous users with similar preferences by K-means.7
At segmentation level, we aggregated clicks and views per
article within user segments, and estimated the article CTR
within segments. A user will be served with the most popu-
lar article in the segment she belongs to. The CTR estima-
tion within segments suﬀers from low-traﬃc issues when the
number of segments is large. On this application, we tried
2, 5, 10 and 20 segments and found the performance of 5
segments is the best out of the four settings.

At both aggregate and segmentation level, we applied the
same online CTR tracking technique [1], which was also used
for updating the dynamic feature of article CTR at aggregate
level in content proﬁles.

5.4.3 Individual Level (IBCF, CB and CB+EMP)

We implemented three alternative individual level approaches

to compare against our bilinear models.

Item-based collaborative ﬁltering (IBCF).

We implemented a standard item-based collaborative ﬁl-
tering algorithm as in [16]. We update the item-item simi-
larity matrix in every hour by calculating cosine similarity of
two articles in the user click behaviors. When the algorithm
cannot recommend anything due to lack of user information
(i.e. new users), the algorithm rank candidate articles based
on the aggregate CTR.

Content-based ﬁltering (CB).

As we discussed in Section 5.2, each user xi and item
zj can be represented as a vector of categorical features
(without dynamic features) as xi = {xi,1, .., xi,D} and zj =
{zj,1, .., zj,C} respectively. We normalized user and item vec-
k=1 zj,k = 1.

tors into unit sum, i.e. 2D

k=1 xi,k = 1 and2C

7Monte Carlo sampling methods suggested in [25] cannot
be applied to our application. We resorted to the MAP
estimate via gradient descent methods. More details of seg-
mentation analysis will be reported in another paper.

For each vector, xi,k = 1|xi|
if the user has the k-th user-
feature and xi,k = 0 otherwise, where |xi| denotes the num-
ber of non-zero features in xi.

We maintained two aﬃnity matrices between heteroge-
neous features for click and view events respectively. For a
click/view event of xi and zj, the click/view aﬃnity between
the b-th user-feature and the a-th item-feature is accumu-
lated with xi,bzj,a. Note that the total contribution from a
single event is always one. For each pair of heterogeneous
features, we aggregated the contributions over all click/view
events in the training samples, and then calculated the aﬃn-
ity ratio between click and view, denoted as υab.

After we learnt the aﬃnities for all feature pairs, the pref-
erence score given by a user xi on an item zj is calculated as
b=1 xi,bzj,aυab which is analogous to our bilin-
ear model in eq(1) but is of diﬀerent feature normalization
and aﬃnity estimation.

cij =2C

a=12D

CB with online CTR (CB+EMP).

Since the estimated CTR of an item at time t, denoted
by CT Rj,t, provides tremendous insight on the quality of
the item at time t, we followed the hybrid approaches [10]
to combine CTR with the score from the content-based ap-
proach. Motivated by the combinations proposed in person-
alized search [38, 2], the ﬁnal score given by a user xi on an
item zj at time t was evaluated by (1 − α) cij + α CT Rj,t
where CT Rj,t denotes CTR of the article zj at time t, and
0 ≤ α ≤ 1 is a trade-oﬀ parameter determined by cross vali-
dation. We found α = 0.8 yields the best validation results.
5.5 Results

We implemented two versions of the probabilistic bilin-
ear models. One treated the feedback as continuous scores
(RG), whereas another took the click-or-not events as bi-
nary targets (LRG). We employed a gradient-descent pack-
age for the MAP estimate in the posterior distribution of the
weights as described in Section 3.3. The model parameter
ς 2 was determined by cross validation on [0.01, 0.1, 1, 10], as
discussed in Section 3.5.1. For each user in test, we com-
puted the expected score ˆsij as in eq(8) for all available
articles at the event, and ranked these articles in descending
order according to the scores.

In Table 3, we presented the portions of clicks at the top
16 rank positions of all the methods we have implemented
and computed the utility function deﬁned as in eq(9). We
also carried out Wilcoxon rank sum tests on the predicted
click ranks to evaluate the signiﬁcance of the diﬀerence be-
tween the LRG’s ranks and other methods’ predictions, and
reported the p-values in Table 3. A p-value close to zero
means the two predictive results are signiﬁcantly diﬀerent,
while near 1 means the diﬀerence is not signiﬁcant. Usually
we set the level of signiﬁcance at 0.05. LRG greatly out-
performs other methods on both click portions on the top
4 positions and the utility function. The hypothesis testing
results also show the improvement is signiﬁcant over all com-
petitors. GM, a rule-based segmentation, doesn’t result in
much improvement, compared with SEG5 that fuses proﬁles
and feedback for user segmentation.

CB relying on user/item static features only recommends
items similar to what a user has already rated, but it is hard
to capture new features that the user might like and to pro-
vide serendipity ﬁnding which collaborative ﬁltering can do.
CB+EMP, a combined approach, performs slightly better

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems6981
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

EMP
12.47%
9.93%
8.80%
8.00%
7.24%
6.85%
6.51%
6.08%
5.60%
5.20%
4.86%
4.46%
4.08%
3.60%
3.18%
2.82%

12.52%
10.06%
8.81%
7.99%
7.29%
6.83%
9.47%
6.03%
5.60%
5.17%
4.78%
4.43%
4.02%
3.57%
3.17%
2.9%

CB

IBCF

SEG5
13.08% 10.01% 8.09%
8.46% 7.87%
10.43%
7.80% 7.32%
9.02%
7.41% 7.34%
8.18%
7.39%
6.72% 6.74%
6.52% 6.63%
6.92%
6.56% 6.52%
6.40%
6.18% 6.12%
5.87%
5.58%
5.81% 6.13%
5.68% 6.41%
5.06%
5.29% 5.82%
4.67%
5.06% 5.22%
4.27%
4.89% 4.75%
3.82%
3.35%
4.73% 5.11%
4.21% 4.75%
2.99%
2.63%
4.15% 4.59%
2.41e-24
0.2157

0.1712

0.1477

12.49%
9.92%
8.81%
7.98%
7.26%
6.88%
6.47%
6.07%
5.68%
5.24%
4.75%
4.45%
4.04%
3.62%
3.18%
2.79%
3-e201
0.2065

9.08%
8.70%
8.15%
7.67%
7.29%
6.92%
6.58%
6.22%
5.84%
5.63%
5.38%
4.98%
4.48%
4.35%
4.18%
4.02%

0

0.1642

13.34% 13.45%
10.57% 10.60%
9.23%
9.28%
8.21%
8.28%
7.56%
7.5%
6.85%
6.98%
6.34%
6.40%
5.84%
5.90%
5.49%
5.37%
4.98%
4.98%
4.56%
4.55%
4.22%
4.16%
3.81%
3.74%
3.22%
3.32%
2.93%
2.85%
2.41%
2.47%
0.1022
0.2198

0.2209

1

Table 3: Click portions on predictive rank positions, along with Ranksum Test and Utility results.
LRG

LRG-CTR

CB+EMP

Rank Position

GM

RG

Ranksum Test

7.109e-212

1.145e-182

Utility

0.2063

0.2075

0

0

6. CONCLUSIONS

We proposed a feature-based bilinear regression frame-
work for personalized recommendation on dynamic content.
We quantiﬁed associations between attributes in user pro-
ﬁles and content proﬁles through learning a parametric bi-
linear regression function from interactive feedback. This
approach results in an oﬄine model but with the dynamic
features in content proﬁles, which provides the capacity of
recommending new high-quality content promptly and accu-
rately. In contrast to traditional recommender systems, our
approach also greatly alleviates the cold-start issue of rec-
ommending for new users, by leveraging interest patterns
in user proﬁles recognized from regression over historical in-
teractive feedback. We found the personalized predictive
models signiﬁcantly outperform six competitive approaches
at aggregate, segmentation or individual levels on the appli-
cation of Yahoo! Front Page Today-Module.

The potentials of the probabilistic bilinear regression frame-

work haven’t been fully exploited. It is straightforward to
implement online learning algorithms within the proposed
regression framework, which may be useful in tracing users’
short-term interests. Based on information-theoretical prin-
ciples, eﬃcient learning could be achieved by actively elect-
ing salient samples. The techniques we proposed for dy-
namic content can be adapted for personalized search as
well. We plan to investigate these directions in future work.

7. ACKNOWLEDGMENTS

We thank Raghu Ramakrishnan, Scott Roy, Deepak Agar-
wal, Bee-Chung Chen, Pradheep Elango, and Ajoy Sojan for
many discussions and helps on data collection.

8. REFERENCES
[1] D. Agarwal, B. Chen, P. Elango, N. Motgi, S. Park,

R. Ramakrishnan, S. Roy, and J. Zachariah. Online models
for content optimization. In Advances in Neural
Information Processing Systems 21, 2009.

[2] J. Ahn, P. Brusilovsky, J. Grady, D. He, and S. Y. Syn.

Open user proﬁles for adaptive news systems: help or

Figure 4: Lift over EMP (the baseline at aggregate
level) on click portion at the top 4 positions.

than EMP, but the improvement gained from the weighted
sum is insigniﬁcant. Traditional item-based collaborative
ﬁltering (IBCF) performs worse than EMP since the great
portion of users in our dataset are new or casual users who
do not click much. Note that 92% of clickers in our test
data have clicked no more than 10 articles, while Google
News [15] and other collaborative ﬁltering literatures only
consider a group of heavy users who have rated at least 20
items, often more than 100 items. We also measured the
performance of LRG after removing the dynamic CTR fea-
ture (LRG-CTR) to see its impact on performance. As seen
in the Table 3, removing the dynamic feature causes signif-
icant performance degradation that shows the CTR feature
is a crucial part in our application.

We presented the portion lift at the top 4 positions in
Figure 4. SEG5 also yields about 5% lift over the EMP
approach, and LRG gives 8% lift. RG also performs well but
is worse than LRG, as shown in Table 3. On this application
with click-or-not feedback, it is prudent to apply LRG on the
binary targets.

 	
WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems699harm? In Proceedings of the International World Wide
Web Conference, 2007.

[3] M. Balabanovic and Y. Shohan. Fab: Content-based,

collaborative recommendation. Communications of the
ACM, 40, 1997.

American Association of Artiﬁcial Intelligence, pages
439–446, 1999.

[21] R. Guttman, A. Moukas, and P. Maes. Agent-mediated
electronic commerce: A survey. Knowledge Engineering
Review, 13(3), June 1998.

[4] J. Basilico and T. Hofmann. A joint framework for

[22] T. Jiang and A. Tuzhilin. Segmenting customers from

collaborative and content ﬁltering. In Proceedings of the
International ACM SIGIR Conference, 2004.

[5] C. Basu, H. Hirsh, and W. W. Cohen. Recommendation as
classiﬁcation: Using social and content-based information in
recommendation. In Proceedings of the Fifteenth National
Conference on Artiﬁcial Intelligence, pages 714–720, 1998.

[6] D. Billsus and M. Pazzani. Adaptive news access. In
P. Brusilovsky, A. Kobsa, and W. Nejdl, editors, The
Adaptive Web — Methods and Strategies of Web
Personalization, volume 4321 of Lecture Notes in
Computer Science. Springer Berlin / Heidelberg, 2007.

[7] J. S. Breese, D. Heckerman, and C. Kadie. Empirical

analysis of predictive algorithms for collaborative ﬁltering.
In Proceedings of the Conference on Uncertainty in
Artiﬁcial Intelligence, pages 43–52, 1998.

[8] P. Brusilovsky, A. Kobsa, and W. Nejdl, editors. The

Adaptive Web — Methods and Strategies of Web
Personalization, volume 4321 of Lecture Notes in
Computer Science. Springer Berlin / Heidelberg, 2007.

[9] A. G. B¨uchner, J. G. Hughes, and D. A. Bell. Contextual

data and domain knowledge for incorporation in knowledge
discovery systems. In J. Wang, editor, Modeling and Using
Context, volume 1688, pages 831–832, 1999.

[10] R. Burke. Hybrid systems for personalized

recommendations. In B. Mobasher and S. S. Anand,
editors, Intelligent Techniques for Web Personalization.
Springer-Verlag, 2005.

[11] W. Chu and Z. Ghahramani. Probabilistic models for

incomplete multi-dimensional arrays. In Proceedings of the
12th International Conference on Artiﬁcial Intelligence
and Statistics, 2009.

[12] M. Claypool, A. Gokhale, T. Miranda, P. Murnikov,

D. Netes, and M. Sartin. Combining content-based and
collaborative ﬁlters in an online newspaper. In ACM SIGIR
Workshop on Recommender Systems, 1999.

[13] M. Claypool, P. Le, M. Wased, and D. Brown. Implicit

interest indicators. In the 6th International Conference on
Intelligent User Interfaces. ACM Press, 2002.

[14] R. Coppi and S. Bolasco, editors. Multiway data analysis.

North-Holland Publishing Co., Amsterdam, The
Netherlands, The Netherlands, 1989.

[15] A. Das, M. Datar, A. Garg, and S. Rajaram. Google news

personalization: scalable online collaborative ﬁltering. In
Proceedings of the International World Wide Web
Conference, 2007.

[16] M. Deshpande and G. Karypis. Item-based top-n

recommendation algorithms. ACM Transactions on
Information Systems (TOIS), 22(1):143–177, Jan 2004.

[17] B. J. Frey, R. Patrascu, T. Jaakkola, and J. Moran.

Sequentially ﬁtting inclusive trees for inference in noisy-or
networks. In Advances in Neural Information Processing
Systems 13. MIT Press, 2000.

[18] E. Gabrilovich, S. Dumais, and E. Horvitz. Newsjunkie:

providing personalized newsfeeds via analysis of
information novelty. In Proceedings of the International
World Wide Web Conference, 2004.

[19] S. Gauch, M. Speratta, A. Chandranouli, and A. Micarelli.

User proﬁles for personalized information access. In
P. Brusilovsky, A. Kobsa, and W. Nejdl, editors, The
Adaptive Web — Methods and Strategies of Web
Personalization. Springer Berlin / Heidelberg, 2007.

[20] N. Good, J. B. Schafer, J. A. Konstan, A. Borchers, B. M.

Sarwar, J. L. Herlocker, and J. Riedl. Combining
collaborative ﬁltering with personal agents for better
recommendations. In Proceedings of the Conference of the

population to individuals: does 1-to-1 keep your customers
forever? IEEE Transactions on Knowledge and Data
Engineering, 18(10):1297–1311, 2006.

[23] B. Krulwich. Lifestyle ﬁnder: Intelligent user proﬁling using

large-scale demographic data. Artiﬁcial Intelligence
Magazine, 18(2):37–45, 1997.

[24] N. Lawrence, M. Seeger, and R. Herbrich. The informative

vector machine. In Advances in Neural Information
Processing Systems 15. MIT Press, 2003.

[25] P. J. Lenk, W. S. DeSardo, P. E. Green, and M. R. Young.
Hierarchical Bayes conjoint analysis: Recovery of partworth
heterogeneity from reduced experimental designs.
Marketing Science, 15(2):173–191, 1996.

[26] D. J. C. MacKay. The evidence framework applied to

classiﬁcation networks. Neural Computation, 4(5):720–736,
1992.

[27] P. Melville, R. Mooney, and R. Nagarajan. Content-boosted

collaborative ﬁltering. In Proceedings of the Conference of
the American Association of Artiﬁcial Intelligence, 2002.

[28] A. Micarelli, F. Gasparetti, F. Sciarrone, and S. Gauch.

Personalized search on the World Wide Web. In
P. Brusilovsky, A. Kobsa, and W. Nejdl, editors, The
Adaptive Web — Methods and Strategies of Web
Personalization, volume 4321 of Lecture Notes in
Computer Science. Springer Berlin / Heidelberg, 2007.

[29] T. P. Minka. A family of algorithms for approximate

Bayesian inference. Ph.D. thesis, Massachusetts Institute
of Technology, January 2001.

[30] D. Mladenic. Text-learning and related intelligent agents:

A survey. IEEE Intelligent Agents, pages 44–54, 1999.

[31] B. Mobasher and S. S. Anand, editors. Intelligent

Techniques for Web Personalization, volume 3169 of
Lecture Notes in Artiﬁcial Intelligence. Springer-Verlag,
2005.

[32] O. Nasraoui. World Wide Web personalization. In J. Wang,

editor, Encyclopedia of Data Warehousing and Mining,
pages 1235–1241. Idea Group, 2005.

[33] S.-T. Park, D. M. Pennock, O. Madani, N. Good, and

D. DeCoste. Na¨ıve ﬁlterbots for robust cold-start
recommendations. In Proceedings of the ACM SIGKDD
Conference on Knowledge Discovery and Data Mining,
2006.

[34] M. J. Pazzani. A framework for collaborative,

content-based and demographic ﬁltering. Artiﬁcial
Intelligence Review, 13, 1999.

[35] A. Popescul, L. Ungar, D. Pennock, and S. Lawrence.

Probabilistic models for uniﬁed collaborative and
content-based recommendation in sparse-data
environments. In Proceedings of the Conference on
Uncertainty in Artiﬁcial Intelligence, pages 437–444, 2001.
[36] J. Saloj¨arvi, K. Puolam¨aki, and S. Kaski. Implicit relevance

feedback from eye movements. In Proceedings of the 15th
International Conference on Artiﬁcial Neural Networks,
pages 513–518, 2005.

[37] J. B. Schafer, K. J., and J. Riedl. Recommender systems in

e-commerce. In Proceedings of the ACM Conference on
Electronic Commerce, 1999.

[38] M. Speretta and S. Gauch. Personalized search based on

user search histories. In Web Intelligence. IEEE Computer
Society, 2005.

[39] J. B. Tenenbaum and W. T. Freeman. Separating style and

content with bilinear models. Neural Computation,
12:1247–1283, 2000.

[40] Y. Wind. Issue and advances in segmentation research.

Journal of Marketing Research, 15:317–337, 1978.

WWW 2009 MADRID!Track: Social Networks and Web 2.0 / Session: Recommender Systems700