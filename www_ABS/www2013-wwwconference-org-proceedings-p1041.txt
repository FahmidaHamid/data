collective intelligence, which aggregates the shared information from large crowds, is often negatively impacted by unreliable information sources with the low quality data. this becomes a barrier to the effective use of collective intelligence in a variety of applications. in order to address this issue, we propose a probabilistic model to jointly assess the reliability of sources and  nd the true data. we observe that different sources are often not independent of each other. instead, sources are prone to be mutually in uenced, which makes them dependent when sharing information with each other. high dependency between sources makes collective intelligence vulnerable to the overuse of redundant (and possibly incorrect) information from the dependent sources. thus, we reveal the latent group structure among dependent sources, and aggregate the information at the group level rather than from individual sources directly. this can prevent the collective intelligence from being inappropriately dominated by dependent sources. we will also explicitly reveal the reliability of groups, and minimize the negative impacts of unreliable groups. experimental results on real-world data sets show the effectiveness of the proposed approach with respect to existing algorithms.
