recommending phrases from web pages for advertisers to bid on against search engine queries is an important research problem with direct commercial impact. most approaches have found it infeasible to determine the relevance of all possible queries to a given ad landing page and have focussed on making recommendations from a small set of phrases extracted (and expanded) from the page using nlp and ranking based techniques. in this paper, we eschew this paradigm, and demonstrate that it is possible to e ciently predict the relevant subset of queries from a large set of mon-etizable ones by posing the problem as a multi-label learning task with each query being represented by a separate label. we develop multi-label random forests to tackle problems with millions of labels. our proposed classi er has prediction costs that are logarithmic in the number of labels and can make predictions in a few milliseconds using 10 gb of ram. we demonstrate that it is possible to generate training data for our classi er automatically from click logs without any human annotation or intervention. we train our classi er on tens of millions of labels, features and training points in less than two days on a thousand node cluster. we develop a sparse semi-supervised multi-label learning formulation to deal with training set biases and noisy labels harvested automatically from the click logs. this formulation is used to infer a belief in the state of each label for each training ad and the random forest classi er is extended to train on these beliefs rather than the given labels. experiments reveal signi cant gains over ranking and nlp based techniques on a large test set of 5 million ads using multiple metrics.
