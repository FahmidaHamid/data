a classi er that determines if a webpage is relevant to a speci ed set of topics comprises a key component for focused crawling. can a classi er that is tuned to perform well on training datasets continue to  lter out irrelevant pages in the face of changed content on the web? we investigate this question in the context of researcher homepage crawling. we show experimentally that classi ers trained on existing datasets for homepage identi cation underperform while classifying  irrelevant  pages on current-day academic websites. as an alternative to obtaining datasets to retrain the classi er for the new content, we propose to use e ectively unlimited amounts of unlabeled data readily available from these websites in a co-training scenario. to this end, we design novel url-based features and use them in conjunction with content-based features as complementary views of the data to obtain remarkable improvements in accurately identifying homepages from the current-day university websites. in addition, we propose a novel technique for  learning a conforming pair of classi ers  using mini-batch gradient descent. our algorithm seeks to minimize a loss (objective) function quantifying the di erence in predictions from the two views a orded by co-training. we demonstrate that tuning the classi ers so that they make  similar  predictions on unlabeled data strongly corresponds to the e ect achieved by co-training algorithms. we argue that this loss formulation provides insight into understanding the co-training process and can be used even in absence of a validation set.
