modern information retrieval interfaces typically involve multiple pages of search results, and users who are recall minded or engaging in exploratory search using ad hoc queries are likely to access more than one page. document rankings for such queries can be improved by allowing additional context to the query to be provided by the user herself using explicit ratings or implicit actions such as clickthroughs. existing methods using this information usually involved detrimental ui changes that can lower user satisfaction. instead, we propose a new feedback scheme that makes use of existing uis and does not alter user s browsing behaviour; to maximise retrieval performance over multiple result pages, we propose a novel retrieval optimisation framework and show that the optimal ranking policy should choose a diverse, exploratory ranking to display on the  rst page. then, a personalised re-ranking of the next pages can be generated based on the user s feedback from the  rst page. we show that document correlations used in result diversi cation have a signi cant impact on relevance feedback and its e ectiveness over a search session. trec evaluations demonstrate that our optimal rank strategy (including approximative monte carlo sampling) can naturally optimise the trade-o  between exploration and exploitation and maximise the overall user s satisfaction over time against a number of similar baselines.
