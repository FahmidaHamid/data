crowdsourcing is a new web phenomenon, in which a  rm takes a function once performed in-house and outsources it to a crowd, usually in the form of an open contest. designing ef cient crowd-sourcing mechanisms is not possible without deep understanding of incentives and strategic choices of all participants. this paper presents an empirical analysis of determinants of individual performance in multiple simultaneous crowdsourcing contests using a unique dataset for the world s largest competitive software development portal topcoder.com. special attention is given to studying the effects of the reputation system currently used by top-coder.com on behavior of contestants. we  nd that individual spe-ci c traits together with the project payment and the number of project requirements are signi cant predictors of the  nal project quality. furthermore, we  nd signi cant evidence of strategic behavior of contestants. high rated contestants face tougher competition from their opponents in the competition phase of the contest. in order to soften the competition, they move  rst in the registration phase of the contest, signing up early for particular projects. although registration in topcoder contests is nonbinding, it deters entry of opponents in the same contest; our lower bound estimate shows that this strategy generates signi cant surplus gain to high rated contestants. we conjecture that the reputation + cheap talk mechanism employed by topcoder has a positive effect on al-locative ef ciency of simultaneous all-pay contests and should be considered for adoption in other crowdsourcing platforms.
