duplicate urls have brought serious troubles to the whole pipeline of a search engine, from crawling, indexing, to result serving. url normalization is to transform duplicate urls to a canonical form using a set of rewrite rules. nowadays url normalization has attracted signi cant attention as it is lightweight and can be  exibly integrated into both the online (e.g. crawling) and the o ine (e.g. index compression) parts of a search engine. to deal with a large scale of websites, automatic approaches are highly desired to learn rewrite rules for various kinds of duplicate urls. in this paper, we rethink the problem of url normalization from a global perspective and propose a pattern tree-based approach, which is remarkably di erent from existing approaches. most current approaches learn rewrite rules by iteratively inducing local duplicate pairs to more general forms, and inevitably su er from noisy training data and are practically ine cient. given a training set of urls partitioned into duplicate clusters for a targeted website, we develop a simple yet e cient algorithm to automatically construct a url pattern tree. with the pattern tree, the statistical information from all the training samples is leveraged to make the learning process more robust and reliable. the learning process is also accelerated as rules are directly summarized based on pattern tree nodes. in addition, from an engineering perspective, the pattern tree helps select de-ployable rules by removing con icts and redundancies. an evaluation on more than 70 million duplicate urls from 200 websites showed that the proposed approach achieves very promising performance, in terms of both de-duping effectiveness and computational e ciency.
