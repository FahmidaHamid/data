this paper is concerned with the problem of learning a model to rank objects (web pages, ads and etc.). we propose a framework where the ranking model is both optimized and evaluated using the same information retrieval measures such as normalized discounted cumulative gain (ndcg) and mean average precision (map). the main di culty in direct optimization of ndcg and map is that these measures depend on the rank of objects and are not di erentiable. most learning-to-rank methods that attempt to optimize ndcg or map approximate such measures so that they can be di erentiable. in this paper, we propose a simple yet e ective stochastic optimization algorithm to directly minimize any loss function, which can be de ned on ndcg or map for the learning-to-rank problem. the algorithm employs simulated annealing along with simplex method for its parameter search and  nds the global optimal parameters. experiment results using ndcg-annealing algorithm, an instance of the proposed algorithm, on letor benchmark data sets show that the proposed algorithm is both e ective and stable when compared to the baselines provided in letor 3.0. in addition, we applied the algorithm for ranking ads in contextual advertising. our method has shown to signi cantly improve relevance in o ine evaluation and business metrics in online tests in a real large-scale advertising serving system. to scale our computations, we parallelize the algorithm in a mapreduce framework running on hadoop.
