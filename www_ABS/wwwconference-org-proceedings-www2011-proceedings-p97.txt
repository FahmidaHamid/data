we address the problem of query segmentation given a keyword query, the task is to group the keywords into phrases, if possible. previous approaches to the problem achieve reasonable segmentation performance but are tested only against a small corpus of manually segmented queries. in addition, many of the previous approaches are fairly intricate as they use expensive features and are dif cult to be reimplemented. the main contribution of this paper is a new method for query segmentation that is easy to implement, fast, and that comes with a segmentation accuracy comparable to current state-of-the-art techniques. our method uses only raw web n-gram frequencies and wikipedia titles that are stored in a hash table. at the same time, we introduce a new evaluation corpus for query segmentation. with about 50 000 human-annotated queries, it is two orders of magnitude larger than the corpus being used up to now.
