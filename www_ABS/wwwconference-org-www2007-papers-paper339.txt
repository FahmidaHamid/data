this paper proposes a random web crawl model. a web crawl is a (biased and partial) image of the web. this paper deals with the hyperlink structure, i.e. a web crawl is a graph, whose vertices are the pages and whose edges are the hypertextual links. of course a web crawl has a very special structure; we recall some known results about it. we then propose a model generating similar structures. our model simply simulates a crawling, i.e. builds and crawls the graph at the same time. the graphs generated have lot of known properties of web crawls. our model is simpler than most random web graph models, but captures the sames properties. notice that it models the crawling process instead of the page writing process of web graph models.
