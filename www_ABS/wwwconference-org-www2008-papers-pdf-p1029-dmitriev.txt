this  paper  considers  the  problem  of  identifying  on  the  web compound  documents  (cdocs)     groups  of  web  pages  that  in aggregate  constitute  semantically  coherent  information  entities. examples  of  cdocs  are  a  news  article  consisting  of  several  html pages, or a set of pages describing specifications, price, and reviews of a digital camera. being able to identify cdocs would be useful in intranet  search,  user many  applications navigation,  automated  collection  generation,  and information extraction. including  web  and in the past, several heuristic approaches have been proposed to identify cdocs [1][5]. however, heuristics fail to capture the variety of  types,  styles  and  goals  of  information  on  the  web,  and  do  not account for the fact that the definition of a cdoc often depends on the context. this paper presents an experimental evaluation of three machine  learning-based  algorithms  for  cdoc  discovery.  these algorithms  are  responsive  to  the  varying  structure  of  cdocs  and adaptive to their application-specific nature. based on our previous work  [4],  this  paper  proposes  a  different  scenario  for  discovering cdocs, and compares in this new setting the local machine learned clustering  algorithm  from  [4]  to  a  global  purely  graph  based approach  [3]  and  a  conditional  markov  network  approach previously  applied  to  noun  coreference  task  [6].  the results show that  the  approach  of  [4]  outperforms  the  other  algorithms, suggesting that global relational characteristics of web sites are too noisy for cdoc identification purposes.
