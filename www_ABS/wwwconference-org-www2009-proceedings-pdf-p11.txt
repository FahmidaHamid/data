given a terabyte click log, can we build an e cient and effective click model? it is commonly believed that web search click logs are a gold mine for search business, because they re ect users  preference over web documents presented by the search engine. click models provide a principled approach to inferring user-perceived relevance of web documents, which can be leveraged in numerous applications in search businesses. due to the huge volume of click data, scalability is a must. we present the click chain model (ccm), which is based on a solid, bayesian framework. it is both scalable and incremental, perfectly meeting the computational challenges imposed by the voluminous click logs that constantly grow. we conduct an extensive experimental study on a data set containing 8.8 million query sessions obtained in july 2008 from a commercial search engine. ccm consistently outperforms two state-of-the-art competitors in a number of metrics, with over 9.7% better log-likelihood, over 6.2% better click perplexity and much more robust (up to 30%) prediction of the  rst and the last clicked position.
