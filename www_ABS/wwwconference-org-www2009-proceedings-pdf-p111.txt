we present a probabilistic model for generating personalised recommendations of items to users of a web service. the matchbox system makes use of content information in the form of user and item meta data in combination with collaborative  ltering information from previous user behavior in order to predict the value of an item for a user. users and items are represented by feature vectors which are mapped into a low-dimensional  trait space  in which similarity is measured in terms of inner products. the model can be trained from di erent types of feedback in order to learn user-item preferences. here we present three alternatives direct observation of an absolute rating each user gives to some items, observation of a binary preference (like/ don t like) and observation of a set of ordinal ratings on a user-speci c scale. e cient inference is achieved by approximate message passing involving a combination of expectation propagation (ep) and variational message passing. we also include a dynamics model which allows an item s popularity, a user s taste or a user s personal rating scale to drift over time. by using assumed-density filtering (adf) for training, the model requires only a single pass through the training data. this is an online learning algorithm capable of incrementally taking account of new data so the system can immediately re ect the latest user preferences. we evaluate the performance of the algorithm on the movielens and net ix data sets consisting of approximately 1,000,000 and 100,000,000 ratings respectively. this demonstrates that training the model using the online adf approach yields state-of-the-art performance with the option of improving performance further if computational resources are available by performing multiple ep passes over the training data.
