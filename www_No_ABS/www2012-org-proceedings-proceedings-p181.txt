With the proliferation of web applications such as blogs, wikis, social networking sites, etc., users can not only consume news content but also share their opinions.
On many web sites such as Yahoo!
News, a user can post comments, reply to other comments, and even provide ratings to other comments.
As [19] notes, user experience on the internet is becoming a shared social experience through discussions, tweets, comments, etc.
In fact, [19] reports that around 25% of internet users have commented on a news article.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
Figure 1: Sample abusive comments that receive many thumbs-up ratings.
Depending on the news event, an article can receive either a few or thousands of comments.
For a user, it is simply not possible to read and rate all the comments.
To address this, web sites such as Yahoo!
News provide a number of options to order the comments for an article.
These include sorting by time, most replied, top rated, popular now, etc.
Of these measures, top rated and popular now do require some algorithmic computation on the ratings provided by users.
For instance, a user gives a comment a thumbs-up rating to indicate a positive vote and a thumbs-down to signal a negative vote.
The top rated comments are then the ones with the highest fraction of thumbs-up ratings.
Thus, crowdsourced ratings are used to measure the quality of a comment, and the whole system is moderated using crowdsourcing.
A comment from a user represents his/her view on a topic.
On sensitive topics, however, comments do appear to be highly biased.
One study [7] found that categories like war, crime, law, politics, society, and many others have a higher fraction of comments that get  ltered.
On many topics such as war and immigration, we often see hate speech directed at the people of another community.
In Figure 1, we show examples of this where the content is obviously abusive.
To a neutral (unbiased) person, such content would appear very o ensive.
Clearly, such comments should either be hidden or deleted.
Web sites do have a policy against posting abusive content, hate speech, spam, etc.
Currently, most of the automated systems rely on some form of human activity to iden-as spam, giving thumbs-down to comments, etc.
If the number of spam  ags or thumbs-down ratings is high then these comments are removed.
In [14], it was shown that crowd-based moderation is indeed e ective (on Slashdot) in a controlled environment.
However, due to human bias, o ensive comments may not always attract many thumbs-down ratings.
Even editors and moderators acknowledge that there are some gray areas, and people s perceptions of what constitutes distasteful material can vary [8].
To make matters worse, such comments often attract a large number of thumbs-ups (or thumbs-downs) from other biased users who easily outnumber the unbiased ones.
For example, in Figure 1, a majority of users have given the comments a thumbs-up rating.
Since such comments receive many thumbs-ups, they appear as the top rated comments, which is clearly undesirable.
Such comments should be hidden, or at the very least, should not appear at the top.
The main problem here lies with the metric that is used to compute top rated comments.
Simple statistical measures such as fraction of thumbs-up are not su ciently equipped to identify the bad comments or reduce their ratings.
They do not factor bias while calculating the rating for a comment.
Ideally, the opinion of a highly biased user should be given less weight, i.e., user reputation should be considered as well in the calculation.
Similar intuition underlies modern ranking algorithms like HITS [12] and PageRank [4], where the outlinks from a highly ranked page are considered more importance.
In this paper, we propose unsupervised, semi-supervised, and active learning algorithms for correcting the bias in comment ratings provided by users; thus, our algorithms compute the unbiased ratings of comments.
In our work, we only rely on the structural aspects, i.e., the user-comment graph containing who-rated-what.
We do not make use of the content of comments.
Our main contributions are as follows:
 unbiased comment rating in terms of one another leveraging the user-comment graph (Section 3).
We use  xed-point iteration to solve the mutually-recursive equations of bias and rating in time that is linear in the number of ratings.
We prove that our iterations converge to a unique  xed-point.
We also present an analytical solution to our problem and show a connection with randomized HITS [27].
number those from others.
To determine the unbiased ratings in these cases, we use semi-supervision (Section 4).
Speci cally, we obtain labels from human editors that re ect the ground truth for a small number of comments.
We use these comment labels in conjunction with the rating information provided by users to iteratively compute the unbiased ratings for unlabeled comments.
able active learning algorithm to select the comments to label (Section 5).
In each step, our active learning algorithm greedily selects the comment with the lowest expected risk as the next comment to label, and incrementally updates the risk for neighboring comments.
In the computation of expected error, we use the true rating computed for a comment (by our semi-supervised method) to approximate the probability of a thumbs up.
We devise e cient algorithms for incrementally updating the ratings and expected errors of comments in the neighborhood of a newly labeled comment.
life comments from Yahoo!
News (Section 7).
Even without supervision, our algorithm signi cantly outperforms simple baselines.
Furthermore, the accuracy of our predicted ratings increases as more comments are labeled.
Finally, our active learning scheme achieves high accuracy with 5 times fewer labeled examples compared to random labeling schemes.
We consider a model where users post comments on a news article expressing their views.
Other users have a choice to show their like/dislike through a thumbs-up/thumbs-down rating.
A user is not allowed to give more than one rating to a comment.
We model this system using a bipartite graph G, where users are on one side and comments are on the other side.
A directed edge from a user to a comment represents that the user has given a thumbs-up or thumbs-down.
Let wij denote the rating given by user i to comment j.
Here, wij   { 1, +1}, where wij = +1 corresponds to a thumbs-up rating and wij =  1 means a thumbs-down rating.
Note that a user will have only outgoing edges and likewise, a comment will have only inlinks.
A user may be biased on certain topics, which makes his/her ratings biased as well.
However, the user may behave normally on other topics.
This phenomenon of topicality is also pointed out by [8], especially on many sensitive topics such as immigration.
We say that a user is biased with respect to a topic if his/her opinion deviates signi cantly from the correct opinion on the comments belonging to that topic.
Therefore, we have di erent bias scores for a user for di erent topics.
The standard method used to compute the rating of a comment j is to take the mean of all ratings (avgi{wij}) the comment receives (at times, over a certain period).
However, such a method does not factor in bias.
Our objective in this paper is to develop techniques which also factor in bias while computing the rating of a comment.
We refer to such a rating as the unbiased rating.
We compute the bias for users and unbiased ratings for comments separately for each topic.
In this section, we present an unsupervised algorithm to compute the bias and unbiased rating of a comment.
We show a mutually recursive relationship between bias and unbiased rating, i.e., we write bias as a function of unbiased rating and unbiased rating as a function of bias.
We use  xed-point iteration to solve this mutually recursive equation.
Later, we propose a semi-supervised framework to further improve this approach by allowing some comments to be explicitly labeled.
As mentioned earlier, a user is considered to be biased if his/her ratings deviate considerably from the correct ratings.
then the function |wij   r(j)| is a good choice for capturing the bias of user i on comment j.
If the gap between the user rating and unbiased rating is more, then the function |wij   r(j)| will attain a high value re ecting a high level of bias.
On the other hand, if the gap is small, then the bias will be low.
Recall that a user gives either a thumbs-up or thumb-down rating.
Therefore, wij   { 1, 1}.
In contrast, we allow the unbiased rating r(j) to take any value between  1 and 1; thus, r(j)   [ 1, 1].
The function |wij   r(j)| can be equivalently written as (1   wij   r(j)).
We use this latter equivalent formulation throughout the paper.
The bias of a user i on comment j after normalization is given as: biasj(i) = 1   wij   r(j)
 (1) (cid:4) (cid:2) (cid:3) j:i j Equation (1) computes bias only for one comment.
In order to compute the bias of a user over all comments he/she has rated on a given topic, we simply take the mean.
Therefore, bias can be viewed as the expected error a user is likely to make on a comment.
Let do(i) denote the number of ratings given by a user i on a topic.
Then, bias is de ned as: bias(i) =
 2   do(i) 1   wij   r(j) (2) Observe that if a user gives many irrational ratings (wij (cid:3)= r(j)), then he/she will have a high bias.
Also, bias   [0, 1], where 0 signi es that a user is unbiased and 1 indicates that his/her opinion is highly biased.
Our de nition of bias has a remarkable similarity with the hubs vector of randomized HITS [27] (see Section 6.2).
In our framework, bias is the expected error a user is likely to make while rating a comment.
Related approaches [13, 17] that address bias in user ratings, and their followup work, de ne bias as the propensity to give high or low ratings.
Roughly, the bias of a user is viewed as the average in ation or de ation in ratings by the user.
However, such a de nition is not applicable in our comment rating environment since a user can arti cially keep his/her bias close to zero, while in reality, it is very high.
For example, consider a user who always gives ratings opposite to the unbiased ratings.
Using our method, such a user will have a high bias score, whereas with the schemes of [13, 17], it is possible for a user to keep his/her bias close to zero.
There is another noteworthy di erence which makes the above approaches unsuitable for computing the bias.
Consider a user who likes a particular movie.
Whenever a good comment about the movie appears, he/she is likely to give a thumbs-up rating, and if a negative comment appears, he/she is expected to give a negative rating.
This intuition conforms with our de nition of bias.
However, with the other de nitions, the user is expected to give either high ratings to both positive and negative comments about the movie, or low ratings to both.
We compute the unbiased rating of a comment by factoring user bias.
If a comment receives a rating from a highly biased user, then we give a lower weight to that user.
Intuitively, we ignore a user s opinion if it is frequently wrong.
If a user i is biased, then the quantity (1   bias(i)) is the con dence with which he/she gives the correct rating.
For instance, if (1   bias(i)) = 0, then the user is very likely to give an incorrect rating.
We modify the rating by factoring bias as: (cid:2) ij = wij(1   bias(i)) w (3) The above formulation ensures that if a user is unbiased, then his/her rating remains unchanged.
However, if he/she is biased, say bias(i) = 0.9, then we reduce the rating to 0.1 fraction.
To compute the unbiased rating r, we simply take the mean of all the modi ed ratings as follows: (cid:2) r(j) =
 di(j) i:i j (cid:2) ij w (4) (cid:5) Here, di(j) denotes the number of incoming links (ratings) comment j receives.
Note that r(j)   [ 1, 1].
Like bias, unbiased rating is similar to the authority vector of randomized HITS [27] (see Section 6.2).
i(1   bias(i)).
Observe that in Equation (4), we divide by the number of inlinks.
Instead of this simple mean, a weighted mean could be seen as a better option, i.e., dividing by However, this has a major drawback.
For example, consider two heavily biased users with bias = 0.99.
Let the users give ratings with a score 1 to the same comment.
Then, the rating with weighted mean is still 1.
However, with simple mean, we get a rating of 0.01 (close to neutral).
Since the two users are heavily biased, their opinion cannot be trusted, and so giving something close to a neutral rating is the best option   the weighted mean does not provide this.
We use  xed-point iteration to solve the mutually-recursive equations of bias and rating.
In Section 4.2, we show that this system converges to a unique  xed point, i.e., converges to a unique solution irrespective of initial conditions.
Let biast(i) and rt(j) denote the bias and rating, respectively, in iteration t. Then, rt+1(j) is computed as follows: wij(1   bias (cid:2) (cid:3) 1   wij   r j:i j t (i)) (5) (cid:4) t+1 (j) (6) t+1 r (j) =
 di(j) (cid:2) i:i j Similarly, we compute biast+1(i) as: bias(i) t+1 =
 2   do(i)
 Computing the bias of users, given the unbiased ratings of all comments, requires O(m) time, where m is the number of ratings.
Similarly, O(m) time is required to compute the unbiased ratings.
Thus, if k is the number of iterations needed to reach  xed point, then the complexity of the algorithm is O(km).
Usually the number of ratings provided by users is considerably less than all the possible ratings.
This makes the  xed point computation very e cient.
Later on, in Section 4.2, we also give a bound on the number of iterations required to guarantee a certain level of accuracy.
As discussed earlier, it is possible that a majority of the users who give ratings are biased on a topic.
Then, the above formulation may not work, and worse, it is likely to make other opinions look biased.
For example, let +1 be view.
If a majority gives the comment  1, then users who gave +1 will be deemed as biased, even though they give correct ratings.
In order to address this anomaly, we assume that we know the labels of a few comments apriori.
By doing so, we can ensure that unbiased users are not punished even though they are in small numbers.
Now, there will be many comments and users who are not a part of the labeled set.
By including the available unlabeled set as well for training, we let our semi-supervised algorithm learn ratings from both labeled and unlabeled data.
We use active learning (presented in Section 5) to identify the best comments to label.
Unlike traditional graph-based semi-supervised learning [3, 28, 29], we do not make any smoothness assumptions, i.e., neighboring nodes share similar labels, as it is not applicable on a user-comment graph.
Let L and U L be the two sets of labeled and unlabeled comments, respectively.
In general we assume that |L| (cid:4) |U L|.
We now de ne notation that will be used later.
Let L(j) represent the label of comment j, if j   L. Furthermore, let do L(i) denote the number of labeled ratings available for user i and likewise, do U L(i) denote the number of unlabeled ratings.
Therefore, do L(i) + do U L = do(i).
We now modify the expressions for unbiased rating and bias.
The expression for r is: (cid:5) L(j) if j   L otherwise (cid:2) ij (7) r(j) =
 di(j) i:i j w (cid:6) Bias can also be divided into two types: one from the labeled set and the other from the unlabeled set.
The new bias formulation is as follows: bias(i) =
 L(i) + do 2(    do (cid:2) + j:i j,j U L   (cid:3) U L(i)) 1   wij   r(j) (cid:7) (cid:3) (cid:2) (cid:4)(cid:8) j:i j,j L
 (cid:4) (8) Here, the  rst sum term computes the deviation for user i using labeled comments which he/she has rated.
Whereas the second term uses the ratings obtained from the unlabeled set.
Since |L| << |U L|, we give a higher disagreement cost to the labeled data, i.e., we give a higher weight to bias introduced due to the labeled data.
The parameter   > 1 helps to maintain the relative weight between labeled and unlabeled comments.
If the number of labeled comments is really small, then we may choose to have a higher value for  .
It is also helpful to choose a large   when a signi cant fraction of users are biased on a certain topic.
In this section, we show that the di erence between two iterations is bounded.
Later, this is used to show convergence.
We then prove the uniqueness of the system.
Theorem 1.
The di erence in bias of a node between two consecutive iterations t and t + 1 is bounded by an inverse exponential function of t: |bias t+1 (i)   bias t (i)|   Proof.
See Appendix B.
(cid:9) (cid:10)t .
(9) We use this bound to show convergence.
This bound also helps to determine the number of iterations required apriori.
(cid:5)  k

 k=x For some  > 0, let x be the smallest integer such that < .
Here, due to Theorem 1,  represents the maximum di erence in the bias values between the iteration x and any iteration after that.
Therefore, for any iterations p, q > x, we have : |bias p (i)   bias q (i)| <  (cid:2) k=x k

 <  The above sequence is a Cauchy sequence and thus converges.
In practice, we iterate until the di erence (L1 norm) between two consecutive iterations across all nodes becomes small, say  .
It can easily be shown that in order to get n within the   range, we are required to do at most log2   iterations.
We omit the proof due to space constraints.
In practice, we observed that the algorithm converges in fewer iterations (see Section 7.2.4).
In this section, we provide a proof (by contradiction) for the uniqueness of the system.
Let there be at least two values of bias which satisfy the bias equation.
Let bias1(i) and bias2(i) be two converged values of node i.
Further, let  (i) = bias1(i)   bias2(i) and M = maxp | (p)|.
Also, let i be the node for which we get M .
Now, if we can show that M is zero, then uniqueness is proved.
Theorem 2.
There exists a unique solution to the bias equation.
Proof.
(cid:11)(cid:11)(cid:11)(cid:11)(cid:11) (cid:11)(cid:11)(cid:11)(cid:11)(cid:11) (cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)
     = (cid:7) (cid:2) (cid:7) (cid:2) j:i j,j U L j:i j,j U L
 |bias (k)   bias     (cid:2) 2(    do L(i) + do U L(i)) 2(    do L(i) + do U L(i)) (cid:2)
 di(j) k:k j


 2(    do L(i) + do U L(i)) M   do U L(i)) L(i) + do 2(    do U L(i)) j:i j,j U L

 (cid:8)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11)
 (j))
 (j)   r wij(r (cid:3) (k)|(cid:4)        1 di(j)
 (cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11) (cid:2)
 k:k j         (cid:11)(cid:11)(cid:11)(cid:11)(cid:11)(cid:11) By de nition, M is a positive quantity.
So the above inequality only holds when M = 0.
In the semi-supervised approach, we supply labels to some of the comments.
We use an active learning based strategy to pick the comments for labeling.
Active learning has beled points when chosen interactively.
See [21] for a detailed survey and references therein.
Algorithm 1 ComputeNewRatings Input: User-comment graph G, existing ratings r, Labeled comments L, comment j, new label l for j, neighborhood hops k; Output: New ratings r for comments in Nk(j); (cid:5) We develop a technique based on empirical risk minimization [20, 29].
In each successive step, we pick a comment to label such that it minimizes the expected risk on the whole data.
We assume the true label L(j) for a comment j to be either +1 or  1.
For a rating, r(j), computed using the existing labeled and unlabeled data, we de ne a loss function as: loss(j) = (L(j)   r(j))/2 (r(j)   L(j))/2 if L(j) = 1 if L(j) = 1 (10) (cid:16) This is not the typical 0/1 loss function.
Instead we capture the normalized absolute distance between the computed rating r(j), and its true label L(j).
Notice that our loss function has exactly the same formulation as bias (see Section 3.1).
Now, the expected risk across all the comments 1, .
.
.
, n is given by: n(cid:2) (cid:2) Risk = i=1 l= 1,+1 p(L(j) =l )   loss(j) (11) Since the true label L(j) is unknown, we use r(j) to estimate the probability that L(j) has label l. We ensure that this probability lies in [0, 1] by shifting and scaling r(j).
p(L(j) = +1)   (1 + r(j))
 (12) Therefore, the estimated expected risk, puted as follows:  Risk can be com Risk = (cid:9) n(cid:2) n(cid:2) j=1 = j=1 (1 + r(j))
 1   r2(j)
   (1   r(j))
 + (1   r(j))
   (1 + r(j))
 (13) If we add a label to a comment, say j, then this will result in new values for bias and unbiased ratings for all nodes.
Thus, the estimated risk will also change.
Note that the estimated risk will be di erent for di erent labels (+1 or  1) for the comment j.
Let denote the estimated risk after adding comment j and label l. Again, since we don t know the true label l for j, we use r(j) to estimate the probability of L(j) = l and weigh the risk for each label l by the probability estimates.
Therefore, the estimated expected risk after adding comment j will be (1   r(j)) (1 + r(j)) +(j, 1)  Risk +(j,1) +(j,l) +j  Risk =  Risk +  Risk

 (14) We choose the comment k to label that minimizes the estimated expected risk as k = arg min j (  Risk +j ) +j  Risk To pick a comment to label, we need to  nd the expected for each comment j which involves computing risk unbiased rating and bias scores for all nodes in the graph using our semi-supervised algorithm.
Moreover, we run the (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) (cid:5) ; in G in G are not all in G be the subgraph of G comprising nodes in Nk(j); such that neighbors of all comments in L   X to their rating Let G Let X be the set of comments j of j Fix ratings r values in r; (cid:5) Fix rating r Run semi-supervised (iterative) algorithm on G ratings of comments in L   X   {j}  xed; (cid:5) (cid:5) Let r be the new ratings for comments j return {r (cid:5)   Nk(j)}; (cid:5) keeping (j) to l; in G ) :j (j ; (cid:5) (cid:5) (cid:5) +(j,l)  Risk algorithm twice to compute for each possible label l ( 1 and +1).
Thus, each iteration of the active learning procedure has time complexity O(mn), and it is very expensive to  nd a single comment to label.
Even if we use a matrix based procedure to update the risks (as in [29]), it is still very expensive with time complexity O(n2).
Also, the matrix based procedure requires the matrix to be inverted initially.
This motivates us to design a fast and scalable technique to approximate expected risk.
Here, we exploit the fact that the unbiased rating and bias score of a node depends primarily on the nodes in its close vicinity (see Section 6.2).
(cid:10)
 (cid:5) (cid:5) At the core of our scalable active learning algorithm is an extremely fast procedure for computing new ratings r (from current ratings r) when a single comment j is assigned a label l. Let Nk(j) denote the comments within k hops of comment j, and let G be the subgraph of G consisting of nodes in Nk(j).
In Section 6.2, we make the following key observation: a node s in uence decreases exponentially as the length of the path is increased.
As a result, the label assignment to j mainly a ects the ratings of comments in the immediate neighborhood of j.
Thus, we only need to compute new ratings for comments in Nk(j) (for a small k) which can be accomplished very e ciently by running our semi-supervised iterative algorithm on the much smaller graph G instead of the entire graph G. And these new ratings for comments in Nk(j) can in turn be used to e ciently approximate the (cid:5) +(j,l)  Risk .
Note also that each time a com-expected risk ment j is labeled, only the ratings for comments in its neighborhood Nk(j) change, and so we only need to re-estimate +(j(cid:2),l)  Risk (cid:5) for comments j the expected risk in its 2k-hop neighborhood N2k(j).
This is because the val-(cid:5)   N2k(j) could have changed since ues of only comments j these are the only comments whose k-hop neighborhoods have comments with new (changed) ratings.
+(j(cid:2),l)  Risk (cid:5) Algorithm 1 describes our procedure for computing the new ratings r of comments in the k-hop neighborhood of a comment j when its label is set to l. As mentioned earlier, this procedure is at the core of our active learning algorithm.
Since G is bipartite, parameter k is set to an even value,
 (cid:5) (cid:5) (cid:5) ; i=1 1 r2(i) =  Risk + (cid:5) (cid:5) Input: User-comment graph G, number of labels N , neighborhood hops k; Output: Set of labeled comments L with labels;
 (cid:5)n Run semi-supervised algorithm on G to compute ratings r;  Risk = S = {1, .
.
.
, n}; while |L| < N do for each j   S do )} =ComputeNewRatings(G, r, L, j, +1, k); +(j,1) )} =ComputeNewRatings(G, r, L, j, 1, k); (cid:5) +(j, 1) {r (j  Risk {r (j  Risk  Risk end for Select comment j with highest expected estimated risk  Risk L = L   {j}; r(j) = L(j) =l ; {r  Risk =  Risk + (cid:5) Set ratings r(j S = {j end while return {L(j) :j   L}; )} =ComputeNewRatings(G, r, L, j, l, k); (cid:5)   Nk(j); j(cid:2) Nk(j) (cid:5)   N2k(j)}   L; =  Risk +  Risk
 (1 r(j))  Risk and let l be the label for j; ) for comments j r(j)2 r(cid:2)(j)2 r(j)2 r(cid:2)(j)2 r(j)2 r(cid:2)(j)2 ; +(j, 1) j(cid:2) Nk(j) j(cid:2) Nk(j) (cid:5) ) = r (1+r(j)) +(j,1) : j (j (j = + +j +j ; ; ; (cid:5) (cid:5) (cid:5) (cid:5) (cid:5)



 (cid:5) (cid:5) (cid:5) for e.g., 4.
Now, in the subgraph G comprising nodes in Nk(j), there may be comment nodes j that are k hops from j such that edge i   j .
Since all the neighbors of j , our semi-supervised algorithm may not compute its rating precisely, and so we  x j  s ratings.
We also  x the ratings of labeled comments in L and comment j with label l.
is in G and i (cid:3)  G are not contained in G (cid:5) (cid:5) (cid:5) (cid:5) +j +(j,l)  Risk Our fast neighborhood-based active learning procedure is described in Algorithm 2.
The algorithm keeps track of  Risk.
It com-the total expected risk for all comments in putes for a comment j using Equation (14) where (cid:5) is estimated from  Risk and the new ratings r  Risk for comments in Nk(j) returned by ComputeNewRating.
Once the comment j with the highest value is labeled, say with label l, the new ratings r for comments in j s neighborhood are recomputed (by invoking Compute Risk is adjusted to re ect the new rat-NewRating) and (cid:5)   N2k(j)  Risk ings r .
Also, the whose neighborhoods overlap with j s neighborhood are recomputed since ratings of comments in j s neighborhood may have changed.
The procedure terminates once N comments have been labeled.
values for comments j  Risk +j +j (cid:5) (cid:5) Note that we can periodically rerun our semi-supervised algorithm on the entire graph G to ensure that our ratings and expected risk estimates for nodes remain fairly accurate.
To optimize even further, after computing the risk for all the nodes, we can select a batch of the top m comments with the highest risk to label.
In this section, we give the analytical solution to our unsupervised method.
This can also be generalized to the semi-supervised method.
i = diag{1/di(1), .
.
.
,1 /di(n)},  1 Let A be the adjacency matrix of the graph.
Also, let the inverse in-degree matrix be D  1 and likewise, we have the inverse outdegree matrix D o .
Assume a zero entry in case d(i) is zero.
Let (cid:5)b and (cid:5)r be the vectors for bias and unbiased rating.
The analytical solution of unbiased rating using Equations (5) and (6) is given as follows: (cid:5)r = (I   1


  1 o A)  1 o ) (cid:5)1  1 i A  1 i A  1 i A
  1





 (15)

  1 o A)  1 i AT D For completeness, we give a short proof of the existence of
  1 in Appendix C. We can similarly give an analytical solution to the bias vector (cid:5)b as follows:  1 o ) (cid:5)1 (16)

 o   D  1  1 o AD  1 i A  1 i A  1 i A
 (cid:5)b =  1




 )



 In this subsection, we examine the solution in depth and explore the connection with other works.
The  rst observa- 1 (cid:5) tion we make is that matrices D o A are simply the row-normalized (L0 or L1) forms of AT and A.
That j |aij|.
From here on, is, for any aij, we divide it with (cid:5)T and A we refer to D Rewriting (cid:5)r, we get  1 i AT and D  1 i AT and D  1 o A as A , respectively.
(cid:5)(cid:5) (cid:5)r = (I   1
 (cid:5)T  1 (cid:5)(cid:5) )
 (cid:5)y
 (17)  1 i AT D i AT   1  1

  1 o ) (cid:5)1 .
The matrix A (cid:5)T A (cid:5)(cid:5) Here, (cid:5)y = (D is a co-citation matrix with some normalization.
It means that if two users have given a similar score (+1 or  1) to many comments, then their co-citation score would be high.
However, if their opinions di er (they give di erent scores), then the co-citation score would be negative.
Note that when we typically refer to a co-citation matrix, we assume that matrix would have all non-negative entries.
However, this is not the case with A .
Entries of the principal eigenvectors of a non-negative co-citation matrix are also the motivation behind the famous HITS algorithm.
Therefore, our algorithm also resembles HITS closely, especially Randomized
 By choosing (1   )2 = 1/2 (see Section 5.1 in [27]), we can notice the close resemblance of Equation (15) with the authority vector (cid:5)a of Randomized HITS which is given by (cid:5)T A (cid:5)(cid:5) (cid:5)a = (I   1

 rowAcol)
  1(cid:5)k (18) Here, vectors (cid:5)y (Equation (17)) and (cid:5)k (Equation (18)) set prior weights for di erent nodes.
The rating vector (cid:5)r is similar to the authority vector.
A similar interpretation can be deduced for the bias vector, which relies on the co-reference matrix.
To gain more insight, we now approximate the matrix  1 by a generalization of the geometric series (cid:5)T A (cid:5)(cid:5) ) (cid:5)T (cid:5)(cid:5)
 )




 (cid:5)T A known as the Neumann series (see Section 4.1 from matrix algorithms [23]), as:

 + .
.
.
(19)
 )+(

 (cid:5)(cid:5)  1
 ) (cid:5)T (cid:5)T

 (cid:5)(cid:5) Notice that higher-order terms are higher-order co-citation )l]ij represents the co-citation matrices.
An element [(A score between nodes i and j using network paths of length l. We can observe that if the length of a path is increased by 1, its contribution decreases by 1/2, indicating that bias and unbiased rating scores of nodes are heavily in uenced by other nodes in their neighborhood.
Here, the  rst few terms provide a good approximation of the inverse matrix.
Category # votes # comments # thumbs-up # users Business (bs) Science (sc) US (us) Politics (pl) World (wl)







































 Table 1: Dataset description.
In this section, we give experimental evidence of the superiority of our techniques under di erent settings.
We then discuss the topicality of user bias, and  nally, we show the convergence rate of the algorithm.
The dataset consists of comments from Yahoo!
News.
Each comment belongs to a particular news article pre-categorized as politics (pl), business (bs), world (wl), science (sc), and US (us).
We use the terms category and topic interchangeably throughout this section.
While creating the dataset, we considered the votes of only frequent users (minimum   10 votes), and extracted comments with at least   10 votes from frequent users.
Therefore, it is possible to have users with less than 10 votes in the dataset.
Table 1 contains a description of the dataset for di erent categories   each category dataset comprises comments belonging to the category and users that rate these comments.
We collected editorial reviews on 456 comments from three editors across all categories.
Editors followed general editorial guidelines while rating a comment such as harms minors in any way, content that is unlawful, harmful, threatening, abusive, harassing, tortuous, defamatory, vulgar, etc.
We consider the mean rating (between 1 and +1) provided by the three editors as the true label of a comment.
We consider this editorial rating as the ground truth, and compare our techniques, namely unsupervised method, semi-supervised method with random labels, and semi-supervised method with active learning.
We also give a detailed comparison with the simple mean of user ratings, which is currently used in most systems.
We run the algorithms separately for each topic.
As discussed in Section 3.1, other works [13, 17] have different notions of bias which do not  t well in the comment-rating environment.
We present the results for a representative approach in Section 7.2.5.
We refer to the rating returned by the unsupervised and semi-supervised techniques as the unbiased rating, and the rating based on the mean (avgi{wij}) as the mean rating.
We compare these two ratings with the 456 available editorial ratings score (which we assume to be the ground truth), and compute the mean-square-error (MSE).
We also present the relative improvement of our algorithms over mean rating.
The relative improvement is the percentage decrease in MSE over mean rating.
In this subsection, we compare the results of our unsupervised technique with the mean rating.
We show the MSE of these two ratings in Table 2.
The second column depicts the MSE between unbiased ratings and the editorial ratings for di erent categories.
We can observe that even an unsupervised approach signi cantly reduces the error over the mean rating (in the third column).
The percentage decrease (fourth column) shows the relative improvement our algorithm has over the mean rating.
In all the categories, we have signi cantly outperformed mean rating with at least 35% improvement.
Observe that our algorithm has much better performance in categories such as science and US.
In later experiments, we only show the percentage improvement rather than the actual MSE numbers as it helps in easy comparison across categories.
Unbiased Rating Mean Rating % bs sc us pl wl Error




 Error




 decrease




 Table 2: Results for our unsupervised algorithm.
The unsupervised technique outperforms the baseline mean rating on all topics.
Semi-supervised Setting In the unsupervised setting, we ran the algorithm on nearly
 ments.
In the semi-supervised algorithm, we supply some labels and then test the algorithm.
However, even for semi-supervised learning, we require a meaningful number of labeled comments.
But 456 is too small for both training and testing.
Therefore, we created a smaller dataset for our semi-supervised algorithm.
We built a new dataset with these
 ments which received the most ratings constitute the rest (  90%).
This ensures that the resulting graph is well connected.
Note here that connectivity is important because running the algorithm on two disconnected components is the same as running on them separately.
Semi-supervised with random labels: In this setting, we compare the unsupervised and semi-supervised (with random labels) algorithms.
In the semi-supervised setting with random labels, we supply roughly 50% of the labels (representing   5% of the data) to the algorithm.
We test on all the topics and thus, we have their bias scores (computed by our unsupervised algorithm).
Therefore, we have  ve bias scores for each user.
We compute the minimum and maximum bias scores across  ve categories for each user.
The di erence between the minimum and maximum scores is a good indication of the topicality of bias.
Table 5 shows the di erence in bias for the top percentile of users.
Observe that there is a signi cant di erence in bias scores even for the 40th percentile.
Percentile Bias








 Table 5: Maximum bias di erence of a user across di erent categories.
We iterate until the L1 di erence between two consecutive iterations across all the nodes becomes very small.
We refer to this di erence as error, calculate it as follows: (cid:2) error = i |f t+1 (i)   f t (i)| (20) Here, function f t(i) represents the bias/unbiased rating of node i, and at iteration t. As we continue to iterate, we expect the error to decrease.
Earlier, in Theorem 1, we proved that the error between two consecutive iterations decreases exponentially as we perform more iterations.
In Figure 2, we show the errors of unbiased rating and bias after each iteration.
We can observe that the error has reduced signi cantly after a few iterations.
Theoretically, we expect the error to decrease from
 can observe that in practice the decrease is much faster than anticipated (  105 to 1 in 10 iterations).
the remaining 50% of the labels.
The relative improvement over the mean rating for di erent values of   is displayed in Table 3.
We can observe that with only 5% labeled comments, the performance of semi-supervised has improved sig-ni cantly over the unsupervised technique.
We obtained the best performance for   = 10.
For a category such as politics, we indeed see a dramatic improvement.
Another interesting comparison is between the unsupervised algorithm on the larger dataset (Table 2) and the smaller subset (Table 3).
Running the algorithm on the bigger dataset generally gave superior performance (except in category business).
The implication here is that the algorithm improves with more data.
Semi-supervised (random labels)   = 1   = 3   = 10 Unsupervised bs sc us pl wl



















 Table 3: Comparison between the unsupervised and semi-supervised algorithm.
Semi-supervised shows improvement, especially in category politics.
Semi-supervised with active learning: The goal of the active learning technique is to maximize performance with few labels.
Therefore, we let the algorithm pick 10% of the labeled data (that constitutes only 1% of all the comments).
Recall that the labeled data comprises 456 comments.
We compare our active learning scheme with the earlier semi-supervised algorithm with random labels (50% of the labeled data).
The results are shown in Table 4.
With just 1% labeled comments (chosen actively), the active learn ing algorithm outperforms random that uses 5% in most of the categories (except for politics).
Here, note that we restrict our active learning method to pick comments only from the available set of editorial ratings, and this may be sub-optimal.
In an ideal scenario, however, our algorithm can select any comment to label.
Therefore, we expect active learning to perform even better in practice.
Semi-supervised Active Learning Random labels labeled = 5% labeled = 1% bs sc us pl wl









 Table 4: Comparison between random labels and labels identi ed with active learning.
In general, active learning gives better performance with fewer labels.
We examine the user s bias across  ve categories.
We mentioned earlier that a user could be biased on certain topics.
This phenomenon of topicality is discussed in this subsection, as well as in some earlier work [8].
Figure 2: Error decreases exponentially with iterations.
Related approaches, e.g., [17] consider bias to be the propensity of a user to consistently give higher or lower ratings than others.
In this subsection, we consider one such representative approach [17] that uses an iterative algorithm to capture the above notion of bias.
Figure 3 shows the rating scores obtained by running the algorithm of [17] on the science category after 10 iterations.
Unfortunately, the algorithm did not converge (for any topic), returned ratings that are out of ness assumption, i.e., neighboring nodes share similar labels.
However, this assumption is not valid in our case.
A comprehensive survey of active learning schemes for selecting data to label can be found in [21].
There has been a limited amount of work on active learning in graphs [5, 9,
 sidered the bipartite graph similar to our model.
Existing results also assume smoothness on graphs.
Few heuristics such as [2, 18] also exist, which rely on  nding communities and picking a representative.
Our technique is based on empirical risk minimization [20, 29], and includes optimizations to incrementally compute risk for neighboring nodes each time a comment is labeled.
Thus, our active learning method can scale to large user-comment graphs.
In this paper, we proposed a semi-supervised learning technique for correcting the bias in user ratings.
We showed that our algorithm has a number of desirable properties such as convergence, uniqueness, and low computational cost.
Furthermore, we presented a scalable active learning algorithm that greedily chooses comments to label such that the overall expected risk is minimized.
Empirical results on real-life comments from Yahoo!
News show that our semi-supervised method, even without any labeled data, reduces error by as much as 48% over baseline measures.
With only 5% random labels, the error reductions increase further to as much as 64%.
Furthermore, with active learning we are able to achieve superior performance in most of the categories with only 1% labeled data.
An interesting direction for future work is to exploit the textual content of comments along with the structural information used by our algorithms to further improve the accuracy of computed ratings.
The authors are grateful to the reviewers for their helpful comments.
We thank Deepak Agarwal and Bee-Chung Chen for sharing the dataset, and Vineet Chaoji for the useful feedback.
