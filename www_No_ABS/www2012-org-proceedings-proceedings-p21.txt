Recommender systems have been indispensable nowadays due to the incredible increasing of information in the world, especially on the Web.
These systems apply knowledge discovery techniques to make personalized recommendations that can help people sift through huge amount of available articles, movies, music, webpages, etc.
Popular examples of Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
Figure 1: A toy example of the user-item matrix and subgroups.
Note that users and items are not necessarily adjacent in a subgroup.
such systems include product recommendation in Amazon1, music recommendation in Last.fm2, and movie recommendation in Movielens3.
Collaborative  ltering (CF) [1, 14, 30] is one of the most widely adopted and successful recommendation approaches.
Unlike many content-based approaches which utilize the attributes of users and items, CF approaches make predictions by using only the user-item interaction information.
These methods can capture the hidden connections between users and items and have the ability to provide serendipitous items [21], which are helpful to improve the diversity of recommendation.
The user-item interaction information can be either explicit or implicit [3].
Explicit interactions refer to users consciously expressing their preferences for items, e.g., discrete ratings for movies.
Implicit interactions can be any source of user-generated information, such as purchases, clicks, bookmarks, listening times, etc.
Usually, both explicit and implicit interactions can be recorded in a large but very sparse user-item matrix (Fig.1 shows an example).
Typical CF-based recommender systems associate a user with a group of like-minded users based on their preferences over all the items, and then recommends to the user those items enjoyed by others in the group.
The basic assumption is that users with similar behaviors (e.g., ratings) will have similar tastes on all the items.
However, we  nd that this assumption is not always tenable   two users having similar tastes on one item subset may have totally di erent tastes on another set.
Moreover, one user s interests are usually 1http://www.amazon.com 2http://www.last.fm 3http://www.movielens.org items.
So it is more natural to say a group of users are like-minded on a subset of items.
In this paper, we call a subset of items and a group of interested users as a user-item subgroup.
Fig.1 shows two subgroups.
Note that users and items are not necessarily adjacent in the matrix.
We expect that subgroups can help to capture similar user tastes on a subset of items.
Many clustering CF models utilize user clusters [29], item clusters [23], or co-clusters [9] to design CF algorithms.
In these models, each user or item can only belong to a single cluster.
In reality, it is more natural to assume that users (items) can join multiple clusters (subgroups), e.g., a user could like some movie topics and a movie could belong to multiple movie categories.
In this paper we extend traditional clustering CF models by co-clustering both users and items into multiple subgroups, and try to use them to improve the performance of CF-based recommender systems.
Many previous works focus on the prediction accuracy, but the low prediction error can not guarantee a good recommendation quality.
We focus on the top-N recommendation performance, which is more meaningful for real recommender systems.
The main contributions of this paper include: (1) we formulate the Multiclass Co-Clustering problem (MCoC) and propose an e ective solution to it for  nding user-item subgroups; (2) we propose an uni ed framework to combine subgroups with (any) pure CF models; (3) we provide top-N recommendation comparisons of many CF models (before and after using our framework) on three real data sets and make a systematic empirical analysis for the results.
The remaining of this paper is structured as follows.
Section 2.1 introduces CF and clustering CF models.
Section
 tal settings and results are discussed in section 4 and 5.
In section 6 we provide a conclusion.
Breese et al. [3] divide collaborative  ltering approaches into two classes: memory based and model based algorithms.
Memory based algorithms maintain the original setup of the CF task.
They use statistical techniques to build the neighborhood relationship for an active user, and then usually use a weighted sum of the ratings to prediction missing values.
This process is a bit like a ranking-analogue of nearest neighbor classi er, whereas the result is a real score but not a category label.
A general user-based formulation of the weighted sum scheme can be [3]: n(cid:2) pa,j = ra +   w(a, i)(ri,j   ri), (1) i=1 where n is the size of neighbors and ra, ri are the average ratings for the active user a and neighbor user i respectively.
Actually, The most important part for memory based algorithms is the similarity measurement.
Popular examples are pearson correlation (PC) [26], vector similarity and various extensions of them [30].
Saewar et al. [27] and Deshpande et al. [7] compute item-item similarities and obtain the predictions or top-N recommendation via item-based ways.
Model based algorithms, in contrast, utilize the collection of training data to learn a model  rst and then use it to make predictions instead of directly manipulating the original database.
The modeling process is always performed by machine learning or data mining techniques such as the Bayesian model [11], Regression-based model [32], Latent Semantic model [5, 12] and Clustering model [9, 23, 29, 31].
Although traditional CF models have been successful in many areas, they all have to face several critical problems: data sparsity, scalability and cold-start.
To alleviate the sparsity problem, many matrix factorization models are used, such as the Singular Value Decomposition (SVD) [28], Non-negative Matrix Factorization (NMF) [4,16], Maximum Margin Matrix Factorization (MMMF) [25] and Nonparametrix pPCA (NPCA) [33].
These models usually reduce the dimensions of the user-item matrix and smoothing out the noise information, which is also helpful to algorithm scala-bility.
Many evidence have shown that many matrix factorization models outperform traditional CF methods in prediction accuracy.
The cold-start situation is very common for real recommender systems, since they have many new users and new items in di erent time windows.
For a new user with only a few user-generated information, normal CF methods can not capture his (her) personal taste accurately.
An intuitive solution is to adding the content-based characteristics to collaborative models.
Typical works using content information include [2, 21].
Personality diagnosis (PD) [24] is a special kind of hybrid approach which combines memory based and model based CF methods and retains some advantages of both algorithms.
With the hot development of Web2.0, recently many new collaborative  l-tering algorithms are designed to integrate social or trust information [15, 18].
The most related model to this paper is the clustering collaborative  ltering model.
A cluster is a collection of data samples having similar features or close relationships.
For the collaborative  ltering task, clustering is often an intermediate process and the resulting clusters are used for further analysis [30].
In general, the clustering models can be classi ed into several di erent types.
We draw the sketch maps in Fig. 2.
The most straightforward way is to partition the users into distinct groups.
Sarwar et al. [29] cluster the complete user set based on user-user similarity and use the cluster as the neighborhood.
In contrast, O Connor et al. [23] use clustering algorithms to partition the set of items based on user rating data.
Unger et al. [31] propose to cluster users and items separately by variants of k-means and Gibbs sampling.
Users can then be re-clustered based on the number of items in each item cluster they rated, and items can similarly be re-clustered based on the number of user in each user cluster that rated them.
The above three algorithms are all one-sided clutering, either for users or items.
See Fig. 2(a) and Fig. 2(b), after some row (column) exchanges, we get the hard partitions of users (items).
Some other works consider of the two-sided clustering model.
Typical works are [9, 13].
We could see these methods as co-clustering (CoC) based CF models, since their clustering strategies are traditional co-clustering, e.g., the key idea of [9] is to simultaneously obtain user and item neighborhoods via co-clustering and generate predictions based on the average ratings of the co-clusters while taking the bi-(b) Item Clustering (c) Co-Clustering (d) Biclustering (e) Multiclass CoC Figure 2: Comparison of  ve clustering models for collaborative  ltering.
ases of the users and items into account.
See Fig. 2(c), after some row and column exchanges, we can get the distinct co-clusters with both users and items (we call them user-item subgroups in this paper).
One big limitation of the co-clustering approaches as well as the above one-sided clustering approaches is that, each user or item can be clustered into one single cluster only, whereas some recommender systems may bene t from the ability of clustering users and items into several clusters at the same time [1].
For example, in a movie web site, a user may be interested in multiple topics of movies and a movie can be liked by di erent groups of users from di erent aspects.
So the multiclass co-clustering (MCoC) model, which is shown in Fig. 2(e), is more reasonable.
It allows each user and item to be in multiple subgroups at the same time, i.e., subgroups may have some overlaps.
The last clustering type is the biclustering model (see Fig.2(d)) which is well studied in gene expression data analysis [6, 19].
It seems similar to MCoC   a bicluster is a subgroup of genes (users) and conditions (items).
But they are di erent for that biclustering usually  nds some maximum biclusters with low residue scores [6], i.e., biclusters always can not cover all rows and columns.
In this paper, we pay our most attention to the model of multiclass co-clustering.
Our primary goal is to  nd potential user-item interest subgroups  ooded in the large user-item matrix, and then use them to improve the performance of collaborative rec-ommender systems.
There are two main questions:
 ited information?
The only information we have is the user-item matrix, such as ratings for movies and listening times for music.
laborative  ltering methods and improve their performance?
We need a strategy to handle the cases that one user and one item can both belong to one, two (or more), or zero subgroups.
Our algorithm is to answer these two questions   we  nd user-item subgroups by solving a Multiclass Co-Clustering problem (MCoC) and propose an uni ed strategy to combine subgroups with existing collaborative  ltering methods.
Considering that this paper is just an exploration work   to explore a new improving space for collaborative recom-mender systems, we choose to pay our attention to the pure CF situation.
Suppose there are n users and m items, and the only information we have is the user-item matrix T   R n m where each element Tij is the preference of user i to item j.
We use ui to denote the i-th user and yj to denote the j-th item.
The goal is to simultaneously divide the users {u1,  , un} and items {y1,    , ym} into c subgroups.
This is a bit like the Co-Clustering (CoC) problem [8, 9, 34], but the main di erence and also the key point is that any user or item can appear in multiple subgroups.
So we call it Multiclass Co-Clustering problem, or just MCoC for short.
We want the MCoC result be represented by a partition matrix P   [0, 1](n+m) c, where each element Pij is an indicator value of the corresponding entry (a user or an item).
Pij > 0 if the i-th entry belongs to the j-th subgroup, and Pij = 0 otherwise.
The magnitude of Pij shows the relative weight of entry i belonging to subgroup j, thus each row of P sums to 1.
If we  x the number of subgroups that each entry belongs to, e.g., k subgroups (1   k   c), then we get exactly k non-zeros in each row of P .
When k = 1, the problem above is equal to the traditional Co-Clustering problem.
Naturally, partition matrix P can be written as
 (2) where Q   [0, 1]n c is the partition matrix of users and R   [0, 1]m c is the partition matrix of items.
We use a very simple but reasonable method to solve MCoC Problem.
However, better methods could be explored to further improve the quality of user-item subgroups in future work.
Intuitively, if one user and one item have a high rating score, they are very likely to appear in one or more subgroups together.
In order to make those strongly associated users and items together, inspired by [10, 34, 35], we adopt the following loss function to model the user-item relationships: (cid:3) (cid:4) ,


 (cid:4)2Tij ), (3) n(cid:2) m(cid:2) i=1 j=1 qi(cid:5) ((cid:4) Drow ii   rj(cid:6) Dcol jj (cid:7)m where qi is the i-th row of Q and rj is the j-th row of R.
Drow   R n n is the diagonal degree matrix of users with (cid:7)n j=1 Tij and Dcol   R m m is the diagonal degree Drow ii = matrix of items with Dcol i=1 Tij .
jj = The loss function is easy to understand.
Since we have only the user-item interaction information, minimizing Eq.
(3) means that the indicator vectors of user i (qi) and item j (rj) should be very close if they have a high rating score.
And indicator vectors.
By some simple linear algebra derivations, we can get : i=1
 m(cid:7) (cid:3) (cid:4)qi(cid:4)2 + (cid:8) (cid:4)ri(cid:4)2   n(cid:7) n(cid:7) = = T r(QT Q + RT R   QT SR)

 = T r Im = T r(P T M P ), In
 j=1 i=1 m(cid:7) (cid:4)(cid:3) j=1
 (cid:2) Drow i rj Tij ii Dcol jj (cid:4)(cid:9)

 (cid:3) where In

 Im   1   1 S = (Drow


 ) ) (5) In is an identity matrix in the size of n  n. We have several strong constraints on the partition matrix P (described in section 3.1), so  nally, we are to solve the following optimization problem: .
(4) (cid:4)
 (m+n) c, T r(P T M P ) min s.t.
P   R
 P 1c = 1m+n, |Pi| = k, i = 1, .
.
.
,( m + n).
(6) and There are two cases: a user or an item can belong to one single class or multiple classes.
For single class case, we use k-means to cluster the data X.
Then each row of P has only one positive number and the index is the cluster label.
For multiple class case, which is the main focus of this paper, we choose to use the fuzzy c-means [17], a soft clustering method.
The algorithm is an iterative optimization that minimizes the criterion function: m+n(cid:2) c(cid:2) i=1 j=1 Jm(P, V ) = (Pij ) ld(xi, vj)
 (8) where Pij is the membership of entry xi (a user or an item) in cluster j, and vj is the center of cluster j.
The function d is a distance function which can be prede ned and the parameter l is a weighting exponent controlling the fuzziness of the resulting partition.
In our method, d is the Euclidean distance and l is 2.
During each iteration, we update P and V as follows: (cid:10)(cid:11) (cid:12) Pij = (d(xi, vj)) 2/(1 l) (cid:11) m+n(cid:2) i=1 P l ijxi vj = c(cid:2) (cid:12)(cid:10)(cid:11) k=1 (d(xi, vk)) 2/(1 l) , (9) (cid:12) P l ij , (10) m+n(cid:2) i=1 for all i = 1, .
.
.
,( n + m), and j = 1, .
.
.
, c. The algorithm is stopped if the improvement of objective function values at two successive iteration steps is less than a threshold  .
In our experiments,   is 1e-5.
Then for each row of P , only the top-k biggest elements are retained and each row sums to one (normalized).
By now we have  nd some user-item subgroups, then, we ll describe how to combine them with existing collaborative recommender systems.
The main idea is applying some CF algorithm in each subgroup and try to merge the prediction results together.
For a pure CF method, the only input is the user-item matrix and the output is the prediction score for each missing value in the matrix.
Actually, for each subgroup, we could get a submatrix from the original big user-item matrix T , i.e., we could adopt any CF method without any modi cation.
This is a big bene t for us that we can pay our most attention to subgroup discovering, for better subgroup quality, but concern little about the e ectiveness of a CF method.
The last problem is how to merge the prediction results from all subgroups.
One user and one item can belong to one , two (or more), or zero subgroups, so we propose an uni ed framework to handle all cases.
Let P re(ui, yj, k) be the prediction score of user i to item j in subgroup k by some CF method, and Yij be the  nal prediction score of user i to item j, we de ne (cid:7) k P re(ui, yj , k)    ik     Yij = if ui and yj belong to one or more subgroups,
 otherwise.
(11) In the above formulation,  ik is an indicator value of user i representing whether subgroup k is his (her) most interesting The combined constraints P   0 and P 1c = 1m+n force each element of P to stay in the range of [0, 1].
Parameter c is the total number of subgroups and k is the number of subgroups each user or item can join in (1   k   c).
Notation | | is the cardinality constraint which means the number of nonzero elements of a vector.
Vector Pi is the i-th row of partition matrix P .
Solving objective function (6) directly is not easy, since it is nonconvex and discontinuous.
In this paper, we propose to use an e cient approximation method to solve this problem.
Similar to the spectral clustering model [22] and the bipartite graph model [8], our method has two primary stages: Stage 1.
Mapping all users and items into a shared low-dimensional space.
According to the objective function (6), we think that the optimal r-dimensional embedding X  , which preserves the user-item preference information, could be got by solving the following problem: T r(X T M X) min s.t.
X   R
 (m+n) r, X T X = I.
(7) The constraint X T X = I is to avoid the arbitrary scaling of X.
From Eq.
(3) and (4), we  nd that M is a positive semide nite matrix.
The optimal solution X  that minimizes the objective function (7) is given by the solution of eigenvalue problem M X =  X.
So X  = [x1, .
.
.
,x r], where x1, .
.
.
,x r are the smallest eigenvectors of matrix M sorted by their corresponding eigenvalues.
Stage 2.
Discovering subgroups.
As long as we have the uni ed representation X of users and items, we need to  nd the user-item subgroups, i.e., to compute the partition matrix P .
(cid:18) (cid:18) Qyj ), (12) subgroup in the shared subgroups with item j.
Then  ik =

 if Pik is max(Rui otherwise.
where operator returns the index of nonzero overlap items of two vectors and function max( ) returns the maximal element value in a vector and matrix P is the partition matrix which has been described above.
This simple framework can handle di erent overlapping cases for users and items.
We could see  ik as a weight of the prediction P re(ui, yj, k), but in this paper we just use the hard weight, 0 or 1.
The performance of using a soft weight could be investigated in future work.
By the strategy above, we get a lot of (but not all) prediction scores for each user and commonly the items (unrated) having top scores are recommended to the user.
This is the end of our method.
It is independent of any speci c CF algorithm.
In this section, we will talk about several detailed issues for our proposed approach.
By Eq.
(11), we just consider of those correlated users and items   an item could be a candidate recommendation item for a user if and only if they both belong to one or more subgroups.
But occasionally, some subgroups may have very few elements due to the unbalance of clustering, e.g., less than 10.
So under the extreme case, some user may have not enough correlated items for recommendation.
We could remove the small subgroups or recompute the fuzzy c-mean process, or just make an easy solution   add some popular items to those users for this time of recommendation.
The latter one is a good strategy for a real recommender system.
But our goal is to investigate the usefulness of subgroups, so we don t add any additional uncorrelated items.
Although the user-item interaction data is very sparse, our method utilize the dimensionality reduction technique to alleviate the data sparsity problem.
Even for some new users with very few interaction data (we call it Cold Start problem), the algorithm is still competent for this case and recommend items for them in the same way.
Moreover, since users and items belong to multiple groups, most submatri-ces are more dense but smaller than the original user-item matrix.
So the sparsity and scalability problems for some recommendation methods are both reduced in a degree in our framework.
The last critical issue is the computational cost.
Our method seems to be costly   both the eigenvector computation and fuzzy clustering are time consuming.
However, due to the high sparsity of the user-item matrix, we just require very few eigenvectors, e.g., 3, for data representation (see section 5.1.2).
Clustering a data set with only 3 dimensions is always very fast.
So for a common size data set, our framework will not a ect the recommender system s ef- ciency.
Both the sparsity and computational cost are compared by experiments in section 5.5.
Here we make a brief summary of our framework for top-N recommendation.
In practice, we do following steps: Step1: Dimensionality reduction.
trix T and construct matrix M .
See Eq.
(5).
and form the shared low dimensional representation
 = [x1, .
.
.
,x r].
See Eq.
(7) Step2: Finding subgroups.
means for multi-class case or by k-means for single-class case.
See Eq.
(9) and (10).
So we get the partition matrix P describing group information of all the users and items.
Step3: Top-N recommendation.
predict missing values, and merge the results by an uni ed framework.
See Eq.
(11).
recommended.
We conduct many experiments to evaluate the e ective-ness of the proposed method.
In this chapter, we describe the experimental settings in detail.
Our experiments are performed on three real data sets: MovieLens-100K4, MovieLens-1M and Lastfm.
The MovieLens-100K data set is a classic movie rating data set collected through the MovieLens web site.
It consists of 100,000 ratings (1-5) from 943 users on 1,682 movies and each user has rated at least 20 movies.
The MovieLens-1M data set is a larger data set which consists of 1,000,209 ratings (1-5) from 6,040 users on 3,952 movies and each user has rated at least 20 movies.
We collected Lastfm data set from Last.fm web site in December 2009.
We  rstly crawled the listening counts of
 set of songs and users by restricting that each song has been listened by more than 30 users and each user has listened more than 50 songs.
So we get a subset of 2,059 users and
 shown in Table 1.
Table 1: Basic statistics of the data sets MovieLens-
# of users # of items # of ratings # of ratings per user # of ratings per item





 ML-1M Lastfm










 We investigate many popular CF methods including two memory based algorithms with User-based and Item-based, one hybrid method of personality diagnosis (PD), four well known matrix factorization methods (model based) of SVD, 4http://www.grouplens.org/
 Sk SkV T (i)     NMF, MMMF, NPCA, and also recommendation by popularity (POP).
Later we combine these recommendation methods with our framework and check whether their performance is improved.
User-based: For user-based algorithm, we use a representative similarity metric   pearson correlation, to measure the user-user similarities and use the user-based model in [14].
Item-based: For item-based algorithm, we use the vector cosine similarity model to compute the item-item similarities and use the item-based model in [14].
PD: Personality diagnosis is a representative hybrid CF approach that combines memory based and model based algorithms and retains some advantages of both algorithms [24].
We adopt the procedure in the CF toolkit5 for PD.
SVD: This is maybe the most popular collaborative  ltering technique.
Once the user-item matrix is decomposed into three component matrices with k features: T = UkSkV T k , the prediction score of user i to item j is P redij = ri + Uk k (j), where ri is the i-th row average of T , and T is the normalization of T according to [28].
NMF: We use the most commonly used algorithm for Non-negative Matrix Factorization described in [16].
Similar to SVD, the user-item matrix is decomposed into two component matrices with the base matrix having k bases.
For both SVD and NMF, we use k = 6.
MMMF: The Maximum Margin Matrix Factorization is a state-of-the-art algorithm with good collaborative prediction performance.
We use the procedure in [25].
NPCA: The algorithm was proposed in [33] and according to the authors, it produced one of the most accurate prediction results among matrix factorization methods.
POP: Recommendation by popularity is wildly used in many recommender systems.
Usually, it has a competitive recommendation precision due to the hot e ect   hot items are more likely to be clicked.
But it s result could not re ect personalization.
In this paper, we use the number of ratings for each item as the popularity score.
Many previous works compute Root Mean Square Error (RMSE) or Mean Absolute Error (MAE) to evaluate accuracy of the predict scores.
In our consideration, they are good measurements for prediction or matrix completion task, but not for a general top-N recommendation task.
For a real top-N recommender system, no matter what strategy it adopts, the  nal output for a user is just a ranked list of items, e.g., a list of movies in a video web site, a list of songs in a music web site, or a list of hotels in a travel web site.
The low error prediction scores can t guarantee a good recommendation list, e.g., prediction score 3 and 5 have the same absolute error with the test score 4 (ground truth), but their positions in the ranked list are extremely di erent in a 1-5 rating system.
So the most important is to evaluate the quality of the ranked list.
The click action at a recommended item maybe the most straightforward but useful feedback from the user   at least he (she) is interested in the item.
The click may cause a user to listen to a song in a music web site or buy a product in a e-commerce web site.
So if one recommended item is clicked, it is treated as a hit item, otherwise it s a miss item.
But we don t have the click information, so we use the test
 data (e.g., ratings) to approximate the click action   if one recommended item has a rating score on the test data, it s a hit item, otherwise it s a miss item.
To make the experimental results comparable, we use many well known metrics to measure the ranked list.
Similar to information retrieval evaluation, we use Precision@K to evaluate the quality of the top K recommended items.
Considering that some users may have a large number of ratings in the test data while some other users just have a few, so F1 score may be more reasonable.
MAP (Mean Average Precision) provides a single gure measure of quality across recall levels [20].
For a single user j, Average Precision is the average of precisions computed at the point of each correctly recommended item (d1, .
.
.
, dmj ) in the ranked list, and this value is then averaged over the user set U : |U|(cid:2) mj(cid:2)



 mj j=1 k=1 Precision(Rjk), (13) where Rjk is the set of ranked results from the top result until you get to item dk.
NDCG [20] is a wildly used metric for a ranked list.
NDCG@K is de ned as:


 2ri 1 log2(i + 1) , (14)   K(cid:2) i=1 where ri is 1 if the item at position i is a hit item and 0 otherwise.
IDCG is chosen so that the perfect ranking has a NDCG value 1.
We run many state-of-the-art recommendation methods and check whether their top-N recommendation performance are improved after using our framework.
After that, we make an empirical analysis to the results, as well as the sparsity and scalability.
The MovieLens-100K data set is divided into  ve disjoint splits.
Each split is used for testing and the rest four for training, so there are  ve di erent training/testing sets.
We repeat our experiment with each set and average the results.
In Fig.3 we plot MAP of the top-N recommendation results versus di erent number of subgroups by eight methods described above.
In each subgraph, the horizontal broken line represents original performance of that method, and the other two lines represent the performance of using subgroups.
The red line with small squares is for the case that users and items belong to multiple classes and the blue line for single class.
From the results, we  nd that our method has positive e ect for most of the methods including POP, User-based, SVD, NMF, MMMF, and PD.
However it has unstable e ect to NPCA and has negative e ect to Item-based recommendation method.
Then in Table 2, we record other three evaluation metrics: Precision, NDCG and F1 score on position 10.
We compare the performance of using 15 and 25 subgroups with the base performance.
The bold number indicates that its value has an obvious improvement than the base value (di erence  
 rate of top-10 recommendation, while F1 score, which both considering of the corresponding recall value, is more fair




















 MultiClass+POP SingleClass+POP















 #Subgroups (a) POP MultiClass+UB SingleClass+UB









 MultiClass+IB SingleClass+IB












 #Subgroups






 #Subgroups



 (b) User-based (c) Item-based MultiClass+SVD SingleClass+SVD





 #Subgroups (d) SVD MultiClass+NMF SingleClass+NMF







 MultiClass+MMMF SingleClass+MMMF







 MultiClass+NPCA SingleClass+NPCA







 MultiClass+PD SingleClass+PD



 #Subgroups (e) NMF












 #Subgroups (f) MMMF


 #Subgroups (g) NPCA









 #Subgroups (h) PD Figure 3: Comparisons of the recommendation performance on MovieLens-100K data set by eight CF methods.
In each subgraph, the black broken line shows the original performance while the red (with squares) and blue real lines show the performance of using subgroups for multi-class and single-class respectively.
The number of subgroup varies along the horizontal axis.
Table 2: Performance Comparisons on MovieLens-100K in terms of Precision, F1 and NDCG.
15 and 25 subgroups are used for our approach.
The bold number indicates an obvious improvement (di erence   0.01).
Recommendation base performance Method
 User-based Item-based






























 performance on 15 subgroups

























 performance on 25 subgroups

























 and comprehensive.
But to evaluate the quality of a ranked list, only the hit rate is not enough   a hit item in position
 is more meaningful to compare the ranked lists.
From the NDCG values in Table 2, we can see that our method has positive e ect for the methods of POP, User-based, SVD, MMMF, NPCA and PD, but has negative e ect for NMF and Item-based methods.
An interesting phenomenon is that when the number of subgroups (c) is very small, e.g., just 2 or 3, the performance of our method with single-class is very good (see the blue lines in Fig.3).
This is easy to understand: one people s interests are usually concentrative on some topics or some correlated items, but not dispersive over all the item set.
Clustering with a small number of clusters actually do the work of denoising   separating uncorrelated items into di erent subgroups.
This result is conform with some previous clustering CF models [9, 29]: they have good performance with small number of clusters, e.g., in [9], the number of clusters is just
 decreases, which makes the performance dropped quickly.
For some recommendation methods, such as POP, User-based and MMMF, the performance of our method with multi-class is just opposite to the single-class: bad in small subgroup number but good in large number.
In our consideration, that means small number of subgroups can not clearly partition di erent user-item interest subgroups.
Under such condition, the fuzzy weights are inaccurate to capture the user s preferences.
As c increases, better subgroups are got and the fuzzy weights are more meaningful.
Then for those algorithms, the e ect of our method becomes more and more evident.
Parameter selection plays a key role to many algorithms.
Sometimes, one algorithm s performance may drastically vary with di erent choices of parameters.
For our method, there are two main parameters: r and k. Parameter r is the number of eigenvectors computed in the dimensionality reduction step.
Fig.4 shows the performance of combining MCoC with SVD by di erent number of dimensionality r. From the  gure, we  nd that the performance is competitive when using just a few eigenvectors, so in our experiments, we just select r = 3.
Parameter k is the number of subgroups that are used for our approach.
The bold number indicates an obvious improvement (di erence   0.01).
Recommendation base 5 subgroups 15 subgroups 25 subgroups Method
 User-based Item-based












































































 each user or item can belong to.
For di erent subgroup number c, we set k = (cid:7)log2(c)(cid:8).
the big variance.
Let  Tij be the new element of user-item matrix T , then









 MCoC+SVD


 Dimensionality: r











 MCoC+SVD


 Dimensionality: r

 (a) 10 subgroups (b) 20 subgroups Figure 4: Performance on di erent number of di-mensionality r with 10 and 20 subgroups.
MovieLens-1M is a large data set with more distinct users than items.
It is randomly divided into 60% training data and 40% testing data.
Parameters are the same with those in section 5.1.2.
We record the MAP and NDCG@10 of each algorithm s result before and after using our method in Table 3.
We select to use 5, 15 and 25 subgroups for our approach.
The bold number indicates that its value has an obvious improvement than base value (di erence   0.01).
From NDCG values, we  nd that our method has positive e ect to POP, User-based, SVD, NMF, MMMF, NPCA and PD.
But from the MAP values, our method s performance falls in NPCA.
That means in MovieLens-1M data set, by using MCoC, the rate of hit items in NPCA s recommendation list is reduced, whereas the positions of hit items are moved up.
Overall, the performance of our approach on MovieLens-1M is similar to that on MovieLens-100K, since they are from the same web source.
Lastfm data set is quite di erent with the above two Movie-Lens data sets.
Its user-item data is not user speci ed ratings.
In last.fm web site, we can get one user s listening logs.
So we use the listening count as the implicit interaction data and form the user-item listening matrix.
It is randomly divided into 60% training data and 40% testing data.
Parameters are the same with those in section 5.1.2.
Obviously, the elements of the user-item matrix vary in a large range   for a user, some music are just listened once and some are listened more than one hundred times.
So how to use the user-item matrix is a problem.
Besides to use the original listening data, we use the re-scaled data to alleviate  Tij = log2(Tij + 1).
(15) By the equation, zero values will be still zero and positive values will be re-scaled by logarithm.
This is quite reasonable for dealing with the listening number: listening one song 10 times means likeness for some users, but does listening 100 times for some other users means a 10 times stronger likeness?
Sometimes, it doesn t mean a strong likeness for those users, but just means that they are active users.
The usage of re-scaling could be observed from Table 4.
Most algorithms  base performance are improved in a large degree after using the re-scaled data.
Due to the uncertain range of the data, we can t use the method of PD, since its procedure requires to input the number of distinct preference values.
We use the rest seven methods in Lastfm data set and the results are showed in Table 4.
From NDCG and MAP values, we  nd that our approach is useful for the methods of POP, User-based, SVD and NMF, but not for Item-based, MMMF and NPCA.
The results on two MovieLens data sets (100K and 1M) and Lastfm data set evidently show that our approach has positive e ect for many CF methods, but not for all.
Among these methods, the Item-based method is a very special one   our approach always lowers its performance on all the data sets.
This is mainly because the Item-based method depends on the prior information of one user s history ratings and all item-item similarities, i.e., it doesn t bene t from the neighborhood relationships as traditional CF models does.
When we use the subgroups, the prior information is reduced for each user, which negatively a ects the recommendation.
But for the other seven methods, our approach has positive e ect for them on one or more data sets.
The Item-based method has almost the best base performance on all the data sets.
This proves our assumption that one user s interests are concentrative on some topics or some correlated items, because Item-based method tends to recommend similar items agreeing with the user s preference history.
However, although Item-based method is good in precision, it is hard to extend the selection range for the user, i.e, the diversity of the recommendation is low.
In our consideration, a good recommendation list should consider of both relevance and diversity.
Our approach acts di erently on explicit rating data and implicit listening data.
On explicit rating data, it is useful for most of the methods.
On implicit listening data, it is only useful for four methods, but the improvement is relatively approach.
The left part is the result of using original data and the left part is the result of using normalized data.
The bold number indicates an obvious improvement (di erence   0.01) and symbol * indicates a big improvement (di erence   0.05).
Original Data Recommendation base 30 subgroups Method
 User-based Item-based



































 base







 Re-scaled Data 30 subgroups























 large, e.g., the NDCG improvement of SVD on re-scaled Lastfm data is very large (di erence > 0.15).
At last, we  nd that people s behaviors are largely affected by the factor of popularity   for all the three data sets, POP method has a relatively good performance.
And the popularity in a subgroup still works, so POP is always improved by our approach.
Actually, both the popularity and personal taste can attract the user to click an item in a real web system.
In Table 5 we record the sparsity (percent of zero elements in a matrix) of original user-item matrix and the average sparsity of subgroups, as well as the computational time of MCoC.
10, 20 and 30 subgroups are used for comparison.
Each number of our method are the average result of ten independent runs.
Experiments are run on a computer with double 3.16 GHz CPU and 3 GB RAM.
From the results, we  nd that when more subgroups are used, each subgroup becomes more dense, which is good for reducing data sparsity problem for some CF methods.
Note that when 30 subgroups are used, the sparsity of Lastfm is very low.
In our opinion, this is one reason of why MCoC has a big improvement for some CF methods on Lastfm.
The short runtime of MCoC shows its good e ciency.
Table 5: Sparsity and runtime comparisons on MovieLens-100K, MovieLens-1M and Lastfm data sets.
Term subg is short for subgroups.
Sparisity Base 10 subg 20 subg 30 subg MCoC Runtime (s) 10 subg 20 subg 30 subg



 ML-100K ML-1M Lastfm



 ML-100K ML-1M Lastfm














 User-item subgroups can help to capture similar user tastes on a subset of items.
In this paper, we explore a new improving space for collaborative recommender systems   utilizing user-item subgroups.
This is a natural extension of traditional clustering CF models.
Experimental results show that using subgroups is a promising way to further improve the top-N recommendation performance for many popular CF methods.
We expect our exploration can attract further research or practice on the topic of clustering CF model.
Future works are needed in two main aspects: one is to  nd better user-item subgroups and the other is to design new methods to fully utilize subgroups.
