Online advertising is a multi-billion dollar industry, with billions of auctions taking place daily.
At such scales automated bidding agents have become the norm.
An automated agent takes as input a set of parameters, or goals, of the advertiser: for example, the targeting constraints, desired number of impressions, quality constraints, etc., and (cid:3)Work done while visiting Yahoo!
Labs.
Partially supported by the NSF grant CCF-1016684.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
then outputs a bid for every advertising opportunity.
The bids from all interested parties are collected by the publisher, often through an advertising exchange (e.g.
RightMedia Exchange, Google Ad Exchange), and the opportunity to show an advertisement is given to the highest bidder.
The goals of the bidding agents are quite diverse: some bidding agents aim to maximize the number of clicks or conversions for an advertiser, others look to achieve a representative allocation, aiming for a uniform slice of all eligible impressions [8], still others care about temporal smoothness, making sure the advertiser receives a stream of impressions throughout the day, as opposed to getting them all in the morning or in the evening.
Regardless of the speci(cid:12)c goal, almost all of the agents rely on some sort of forecasting in order to properly set the bidding parameters.
Speci(cid:12)cally, almost all of the optimization formulations rely on supply and price forecasts.
Intuitively, the forecasts are needed to judge the utility of a speci(cid:12)c impression.
Deciding whether an impression looks cheap or expensive requires the knowledge of the typical price of such impressions.
Similarly, knowing how many of such impressions will arrive in the future helps decide the urgency with which the bidding agent should be bidding, since most advertisers have an additional budget constraint on their campaigns.
Accurately predicting both supply and price forecasts is a nontrivial endeavor.
For example, for the supply forecasts, although general tra(cid:14)c trends stay consistent day to day| there are more impressions in the middle of the day than in the middle of the night|the exact forecasts experience a lot of daily (cid:13)uctuations |the Oscars, for example will change the tra(cid:14)c pattern for websites related to the entertainment industry.
Moreover, an individual bidder may not have access to the necessary data to make the desired predictions.
Some exchanges employ selective call out strategies [1], wherein the number of eligible impressions observed by the bidder is correlated with his win percentage.
In other situations, when the bidding agents are hosted by the exchange, the exchange only reports the number of won opportunities for each bidder, not the number of eligible opportunities.
(In fact early termination methods [11] result in situations where a full eligible set is never computed for each opportunity.)
All of the above leads to a natural question for a bidding agent designer: how to deal with forecast errors in developing a bidding strategy.
One approach requires investing heavily in better forecasting strategies to reduce the number of errors, but one quickly hits a state of diminishing returns: there is enough entropy in the system, so that perfect fore-myopically adjust the bidding parameters based on the past history, relying on frequent re-optimization to achieve the goals of the agent.
In this work we formally analyze the latter approach, and show that as long as the adjustments are done su(cid:14)ciently frequently, the agent can automatically compensate for reasonably large errors in forecasts.
Advertising exchanges sell billions of impressions per day requiring the use of automated bidding agents to buy advertising opportunities online [13].
The typical problem facing a bidding agent is to obtain a target number of impressions to users satisfying speci(cid:12)c targeting characteristics (e.g.
Male, Age > 30) over some limited time horizon (e.g.
one week), while limited by a budget constraint.
The problem of (cid:12)nding a good bidding strategy falls under the larger umbrella of allocation problems for display advertising.
Previous work focused on the allocation problem in the Guaranteed Advertising scenario, where a publisher is trying to satisfy multiple display advertising contracts simultaneously, by deciding which ad to show to each user visiting his page.
This problem is often modeled as an online matching problem, which has a rich history beginning with the seminal work by Karp et al.
[10] who showed a lower bound of 1 (cid:0) 1=e on the competitive ratio of any algorithm, and gave a randomized algorithm that matched that bound.
This work has been applied to the online advertising scenario in a series of works by Feldman et al. [6, 7], who used the speci(cid:12)cs of the problem to improve on that bound.
A di(cid:11)erent direction was to phrase the problem as a stochastic optimization problem, where the user arrivals are not adversarial, but rather are drawn from some distribution.
Devanur and Hayes [5] assumed that the arrivals are independent and e(cid:11)ectively showed how to learn the distribution before performing the analysis.
Vee et al. [14], assumed full knowledge of the distributions and focused on providing a compact strategy that can be readily implemented in ad serving.
Only the recent work by Chen et al. [3] explicitly addressed the limitations of supply forecasts and experimentally showed that control theory based methods mitigate the impact of forecast errors.
In this work we show both analytically and experimentally that even simpler methods lead to good performance.
The allocation problems described above focus on obtaining the target number of impressions in situations where the publisher controls the allocation, and hence no explicit bidding is necessary.
Requiring that the bidding agent buy the impressions directly from an exchange adds an additional layer of complexity.
In addition to supply forecasts, the competitors bids need to be forecast as well [4], or learned in real time [9].
Moreover, the choice of the objective function for the bidder becomes more important.
For example, Ghosh et al. [8] conclude that one should aim for a fair or representative allocation, rather than getting the cheapest impressions possible.
We explicitly study the problem faced by the bidding agent designer in the face of inaccurate forecasts.
We begin by analytically bounding the error in the number of impressions won and the total spend when given inaccurate forecasts and using a well known bidding strategy.
We then show that a simple algorithm that myopically re-optimizes the bidding parameters can greatly mitigate the errors in the forecasts.
The algorithm is simple and requires minimal feedback from the system, yet a formal analysis shows that the re-optimization approach quickly converges to the bidder s desired budget and demand.
We prove the algorithm s e(cid:11)ectiveness as a function of the number of update cycles and the original error in the forecasts.
We conclude with an experimental analysis on both synthetic and real-world datasets.
Our experimental evaluations shows that the algorithm performs extremely well on real data, even with forecasts with large error.
We consider the problem from the perspective of a single advertiser, Alice, bidding in a second price auction.
Alice has a total budget of B and desires to win D impressions.
We note that Alice s goal is not to win D impressions at minimum cost: as [8] argued, advertisers in these markets have a common value, which means the cheapest impressions are precisely the lowest quality ones.
This setting best describes advertisers buying individual impressions.1 At every opportunity, Alice can submit a bid b.
Other advertisers submit bids as well, and we model the highest competing bid as being chosen independently from a distribution with density p(cid:3), and CDF of P (cid:3).
Let c (cid:24) P (cid:3) be the highest competitor bid.
If b > c then Alice wins the impression, decrementing her desired demand by 1 and her budget by c. Otherwise, c (cid:21) b and Alice loses the impression, leaving her demand and her remaining budget unchanged.
If the distribution P (cid:3) and the total number of impressions n(cid:3) is known to Alice, she can use an easy bidding strategy that achieves her demand while spending exactly the budget.
We call this algorithm SingleRound.
To analyze the algorithm, we will denote by DA the total number of auctions won using bidding strategy A, dropping the subscript when it s clear from the context.
Similarly, denote by BA the expected budget spent using strategy A.
Let t = B=D be the desired target spend per win.
If t (cid:20) E[P (cid:3)] then there exists a bid b(cid:3) so that the expected price to Alice conditioned on winning the impression is exactly t, i.e.
E[pjp < b(cid:3)] = t: The expected number of impressions won by bidding b(cid:3) is exactly n (cid:1) P (cid:3)(b(cid:3)).
The SingleRound bidding strategy bids b(cid:3) with probability q(cid:3) = n(cid:3) (cid:1)P (cid:3)(b(cid:3)) (For simplicity we assume that q(cid:3) (cid:20) 1, we investigate this further in Section 5.)
It is easy to see that E[D] = D and E[B] = B.
Unfortunately, in practice, neither the total supply, n(cid:3), nor the price distribution, P (cid:3) are known ahead of time, instead only forecasts, which we denote by n and P respectively, are available.
To quantify the forecast error, we will use (cid:14) to denote the relative error in the supply forecast: n(cid:3)(1 (cid:0) (cid:14)) (cid:20) n (cid:20) n(cid:3)(1 + (cid:14)).
Similarly, we denote by (cid:13) the relative error in the price forecast: for any b (cid:21) 0, p(cid:3)(b)(1 (cid:0) (cid:13)) (cid:20) p(b) (cid:20) p(cid:3)(b)(1 + (cid:13)).
We emphasize that while we use (cid:14) and (cid:13) for the analysis, neither of the parameters is known to the advertiser.
only pay per click.
In this Section we analyze the performance of a non-adaptive bidding algorithm as a function of the forecast errors, (cid:14) and (cid:13).
As we saw before, given the bidding agent parameters: the demand D and the budget B, and the forecast of others  behavior: the total supply, n and the distribution of the highest competing bid, P , the algorithm SingleR-ound achieves the goals in expectation.
Here SingleRound uses the forecasts P and n as if they were the actual supply and bid landscape to determine the bid and probability of bidding.
Now consider the performance of SingleRound in the face of forecast errors.
We bound the demand ful(cid:12)lled, i.e. the number of auctions won, and the budget spent: Theorem 3.1.
Consider the bidding strategy SingleRound, under supply forecast error, (cid:14), and bid forecast error (cid:13).
Then and
 (1 + (cid:13))(1 + (cid:14)) (cid:20) E [D] (cid:20)
 (1 (cid:0) (cid:13))(1 (cid:0) (cid:14))
 (1 + (cid:13))(1 + (cid:14)) (cid:20) E [B] (cid:20)
 (1 (cid:0) (cid:13))(1 (cid:0) (cid:14)) ; : Proof.
Let y be the bid computed by SingleRound, and q the probability of participating.
Then the expected number of impressions won is E[D] = q (cid:1) P (cid:3)(y) (cid:1) n(cid:3) =
 nP (y) (cid:1) P (cid:3)(y) (cid:1) n(cid:3)
 (1 + (cid:14))(1 + (cid:13)) 2(cid:20) ;
 (1 (cid:0) (cid:14))(1 (cid:0) (cid:13))(cid:21) To bound the total budget spent, consider the expected amount spent: E[B] = n(cid:3) (cid:1) q (cid:1) P (cid:3)(y) (cid:1) EP (cid:3) [x : x < y] = n(cid:3) (cid:1)
 (cid:1) P (cid:3)(y) (cid:1) EP (cid:3) [x : x < y] n (cid:1) P (y) n(cid:3) n P (cid:3)(y) P (y) (cid:1) = B (cid:1) (cid:1) EP (cid:3) [x : x < y] EP [x : x < y] Since EP [x : x < y] = 1 b=0 bp(b)db, we can simplify to: E[B] = B (cid:1) n(cid:3) P (y) R y n R y R y b=0 bp(cid:3)(b)db b=0 bp(b)db
 (1 + (cid:14))(1 + (cid:13)) 2(cid:20) ;
 (1 (cid:0) (cid:14))(1 (cid:0) (cid:13))(cid:21) ; where the last line follows because p(cid:3)(b) 2 p(b) 1(cid:6)(cid:13) for all b.
At this point we have shown that a simple algorithm will have bounded error in the expected budget spent and the expected number of auctions won.
However, this error maybe quite large depending on the exact values of (cid:14) and (cid:13).
In the next section we show that a myopic adaptive algorithm can dramatically reduce the overall error.
We show that the simplest adaptive strategy, which periodically reruns the SingleRound Algorithm using updated budget and impressions targets, can be very powerful in limiting the e(cid:11)ect of the forecast errors.
The only intermediate information required to rerun SingleRound is the total amount spent and total number of impressions won during the previous time period.
We state our results more broadly for any optimization algorithm A that takes a supply forecast, bid landscape forecast, desired demand and remaining budget.
For the purposes of the analysis, we assume that impressions begin arriving at time t = 0 and denote by T the expiration date of the contract.
Let k 2 N+ denote the number of optimization routines performed in time T .
We will assume that supply is distributed uniformly during the T time steps.
This assumption does not hold in practice, but makes for a simpler analysis.
We investigate its e(cid:11)ect If n(cid:3) is the on the algorithm s performance in Section 5.
total available supply, then n(cid:3) (cid:1) (1 (cid:0) i k ) opportunities are available after time T (cid:1) i=k, which will also serve as the time of the i + 1-st optimization by A.
Our goal is to bound the expected budget spent and the expected demand received by the optimization algorithm as a function of the forecast errors (cid:14) and (cid:13) and the number of optimization cycles, k. We will show that as k increases, the total error in the demand received and budget spent decreases as a function of k. To do this, we abstract both problems into one general problem.
In this problem there are n(cid:3) events.
During each event the algorithm makes a decision and experiences some reward.
Let Yi be the random variable i=1 Yi.
The goal of the algorithm is to make decisions on each event so that the expected value of X is equal to a goal parameter, (cid:11).
In the case of analyzing the demand, (cid:11) = D and Yi is the probability of winning the impression.
In case of analyzing the total spend, (cid:11) = B and Yi is the expected spend per impression.
denoting the reward during the ith event.
Let X = Pn(cid:3) The goal of this section is to prove the following theorem, which roughly shows that the error experienced by the algorithm drops as 1=k, and so even a small number of re-optimization cycles can go a long way towards improving performance.
(We note that a more specialized version of this theorem geared speci(cid:12)cally for performance of target demand appears in [2].)
Theorem 4.1.
Let (cid:15); (cid:15)0 > 0.
If A ensures that (1 (cid:0) (cid:15)0) (cid:11) n(cid:3) (cid:20) E[Yi] (cid:20) (1 + (cid:15)) (cid:11) n(cid:3) for any possible value of n(cid:3), (cid:11) and i 2 [n(cid:3)] then rerunning A k (cid:21) 1 times every n(cid:3)=k events, guarantees: (cid:0)(cid:11)(cid:15)0(cid:18) 1 k(cid:19)1(cid:0)(cid:15)0 (cid:20) E[X (cid:0) (cid:11)] (cid:20) (cid:11)(cid:15)(cid:18) 1 k(cid:19)1(cid:0)(cid:15)0 : The algorithm A s goal is to have E[X] = (cid:11), however the algorithm may not be able to achieve this in expectation.
This is because the algorithm may have some bounded error as described by (cid:15) and (cid:15)0.
Now, if we use the algorithm to optimize k times, then the algorithm converges on E[X] = (cid:11) at a rate of(cid:0) 1 .
Thus, simply optimizing k times makes the algorithm converge on the correct value quickly.
For a concrete example, let A be SingleRound, (cid:15) = (cid:14)+(cid:13)(cid:0)(cid:14)(cid:13) (1(cid:0)(cid:14))(1(cid:0)(cid:13)) , (cid:15)0 = (cid:14)+(cid:13)+(cid:14)(cid:13) (1+(cid:14))(1+(cid:13)) and (cid:11) to be either the budget or the demand.
In this case, using previous theorem with Theorem 3.1 we have the following corollary.
Using the previous lemma we upper bound E[R(k)].
Lemma 4.4.
We have that E[R(k)] (cid:20) (cid:11)(cid:0) 1 Proof.
k(cid:1)(1(cid:0)(cid:15)0).
Corollary 4.2.
If the SingleRound is rerun k times at even time intervals between 0 and T , then: E[R(k)] (cid:20) (cid:11) (1 (cid:0) (cid:15)0(cid:18) 1 )D (cid:20) E[D] (cid:20) (1 + (cid:15)(cid:18) 1 and (1 (cid:0) (cid:15)0(cid:18) 1 )B (cid:20) E[B] (cid:20) (1 + (cid:15)(cid:18) 1 k(cid:19)1(cid:0)(cid:15)0 k(cid:19)1(cid:0)(cid:15)0 k(cid:19)1(cid:0)(cid:15)0 k(cid:19)1(cid:0)(cid:15)0

 As an example, suppose that both supply and price forecasts are o(cid:11) by 25%: (cid:14) = (cid:13) = 1=4.
Then, a single optimization may lead to an underdelivery factor of 36% = (cid:15)0, or a budget overspend of 78% = (cid:15).
A single additional re-topimization (setting k = 2), reduces both by a factor of

 leads to a reduction in error of more than half ((cid:25) 56%).
(cid:25) 0:78, or over 20%.
Having k = 10 re-optimizations, 1(cid:0)(cid:15)0 To show the previous theorem, let Xi = Pn(cid:3)i=k j=1 Yi be the expected value given to the algorithm just before the ith optimization where 1 (cid:20) i (cid:20) k + 1.
(Xk+1 denotes the value remaining in the end.)
De(cid:12)ne the recurrence R(i) = (cid:11)(cid:0)E[Xi].
Intuitively, R(i) is either the remaining demand or budget just before the ith optimization.
Note that R(1) := (cid:11).
Further, R(i + 1) = (cid:11) (cid:0) E[Xi+1] = (cid:11) (cid:0) E[Xi] (cid:0) (E[Xi+1] (cid:0) E[Xi]) = R(i) (cid:0) (E[Xi+1] (cid:0) E[Xi]).
The goal is to (cid:12)nd a lower bound and upper bound on R(k + 1).
To do this, the proof proceeds as follows.
First, we bound R(i) in terms of R(i (cid:0) 1).
Using this we can upper bound R(k).
With an upper bound on R(k) we can derive the (cid:12)nal bounds on R(k + 1).
Lemma 4.3.
(1 (cid:0) 1+(cid:15) k(cid:0)i+1 )E[R(i)] (cid:20) E[R(i + 1)] (cid:20) (1 (cid:0) 1(cid:0)(cid:15)0 k(cid:0)i+1 )E[R(i)] for any 1 < i (cid:20) k.
Proof.
Consider the time the ith optimization is performed.
At this time there are n(cid:3)(1(cid:0) i(cid:0)1 k ) events remaining.
There will be n(cid:3)=k events available before the (i + 1)st optimization.
Therefore a 1=(k (cid:0) i + 1) fraction of the remaining events occur in the ith stage.
We have that, E[R(i + 1)] = Xx (cid:21) Xx E[R(i + 1)jR(i)] (cid:1) Pr[R(i) = x] (1 (cid:0) 1 + (cid:15) k (cid:0) i + 1 )R(i) (cid:1) Pr[R(i) = x] [De(cid:12)nition of A and R] = (1 (cid:0) 1 + (cid:15) k (cid:0) i + 1 )E[R(i)] and similarly we have, E[R(i + 1)] = Xx (cid:20) Xx E[R(i + 1)jR(i)] (cid:1) Pr[R(i) = x] (1 (cid:0) 1 (cid:0) (cid:15)0 k (cid:0) i + 1 )R(i) (cid:1) Pr[R(i) = x] [De(cid:12)nition of A and R] = (1 (cid:0) 1 (cid:0) (cid:15)0 k (cid:0) i + 1 )E[R(i)] k Yj=2 k Yj=2 (1 (cid:0) 1 (cid:0) (cid:15)0 k (cid:0) j + 2 ) [Lemma 4.3 and R(1) = (cid:11)] (cid:20) (cid:11) exp(cid:18)(cid:0) 1 (cid:0) (cid:15)0 k (cid:0) j + 2(cid:19) k (cid:20) (cid:11) exp (cid:0)(1 (cid:0) (cid:15)0) Xj=2 (cid:20) (cid:11) exp(cid:0)(cid:0)(1 (cid:0) (cid:15)0) log k(cid:1) (cid:20) (cid:11)(cid:18) 1 k(cid:19)(1(cid:0)(cid:15)0)
 k (cid:0) j + 2!
Now we (cid:12)nd upper and lower bounds on E[R(k + 1)].
Lemma 4.5.
(cid:0)(cid:11)(cid:15)(cid:0) 1 Proof.
We have that, k(cid:1)(1(cid:0)(cid:15)0) (cid:20) E[R(k+1)] (cid:20) (cid:0)(cid:11)(cid:15)0(cid:0) 1 k(cid:1)(1(cid:0)(cid:15)0) E[R(k + 1)] (cid:21) (cid:0)(cid:15)E[R(k)] [Lemma 4.3] (cid:21) (cid:0)(cid:11)(cid:15)(cid:18) 1 k(cid:19)(1(cid:0)(cid:15)0) [(cid:15) > 0 and Lemma 4.4] and E[R(k + 1)] (cid:20) (cid:15)0 E[R(k)] [Lemma 4.3] (cid:20) (cid:11)(cid:15)0(cid:18) 1 k(cid:19)(1(cid:0)(cid:15)0) [(cid:15)0 > 0 and Lemma 4.4] Lemma 4.5 and the de(cid:12)nition of R gives Theorem 4.1.
The previous sections described a bidding algorithm that is tolerant of errors in the supply and price forecasts, and presented a theoretical analysis showing that, under certain simplifying assumptions, an advertiser using this bidding algorithm can nearly hit a campaign s demand target and spending target, with errors that become smaller when the campaign s lifetime is divided into more time blocks (thus causing more re-optimizations to occur).
Because the problem addressed by this paper is real, that theoretical analysis is only the (cid:12)rst step.
It is also important to (cid:12)nd out whether the simplifying assumptions made during the analysis are reasonable, and whether the algorithm is su(cid:14)ciently practical and robust to work under realistic conditions.
Among the simplifying assumptions were the following: paign encounters during its lifetime is divided equally between the time intervals.
In reality, the amount of supply in the various time intervals can be highly unequal.
(cid:15) The analysis makes a feasibility assumption that D impressions can be obtained while spending B.
In the experiments, we will examine the assumption-violating case where the bid z leading to the correct demand is greater than the bid y leading to the correct spend.
(cid:15) The analysis assumes that the forecasts are being used as-is, with no updates.
This is a reasonable assumption given that it would be expensive to obtain the feedback necessary to update the forecasts.
Nevertheless, it is natural to ask whether better performance could be obtained if the forecasts could be updated.
The next couple of sections contain experiments that address the following 5 questions:

 assumption about equal time intervals is violated?
distributions.?
z (cid:20) y is violated?
Since there is value both in using real data, and in using non-proprietary data, we will present two sets of experiments in the next two sections.
In Section 6 we will use real data to address questions 1,2,3 from the list above.
In Section 7 we will use synthetic (and hence non-proprietary) data to address questions 1,2,4,5 from the list above.
In this section we give an experimental study of the algorithm introduced in this paper.
The goal of this section is to show that the algorithm does not only perform well theoretically, but the algorithm, in fact, performs well on real world data sets and is robust.
All of the data used in the experiments was gathered from live auctions from the RightMedia exchange.
RightMedia is currently the largest ad exchange currently in industry with over nine billion transactions daily [13].
The highest bid from 100,000 auctions was collected from four separate days.
We will refer to these as four separate datasets.
These bids were used to represent the bid landscape.
To construct the bid forecast we used the bid distribution from one of the datasets.
One of the goals of the experiments was to show the robustness of the algorithm.
To this end, we constructed the bid forecast on only 10,000 auctions from one of the datasets.
Then we ran the algorithm, using this forecast, on the 100,000 auctions from the other three datasets, separately.
For each experiment we ran the algorithm 5 times and took the average of the outputs considered (e.g.
the budget spent or demand received).
Convergence of Budget and Demand with Supply and Landscape Error:.
Our (cid:12)rst experiment is designed to show that the budget spent and demand received converges to the desired budget B and demand D as the number of optimizations increase.
First we focus on the case which we call the  non-varying interval  case.
In this case, when the number of optimizations is k, the algorithm is optimized after each 1=k fraction of the total number of opportunities have occurred.
To exemplify that the algorithm is robust, we set two parameters (cid:14) and (cid:12).
The value of (cid:14) represents the error in the supply forecast.
Here the forecasted supply which was input to the algorithm is (1 + (cid:14)) multiplied by the actual supply.
For this experiment (cid:14) was set to 1=2 and therefore the forecasted supply for each of the experiments was 150; 000 while the actual supply was 100; 000.
In practice, this would be a quite large margin of error in the supply forecast.
Now consider the bid landscape forecast.
In the experiment, a small sample of real bids were used to construct the supply forecast.
It would seem somewhat surprising that using this as the forecast would accurately forecast bids from another day s auctions.
However, the following data shows that the optimization algorithm overcomes this.
To further show the robustness of the algorithm, we also used a parameter (cid:12), which is the error in the bid landscape forecast.2 When using this parameter, the real bids used to construct the forecast were multiplied by (1 (cid:0) (cid:12)).
In the following experiment we set (cid:12) = :5.
Thus, each bid in the training data set used for the bid landscape forecast was scaled by a factor of :5.
Still the optimization algorithm performed well.
The second experiment performed we call the  varying interval  case.
In this case, the number of opportunities between each optimization is random.
Here we choose k (cid:0) 1 random numbers between 0 and the total supply 100; 000.
When the number of opportunities which occurred previously was equal to the one of the random numbers then an optimization was performed.
In practice, the number of auctions which occur during a time period do vary and here we essentially consider the worst cast scenario.
For the advertiser we set the demand D to be 10; 000, one tenth of the total supply.
The advertiser s budget was set at about 2:3% of the total sum of the bids.
Thus, the advertiser desires a large fraction of the total supply (10%) while using a relatively small budget (2:3%).
When bidding in the auction, if there was a tie between the advertiser and the external bid then it was assumed that the external bidder won the auction.
We used the advertiser with these parameters on the auctions from the three di(cid:11)erent datasets using a di(cid:11)erent number of optimizations during each run.
The data from each of the three datasets was quite similar and the graph in Figure 1 and Figure 2 shows one of the datasets.
First consider the non-varying interval case.
Figure 1 shows that if the algorithm performs only a single optimization, then an average of 6349.8 auctions are won, which is about 63:5% of the desired demand.
However, if the algorithm were to optimize 15 times then the demand received would increase to about 9000, within 10% of the desired demand.
This shows that with a small number of optimizations the algorithm converges to the desired demand.
Fur-
is slightly di(cid:11)erent from the (cid:13) in the theoretical analysis, which bounds the error in the probabilities of bids.
o
 s n o i t c u








 Demand Varying Intervals Actual Demand Non-Varying Intervals Desired Demand




 Optimizations Figure 1: Demand received, as a function of number of optimizations.
The desired demand was 10,000.
The  Actual Demand  is the demand received in the experiments.
ther, if the number of optimizations is as large as 50 then the algorithm is within 5% of the desired demand.
Being able to optimize frequently can be di(cid:14)cult to do in practice because it is time consuming to receive feedback from the system.
However, even if the optimizations can not be done often, the algorithm still converges well.
Figure 2 shows the corresponding budget.
It can be seen that the budget has 3% error when no optimizations were performed.
With a large number of optimizations the budget converges with less than :4% error with 50 optimizations.
Thus, converging on the desired demand comes at little relative expense in the budget spent.
Actual Budget Spent Varying Intervals Actual Budget Spent Non-Varying Intervals Desired Budget t n e p
 t e g d u











 Optimizations Figure 2: Budget spent, as a function of number of optimizations.
The desired budget was 1.
Now consider the varying interval case.
It can be seen that the demand received and the budget spent is more variable in this case.
The demand received converges to within 10% of the desired demand when the number of optimizations is larger than 10.
The budget is more variable, however, once the number of optimizations is larger than 10 the over spent budget was no larger than 10%.
This shows that the algorithm is fairly robust to there being (cid:13)uctuations in the number of opportunities available during a single optimization.
Similar results were obtained as above when the parameters (cid:14) and (cid:12) were varied up to :8.
However, once the error parameters became too large, the algorithm could not overcome the error in the forecasts.
Further, similar results were obtain when the budget and demand were varied.
However, once the demand becomes too close to the total number of opportunities, there were not enough remaining opportunities for the algorithm to converge on the budget and demand.
Also when the budget was quite small the algorithm, naturally, was unable to win enough auctions.
In summary, this section contained experiments using real price distributions which yielded the answer \yes" for questions 1-3 in Section 5.
Forecasted Supply Fcast.
Prices too high accurate too low too low accurate too high (cid:14)=0.4 (cid:12)= 0.4 (cid:14)=0.4 (cid:12)= 0.0 (cid:14)=0.4 (cid:12)= -0.6 (cid:14)=0.0 (cid:12)= 0.4 (cid:14)=0.0 (cid:12)= 0.0 (cid:14)=0.0 (cid:12)= -0.6 (cid:14)= -0.2 (cid:12)= 0.4 (cid:14)= -0.2 (cid:12)= 0.0 (cid:14)= -0.2 (cid:12)= -0.6 Figure 3: The 9 scenarios tested in Section 7.
This section describes some additional experiments that are easier to replicate because they use synthetic rather than proprietary data.
First, in Section 7.1, the experimental setup is described, and some basic results are presented that once again demonstrate that the errors in hitting the campaign s demand and spending targets decrease with increasing k, and also that the algorithm is robust to unequal subdivision of supply between time intervals.
Then in Sections 7.2 and 7.3, the previously unaddressed questions 4 and 5 are empirically investigated.
(cid:15) True supply N = 100000 auctions.
(cid:15) Forecasted supply Nf = N (cid:1) (1 + (cid:14)), where (1 + (cid:14)) is the simulation s forecast error factor.
(cid:15) Demand Target D = 10000 auction wins.
(cid:15) Budget Target B = 2500 units of money.
(cid:15) Implied target spend per win = 0.25.
(cid:15) Competitors  bids are drawn from the lognormal distribution exp(gaussian(mean=0,sigma=4/3)).
(cid:15) The price forecast given to the bidding agent is represented by a separate ensemble of samples drawn from the same lognormal distribution, but then multiplied by the simulation s price error factor (1 (cid:0) (cid:12)).
(cid:15) Simulations were run with two di(cid:11)erent schemes for subdividing the supply amongst the time intervals: nearly equal random subdivision, which is probably better updateModels=false favorDemand=false equalIntervals updateModels=false favorDemand=false varyingIntervals






 i n
 r e p d n e p
 e g a r e v
 k=1






 i n
 r e p d n e p
 e g a r e v
 k=1 k=4 k=16 k=64






 i n
 r e p d n e p
 e g a r e v
 k=1 k=4 k=16 k=64





 Number of Auctions Won Number of Auctions Won Number of Auctions Won Figure 4: Left: Simulation results for k=1.
The 9 obvious clusters correspond to the 9 scenarios listed in Table 3, with the same layout.
Middle: Results for k in f1,4,16,64g.
Notice that as k is increased, the distribution of outcomes contracts towards the target demand of 10000 and target price of 0.25.
Right: the results are more scattered, but the same kind of contraction is evident when the supply is subdivided arbitrarily rather than equally between intervals.
Campaign Inputs: (D; B; k) Model Inputs: (Nf , Pf ) Control Inputs: (favorDemand, updateModels) // supply model // price model SM initSM(Nf ; k) PM initPM(Pf ) Da 0; Ba 0 for ka = 0 to k (cid:0) 1 do // loop over time blocks Dr D (cid:0) Da; Br B (cid:0) Ba; kr k (cid:0) ka Ne estimateRemainingSupply(SM, kr) Pe estimatePriceDistribution(PM) de(cid:12)ne: Fe(y) = 1 winratez Dr=Ne spendratey Br=Dr bidz = P (cid:0)1 (winratez) bidy = F (cid:0)1 (spendratey) winratey = Pe(bidy) if (bidz (cid:20) bidy) then curBid bidy; bidProb winratez=winratey // \feasible" case Pe(y) R y 0 b (cid:1) pe(b)db // aim for D // aim for B e e else // \infeasible" case where (bidz > bidy) if (favorDemand) then curBid bidz else curBid bidy end if bidProb 1:0 end if (numWins, amtSpent, numAuctions, competingBids) ResultsOfBlock (curBid, bidProb) Da Da + numWins Ba Ba + amtSpent if updateModels then updateSupplyModel (SM, numAuctions) updatePriceModel (PM, competingBids) end if end for Outputs: (Da; Ba) Figure 5: Pseudocode for bidding algorithm.
than reality, and unconstrained random subdivision, as described in section 6, which is probably worse than reality.
(cid:15) Nine di(cid:11)erent error scenarios were tested, each speci-(cid:12)ed by values for the supply error (cid:14) and the price error (cid:12).
These scenarios are listed in Table 3.
(cid:15) 25 simulations were performed for every combination of (intervalScheme, ErrorScenario, k).
(cid:15) The results are presented as scatter plots, with number of auctions won on the x axis, and average spend per win on the y axis.
(cid:15) Pseudocode for the simulated bidding agent appears in Figure 5.
There are control (cid:13)ags called favorDemand and updateModels.
These will be explained in Sections 7.2 and 7.3, but were both set to false for the basic simulations whose results we will now discuss.
Consider the plots in Figure 4.
The leftmost pane shows results for k=1 and equalIntervals.
There are nine obvious clusters of points which correspond to the nine error scenarios, and in fact have the same spatial layout as the table in Figure 3.
We will mention a couple of the clusters.
The middle cluster in this leftmost plot is for the accurate-forecast scenario ((cid:14) = 0; (cid:12) = 0).
Naturally, this cluster of outcomes is centered on the target demand of 10000 and the target price of 0.25.
The upper left cluster is for the scenario ((cid:14) = 0:4; (cid:12) = 0:4).
The inaccurate forecasts are causing the bidding agent to under-deliver (5000 wins) and overspend per win (price of about 0.28).
Now consider the center pane of Figure 4, in which k ranges over f1,4,16,64g.
Evidently the ensemble of outcomes (comprising 25 runs each for 9 scenarios) is contracting towards the target demand and target price as k increases.
This re-a(cid:14)rms the earlier answer of \yes" for question 1.
Now consider the rightmost pane of Figure 4, which differs from the center pane in that the simulator subvided the supply unequally rather than equally between the time intervals.
The results for the unequal subdivision are much more more scattered, but still there is an overall pattern of contraction towards the target demand and target price as k increases.
This re-a(cid:14)rms the earlier answer of \yes" for question 2.
n
 r e p d n e p
 e g a r e v
 i n
 r e p d n e p
 e g a r e v




















 updateModels=false favorDemand=false varyingIntervals updateModels=F favorDemand=F eqIntvls (delta=beta=0.4) k=1 k=4 k=16 k=64 k=1 k=2 k=3 k=4 k=6 k=8 k=12 k=16 k=24 k=32 k=48 k=64 k=96






 i n
 r e p d n e p
 e g a r e v





 Number of Auctions Won

 Number of Auctions Won updateModels=false favorDemand=true varyingIntervals updateModels=F favorDemand=T eqIntvls (delta=beta=0.4) k=1 k=4 k=16 k=64 k=1 k=2 k=3 k=4 k=6 k=8 k=12 k=16 k=24 k=32 k=48 k=64 k=96






 i n
 r e p d n e p
 e g a r e v





 Number of Auctions Won

 Number of Auctions Won Figure 6: These plots are discussed in x7.2.
Figure 7: These plots are discussed in x7.2.
Investigation of Z > Y Case In this section we investigate Question 4: what should the algorithm do when the demand-based bid z exceeds the spending-based bid y?
This case can occur in reality, but it violates a simplifying assumption that was made during the theoretical analysis.
The experimental investigation of this case involves new algorithmic details:
 The favorDemand (cid:13)ag in the pseudocode of Figure 5 determines which bid is used in the assumption-violating \in-feasible" case where the demand-based bid z is greater than the spending-based bid y.
If favorDemand=true, then the algorithm will use the demand-based bid z, and will attempt to ful(cid:12)ll the demand even though that might result in overspending.
If favorDemand=false, then the algorithm will use the spending-based bid y, and will avoid overspending but will tend to fall short of satisfying the demand.
It is worth pointing out that in the \feasible" case z (cid:20) y (which was assumed in the theoretical analysis) there is no corresponding policy question because it is possible to simultaneously hit the demand and spending targets.
To study the policy question for the z > y case, we ran all of the experiments on synthetic data twice, once with favorDemand=false and once with favorDemand=true.
Some of the results are shown in Figure 6.
Both panes contain scatter plots showing the outcomes of 25 runs each of the 9 error scenarios, with 4 di(cid:11)erent values of k, all with with unequal division of supply between time blocks.
The top pane shows results for favorDemand=false, while the bottom pane shows results for favorDemand=true.
The results are qualitatively similar, except for the larger number of magenta squares near the top of the bottom plot, indicating that some of the 25*9 runs for k = 64 ended up paying an excessive average price per auction win.
Further investigation showed that the runs in which the k = 64 runs overpaid were mostly for the ((cid:14) = 0:4; (cid:12) = 0:4) error scenario, which for k=1 causes a bidder to under deliver and overpay per auction win.
To more clearly illustrate what is going on, consider the plots in Figure 7, which only contains results for the ((cid:14) = 0:4; (cid:12) = 0:4) scenario, and which were obtained under the less-noisy simulation conditions where supply is equally divided between time intervals.
The top pane in Figure 7, which is for favorDemand=false, shows that as k is increased, the algorithm s demand achieved and average price paid initially moves towards the target values, but then seems to asymptote at values that fall short of the targets.
The bottom pane in Figure 7, which is for favorDemand=true, shows a very di(cid:11)erent behavior.
The amount of demand sat-is(cid:12)ed continues to increase with increasing k, but the price paid stops decreasing and starts increasing around k = 24.
k=1 k=2 k=3 k=4 k=6 k=8 k=12 k=16 k=24 k=32 k=48 k=64 k=96








 Number of Auctions Won updateModels=T favorDemand=T eqIntvls (delta=beta=0.4) k=1 k=2 k=3 k=4 k=6 k=8 k=12 k=16 k=24 k=32 k=48 k=64 k=96






 i n
 r e p d n e p
 e g a r e v
 i n
 r e p d n e p
 e g a r e v


 Number of Auctions Won Figure 8: These plots are discussed in x7.3.
This is actually a general phenomenon that can occur whenever the following three conditions are met:
 behind in satisfying the demand target.
mains.
This can only happen for larger values of k.
the price curve in pursuit of the faster win rates that would allow it to catch up.
Notice that the favorDemand=true policy can climb too far up the price curve, but the favorDemand=false policy cannot.
In summary, when forecast errors are such that the z > y case arises, one can adopt the favorDemand=false policy and end up with some demand that is unsatis(cid:12)ed even for large k, or one can adopt the favorDemand=true policy and end up with an excessive average price that is exacerbated by large k.
It is in this situation, where increasing k does not strictly improve the outcome, that the idea of updating the erroneous forecasts begins to sound attractive.
That idea is explored in the next section.
In this section we investigate Question 5: Can updating the forecasts yield better results?
This involves some new algorithmic details.
The updateModels (cid:13)ag in the pseudocode of Figure 5 determines whether the supply and price models are updated after each time block.
We note that the basic algorithm, as considered in all previous sections, corresponds to update-Models=false.
This paper does not address the question of how to optimally update the models given the hypothetical feedback that would enable those updates.
Instead, the models are updated in a very simple way that su(cid:14)ces to give some preliminary insight into question 5.
When updateModels = false, remaining supply is estimated as follows: (the variables here are explained in Table 9) Ne = kr (cid:1) Nf k When updateModels = true, remaining supply is estimated as follows: Ne = kr (cid:1) wNf + Na wk + ka The rate at which observations overcome the forecast is a(cid:11)ected by the parameter w. In these experiments, w = 1, so at the end of the simulation, the initial forecast and the observed data have approximately equal weight.
The initial price model is represented by a set of samples drawn from the true price distribution and multiplied by the error factor (1 (cid:0) (cid:12)).
If updateModels = false, this initial model is never changed, but if updateModels = true, the model is updated after each time block by unioning the model s current set of samples with the set of competing bids observed during that time block.
The rate at which observations overcome the forecast is affected by the size of the initial set of samples.
In these experiments, there are 100000 samples in the initial forecast, and 100000 opportunities during the campaign, so at the end of the simulation the initial forecast and the observed data have equal weight.
To study the question of whether a simple scheme for updating forecasts can yield improved performance, we ran all of the experiments on synthetic data twice, once with up-dateModels=false, and once with updateModels = true.
In all, we performed 23400 simulations, which are (25 tries) * (9 error scenarios) * (13 values of k) * (2 supply subdivision schemes) * (2 values for favorDemand) * (2 values for up-dateModels).
The general impression one obtains from looking at all of the resulting plots is that updating the models tends to give a tighter concentration of results around the target values, but not greatly so.
Due to space limitations, here we will just exhibit the plots in Figure 8, which correspond directly to the plots in Figure 7, except that the models are being updated in Figure 8.
A comparison of the top panes in the two (cid:12)gures, which are both for favorDemand=false, shows that the updating algorithm was able to get past the demand value of about 9000 at which the non-updating algorithm was asymptoting.
Dr Da
 Br Ba k kr ka Nf Ne Na Pf Pe Demand Target Demand Remaining Unsatis(cid:12)ed Demand Already Satis(cid:12)ed Budget Target Budget Remaining Unspent Budget Already Spent Number of Time Blocks Time Blocks Remaining Time Blocks Already Occurred Forecasted Total Supply Estimated Remaining Supply Supply actually observed so far Forecasted Price Distribution Estimated Price Distribution The following are hidden from the bidder.
N (cid:3) P (cid:3) (cid:14) (cid:12) True total Supply True Price Distribution Supply Error: Nf = N (cid:3) (cid:1) (1 + (cid:14)) Price Error: Pf = P (cid:3) (cid:1) (1 (cid:0) (cid:12)) Figure 9: Explanation of variables appearing in the pseudocode of Figure 5.
A comparison of the bottom panes in the two (cid:12)gures, which are both for favorDemand=true, shows that the average price paid by both algorithms starts to increase above a certain value of k. However, the average price paid for any given value of k is less for the updating algorithm.
Most online advertising today is sold via real-time auctions in which advertisers are represented by automated bidding agents that bid strategically in an attempt to achieve various goals including hitting demand targets and spending targets over a speci(cid:12)ed period of time.
The inputs to these agents typically include machine-learned models of the world which facilitate extrapolation from the past to the future and from common events to rare events.
Given their extrapolative function, it is not surprising that these models are imperfect.
While improving the accuracy of the models is a worthwhile research goal, in this paper, we have instead assumed that the models of future supply and future prices are inaccurate, and investigated the question of how a bidding agent can win the right number of impressions and spend the right amount of money given this inaccuracy.
In Theorem 4.1, we proved that, subject to certain feasibility conditions, a very simple bidding strategy, which only requires occasional feedback of the number of auctions actually won and the amount of money actually spent, quickly converges to the bidder s desired budget and demand.
We have also provided experimental evidence in Sections 5 through 7 that the proposed bidding strategy is robust enough to work even when some of the simplifying assumptions in the formal analysis are violated.
