Search engine has become the most convenient way for people to  nd their information on the Web, which is the world s largest encyclopedic source.
Unfortunately, in response to the query for the facts or speci c attributes about
 with kNowleDge basE via semaNtic knowledge.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
certain named entity, search engine always returns a  at, long list of Web pages containing the name of that entity.
The users are then forced either to re ne their queries by adding new keywords or to browse through every returned Web page which is quite time consuming.
Therefore, the trend to advance the functionality of search engine to a more expressive semantic level has attracted a lot of attention in recent years.
To achieve this goal, it is a vital step to construct a comprehensive machine-readable knowledge base about the world s entities, their semantic classes and their mutual relationships.
Recently, many large scale publicly available knowledge bases including DBpedia [1], YAGO [27, 26] and KOG [28, 29] have emerged.
As world evolves, new facts come into existence and are digitally expressed on the Web.
Therefore, maintaining and growing the existing knowledge bases become more and more important.
However, inserting new extracted knowledge derived from the information extraction systems into an existing knowledge base inevitably needs a system to map the entity mention associated with the extracted knowledge to the corresponding real world entity in the knowledge base.
This entity linking task is challenging due to name variations and entity ambiguity.
In reality, an entity may have multiple surface forms.
For example, the entity of  National Basketball Association  has its abbreviation  NBA  and the entity of  New York City  has its nickname  Big Apple .
On the contrary, one entity mention may also refer to several di er-ent real world entities.
For instance, the entity mention of  Michael Jordan  can refer to the famous basketball player, the computer science professor or some other persons.
Entity linking is the task to link a textual entity mention, possibly identi ed by a named entity recognizer in the unstructured text, with the corresponding real world entity in the existing knowledge base.
If the matching entity of certain entity mention does not exist in the knowledge base, NIL (denoting an unlinkable mention) should be returned for this entity mention.
This task is also known as entity resolution, record linkage, or entity reconciliation.
Entity linking is bene cial for many information extraction applications.
For example, relation extraction is the process of discovering useful relationships between named entities mentioned in the text [11, 30, 9], and the extracted relations require the process of mapping entities associated with the relations to the knowledge base before they can be populated into the knowledge base.
Besides, a large number of question answering systems rely on their supported knowledge bases to date of the famous basketball player Michael Jordan, the system should  rstly leverage the entity linking approach to map the queried  Michael Jordan  to the NBA player, not to the Berkeley s professor; and then it retrieves the birth date of the NBA player named  Michael Jordan  from the knowledge base directly.
The emergence of large scale knowledge bases has spurred great interests in the entity linking task.
Several methods [4, 6, 7] have been proposed to address this problem and they all aim to map the entity mention to its corresponding entity page in Wikipedia.
Generally speaking, the essential step of entity linking is to de ne a similarity measure between the text around the entity mention and the document associated with the entity.
Previous proposed methods [4, 6, 7] all use the bag of words model to measure the context similarity and consider this kind of similarity as an important feature to make the  nal decision.
The bag of words model represents the context as a term vector consisting of the terms occurring in the window of text and their associated weights.
Here,  terms  means words, phrases, named entities or Wikipedia concepts depending on the di erent methods.
Anyway, in the bag of words model, similarity is measured by the co-occurrence statistics of terms and cannot capture various semantic relations existing between concepts.
The entity mention would be mapped to the corresponding entity in knowledge base only if the compared texts contain some identical contextual terms.
However, by leveraging the semantic relation existing between concepts, the similarity can also be bridged by the semantically related concepts.
For instance, we assume the knowledge base contains the following two entities which could be referred by the same name  Michael Jordan :   Entity name: Michael J. Jordan Description text: American basketball player   Entity name: Michael I. Jordan Description text: Berkeley professor in AI When the entity mention appears in the text  Michael Jordan wins NBA champion. , we should map this occurrence of  Michael Jordan  to the American basketball player, because the concept  NBA  around the entity mention is highly semantically related to  American  and  Basketball  which are the concepts appearing in the description text associated with the entity  Michael J. Jordan .
While in this situation, the bag of words model cannot work well.
In this paper, we propose LINDEN, a novel framework to link named entities in text with a knowledge base unifying Wikipedia and WordNet by leveraging the semantic knowledge derived from Wikipedia and the taxonomy of the knowledge base.
It is assumed that the named entity recognition process has been completed, and we focus on the task of linking the detected named entity mention with the knowledge base.
Speci cally, we collect a dictionary about the surface forms of entities from four sources in Wikipedia (i.e., entity pages, redirect pages, disambiguation pages and hyperlinks in Wikipedia article), and record the count information for each target entity in the dictionary.
Using this dictionary, we can generate a candidate entity list for each entity mention and try to include all the possible corresponding entities of that mention in the generated list.
Furthermore, we leverage the count information to de ne the link probability for each candidate entity.
Subsequently, we recognize all the Wikipedia concepts in the document where the entity mention appears.
By leveraging the link structure of the Wikipedia pages and the taxonomy included in the ontology, we start by constructing a semantic network among the recognized Wikipedia concepts and candidate entities.
Via this constructed semantic network, semantic as-sociativity which is derived from the Wikipedia link structure and semantic similarity measured from the taxonomy of the knowledge base can be calculated among Wikipedia concepts and candidate entities.
In addition, we de ne the global coherence for each candidate entity to measure the global document-level topical coherence among the mapping entities in the document.
And then we can give a rank to the candidate entity list for each entity mention with the combination of these four measures, link probability, semantic associativity, semantic similarity and global coherence.
Furthermore, LINDEN learns how to return NIL for the entity mention which has no matching entity in the knowledge base.
To validate the e ectiveness of LINDEN, we empirically evaluate it over two public data sets (i.e., Cucerzan s ground truth data [6] and the standard TAC2 data set).
The experimental results show that LINDEN greatly outperforms the previous methods in terms of accuracy.
The main contributions of this paper are summarized as follows.
  We present LINDEN, a novel framework which leverages the rich semantic information derived from Wikipedia and the taxonomy of the knowledge base to deal with the entity linking task.
  We propose a novel method to measure the semantic similarity between Wikipedia concepts based on the taxonomy of the knowledge base.
  We extensively evaluate LINDEN for the entity linking task over two public data sets.
The experimental results show that LINDEN can achieve signi cantly higher accuracy on both data sets compared with the state-of-the-art methods.
The rest of the paper is organized as follows.
Section 2 discusses related work and Section 3 introduces the LINDEN framework and some notations.
Next, Section 4 describes how to generate candidate entities for the entity mention.
Section 5 presents the approach for entity disambiguation, and NIL mention prediction is introduced in Section 6.
Section 7 presents our empirical results and Section 8 draws conclusions.
Name ambiguity is very common on the Web and has raised serious problems in many di erent areas such as Web people search, question answering and knowledge base population.
Before the emergence of large scale publicly available knowledge bases, named entity disambiguation is called coreference resolution and is regarded as a clustering task.
Entity mentions of a particular name either within one document or across multiple documents are clustered together, and each resulting cluster represents one speci c real world entity.
This problem has been addressed by many researchers starting from Bagga and Baldwin [2], who used the bag of 2http://www.nist.gov/tac/ and applied the agglomerative clustering technique based on the vector cosine similarity.
Mann and Yarowsky [16] extended the work by adding a rich feature space of biographic facts.
Pedersen et al. [25] employed the statistically signi cant bigrams to represent the context of a name observation.
After that, several methods [14, 15, 3] tried to capture the semantic relation between terms via constructing social networks to add the background knowledge for disambiguation.
The work in [22, 10] adopted the graph based framework to extend the similarity metric to disambiguate the entity mentions e ectively.
However, all these studies focus on clustering all mentions of an entity within a given corpus, which are insu cient for the entity linking task.
As several knowledge bases like DBpedia [1] and YAGO [27, 26] are available publicly, researchers have shown a great interest in mapping the textual entity mention to its corresponding entity in the knowledge base.
Bunescu and Pasca [4]  rstly tackled this problem by exploiting a set of useful features derived from Wikipedia for entity detection and disambiguation.
They leveraged the bag of words model to measure the cosine similarity between the context of the mention and the text of the Wikipedia article.
Besides, to overcome the de ciency of the bag of words model, they used a disambiguation SVM kernel which models the magnitude of each word-category correlation based on the Wikipedia taxonomy.
The work proposed by Cucerzan [6] is the  rst system to recognize the global document-level topical coherence of the entities.
The system addresses the entity linking problem through maximizing the agreement between the text of the mention document and the context of the Wikipedia entity, as well as the agreement among the categories associated with the candidate entities.
This work assumes that all entity mentions have the corresponding entities in the knowledge base, however, this assumption fails for a large number of mentions in reality.
The learning based solution in [7] focuses on the classi cation framework to resolve entity linking.
It develops a rich set of features based on the entity mention, the source document and the knowledge base entry, and then uses a SVM ranker to score each candidate entity.
Moreover, this solution incorporates NIL prediction into the ranker, which obviates hand tuning.
However, the performance of these previous methods is largely based on the feature of context similarity which depends on the term co-occurrence between the text around the entity mention and the document associated with the entity.
Therefore, they ignore the semantic knowledge existing between concepts.
Furthermore, the knowledge bases used in these methods are directly derived from the Wikipedia, and the categories in Wikipedia are not clean and well-formed enough for the ontological purpose although they are indeed arranged in a hierarchy.
Hence, the semantic knowledge embedded in the taxonomy of concepts cannot be well taken advantage of by these methods.
The task of entity linking is similar to the lexical task of word sense disambiguation (WSD) in some aspects.
The task of WSD aims to assign dictionary meanings to all instances of a prede ned set of polysemous words in a corpora [23, 18, 24].
For instance, it has to choose whether the word  tree  in some speci c context refers to the meaning of plant or data structure in the  eld of computer science.
Recently, people start to use Wikipedia as a resource for word sense d
 m   M0
 e   E Em

  d   Fm(e) w   Scorem(e) LP (e|m) SA(e) SS(e) GC(e) Table 1: Notations A document to be processed All named entity mentions in d A named entity mention required to be linked All entities in KB An entity label, here, the entity name in KB The set of candidate entities for mention m All candidate entities for all mentions in M0 The label for the unlinkable mention The set of context concepts in d The feature vector for entity e   Em Weight vector Score of entity e   Em Threshold for returning NIL The link probability of entity e, given m Semantic associativity of entity e with  d Semantic similarity of entity e with  d Global coherence of entity e in d disambiguation.
Given an input document, these systems are able to automatically enrich the input text with links to Wikipedia pages [19, 21, 12].
However, this task is di er-ent from our entity linking task in several respects:  rstly, these systems have to decide whether the detected terms or phrases are important enough in the document to be linked to Wikipedia due to considering the system users  experience, which raises the problem of tradeo  between precision and recall.
On the contrary, entity linking is the task to just map every detected entity mention in the text to the knowledge base to pursue high accuracy.
Secondly, the named entity mentions like common person or place names have much higher average ambiguity compared with the keywords or concepts in the task of word sense disambiguation.
Therefore, the entity linking task has much more challenges in comparison with the WSD task.
Thirdly, the entity linking task has to encounter the problem that some entity mentions have no matching entities in the knowledge base.
Consequently, it must learn how to predict NIL for the unlinkable mentions, while the word sense disambiguation task has no such problem.
In this paper, entity linking is de ned as the task to map a textual named entity mention m, already recognized in the unstructured text, to the corresponding real world entity e in the knowledge base.
If the matching entity e for entity mention m does not exist in the knowledge base, we should return NIL for m. The knowledge base we adopt in this work is YAGO [27, 26], an open-domain ontology combining Wikipedia and WordNet with high coverage and quality.
The reasons why we choose YAGO as the knowledge base are as follows.
On one hand, YAGO has the vast amount of entities in the same order of magnitude as Wikipedia.
On the other hand, it adopts the clean taxonomy of concepts from WordNet [8] which can be made fully use of by our LINDEN.
Currently, YAGO contains over one million entities and  ve million facts about them.
We process one document at a time, so we consider the entity mentions appearing in one document together.
Given an input document d, M0 is the set of named entity mentions m   M0 is a token sequence of a named entity that is potentially linked with an entity in the knowledge base, which has been detected beforehand.
E is the set of all entities in the knowledge base, and an entity is expressed as the entity name in the knowledge base and denoted as e. Since some mentions  mapping entities do not exist in the knowledge base, we de ne this kind of mentions as unlinkable mentions and give NIL as a special label denoting  unlinkable .
In this paper, we propose LINDEN, a framework to address this entity linking task with three modules as follows:   Candidate Entity Generation For each named entity mention m   M0, we retrieve the set of candidate entities Em in this module.
Using a dictionary collected from four sources in Wikipedia (i.e., entity pages, redirect pages, disambiguation pages and hyperlinks in Wikipedia article), we try to include all the possible candidate entities for each m   M0 in Em.
E0 is the set of all candidate entities for all mentions in M0.
  Named Entity Disambiguation In most cases, the size of Em is larger than one, so we de ne a scoring measure for each e   Em and give a rank to Em to  nd which entity e   Em is the mostly likely link for m. We  rstly recognize all the Wikipedia concepts  d in the context of d and regard them as context concepts to represent the context of d. And then we de ne a rich set of features and generate a feature vector Fm(e) for each e   Em.
The features used in LINDEN are mainly based on the link probability LP (e|m), semantic associativity SA(e) of entity e with the context concepts in  d derived from the Wikipedia link structure, semantic similarity SS(e) of entity e with the context concepts in  d measured from the taxonomy of YAGO, and global coherence GC(e) of entity e with the other mapping entities associated (cid:4)= m   M0.
We also learn a   with the mentions m w which gives di erent weights for each weight vector   feature element in Fm(e).
Then we can calculate a w   Fm(e) for each e   Em and rank the candi-score dates according to their Scorem(e).
  Unlinkable Mention Prediction (cid:2) To deal with the problem of predicting unlinkable mentions, we learn a threshold   in this module to validate whether the entity etop which has the highest score in Em is the target entity for mention m. If Scorem(etop) is smaller than the learned threshold   , we return NIL for mention m.
Those three modules are introduced in the following sections in details and some notations used in this paper are summarized in Table 1.
Given an entity mentionm   M0, we generate the set of candidate entities Em in this module.
Intuitively, the candidates in Em should have the name of the surface form of m. To solve this problem, we need to build a dictionary that contains vast amount of information about the surface forms of entities, like name variations, abbreviations, confusable names, spelling variations, nicknames, etc.
We take advantage of the huge amount of knowledge available in Wikipedia, a free online encyclopedia created through decentralized, collective e orts of thousands of users3.
Wikipedia is the largest encyclopedia in the world and is also a very dynamic and quickly growing resource.
English Wikipedia contains over 3,500,000 articles and new articles are added within days after their occurrence.
The structure of Wikipedia provides a set of useful features for the construction of the dictionary we need, such as redirect pages, disambiguation pages and hyperlinks in Wikipedia article.
Besides, Wikipedia has high coverage of named entities [31], which is pro table for constructing our dictionary.
We use the following four structures of Wikipedia to build the dictionary about the surface forms of entities:   Entity pages: Each entity page in Wikipedia describes a single entity and contains the information focusing on this entity.
Generally, the title of each page is the most common name for the entity described in this page, e.g., the page title  Microsoft  for that giant software company headquartered in Redmond.
When the name of the entity is ambiguous, it is further qual-i ed with a parenthetical expression.
For example, the article for the English goalkeeper Michael Jordan has the title  Michael Jordan (footballer) .
Therefore, we store not only the exact article title but also the surface form from which we eliminate appositives, i.e.,  Michael Jordan  in this example.
  Redirect pages: A redirect page exists for each alternative name which can be used to refer to an existing entity in Wikipedia.
For example, the article titled  Microsoft Corporation  which is the full name of  Microsoft  contains a pointer to the article titled  Microsoft .
Redirect pages often indicate synonym terms, abbreviations or other variations of the pointed entities.
  Disambiguation pages: When multiple entities in Wikipedia could be given the same name, a disambiguation page is created to separate them and contains a list of references to those entities.
For example, the disambiguation page for the name  Michael Jordan  lists eight associated entities having the same name of  Michael Jordan  including the famous NBA player and the Berkeley professor.
These disambiguation pages are very useful in extracting abbreviations or other aliases of entities.
  Hyperlinks in Wikipedia article: The article in Wikipedia often contains hyperlinks which link to the pages of entities mentioned in this article.
The anchor text of a link pointing to an entity page provides a very useful source of synonyms and other variations of the entity, and can be regarded as the surface form of that linked entity.
Using the above mentioned structures in Wikipedia, we can construct the dictionary containing all surface forms for each entity.
In the mean time, we record the count information for each target entity which is linked by some surface forms as well.
An example of the dictionary is shown in Table 2.
For each mention m   M0, we look up the dictionary 3http://www.wikipedia.org/ Surface form Microsoft Corporation Target entity Microsoft Michael Jordan Michael I. Jordan Michael Jordan Michael Jordan (mycologist) Michael Jordan (footballer) New York .
.
.
New York City New York (magazine) New York ( lm)  New York  (Eskimo Joe song) .
.
.
Count




 .
.
.
.
.
.
and search for the mention m directly in the  eld of surface forms.
If a hit is found, we add all target entities of that surface form m to the set of candidate entities Em.
It can be seen from the count information in Table 2 that each e   Em having the same surface form m has di erent commonness and some entities are very obscure and rare for the given surface form m. For example, for the surface form  New York , the entity  New York ( lm)  is much rarer than  New York City , and in most cases when people mention  New York , they mean the city of New York rather than the  lm whose name is also  New York .
Hence, we take advantage of this count information and de ne the link probability LP (e|m) for entity e as: LP (e|m) = countm(e) (1) (cid:2) ei Em countm(ei) where countm(e) is the number of links which point to entity e and have the surface form m. The candidate entities with very low link probability will be discarded.
In this section, we describe how to give a rank to Em when the size of Em generated in Section 4 is larger than one.
Our guiding premise is that a document largely refers to coherent entities or concepts from one or a few related topics, and we exploit this  topical coherence  for named entity disambiguation.
To achieve this goal, we  rstly recognize all the Wikipedia concepts  d in the document d, and by leveraging the rich semantic knowledge embedded in Wikipedia and YAGO, we construct a semantic network among the recognized Wikipedia concepts  d and candidate entities E0, which will be described in Section 5.1.
From the semantic network, we can see the rich semantic relations existing among Wikipedia concepts  d and candidate entities E0, however, it does not explicitly provide the value of the semantic relation s strength.
In order to measure the semantic relation s strength, we show how to compute the semantic associativity SA(e) of entity e based on the Wikipedia link structure and semantic similarity SS(e) of entity e derived from the taxonomy of YAGO in Section 5.2 and Section 5.3, respectively.
Besides the semantic relation existing between  d and E0, we exploit the global document-level topical coherence among entities which are chosen to be mapped to by the mentions in M0.
The global coherence GC(e) of entity e is measured as the average semantic associativity of entity e to the other mapping entities associated with the mentions (cid:2) (cid:4)= m   M0, which will be introduced in details in Sec-m tion 5.4).
Combining those features introduced above, we generate a feature vector Fm(e) for each e   Em and learn a     w which gives di erent weights for each fea-weight vector w   Fm(e) ture element in Fm(e).
Then we calculate a score for each e   Em and rank the candidates according to their Scorem(e), which will be introduced in Section 5.5.
To construct the semantic network, we start by recognizing the Wikipedia concepts  d in the context of the document d, and regard them as context concepts to represent the context of d. For the general textual document, we utilize the open source toolkit Wikipedia-Miner4 to detect the Wikipedia concepts appearing in the context.
The Wikipedia-Miner toolkit takes the general unstructured text as input and uses the machine learning approach to detect the Wikipedia concepts in the input document [21].
For instance, the entity mention of  Michael Jordan  occurs in a document containing such a sentence,  The Chicago Bulls  player Michael Jordan won his  rst NBA championship in
 tion, and then utilize this Wikipedia-Miner toolkit to obtain four Wikipedia concepts, i.e., Chicago Bulls, National Basketball Association, NBA Finals and Chicago.
Therefore, it can be seen that these detected Wikipedia concepts are highly semantically related to the NBA player Michael Jordan, and we can leverage this semantic information to link this entity mention  Michael Jordan  with the corresponding real world entity (i.e., the NBA player Michael Jordan) in the knowledge base e ectively.
As we know, for the document from the Wikipedia, it has its special layout to organize its content, i.e., Wiki markup5.
The references to other Wikipedia concepts in the Wikipedia document are within pairs of double square brackets, which can be exploited to identify the Wikipedia concepts easily.
Illustratively, the Wikipedia article for the entity Bill Gates, the billionaire, contains the following Wikitext: Gates was born in [[Seattle]], Washington, of [[English people|English]], [[Germans|German]], and Scotch-Irish descent.
In this Wikitext, there are three references which surround with double square brackets.
If a reference contains a vertical bar (e.g.,  English people|English ), then the text at the left of the bar is the name of the referred Wikipedia concept (e.g.,  English people ), while the text at the right of the bar (e.g.,  English ) is the anchor text of this link.
Otherwise, the anchor text is identical to the title of the Wikipedia concept referred (e.g.,  Seattle ).
Henceforth, for the Wikipedia document, we can identify the Wikipedia concepts appearing in it directly by leveraging the characteristic of Wiki markup.
Wikipedia contains rich semantic information between concepts and the hyperlink structure of Wikipedia articles is one important form of expressing semantics.
Therefore, we add all the link relations and the associated Wikipedia articles to our constructed semantic network.
Moreover, the taxonomy of concepts in YAGO also expresses the semantic relation between Wikipedia concepts which we call semantic similarity.
Hence, we add the taxonomic relations among these detected context concepts and candidate entities as well.
Figure 1 shows an example of the constructed seman-4http://wikipedia-miner.sourceforge.net/index.htm
 A ll-Star Game D avid Joel Stern Charlotte Bobcats Chicago Bulls Context concept Candidate entity Link relation W ikipedia article Concept in taxonomy Taxonomic relation Michael J.
Jordan Michael I.
Jordan Natio n al Bas ketb all A s s o ciatio n N epal Basketball A ssociation Figure 1: An example of the constructed semantic network tic network.
The four candidate entities in Figure 1 are generated from two entity mentions (i.e.,  Michael Jordan  and  NBA ), and each of the entity mentions has two candidate entities respectively.
From the constructed semantic network, we can see that the candidate entities  Michael J.
Jordan  and  National Basketball Association  are more semantically related to the four context concepts compared with the other two candidate entities.
Moreover, the semantic relations between  Michael J. Jordan  and  National Basketball Association  also show the highly global topical coherence.
Therefore, we can predict that  Michael J. Jordan  and  National Basketball Association  are the mapping entities for the entity mentions  Michael Jordan  and NBA , respectively.
Though the link relations among the context concepts  d and candidate entities E0 in Figure 1 express high semantic relations, this structure does not explicitly provide the exact value of the semantic relation s strength.
In order to measure the strength of the link relation, we adopt the Wikipedia Link-based Measure (WLM) described in [20] to calculate the semantic associativity between Wikipedia concepts.
Since all the context concepts  d and candidate entities E0 in our work are Wikipedia concepts, we can leverage this measure of WLM directly.
The WLM which is modeled from the Normalized Google Distance [5] is based on Wikipedia s hyperlink structure.
Given two Wikipedia concepts e1 and e2, we de ne the semantic associativity between them as follows: SmtAss(e1, e2) = 1  log(max(|E1|, |E2|))   log(|E1 (cid:3) log(|W|)   log(min(|E1|,|E2|))
 (2) where E1 and E2 are the sets of Wikipedia concepts that link to e1 and e2 respectively, and W is the set of all concepts in Wikipedia.
The numerator is a slight variation of Jaccard similarity and the denominator is inversely related to min(|E1|,|E2|).
Therefore, this de nition gives higher value to more related concept pair.
The feature value of semantic associativity SA(e) for each entity e is de ned as the average of its semantic associativity to each context concept in  d: (cid:2) SA(e) = cc d SmtAss(cc, e) | d| (3)
 In this subsection, we propose a novel method to measure the semantic similarity between Wikipedia concepts based on the taxonomy of the knowledge base.
According to the rules of constructing YAGO ontology in [27], each Wikipedia concept may have multiple super classes in the taxonomy.
Given two Wikipedia concepts e1 and e2, we assume the sets of their super classes are  e1 and  e2 , respectively.
To measure the semantic similarity between Wikipedia concepts, we  rstly de ne how to calculate the semantic similarity between the sets of their super classes.
Since the sizes of  e1 and  e2 , and the elements in  e1 and  e2 are likely to be di erent, we start by de ning the correspondence between the elements of classes from one set to another set.
For each class C1 in the set  e1 , we assign a target class  (C1) in another set  e2 as follows:  (C1) = arg max C2 e2 sim(C1, C2) (4) where sim(C1, C2) is the semantic similarity between two classes C1 and C2, and  (C1) is the class in  e2 which maximizes the semantic similarity between these two classes.
To compute sim(C1, C2), we adopt the approach introduced in [13] which is an information-theoretic method.
Assuming the taxonomy is a tree and C is a class in the taxonomy, the amount of information contained in the statement  x   C  is  log(P (C)), where P (C) is the probability that a randomly selected object belongs to the subtree with the root of C in the taxonomy.
We assume that C0 is the class which is the most speci c class that subsumes both C1 and C2 in the taxonomy, in other words, C0 is the root of the smallest following is the de nition of the semantic similarity between two classes C1 and C2 in the taxonomy: sim(C1, C2) =
 log(P (C1)) + log(P (C2)) (5) Next, we can calculate the semantic similarity from one set of classes  e1 to another set of classes  e2 : (cid:2) sim( e1    e2 ) = C1 e1 sim(C1,  (C1)) | e1| (6) Identically, we can calculate the semantic similarity from  e2 to  e1 , i.e., sim( e2    e1 ), in the similar way to that in Formula 6.
Based on the de nitions mentioned above, we can de ne the semantic similarity between Wikipedia concepts e1 and e2 as the average of the semantic similarity from  e1 to  e2 and that from  e2 to  e1 : sim( e1    e2 ) + sim( e2    e1 ) SmtSim(e1, e2) = (7) Intuitively, there might be some context concepts having similar types to entity e but it is unlikely that all the types of context concepts are similar to the entity e s type.
Therefore, we de ne the set of k context concepts in  d which have the highest semantic similarity with entity e as  k and the parameter k is set empirically.
We calculate the feature value semantic similarity SS(e) for entity e as follows:
 (cid:2) cc k SmtSim(cc, e) SS(e) = k (8)
 In this subsection, we exploit the global document-level topical coherence among entities which should be linked with by the mentions in M0.
In this work, the global coherence GC(e) of entity e is measured as the average semantic as-sociativity of entity e to the mapping entities of the other (cid:2) (cid:4)= m   M0.
If em(cid:2) is the mapping mentions m , then for entity e, the global coherence entity of mention m GC(e) is de ned as , where m (cid:2) (cid:2) GC(e) =  m(cid:2)(cid:4)=m M0 (SmtAss(em(cid:2) , e))
 (9) (cid:2) Unfortunately, em(cid:2) , the mapping entity of mention m , is unknown to us and needs to be assigned in this task.
It can be seen that the assignment of an entity to a mention depends on all the other assignments made for other mentions, which makes this a di cult optimization problem.
In this paper, we adopt an arguably more robust strategy which is to calculate the average semantic associativity of entity e to the most likely assigned entities of the other mentions.
The most likely assigned entity e is considered as the candidate entity which has the maximum link probability in Em(cid:2) .
(cid:2) m(cid:2) = arg max e(cid:2) Em(cid:2) (cid:2) m(cid:2) for mention m (cid:2)|m LP (e (10) e ) (cid:2) (cid:2) Now the computation of global coherence GC(e) in Formula
 puted directly.
GC(e) =  m(cid:2)(cid:4)=m M0 (SmtAss(e
 (cid:2) m(cid:2) , e)) (11)
 Combining those features introduced in the subsections above, we can generate a feature vector Fm(e) for each e   Em where Fm(e) =< LP (e|m), SA(e), SS(e), GC(e) >.
The di erent features in Fm(e) have di erent degrees of im-  portance for the entity disambiguation task.
Therefore, we w which gives di erent weights for learn a weight vector   each feature element in Fm(e).
Then we calculate Scorem(e) for each e   Em,where Scorem(e) = w   Fm(e).
Finally, we rank the candidates according to their Scorem(e) and pick etop = arg maxe Em Scorem(e) as the predicted mapping entity for mention m.
  w , we use a max-margin technique based on the training data set.
Given the ground truth mapping entity   e ) is larger than any other Scorem(e) with a margin, where e   Em and e (cid:4)= e .
This gives us the usual SVM linear constraints for all linkable mentions:   w   Fm(e for mention m, we assume that Scorem(e w   Fm(e)   1    m and we minimize over  m   0 and the objective ||  w||2 )     To learn (12)
        m m where   is the usual balancing parameter.
The approach discussed above implicitly assumes that the knowledge base contains all the matching entities of the mentions.
But in practice, this assumption fails in many cases without a doubt.
Therefore, we have to deal with the problem of predicting unlinkable mentions in LINDEN.
Firstly, if the size of Em generated in the Candidate Entities Generation module for mention m is equal to zero, we predict mention m as an unlinkable mention and return NIL for mention m undoubtedly.
If the size of Em is equal to one, we assume the only entity in Em as etop and regard it as the predicted mapping entity for mention m. When the size of Em generated in Section 4 is larger than one, we give a score to each e   Em in the Named Entity Disambiguation module and pick etop = arg maxe Em Scorem(e) as the predicted mapping entity for mention m. In this module, our task is to validate whether the predicted entity etop is the target entity for mention m. We adopt a simple method and learn a threshold   to validate the predicted entity etop.
If Scorem(etop) is greater than the learned threshold   , we return etop as the target entity for mention m, otherwise we return NIL for m.
To evaluate the performance of LINDEN, we have to choose some test data sets available publicly.
The experimental data used by Bunescu and Pasca [4] is not publicly available.
The newswire data used by Cucerzan [6] (which we refer to  CZ ) is available and we use it to test our LINDEN.
The data set  IITB  built by Kulkarni et al.
in [12] is unsuitable for our task since they annotated a broad set of types of entities rather than named entities due to their aggressive recall target, which is similar to the WSD task addressed in [19, 21].
In addition, entity linking is initiated as a task in the track of Knowledge Base Population (KBP) at the Text Analysis Conference (TAC) recently.
The data # of total mentions All Linkable Unlinkable



 #


 Accu.
Cucerzan #


 Accu.
set for TAC-KBP20096 is available for us so we use it as another test data set for LINDEN.
We downloaded the October 2010 version of Wikipedia and YAGO(1)7 of version 2009-w10-5 for our experiments.
In the following subsections, we will introduce the experimental results of LINDEN over the two test data sets, i.e., the CZ data set and the TAC-KBP2009 data set, respectively.
To evaluate the performance of LINDEN, in this paper we adopted the evaluation measure Accuracy (Accu.)
which is used in most work about entity linking [4, 6, 7] and TAC-KBP2009[17].
The accuracy is calculated as the number of   correctly linked entity mentions divided by the total number w and all parameters of all mentions.
The weight vector are tuned using 10-fold cross validation over the CZ data set.
Since in the CZ data set, it is fairly common for one of the mentions of an entity in the document to be a long and typical surface form of that entity (e.g., Bob Nardelli), while the other mentions of the same entity are shorter surface forms (e.g., Nardelli).
To address this problem, we used a simple in-document coreference resolution method which is to map short surface form to longer surface form in the same document before generating candidate entities for mentions.
The original data set in [6] contains 20 news stories which include the top two stories in each of the ten MSNBC news categories of January 2, 2007.
But unfortunately, one of the MSNBC news articles is no longer available, so we used the remaining 19 articles.
Meanwhile, the contents of these articles have changed slightly compared with them at the time Cucerzan annotated, therefore, we removed the entity mentions which did not appear in the articles we downloaded.
Lastly, we obtained 614 entity mentions in those articles to construct the CZ data set, in which there are 522 entity mentions which are manually linked to the knowledge base and another 92 mentions are unlinkable.
Since the CZ data set we used in this experiment is di er-ent from the original data set in [6], the accuracy of 0.914 achieved by Cucerzan s system reported in [6] is not comparable.
In order to give a fair comparison, we implemented the algorithm of Cucerzan s system and evaluated it over the CZ data set.
The experimental results of LINDEN and our implemented Cucerzan s system over the CZ data set are shown in Table 3.
Besides the number of total mentions, we also show the number of correctly linked mentions and the accuracy for both LINDEN and our implemented Cucerzan s system with di erent types (i.e., all, linkable and unlinkable).
From the results in Table 3 we can see that LINDEN achieves signi cantly higher accuracy compared with the Cucerzan s system in all aspects.
Though the system reported in [7] obtained the accuracy of 0.9469 in CZ data 6http://apl.jhu.edu/ paulmac/kbp.html 7http://www.mpi-inf.mpg.de/yago-naga/yago/ Table 4: Feature set e ectiveness over the CZ data set All Linkable Unlinkable Accu.
# Accu.
Feature Set
 #









 Accu.
#





 set, this result is not comparative with the result of our system due to the following reasons:  rstly, they removed 297 mentions not recognized as entities by SERIF from the test data set; Secondly, the knowledge base they used is a subset of Wikipedia, which enabled many mentions to be unlink-able.
Consequently, the test data set they used to evaluate their method contains total 452 mentions in which there are 187 unlinkable mentions, which is greatly di erent from the original test data set in [6].
We also analyzed the e ectiveness of di erent feature sets to LINDEN s performance.
Table 4 shows the accuracy and the number of correctly linked mentions obtained by LINDEN with di erent feature sets.
It can be seen from Table 4 that every feature has a positive impact on the performance of LINDEN, and with the combination of all features LINDEN can obtain the best result.
The improvement achieved by adding semantic associativity (SA) feature to link probability (LP) feature is greater than what can be achieved by adding one of the other two features (i.e., semantic similarity (SS) feature and global coherence (GC) feature), which indicates that the feature of semantic associativity is quite useful to deal with entity linking problem.
Since these features correlate with each other quite closely, we can just get slight improvement by adding SS feature to the feature set of LP and SA, and the same thing occurs when adding GC feature to the feature set of LP, SA and SS.
data set The TAC-KBP2009 test data set consists of 3904 entity mentions (which they call queries) in which 1675 entity mentions can be aligned to their knowledge base.
There are 2229 entity mentions which cannot be mapped to their knowledge base and hold 57% of the total queries.
The reason why most queries are unlinkable in the TAC-KBP2009 data set is that the knowledge base they used to annotate these queries is   a subset of Wikipedia and only contains the set of entities w and that have infoboxes in Wikipedia.
The weight vector all parameters are tuned using 10-fold cross validation over the TAC-KBP2009 data set.
Since in LINDEN we use the whole information in Wikipedia to generate candidate entities in the Candidate Entities Generation module, we have to add some unlinkable mentions prediction strategies to the module of Unlinkable Mentions Prediction described in Section 6 in order to directly use the ground truth annotation of the TAC-KBP2009 data set.
Before we learn the threshold   to validate the predicted entity etop in the Unlinkable Mentions Prediction module, we  rstly verify whether the predicted entity etop exists in the knowledge base of TAC-KBP2009.
If it exists in the knowledge base of TAC-KBP2009, we go on the following steps KBP2009 data set compared with top 4 ranked systems in TAC-KBP2009 Accu.
of all Accu.
of linkable Accu.
of unlinkable














 System Rank 1 Rank 2 Rank 3 Rank 4
 Feature Set



 Table 6: Feature set e ectiveness over the TAC-KBP2009 data set All Linkable #



 Accu.
#



 Accu.
Unlinkable # Accu.
introduced in Section 6, otherwise, we return NIL for this mention directly.
In addition, the track of TAC-KBP2009 requires the systems who participate in the track to process the queries independently from one to another, which means they require that systems cannot leverage the knowledge among the set of queries according to the task description of TAC-KBP20098.
Meanwhile, the total 3904 entity mentions exist in 3688 documents each of which has at most two mentions in its context according to the statistics of the TAC-KBP2009 data set.
Therefore, we removed the feature of global coherence (GC) introduced in Subsection 5.4 in the following experiments for two reasons.
On one hand, the systems in TAC-KBP2009 did not leverage the knowledge among the set of queries, so we want to give a relatively fair comparison of LINDEN with these systems.
On the other hand, the global coherence feature can hardly have any positive impacts on the performance of LINDEN in this data set according to the data distribution mentioned above.
In addition, due to many spelling errors existing in the set of queries, we also try to correct them using the query spelling correction supplied by Google.
The experimental results of LINDEN over the TAC-KBP2009 data set are shown in Table 5.
The results of the top 4 systems which perform best in the track of TAC-KBP2009 [17] are also shown in Table 5 for the purpose of comparison.
Moreover, the system introduced in [7] is the rank 3 system in TAC-KBP2009 track and obtains the overall accuracy of
 Table 5 show that LINDEN outperforms the best systems in TAC-KBP2009, which demonstrates the e ectiveness of
 We also show the e ectiveness of di erent feature sets to LINDEN s performance over the TAC-KBP2009 data set in Table 6.
The overall accuracy of LINDEN only using link probability (LP) feature is higher than the rank 4 system in TAC-KBP2009, which demonstrates that the link probability feature is also quite useful for this task.
From the other results in Table 6 we can get the similar conclusion to what we get over the CZ data set.
The impact of semantic asso-8http://apl.jhu.edu/ paulmac/kbp/090601- KBPTaskGuidelines.pdf ciativity (SA) feature is greater than the semantic similarity (SS) feature when dealing with entity linking problem, and with the combination of all features LINDEN can obtain the best result.
Entity linking is a very important task for many applications such as Web people search, question answering and knowledge base population.
In this paper, we propose LINDEN, a novel framework to link named entities in text with YAGO, a knowledge base unifying Wikipedia and WordNet.
By leveraging the rich semantic knowledge derived from the Wikipedia and the taxonomy of YAGO, LINDEN can obtain great results on the entity linking task.
A large number of experiments were conducted over two public data sets, i.e., the CZ data set and the TAC-KBP2009 data set.
Empirical results show that LINDEN signi cantly outperforms the state-of-the-art methods in terms of accuracy.
Moreover, all features adopted by LINDEN are quite e ective for the entity linking task.
This work was supported in part by National Basic Research Program of China (973 Program) under Grant No.
under Grant No.
60833003, and an HP Labs Innovation Research Program award.
