The study of strategic network formation seeks to understand the emergent behavior and properties of a network when self-interested agents establish connections to other agents based on their local information.
In general, establishing a connection incurs a cost but also yields some bene t to agents connected through that edge.
The agents are deemed to be utility-maximizing, that is, they make decisions in order to maximize the difference between their total ben-e t and their total cost.
This problem has been studied in many different settings [11, 2, 8, 5, 1].
One can ask interesting questions about the emergent properties of the networks formed in each setting: What network topologies are feasible in equilibrium?
How do equilibrium networks differ from socially optimal ones?
How does this depend upon the cost of forming an edge and the bene t derived from having a connection?
If there are multiple equilibria, can agents select among them through some kind of iterated better-response dynamics?
This paper is an investigation into some of these questions in the context of credit networks, an abstraction for modeling trust among autonomous agents.
A credit network represents trust relationships through a directed graph with edge capacities.
Nodes in this graph correspond to agents, and edges correspond to credit relationships between them.
An edge of capacity c from node u to node v indicates that agent u extends c units of credit to agent v, or equivalently, u is committed to accept IOUs (obligations) issued by v up to value c. The capacity of this edge can be viewed as a measure of u s trust in v. Nodes pay for goods and services by issuing their own IOUs, instead of using a common currency.
Credit commitments between trusting nodes also enable remote transactions, as illustrated in Fig. 1.
Say node w wants to buy a good worth p units from node u.
Nodes u and w can transact even though u does not directly trust w via the trusted intermediary v. Assuming p   min{c1, c2}, the payment proceeds by w issuing an IOU to v worth p units, and v issuing an IOU to u worth p units.
If, however, p > min{c1, c2}, the transaction fails.
As a result of a successful transaction, the credit capacities cuv and cvw decrease by p, representing the remaining credit commitments.
In addition, the capacities cvu and cwv both increase to p from zero, since v and w will both accept the return of their own IOUs as payment.
Thus arbitrary payments can be routed through a credit network by passing IOUs along a chain of trusting agents, obviating the need for a common currency.
Observe that routing payments in credit networks is identical to routing residual  ows in general  ow networks.
Also note that payment  ows in the opposite direction of credit, so a payment merely results in a redistribution of credit: buyers expend credit and sellers gain it while intermediaries exchange credit between their neighbors, but the total credit in the network remains unchanged.
u w w c1 v c2 (a) Before the transaction p p v c1   p c2   p (b) After the transaction Figure 1: Updating credit to process a transaction between u and w worth p units.
The credit network model was introduced independently by De-Figueiredo and Barr [7], Ghosh et al. [9], and Karlan et al. [13] as a mechanism for enabling transactions among untrusting agents in a network.
This model is particularly well-suited for transactions in exchange economies such as P2P networks where it has been shown to improve inef ciencies resulting from asynchronous demand and bilateral trading [14].
It has been used to thwart spam in email and content-sharing systems such as YouTube [16].
It can also be used in settings such as packet routing in mobile ad-hoc networks and combating spam in viral marketing over social networks.
There is a large body of work in economics and sociology on social capital and favor exchanges in networks [10].
This model not only provides a rigorous way of keeping track of favors owed to and by each individual in a network, but also facilitates exchange of favors, via trusted intermediaries, between individuals who do not know each other directly.
Prior research shows that liquidity (ability to route payments) in many credit network topologies is comparable to that in equivalent centralized currency systems [6].
Whereas that work takes the credit network to be exogenously de ned, here we address the question of how credit networks may be formed in the  rst place.
We endogenize network formation by explicitly modeling the decision by each agent to issue credit to others.
Issuing credit entails risk (a counterparty may violate the trust extended), as well as bene ts (it increases the probability that pro table transactions may be completed).
A natural question is whether agents who rationally weigh these risks and bene ts will actually form viable credit networks.
Network formation in the presence of risk was recently studied by Blume et al. [4] in a model motivated by  nancial contagion and epidemic diseases.
In their setting, nodes derive utility only from direct edges, whereas risk is contagious (i.e., failure of distant nodes is also a source of risk).
Our model  ips this: nodes derive bene t from transactions along direct as well as multi-hop paths, whereas only direct edges are sources of risk.
In our model, each agent has a credit budget representing the total credit that agent can extend others.
Agents play a one-shot game where they determine how much credit to extend other agents, and then engage in repeated probabilistic transactions over the formed credit network.
Agents derive utility from successful transactions.
Extending credit to other agents increases transaction success probability, thus contributing to utility.
On the other hand, when agent u extends credit to agent v, u risks a potential loss of utility resulting from violation of the trust it placed in v. Thus, an agent s net utility is its total utility from successful transactions minus the utility loss from extending credit to untrustworthy agents.
We analyze the formation of credit networks under various models of risk.
We start with a model of dichotomous risk: agents are embedded in a social network represented by an undirected graph.
Agents trust their neighbors in the social network and may extend credit to them.
However, they associate a very high loss of utility with extending credit to non-neighbors, and consequently, never extend credit to them.
This setting captures situations illustrated by the following examples where directly transacting with a stranger may have grave consequences.
  During a disease epidemic within a human population, high-risk groups will limit their interactions to those who belong to similar social circles.
Evidence of this has been found, for example, in the setting of HIV/AIDS [12, 3].
  Users trying to circumvent Internet censorship and evade network surveillance in repressive regimes make use of Internet proxies [15].
If caught, penalties may be severe.
Thus, users rely on their friends and acquaintances to distribute proxy addresses.
  Members of covert organizations face the prospect of severe harm at the hands of the enemy if their identity is compromised.
As a result, they may rely on longstanding relationships and assets built over time to conduct their business.
We also study a model of global risk, which represents the other extreme with respect to the dichotomous risk model.
In this model, each node has a publicly known risk of default.
This corresponds to situations involving small, densely interacting social groups, or where there are organizations such as credit-reporting agents that systematically gather and disseminate relevant risk information.
Finally, we study a model of graded risk that helps bridge the gap between global and dichotomous risk.
Under this model, each agent has a private default probability.
Agents receive noisy signals about each other s probability of defaulting, and these signals are more informative for neighbors in the social network.
Dichotomous Risk Under dichotomous risk, when we allow only bilateral transactions (i.e., transactions only between adjacent nodes in the social network, and payments routed only along the direct edge between nodes), we show that the formation game is a potential game (Theorem 3.1).
This implies that best-response dynamics always converge to a Nash equilibrium1.
Moreover, for a large, natural class of transaction size distributions, we show that agents  utilities are concave in their credit allocations.
This allows us to prove that every Nash equilibrium of the game maximizes social welfare (Theorem 3.4).
More interestingly, we show that the Nash equilib-ria are equivalent in a much stronger sense: any two Nash equilibria are cycle-reachable from each other (Theorem 3.6), which means that it is possible to transform one equilibrium into another by routing a sequence of payments from a node to itself along a feasible path.
The signi cance of this structural property follows from [6]: for any two Nash equilibria s and s of the game, if an arbitrary sequence of transactions is feasible starting from s, that sequence is also feasible starting from s (cid:2) (cid:2) .
With non-bilateral transactions, the game becomes signi cantly less well-behaved: the game may not admit a Nash equilibrium (Theorem 3.8), and even when it does, the price of anarchy in this setting can be unbounded (Theorem 3.9).
Global Risk Under global risk, we analyze the price of anarchy and the structure of equilibria when each agent is limited to extend credit to at most one other agent.
We prove if we disallow the empty network as an outcome, the price of anarchy of the formation game
 Nash equilibrium, except when we explicitly consider mixed strategy equilibria of simulated games in Section 4.2.
a star-like structure (Theorem 4.3).
Instead we focus on the structure of equilibria under two simple dynamics: sequential arrival and myopic best response.
When nodes arrive sequentially and create a single link, we show that a node u always extends credit to either the node v that arrived immediately before u or to the node that v extends credit to (Theorem 4.6).
Thus the resulting network has a comb-like structure.
Under myopic best response, nodes extend their entire credit budget to the node that has the lowest risk of default.
If the default risks are unique, this results in a star-like network structure which is also the optimal structure in terms of social welfare (Theorem 4.5).
Thus, even though the price of anarchy can be unbounded, nodes can easily  nd the optimal network using myopic best response.
Simulations We use empirical game simulation to study a more general formulation of the global risk model,  nding that nonempty equilibrium networks tend to have a centralized, star-like structure due to use of default probability as a primary credit-issuing criterion.
We also analyze several graded risk settings, and  nd that centralized networks only arise when defaults are relatively rare, and otherwise, credit links tend to be issued over short social distances conforming to the locality of information.
Let V denote the set of n agents.
Each agent u   V has a budget Bu   0 representing the total credit that u can extend to other agents in V .
Agents play a one-shot game where they choose credit allocations to form an initial network s. Agents represent nodes of the formed network.
An edge from node u to node v of (cid:2) capacity cuv(s) represents the credit extended by agent u to agent v in the network s. A strategy for agent u is a set of feasible credit allocations {cuv(s), v   V : cuv(s)   0 and v V cuv(s)   Bu}.
u,v  uv = 1.
Once a network s is formed, agents engage in repeated probabilistic transactions with each other.
At each time step t = 1, 2, .
.
.
, a pair of transacting agents (cid:5)u, v(cid:6), with u being the payer (buyer) and v the payee (seller), is chosen with probability  uv.
The transaction rate matrix   = { uv : u, v   V } is public, and sat-(cid:2) is es the following properties: (i)  uu = 0, (ii)  uv   0, and (iii) Suppose agents (cid:5)u, v(cid:6) are chosen to transact at time t. Then the transaction size, xt uv, between u and v is drawn from a transaction size distribution over [0,  ) with a probability density function (pdf) guv( ) and a corresponding cumulative distribution function (cdf) Guv( ).
We assume that the pdfs guv( ) are public.
Let G := {guv( ) : u, v   V } be the pdf matrix.
Given a transaction size x, a feasible path in the network s from node v to node u is a set of directed edges P = {(v, u1), (u1, u2), .
.
.
, (uk 1, uk), (uk, u)} such that for all (w, y)   P, cwy(s)   x.
We route payments along the shortest feasible path in the network.
Let P t vu be the shortest feasible path in the credit network from v to u at time t. A successful transaction of size xt uv results in a change of credit capacities along edges in P t vu as follows.
Let st := {cuv(st) : u, v   V } denote the state of the network s at time t = 0, 1, 2, .
.
., where s0 = s. Then, for w, y   V and for t >0 ,     cwy(st 1)   xt uv, cwy(st 1) + xt uv, cwy(st 1), cwy(s t ) = if (w, y)   P t 1 if (y, w)   P t 1 otherwise vu vu So, in order for a payment xt uv from u to v to succeed, there must exist a feasible path in the credit network from the payee v to the payer u.
If no such path exists, the transaction fails, in which case all credit capacities remain unchanged.
Thus, for all t >0 , and for all u, v   V, cuv(st) + cvu(st) = cuv(s) + cvu(s).
The repeated probabilistic transactions induce a Markov chain over the states of the network, which we denote by M(s,  ,G).
A transaction regime is de ned as the tuple (cid:5) ,G(cid:6).
We say a transaction regime (cid:5) , G(cid:6) is symmetric if the transaction rate matrix   is symmetric: for all nodes u, v   V,  uv =  vu, and the transaction size pdfs are symmetric: for all u, v   V, guv( ) = gvu( ).
We are interested in the success probabilities of transactions in the steady-state of this Markov chain, which are dif cult to characterize for arbitrary networks and transaction regimes.
However, we can do so in some simple cases, including the unit transaction regime.
DEFINITION 2.1.
A unit transaction regime over credit network s is a transaction regime (cid:5) ,G(cid:6) where, for all u, v   V and for all t >0 , the transaction size xt uv = 1, the transaction rate matrix   is symmetric and the Markov chain M(s,  ,G) is ergodic.
When the network s is acyclic (ignoring directionality), Dandekar et al. [6] characterize the steady-state success probabilities under a unit transaction regime.
([6]).
Consider a credit network s. Assume that s is acyclic if we ignore the directions of the edges in s. Let Puv be the set of (undirected) edges along the path between nodes u and v. Then, in a unit transaction regime over s, the steady-state transaction success probability, fuv(s), between two nodes u, v   V is given by
 (cid:6) (cid:8)cwy(s)(cid:9) + (cid:8)cyw(s)(cid:9) (cid:8)cwy(s)(cid:9) + (cid:8)cyw(s)(cid:9) + 1 fuv(s) =  uv e=(w,y) Puv
 Agents choose credit allocations to maximize their utility.
Successful transactions contribute to agents  utility, but agents risk loss of utility when they extend credit to potentially untrustworthy agents.
We model this risk in several ways, but denote the expected loss of utility to u associated with the prospect of default by v by  uv(s), with the constraints that  uv(s)   0 and  uv(s) > 0 only if cuv(s) > 0.
Let fuv(s) be the steady-state success probability of the transactions from u to v when the initial network is s.
Then, the total utility of an agent u when the initial network is s is given by (cid:7) (cid:7) Uu(s) =   w V fuw(s)    uv(s) (1) v V :cuv (s)>0 where   is a constant that converts transaction success probability into equivalent utility units.
The overall social welfare in network s is simply the sum of utilities of all nodes in s: U (s) = (cid:2) u V Uu(s).
In order to model variation in  uv(s), we assume that the agents are embedded in an exogenously-de ned social network represented by a simple undirected graph H = (V, E).
The social network H in uences the how  uv(s) for an agent u varies across agents v   V .
We consider three speci c models of how risk changes as a function of distance between u and v in H.
Dichotomous Risk.
In this model, an agent u partitions the set of agents V into two sets using H: neighbors in H and non-neighbors in H. For any network s, agent u estimates risk exposure (cid:8)  uv(s) = if (u, v)   E otherwise
  , (2) This model assumes agents are willing to interact only with their neighbors in H. For any credit network s formed under this model, cuv(s) = 0 if (u, v) /  E.
Global Risk.
In this model, we assume that each agent v has a default probability  v   (0, 1] which is public.
If v defaults, a node u that extended credit cuv(s) to v loses cuv(s) units.
Thus,  uv(s) =  vcuv(s).
Graded Risk.
Here, as in the Global Risk model, each agent v has default probability  v, but this information is not publicly known.
Instead, each agent u receives a signal  uv about the default probability of each other agent v. These signals are decreasingly informative with distance in H, so agents know much more about the default probabilities of their neighbors in the social network than about distant nodes.
In our simulations, we implement this by drawing agents  default probabilities from a beta distribution:  v   Beta( ,  ).
Agent u then receives a signal in the form of some number of samples Suv drawn from the binomial distribution on  v, where Suv decreases exponentially with social network distance.
Recall that under dichotomous risk,  uv(s) is de ned by (2), as a result nodes only extend credit to their neighbors in H.
We call a transaction between nodes u and v bilateral if (u, v)   E and the payment is routed along the edge (u, v).
Here we allow only bilateral transactions: if a payment between adjacent nodes u and v cannot be routed along the direct edge (u, v), we fail the transaction.
As a result, if (u, v) /  E, the steady-state success probability fuv(s) = fvu(s) = 0.
Moreover, the steady-state transaction success probabilities along an edge e = (u, v) in a network s are governed only by the credit allocations, cuv(s), cvu(s), along e in s. We also assume that the transaction regime (cid:5) , G(cid:6) is symmetric and that  uv > 0 if (u, v)   E. As a result, for all nodes u and v, fuv(s) = fvu(s).
In our analysis of the symmetric bilateral transaction regime, for an edge e = (u, v)   E, we will use  e, ge( ), Ge( ) and fe( ) to denote  uv, guv( ), Guv( ), and fuv( ), respectively.
We  rst show that in this setting, the network formation game is a potential game.
THEOREM 3.1.
The network formation game under a symmetric bilateral transaction regime is a potential game.
PROOF.
Consider the function  (s) de ned as (cid:7) (cid:7) (cid:7)  (s) := U (s)
 =

 Uu(s) = u V fuv(s) u V v V  
 Since we are in a symmetric bilateral transaction regime, fuv(s) = fvu(s) for all (u, v)   E, and fuv(s) = 0 if (u, v) /  E. Therefore, (cid:7) This implies  (s) =   e E fe(s).
We will show that  (s) is a potential function.
Fix a node u   V .
Consider a network s which differs from s only in the credit allocation of u.
Formally, for all (cid:2) (cid:7) u V (cid:7) (cid:2) v V fuv(s) = 2 fe(s) e E w, y   V , (cid:8) (cid:2) cwy(s), (cid:2) c wy, if w (cid:11)= u if w = u and (u, y)   E ) = cwy(s where {c uy : (u, y)   E} is any feasible allocation of u s credit.
(cid:2) Let Eu   E be the set of edges incident upon u in E. Note that (cid:2) (cid:2) for all e ).
As a result, = (u (cid:2) fe(cid:2) (s) = fe(cid:2) (s  (s)    (s (cid:2) ) /  Eu, cu(cid:2)v(cid:2) (s) = cu(cid:2)v(cid:2) (s (cid:7) , v ).
It follows that = Uu(s)   Uu(s ) =   fe(s)   fe(s (cid:2) ) (cid:9) (cid:10) (cid:2) ) (cid:2) (cid:2) e Eu (cid:11) (cid:12) ce(s)
 Thus the network formation game is a potential game with  (s) as the potential function.
Theorem 3.1 implies that in this setting, a Nash equilibrium always exists, best-response dynamics always converge to a Nash equilibrium, and  nally, because the potential function is given by  (s) = U (s)/2, the price of stability is 1.
Next we will show that for a large, natural class of transaction size distributions, agents  utilities are concave, and consequently, the price of anarchy is also
 social welfare.
Consider an edge e = (u, v)   E. Assume that ge( ) has support over [0,  ).
Also, let Ge( ) be twice differentiable.
First we derive an expression for fe(s) in terms of the credit allocations cuv(s) and cvu(s) along edge e.
LEMMA 3.2.
Consider a credit network s. For nodes u, v   V such that e = (u, v)   E, the steady-state transaction success probability, fe(s), under a symmetric bilateral transaction regime is given by fe(s) = fe(ce(s)) =  e ce(s) Ge(y)dy,
 if ce(s) > 0 if ce(s) = 0 (3) where ce(s) = cuv(s) + cvu(s) is the total credit allocated along edge e in s.
The proof is omitted due to space constraints.2 Observe from (3) that fe(s) depends only on the total credit capacity ce(s) along the edge e = (u, v).
Therefore, for the rest of this section, instead of thinking of fe as a function of cuv(s) and cvu(s), we will think of fe as the function fe : R+   [0, 1].
That is, fe(x) is the steady-state transaction success probability along edge e when the total credit allocated along it is x.
We will write fe(s) to mean fe(ce(s)) when there is no ambiguity.
Next we prove some properties of the functions fe( ) that enable us to establish that every Nash equilibrium maximizes social welfare.
LEMMA 3.3.
Consider a credit network s under a symmetric bilateral transaction regime.
For an edge e   E,
 differentiable and strictly increasing.
As a corollary, if ge( ) is strictly decreasing, fe( ) is strictly concave.
Many natural distributions have strictly decreasing density
 available at http://www.stanford.edu/~ppd/papers/ cn-formation.pdf.
tion, the normal distribution N (0,  2), and the power-law distribution.
Next we show that if the transaction success probabilities, fe( ), are concave, every Nash equilibrium maximizes social welfare.
THEOREM 3.4.
Let s be a Nash equilibrium of the network formation game under a symmetric bilateral transaction regime.
If the transaction success probabilities, fe( ), e   E, are concave, then s maximizes social welfare U (s).
(cid:2) PROOF.
Recall from Theorem 3.1 that the formation game under a symmetric bilateral transaction regime is a potential game and e E fe(s) is a potential function.
Recall  (s) = U (s)/2 =   from Lemma 3.3, that fe( ), e   E, are continuously differentiable, which implies  ( ) is continuously differentiable.
Since fe( ) are concave (by assumption),  ( ) is also concave.
It was shown by Neyman [17] that any Nash equilibrium of a potential game with a concave and continuously differentiable potential is also a potential maximizer.
Therefore, s maximizes  (s), or equivalently, U (s).
(cid:2) (cid:2) Theorem 3.4 implies an equivalence between the Nash equilibria of the game; any two Nash equilibria s and s have the same social ).
Next we show that if fe( ), e   E, are welfare, U (s) = U (s strictly concave, the Nash equilibria of this game are equivalent in a much stronger sense: any two Nash equilibria s and s are cycle-reachable, which, as shown by Dandekar et al. [6], implies that the sequences of transactions that succeed starting from s and starting from s are identical.
(cid:2) (cid:2) We  rst show that the total credit capacity of any edge in E is identical in any Nash equilibrium.
LEMMA 3.5.
Let fe( ), e   E, be strictly concave.
Let s and be two Nash equilibria of the network formation game.
Then for (cid:2) s all edges e   E, ce(s) = ce(s PROOF.
First, let us de ne the marginal utility of an edge e   ).
(cid:2)
 DEFINITION 3.1.
The marginal utility of an edge e   E is the function re : R+   R+ given by (cid:2) e(x) = re(x) = f dfe(x) dx (cid:2) We show that for any edge e   E, re(s) = re(s ).
The lemma follows as a direct consequence.
Since fe( ) is strictly concave (by assumption), strictly increasing and continuously differentiable (by Lemma 3.3), re( ) is continuous, strictly decreasing and strictly positive.
In network s, the marginal utility on an edge e   E is given by re(ce(s)).
We denote it by re(s) when there is no ambiguity.
Let Eu be the set of edges in E incident upon node u.
DEFINITION 3.2.
For a node u   V and a network s, we de ne u(s)   Eu as the set of edges    u(s) := maxe Eu re(s) and E e   Eu such that re(s) =  u(s).
  u(s) is the set of edges incident on node u that have the In words, E highest marginal utility in network s among all edges in Eu.
We show that in any Nash equilibrium s, each node u exhausts its entire budget and allocates nonzero credit only along edges in E   u(s).
PROPOSITION 1.
Let s be a Nash equilibrium.
Then, for all nodes u   V , both (1) and (2) are true: (cid:2)

 v:(u,v) E cuv(s) = Bu.
Next we de ne a slack edge.
  u(s) then cuv(s) = 0.
DEFINITION 3.3.
Let s be a Nash equilibrium.
We call an edge   v (s) or e = (u, v)   E a slack edge in s if e /  E both.
u(s) or e /  E   Note that by Proposition 1, if edge e = (u, v) is a slack edge in Nash equilibrium s, either cuv(s) = 0 or cvu(s) = 0 or both cuv(s) = cvu(s) = 0.
DEFINITION 3.4.
Let s be a credit network.
We de ne 1. rmin := mine E re(s) to be the minimum marginal utility s of any edge e   E in s, := {e   E | re(s) = rmin := {u   V | u is incident on some edge in Emin }, s s },

 s s and
 s   V min :={u   V | u is incident upon some edge in E as s min s
 s
 and upon some edge in E   E min s } The minimum marginal utility in any two Nash equilibria is identical.
PROPOSITION 2.
Let s and s rmin s = rmin s(cid:2) .
(cid:2) be two Nash equilibria.
Then Moreover, in any two Nash equilibria s and s (cid:2) , the set of edges (cid:2) with the minimum marginal utility in s is identical to that in s .
PROPOSITION 3.
Let s and s s = Emin Emin .
s(cid:2) (cid:2) be two Nash equilibria.
Then COROLLARY 3.1.
Let s and s V min s = V min s = V X s(cid:2) .
and V X s(cid:2) (cid:2) be two Nash equilibria.
Then s (cid:2) (cid:2) Thus, we have established that for any two Nash equilibria s and , re(s) = re(s .
We show using an ) for all edges e   Emin s inductive argument that this is true of all edges in E.
DEFINITION 3.5.
Given an instance I : G = (V, E); fe, e   E; Bu, u   V of the network formation game under a symmetric bilateral transaction regime, a network s, and an arbitrary set of edges F   E, we de ne the (s, F )restriction of I, denoted I(s,F ), as follows: G(F ) := (V, E \ F ), f := fe, e   E \ F , and
 e (s,F )
 u if Eu   F (u,w) F cuw(s) otherwise Note that for a node u, if Eu   F , then the value of B is immaterial since u has no incident edges in I(s,F ) along which to allocate its budget.
(s,F ) u Bu  (cid:2) (cid:8) :=
 DEFINITION 3.6.
Given a network s and an arbitrary set of edges F   E, we de ne an F restriction of s, denoted, s(F ), as follows: for all edges e = (u, v)   E \ F, cuv(s(F )) = cuv(s) and cvu(s(F )) = cvu(s).
PROPOSITION 4.
If s is a Nash equilibrium for instance I of the network formation game in the bilateral transaction setting, then s(F ) is a Nash equilibrium for I(s,F ) for any set F   E.
PROPOSITION 5.
Let s and s be two Nash equilibria for instance I of the network formation game under a symmetric bilateral transaction regime.
Then for all edges e   E, re(s) = re(s (cid:2) ).
Observe that since fe( ) is strictly concave, re( ) is strictly decreasing.
Therefore, Proposition 5 implies that for all e   E, ce(s) = (cid:2) ce(s ).
Lemma 3.5 allows us to show that any two Nash equilibria are cycle-reachable.
(cid:2) (cid:2)
 ([6]).
Let s and s be two credit networks.
(cid:2) is cycle-reachable from s if s can transformed into s We say that s by routing a sequence of payments along feasible cycles (i.e., from a node to itself along a feasible path).
THEOREM 3.6.
Let fe( ), e   E, be strictly concave.
Let s be two Nash equilibria of the network formation game under are cycle-and s the symmetric bilateral transaction regime.
Then s and s reachable from each other.
(cid:2) (cid:2) PROOF.
First we de ne the generalized score vector of a credit
 network s.
([6]).
Given a credit network s of n nodes, the generalized score vector of s is the vector D(s) = (cid:5)du(s) : u   V (cid:6)   R Next we show that any two Nash equilibria have the same generalized score vector.
+ where for all u   V, du(s) := v V cvu(s).
(cid:2) n PROPOSITION 6.
Let s and s be two Nash equilibria.
Then, (cid:2) (cid:7) (cid:2) ).
(cid:7) D(s) = D(s PROOF.
Fix a node u   V .
Recall from Proposition 1 that cuv(s) = v:(u,v) E v:(u,v) E (cid:2) cuv(s ) = Bu Also, from Lemma 3.5, we know that for all edges e   E, (4) (5) Let Eu be the set of edges in E incident upon u.
It follows from (4) and (5) that
 Here we lift the restriction that transactions be bilateral, allowing transactions between nodes that are not neighbors in H. We also allow payments between neighboring nodes to be routed along paths other than the direct edge between them.
x
 y a 1   x b 1   y d e h

 j Figure 2: Example of a formation game that does not admit a Nash equilibrium.
THEOREM 3.8.
There exists an instance of the network formation game under a symmetric transaction regime that does not admit a Nash equilibrium.
PROOF.
We will construct an instance of network formation game and show that it does not admit a Nash equilibrium.
Consider a game with six agents: V = {a, b, d, e, h, j}.
The graph H is a line graph over nodes in V with edges (a, b), (b, d), (d, e) and so on.
For each node u   V, Bu = 1.
The nonzero transaction rates are given by:  ab =  ba =  de =  ed =  hj =  jh = 0.001,  ae =  ea =  bj =  jb = 0.2435,  ej =  je = 0.01.
All other entries in the transaction rate matrix   are zero.
All transactions are of size one.
Observe that this is a unit transaction regime, so we can use Lemma 2.1 to compute the steady-state transaction success probabilities between nodes.
Let s be a Nash equilibrium.
Then, it must be that cab(s) = cde(s) = chj (s) = cjh(s) = 1.
Let cbd(s) = x and cba(s) =
 since all transactions are of size one, and s is a Nash equilibrium, it must be that x, y   {0, 1} (i.e., x and y cannot be strictly between
 namely, (0, 0), (0, 1), (1, 0) and (1, 1), either b or e has an improving unilateral deviation.
In fact, the four combinations form a best-response cycle.
Hence, there is no assignment of x, y   [0, 1] that will ensure that s is a Nash equilibrium.
ce(s) = ce(s ) (cid:2) (cid:7) v:(u,v) E (cid:7) e Eu (cid:7) (ce(s)   cuv(s)) (cid:7) e Eu (cid:2) ) = du(s cuv(s e Eu du(s) = cvu(s) = cvu(s) = ce(s)   Bu = (cid:2) ce(s )   (cid:7) (cid:7) v V = e Eu Next we show that even if agents reach a Nash equilibrium, it may be arbitrarily bad in terms of social welfare compared to a social optimum.
(cid:2) )
 ([6]).
Two credit networks s and s reachable if and only if D(s) = D(s ).
(cid:2) are cycle-Proposition 6 along with Proposition 7 complete the proof.
(cid:2)
 are cycle-reachable, The signi cance of this result is that if s and s they support the same set of feasible transactions.
([6]).
Let s1 and s2 be two cycle-reachable networks.
If a transaction   = (cid:5)u, v, p(cid:6) (i.e., routing p units from node u to node v) is feasible in s1, it is also feasible in s2.
Further, (cid:2) if transaction   in network s1 results in a network s 1, and the same (cid:2) (cid:2) transaction in network s2 results in a network s 1 and s
 are cycle-reachable.
(cid:2) 2, then s Thus, for two Nash equilibria s and s of the game, if a sequence of transactions succeeds starting from s it also succeeds starting from (cid:2) .
Observe that this equivalence between Nash equilibria implied s by Theorem 3.6 is stronger than that implied by Theorem 3.4.
(cid:2) (cid:2)



 b c (a) An equilibrium network s
 b

   (b) An optimal network s
 c a a d d Figure 3: Example of a game with an unbounded price of anarchy.
THEOREM 3.9.
The price of anarchy of the network formation game under a symmetric transaction regime is unbounded.
PROOF.
We will construct an instance of the game and show that it has an unbounded price of anarchy.
Consider a game with four agents: V = {a, b, c, d}.
The graph H is a line graph over (cid:7) u V

 v V

 =  1   nodes in V with edges (a, b), (b, c) and (c, d).
For each node u   V, Bu = 1.
The nonzero transaction rates are given by:  ab =  ba =  cd =  dc =  1 > 0,  ad =  da =  2 (cid:14)  1.
All other entries in the transaction rate matrix   are zero.
All transactions are of size one.
Consider the network s shown in Fig. 3a.
Observe that we can use Lemma 2.1 to compute the steady-state transaction success probabilities between nodes in s. Verify that s is a Nash equilibrium.
The overall social welfare, U (s), in network s is given by Uu(s) = fuv(s) = 2fab(s) + 2fcd(s) (cid:7) U (s) = u V = 2 1

 + 2 1 (cid:7)   Now consider the network s optimum.
The overall social welfare U (s in Fig. 3b.
Verify that s ) is given by   (cid:13) ) = U (s Uu(s As  1   0, the ratio U (s u V    
  1 ) = 2
 )/U (s)    .
+  1

 +  2

   is a social (cid:14)


 Recall that in the global risk model, each agent v has a public default probability  v   (0, 1].
If v defaults, a node u that extended credit cuv(s) to v loses cuv(s) units.
Thus,  uv(s) =  vcuv(s).
We analyze the setting where agents may issue credit to at most one counterpart.
DEFINITION 4.1.
We say that agent u   V is single-minded if in any credit network s, either cuv(s) = 0 for all v   V , or there exists a single agent w   V such that cuw(s) = Bu.
Further, we assume that (i) the transaction rate matrix   is uniform: for all u, v   V,  uv =   = 1/(n(n  1)), (ii) all transactions are size one: for all u, v   V , and for all t >0 , xt uv = 1, and (iii) for all agents u   V , the credit budget Bu = c > 0, where c is an integer.
First we illustrate using a simple example that if the default probabilities are in a certain range, the empty network is a Nash equilibrium, and the price of anarchy is  .
Example 1: Consider a set of n agents.
Further suppose that for all u   V,  (h + h2) >  uc >  h, where h = c/(c + 1).
Let s be the empty network.
Observe that, Lemma 2.1, the utility to a node u from extending to any node v in s is  h, which by assumption is less than  vc.
Thus s is a Nash equilibrium.
On the other hand, since  (h + h2) >  uc for all u   V , the social optimum is a star network where every node extends credit to the root, while the root extends no credit.
As a result, the price of anarchy is  .
For the rest of this section, we assume that extending zero credit is not part of the agents  strategy set.
This assumption, coupled with the fact that agents are single-minded, implies that any credit network formed in this setting will have exactly n directed edges each of capacity c, where n is the number of agents playing the game.
Since an agent extends credit to exactly one agent in any network, we de ne the following notation to denote the agent that has been extended credit by an agent u in network s: for a network s, we de ne  s : V   V to be the  trustee function":  s(u) = v implies cuv(s) = c.
We use the following observation to prove our results; the observation follows from the analysis by Dandekar et al. [6] of the steady-state success probability in trees under a unit transaction regime.
([6]).
Consider a network s. Let u   V be a node such that no node extends credit to u in s and let  s(u) = v.
Assume the transaction rate matrix   is uniform and s is under a unit transaction regime.
Then, for any node w   V \{u, v}, fuw(s) = hfvw(s), where h = c/(c + 1).
LEMMA 4.2.
Let v It is easy to see that any socially optimal network will have a star-like structure where the root is a node with the minimum default probability.
    arg minv V  v be a node with the mini    arg minv V \{v }  v be a node mum default probability.
Let u   with the minimum default probability among nodes other than v .
 },  s  (u) =   Consider a network s     maximizes social welfare.
More-v ) = u over, s Next we show that all Nash equilibria have a star-like structure.
such that for all nodes u   V \{v .
Then, s is also a Nash equilibrium.
, and  s  (v       THEOREM 4.3.
For a suf ciently large n, in any Nash equilib-such that for all nodes v   V \  },  s(v) = u     rium s there exists a node u {u Next we show that despite ruling out the empty network as a Nash equilibrium, the price of anarchy in this setting can be unbounded.
THEOREM 4.4.
The price of anarchy of the network formation .
game with single-minded agents is unbounded.
PROOF.
Consider a set of n agents.
Assume, without loss of generality, that for nodes u1, .
.
.
, un   V,  u1   .
.
.
   un .
Let  u1 c =  (n  3)h22c/(2c + 1), and  u2 =  u3 =  (n  3)h2, where recall that h = c/(c+1).
Consider the network s in Fig. 4a.
It follows from Lemma 4.2 that s is a socially optimal network.
Consider the network s1 in Fig. 4b.
Observe that Lemma 2.1 can be used to compute the steady-state transaction success probabilities and, hence, the utilities, of all nodes in s1.
Since c( u3    u1 )   (n   3)  h2 2c+1 , nodes in s1 cannot bene t from extending credit to u1 or u2 instead of u3.
Thus, s1 is a Nash equilibrium.
Note that since s and s1 are structurally identical       (cid:7) (cid:7) (cid:14) + 2h + 2  2c 2c + 1 fuv(s1)   u,v u,v ) = fuv(s (cid:13) =  (n   2) (n   3)h =  (n   2)(n   3)h

 + 2h 2c 2c + 1 +  (n)     U (s Thus, the total social welfare in s ) =   fuv(s u,v =  (n   3)h
   is given by )   (n   1) u1 c    u2 c (cid:13) (n   2)   (n   1) (cid:14)
 +  (n) =  (n ) 2c 2c + 1 (cid:7) (cid:7) (cid:7) u,v =   u,v On the other hand, U (s1) =   fuv(s1)   (n   1) u3 c    u1 c fuv(s1)    (n   1)(n   3)h
 Since the price of anarchy is lower-bounded by U (s have that PoA =  (n).
  )/U (s1), we c u3 c c c c c c c c c u2 u4 u3 (a) Socially optimal network s   .
un u2 u1 un (b) Nash equilibrium s1; node u3 is the root node.
u4 Figure 4: Example of a game under the global risk model with an unbounded price of anarchy.
Despite the fact that the price of anarchy in this setting can be arbitrarily high, we demonstrate that myopic best-response dynamics can quickly converge to a socially optimal network.
Myopic Best Response For network s, and an agent u, we de ne     arg minv V \{u}  v myopic best-response by u as follows: let v be a node with the lowest default probability among all nodes ex  , cept u.
Then, u s myopic best response is to extend credit to v ) : u, v   V } de ned below i.e.,  s(cid:2) (u) = v is the network resulting from u s myopic best-response in s. For nodes w, y   V , = {cuv(s , where s   (cid:2) (cid:2) if w (cid:11)= u if w = u and y (cid:11)= v if w = u and y = v         cwy(s),
 c, (cid:2) ) := cwy(s THEOREM 4.5.
Assume that the default probabilities,  v, v   V , are all distinct.
Consider a network s. Let s be the network obtained after all agents have played myopic best response, starting from s. Then s maximizes social welfare.
      PROOF.
Since the default probabilities are all distinct, there ex, with the lowest default probability, and with the second lowest default probability.
Then,   .
) = u ists a unique node, say v   another node u observe that for all u   V \{v The optimality of s  },  s (u) = v follows from Lemma 4.2.
and  s  (v       Sequential Arrival We consider a model where agents arrive sequentially, and strategically decide which one of the agents in the network to extend credit to.
Let s0 be a network of two agents, say u0 and v0, such that  s0 (u0) = v0 and  s0 (v0) = u0.
At each time t = 1, 2, .
.
.
, an agent ut arrives and extends credit to one of agents in the network st 1 in order to maximize Uut (st) where st is the resulting network.
We denote by Vt the set of agents that have arrived up to and including time t. We show that the agent ut arriving at time t always extends credit either to ut 1 or to  st 1 (ut 1).
THEOREM 4.6.
For all t   1,  st (ut)   {ut 1,  st 1 (ut 1)}.
Since the node ut arriving at time t always extends credit to either ut 1 or  st 1 (ut 1), the resulting network has a comb-like structure, i.e., there is a chain of nodes forming the spine of the network, and each node in that chain is trusted by a number of leaf nodes.
To address a more general case, we turn to empirical game analysis methods.
In this approach, we choose a small set of heuristic strategies for agents to follow, and apply hierarchical reduction [18] to limit the number of players.
We repeatedly simulate strategy pro les in this restricted game to estimate their payoffs.
Evaluating the resulting empirical game yields insight on general strategic issues as exhibited by the heuristic strategies.
This methodology allows us to generalize the setting in several ways: nonuniform transaction rates and values, issuing credit to multiple counterparts, and graded risk based on incomplete information.
In the experiments reported here, we simulate 60-agent credit networks and construct 6-player hierarchically reduced games in which a multiple of 10 agents plays each strategy.
In each simulation run, agents are  rst assigned strategies, after which the random parameters H (social network),   (default probabilities),   (transaction rates), and G (transaction sizes) are realized.
Then agents issue credit according to their strategies, defaults occur according to  , and 10,000 transactions are attempted according to  .
Each successful transaction in which agent u buys from agent v adds xuv to u s payoff and subtracts 1 from v s, while transferring 1 unit of credit through the network.
Each agent also loses cuv for each defaulter v to which it had issued credit.
We calculate the payoff to a strategy s as the average payoff to agents playing s. Strategy payoffs are averaged over 250 to 3500 simulation runs as necessary to statistically distinguish empirical game equilibria.
In all simulation environments, the transaction rate  uv for each pair of agents is drawn uniformly and then normalized.
The transaction size distribution guv( ) = xuv is a singleton for each pair of agents, but the value is drawn from one of two distributions: xuv   U [1, 1.2] or xuv   U [1, 2].
Note that we are using xuv   G here to indicate the value to the buyer u, whereas the seller s cost, and the amount of credit transferred are  xed at one.
Default probabilities  v for each agent are drawn from one of three Beta distributions: Beta(1, 1), Beta(1, 2), or Beta(1, 9).
Our experiments consider two risk models: global risk, with no social network, and graded risk, where H is an Erd s-R nyi graph.
Under global risk, all agents are fully informed about transaction rates ( ), transaction values (G), and default probabilities ( ).
Under graded risk, agents still know   and G, but information about   comes in the form of signals whose informativeness decreases exponentially with social network distance.
If we call the length of the shortest path between u and v in the social network |SP uv|, then the number of samples u receives from Binom( v) is Suv = (cid:8)103 |SP uv|(cid:9), meaning that agents receive 100 samples for their neighbors, 10 for nodes at distance 2, 1 at distance 3, and none at greater distances.
If agent u receives a signal with Suv samples including Sd uv defaults, its posterior belief about v s default probability is  uv = Beta(  + Sd
 uv,   + Suv   Sd uv).
We are particularly interested in what criteria agents might use to allocate credit.
We therefore focus on heuristic strategies that create a  xed number of credit links (either 0 or 5), and allocate the same amount of credit (5 units) on all links.
An agent s strategic decision is then whether to allocate any credit, and if so, what criteria to employ in picking the  ve nodes to which they connect.
We test eight heuristic strategies under which agent u could issue the following sets of credit links, where the pair (v, cuv) indicates that u issues cuv units of credit to agent v:   ZE (zero credit):   pairs of agents.
G(n = 60, p = 1
 (b) Social network distances for credit links under DP.
DT is similar.
(c) Social network distance for credit links under TD.
IX, TV, TP, and EU are similar.
Figure 5: Distributions of social network distances: (a) between pairs of agents; (b) over credit links produced by strategy DP with; (c) over credit links produced by strategy TD.
Parameter settings: graded risk;  v   Beta(1, 2); xuv   U [1, 2].
  IX (index): {(v, 5) : v   {v1, .
.
.
, v5}}   {(v, 5) : v is among the 5 best agents according to .
.
.}
are shown in the top half of Fig. 6.
Strategies appearing in a cell are supported in some symmetric mixed-strategy Nash equilibrium of the corresponding game.
Each circled strategy is a symmetric pure-strategy Nash equilibrium.
  DP (estimated default probability):  uv   TV (myopic trade value):  uvxuv   TP (net trade pro t):  uvxuv    vu   EU (expected utility): 104(1   uv)( uvxuv    vu)  5 uv   TD (trade then default): 104(1    uv) uvxuv   5 uv   DT (default then trade):  uvxuv   5 uv Some of these strategies warrant further explanation: DP, which chooses the agents least likely to default, has very different results under global and graded risk.
In the former case,  v is common knowledge for all agents, so all agents playing DP coordinate their credit issuance.
Under graded risk, agents  beliefs  uv depend on their position in the social network, hence different DP agents make varying choices.
By always issuing credit to agents 1 to 5, IX provides a way for agents to coordinate in either the global or graded risk settings.
EU estimates the expected utility attributable to each agent, assuming that all attempted transactions succeed.
TD does the same, but excludes the cost from selling to other agents.
These strategies both tend to weight  uvxuv much more heavily than  uv, so the strategy DT also considers both transactions and defaults, but switches the relative weights.
Fig. 5a illustrates the distribution of social network distances for all agents in the Erd s-R nyi graph under graded risk.
The distribution over distances in the social network for credit links produced by strategy DP is shown in Fig. 5b.
Comparing these two histograms, we can see that preferring low-default counterparts results in issuing credit to agents nearby in the social network.
Although neighbors in the network have the same prior probabilities of default as distant agents, the superiority of information about them means that nearby agents are much more prevalent among those with lowest posterior probabilities.
The strategy DT produces a similar histogram to DP, as it also relies heavily on beliefs about default probability, adding just a small factor for trade value that acts as a tiebreaker.
The remaining six strategies are in uenced only slightly or not at all by the social network, and therefore exhibit histograms (Fig. 5c) much like the underlying distance distribution shown in Fig. 5a.
The results of equilibrium analysis under global risk for each combination of default probability distribution, and buyer surplus Default probability is clearly the most relevant criterion in the global risk setting.
At least one of DP and DT, and often both, is supported in an equilibrium of all settings except the bottom left, which has the lowest transaction values and highest default probabilities (where the empty network is the unique equilibrium).
That the empty network is among the equilibria in all three environments with low transaction values is an indication of the importance of network effects: it is much more pro table to participate in a credit network if many other agents do so as well.
We also observe the importance of coordinating on a centralized, star-like network, in that DP and IX both appear as symmetric pure strategy equilibria.
This point is reinforced by the poor performance of the strategies relying primarily on transaction value: TV, TP, and TD.
l s u p r u s r e y u b .
g v a










 global risk model (complete info)

 avg.
default probability




 l s u p r u s r e y u b .
g v a

 graded risk model (incomplete info)








 prior default probability


 Figure 6: Strategies appearing in symmetric Nash equilibria in six global risk environments (top), and six graded risk environments (bottom).
Circled strategies in a cell constitute pure symmetric equilibria of the associated game.
The bottom half of Fig. 6 shows equilibrium analysis under graded risk.
DP, which appears in equilibria of nearly all global risk settings is less prevalent in graded risk equilibria, indicating that it owes much of its success to its function as a coordination device.
TD, on the other hand, continues to perform well, making clear the low-value settings, it is unsurprising that the empty network is more likely to arise, because agents have less information available.
When defaults are suf ciently rare, a centralized network from all agents playing IX is again an equilibrium.
The case of high value and low default probability shows a multiplicity of equilibria, including the only appearance of one of the strategies focused on trades: TD.
The clear messages from our empirical game simulations are twofold.
First, coordinating on a centralized, star-like network can be very bene cial, when such coordination is feasible.
Second, network effects are very strong: none of the strategies that rely heavily on transaction-related criteria perform well; instead agents tend to play strategies like TD, IX, and DP that result in a high likelihood of remaining connected to most of the network in equilibrium.
Our investigation of strategic issues in the formation of credit networks characterizes, in various settings, the nature and ef ciency of credit networks that are formed by self-interested agents autonomously choosing how to issue credit among available counterparts.
The analysis employs game-theoretic solution concepts, employed in theoretical examination of analytic models, as well as simulation-based exploration of extended environments.
Under dichotomous risk, if only bilateral transactions are allowed, we show that the formation game is a potential game.
Moreover, for many transaction size distributions, we show that agents  utilities are concave, and consequently, every Nash equilibrium of the game maximizes social welfare.
More interestingly, we showed that the Nash equilibria are equivalent in a much stronger sense: all Nash equilibria are cycle-reachable [6] from each other, which implies that the sequences of transactions that can be supported from each equilibrium network are identical.
However, when we allow transactions over longer paths, best-response dynamics may not converge, and the price of anarchy is unbounded.
Under a model of global risk, if agents are limited to extend credit to at most one other agent, we prove that the networks formed in equilibrium have a star-like structure.
Although the price of anarchy is unbounded, myopic best response quickly converges to a social optimum.
Even when agents are allowed to extend credit to multiple agents, we show using empirical game simulation that nonempty equilibria tend to be star-like.
We also analyze several graded risk settings, and  nd that agents coordinate in a star-like structure only when defaults are relatively unlikely, and otherwise, credit links tend to be issued over short social distances conforming to the locality of information.
This research was supported in part by NSF award IIS-0904325.
Part of the research was also sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-09-2-0053.
The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the of cial policies of the Army Research Laboratory or the U.S. Government.
The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.
