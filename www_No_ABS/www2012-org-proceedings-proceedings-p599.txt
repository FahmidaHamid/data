Numerous aspects of the Web change over time, from such salient changes as the addition and evolution of content, to more subtle but important dynamics.
We explore the temporal dynamics of user behavior, investigating how we can model and predict changes in the queries that people issue, the informational goals behind the queries, and the search results they click on during Web search sessions.
In information retrieval, models of user behavior have been employed in the past as static sources of evidence for enhancing access; user behavior has been aggregated over time and also used identically for all types of queries.
We explore opportunities  Part of the research was performed while the author was at Microsoft Research.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
Figure 1: A time series (2/14 5/25, 2011) for the query japan (normalized by overall #clicks logged on each day).
for learning about how the behavior of users changes over time and then using predictive models to enhance retrieval.
As an example, for a population of users, the frequency that a query is issued and the number of times that a search result is clicked on for that query can change over time.
We model such dynamics in the behavior as a time series, focusing on queries, URLs, and query-URL pairs as the behaviors.
In Figure 1, we show the query-click behavior of the query japan over time, i.e., number of clicks on any URL shown for the query.
We can see a dramatic change in behaviors associated with this query following the Japanese earthquake on March 11th, 2011.
The number of clicks surges for the query for a period of time, and then slowly decays.
Both the frequency with which a URL is returned for a query and the frequency that speci c URLs are clicked on can change over time.
We explore the changing behavior of a population of searchers via changes in the frequency of query-URL pairs over time.
For the japan query example, the frequencies of access of some URLs change over time because of changes in query frequency, while others do not change (see Figure 2).
We can also examine temporal patterns in how often a URL is presented and clicked, averaged over all queries where it is returned.
In Figure 3, we provide an illustration of the number of clicks on the URL http://en.wikipedia.org/wiki/Japan over time.
These di erent kinds of dynamics, based in changing behaviors among a population of users, can be modeled systematically and predicted.
Although the timing of the initial peak for the query japan may be hard to predict, there are many other cases in which search behaviors are easier to predict.
Consider the queries presented in Figures 4  
 decrease in click frequency.
Figure 5 shows a query undergoing a steady increase in click frequency.
Figure 6 presents a query with periodic changes in frequency of clicks.
Using Japan query time series Query time series: Japan Normalized #Clicks (10^-6) WWW 2012   Session: Web User Behavioral Analysis and ModelingApril 16 20, 2012, Lyon, France599gregations of queries over time to understand changes in the popularity [21] and uniqueness of topics at di erent times of day [3].
Vlachos et al. [20] were among the  rst to examine and model periodicities and bursts in Web queries using methods from Fourier analysis.
They also developed a method to discover important periods and to identify query bursts.
Jones and Diaz [10] identi ed three general types of temporal query pro les: atemporal (no periodicities), temporally unambiguous (contain a single spike), and temporally ambiguous (contain more than one spike).
They further showed that query pro les were related to search performance, with atemporal queries being associated with lower average precision.
Some studies [5, 16] used temporal patterns of queries to identify similar queries or words.
Shok-ouhi [18] identi ed seasonal queries using time-series analysis.
Kulkarni et al. [14] explored how queries, their associated documents, and the intentions behind the queries change over time.
The authors identify several features by which changes to query popularity can be classi ed, and show that presence of these features, when accompanied by changes in result content, can be a good indicator of change in the intention behind queries.
Kleinberg [11, 12] developed general techniques for summarizing the temporal dynamics of textual content and for identifying bursts of terms within content.
Researchers have also examined the relationship between query behavior and events.
Radinsky et al. [17] showed that queries re ect real-world news events, and Ginsberg et al. [8] used queries for predicting H1N1 in uenza outbreak.
Similarly, Adar et al. [2] identi ed when changes in query frequencies lead or lag behind mentions in both traditional media and blogs.
From a Web search perspective, breaking news events are a particularly interesting type of evolving content.
Diaz [7] and Dong et al. [1] developed algorithms for identifying queries that are related to breaking news and for blending relevant news results into core search results.
Yang and Leskovec [22] studied temporal patterns associated with online content via a time series clustering approach that uses a similarity metric that is invariant to scaling and shifting.
Information about time-varying user behavior was also explored by Koren et al. [13], who used matrix factorization to model user biases, item biases, and user preferences over time.
Although much has been done in the investigation of user behavior over time on the Web, few have pursued the construction of underlying models of this behavior, and then used these models for prediction of future behavior.
We present methods for modeling behaviors over time that explain observed changes in the frequency of queries, clicked URLs, and clicked query-URL pairs.
In this section we present a modeling technique that can be used to capture the dynamic nature of web behavior.
Of special importance in modeling web search behavior are global and local trends, periodicities, and surprises.
We present the general theory behind this model (Section 3.1), the modeling techniques (Section 3.2), the learning procedure for these models from real-world data (Section 3.4), and how forecasting is performed using these models (Section 3.3).
The state-space model (SSM) is a mathematical formulation used frequently in work on systems control [9] to Figure 2: Time series (2/14 5/25, 2011) for sample clicked URLs for query Japan (normalized by total #clicks on each day).
Figure 3: A Wikipedia article time series (2/14 5/25,
 and position of the URL).
time series modeling, we can estimate these trends and peri-odicities and predict future values of the frequency of clicks.
More accurate predictions of search behavior can be used to improve crawling policy and the ranking of search results.
The key contributions described in this paper are as follows: (1) We highlight the rich opportunities to study human behavior on the web and explore several models based on time series to represent and predict di erent aspects of search behavior over time.
We discuss how these models can be learned from historical user-behavior data, and develop algorithms tailored to address several properties seen in the dynamics of population behavior on the web, including trend, periodicity, noise, surprise, and seasonality detection.
(2) We present a novel learning algorithm which we refer to as dynamics model learner (DML), that determines the right model for every behavior based on features extracted from logs of web behavior.
We show that DML is superior to more traditional model selection techniques.
(3) Finally, we perform empirical evaluation of our approaches over real-world user behavior, providing evidence for the value of our modeling techniques for capturing the dynamics of user behavior on the Web.
In this paper we examine how to model and predict peoples  Web search behavior.
Of particular interest are changes in query frequency and clicked URLs over time.
Researchers have examined previously how query volume changes over time.
For example, some researchers have investigated ag-Japan query-URL time series Query-URL time series: Japan Normalized #Clicks (10^-6) URL time series: en.wikipedia.org/wiki/Japan Normalized #Clicks (10^-6) WWW 2012   Session: Web User Behavioral Analysis and ModelingApril 16 20, 2012, Lyon, France600represent a physical system as a set of input, output, and state variables related by  rst-order di erential equations.
It provides an easy and compact approach for analyzing systems with multiple inputs and outputs.
The model mimics the optimal control  ow of a dynamic system, using some knowledge about its state variables.
These models allow for great  exibility in the speci cation of the parameters and the structure of the problem based on some knowledge of the problem domain, that provides information about the relations (e.g., linear) among the parameters.
Using upper case letters for matrices and lower case for scalars, the linear space state model (with additive single-source error) de nes a system behavior by the following two equations: Yt = W ( )Xt + t, X(t+1) = F ( )Xt + G( )t, (1) (2) Figure 4: Query exhibiting behavior where historical data has little relevance for prediction (normalized by overall #clicks on each day).
where Yt is the observation at time t, Xt is the state vector, t is a noise series, and W ( ), F ( ), G( ) are matrices of parameters of the model.
For a longer prediction range h, it is usually assumed that Yt+h = Yt.
In our work we assume (as commonly assumed in natural systems representations) that t is a Gaussian process with variance  2.
Equations (1) and (2) are called the measurement and transition equations, respectively.
To build a speci c SSM, a structure for the matrices W ( ), F ( ), G( ) is selected, and the optimal parameters   and   and an initial state X0 are estimated.
The SSM representation encompasses all linear time-series models used in practice.
We show in this section how the SSM can be applied to model the search behavior of a population of people searching on the Web.
We model the state Xt using a trend and seasonal component, as is often done for modeling time-series [15].
The trend represents the long-term direction of the time series.
The seasonal (or periodicity) component is a pattern that repeats itself with a known periodicity, such as every week or every year.
We now present models for user search behavior without trend and periodicity (using just historical smoothing), models with only trend or periodicity, and models that combine periodicity and trend.
Each such combination will be represented by setting the scalars of the matrices W ( ), F ( ), G( ).
Figure 4 displays the click behavior of a population of users for the query justin bieber.
The click popularity decreases with time, therefore models that simply average historical data, and then extrapolate a constant value as a prediction, can be poor models of the future.
The Simple Holt-Winters model is a technique for producing an exponentially decaying average of all past examples, thus giving higher weights to more recent events.
The model is represented by the equation yt+1 =     xt + (1    )   yt.
Intuitively, for y = x0, solving the recursive equation as follows yt+1 =  xt + .
.
.
+  (1    )k 1xt k + .
.
.
+ (1    )tx0 produces a prediction yt+1 that weights historical data based on exponentially decay according to the time distance in the past.
The parameter   is estimated from the data (see Section 3.4).
Converting to SSM notation, let lt = yt+1 where lt is the level of the time series at time t and t = xt   yt.
The measurement and transition equations can be de ned as: Yt = yt = lt 1, Xt = lt = lt 1 +  t.
(3) In this case, W = (1), F = (1), G = ( ).
In many cases, using only one coe cient to decay previous data is not expressive enough to capture the dynamics of the system.
One such case is a time series that exhibits a local trend.
Figure 5 shows the query-click behavior for the query harold camping, who predicted that the end of the world would commence on May 21st, 2011.
The growing interest in this prediction around this date shows a clear local growth trend in the time series.
Simple smoothing of historical data would underestimate the dynamics of interest in this topic.
A solution to this problem is the addition of a trend component to the simple Holt-Winters model: yt = lt 1 + d   bt 1 + t, lt = lt 1 + bt 1 +  t, (lt   lt 1   bt 1),   bt = bt 1 +   (4) where lt is the level of the time series at time t, d is the damping factor, and bt is an estimation of the growth of the series at time t, which also can be written as bt = bt 1 +     t = bt 1 +  t = bt 1 +  t.
Converting to SSM notation, let Xt = (lt, bt)(cid:48), then: (cid:18)1 1 Yt =(cid:0)1 d(cid:1) Xt 1, (cid:19) (cid:18)  (cid:19) (cid:18)1 1 (cid:19) Xt 1 +   t.
Xt = In this case, W =(cid:0)1 d(cid:1) , F =
 (cid:18)  (cid:19)   .
Figure 6 shows query-click behavior for the query consumer report that exhibits weekly periodicity.
Predictions based only on local trends or smoothing of the data will perform badly during the peaks.
A solution is the addition of a periodic or seasonal component st to the Simple Holt-Winters model, yt = lt 1 + st m + t, lt = lt 1 +  t, )st m,     (yt   lt 1) + (1       st =   Smoothing: Justin Bieber Normalized #Clicks (10^-6) WWW 2012   Session: Web User Behavioral Analysis and ModelingApril 16 20, 2012, Lyon, France601Figure 5: Query exhibiting behavior with local trend.
Figure 6: Query exhibiting a periodic behavior (normalized by overall #clicks on each day).
where m is the periodicity parameter that is estimated based on the data along with other parameters.
In SSM notation, the equation system can be written as: yt = lt 1 + st m + t, lt = lt 1 +  t, st i = st i+1, .
.
.
, st = st m +  t, (5) and for Xt = (lt, s1, .
.
.
, sm), we can represent the parameters F, G, W in a form of matrices similar to the Trend Holt-Winters model formulation.
In the previous models, the trend and periodicity were considered separately.
However, for many queries, like the query vampire diaries shown in Figure 7, the trend and periodicity components are mixed together.
The addition of trend and periodicity parameters produces the following model: yt = lt 1 + d   bt 1 + st m + mt + t, lt = lt 1 + bt 1 +  t, bt = bt 1 +  t, st = st m +  t, .
.
.
, st i = st i+1.
(6)
 The Holt-Winters models assume the conversion of a set of parameters to a single forecast variable Yt.
However, in Figure 7: Query exhibiting periodic behavior with local trend (normalized by overall #clicks on each day).
many real-world time series, the model itself changes over time and is a ected by external disturbances caused by non-modeled processes in the open world.
For example, in Figure
 4th, due to an external event concerning the announcement that some prescription cold products are unsafe.
Inclusion of such outliers might have a strong e ect on the forecast and parameter estimation of a model.
We want to identify characteristics in the temporal patterns which are not adequately explained by the  tted model, and try to model them for a better estimation of Yt.
If these characteristics take the form of sudden or unexpected movements in the series we can model them by the addition of disturbances that capture the occurrences of surprises from the perspective of the model.
A disturbance or a surprise is an event which takes place at a particular point in the series, de ned by its location and magnitude.
In a time series, the e ect of a disturbance is not limited to the point at which it occurs, but also propagates and creates subsequent e ects that manifest themselves in subsequent observations.
We augment the standard Holt-Winters model with the addition of two surprise parameters: mt, which is a surprise measurement at time t, and kt, which is the surprise trend at time t: yt = lt 1 + d   bt 1 + st m + mt + t, lt = lt 1 + d   bt 1 +  t, bt = bt 1 + kt +  t, st = st m +  t, .
.
.
, st i = st i+1.
(7) We discuss in Section 4.4 methods for identifying the surprises kt in a time series.
Once this structure is speci ed, the distribution of the future values of the time series can be evaluated, given past history.
That is, we learn an SSM for time series Y1, .
.
.
, Yn jointly with the internal states X0, .
.
.
, Xn, and residuals 0, .
.
.
, n.
During prediction, future states Xn+1 are generated using the state transition equation (2), and based on these, a distribution of the future values Yn+1 is generated using the measurement equation (1).
The  nal prediction can be generated by simply using the expected value of this distribution.
Local Trend: Harold Camping Normalized #Clicks (10^-6) Periodic: Consumer Reports Normalized #Clicks (10^-6) Local Trend & Periodicity: Vampire Diaries Normalized #Clicks (10^-6) WWW 2012   Session: Web User Behavioral Analysis and ModelingApril 16 20, 2012, Lyon, France602search behavior.
For example, we know what query was issued, the number of clicks on a given URL for that query, and so on.
In this section, we discuss how to use domain knowledge to further improve behavior prediction.
We focus on learning which of the trained temporal SSM models is most appropriate for each object of interest, and then estimating parameters for the chosen model.
We start by motivating the algorithm formally and de n-ing the learning problem.
Let T be the discrete representation of time and O be the set of objects and let fi : O  T   Image(fi) be a set of features.
For example, O can be the URLs, f1(o, t) can be the number of times URL o was clicked at time t, and f2(o, t) can be the dwell time on the URL at time t.
In time-series analysis, the learner is given examples of a single object o over some period t0, .
.
.
, tn, and produces a classi er C : T   R based on those examples.
In its use for prediction, the classi er is provided with an example of the object seen at training time ti, and produces the prediction of its class at time ti+1 (for example, how many times the URL o is clicked tomorrow).
In regression learning, the learner is given examples of multiple objects O(cid:48)   O and produces a classi er C : O   R based on those examples.
During prediction, the classi er is given an example of an object oi, that has not been seen before and produces the prediction of its class.
The time-series approach is capable of making speci c predictions about a speci c object at a certain time, but does not consider information about other objects in the system and therefore cannot generalize based on their joint behaviors.
Regression learning, on the other hand, generalizes over multiple objects, but does not use the speci c information about the object it receives during prediction, and therefore does not use the information about how this speci c object behaves over time.
We combine the two approaches into a uni ed methodology that  rst considers generalized information about other objects to choose a model of prediction and then uses the speci c knowledge of the predicted object to learn the spe-ci c parameters of the model for the object.
Formally, given a set of objects O(cid:48)   O over some period of time t0, .
.
.
, tn, we produce a classi er C that receives an object o   O (not necessarily o   O(cid:48)) over some period t0, .
.
.
, tn, and produces the prediction of its class at time tn+1.
In this section we present a new learning algorithm, dy-learner (DML), for learning from multiple namics model objects with historical data.
Let O(cid:48)   O be a set of objects given as examples for training the learning model.
Let t1, .
.
.
, tn+  be the times dedicated for training the model.
For example, O(cid:48) can be a set of queries for which we have user behavior for the period of time t1, .
.
.
, tn+ .
We divide the objects into two sets   the learning set, t1, .
.
.
, tn, and the validation set tn+1, .
.
.
, tn+ .
For every temporal model described in Section 3, we train a model Yi on the learning period.
We then check for mean square error (MSE) over the validation period.
Formally, let o(t) be the behavior of object o at time t (e.g., how many times the query o was searched), then (o(t)  (cid:98)o(t))2 where(cid:98)o(t) is the model m estimation at time t.
M SE(o, t1, .
.
.
, tn+ , m) =   (cid:80)tn+  t=tn+1 , Figure 8: Query exhibiting behavior with surprises.
The SSM family provides a prede ned structure for forecasting, where the speci c parameters of the model need to be evaluated from the data.
We apply gradient descent [19] to optimize the model parameters based on training data.
We assume here the following loss function, which is a common criteria for measuring forecast error: T(cid:88)
 2 t .
(8) t=1 We de ne this to be the likelihood that the residual  = (0, .
.
.
, T ) is zero.
The initial values of X0 are set heuristically, and re ned along with the other parameters.
The seasonal component m is estimated from the data by auto-correlation analysis (see Section 4.3).
As described in Section 3, di erent temporal models can be employed to represent user behaviors over time.
We now present a known method for model selection based on the information criteria of the time series (Section 4.1), and then provide a novel method for inferring the model based on extended and domain-speci c characteristics of the Web behaviors (Section 4.2).
We conclude with models to detect periodicity (Section 4.3) and surprise (Section 4.4).
We employ training data to select the best predictive model.
A common practice in model selection is to optimize the Bayesian information criterion (BIC), BIC =  2   log(L) + q   log(n), (9) where q is the number of parameters, n is the length of the time series, and L is the maximized likelihood function.
For a Gaussian likelihood, this can be expressed as BIC = n   log( 2 e ) + q   log(n), (10) where  e is the variance of the residual in the testing period (estimated from the test data).
The model with the lowest BIC is selected to represent the time series and to issue point forecasts.
The criteria mentioned in Section 4.1 takes into account only the model behavior on the time-series values.
However, in our domain we have access to richer knowledge about Surprise: FDA Normalized #Clicks (10^-6) WWW 2012   Session: Web User Behavioral Analysis and ModelingApril 16 20, 2012, Lyon, France603Let m(i, o) be the model index with the lowest MSE on the test period for the object o.
We construct a set of examples E = {(cid:104)f1(o), .
.
.
, fn(o)(cid:105), m(i, o)|o   O(cid:48)}   a vector representing an object and labeled with the best-performing model for that object.
We then use a learner (in our experiments, a decision-tree learner) along with the examples E to produce a classi er C. During prediction, C is applied on the object we wish to predict, otarget.
The output m(i, otarget) = C(otarget) represents the most appropriate model for the object otarget.
We train model i using the behavior of otarget during t1, .
.
.
, tn+ .
A detailed algorithm is illustrated in Figure 9.
An example of a learned decision tree is shown in Figure 10.
In this  gure, we see that the periodic model should be applied only on queries considered periodic (as de ned in Section 4.3), along with other characteristics.
If the query is not periodic, either the trend or smoothing model should be applied, depending on the query shape (quefrencies values) (see Section 4.2.3).
Thus by using the DML model we learn to apply the correct model for every query, URL or query-URL pair.
Procedure Dynamics Model Learner(O(cid:48), Learner) Train: Train temporal models m1(o), .
.
.
, mM (o) for every o   O(cid:48) E = { (cid:104)f1(o, ti), .
.
.
, fn(o, ti)(cid:105), arg mini M SE(o, t1, .
.
.
, tn+m, mi)|o   O(cid:48)} Call Learner with E, and receive the hypothesis classi er C Prediction: Given unlabeled instance otarget at time t chosenModel   Evaluate C on learntModel   Learn chosenModel parameters (cid:104)f1(otarget, t), .
.
.
, fn(otarget, ti)(cid:105) using otarget(t1), .
.
.
, tn+m Return Evaluate learntModel on otarget(t) Figure 9: The procedure estimates the model type to learn based on past examples and their features.
The model parameters are estimated and a prediction for the new object is performed.
DML uses a set of features fi about each object o.
In this section, we discuss the speci c features we use to train the DML model used in our experiments.
We devise a total of 973 features (partial description of the features is available on 1), and group them into three groups: aggregate features of the time series o, shape feature of the time series o, and other domain-speci c features such as the query class.
Aggregate Features.
Features such as the average, minimum, maximum, and period of the time series, e.g., the average of the query volume.
Other features consider the dynamics of the series, e.g., the time series periodicity (see Section 4.3) and number of surprises (see Section 4.4).
We also consider the size of the spikes during the surprises (the magnitude of the disturbance).
Shape Features.
Shape features represent the shape of the time series.
Our goal is to produce a representation that is not sensitive to shifts in time or the magnitude of the di erences.
Formally, for a time series y[n] = x[n], we are looking for a representation that will be equivalent to series of the form y[n] = x[n h] and y[n] = A x[n], for any shift h Figure 10: A part of the learned dynamic model.
and any scalar A. Homomorphic signal processing is a solution that satis es these conditions.
Intuitively, application of the Finite Fourier transform (FFT) operator N 1(cid:88) xk =  i2 k n
 xne n=0 on a time series transforms it to what is called the spectral domain, i.e., produces a vector x of size k, where every xk represents the k-th frequency of the time series.
Application of a log function on the resulting frequency vector and an additional FFT operator transforms it to what is called the cepstral domain [6], and the values of x in this product are called quefrencies.
We consider these features to represent the shape of the series.
Domain-Speci c Features.
We also consider a set of temporal and static features that are domain speci c.
For the query-click time series we consider the total number of clicked URLs, and the query-click entropy at time t, which is de ned as: QueryClickEntropy(q, t) =   n(cid:88) click(ui, q) log p(click(ui, q)) i=1 where u1, .
.
.
, un are the clicked URLs at time t, and click(ui, q) is the number of clicks on ui for a query q at time t. We consider an aggregated version of query-click entropy as the average of the last k = 7 days before the prediction.
For both the query and URL click time series, we consider the topical distribution of the URL or query.
We used a standard topical classi er which classi es queries into topics based on categories from the Open Directory Project (ODP) [4].
We chose to classify into approximately 40 overlapping topics, such as travel, health, and so on.
Detecting the periodicity size of a time series is crucial for periodic models.
For this process we use a signal processing method called autocorrelation that provides a signal s correlation value with itself.
This method can be used to detect repeating patterns with noise, and is de ned as Autocorrelation(f, h) = f (t + h)f (t) dt, (11) (cid:90)     where h is the shift of the series, i.e., the periodicity.
Several h values are experimented, and the highest value of the autocorrelation for those values is used.
A query is classi ed as periodic based on a certain threshold  :
 Autocorrelation(f, h) >  , (12) Is Query Periodic?
urlImpression_quefrancy1 <= 29.66 queryurlAVG <= 0.04 urlImpression quefrancy10 <= 13.72 Query Period <= 130 URL Peaks AVG<= 0 Query Period <= 126: Smoothing (Eq.
3) Query Period > 126: Periodic (Eq.
5) queryurlImpression_LastValue <= 6 urlImpression_quefrancy_3 <= 5.12 urlImpression quefrancy5 <= 5.76: Local Trend (Eq.
4) urlImpression quefrancy_5 > 5.76: Smoothing (Eq.
3) NO YES WWW 2012   Session: Web User Behavioral Analysis and ModelingApril 16 20, 2012, Lyon, France604Speci cally in the web domain, we found it bene cial to limit the possible h values to common web-periodic intervals, such as weekly, monthly, and yearly (see Section 6.2).
Queries can be modeled using one of the SSM models introduced previously but, as we discussed earlier, sometimes areas of the time series exhibit  surprising  behavior that is not well t by the model.
We conjecture that, when a temporal model encounters a surprise in the data, the model s residual error stops behaving linearly.
Intuitively, in the beginning of a spike the model  under-predicts  the data since the previous data did not include any indication of a spike.
After the spike, the model tends to  over-predict  the data, as it still considers the spike s data.
We introduce surprises as signi cant changes in the residual during the period of an event.
Let r = r1, .
.
.
, rn be the residuals of the temporal model for the times t1, .
.
.
, tn, where time t. Let t(cid:48) m be surprise candidates time points, < 0 for each t(cid:48)   {t(cid:48) m}, i.e., lo-such that rt(cid:48) cations in the time series where the residual changes signs.
Let rt1 and rt2 be two neighboring sign-change points, such that rt1 1   rt1 < 0, rt2+1   rt2 < 0, rt   rt1 > 0, t1   t   t2.
We de ne an impact of an event as rt = o(t)  (cid:98)o(t), and (cid:98)o(t) is the prediction of the model for 1, .
.
.
, t(cid:48) 1 1   rt(cid:48) 1, .
.
.
, t(cid:48)
 Impact(t1, t2) = M SE(o, t1, t2, m) = Intuitively, only surprises that have long impact on the model should be considered as a surprise.
We propose a greedy procedure that adds the surprise locations starting from highest to lowest impact to the model and measures the improvement of the model (using BIC criteria).
When the model stops improving, we output the surprises.
The full surprise detection algorithm is given in Figure 11.
Procedure Surprise Detector(o(t1), .
.
.
, o(tn),m) (cid:80)t2 t=t1 r2 t t2   t1 .
BICi 1     BICi     EventCandidates = {t(cid:48) Events = {} Do 1, .
.
.
, t(cid:48) m|rt(cid:48)   rt(cid:48) i < 0} i 1 i Impact(t(cid:48) i) curEvent   arg maxt(cid:48) EventCandidates   EventCandidates/{curEvent} mi   Build model m with events Events BICi   BIC(mi) If BICi > BICi 1 Events   Events   {curEvent} BICi 1   BICi using training data o(t1), .
.
.
, o(tn) Else Return Events While EventCandidates (cid:54)= {} Return Events Figure 11: Detecting surprises in time series.
We now outline the experimental methodology we employed to test the temporal models that we have presented.
We  rst describe the setup for the prediction experiments, and then for the periodicity and surprise detection experiments.
We perform several prediction experiments, namely predicting query, URL, and query-URL click frequencies.
We also modeled and predicted query, URL and query-URL impressions.
Because of space limitations, we present results only for click behavior.
In every experiment, a time series is created for the behavior for 5 SSM models (Section 3), 2 selection models (BIC (Section 4.1), DML (Section 4.2)), and
 shown for a variant of the M SE to avoid numerical errors: M SE(predicted) = E[(predicted   real)0.5].
The above error is averaged over 12 consecutive prediction days (to avoid over tting of a speci c day).
For the experiments, we use a dataset containing query and URL user visit activity obtained from Bing during the period December 15th, 2010 to April 25th, 2011.
The data contains information about a query s daily click counts, a URL s daily click counts, and, for each query, all of the URLs presented along with their corresponding daily rank positions and daily click counts.
We  lter the data and consider only queries and URLs that have more than 5 clicks per day.
For each query, we consider the  rst 4 top URLs by click frequency.
We normalize every activity time series by the total number of activities on that day, to known seasonality of high searches over weekends.
For query and URL pairs, we also normalize by the number of clicks on the URL at the position at which it was displayed in the displayed ranked results for the query, producing a value which is not dependent on the position.
We focus on several types of queries:
 general sample of queries issued to Bing.
For this purpose we use 10000 queries randomly sampled without repetition on a given day, and 35,862 clicked URLs.
interesting in cases where the behavior of the population of users changes over time.
To study such changes, we identi ed three types of queries that we believe will bene t from temporal modeling.
(a) Dynamic Queries Queries like the japan query described earlier arise because of external events and require fresh content to satisfy users  needs.
Trained judges labeled queries that required fresh results at speci c points in time.
We say that a query q is Dynamic if a human labeled it at time t as a query requiring fresh results.
In the experiments, a total of 504 dynamic queries and 1512 URLs were used.
(b) Temporal-Reformulation Queries Another way of identifying queries associated with time-sensitive informational goals is to examine queries that explicitly refer to a period of time.
We focused on queries that were reformulated to include an explicit temporal referent (e.g., an initial query world cup might be later reformulated as world cup 2011 or world cup latest results).
We say that a query q was reformulated to a query q(cid:48) = q + w, if a user issuing a query q at time t issued the query q with an additional word w at time t + 1 in the same session.
We say that a query q was temporally reformulated if w is of type year, day of week, or if w is one of the following words: current, tained for queries issued in the years 2007-2010.
In the experiments, a total of 330 and 1320 URLs were used.
method that detects peaks as events.
This is a reasonable baseline, as many of the events can be seen as peaks in the query stream.
(c) Alternating Queries Queries that exhibit interesting temporal behavior often show changes in the URLs that are presented and clicked on over time.
We focus on a subset of queries, whose most frequently clicked URLs alternate over time.
We say that a query q is alternating if  t1, t2   T, i, j   N : Click(ui, t1|q) > Click(uj, t1|q), Click(ui, t2|q) < Click(uj, t2|q), where u1, .
.
.
, un are the matching URLs to the query q, and Click(u, t|q) is the number of clicks on u at time t for the query q.
In the experiments, a total of 1836 and

 The most commonly used baseline for representing user search behavior is the averaging of activity over some period of time.
Generally speaking, we consider baselines that perform some kind of uniform or nonuniform mapping of the data, and output the average of the mapping as the prediction.
We call these di erent mappings Temporal Weighting Functions.
The modeling in this case is of the form t 1(cid:88) i=0 yt = (cid:80)t 1 w(i, yi)yi j=0 w(j, yj) , where w(i, yi) is a temporal weighting function.
In this work, we consider the following baseline functions:


 ments we set p = 2): w(i, yi) = ip.
siders the last value of the time series ( what happened yesterday is what will happen tomorrow ): The YES (cid:40) weighting function: w(i, yi) = 1 i = t   1 0 otherwise.
We performed experiments to evaluate the periodicity detection algorithms.
This component is crucial for initializing the SSM seasonal models.
To capture long as well as short periodicity, search logs for query-click data for the period 2006 2011 were obtained, and a daily time series was gen erated for every query.
We used the seasonality dataset [18] that contained 259 queries, each annotated as seasonal or not by several judges.
We compare our method for periodicity detection against the method described in Shokouhi [18], which was applied to perform seasonal-trend decomposition on the time series, comparing the seasonal component to that of the time series before the decomposition.
We performed experiments to evaluate our surprise detection algorithm.
We obtained a set of 24 queries judged by humans as news-related queries.
Judges were also asked to provide a label (event or not) for every week in the series (a total of 313 data points for queries behavior for the years
 query we trained the surprise detection model and a baseline method, and compare their results.
The baseline model is a

 We now summarize the results for prediction for di erent temporal models, and also provide results of experiments on detecting periodicity and surprise.
We  rst summarize the di erent prediction results for query, URL, and query-URL click behavior.
Query click prediction results are shown in Table 1.
The table reports prediction errors, so the smaller the number the better the prediction accuracy.
The best performing model for each query type is shown in bold.
For all of the query types, we observe that the DML method performs the best.
DML always outperforms the well-known BIC method for model selection as well as all of the SSM models and baselines.
This shows that learning which model to apply based on the di erent query features is extremely useful for query-click prediction.
Comparing the temporal SSM models versus the baselines, we observe that for the General class of queries the model that smooths surprises performs the best.
This result indicates that most queries are noisy and strongly in uenced by external events that tend to interfere with model  tting.
For the Dynamic class, temporal models that only take into account the trend or learn to decay historical data correctly perform the best.
This result aligns with the intuition that queries which require new results need the most relevant new information.
Thus, old data interferes with prediction.
Most of those queries exhibited a trend in the end of the period.
Few disturbances (surprises) were detected, therefore the Surprise model was not useful for this set.
A similar pattern is shown for the Alternating queries.
For the Temporal-reformulations query class, the baseline that performs simple averaging of historical data yields the best results.
In this category, the best performing temporal models are those that take into account the periodicity of the query.
Overall, predictions were the most accurate for the General class of queries, indicating that many queries are predictable.
The Temporal Reformulation class of queries provides the most di cult challenge for predictive models, showing prediction errors of 0.52 (best prediction model error).
Most errors result from queries that are seasonal with a periodicity of more than a year, e.g., holiday related queries (sears black Friday) or other annual informational goals as exempli ed by the query 2007 irs tax.
As we only had data for a period of 5 months, such longer-term periodicities were not detected.
URL click prediction results are given in Table 2.
We see again that the DML procedure has the best prediction accuracy for Dynamic and Temporal Reformulation queries.
For these classes of queries, models that learn to weight historical behavior and trend models achieve the best performance.
For Alternating queries, we observe that the clicked URL behavior bene ts from seasonality modeling.
For Temporal Reformulation queries, the baseline and DML models show the best prediction performance.
Interestingly, the Periodic, Trend+Periodic and Surprise models perform poorly.
Similar to what we observed for query prediction, here again the Temporal SSM Models Model Selection Query Type

 General Dynamic

 Temp Reform 0.56
 Alternating











































 Table 1: Query number of click prediction Error (lower numbers indicate higher performance).
Statistically signi cant results are shown in bold.
tion for regular web periodicity (h = 7, 28, .
.
.
, 31, 360 .
.
.
365) is important.
Table 4 shows results of our surprise detection algorithm compared to the baseline peak detection algorithm.
We see the surprise detector has high precision and low recall.
On the other hand, the peak detector identi es all surprises but with very low precision.
As most peaks in queries are usually noise, and not real events, we prefer the Surprise Detector over the peak detection method.
For example, the query credit rating has some seasonal peaks after S&P declarations, which should not be considered a surprise.
However, the peak detector identi es them as such, while the surprise detector does not recognize it as an event.
On Aug 8th, when U.S. credit rating was downgraded, the query volume exhibited an unusual peak, which was identi ed by the surprise detector.
Surprises Detector Peak Detector Precision Recall



 Table 4: Recall and precision of the di erent surprises detectors.
Statistically signi cant results are shown in bold.
We developed methods for modeling the dynamics of the query and click behaviors seen in a large population of Web searchers.
We modeled temporal characteristics that are often observed in query and URL click behavior, including trend, periodicity, and surprise disruptions.
We presented di erent temporal representations and learning procedures and showed how we can construct models that predict future behaviors from historical data.
Temporal models performed better than the baseline models that use the same weighting of historical data for all queries in almost all cases.
We also found that di erent temporal models are appropriate for di erent types of queries.
Query click behavior tends to be rife with disturbances (surprises).
Thus, models that identify and smooth out such disturbances tend to predict well.
For speci c types of queries, such as Dynamic and Alternating queries, trend models are more appropriate.
URL click behavior tends to exhibit different temporal behavior showing fewer disturbances (as we did not see much gain with using the surprise temporal model).
Thus, models that understand trend and smooth historical data using learned models tend to perform better for these predictions.
For Alternating queries, periodic modeling tends to work better.
We found the dynamics seen in query-URL click behavior to be interesting sources of insight into changes in users  intentions over time.
We observed that, in general, the application of correct smoothing or incorporating trend is the best methodology.
Figure 12: Comparison of STL method with Autocor-relation method for seasonality detection by precision (y axis) and recall (x axis).
errors stem from URLs that have periodic content with an annual periodicity lag, which is bigger than the 5 months of data obtained for training the models.
The models incorrectly estimate the lag, which is outside of the scope of the data, and therefore the prediction accuracy is poor.
For URL prediction, the best accuracy is achieved for the General query set.
The most di cult prediction challenge came from the Dynamic set.
Query-URL pair click prediction results are shown in Table 3.
We  rst observe the DML has the best performance for the General and Temporal Reformulation queries.
The temporal model which smooths across surprises (Surprise) is especially useful for the Dynamic query type.
Across Tables 1 3, there appear to be two groups of SSM models: (1) Smooth and Trend models (2) Periodic, Trend+Periodic and Surprise models.
Smooth and Trend models show very similar performance to each other.
Similarly the Periodic, Trend+Periodic and Surprise model behave similarly.
Sometimes one group performs better than the other, but the groupings are consistent across the three tables and four query types.
To evaluate our periodicity model, we evaluate performance for di erent autocorrelation thresholds,  .
Figure 12 shows the precision-recall results for our autocorrelation model (Autocorrelation) compared to the baseline model (STL).
The Autocorrelation method proposed in this work reaches the same maximum recall as the state-of-the-art STL autocorrelation method (around 0.85), and outperforms it in precision for every recall level by up to 15 percent.
We also performed experiments for applying autocorrelation without any lag limiting.
The result yields a recall of about 0.25 0.27 with precision of 0.5 0.6.
We conclude that the lag limita-Temporal SSM Models Model Selection Query Type

 General Dynamic

 Temp Reform 0.31
 Alternating











































 Table 2: URL number of click prediction Error (lower numbers indicate higher performance).
Statistically signi cant results are shown in bold.
Baselines Temporal SSM Models Model Selection Query Type

 General Dynamic

 Temp Reform 0.53
 Alternating











































 Table 3: Query-URL number of click prediction Error (lower numbers indicate higher performance).
Statistically signi cant results are shown in bold.
We introduced a novel Dynamics Model Learner (DML) algorithm, that learns the correct model to apply for every query, URL or query-URL pair that it is presented with, without a priori categorization of queries into groups.
We compared the predictive performance of this method with static baselines, temporal models, and a standard model selection algorithm (BIC), and found that it has superior performance in all groups.
We believe this result paves the way for incorporating multiple types of models for better time-aware search procedures.
The kinds of time-aware modeling of user behavior that we introduced in this paper can be incorporated in many search-related applications.
Query click prediction can be used to improve query suggestions to present the most appropriate suggestions at the time the query is issued.
URL click prediction can be used to improve re-crawling strategies, by focusing crawling e orts on URLs that are likely to be clicked.
And, Query-URL prediction can induce better ranking that is more aware of the user query-URL temporal intent.
Additionally, the models we have presented in this work can also be used at di erent time granularities and applied on di erent types of objects (Query, URL and Query-URL), either aggregated for all users or applied on speci c user behavior, thus creating time-aware personalized retrieval, where the temporal intent is modi ed to accommodate individual searchers.
We thank Dan Liebling for help with obtaining the user behavior data, and Chris Meek and Kuansan Wang for fruitful discussions.
We also thank Milad Shokouhi for providing the labeled seasonal queries.
