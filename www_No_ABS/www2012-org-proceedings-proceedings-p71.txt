Cyber criminals have utilized Twitter as a new platform to conduct their malicious behavior including sending spam and phishing scams [12], spreading malware [9, 5], hosting botnet command and control (C&C) channels [10], and launching other underground illicit activities.
In March 2010, cyber criminals exploited Twitter to spread malware using festive-themed messages [9].
In September 2010, thousands of Twitter users including the wife of former British Prime Minister and White House Press Secretary were compromised by Twitter cyber criminals [12].
While most existing approaches [15, 26, 14, 32, 35] focus on detecting Twitter criminal accounts individually, we still understand far less about the properties of those criminal accounts  social relationships on Twitter.
Yet, it is these very relationships that may be utilized by criminal accounts to increase their in uence or to avoid detection and suspension.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
Guofei Gu Texas A&M University College Station, Texas 77840 guofei@cse.tamu.edu Speci cally, since Twitter users can automatically obtain their following accounts  updates, criminal accounts  social relationships can aid them in increasing the visibility of their malicious content   thus in obtaining more victims.
In addition, by gaining more followers, Twitter criminal accounts can evade existing detection approaches such as  Twitter Rules  and break through Twitter s  Follow Limit Policy 1, while maintaining their high visibility.
Particularly, according to Twitter Rules [8],  a Twitter account can be considered to be spamming, and thus be suspended by Twitter, if it has a small number of followers compared to the amount of accounts that it follows.  However, we lack basic insights into the characteristics of criminal accounts  social relationships.
How do criminal accounts socially connect with each other on Twitter?
What is the topological structure of social relationships among those criminal accounts?
Due to the fact that legitimate accounts normally do not like to follow criminal accounts, what are the main characteristics of criminal accounts  followers?
Can we exploit these miscreants  tactics to build e ective defense strategies against cyber criminals?
The desire of addressing these questions empirically   and thus obtaining insights for defending against Twitter criminal accounts   forms the core motivation of this work.
Figure 1: Structure of the cyber criminal ecosystem.
In this paper, we empirically analyze the cyber criminal ecosystem on Twitter, containing criminal account community composed of criminal accounts, and criminal supporter community composed of those accounts outside
 users, the number of additional accounts it can follow is limited to its follower number [13].
(following relationships) with criminal accounts, de ned in our work as criminal supporters (See Figure 1).
Speci -cally, we analyze inner social relationships in the criminal account community to reveal insights on how criminal accounts socially connect with each other.
Meanwhile, we analyze outer social relationships between criminal accounts and their criminal supporters to reveal the characteristics of those accounts who have close friendships with criminal accounts.
We also aim at  nding possible reasons why criminal supporters outside the criminal community become criminal accounts  followers.
Essentially, these supporters aid criminal accounts in avoiding detection by increasing criminal accounts  followers, and in preying on more victims due to the  social-intercourse  nature of Twitter (Twitter users may visit their friends  friends  pro les).
Through these analyses, we aim at understanding how criminal accounts mix into the whole Twitters space, and presenting new defense insights to e ectively catch Twitter criminal accounts.
We conduct our empirical analysis based on a sample dataset containing around half million Twitter accounts with around 14 million tweets and 6 million URLs.
After building a sample criminal account community composed of 2,060 identi ed spammer accounts in that dataset, we analyze its inner relationships by building and analyzing the social relationship graph.
To analyze outer relationships, we propose a Malicious Relevance Score Propagation Algorithm (Mr.SPA) to extract criminal supporters.
We then observe typical characteristics of three categories of supporters and provide possible reasons why these supporters have close friendships with criminal accounts.
Finally, we design a Criminal account Inference Algorithm (CIA), to infer unknown criminal Twitter accounts by starting from a seed set of known criminal ones and exploiting the properties of their social relationships and semantic coordinations with other criminal accounts.
In summary, the main contributions of our study are:   We present the  rst in-depth case study of analyzing inner social relationships of criminal accounts.
We have two main  ndings: (i) criminal accounts tend to be socially connected, forming a small-world network; (ii) compared with criminal leaves, criminal hubs are more inclined to follow criminal accounts.
  We propose a new algorithm Mr.SPA and have extracted 5,924 criminal supporters who have close friendships with criminal accounts.
We also investigate the characteristics of three representative categories of criminal supporters.
For example, we  nd that a representative category of such supporters, which we term as social butter ies, easily follow back any random account who initially follows them (in our test, about 48% of them do so within 48 hours), while in real ity very few (less than 2%) normal accounts would do this.
This implies that by initializing social relationships with these kind of accounts, criminal accounts can easily mix into Twitter.
  We design a new algorithm CIA to infer more criminal accounts based on a small known seed set, by simply analyzing the social relationships and semantic coordi-nations among accounts.
Using CIA, we can infer over 20 times more criminal accounts than that of using a random selection strategy.
Our research goal is to provide the  rst empirical analysis on how criminal accounts mix into and survive in the whole Twitter space.
Speci cally, we target on those criminal accounts as de ned by Twitter Rules [8], who mainly post malicious URLs linking to malicious content with an intention to compromise users  computers or privacy.
Through analyzing inner social relationships in the criminal community composed of criminal accounts (in Section 3), we aim at answering the following questions.
What is the structure of criminal accounts  network?
What are possible factors and inherent reasons leading to that structure?
Are there any di erent social roles for di erent types of criminal accounts?
Through analyzing outer social relationships (in Section 4), we aim at answering the following questions.
What are typical characteristics of the accounts outside the criminal community that tend to follow criminal accounts?
What are possible reasons that these accounts have close friendships with criminal accounts?
Then, through exploiting criminal accounts  social relationships, we design an inference algorithm to catch more criminal accounts (in Section 5).
To achieve our research goals, we analyze the dataset from our previous Twitter spam account detection study [35], which is crawled by tapping into Twitter s Streaming API [11] from April 2010 to July 2010.
The dataset contains 485,721 Twitter accounts with 14,401,157 tweets and
 URLs on Twitter, for each URL in every tweet, the dataset records its  nal destination URL through following the URL redirection chain.
To analyze criminal accounts, we also use the results from that previous study [35], which outputs 10,004 malicious a ected accounts posting malicious URLs.
Of those malicious a ected accounts, 2,060 accounts are  nally identi ed as spammer accounts.
The URLs are labeled as malicious by using the widely-used URL blacklist Google Safe Browsing (GSB) [4] and a high-interaction client honeypot, implemented using Capture-HPC [3].
We clearly acknowledge and discuss the limitations of our analyzed dataset in Section 7.
Based on this dataset, we build and analyze a sample criminal account community, which is composed of those 2,060 identi ed spam accounts.
In this section, we empirically analyze inner social relationships in our sample criminal account community by visualizing its relationship graph and revealing its relationship characteristics.
If we view each criminal account as a node v and each follow relationship as a directed edge e, we can view inner social relationships in the criminal account community on Twitter as a directed graph, named as the criminal relationship graph G = (V, E).
In our dataset, the criminal relationship graph consists of 2,060 nodes and 9,868 directed edges (see Figure 2(a)).
By further breaking down the graph, we can obtain 8 weakly connected components containing at least three nodes and 521 isolated nodes.
(Since we can partially crawl the whole Twitters space and utilize a relatively strict way of identifying criminal accounts, the number of isolated even smaller, which is 2.60.
This implies that the criminal account community is also a small-world network.
As an important property, a small-world network contains a giant connected component, which can be veri ed in Figure 2(b).
From the above analysis, we can  nd that criminal accounts have strong social connections with each other.
Then, the next question we try to answer is: what are the main factors (criminal accounts  actions) leading to that structure?
l a c i r i p m













 l a i c i r i p m
 NA in Crawled Graph CA in Crminal Graph




 Reciprocity




 Normal Accounts Criminal Accounts

 x 104

 Following Quality (a) Reciprocity (b) Following Quality Figure 3: The comparison of the criminal accounts (CA) and normal accounts (NA).
Possible Factor 1: Criminal accounts tend to follow many other accounts without considering those accounts  quality much, making themselves to connect to other criminal accounts.
The observation that criminal accounts tend to follow many other accounts has been widely analyzed and utilized to build detection schemes in existing work [26, 14,
 criminal accounts  followings.
Speci cally, we use an account s follower number to re ect its quality, i.e., intuitively, an account with more followers has higher quality.
(We acknowledge that an account s follower number may not accurately measure its quality in all cases.
However, it is still a practical and well-accepted metric to laterally re ect an account s fame and reputation [2].)
Then to measure the quality of an account s following accounts, we use a metric, named  following quality , which is the average follower number of an account s all following accounts.
In this way, a higher following quality of an account implies that this account tends to follow those accounts with more followers.
We can  nd that compared with normal accounts, criminal accounts tend to follow accounts with fewer followers (See Figure 3(b)).
Around 85% of criminal accounts have the following quality lower than 20,000, while only around
 validates that criminal accounts  actions of indiscriminately following others lead them to connect with low quality accounts, and hence connect with other criminal accounts.
Possible Factor 2: Criminal accounts, belonging to the same criminal organizations, may be arti cially/intentionally connected with each other.
To validate this possible factor, similar to [22], we  rst group criminal accounts into di er-ent criminal campaigns/clusters (possibly denoting di erent organizations) by clustering them with their posted malicious URLs.
Each criminal campaign contains the criminal accounts that post the same unique malicious URLs.
In this way, we obtain 17 criminal campaigns and each of them has at least 3 nodes.
Then, for each campaign, we draw its criminal relationship graph using a similar method to the one mentioned in Section 3.1 and calculate its number of edges.
The sum of those numbers of edges is 8,667, which is around 87.8% of all edges in the whole criminal commu-(a) Relationship graph (b) Connected component Figure 2: Criminal relationship graph.
Each  dot  represents a criminal account and each  line  connects a pair of following and follower criminal account.
The more relationships an account has, the more central it is positioned in the graph.
accounts may be somewhat overestimated.)
The giant connected component contains 954 nodes (see Figure 2(b)).
After visualizing our sample criminal relationship graph, we analyze this graph through utilizing graph theoretical knowledge, and observe the following two main  ndings.
Finding 1: Criminal accounts tend to be socially connected, forming a small-world network.
From Figure 2(a), we can observe that criminal accounts tend to socially connect with each other.
To quantitatively validate this  nding, we measure three graph metrics: graph density, reciprocity, and average shortest path length.
Graph density is the proportion of the number of edges in a graph to the maximal number of edges, which can be |V | (|V | 1) .
This metric measures how closely computed as a graph is to be a complete graph.
A higher value implies that the graph is denser.
After calculating the graph density for both our sample criminal relationship and a public entire Twitter snapshot[25] containing 41.7 million users and 1.47 billion edges, we  nd that the graph density of our sample criminal relationship graph, which is 2.33   10  3, is much higher than that of the Twitter snapshot, which is 8.45    7.
This shows that the criminals have closer relationship
 than regular Twitter users.
Reciprocity is represented by the number of bidirectional links2 to the number of outlinks.
We  nd that criminal accounts have stronger reciprocal social relationships than legitimate accounts.
For example, around 95% criminals accounts have the reciprocity higher than 0.2 in the criminal graph, while only around 55% normal accounts in our crawled graph (containing around 500K nodes) [35] have such values (See Figure 3(a)).
Furthermore, around 20% of criminal accounts  values of reciprocity in the criminal graph are nearly 1.0, i.e., all criminal accounts followed by these
 vation clearly implies that criminal accounts have stronger social relationships in the criminal account community.
Average Shortest Path Length is de ned as the average number of steps along the shortest paths for all possible pairs of graph nodes.
It can be used to measure the ef- ciency of information  ow on a graph.
Compared with the average path length of a sample data set with 3,000 legitimate Twitter accounts [25], which is 4.12, the average
 reciprocally link to each other.
criminal campaigns (rather than across di erent campaigns) implies strong social connections within criminal campaigns.
Although it is di cult to accurately trace how these connections are generated, this observation still re ects the high probability that criminal accounts in the same criminal organization are arti cially/intentionally connected.
In fact, no matter whether these connections are built using random selection or intentional construction, criminal accounts could bene t from such strong social connections in the criminal community.
Essentially, this structure provides  support  (followers) to criminal accounts, which are very important for criminal accounts to either break the Following Limits Policy or evade detection features that are built based on the metric of follower number.
As seen in Figure 2(a), some nodes in the middle of the graph, termed as criminal hub in our work, have a bunch of social relationships with the nodes in the periphery, termed as criminal leaf.
Are there any di erences between these two types of criminal accounts?
This motives us to study special characteristics of those criminal hubs.
Before analyzing those hubs, we extract criminal hubs by calculating hub scores of criminal accounts in terms of their positions in the criminal relationship graph by utilizing the HITS algorithm [23].
Particularly, for each vertex i in the graph, we can use Eq.
(1) and (2) to compute its hub score H t i and authority score At i in the t-th iteration.
When the computation converges within several iterations, we can obtain this vertex s  nal hub score Hi.
(cid:3) (cid:3) (i,j) E (j,i) E (cid:2) (cid:2) H t i = At i =
 At 1 , j if t = 0 if t > 0
 H t 1 , j if t = 0 if t > 0 (1) (2) According to this algorithm, a higher hub score of an account implies that it follows many accounts with high follower numbers.
Thus, we extract 90 criminal hubs with higher scores and 1,970 criminal leaves with lower scores by using k-means algorithm and setting k = 2.
Finding 2: Compared with criminal leaves, criminal hubs are more inclined to follow criminal accounts.
To validate this  nding, we examine whether criminal hubs  followings are more likely to be criminal accounts.
For better description, we term a criminal account s following account as a  criminal-following , if this following account is also a criminal.
Then, we design a metric, named Criminal Following Ratio (CFR), which is the ratio of the number of an account s criminal-followings to its total following number.
A higher CFR of an account implies that this account is more inclined to follow criminal accounts.
From Figure 4(a), we can  nd that criminal hubs  CFRs are much higher than that of criminal leaves.
Speci cally, around 80% criminal hubs  CFRs are higher than 0.1, while only 20% of criminal leaves have such values.
Also, almost no criminal hubs  CFRs are lower than 0.05, while around
 servation validates that criminal hubs tend to follow more criminal accounts than leaves do.
Similar to Finding 1, we next provide possible explanations to Finding 2.
Possible Explanation: Criminal hubs tend to obtain followers more e ectively by following other criminal accounts (to obtain their followers).
Although criminal accounts could obtain followers by randomly following any account and expecting it to follow back, this method is still not very e ective, due to the low chance of successfully alluring legitimate accounts to follow back.
However, through following criminal accounts, hubs can automatically acquire those criminal accounts  followers  information (Username or Account ID).
Then, there is a better chance for criminal hubs to successfully allure other criminal accounts  followers to become their own followers.
Particularly, these followers have been already proved to be more susceptible to follow criminal accounts, which many legitimate accounts may not choose to do.
(For more details supporting this argument, refer to Section 4.)
In this way, criminal hubs can obtain followers more e ectively.
To validate this explanation, we examine whether criminal hubs  followers are highly shared with their criminal-followings.
Speci cally, we design a metric, named Shared Follower Ratio (SFR), which is the percentage of an account s followers, who also follows at least one of this account s criminal-followings.
A high SFR of an account implies that most of this account s followers are also its criminal-followings  followers, i.e., this account tends to share common followers with its criminal-followings.
We  nd that criminal hubs  SFRs are higher than criminal leaves .
Around

 This observation re ects that compared with criminal leaves, criminal hubs  followers share more followers with their criminal-followings.
This indirectly implies that criminal hubs could obtain followers by knowing their criminal-followings  followers  information.
l a c i r i p m







 Criminal Hub Criminal Leaf
 Criminal Following Ratio (CFR)


 l a c i r i p m












 Criminal Hub Criminal Leaf
 Shared Follower Ratio (SFR)
 (a) Criminal Following Ratio (b) Shared Follower Ratio Figure 4: The comparison between criminal hubs and criminal leaves.
From these two  ndings, we can roughly draw a picture on how criminal accounts could obtain followers on Twitter.
Similar to the Bee Community, in the criminal account community, criminal leaves, like bee workers, mainly focus on collecting pollen (randomly following other accounts to expect them to follow back); criminal hubs in the interior, like bee queens, mainly focus on supporting bee workers and acquiring pollen from them (following leaves and acquiring their followers  information).
If criminal accounts mainly build inner social relationships within themselves, according to existing approaches such as Sybil Guard [37] and Sybil Infer [19] on detecting sybil nodes, criminal accounts can be easily detected.
However, many Twitter criminal accounts have already utilize several tricks to obtain followers outside the criminal account community and mix well into the whole Twittersphere [7].
close  follow relationships  with criminal accounts, essentially aid criminal accounts both in avoiding detection and in spreading malicious content [6].
In our work, we de ne them as criminal supporters.
However, currently we have little knowledge about the characteristics of these criminal supporters.
Thus, in this section, we conduct the  rst analysis of outer social relationships between criminal accounts and their supporters.
By extracting and characterizing criminal supporters, we reveal typical characteristics of these supporters and understand more on how criminal accounts could mix into the Twitter space.
We  rst design a Malicious Relevance Score Propagation Algorithm (Mr.SPA) to extract criminal supports.
Specifically, Mr.SPA will assign a malicious relevance score (MR score) to each Twitter account, measuring how closely this account follows criminal accounts.
A higher MR score implies a closer  follow relationship  to criminal accounts.
Then, we measure the MR score based on three heuristics: (1) the more criminal accounts that an account has followed, the higher score this account should inherit; (2) the further an account is away from a criminal account, the lower score the account should inherit; (3) the closer the support relationship between a Twitter account and a criminal account is, the higher score the account should inherit.
To formalize the above intuitions, we build a malicious relevance graph G = (V, E) to model the support relationship.
In this graph, we consider each Twitter account i in our dataset outside the criminal community as a node Vi.
There is a directed edge eij from the node Vi to the node Vj , if the account i follows the account j.
The weight Wij of the edge eij is determined by the closeness of the relationship between i and j.
We next introduce our malicious relevance score propagation algorithm, which contains two phases: initializing MR score, and propagating MR score.
MR Score Initialization: Before propagating MR score, we  rst assign an initial score M 0 i to each node Vi.
If we denote C = {Ci|Ci is a criminal account}, then each criminal account Ci   C is assigned a nonzero score mi
 accounts, the score is initialized to zero.
MR Score Propagation: To propagate a MR score Mi to each node Vi after the initialization phase, we make the following three score-assigning policies according to the above three heuristics: Policy 1: MR Score Aggregation.
An account s score should sum up all the scores inherited from the accounts it follows.
As Figure 5(a) illustrates, when A follows both criminal accounts C1 and C2, the score of A is the sum of the malicious scores of C1 and C2.
Policy 2: MR Score Dampening.
The amount of MR score that an account inherits from other accounts should be multiplied by a dampening factor of   according to their social distances, where 0 <   <1.
As Figure 5(b) illustrates, when A1 is one hop away from a criminal account C, we assign it a dampening factor of  , where 0 <   <1.
When A2 is two-hop away, A2 will get a dampening factor of       =  2.
Policy 3: MR Score Splitting.
The amount of MR score that an account inherits from the accounts it follows should be multiplied by a relationship-closeness factor Wij, which
 is the weight of the edge in our malicious relevance graph.
Speci cally, we use the number of followers of an account to re ect the closeness of the relationship between this account and its followers.
(The intuition is that if an account has more followers, the closeness of the relationship between this account and each of its followers will become weaker.)
As Figure 5(c) illustrates, if A1 and A2 have followed the same criminal account C, the relationship-closeness factor of each account to C is 0.5.
Thus, according to this policy, the score of a node Vi can be computed as Mi = Wij Mj, if (i, j)   E.
Figure 5: The policies of assigning MR scores.
Before presenting our mathematical model of propagating MR score, we  rst introduce some notations.
Let n be the number of nodes in the malicious relevance graph.
We use the indication function Iij = {0, 1} to indicate whether (i, j)   E (i.e., if (i, j)   E, Iij = 1; otherwise, Iij = 0).
If we use numIndegree(j) to denote the number of the in-degree of the node j, then from MR Score Splitting pol-numIndegree(j) .
We use I to icy, we can obtain that Wij = denote the column-vector normalized adjacency matrix of nodes (i.e., Iij = Iij   Wij, if numIndegree(j) (cid:3)= 0; Iij = 1   n , M0 be initial MR Score vector   if numIndegree(j) = 0).
Let Mt be malicious score column vector
 for all nodes and let for all nodes at the step t.
According to those three policies and our notations, at each step, for each node Vi, its simple MR score Mi can be computed using Eq.
(3).
Iij   Wij   Mj (3) Mi =     n(cid:4) j=1   Mt =       I   Mt 1 + (1    )    

 In addition, with the consideration of each node s historical score record, at each step t(t > 0), we add an initial score bias (1 ) M 0 i to its simple MR Score.
(In our experiment, we set   = 0.85, since it is widely used in the random-walk   model.)
Thus, we can compute the MR Score column-vector Mt for all nodes at the step t(t >0) by Eq.
(4).
(t >0) (4) When the score vector converges after several propagation steps, we can obtain  nal MR scores for all nodes.
Once all MR scores have been calculated, a threshold is needed to determine which accounts have su ciently close friend relationships to their criminal counterparts.
To  nd an acceptable threshold, we  rst use x-means algorithm [29] to cluster accounts based on their MR scores.
In this way, accounts with similar scores will be grouped together indicating they have similar follow relationships with criminal accounts.
Then, we observe that most accounts have relatively small scores and are grouped into one single cluster.
That is mainly because most accounts do not have very close follow relationships with criminal accounts.
With this observation, we choose the highest score of the account in that supporters, whose MR scores are higher than the threshold.
After extracting criminal supporters, according to our empirical studies, we observe three representative categories of supporters (social butter ies, social promoters, and dummies) according to our de ned thresholds.
(Since we aim at showing preliminary and basic insights of criminal supporters  characteristics, the thresholds that are used to characterize them can be tunable according to how strictly to re ect their behavioral characteristics.)
Social Butter ies are those accounts that have extraordinarily large numbers of followers and followings.
Like social butter ies in our real life, these accounts build a lot of social relationships with other accounts without discriminating those accounts  qualities.
To qualitatively de ne social butter ies, we use 2,000 following as a threshold in terms of Twitter s Follow Limit Policy [13].
This number could be e ciently used to distinguish whether an account is socialized.
In this way, we  nd 3,818 social butter ies.
We present our hypothesis that the reason why social butter ies tend to have close friendships with criminals is mainly because most of them usually follow back the users who follow them without careful examinations.
Especially, some public software and services can help users automatically follow back other users, who have followed them [1].
In this way, these social butter ies might unintentionally follow back criminal accounts upon requests.
To validate this hypothesis, we  rst sign up 30 Twitter accounts without any tweets and any personal information.
Then we use 10 accounts to follow 500 accounts (each account follows 50 accounts) that are randomly selected from those 3,818 butter ies.
Meanwhile, we use another 10 accounts to follow another randomly selected 500 normal accounts without posting any malicious tweets, and the other 10 accounts to follow another randomly selected 500 identi-  ed criminal accounts.
To minimize the in uence generated by our experiment, we close our signed-up accounts after 48 hours.
During this timespan, we  nd 47.8% of those butter ies follow back to our signed-up accounts, while only 1.8% of those normal accounts and 0.6% of those criminal accounts follow back.
The fast speed in which these social butter y accounts followed our accounts back validates our hypothesis that these accounts may automatically follow back any accounts that follow them.
Such a low value for those criminal accounts validates that our identi ed criminal accounts are not social butter ies.
And they usually will not follow back other accounts, since this behavior will not increase their follower numbers and in uence.
This experiment also shows that even though those Twitter accounts with many followers are usually popular and trustable, we cannot always trust their friends  quality.
Social Promoters are those Twitter accounts that have large following-follower ratios (the ratio of an account s following number to its follower number), larger following numbers and relatively high URL ratios.
The owners of these accounts usually use Twitter to promote themselves or their business.
We extract those social promoters whose URL ratios (the ratio of the number of URLs to the number of tweets) are higher than 0.1, and following numbers and following-follower ratios are both at the top 10-percentile of all accounts in our dataset.
In this way, we can obtain 508 social promoters.
We make our hypothesis that the reason why social promoters tend to have close friendships with criminal accounts is probably because most of them usually promote themselves or their business by actively following other accounts without considerations of those accounts  quality.
Thus, promoters may become criminal supporters by unintentionally following criminal accounts.
For this type of supporters, we use a heuristic method to validate our hypothesis.
Since the goals of these promoters are promoting themselves or their business, they usually repeat posting URLs with the same domain names, which link to the webpages containing their promotion information.
Thus, the purity of domain names in promoters  posted URLs are higher, leading a lower domain name entropy.
With this intuition, to calculate domain name entropy for each social promoter, we extract each promoter s posted domain names in the  nal URLs, which are obtained through following URL redirection chains, due to the wide usage of shortening URLs on Twitter.
Then, we compute its domain name entropy by using   N(cid:3) pi ln pi, where N denotes the i=1 number of distinct domain names and pi denotes the ratio of the occurrences of the i-th distinct domain name to the total number of domain names.
l a c i r i p m



 Social Promoters All Accounts


 Domain Name Entropy Figure 6: The entropy of the domain names.
Figure 7: A Case study for social promoters.
From Figure 6, we can  nd around 40% social promoters  domain name entropy are zero, which implies that all their URLs have the same domain names.
Also, social promoters  domain name entropy are lower than that of other accounts.
Speci cally, around 80% social promoters have the domain name entropy lower than 1.0, whereas around 45% of all accounts in our dataset have such values.
The observation heuristically validates our hypothesis that supporters tend to use Twitter to promote themselves by actively following other accounts, leading to close relationships with criminal accounts.
One case study for a social promoter can be seen in Figure 7.
The owner of this promoter mainly utilizes Twitter to promote an online book selling website.
Dummies are those Twitter accounts who post few tweets but have many followers.
Since in Twitter, legitimate users tend to follow those accounts that share more useful information, it is relatively weird that these dummies has close relationships with criminal accounts while sharing little information, but they have many followers.
In particular, we extract intriguing dummy accounts, who post fewer than percentile.
In this way, we obtain 81 dummies.
We make our hypothesis that the reason why dummies intend to have close friendship with criminals is mainly because most of them are controlled or utilized by cyber criminals.
To validate this, we analyze these dummy accounts several months after the data collection.
Then, we  nd that
 do not exist any more (closed), and 36 accounts begin posting malware URLs labeled by Google Safe Browsing, and 8 accounts begin posting (veri ed) phishing URLs.
The observation that dummies begin posting malicious URLs shows that these dummies who have close relationships with cyber criminals are highly likely controlled by cyber criminals.
A case study of one dummy account, who posted no tweets at the time when we crawled its pro le but starts to post malicious tweets later, can be seen in Figure 8.
This dummy account steals victims  email addresses through claiming to help people earn money.
However, the dummy account sends email spam.
Figure 8: A case study for dummies.
Also, we  nd that unlike social butter ies and promoters, dummies are a special type of supporters extracted by Mr.SPA, since they initially do not post malicious URLs.
However, they may later evolve to be criminal accounts.
This discrepancy is mainly because our work provides a static view of the ecosystem.
We note that criminal accounts could be dynamically evolved from those dummies extracted by Mr.SPA, and thus we do not argue whether dummies are supporters or criminal accounts.
Through analyzing outer social relationships between criminal accounts and their supporters, we can understand more on how criminal accounts could mix into the whole Twitter space by achieving criminal supporters.
Also, once we extract these supporters, we can warn legitimate users not to make friends with these supporters so as to avoid exposure to criminal accounts.
Considering the huge number of Twitter accounts, it is impractical to make in-depth checks on every account whether it is a criminal account at the same time.
A lightweight inference algorithm, to guide to more suspicious accounts instead of scanning or analyzing all accounts given limited resources or time, is indeed needed.
(In fact, similar existing work such as [38] mainly utilizes a ranking mechanism to predict potential threats.)
As criminal accounts tend to be socially connected, a spontaneous and practical strategy is to  rst check those accounts that are connected with known criminal accounts by using Breadth First Search (BFS) al-In this section, we propose a Criminal accounts gorithm.
Inference Algorithm (CIA) to infer more criminal accounts by exploiting criminal accounts  social relationships and semantic coordinations.
licious by GSB or honey client.
In brief, our Criminal account Inference Algorithm (CIA) propagates malicious scores from a seed set of known criminal accounts to their followers according to the closeness of social relationships and the strength of semantic coordina-tions.
If an account accumulates su cient malicious score, it is more likely to be a criminal account.
The intuition of CIA is based on the following two observations: (1) criminal accounts tend to be socially connected; (2) criminal accounts usually share similar topics (or keywords or URLs) to attract victims, thus having strong semantic coordinations among them.
The  rst observation has been shown and discussed in Section 3.
The second observation has also been widely analyzed in existing work such as [22, 21], which validates the existence of shared semantic topics among di erent criminal account campaigns.
In general, our CIA integrates the  rst observation by referring to Mr.SPA designed in Section 4 to quantify the closeness of social relationships.
To integrate the second observation, we design a metric, Semantic Similarity score (SS score), among each pair of accounts to quantify their semantic coordinations.
To calculate SS score, we  rst extract a Semantic Fingerprint Vector (SFV) for each account, which essentially contains several representative terms in its tweets based on the TF-IDF algorithm [31], a widely used metric in the information retrieval community to measure the rep-resentativeness of terms.
Then, SS score of each pair of accounts can be computed as the distance of their SFVs.
(Due to the page limitation, we omit the technical details of extracting SFV and calculating SS score.
Here, we just note that a higher SS score between two accounts implies that they have stronger semantic coordinations.)
With the above intuitions and notions, we then describe the design of CIA in details.
To infer criminal accounts in a set of U Twitter accounts, we  rst start from a known seed set of M criminal accounts.
Then, similar to Mr.SPA, we build a malicious relevance graph by using these (M +U ) accounts, denoted as G = (V, E).
In this graph, each account denotes a vertex in V and each follow relationship denotes a directed edge in E. Then, unlike Mr.SPA, we assign a weight for each edge eij   E (by using a semantic weight assignment function W S(i, j)) to re ect the semantic coordination between each pair of accounts.
The basic intuition of designing this function is that if an account has higher SS scores (stronger semantic coordination) with its followings, it should inherit more malicious score from its followings.
With this intuition, for each account j, we calculate every SS score between itself and each of its follower account i, denoted as SSij.
Then, the weight W S(i, j) of the edge eij can be calculated as W S(i, j) = SSij(cid:2) .
SSkj ekj E Then, similar to Mr.SPA, for each criminal account, we assign a nonzero malicious score and propagate this score by using the semantic weight assignment function W S(i, j) in Eq.
(3).
In this way, we can see that an account s malicious score can be proportionally distributed to its followers according to the closeness of social relationships and strength of semantic coordinations.
When the score vector converges after several propagation steps, we infer those accounts with high malicious scores as criminal accounts.
We evaluate our Criminal account Inference Algorithm II.
Dataset I refers to the one with around half million accounts from our previous study [35].
Dataset II contains another new crawled 30K accounts by starting from 10 newly identi ed criminal accounts and using breath rst search (BFS) strategy.
To evaluate the e ectiveness of our CIA, similar to [38] that uses the number of hits in a top list, we use the number of correctly inferred criminal accounts and malicious affected accounts (denoted as CA and M A, respectively) in a top (ranked) list.
(Even though these malicious a ected accounts may not be criminal accounts, they still pollute Twitter with malicious URLs and create a risk for innocent users.)
Thus, a higher number of CA and M A indicates that the algorithm is more e ective to infer criminal accounts.
Note that as a lightweight inference and ranking algorithm aiming at magnifying suspicious accounts from a small seed set, we do not position CIA as a full detection algorithm.
Thus, we adopt similar metrics to  Hit Count  used in [38] to measure CIA s e ectiveness rather than using false positive and false negative rate.
However, CIA could de nitely be incorporated into some actual criminal account detection system by combining with other detection features.
We  rst design  ve experiments to evaluate the e ective-ness of our CIA based on Dataset I.
Di erent Selection Strategies.
In this experiment, we start from the same seed set of N identi ed criminal accounts, which are randomly selected from 2,060 identi ed criminal accounts.
Then, starting from this seed set, we use the following  ve strategies to select  ve di erent account sets with the same selection size of k from the dataset5: random search (RAND), breath rst search (BFS), depth rst search (DFS), random combination of breadth rst and depth rst search (RBDFS)6, and CIA.
From Figure 9(a), we can see that CIA can outperform all the other selection strategies.
Speci cally, CIA can infer 20.42 times as many CA and 10.66 times as many M A as that of using random selection strategy.
Also, CIA can infer 2.58 times as many CA and around 2.00 times as many M A as that of using BFS, which can infer the second most CA.
Also, CIA can perform much better than the naive algorithm that considering all accounts are possible criminal accounts.
Speci -cally, CIA can correctly predict around 0.0625 criminal accounts and over 0.25 malicious a ected accounts by selecting
 predict 0.004 criminal accounts and 0.02 malicious a ected accounts by selecting 1 account.
Di erent Selection Sizes: In this experiment, we start from 100 identi ed criminal account seeds and use CIA to infer criminal accounts by choosing di erent selection sizes of accounts, i.e., we evaluate our CIA by changing the values of k in the previous experiment.
From Figure 9(b), we can see that when we select more accounts, we can infer more CA and M A, and the increase of CA and M A is sub-linear with the increase of the selection size.
Di erent Sizes of Seed Sets.
In this experiment, we evaluate CIA by starting from di erent sizes of criminal

 have a probability of 50% to make a breath rst or a depth rst search in the next step.
r e b m u
















 r e b m u






 Selection Size
 (a) Selection Strategies (b) Selection Sizes Figure 9: Using di erent selection strategies and setting di erent selection sizes of accounts.
seeds, i.e., we set di erent values of N .
In this experiment, we also set k = 4, 000.
From Figure 10(a), we can see that when we increase the number of seeds, we can infer more criminal accounts while selecting the same size of accounts.
This is because when we use more criminal seeds, we have more knowledge about the relationships among the criminal account community.
r e b m u















 (a) Seed Size


 r e b m u











 (b) Seed Type Figure 10: Striating from di erent sizes of seed sets and di erent types of seeds.
Di erent Types of Seeds.
In this experiment, we evaluate CIA by using di erent types of accounts as the seeds.
Speci cally, we start from the same number (100) of randomly selected normal accounts (NOR) (posting no malicious tweets), malicious a ected accounts (MA), criminal accounts (CA), and criminal hubs (CAHUB) and use CIA to select the same amount of 4,000 accounts.
From Figure
 predict much more CA and M A. Speci cally, starting from CA, we can infer 245 CA and 1,102 M A, while starting from MA, we can infer 6 CA and 248 M A, and from NOR, we can infer 2 CA and 121 M A.
This observation also validates that criminal accounts have stronger social relationships and semantic coordinations among themselves.
Thus, it will be more e ective to use known criminal accounts other than normal accounts as seeds to infer other criminal ones.
In addition, we can also  nd that using CAHUB can even infer more CA and M A than using CA.
That is also mainly because these criminal hubs have even more social relationships with other criminal accounts than criminal leaves.
Multiple Round Recursive Inference.
In this experiment, we initially start from a small set of randomly selected 50 identi ed criminal accounts to recursively run CIA to infer criminal accounts.
Speci cally, during each round, we will combine previous round s seeds and identi ed criminal accounts correctly inferred in the previous round as new seeds to run CIA again.
From Figure 11(a), we can  nd that even when we start from a small number of criminal accounts (50, which is around 2.4% of all CA in the dataset) within running 3 rounds of CIA, we can infer around 9 times more This observation shows that we can use CIA to recursively infer more criminal accounts by adding newly correctly inferred criminal accounts into the existing seed set.
r e b m u




 Round

 r e b m u














 (a) Recursive inference (b) Dataset II Figure 11: Evaluation of multiple round recursive inference and Dataset II.
To decrease the e ect of possible sampling bias in our analyzed dataset and to show the fact that the performance of CIA are reproducible, we also test CIA on another newly crawled dataset.
Also, to guarantee the correctness of identifying criminal accounts, we  rst use Google Safe Browsing, a trustable blacklist, to collect malicious a ected accounts.
Then, we manually identify criminal accounts from those malicious a ected accounts7.
Then, we examine the e ectiveness of CIA on newly crawled dataset by comparing di erent account selection strategies.
Speci cally, we start from only 10 identi ed criminal accounts and select 4,000 accounts by using each strategy.
From Figure 11(b), we can also  nd that CIA can generate the best results.
CIA can infer 13 more criminal accounts than that of using RAND.
Through all above experiments, we can  nd that CIA can be used to e ectively infer unknown criminal accounts.
Also, unlike most current work on detecting Twitter spammers based on machine learning techniques, which require extracting many features from all the accounts in the dataset, CIA mainly focuses on those accounts that have strong social relationships with existing known criminal accounts.
In addition, CIA can be utilized to work as an early-stage monitoring and ranking algorithm to monitor those highly suspicious accounts, which may evolve to be criminal accounts later.
We discuss prior related work on Online Social Networks (OSN) by organizing them into two general categories.
Due to the great popularity of the OSNs, many studies have analyzed OSN characteristics.
Mislove et al. present a large-scale measurement study on the structure of multiple OSNs including Flickr, YouTube, LiveJournal, and Orkut [28].
Kwak et al. have shown a comprehensive and quantitative study on Twitter accounts  behavior [25].
Yardi et al. analyze social behavior and network structural di erences between spam Twitter accounts and legitimate ones by analyzing a speci c spam campaign [36].
However, due to the limitation of the analyzed dataset, it fails to reveal in-depth structural di erences to answer the questions mentioned in
 low bound of real numbers in the dataset, because we can not detect all CA and M A by simply using GSB itself.
that work, e.g.,  Do spammers follow one another to boost their follower count? .
Wang et al. use Twitter to study the unbiased sampling algorithm for directed social graphs [34].
Cha et al. utilize di erent metrics to measure the user in u-ence on Twitter [18].
Galuba et al. focus on characterizing and modeling the information cascades formed by individual URL mentions in the Twitter follower graph [20].
Castillo et al. design automatic methods for assessing the credibility of a given set of tweets [17].
Metaxas et al. analyze political community behavior and the spread of political opinions on Twitter [27], and Ratkiewicz et al. analyze the spread of Astroturf memes on Twitter [30].
In addition, since spam and attacks are so rampant in the OSNs, many researchers have studied detecting OSN criminal accounts.
A framework to detect tag spam in tagging systems is proposed in [24].
This work prevents the attackers who desire to increase the visibility of an object from fooling the search mechanism.
Benevenuto et al.
[15, 16] utilize machine learning techniques to identify video spammers on YouTube.
Gao et al. present a study on detecting and characterizing social spam campaigns in Facebook [21].
Meanwhile, most Twitter criminal account detection work can be classi ed into two categories.
The  rst category of work, such as [26, 14, 33, 32], utilizes machine learning techniques to classify legitimate accounts and criminal accounts according to their collected training data and their selections of classi cation features.
The second category of work (e.g., [22]) detects and analyzes malicious accounts by examining whether URLs or domains posted in the tweets are labeled as malicious by public URL blacklists or domain blacklists.
Compared with previous work, our work focuses more on the analysis of cyber criminal ecosystem   investigating inner social relationships in the criminal account community and outer relationships between criminal accounts and criminal supporters   to deeply understand how criminal accounts survive and mix into the whole Twitter space.
Thus, our study is a valuable supplement to the previous work.
We acknowledge that our analyzed dataset may contain some bias.
Also, the number of our analyzed criminal accounts is most likely only a lower bound of the actual number in the dataset, because we only target on one speci c type of criminal accounts due to their severity and prevalence on Twitter.
However, it is extremely challenging to obtain an ideal, unbiased dataset with perfect ground truth.
In addition, to reduce possible data sampling bias, we crawled two datasets at very di erent time to evaluate the performance of our CIA.
We also believe that even though the exact values of some metrics used in our work may vary a little bit when using di erent sample datasets, our major conclusions and insights will likely still hold.
We also acknowledge that our validations on some possible explanations proposed in this work may be not absolutely rigorous, due to the di culties in thoroughly obtaining criminal accounts  social actions or motivations.
However, we believe that our  rst-in-its-kind analysis of those phenomenon still provides great values and opens a new door to better understand the cyber criminal ecosystem on Twitter.
In our future work, we will design and test more crawling strategies and crawl more data.
We also plan to further relationship graph and that of normal accounts.
In addition, we plan to design a full detection system by combining our CIA algorithm and other detection features.
In this paper, we present an empirical analysis of the cy-ber criminal ecosystem on Twitter.
We provide in-depth investigation on inner and outer social relationships.
We observe two  ndings in the cyber criminal community and reveal the characteristics of three representative categories of criminal supporters.
Spurred by defense insights originating from these analyses, we design an e ective algorithm to infer more criminal accounts by starting from a seed set of known criminal accounts and exploiting the properties of their social relationships and semantic correlations.
