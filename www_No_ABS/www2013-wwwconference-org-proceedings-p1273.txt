On microblogging platforms such as Twitter or Sina Weibo, where the number of messages that are posted per second exceeds several thousands during big events1, solving the prob-
http://blog.twitter.com/2012/02/post-bowl-twitter-analysis.
html Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
lem of information overload and providing solutions that allow users to access new information e ciently are nontrivial research challenges.
The majority of messages on microblog-ging platforms refer to news, e.g.
on Twitter more than 85% of the tweets are news-related [9].
Many of the microp-osts convey the same information in slightly di erent forms which puts a burden on users of microblogging services when searching for new content.
Teevan et al. [23] revealed that the search behaviour on Twitter di ers considerably from the search behaviour that can be observed on regular Web search engines: Twitter users issue repetitively the same query and thus monitor whether there is new content that matches their query.
Traditional Web search engines apply techniques for detecting near-duplicate content [8, 12] and provide diversi cation mechanisms to maximize the chance of meeting the expectations of their users [19].
However, there exists little research that focuses on techniques for detecting near-duplicate content and diversifying search results on micro-blogging platforms.
The conditions for inferring whether two microposts comprise highly similar information and can thus be considered near-duplicates di er from traditional Web settings.
For example, the textual content is limited in length, people frequently use abbreviations or informal words instead of proper vocabulary and the amount of messages that are posted daily is at a di erent scale (more than 340 million tweets per day2).
In this paper, we bridge the gap and explore near-duplicate detection as well as search result diversi cation in the mi-croblogging sphere.
The main contributions of this paper can be summarized as follows3.
  We conduct an analysis of duplicate content in Twitter search results and infer a model for categorizing di erent levels of duplicity.
  We develop a near-duplicate detection framework for microposts that provides functionality for analyzing (i) syntactical characteristics, (ii) semantic similarity and (iii) contextual information.
The framework also exploits external Web content which is referenced by the microposts.
  Given our duplicate detection framework, we perform extensive evaluations and analyzes of di erent duplicate detection strategies on a large, standardized Twit-
http://blog.twitter.com/2012/03/twitter-turns-six.html
 our supporting website [22].
1273ter corpus to investigate the quality of (i) detecting duplicates and (ii) categorizing the duplicity level of two tweets.
  We integrate our duplicate detection framework into a Twitter search engine to enable search result diversi cation and analyze the impact of the diversi cation on the search quality.
Since Twitter was launched in 2006 it has attracted a lot of attention both from the general public and research communities.
Researchers managed to  nd patterns in user be-haviours on Twitter, including users  interests towards news articles [1], users  behaviour over time [10], and more general habits that users have on Twitter [18].
Previous research also studied the characteristics of emerging network structures [14] and showed that Twitter is rather a news media than a social platform [9].
Another area of interest is event detection in social Web streams [24], for example in the context of natural disasters [20].
The keyword-based search functionality is a generic tool for users to retrieve relevant information.
Teevan et al. [23] analyzed the search behaviour on Twitter and found di er-ences with respect to normal Web search.
A  rst benchmark on Twitter data was introduced at TREC4 2011 with a track related to search in microblogs5.
Among the solutions developed by participating researchers are many feature-driven approaches that exploit topic-insensitive features such as  does the tweet contain a URL?  to rank the tweets that match a given keyword query, e.g.
[16].
More sophisticated search solutions also extract named entities from tweets in order to analyze the semantic meaning of tweets [21].
Bernstein et al. [5] investigated alternative topic-based browsing interfaces for Twitter while Abel et al. [2] investigated the utility of faceted search for retrieval on Twitter.
However, none of the aforementioned research initiatives investigated strategies for near-duplicate detection and search result di-versi cation in microblogs.
Traditional Web search engines bene t from duplicate detection algorithms and diversi cation strategies that make use of Broder et al. s [6] shingling algorithm or Charikar s [7] random projection approach.
Henzinger conducted a large-scale evaluation to compare these two methods [8] and Manku et al. [12] proposed to use the latter one for near-duplicate detection during Web crawling.
To achieve diversi cation in search results, Agrawal et al. [3] studied the problem of search result diversi cation in the context of answering ambiguous Web queries and Ra ei et al. [19] suggested a solution to maximize expectations that users have towards the query results.
However, to the best of our knowledge, the problem of identifying near-duplicate content has not been studied in the context of microblogs.
In this paper, we thus aim to bridge the gap and research near-duplicate detection and search result diversi cation on Twitter.
In this section, we provide the outcomes of our study of duplicate content on the Twitter platform.
We present a 4http://trec.nist.gov 5http://sites.google.com/site/microblogtrack/ de nition of near-duplicate tweets in 5 levels and show concrete examples.
We then analyze near-duplicate content in a large Twitter corpus and investigate to what extent near-duplicate content appears in Twitter search results.
All our examples and experiments utilize the Twitter corpus which is provided by TREC [13].
In this paper, we de ne duplicate tweets as tweets that convey the same information either syntactically or semantically.
We distinguish near-duplicates in 5 levels.
Exact copy The duplicates at the level of exact copy are identical in terms of characters.
An example tweet pair (t1, t2) in our Twitter corpus is: t1 and t2: Huge New Toyota Recall Includes 245,000 Lexus GS, IS Sedans - http://newzfor.me/?cuye Nearly exact copy The duplicates of nearly exact copy are identical in terms of characters except for #hashtags, URLs, or @mentions.
Consider the following tweet: t3: Huge New Toyota Recall Includes 245,000 Lexus GS, IS Sedans - http://bit.ly/ibUoJs Here, the tweet pair of (t1, t3) is a near-duplicate at a level of nearly exact copy.
Strong near-duplicate A pair of tweets is strong near-duplicate if both tweets contain the same core messages syntactically and semantically, but at least one of them contains more information in form of new statements or hard facts.
For example, the tweet pair of (t4, t5) is strong near-duplicate: t4: Toyota recalls 1.7 million vehicles for fuel leaks: Toyota s latest recalls are mostly in Japan, but they also... http://bit.ly/dH0Pmw t5: Toyota Recalls 1.7 Million Vehicles For Fuel Leaks http://bit.ly/flWFWU Weak near-duplicate Two weak near-duplicate tweets either (i) contain the same core messages syntactically and semantically while personal opinions are also included in one or both of them, or (ii) convey semantically the same messages with di ering information nuggets.
For example, the tweet pair of (t6, t7) is a weak near-duplicate: t6: The White Stripes broke up.
Oh well.
t7: The White Stripes broke up.
That s a bummer for me.
Low-overlapping The low-overlapping pairs of tweets semantically contain the same core message, but only have a couple of common words, e.g.
the tweet pair of (t8, t9): t8: Federal Judge rules Obamacare is unconsitutional...
t9: Our man of the hour: Judge Vinson gave Obamacare its second unconstitutional ruling.
http://fb.me/zQsChak9 If a tweet pair does not match any of the above de nitions, it is considered as non-duplicate.
In Section 3.1, the example tweets come from the Tweets
 TREC 2011.
The corpus is a representative sample from tweets posted during a period of 2 weeks (January 23rd to February 8th, 2011, inclusive).
As the corpus is designed to be a reusable test collection for investigating Twitter search

 We construct syntactical features by matching the tweet pairs with respect to their overlap in letters, words, hashtags and URLs.
Levenshtein distance This feature indicates the number of characters required to change one tweet to the other.
Each change can be a deletion, insertion, or substitution.
Hence, Levenshtein distance evaluates the di erence between a pair of tweets on the basis of di erences in the usages of words, phrases, et cetera.
As the furthest Levenshtein distance between a pair of tweets is Lmax = 140 (the maximum length of a tweet), we normalize this feature by dividing the original value by Lmax.
Therefore, the  nal value of this feature is in the range of [0, 1].
Hypothesis H1: The smaller the Levenshtein distance between a pair of tweets, the more likely they are duplicates and the higher the duplicate score.
Overlap in terms This feature compares tweet pairs by words.
Although the tweets of near-duplicates use similar sets of words, the ordering of words may di er.
Therefore we check the overlap in terms between tweet pairs.
In our implementation, this feature is measured by using the Jaccard similarity coe cient as following: overlap(w(ta), w(tb)) = (1) |w(ta)   w(tb)| |w(ta)   w(tb)| Here, w(ta) and w(tb) are the sets of words that are used in ta and tb respectively.
As we use the Jaccard similarity coe cient to measure the overlap, the value of this feature is in the range of [0, 1].
Similarly, the following features that describe overlap in di erent aspects are measured by the Jaccard similarity coe cient.
Hypothesis H2: The more overlap in terms we  nd between a pair of tweets, the higher the duplicate score.
Overlap in hashtags Hashtags are often used by users in tweets to get involved in the discussion about a topic, and also to make their voice easier to be found by others.
This feature measures the overlap in hashtags between tweet pairs.
Hypothesis H3: The more common hashtags we  nd between a pair of tweets, the more likely they are duplicates and the higher the duplicate score.
Overlap in URLs Due to the length limitation of tweets, users often make use of URLs to give pointers to relevant detailed information.
Hence we check the overlap of the links contained in the given pair of tweets.
If a pair of tweets contain the same URL, they are probably about the same topic and are likely to be duplicates.
Hypothesis H4: The more overlap in URLs we  nd between a pair of tweets, the more likely they are duplicates and the higher the duplicate score.
Overlap in expanded URLs Various Twitter client applications and sharing functions used by news media sites shorten the URLs in order to give more space for real content [4].
As a result, we may miss some actual overlap in URLs if we only check original URLs.
For this reason, we measure the overlap in expanded URLs between tweets.
The expanded URLs can be obtained via the redirected locations given in the HTTP responses.
Hypothesis H5: The more common URLs we found between a pair of tweets after expanding the URLs, the more likely they are duplicates and the higher the duplicate score.
Figure 1: Ratios of near-duplicates in di erent levels and ranking, it is used for the experiments of duplicate detection and search result diversi cation in the rest of the paper.
The original corpus consists of 16 million tweets.
Besides the tweets, 49 topics (or queries) were provided for retrieval purposes.
Moreover, TREC assessors judged the relevance between 40,855 topic-tweet pairs.
A total of 2,825 topic-tweet pairs were judged as relevant.
In other words, each topic on average has 57.65 relevant tweets.
Employing Named Entity Recognition (NER) services on the content of these relevant tweets and the content of the 1,661 external resources referred by the links mentioned in them results in 6,995 and 56,801 entity extractions respectively when using DBpedia Spotlight [15], or 6,292 and 35,774 entity extractions respectively when using OpenCalais6.
For each topic, we manually labelled all pairs of relevant tweets according to the levels of near-duplicates that we de ned in in Section 3.1.
In total, we labelled 55,362 tweet pairs.
As a result, we found that 2,745 pairs of tweets are duplicate, 1.89% of them were labelled as exact copy and 48.71% of them were judged as weak near-duplicates (see Figure 1).
For each of the 49 topics, we ranked the tweets according to their relevance to the corresponding topic based on previous work [21] to investigate to what extent the ranked search results contain duplicate items.
In the top 10, 20, 50 items and whole range of search results, we  nd that 19.4%,
 one  fth of the items are duplicates, we consider duplicate detection an important step in the processing pipeline to diversify the search results.
We consider the problem of duplicate detection as a clas-si cation task that can be performed in two steps: (i) deciding whether a pair of tweets are duplicates or not; and (ii) determining the duplicate level.
For both steps, we rely on a collection of features that exploit syntactical elements, the semantics in both tweets and the content of referred Web pages, as well as context information about tweets and users.
Finally, we employ logistic regression classi ers to ensemble the characteristics from pairs of tweets into the detection of duplicates and the determination of the levels.
We now provide an overview of the di erent features that we extract from tweet pairs for the task of duplicate detection.
Given a pair of tweets (ta, tb), four sets of features are constructed.
In the following sections, we elaborate on the de nition of the features and the hypotheses that led us to include them in our strategies.
6http://www.opencalais.com
 tags, and URLs, we also calculate the di erence in length between two tweets and normalize it by Lmax: abs(|tweeta|   |tweetb|)
 length di erence = (2) Hypothesis H6: The smaller the di erence in length between two tweets, the higher the likelihood of them being duplicates and the higher their duplicate score.
Apart from syntactical features of tweet pairs, semantic information may also be valuable for identifying duplicates, especially when the core messages or important entities in tweets are mentioned in di erent order.
For this reason, we analyze the semantics in both tweets of a pair and construct features that may help with distinguishing duplicate tweets.
We utilize NER services like DBpedia Spotlight, OpenCalais as well as the lexical database WordNet to extract the following features.
Overlap in entities Given extracted entities or concepts by employing NER services, we can check the overlap between the sets of entities in tweet pairs.
The near-duplicate tweet pairs should contain the same core messages and therefore the same entities should be mentioned.
Hypothesis H7: The tweet pairs with more overlapping entities are more likely to have a high duplicate score.
Overlap in entity types For entities extracted from NER services, the types of the entities can also be retrieved.
For example, if tb contains the entities of type person and location, ta should also contain the same type of entities to convey the core messages if they are a near-duplicate tweet pair.
Otherwise, more types of entities may indicate it contains more information or less types may suggest only a partial coverage of the core message in ta.
Therefore, we construct features that measure the overlap in entity types between tweet pairs.
Hypothesis H8: The tweet pairs with more overlapping entity types are more likely to have a high duplicate score.
In fact, we found only a slight di erence in performance between using DBpedia Spotlight and OpenCalais.
In practice, we construct two features and derivative features (introduced later) by using DBpedia Spotlight because it yields slightly better results.
Overlap in topics Besides outputting entities with types, OpenCalais can classify the input textual snippets into 18 different categories a.k.a.
topics.
In this case, each tweet may be assigned more than one topic label or no topic at all.
Therefore, it is possible to construct a feature by checking the overlap in topics.
Hypothesis H9: The tweet pairs that share more topics are more likely to have a high duplicate score.
Overlap in WordNet concepts We constructed this feature to compute the overlap based on lexical standards.
To achieve this, we make use of the lexical database Word-Net [17] to identify the nouns in pairs of tweets and calculate their overlap in these nouns.
Practically, we use JWI (MIT Java Wordnet Interface)7 to  nd the root concepts of the nouns in the tweets.
Hypothesis H10: The more overlap in WordNet noun concepts we  nd in a pair of tweets, the more likely they are to be duplicates and the higher their duplicate score.
7http://projects.csail.mit.edu/jwi/ Algorithm 1: WordNet similarity of a tweet pair input : Tweet Pair (ta, tb) output: WordNet similarity of Tweet Pair (ta, tb) acc   0; if |ta| > |tb| then swap(ta, tb); foreach WordNet noun concept ca in ta do maximum   0; foreach WordNet noun concept cb in tb do maximum   similaritylin (ca, cb); if maximum < similaritylin (ca, cb) then acc  acc + maximum; return acc |Wa| ; Overlap in WordNet synset concepts Making use of merely WordNet noun concepts may not fully cover the overlap in information because di erent tweets may use di er-ent words or synonyms to convey the same information.
In WordNet, synsets are interlinked by means of conceptual-semantic and lexical relations.
We can make use of synsets to include all words with similar meaning for checking the overlap between tweet pairs.
Hypothesis H11: If the concepts in synsets are included for checking overlap between tweet pairs then the overlap feature may have a more positive correlation with the duplicate scores.
WordNet similarity There are several existing algorithms for calculating the semantic relatedness between WordNet concepts, e.g.
the method proposed by Lin et al. [11] can measure the semantic relatedness between two concepts with a value between [0, 1].
The WordNet concepts are paired in order to get the highest relatedness.
Practically, we follow Algorithm 1 to get this feature for a tweet pair (ta, tb).
In the description of the algorithm, Wa stands for the set of WordNet noun concepts that appear in ta.
Hypothesis H12: The higher the WordNet similarity of a tweet pair, the higher the likelihood of the tweets being duplicates and the higher their duplicate score.
Due to the length limitation of tweets, 140 characters may not be enough to tell a complete story.
Furthermore, some tweets, created by sharing buttons from other news sites for example, may even break the complete message.
Thus, we make use of the external resources that are linked from the tweets.
This step yields additional information and further enriches the tweets  semantics.
Finally, we build a set of so-called enriched semantic features.
We construct six enriched semantic features, which are constructed in the same way as semantic features introduced in Section 4.1.2.
The only di erence is that the source of semantics contains not only the content of the tweets but also the content that we  nd by retrieving the content of the Web sites that are linked from the tweets.
Besides analyzing syntactical and semantic aspects, which describe the characteristics of tweet pairs, we also evaluate the e ects of the context in which the tweets were published on the duplicate detection.
We investigate three types 1276of contextual features: temporal di erence of the creation times, similarity of the tweets  authors, and the client application that the authors used.
Temporal di erence For several popular events, e.g.
UK Royal wedding, Japanese earthquake, and Super Bowl, users have posted thousands of tweets per second.
During these events, breaking news are often retweeted not long after being posted.
Therefore, it is reasonable to assume that the time di erence between duplicate tweets is rather small.
We normalize this feature by dividing the original value by the length of the temporal range of the dataset (two weeks in our setup).
Hypothesis H13: The smaller the di erence in posting time between a pair of tweets, the higher the likelihood of it being a duplicate pair and the higher the duplicate score.
User similarity Similar users may publish similar content.
We measure user similarity in a lightweight fashion by comparing the number of followers and the number of followees.
Hence, we extract two features: the di erences in #followers and #followees to measure the similarity of the authors of a post.
As the absolute values of these two features vary in magnitude, we normalize this feature by applying log-scale and dividing by the largest di erence in log-scale, which is 7 in our case.
Hypothesis H14: The higher the similarity of the authors of a pair of tweets, the more likely that the tweets are duplicates.
Same client This is a boolean feature to check whether the pair of tweets were posted via same client application.
With authorization, third-party client applications can post tweets on behalf of users.
Hence, di erent Twitter client applications as well as sharing buttons on various Web sites are being used.
As the tweets that are posted from the same applications and Web sites may share similar content, provenance information and particularly information about the client application may be used as evidence for duplicate detection.
Hypothesis H15: The tweet pairs that are posted from the same client application tend to be near-duplicates.
As previously stated, we take the Twitter corpus released at TREC (Tweets2011 ) as our Twitter stream sample for the task of duplicate detection.
Before we turn to (evaluating) duplicate detection strategies, we  rst perform an in-depth analysis of this sample with respect to the features that we presented in Section 4.1.
We extracted these features for the 55,362 tweet pairs with duplicity judged (see Section 3.2).
In Table 1, we list the average values and the standard deviations of the features and the percentages of true instances for the boolean feature respectively (same client).
Moreover, Table 1 shows a comparison between features of duplicate (on all 5 levels) and non-duplicate tweet pairs.
Unsurprisingly, the Levenshtein distances of duplicate tweet pairs are on average 15% shorter than the ones of non-duplicate tweet pairs.
Similarly, duplicate tweet pairs share more identical terms than non-duplicate ones: the duplicates have a Jaccard Similarity of 0.2148 in terms, whereas only 0.0571 for the non-duplicates.
Hence, these two features which compare the tweets in letters and words may be potentially good indicators for duplicate detection.
Although there is a di erence in common hashtags between the duplicates and the non-duplicates, the overlap in hashtags does not seem to be a promising feature because of the low absolute value.
This may be explained by the low usage of hashtags.
The two features that check overlap in hyperlinks show similar characteristics but are slightly better.
As expected, we discover more overlap in links by expanding the shortened URLs.
Tweet pairs may convey the same messages with syntactically di erent but semantically similar words.
If this is the case then the syntactical features may fail to detect the duplicate tweets.
Therefore, the features that are formulated as overlap in semantics are expected to be larger in absolute values than the syntactical overlap features.
Overall, the statistics that are listed in Table 1 are in line with our expectations.
We discover more overlap in the duplicates along 3 dimensions, including entities, entity types, and topics, by exploiting semantics with NER services.
More distinguishable di erences can be found in the features constructed from WordNet.
The duplicate tweet pairs have more overlap in WordNet noun concepts or synsets (0.38) than the non-duplicate pairs (0.12).
The feature of WordNet similarity is also potentially a good criterion for duplicate detection: the average similarity of duplicate pairs is 0.61 compared to 0.35 for non-duplicate pairs.
The comparison of the enriched semantic features shows similar  ndings to those we observed for the semantic features.
Again, the features that compare WordNet-based concepts are more likely to be good indicators for duplicate detection.
However the WordNet similarity shows less di erence if we consider external resources.
Finally, we attempted to detect the duplicates based on information about the context in which the tweets were posted.
Hypothesis H13 (see Section 4.1.4) states that duplicates are more likely to be posted in a short temporal range.
The result for the feature of temporal di erence in Table 1 supports this hypothesis: the average value of this feature for the duplicate pairs is only 0.0256 (about 8 hours before normalization, see Section 4.1.4) in contrast to 0.2134 (about 3 days) for the non-duplicate ones.
With respect to user similarity, we have not discovered an explicit di er-ence between the two classes.
Regarding the client applications from which duplicate tweets are posted, we observe the following: 21.1% of the duplicate pairs were posted from the same client applications whereas only 15.8% of the non-duplicate ones show the same characteristic.
Having all the features constructed in Section 4.1 and preliminarily analyzed in Section 4.2, we now create di er-ent strategies for the task of duplicate detection.
In practice, as requirements and limitations may vary in processing time, real-time demands, storage, network bandwidth et cetra, di erent strategies may be adopted.
Given that our models for duplicate detection are derived from logistic regression, we de ne the following strategies by combining di erent sets of features, including one Baseline strategy and six Twinder strategies: Sy (only syntactical features), SySe (including tweet content-based features), SyCo (without semantics), SySeCo (without enriched semantics), Sy-SeEn (without contextual features), and SySeEnCo (all features).
As baseline strategy, Levenshtein distance, which compares tweet pairs in letters, is used to distinguish the duplicate pairs and further the duplicate levels.
Feature Duplicate Std.
deviation Non-duplicate Std.
deviation syntactical semantics enriched semantics contextual Levenshtein Distance overlap in terms overlap in hashtags overlap in URLs overlap in expanded URLs length di erence overlap in entities overlap in entity types overlap in topics overlap in WordNet concepts overlap in WordNet Synset concepts WordNet similarity overlap in entities overlap in entity types overlap in topics overlap in WordNet concepts overlap in WordNet Synset concepts WordNet similarity temporal di erence di erence in #followees di erence in #followers same client























































































 Table 1: The comparison of features between duplicate and non-duplicate tweets
 The Twinder strategies exploit the sets of features that have been introduced in Section 4.1).
In our duplicate detection framework which is integrated in the Twinder search engine for Twitter streams (see Section 6), new strategies can easily be de ned by grouping together di erent features.
Sy The Sy strategy is the most basic strategy in Twinder.
It includes only syntactical features that compare tweets on a term level.
These features can easily be extracted from the tweets and are expected to have a good performance on the duplicates for the levels of Exact copy or Nearly exact copy.
SySe This strategy makes use of the features that take the actual content of the tweets into account.
Besides the syntactical features, this strategy makes use of NER services and WordNet to obtain the semantic features.
SyCo The strategy of SyCo (without semantics) is formulated to prevent the retrieval of external resources as well as a large amount of semantics extractions that rely on either external Web services or extra computation time.
Only syntactical features and contextual features are considered by this strategy.
SySeCo Duplicate detection can be con gured as applying features without relying on external Web resources.
We call the strategy that uses the sytactical features, semantics that are extracted from the content of tweets, and the contextual informaiton SySeCo.
SySeEn The contextual features, especially the ones related to users, may require extra storage and may be recomputed frequently.
Therefore, the duplicate detection may work without contextual information by applying the so-called SySeEn (without contextual features).
SySeEnCo If enough hardware resources and network bandwidth are available then the strategy that integrates all the features can be applied so that the quality of the duplicate detection can be maximized.
To understand how di erent features and strategies in u-ence the performance of duplicate detection, we formulated a number of research questions, which can be summarized as follows:
 strategies identify duplicates?
duplicate detection?
duplicates?
We employ logistic regression for both steps of the task of duplicate detection: (i) to classify tweet pairs as duplicate or non-duplicate and (ii) to estimate the duplicate level.
Due to the limited amount of duplicate pairs (of all 5 levels, 2,745 instances) in the manually labelled dataset (55,362 instances in total, see Section 3.2), we use 5-fold cross-validation to evaluate the learned classi cation models.
At most, we used
 fraction of positive instances is considerably smaller than the negative one, we employed a cost-sensitive classi cation setup to prevent all the tweet pairs from being classi ed as non-duplicates.
Moreover, because the precision and recall for non-duplicate are over 90%, we use the non-duplicate class as the reference class and focus on the performance of the class of duplicates.
We use precision, recall, and F-measure to evaluate the results.
Furthermore, since our  nal objective in this paper is to reduce duplicates in search results, we also point out the fraction of false positives as the indicator of the costs of losing information by applying our framework.
tection Table 2 shows the performance of predicting the duplicate tweet pairs by applying the strategies described in Section 4.3.
The baseline strategy, which only uses Levensthein distance, leads to a precision and recall of 0.5068 and 0.1913 respectively.
It means, for example, if 100 relevant tweets are returned for a certain search query and about 20 tweets (the example ratio of 20% according to the statistics given in Section 3.2) are duplicates that could be removed, the baseline strategy would identify 8 tweets as duplicates.
However, only 4 of them are correctly classi ed while 16 other
 Performance Measure precision recall F-measure Score


 Baseline

 Sy SyCo SySe SySeEn SySeCo SySeEnCo


















 Table 2: Performance Results of duplicate detection for di erent sets of features true duplicates are missed.
In order to measure both precision and recall in once, the F-measure is used and for the Baseline strategy the value is 0.2777.
In contrast, the Sy strategy, which is the most basic one for Twinder, leads to a much better performance in terms of all measures, e.g.
an F-measure of 0.3923.
By combing the contextual features, the SyCo strategy achieves a slightly better F-measure of
 relatively little to the performance.
Subsequently, we leave out the contextual features and check the importance of semantics in the content of the tweets and external resources.
The SySe (including tweet content-based features) strategy considers not only the syntactical features but also the semantics extracted from the content of the tweets.
We  nd that the semantic features can boost the classi er s e ectiveness as the F-measure increased to 0.4354.
The enriched semantics extracted from external resources brought little bene t to the result as the SySeEn strategy has a performance with F-measure of 0.4403.
Overall, we conclude that semantics play an important role as they lead to a performance improvement with respect to F-measure from 0.3923 to 0.4403.
Thus the so-called SySeCo strategy excludes the features of enriched semantics but again includes the contextual features.
Given this strategy, we observe an F-measure of
 features), the highest F-measure can be achieved.
At the same time, we nearly keep the same precision as with the Baseline strategy but boost the recall from 0.1913 to 0.4299.
This means that more than an additional 20% of duplicates can be found while we keep the accuracy high.
In this stage, we will further analyze the impact of the di erent features in detail as they are used in the strategy of SySeEnCo.
In the logistic regression approach, the importance of features can be investigated by considering the absolute value of the coe cients assigned to them.
We have listed the details about the model derived for the SySeEnCo (all features) strategy in Table 3.
The most important features are:   Levenshtein distance: As it is a feature of negative coe cient in the classi cation model, we infer that a shorter Levenshtein distance indicates a higher probability of being duplicate pairs.
Therefore, we con rm our Hypothesis H1 made in Section 4.1.1.
  overlap in terms: Another syntactical feature also plays an important role as the coe cient is ranked fourth most indicative in the model.
This can be explained by the usage of common words in duplicate tweet pairs.
This result supports Hypothesis H2.
  overlap in WordNet concepts: The coe cients of semantic and enriched semantic vary in the model.
However, the most important feature is overlap in Word-Net concepts.
It has the largest positive weight which Category Feature Coe cient syntactical semantics enriched semantics Levenshtein distance overlap in terms overlap in hashtags overlap in URLs overlap in expanded URLs length di erence overlap in entities overlap in entity types overlap in topics overlap in WordNet concepts overlap in WordNet Synset concepts WordNet similarity overlap in entities overlap in entity types overlap in topics overlap in WordNet concepts overlap in WordNet Synset concepts WordNet similarity contextual temporal di erence di erence in #followees di erence in #followers same client -2.9387




 -2.1404



 -0.8208 -0.8819
 -0.1825 -2.0867

 -12.6370
 -0.3757 -0.1150 Table 3: The coe cients of di erent features.
The  ve features with the highest absolute coe cients are underlined.
means that pairs of tweets with high overlap in Word-Net concepts are more likely to be duplicates, con rming Hypothesis H10 (Section 4.1.2).
However, we noticed a contradiction in the feature set of enriched semantics, in which the coe cient for overlap in Word-Net concepts is negative (-2.0867) whereas the one the coe cient for the overlap in WordNet synset concept is positive (2.5496).
It can be explained by the high correlation between these two features, especially for high coverage of possible words in external resources.
For this reason, they counteract each other in the model.
  temporal di erence: In line with the preliminary analysis, the shorter the temporal di erence between a pair of tweets, the more likely that it is a duplicate pair.
The highest value of the coe cient is partially due to low average absolute values of this feature.
However, we can still conclude that Hypothesis H13 holds (see Section 4.1.4).
Overall, we noticed that the hypotheses that we made for syntactical features can all be con rmed.
Although the same conclusion could not be made for all the features constructed based on semantics, some of them can be explained.
For example, the overlap of WordNet concepts in the set of enriched semantics is negative.
The reason for this may be twofold: (i) more general terms (such as politics, sport, news, mobile) are overlapping if we consider external resources; (ii) the features in the set of enriched semantics may mislead when we extract the features for a pair of tweets from which no external resources can be found or only one tweet contains a URL.
The situation for other features, e.g.
WordNet similarity, can be explained by the dependencies between some of them.
More speci cally, the features that are based on WordNet similarity in the sets of semantics and enriched semantics may have positive correlation.
Therefore, the coe cients complement each other in values.
When we 1279consider only the contextual features, all other three fea- tures except the temporal di erence do not belong to the most important features.
More sophisticated techniques for measuring user similarity might be used to better exploit, for example, the provenance of tweets for the duplicate detection task.
plicate Detection In all reported experiments so far, we have considered the entire Twitter sample available to us.
In this section, we investigate to what extent certain topic (or query) characteristics play a role for duplicate detection and to what extent those di erences lead to a change in the logistic regression models.
Consider the following two topics: Taco Bell  lling lawsuit (MB0208) and Egyptian protesters attack museum (MB010).
While the former has a business theme and is likely to be mostly of interest to American users, the latter topic belongs into the category of politics and can be considered as being of global interest, as the entire world was watching the events in Egypt unfold.
Due to these di erences, we de ned a number of topic splits.
A manual annotator then decided for each split dimension into which category the topic should fall.
We investigated four topic splits, three splits with two partitions each and one split with  ve partitions:   Popular/unpopular: The topics were split into popular (interesting to many users) and unpopular (interesting to few users) topics.
An example of a popular topic is
 In contrast, topic NIST computer security (MB005) is classi ed as unpopular (as one of 25 topics).
  Global/local: In this split, we considered the interest for the topic across the globe.
The already mentioned topic MB002 is of global interest, since soccer is a highly popular sport in many countries, whereas topic Cuomo budget cuts (MB019) is mostly of local interest to users living or working in New York where Andrew Cuomo is the governor.
We found 18 topics of global and 31 topics of local interest.
  Persistent/occasional: This split is concerned with the interestingness of the topic over time.
Some topics persist for a long time, such as MB002 (the FIFA world cup will be played in 2022), whereas other topics are only of short-term interest, e.g.
Keith Olbermann new job (MB030).
We assigned 28 topics to the persistent and 21 topics to the occasional topic partition.
  Topic themes: The topics were classi ed as belonging to one of  ve themes, either business, entertainment, sports, politics or technology.
MB002 is, e.g., a sports topic while MB019 is considered to be a political topic.
Our discussion of the results focuses on two aspects: (i) the di erence between the models derived for each of the two partitions, and (ii) the di erence between these models (denoted MsplitName) and the model derived over all topics (MallT opics) in Table 5.
The results for the three binary topic splits are shown in Table 4.
Popularity: A comparison of the most important features of Mpopular and Munpopular shows few di erences with the exception of a single feature: temporal di erence.
While temporal di erence is the most important feature in Mpopular,
 the o cial TREC dataset.
it is ranked fourth in Munpopular.
We hypothesize that the discussion on popular topics evolve quickly on Twitter, thus the duplicate tweet pairs should have less di erences in posting time.
Global vs. local: The most important feature in Mglobal, the overlap in terms, and the second most important feature in Mlocal, Levenshtein distance, do not have a similar signi cance in each others  models.
We consider it as an interesting  nding and the possible explanation can lie in the sources of the information.
In more detail, on the one hand the duplicate tweets about the local topics may share the same source thus are low in Levenshtein distances; on the other hand, di erent sources may report on the global topics in their own styles but with the same terms.
Temporal persistence: Comparing the Mpersistent and the Moccasional models, yields to similar conclusions as in the previous two splits: (i) the persistent topics are continuously discussed so that the duplicate pairs are more likely to have short temporal di erences, while the temporal di erences between tweets on occasional topics are relatively insignificant; (ii) the occasionally discussed topics are often using the same set of words.
Topic Themes: The partial results of the topic split according to the theme of the topic are shown in Table 5 (full results can be found on the supporting website for this paper [22]).
Three topics did not  t in one of the  ve categories.
Since the topic set is split into  ve partitions, the size of some partitions is extremely small, making it di cult to reach conclusive results.
Nevertheless, we can detect trends such as the fact that duplicate tweet pairs in sports topics are more likely to contain the same source links (positive coe cient of overlap in original URLs and the opposite of overlap in expanded URLs), while duplicate pairs in entertainment topics contain more shortened links (positive coe cient of overlap in expanded URLs).
The overlap in terms has a large impact on all themes but politics.
Another interesting observation is that a short temporal di erence, is a prominent indicator for the duplicates in the topics of entertainment and politics but not in the other models.
The observation that certain topic splits lead to models that emphasize certain features also o ers a natural way forward: if we are able to determine for each topic in advance to which theme or topic characteristic it belongs to, we can select the model that  ts the topic best.
Having estimated whether a tweet pair is duplicate or not, we now proceed to the second step of the duplicate detection task: determining the exact level of the duplicate tweet pairs.
We compare the di erent strategies (see Section 4.3) in the same way as we have done in Section 5.2.
To analyze the performance in general, we used weighted measures, including precision, recall, and F-measure across
 lar pattern in performance improvement can be observed.
However, it appears that the enriched semantics are more prominent than the contextual features as the so-called Sy-SeEn strategy (without contextual features) performs better than SySeCo strategy (without enriched semantics).
In Figure 2, we plot the performance of the classi cation for 5 di erent levels and the weighted average of them with all the strategies that we have introduced in Section 4.3.
The weight of each level depends on the ratio of duplicate instances.
The curves for 5 di erent levels show the simi-
#topics #samples precision recall F-measure popular

 unpopular







 global




 local




 persistent

 occasional







 Category Feature popular unpopular global local persistent occasional Levenshtein distance overlap in terms overlap in hashtags overlap in URLs overlap in expanded URLs length di erence overlap in entities overlap in entity types overlap in topics overlap in WordNet concepts overlap in WordNet Synset concepts WordNet similarity overlap in entities overlap in entity types overlap in topics overlap in WordNet concepts overlap in WordNet Synset concepts WordNet similarity -3.4919

 -0.1865

 -2.3460


 -0.7763 -0.6254 -1.3013
 -0.5470 -1.8633

 -0.6126
 -2.5868



 -1.1651

 -2.4393



 -1.2312



 -1.8751


 -0.2263 -0.3301

 -0.7335



 -2.3160
 -1.0359 -3.5136




 -3.3525



 -0.3909 -0.5548
 -0.1282 -2.4825

 -3.5916




 -3.1071



 -0.5141 -1.9666

 -2.5058

 -1.2338
 -2.7187



 -0.8804





 -0.1884 -2.1868
 -1.1867 syntactical semantics enriched semantics contextual temporal di erence di erence in #followees di erence in #followers same client -15.8249
 -0.9826 -0.1800 -2.9890


 -5.2712 -1.0797 -0.3224 -0.0272 -17.3894

 -0.0692 -18.9433
 -0.1281 -0.2641 -5.6780 -1.0473 -0.5178
 Table 4: In uence comparison of di erent features among di erent topic partitions.
There are three splits shown here: popular vs. unpopular topics, global vs. local topics and persistent vs. occasional topics.
While the performance measures are based on 5-fold cross-validation, the derived feature weights for the logistic regression model were determined across all topics of a split.
The total number of topics is 49.
For each topic split, the three features with the highest absolute coe cient are underlined.
Performance Measure #topics #samples precision recall F-measure business

 entertainment







 sports




 politics

 technology







 Table 5: This table shows the comparison of performance when partitioning the topic set according to  ve broad topic themes.
The full results can be found on the supporting website for this paper [22].
Strategies Precision Recall F-measure Baseline

 Sy SyCo SySe SySeEn SySeCo SySeEnCo


















 Table 6: Performance Results of predicting duplicate levels for di erent sets of features lar trend with the weighted average of them that indicates the overall performance.
We observe that the level of Weak near duplicate performs better than average and the reason can be attributed to the large ratio of learning instances (see Figure 1).
The classi cation regarding the level of Exact copy is the best because of the decisive in uence of the Levensthein distance.
However, we see a declining trend in performance as we integrate more other tweets.
Hence, further optimization is possible.
To optimize the duplicate detection procedure, we exploit the fact that duplicate pairs of level Exact copy can easily Figure 2: The F-measure of classi cation for di er-ent levels and weighted average by applying di erent strategies be detected by their Levenshtein distance of 0.
After the removal of mentions, URLs, and hashtags, we can also apply the same rule for Nearly exact copy.
Therefore, we can optimize the duplicate detection procedure with the following cascade:
 tweets or after removal of mentions, URLs, and hashtags from both of them, they can be classi ed as Exact copy or Nearly exact copy;
 Algorithm 2: Diversi cation Strategy Baseline

 Sy SyCo SySe SySeEn SySeCo SySeEnCo


















 Table 7: Performance Results of duplicate detection using di erent strategies after optimization Figure 3: Architecture of the Twinder Search Engine: duplicate detection and diversi cation based on feature extraction modules.
tect duplicity.
After this optimization, we get a performance improvement from 0.45 to 0.55 with respect to the F-measure.
The corresponding results are listed in Table 7 (the original results are given in Table 2).
A core application of near-duplicate detection strategies is the diversi cation of search results.
Therefore, we integrated our duplicate detection framework into the so-called Twinder [21] (Twitter Finder ) search engine which provides search and ranking functionality for Twitter streams.
Figure 3 depicts the architecture of Twinder and highlights the core modules which we designed, developed and analyzed in the context of this paper.
The duplicate detection and diversi cation is performed after the relevance estimation of the tweets.
Hence, given a search query, the engine  rst ranks the tweets according to their relevance and then iterates over the top k tweets of the search result to remove near-duplicate tweets and diversify the search results.
Both, the duplicate detection and the relevance estimation module, bene t from the features that are extracted as part of the indexing step which is performed iteratively as soon as new tweets are monitored.
The lightweight diversi cation strategy applies the near-duplicate detection functionality as listed in Algorithm 2.
It iterates from the top to the bottom of the top k search results.
For each tweet i, it removes all tweets at rank j with i < j (i.e. tweet i has a better rank than tweet j) that are near-duplicates of tweet i.
In Section 3.2, we analyzed the ratios of duplicates in the search results.
After applying the lightweight diversi cation strategy proposed above, we again examine the ratios.
The results are listed in Table 8 and reveal that the fraction input : Ranking of tweets T , k output: Diversi ed top k ranking T (cid:48)@k T (cid:48)@k    ; i   0; while i < k and i < T.length do j   i+1 ; while j < T.length do if T [i] and T [j] are duplicates then remove T [j] from T; else j++; T (cid:48)[i] = T [i] return T (cid:48)@k; Range Top 10 Top 20 Top 50 All Before diversi cation After diversi cation Improvement











 Table 8: Average ratios of near-duplicates in search results after diversi cation of near-duplicate tweets within the top k search results is considerably smaller.
For example, without diversi cation there exists, on average, for 22.2% of the tweets at least one near-duplicate tweet within the top 20 search results.
In contrast, the diversi cation strategy improves the search result quality with respect to duplicate content by more than
 in the top 20 search results.
People are confronted with a high fraction of near-duplicate content when searching and exploring information on mi-croblogging platforms such as Twitter.
In this paper, we analyzed the problem of near-duplicate content on Twitter and developed a duplicate detection and search result di-versi cation framework for Twitter.
Our framework is able to identify near-duplicate tweets with a precision and recall of 48% and 43% respectively by combining (i) syntactical features, (ii) semantic features and (iii) contextual features and by considering information from external Web resources that are linked from the microposts.
For certain types of topics such as occasional news events, we even observe performances of more than 61% and 50% with respect to precision and recall.
Our experiments show that semantic features such as the overlap of WordNet concepts are of particular importance for detecting near-duplicates.
By analyzing a large Twitter sample, we also identi ed  ve main levels of duplicity ranging from exact copies which can easily be iden-ti ed by means of syntactic features such as string similarity to low overlapping duplicates for which an analysis of the semantics and context is speci cally important.
Our framework is able to classify the duplicity score on that level with an accuracy of more than 60%.
Given our near-duplicate detection strategies, we additionally developed functionality for the diversi cation of search results.
We integrated this functionality into the Twinder search engine and could show that our duplicate detection and diversi cation framework improves the quality of top k retrieval signi cantly since we decrease the fraction of duplicate content that is delivered to the users by more than 45%.
FP7 project ImREAL (http://imreal-project.eu).
