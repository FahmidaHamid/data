User click logs provide rich and valuable implicit feedback information and can be used as a proxy for relevance judgments [14] or signals for directly in uencing ranking [1].
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
However, they are also known to be vulnerable to position-bias   documents appearing at higher positions tend to receive more clicks even though they are not relevant to the query [10].
Therefore, properly modeling and interpreting the underlying mechanism that gives rise to user clicks is an important yet challenging research problem.
To ful ll this goal, click models [4, 5, 8, 11, 20] have been proposed for modeling user clicks and extracting intrinsic relevance information from the biased click logs.
One fundamental assumption made in click models is the so-called examination hypothesis: a user clicks on a returned document if and only if that document has been examined by the user and it is relevant to the given query.
Based on such an assumption, click models aim to distinguish the relevance-driven clicks from the position-driven clicks by postulating di erent dependency assumptions between the events of examining a document and clicking on it, e.g., position models [7, 8] and cascade models [4, 11].
Though deviating in various dependency assumptions about the examine and click events, all click models formalize a document s relevance quality to a given query as an atomic query-document-speci c parameter, e.g., Bernoulli random variable [4, 11], which is solely estimated from multiple occurrences of such speci c query-document pair in the click logs.
However, this commonly used modeling approach totally ignores the actual document content, which presumably would directly in uence a user s click decision.
As a result, the existing click models can neither take advantage of in-depth knowledge about the relevance quality of a document to the query buried in the document content, nor bene t from the semantic relation among the documents under the same query.
For example, diversity is an important criterion for satisfying a user s information need [6].
A user would be less likely to click on a near-duplicate document if she has already clicked on a previous one with similar content; but in such a case, her  skip  decision does not necessarily mean that the document is irrelevant to her query.
In most of the existing click models, we are only aware of which position is clicked, but the underlying  semantic explanations  for the clicking behavior, e.g., clicked content redundancy and click distance, are completely discarded.
A serious consequence of such an overly simpli ed assumption of a document s relevance quality to a given query is that the model s generalization capability is limited: one has to collect a large number of such query-document pairs to obtain a con dent estimate of relevance.
As shown in the previously reported results, only when there is a su cient number of observations for the given query-document pairs, 1365could the existing click models demonstrate their advantages [4, 8, 11].
In the extreme case, when a new document comes into the search engine, there would be no way for us to accurately infer its relevance to the query immediately by a click model.
The situation gets even severer in time-sensitive retrieval tasks, such as news search, where new documents keep emerging and we need timely estimation of their relevance quality to the given query before we could gather large number of user clicks.
In addition, existing click models only target at decomposing the relevance-driven clicks from the position-driven clicks, which boils down to discounting the observed clicks for each document in a pointwise manner.
However, in a real search scenario, when a user decides to skip one document, it does not necessarily indicate the document is irrelevant to the query, since it is also possible that the previous/next clicked document is more relevant than it.
Such property of user behavior has been proved by many real user studies [10, 14].
Therefore, existing click models are not optimized for distinguishing the relative order among the inferred relevance quality.
To the best of our knowledge, no existing work in click modeling attempted to address these two de ciencies, i.e., lack of exploring content information and failing to capture relative relevance preference.
In this work, we propose to solve these limitations within a probabilistic generative framework, which naturally incorporates the document content and relative preferences between documents into click modeling.
In detail, following the assumptions in cascade models, we propose a Bayesian Sequential State (BSS) model to formalize the generation of the observed clicks under a given query.
First, to capture the rich semantic of a document s relevance quality to the query, we introduced a set of descriptive features (e.g., query matching in title and site authority) into query-document relevance modeling.
Instead of hard coding the dependency among the click/examine events within a query (e.g., clicked documents must be relevant) [4, 11], we give our model the freedom to learn such relation from data based on the designed features, e.g., a click decision will be a ected by the content redundancy between the current and previously clicked documents.
Second, ranking-oriented knowledge, e.g., pairwise click preference, is incorporated by regularizing the posterior distribution of clicks, which helps us tailor the proposed probabilistic model and avoid undesirable local maxima.
The proposed model is a general click modeling framework, which covers most of existing models as special cases.
On a large set of real click logs, the proposed BSS model outperformed several state-of-the-art click models in terms of relevance estimation quality.
Especially when we only have limited size of training samples for a particular query-document pair, BSS model demonstrated its advantage by leveraging the information from ranking-oriented features for accurate relevance estimation.
The introduced pairwise click preference renders BSS model better ranking capability in distinguishing the relative order of relevance among the candidate documents.
Besides, BSS model provides a principled way of interpreting and modeling user s click behaviors, which is not available in existing click models.
The main purpose for modeling the user s click behaviors in search engine logs is to  ght against the notorious position-bias and extract the document s intrinsic relevance to the query.
Richardson et al.
[19] attempted to combat position-bias by imposing a multiplicative factor on documents in lower positions to infer their true relevance.
This idea was later formalized as the examination hypothesis and adopted in the position models [7].
The key assumption in position models is that the user clicks on a document if and only if that document has been examined by the user and it is relevant to the query.
In addition, the examination event only depends on the position.
Formally, given a document d displayed at position i, the probability of d being clicked (i.e., C = 1) is determined by the latent examination event (i.e., E = 1) as, P (C = 1|d, i) = P (C = 1|d, i, E = e)P (E = e|d, i) (cid:2) e {0,1} =P (C = 1|d, E = 1)P (E = 1|i) where P (C = 1|d, E = 1) is speci ed by a document-speci c parameter  d describing the document s intrinsic relevance quality to the query, and P (E = 1|i) is determined by a position-speci c parameter  i to capture position bias.
However, the pure position models deal with examination event in an isolated manner, i.e., the examination probability P (E = 1|i) is assumed to be independent from the click events.
Cascade models are one typical extension to conquer this limitation, which further assume the user will examine the returned documents from top to bottom and make click decisions over each examined document.
Once the user stops examining, all the following documents will not be examined.
Therefore, a click event in a query session is modeled as, P (Ci = 1) =P (Ri = 1) i 1(cid:3) (cid:4)
 (cid:5) j=1 where Ri = 1 is the event that document d at position i is relevant to the given query.
One drawback of the original cascade model is that it can only deal with queries containing one click, later work generalizes it to queries with multiple clicks.
Chapelle et al., [4] solved this limitation by distinguishing the perceived and intrinsic relevance of a document: they assumed the perceived relevance controls the click event and the intrinsic relevance determines the user s satisfaction with the current document and her further examination of the following documents.
Our proposed BSS model falls into the category of cascade models: we assume the users would sequentially examine the returned documents from top to bottom for the given query, and a clicked document must be examined beforehand.
In addition, by incorporating a set of ranking features, we model a document s relevance quality to a given query in a more general way: we assume the relevance quality of a document to the given query is not only an intrinsic property of the document itself, but also in uenced by the displayed document content (e.g., title and abstract).
The dependency relation between the examine and click events are  exibly learned from data, e.g., an examined and relevant document may still be skipped.
In addition, the proposed method also explores the relationship among the clicked and skipped documents under the same query, e.g., content redundancy, which is not covered by existing click models.
In previous work, click decision is only determined by the document s own relevance quality; while in our proposed model, 1366ranking-oriented constraints, e.g., pairwise click preferences, are also incorporated to improve the model s capability of distinguishing the relative order of relevant documents.
As discussed earlier, existing click models have two limitations: 1) modeling the relevance of document to the given query as an atomic query-document-speci c parameter; 2) failing to capture the relative order of estimated relevance between the documents.
To break these two limitations and make click models applicable in more search scenarios, we propose a novel Bayesian Sequential State (BSS) model, in which the relevance quality of document to a given query is parameterized by a set of document-speci c features, and the dependencies among the click and examine events within the same session are explicitly captured and exploited.
Following the basic modeling assumption in cascade models, in our proposed BSS model, we assume that when a user submits a query to the search engine and gets a list of ranked results, she would sequentially examine the returned documents from top to bottom; a document must be examined before she clicks on it; and once she decides to stop examining at current position, she would leave this query session without further interactions.
In particular, we assume that when she is examining a document, she would judge its relevance according to the displayed document content, e.g., title and abstract, which can be characterized by a set of features, e.g., query term matching in title and abstract; in addition, the user remembers her previously examined documents under this query, so that when she moves onto lower positions, her previous click/skip decisions will a ect her later choices, e.g., skipping the less relevant documents.
In other words, the click/skip events within the same query session are assumed to be dependent with each other.
Formally, assume there are N queries in our collection and for each query there are M ordered documents.
Following the notations introduced in Section 2, we use binary variables to denote the relevance status, examine and click events of a document, i.e., R = {0, 1}, E = {0, 1} and C = {0, 1}.
To make the presentation concise, we will ignore the symbol di representing the document displayed at position i under a particular query, when no ambiguity is caused.
Hence, the generation process of the observed clicks in a collection of query logs de ned by the proposed BSS model can be formalized as follows: - For each query q in the query log: - For document d in position i:
 sition based on previous examination event Ei 1 and previous document di 1 s relevance status Ri 1, i.e., Ei   P (Ei|Ei 1, Ri 1, q).
If i = 1, Ei = 1;

 P (Ri|di, q); vance quality, i.e., Ci   P (Ci|Ei, Ri, q)
 Ri, Ci}M formulated as: P (E, R, C|q) = As a result, the joint probability of random variables {Ei, i=1 within a search result page for query q can be M(cid:3) i=1 P (Ci|Ri, Ei, q)P (Ei|Ri 1, Ei 1, q)P (Ri|di, q) (1) Di erent from most of the existing click models, where the dependency relation is hard-coded in their conditional probabilities, e.g., an examined and relevant document must be clicked: Ei = 1, Ri = 1   Ci = 1 [4, 11], we relax such hard requirement to accommodate noise in clicks [5].
We assume that even an examined document is not relevant, the user might still click on it because of her carelessness, i.e., P (Ci = 1|Ei = 1, Ri = 0) > 0; and on the other hand, even if an examined document is relevant, the user might still skip it due to the redundancy or her satisfaction of per-vious clicks, i.e., P (Ci = 0|Ei = 1, Ri = 1) > 0.
In addition, to fully explore the dependency between a click event and the document s relevance status, we assume user s further examination also depends on the current document s relevance quality, i.e., P (Ei|Ei 1, Ri 1) (cid:4)= P (Ei|Ei 1).
The generation process introduced in Eq (1) depicts the skeleton of dependencies among the random variables of {Ei, Ri, Ci}M i=1 within the search result page for a given query.
Next, we will discuss the details of how we can incorporate descriptive features to materialize those dependency relations and exploit rich information conveyed in the users  click behaviors.
To parameterize the dependency, we de ne the conditional probabilities in BSS model via logistic functions:
 P (Ri = 1|di, q) =  (wRT f R q,di + wR q,di ) (2)
 P (Ci = 1|Ri, Ei, q) =    
  (wC  (wC

 Tf C Tf C q,di ) q,di ) if Ei = 0 if Ei = 1,Ri = 0 if Ei = 1,Ri = 1 (3)
 P (Ei = 1|Ri 1, Ei 1, q) =    
  (wE  (wE

 Tf E Tf E q,di ) q,di ) if Ei 1 = 0 if Ei 1 = 1,Ri 1 = 0 if Ei 1 = 1,Ri 1 = 1

 (4) q,d} are the features where  (x) = characterizing the conditional probabilities for relevance status, click and examination events of document di under query q; and   = {wR, wC } are the
 corresponding importance weights for the features.
q,d, f E q,d, f C , wC , wE
 , wE

 In particular, to distinguish the intrinsic relevance and perceived relevance, we assume a document s latent relevance status to a given query is determined by the mixture of these two types of relevance, i.e., P (Ri = 1|q) =  (wRTf R q,d is a scaler factor re ecting the intrinsic relevance quality of a document to the given query, which is assumed to be drawn from a zero mean Normal distribution.
And wR Tf R q,d is an q,d) as de ned in Eq (2).
In particular, wR q,d + wR
 (cid:86) w

 i
 (cid:16)
 f

 i
 (cid:16) , d i
 (cid:16) ) Ei-1 Ei w f(cid:86)
 (

 i Ri-1 ( (cid:86) w

 i
 (cid:16)
 f

 i
 (cid:16) , d i
 (cid:16) ) w f(cid:86)
 (

 i Ci-1 ( (cid:86)
 w f

 d i
 (cid:16) + w
 d i )
 R d , i i ) Ci
 R d , i i ) Ri Table 1: Features for materializing conditional probabilities in BSS model.
Type Description f R q,di 65 text matching features e.g., query matching in title, query proximity in abstract Value -( (cid:86)
 w f

 d i (cid:14) w
 d i )
 f C q,di Figure 1: Factor graph representation for the proposed BSS model.
Circles denote the random variables and black squares denote the conditional probabilities de ned in Eq(2)-(4).
Random variable Ei implies whether document di is examined, Ri represents di s relevance status to the query, and Ci indicates whether di is clicked by the user.
estimate of the perceived relevance quality, which is characterized by a weighted combination of relevance-driven features f R q,d, e.g., site authority and query term matching in document title.
When we have su cient observations of the query-document pair (q, d), the estimation of wR q,d will be close to its true intrinsic relevance; but when we only have limited observations, e.g., for a new document, relevance-driven features f R q,d will help to identify its perceived relevance, which leads to user clicks.
Using the language of probabilistic graphical models, we summarize the speci cation of the proposed BSS model by a factor graph representation in Figure 1.
Table 1 lists the detailed de nition of the proposed features in BSS model, which aim at capturing di erent factors a ecting a user s click decision.
Among the proposed features, f R q,d is the set of features describing the relevance quality of a document to the given query.
This is the core problem for modern information retrieval study, and many e ective features have been proposed for this purpose, such as BM25 and PageRank.
In this work, we utilized 65 text matching features (e.g., query term matching in document title and abstract) as our relevance features.
We should note that the proposed model is general and can potentially accommodate any combination of relevance-driven features.
Though we are aiming to distinguish di erent e ects of the current document s relevance status in examination and click events, it is impossible for us to pre-categorize which set of features would only a ect user s click (examine) decision when the current document is relevant and vice versa.
We decide to use the same set of features for these two situations, but give them di erent weights, i.e., {wC } for click event and {wE } for examine event, to portray their distinct contributions.
In detail, the click-event-related features f C q,d are used to indicate how the user would behave when an examined document is judged to be relevant (R = 1) or irrelevant (R = 0).
For example, when the document is irrelevant, a mis-click might be caused by the position of the document (the user trusts more about the top ranked documents); and when the document is relevant, , wC , wE



 (cid:10) i position # clicks i   arg maxj<i[Cj = 1] distance to last click ||q|| query length AVGj<i,Cj =1sim(di, dj ) clicked content similarity skipped content similarity AVGj<i,Cj =0[sim(di, dj)] j<i 1[Cj = 1] f E q,di (cid:5) (cid:10) i position (cid:4) Cj = 1 # clicks i   arg maxj<i distance to last click AVGj<i,k<i[sim(dj, dk)] avg content similarity variance content similarity VARj<i,k<i[sim(dj, dk)] (All three types of features also include an additional bias (cid:5) Cj = 1 (cid:4) j<i 1 term b accordingly.)
a skip decision may be due to the content redundancy of the clicked documents or her satisfaction of current search result (number of clicks).
And the examine-event-related features f E q,d exploit the factors a ecting a user s examine decision on the next position.
For example, when the current document is irrelevant (R = 0) and the user has skipped several documents in a row (e.g, distance to the last click), she would be more likely to give up further examining; and when the current document is relevant (R = 1) and the clicked documents are quite similar to each other so far (average content similarity), she might be more likely to stop.
When applying the proposed BSS model in the testing phase, we do not need to restrict ourself to the documents ever occurred in the training set (i.e., wR q,d exists).
Since we have formalized the perceived relevance by a set of relevance-driven features, we can directly apply the model to any unseen document by calculating  (wRTf R q,d) as an estimate of its relevance quality to the query (i.e., using mean value of the intrinsic relevance wR q,d from prior for all the new candidate documents).
And for those documents occurred in our training set, we can follow Eq (2) to incorporate the intrinsic relevance of document to the given query learned from the training set.
In model learning phase, because a document s relevance quality and examination status are not observed in the click logs, we appeal to the Expectation Maximization algorithm [18] to estimate the optimal parameter setting, which maximizes the lower bound of the log-likelihood of the observed click events in the training set, (cid:2) (cid:2) log q,i Ei,Ri p(Ei, Ri, Ci|q,  ) L(C, q,  ) = (cid:2) (cid:2)   p(Ei, Ri|Ci, q, ) log p(Ei, Ri, Ci|q,  ) (5) q,i Ei,Ri Particularly, in E-Step, we calculate the posterior distribution of P (E, R|C, q,  (t)) for the latent variables (Ei, Ri)M i=1
 One advantage of the proposed model is that, in the model training phase, since the clicked documents are already known, we can  x them and reduce the maximum clique size in the induced graph structure to 3, i.e., {Ri 1, Ei 1, Ei}.
As a result, exact inference is tractable and can be e ciently calculated via Belief Propagation [15].
And in M-Step, we obtain the new model parameter  (t+1) by maximizing the expectation of the  complete  log-likelihood under P (E, R|C, q,  (t)) as de ned in Eq (5), which can be solved by any standard optimization technique (in this work, we used L-BFGS [17]).
The E-Step and M-Step are alternatively executed until the relative change of the righthand side of Eq (5) is smaller than a threshold.
There are close connections and clear di erences between the proposed BSS model and other existing click models.
First, BSS model explicitly encodes a document s relevance quality to a given query as a mix of intrinsic relevance and perceived relevance, which makes it feasible to incorporate richer information conveyed in document content for relevance estimation.
Second, BSS model generalizes the dependency between a click event and the corresponding document s examine and relevance status.
Most of previous work puts hard constraint over the click event, i.e., Ci =
 and dependency among documents under the same query.
Third, the conditional probabilities de ned in BSS are no longer simply treated as document or position-speci c parameters; instead, a set of descriptive features are designed to capture rich semantics of users  click behaviors.
R=0 = wE If we resume the hard dependency setting and drop most of the newly introduced features, the proposed BSS model can be easily adopted to many existing click models: the examination model proposed in [19] can be treated as a special case of our BSS model if we remove all the examine features except position and assume it is independent of previous relevance status, i.e., wE R=1.
And if we disable the relevance features f R q,d for each query-document pair in the logistic function, we will go back to the traditional setting for the click models.
Based on this, if we further remove the examination and click features, it reduces to the CCM model proposed in [11]; if we only keep the examine feature of distance to last click, it will reduce to the UBM model proposed in [8]; and if we restrict the examine probability to be Ei = 1   Ri 1, it will reduce to the original cascade model [7], since the user has to keep examining until the  rst click.
q,d and only keep wR From the above discussion, we can clearly notice that the proposed BSS model is a more general framework for modeling users  click behaviors: through parameterizations, many informative signals and dependency relation are introduced to help the model explore a document s in-depth relevance quality to the given query from historic clicks.
One potential problem of the current BSS model setting is that the designed structure is too  exible for the learning procedure to identify the  true  parameters, which depict the underlying dependency among the latent variables.
One obvious de ciency is that a document s relevance status, Ri =
 events are determined by the same set of features (weights to be learned from data), if we switch the labels of Ri in the whole collection, the model will  nd another optimal weight setting (switch the weights) to maximize the likelihood, but that is undesirable.
The main reason for this unidenti able problem is that to capture noise within the click events we did not set hard constraints on the conditional probability of click events, i.e., we allow P (Ci = 1|Ei = 1, Ri = 0) > 0 and P (Ci = 1|Ei =
 two conditional probabilities, such that they can freely exchange their roles and still maximize the likelihood of clicks.
Existing click models avoid this unidenti able problem by hard-coding the click events, i.e., Ci = 1   Ei = 1, Ri = 1.
In our work, to keep the  exibility of the modeling assumptions and handle the noisy clicks, we decide to regularize the posterior distribution inferred by the model.
Another bene t of posterior regularization is that we can easily incorporate the ranking-oriented knowledge, i.e., pairwise preference, into click modeling, which is hard to be directly encoded in the original conditional probabilities.
Posterior Regularization (PR) proposed by Ganchev et al. [9] is a general framework for postulating structural constraints over the latent variable models.
The method roots in the block coordinate ascent EM framework [18], and it mod-i es the E-step of a standard EM algorithm to inject constraints over the posterior distribution of latent variables via the form of expectations.
And such regularization will not a ect the convergency of original EM algorithm.
Taking our problem as an example, we should expect that the number of relevance-driven clicks should be larger than mistaken clicks, e.g., E[C = 1, E = 1, R = 1] > E[C = 1, E = 1, R = 0].
Formally, the regularized E-step in PR framework aims to optimize: min q,  KL(q(Y )||p(Y |X,  (t))) s.t.
Eq[ (X,Y )]   b     || ||     (6) (7) where p(Y |X,  (t)) is the original posterior distribution of the latent variables Y given the current model  (t) and observation X, q(Y ) is the regularized posterior distribution of Y ,  (X, Y ) is the constraint function de ned over (X, Y ), and   is a slack variable to relax the constraints.
In our case, Y = {Ei, Ri}M form: the primal solution q  terms of the dual solution   The convenience of PR framework comes from its dual (Y ) is uniquely determined in by, i=1 and X = {Ci}M i=1 (8) q 
 p (Y |X) exp{ (X, Y )} Z( ) and the dual problem is de ned as,  b T     log Z( )   || ||  max  0 (9) where Z( ) is the partition function for Eq(8), and || ||  is the dual norm of || ||  .
Eq (9) can be solved by the projected gradient algorithm [3], and Eq (8) can be e ectively computed via Belief Propagation algorithm by factorizing the constraints according to the original factor graph.
Intuitively, the PR framework can
 of the original EM algorithm, such that the posterior distribution of the latent variables could satisfy some desired properties speci ed in the expectations.
In this section, we discuss the constraint that we designed to conquer the unidenti able problem and that to incorporate the search-oriented pairwise constraints into our BSS model.
In detail, we choose to relax the posterior constraints by setting  to be a small constant (0.01), and use L2-norm to regularize the slack  .
As we have discussed before, we need to restrict the in u-ence of the noisy clicks, and we hypothesize that most of the clicks are driven by the relevance quality of the corresponding document.
To achieve this, we de ne the constraint over the click events as: (cid:2)     i  noise(X,Y ) = (cid:2) = i  noise(X, Yi) (10)  1 if Ei = 1 and Ri = Ci if Ei = 1 and Ri (cid:4)= Ci c otherwise
 and set the left-hand side constant b to be zero in Eq(6).
The meaning of this constraint is straightforward: we require the ratio between the expectation of relevance-driven clicks (Ei = 1, Ri = Ci) and noisy clicks (Ei = 1, Ri (cid:4)= Ci) under the same query to be below a constant c, i.e., E[Ei =
 c quire at least c+1 clicks should be explained by the relevance quality of the document rather than a mistake.
Pairwise click preference can be easily incorporated via the PR framework.
In this work, we encoded two frequently employed click heuristics, i.e., skip above and skip next [14], by the constraints de ned below:  pair(X, Yi) (11) (cid:2) i  pair(X, Y ) = (cid:2)     = i

 1 otherwise and set the left-hand side constant b to be 0 in Eq(6).
The meaning of this constraint is: we only put constraint over the examined documents (i.e., Ei = 1) where the user makes di erent decisions in the adjacent positions (i.e., skip above and skip next).
If the inferred relevance is consistent with the observed click preference (i.e., Ri = Ci and Ri 1 = Ci 1), such a constraint is inactive; otherwise, if the inferred relevance preference contradicts the observed click preference, we need to penalize it.
As we have discussed most of existing click models treat the relevance quality of a document to the given query as a static property, and therefore the evaluation is mostly performed in general web search logs, where the relevance quality of a document to a query is relatively stable.
In this work, we are more interested in evaluating the e ectiveness of the click models in a more dynamic search environment, i.e., news search, where new documents keep emerging, and existing documents quickly become out-of-date and fall out of the top ranked results.
In such a scenario, we cannot expect to collect a large number of clicks for each document before we can make a con dent relevance estimation.
We collected a large set of real user search logs from Yahoo!
news search engine1 in a two months period, from late May to late July 2011.
During this period, a subset of queries are randomly selected and all the associated users  search activities are collected, including the anonymized user ID, query string, timestamp, top 10 returned URL sets and the corresponding user clicks.
In order to unbiasedly compare the relevance estimation performance among di erent click modeling approaches, we also set up a random bucket to collect exploration clicks from a small portion of tra c at the same time.
In this random bucket, the top four URLs were randomly shu ed and displayed to the real users.
By doing such random shu ing, we were able to reduce the noise from position-bias in the collected user click feedback, and such feedback can be used as a reliable proxy on information utility of documents [16].
Therefore, we only collected the top 4 URLs from this random bucket.
In addition, we also asked editors to annotate one day s query log on Aug 9, 2011, into  ve-level relevance labels, e.g.,  Bad ,  Fair ,  Good ,  Excellent  and  Perfect , immediately one day after to ensure the annotation quality.
Simple pre-processing is applied on these click data sets: 1)  lter out the queries without clicks in the random bucket, since they are useless for testing purpose; 2) discard the queries only appearing once in the whole collection; 3) normalizing the relevance features f R q,d by their mean and variance estimated on normal click set, i.e., z-score [21].
After these pre-processing steps, we collected 460k queries from the normal click set and 378k queries from the random bucket set.
One thing we should note is that because of the way we set up the random bucket, many queries and documents might only appear in the random bucket.
Existing click models can hardly estimate the relevance quality of such unseen documents.
In order to make a comprehensive comparison, we split the normal click set into two subsets, and ensure each query is evenly distributed in these two subsets.
We choose one of them for training purpose and another for testing.
The basic statistics of the four data sets used in our experiment are listed in Table 2.
Table 2: Statistics of evaluation corpus.
# Unique Query # Query Normal training clicks Normal testing clicks Random bucket clicks Editorial judgment







 In order to test the model s generalization capacity, we further split the queries in the normal click testing set and random bucket click testing set into di erent categories according to their frequencies in the training set.
The basic statistics of those categories are shown in Figure 2.
As can be clearly noticed in the  gure, a large portion of testing 1http://news.search.yahoo.com/ 1370queries in the random bucket set belong to the less frequent query category (62.92% queries are in the <25 category) comparing to the normal click set (11.49%), which makes the prediction more di cult in the random bucket set.
n o i t r o p o r








 Summary of Testing Queries  Distribution Normal Click Set Random Bucket Click Set <25 25 100 100 200 200 400 400 800800 1.2k1.2k 1.6k1.6k 3.2k3.2k 6.4k >6.4k Query Frequency Figure 2: Distribution of testing queries according to their frequencies in training set.
The main question to be answered in our experiments is whether the proposed model is more accurate than the existing click models in terms of relevance estimation.
To answer this question and evaluate the quality of relevance modeling of the proposed BSS model, we compared it with a set of state-of-the-art click models, including the counting-based models of Dynamic Bayesian Model (DBM) [4] and User Browsing Model (UBM) [8], and feature-based models of Logistic Regression model and Examination Model [19].
Among them, Logistic Regression model and Examination Model are trained on the same set of 65 relevance features f R q,d as our BSS model.
In previous work [8, 11, 20], perplexity on the testing click set was often used as the metric for comparing di erent click models, and it is de ned as,   1

 (cid:2)N i=1  (ci=1) log2 p(ci=1)+ (ci=0) log2 p(ci=0) where N is the number of observations in the testing set.
The lower perplexity a model can achieve, the closer its prediction is to the observation in the testing set.
However, such evaluation metric is problematic for two major reasons.
First, clicks in the testing query log is still position-biased: a less relevant document appears at a higher position would still receive more clicks, such that a model correctly downgrades such a document will even get penalized by the perplexity metric.
Second, since perplexity is de ned based on the absolute value of the predicted probabilities, it is inherently sensitive to scaling or normalization of these probabilities, making it di cult to interpret the results appropriately.
To examine whether these two concerns are empirically supported, we included a simple baseline for click modeling, Naive Click Model (NCM), which only uses the frequency of clicks on a particular query-document pair observed in the training set as its relevance estimation.
In Table 3, we compared NCM s perplexity against other sophisticated click models on normal click testing set.
And to compare their relevance estimation quality, we also evaluated their P@1 ranking performance on the random bucket click set, which is proved to be an unbiased proxy of document s rele-Table 3: Comparison between perplexity metric and ranking metric.
Examine UBM DBN
 perplexity











 vance quality [16].
Due to space limitation, we did not show the result from Logistic Regress Model.
From Table 3, we can clearly notice that the naive baseline outperforms all the other click models in perplexity on the normal click testing set, but its ranking performance is not the best on the unbiased random bucket click set.
Besides, we also observed that the perplexity of Examination Model is signi cantly larger than the other click models.
We looked into the detailed output of Examination Model and found that its predicted click probabilities (with mean 0.78) are much larger than the other models  predictions.
Since the probability of a document being clicked in the normal click testing set is generally small (with mean 0.14), Examination Model get seriously penalized by perplexity.
However, Examination Model s ranking performance is much better than NCM in the random bucket click set.
We thus conclude that the perplexity calculated based on position-biased clicks is not a trustable metric for measuring a click model s capacity of recognizing relevant documents.
A potentially better measure than perplexity is to directly compare di erent click models  ranking performance based on the estimated relevance of documents.
To evaluate ranking performance in a click-based data set, we treat all the clicked documents as relevant and calculate the corresponding Precision at 1 (P@1), Precision at 2 (P@2), Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR).
De nitions of these metrics can be found in standard textbooks in information retrieval (e.g., [2]).
And in the editorial annotation data set, we treated the grade  Good  and above as relevant for precision-based metrics, and also included the normalized discounted cumulative gain (NDCG) [12] as an evaluation metric.
Compared with perplexity metric, such a ranking-based evaluation can better re ect the utility of a click model in estimating the relevance of a document.
We evaluate the quality of relevance estimation of these models from two di erent perspectives: one is to directly use the estimated relevance from the click models to rank the documents; and another is to treat such relevance estimation as signals for training a learning-to-rank algorithm.
In this approach of evaluation, we ranked the candidate documents with respect to the estimated relevance given by a click model, and compared the ranking result against the logged user clicks.
The higher position a click model can put a clicked document on, the better ranking capability it has.
We performed the comparison on both random bucket click set and normal testing click set.
We  rst compared di erent models  P@1 performance on the random bucket click set in Figure 3 (a), where we illustrated the detailed comparison results under each category of di erent query frequencies.
Li et al.
[16] proved that P@1 metric on this random bucket click set can be used as an unbiased proxy to measure the relevance of a document to the given query.
And to make a comprehensive comparison, we also performed the same evaluation on the normal click testing set in Figure 3 (b).
@

 <25
 @








 <25 Logistic Regression Examine Model


 25 100 100 200 200 400 400 800 800 1.2k1.2k 1.6k1.6k 3.2k3.2k 6.4k >6.4k Query Frequency Logistic Regression Examine Model


 25 100 100 200 200 400 400 800 800 1.2k1.2k 1.6k1.6k 3.2k3.2k 6.4k >6.4k Query Frequency (a) P@1 ranking performance under di erent query frequency categories on the random bucket click set (b) P@1 ranking performance under di erent query frequency categories on the normal click set Figure 3: P@1 comparison between di erent click models over random bucket click set and normal click set.
As shown in Figure 3 (a) and (b), in the low query frequency category (query frequency <25), feature-based models outperformed the counting-based models on both random click set and normal click set.
For those less frequent queries, counting-based models do not have enough observations to get a con dent estimation of a document s relevance quality; while by leveraging the information across di erent observations via the same set of relevance-driven features, the feature-based models get a more accurate estimation of relevance for the documents in this category.
With more observations available for a particular query, the relevance estimation quality of counting-based methods improves quickly and outperforms the simple feature-based methods on both testing sets.
The reason for this slow improvement of simple feature-based methods is also due to the feature sharing: in terms of model complexity, counting-based models have more freedom to tune the parameters for each query-document pair; while feature-based models have to adjust the shared feature weights across all the training samples, such that it cannot arbitrarily  t all the observations.
Our BSS model takes advantages of both counting-based and feature-based models by combining the perceived relevance, which is de ned by the weighted sum of relevance-driven features as wRTf R q,d, and the intrinsic relevance, which is modeled as query-document dependent parameters wR q,d, in In BSS model, wR a principled optimization framework.
q,d will be pushed close to zero for the less frequent queries, since there are no su cient observations to get con dent estimations for them, and therefore wRTf R q,d plays a more important role in estimating relevance.
And when we get more observations for a particular query, wR q,d is adjusted to further enhance the relevance estimation, which cannot be correctly predicted by the shared relevance features.
In Table 4 and Table 5, we list the ranking performance over all queries in the two testing sets, where a paired two-samples t-test is performed to validate the signi cance of improvement from the best performing method against the runner-up method under each performance metric.
Since a large portion of testing queries in the random bucket click set belong to the less frequent category (only 29.3% queries appeared more than 100 times in the training set) comparing to the normal click set (76.7%), it becomes much more di cult for the purely counting-based methods to make accurate relevance estimation in the random bucket set.
As we can ob-Table 4: Ranking performance on random bucket click set.
LogisicReg Examine UBM DBN







  











 indicates p-value<0.01




 Table 5: Ranking performance on normal click set.
LogisicReg Examine UBM DBN
























 + indicates p-value<0.05 serve in the results, although the counting-based UBM and DBN methods achieved better ranking performance than the simple feature-based models in the normal click set, their performance degraded on the random bucket set, due to the lack of observations.
And as we have discussed earlier, by leveraging the feature-based and counting-based relevance estimations, BSS model outperformed all the other baseline methods on both data sets.
rank algorithm training In this evaluation, we used the estimated relevance given by a click model as labels to extract ranking preference pairs of documents for training a learning-to-rank algorithm.
We employed the pairwise RankSVM [13] as our basic learning-to-rank algorithm.
To stimulate the situation where we have to make prediction over some new documents before we can collect suf- cient training clicks for each query, e.g., in news search, we only sampled 30% query log from each day in the normal training click set in this experiment.
We estimated the click models on the new training set and generated the click preference pairs according to the predictions of each click model on this set.
In particular, we ordered the documents under a given query according to their predicted relevance from a click model, and treated the top ranked document
 P@1 Ranking Performance Updating During EM Iteration  4.2  4.4  4.6  4.8  5  5.2  5.4  5.6 d o o h i l i e k
   g o
 Zero Initialization +Dampen Noise Constraint +Pairwise Preference Constraint Manual Initialization








 Iteration Steps




 @




 Zero Initializaton +Dampen Nosie Constraint +Pairwise Preference Constraint Manual Initialization







 Iteration Steps (a) Per-query Log-likelihood updates (b) P@1 ranking performance on training set updates Figure 4: EM algorithm updating traces with di erent training settings.
Table 6: RankSVM performance on random bucket click set with di erent training signals.
ori.
click UBM DBN












 + indicates p-value<0.05







 Table 7: RankSVM performance on editorial judgments with di erent training signals.
ori.
click UBM DBN












 + indicates p-value<0.05

















 as positive and others as negative.
The preference pairs are extracted according to this predicted relevance labels under each query and fed into a RankSVM model.
In addition, we also included a RankSVM trained on the preference pairs generated by the original clicks with the skip-above and skip-next click heuristics [14] in this training set as a baseline.
We compared the performance of RankSVM models trained by di erent relevance signals on both random bucket click set and editorial annotation set.
In this experiment, we only included the UBM and DBN as the baseline click models since they performed much better than the simple feature-based Logistic Regression model and Examination Model on the normal click set according to Table 5.
As shown in Table 6 and Table 7, the training signals extracted from click models  output led to much better ranking performance of RankSVM than those extracted based on the simple click heuristics.
In addition, though the RankSVM models trained on purely counting-based click models  output have comparable P@1 and NDCG@1 performance as that trained on BSS model s output, their predictions on the lower positions are much worse, e.g., lower MAP and NDCG@5.
The main reason is that traditional click models only work in a pointwise way, and they cannot directly optimize the relative order of the predicted relevance; while in the proposed BSS model, we incorporated such ranking-R=1, wE R=0, wE oriented property via the pairwise preference constraint, which renders BSS model better capability of distinguishing the relative order among the candidate documents.
As a result, the training signals extracted from BSS model s output are more informative for learning to rank algorithm training.
We now examine the e ectiveness of a key component in the proposed BSS model, i.e., posterior regularization.
As discussed in Section 4, there are two motivations for applying posterior regularization: one is to address the problem of  unidenti ability  in the proposed BSS model, and the other is to incorporate pairwise ranking preferences into click modeling.
Below we validate the e ectiveness of posterior regularization in achieving these two goals.
We  rst initialized all the model parameters, i.e., {wR, R=0}, to be zero in our EM algorithm.
R=0, wC wC We refer to this baseline as  zero initialization .
And based on this initialization, we sequentially added the noise dampening constraint and pairwise preference constraint into the model to obtain two runs of model estimation using posterior regularized EM algorithm.
An alternative way for solving the  unidenti ability  problem is to set priors over the model parameters such that we can guide the model to search in a desirable region.
However, the di culty of this approach for our BSS model is that it is unclear how to set proper priors on the model parameters for directly manipulating the probability P (C|E, R), since this probability is de ned over a set of di erent features via a logistic function.
Thus to compare with such an approach, we manually set the initial value for the bias term in wC R=1 to be 1, re ecting the assumption that most of the clicks should be explained by the relevance quality of a document rather than noise.
We refer to this baseline as  manual initialization.  R=0 to be 1 and in wC We plotted the per-query log-likelihood update trace and the corresponding P@1 ranking performance on the training set during EM iterations for these four di erent ways of learning our BSS model in Figure 4(a) and 4(b).
E ect of dampen noise constraint: as we can clearly observe from the EM update trace that without any spe-ci c parameter initialization or posterior regularization, EM failed to  nd a con guration which could improve the log-likelihood over the all-zero initialized model.
Manual initialization helped the model identify better con gurations.
However, it is not a principled way for achieving so, and the scale of such hard-coded setting will directly bias the learned
 same purpose as manual initialization, but it gives model the freedom to learn such scale from data.
As we can  nd from the updating trace, such constraint successfully led the model to a better con guration for both log-likelihood and P@1 ranking performance than the manual initialization.
E ect of pairwise preference constraint: with the pairwise preference constraint, which aims to enforce ranking-oriented requirement, the model s ranking capability is further improved, even though the log-likelihood did not gain too much.
This is expected: log-likelihood de ned in Eq (5) only considers the pointwise relevance estimation of each query-document pair, which does not count the relative order of relevance among the documents under the same query.
The pairwise preference constraint explores such knowledge, which e ectively improves ranking accuracy as shown in Figure 4(b).
And we should note that such knowledge can hardly be encoded by manual initialization.
Therefore, with the pairwise preference constraint, we solved the de ciency of traditional click models that the dependency relation among the clicked/skipped documents is discarded, and we are able to leverage the knowledge about pairwise preferences to further improve the relevance estimation accuracy.
An interesting additional bene t of the proposed BSS model is that the learned feature weights reveal the in uence of different factors on users  click behaviors, which is not available in existing click models.
To explore this bene t, we list a subset of learned feature weights in Table 8.
Table 8: Feature weights learned by BSS model.
title match abs.
match

 bias -4.654
 bias

 f R wR f C wC wC

 f E wE wE

 age -0.839 pos -1.133
 pos
 -1.381 authority
 dis.
to last click query length -0.445
 # click -0.418
 -3.659
 avg cont.
sim.
-2.237 The weights learned by our BSS model followed our intuition about their e ects in in uencing user s click decisions.
For example,  age  is an important factor in news search: the most recent document (shorter age) is always preferred.
Our BSS model correctly identi ed this negative correlation and put a relatively large weight over the age feature.
The most interesting discovery by our model is the weights learned for the position feature in the click and examine events.
In the click event, when the current document is irrelevant (i.e., R = 0), the weight for the position feature is quite negative, which indicates that a user is very likely to click on an irrelevant document when its displayed position is on the top, i.e., position-bias.
But when the document is relevant (i.e., R = 1), the corresponding weight is closer to zero, which means user s click decision is not a ected by the displayed positions of relevant documents.
And in the examine event, the weight for the position feature is largely positive when the current document is irrelevant, which indicates users tend to further examine lower positions since they have not found satisfactory results.
But when the current document is relevant, the weight becomes largely negative, which means users are inclined to stop further examination since their information need has been met by the relevant documents.
Richardson et al.
No previous work directly addressed the two de ciencies of existing click models, i.e., ignoring rich information conveyed in the document content when modeling clicks, and failing to exploit the relative order of relevance among the clicked/skipped documents.
But there are several studies touched the problem of utilizing features in click modeling.
[19] were the  rst to derive a content-based logistic regression model for predicting click throught rate by discounting the bias in lower positions via a position-speci c multiplicative factor.
However, they treated such discount factor as constant, which was only determined by positions, and thus it was independently estimated without considering the speci c displayed documents and the related clicks.
In [22], the authors also considered to introduce additional features to model click events; however, they used empirically tuned linear interpolation to combine the estimated relevance by a click model with external signals (e.g., BM25).
Our method provides a more principled way for introducing rich descriptive features to formalize the dependency structure for both click and examine events within a query, and learn the optimal combination of those features from the data.
Zhu et al. [23] realized the necessity of incorporating features into click models.
However, they used the same set of general features (e.g., time and length of URL) to describe both click and examine events without distinguishing their speci c e ect in these two di erent events.
Click modeling is an important technique for exploiting search log data and is a crucial component in modern Web search engines.
In this work, we proposed a general Bayesian Sequential State (BSS) model for addressing two de cien-cies of existing click models, namely failing to utilize document content information for modeling clicks and not being optimized for distinguishing the relative order of relevance among the candidate documents.
As our solution, a set of descriptive features and ranking-oriented pairwise preferences are encoded via a probabilistic graphical model, where the dependency relations among a document s relevance quality, examine and click events under a query are automatically captured from the data.
Experiments on a large set of news search logs validate the e ectiveness of the proposed BSS model comparing to several state-of-the-art click models, where content-based features help BSS model leverage information across di erent observations when the training set is limited, and pairwise preference constraint gives the model a more accurate estimate of relevance.
As we have shown in the experiment, the proposed BSS model provides an interesting way of understanding user s click behaviors by analyzing the learned weights on di er-ent features.
With appropriate feature design, our model has the potential to help understand user behavior in various other aspects as well.
As our future work, it would be meaningful to incorporate user-related features into our model, i.e., personalized BSS model, where di erent users will have their own weights over the designed features to re ect their unique search intents.
