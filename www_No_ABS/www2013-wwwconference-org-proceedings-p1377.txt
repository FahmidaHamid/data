Recommender systems are popular research topics in the information retrieval community.
Host of academic and industrial incarnations of recommender systems exists in domains such as movies (Net ix), music (Pandora), e-commerce product recommendations (eBay, Amazon).
Traditional research in recommender systems aims to  nd right item(s) to recommend to a user.
For example, a job recommender system would recommend a senior software engineer position to a user working in an engineering function in the software domain.
This discovery can be powered by content-based models, collaborative  ltering, or hybrid systems.
In addition to  nding the right item to recommend, another key aspect is the timeliness aspect of making the appropriate recommendation.
This aspect becomes critical in settings where the decision-making process is dependent on the tenure (i.e., the time interval) between successive decisions, such as in a job transiting scenario.
To make recommendations at the right time helps the system to achieve higher utility.
Utility is de ned as the satisfaction or value a user gets.
To motivate the discussion, consider the following question - when should the recommender system recommend a senior software engineer position to software engineers?
The system is likely to achieve positive utility when a software engineer who works for 2 years receives such a recommendation.
Yet the system might achieve negative utility when a software engineer who works for 2 months or 5+ years receives such a recommendation.
In this paper, we focus on building models to  nd the right time to make appropriate recommendations.
We start tackling the problem by assuming that the job transiting process follows the Markov renewal process, i.e.
the sequence of making decisions is a Markov chain.
In addition the waiting time depends only on the last decision and the current decision.
Inspired by the survival model in statistics, waiting time between successive decisions can be modeled by the Weibull distribution.
In reality however, the waiting time is not only dependent on the last decision and the current decision, but also dependent on other factors.
In the job domain these factors include the user s pro le and behavioral characteristics, the nature of the current position and potential job opportunities, the interaction patterns between the user and the job or the functional area, the global economic environment, and a host of other externalities like location, time of the year, etc.
To illustrate the point, let us consider the scenario of a potential job from a company with a high reputation.
In this case, the user may change to this new job earlier than average.
To incorporate these covariates (i.e., factors or features) into the model, we use 1377the proportional hazards model to model the tenure before a job transition.
We further extend the model with the hierarchical Bayesian framework to solve the data sparsity issue.
The proposed model predicts the probability of a user making a decision at time t, given that the user did not make the decision before time t. We denote this probability as the tenure-based decision probability.
This could be used by a hybrid recommender system in two ways.
To determine whether to present the recommendation at a certain time in the push-based scenario, the system can treat the probability as a threshold in the  ltering process.
To determine which items to recommend in the pull-based scenario, the system can use the probability as the item s additional feature in the ranking process.
We perform experiments with an anonymous job application dataset from millions of users in 140+ industries from LinkedIn.
New evaluation metrics are designed to analyze the hazards model s performance on predicting the tenure-based decision probability.
Metrics include the perplex-ity/likelihood of the model, the accuracy of the estimated decision time/tenure, the utility of the recommender system, etc.
Experiments demonstrate that the hierarchical proportional hazards model has the better predictability of the decision time, which in turn improves the utility of the recommender system.
The major contribution of this paper includes the following:   Analyze the problem of  nding the right time to make recommendations in the job domain.
  Propose using the proportional hazards model to tackle the problem and extend it with a hierarchical Bayesian framework.
  Evaluate the model with a real-world job application data from LinkedIn to demonstrate the better predictability of the proposed model, as well as the effect of the tenure-based decision probability in improving the utility of recommender systems.
A major task of the recommender system is to present recommendations to the user.
The task is usually conducted by  rst predicting a user s ratings for each item and then ranking all items in the descending order.
There are two major recommendation approaches: content-based  ltering and collaborative  ltering.
Content-based  ltering [16, 19] assumes that descriptive features of an item indicate a user s preferences.
Thus, a recommender system makes a decision for a user based on the descriptive features of other items the user likes or dislikes.
Usually, the system recommends items that are similar to what the user liked before.
Collaborative  ltering [9, 25, 10, 15, 27, 18, 8] on the other hand assumes that users with similar tastes on some items may also have similar preferences on other items.
Thus, the main idea is to use the behavior history from other like-minded users to provide the current user with good recommendations.
Research on collaborative  ltering algorithms reached a peak due to the 1 million dollar Net ix movie recommendation competition [1].
Factorization-based collaborative  ltering approaches [4, 11, 28, 23], such as the regularized Singular Value Decomposition performed well on this competition, possibly better than Net ix s own well-tuned Pearson correlation coe cient algorithm.
A common characteristic of these models is the introduction of user latent factors or/and item latent factors to solve the data sparsity issue.
Factoring time [12, 27, 34, 22, 24, 14, 33, 5, 13, 31, 26] has received much research attention.
In the  eld of recom-mender systems, one focus is about the drift of the user s preference over time [12, 32, 21].
Koren [12] revamped two popular collaborative  ltering methods by modeling the time drifting factor of user preferences.
Rendel et.
al [21] proposed a factorized personalized model that subsumes both a common Markov chain and the normal matrix factorization model.
Compared to their work, our work explicitly models the tenure and the user s interest at each time as a white box.
On one hand, the resulting tenure-based decision probability can be used in the hybrid system to  nd relevant items while on the other, it can be used as a signal to determine when is the right time to recommend an item.
Another research focus is modeling the tenure between purchase orders in the e-commerce domain [27, 34].
Wang et.
al [27] discovered di erent post-purchase behavior in di erent time windows after purchase.
Zhao et.
al [34] used the purchasing tenure to improve the temporal diversity [21].
The tenure and the corresponding purchase probability is modeled inside the framework of a utility-based rec-ommender system [28].
The hybrid system takes the tenure into consideration when ranking all candidate items.
Di er-ent from their work, we propose a more generalized model to explicitly predict the tenure-based decision probability.
This probability can be leveraged in the  ltering process of recommendation items from any system in the domain where the time interval between successive decisions is an important factor.
In this paper, we aim to answer the question: When is the right time to make a job recommendation and how do we leverage it in a job recommender system?
The following notations are used in this paper.
The relationship between di erent variables is shown in Figure 1.
  u = 1, 2, ..., U : the index of the user.
  a, b = 1, 2, ..., C: the index of the item category.
In the job domain, it is the title of the job, such as software engineer, realtor, lawyer, etc.
  ja = 1a, 2a, ..., Ja: the index of the item in category a.
In our setup, an item is a job.
This item has metadata like industry, seniority, function, company, etc.
For example, a job in category Software Engineer belongs to the computer software industry, Information Technology function, Google company, and Entry seniority level.
  m = 1, 2, ..., M : the index of the decision transition between items in category a to items in category b.
If a user with jobj a applies to a job jb, these two job categories {a   b} form a decision transition m. Note that horizontal transitions such as {a   a} is included in the model as well.
1378(cid:15)(cid:13)(cid:3)(cid:11)(cid:14)(cid:8)(cid:16)(cid:12)(cid:11)(cid:1)(cid:10)(cid:1)(cid:26)(cid:1)(cid:24)(cid:3)(cid:1)(cid:23)(cid:27)(cid:1)(cid:4)(cid:25)(cid:1) (cid:5)(cid:3)(cid:15)(cid:6)(cid:7)(cid:12)(cid:13)(cid:19)(cid:1)(cid:3)(cid:1) (cid:5)(cid:3)(cid:15)(cid:6)(cid:7)(cid:12)(cid:13)(cid:19)(cid:1)(cid:4)(cid:1) (cid:12)(cid:4)(cid:14)(cid:6)(cid:13)(cid:18)(cid:3)(cid:16)(cid:12)(cid:11)(cid:1)(cid:8)(cid:1) (cid:8)(cid:15)(cid:6)(cid:10)(cid:22)(cid:1)(cid:9)(cid:3)(cid:1) (cid:8)(cid:15)(cid:6)(cid:10)(cid:22)(cid:1)(cid:9)(cid:4)(cid:1) (cid:19)(cid:10)(cid:21)(cid:8)(cid:1) (cid:16)(cid:10)(cid:6)(cid:22)(cid:1)(cid:15)(cid:3)(cid:1) (cid:16)(cid:10)(cid:6)(cid:22)(cid:1)(cid:15)(cid:4)(cid:1) (cid:2)(cid:8)(cid:10)(cid:6)(cid:1)(cid:15)(cid:1) Figure 1: Illustration of the relationship of variables.
The user  rst makes a job decision of item ja in category a at time ta and then makes a decision of item jb in category b at time tb.
This transition from category a to category b is the ith observation in transition m = {a   b}.
This observation is associated with two parts: 1) tenure ym,i and 2) covariates xm,i (which is not shown in the plot).
  D = {D1, ..., Dm, ..., DM}: The observed data of all transitions from all users.
  Dm = {ym,i, xm,i}: A set of observed data associated with transition m. Each transition m has Nm data observations from all users.
Each observation i = 1, ..., Nm in transition m is associated with two parts: the tenure ym,i and covariates xm,i.
  ym,i: the tenure with the ith observation in transition m. It is the tenure between the user s decision time tb of item jb and the user s decision time ta of item ja.
ym,i = tb   ta.
  xm,i: the k-dimensional vector of covariates that associate with the ith observation in transition m. Covari-ates could be associated with user u who makes the decision transition, the source item ja, the destination item jb, the interaction between ja and jb, the global environment, etc.
The goal of the model is to predict the probability that a user makes a decision of itemj b at current time tb, given that she made the last decision of ja at time ta and she did not make the transition decision up to time tb.
It is the same as predicting the probability that a user makes a decision of item jb at tenure ym,i = tb   ta with covariates xm,i being associated with the transition.
Before describing the hierarchical model that we propose, we  rst brie y review the basic proportional hazards model.
In survival analysis, the survival function determines the time of a particular event, often the failure of a machine or the death of a subject.
Here we consider failure as a user making a decision to transit to a new job.
Let p(y) denote the probability density function of such an event.
The cumulative distribution function P (y) and survival function S(y) are then given by P (y) = P r(T   y) S(y) = P r(T > y) = 1   P (y) (1) (2) where T is a random variable denoting the survival time.
In addition, the hazards function is de ned as the event rate at tenure y, given that the event does not occur until tenure y or later.
h(y) = p(y) S(y) .
In the real world, the hazards function is dependent on covariates.
Two common approaches to incorporate covariates x in the hazards model are: Cox proportional hazards model, which assumes that the covariates are multiplicatively related to the hazards [20]: h(y) = h0(y)exp( 
 x) (3) where h0(y) is the baseline hazards function and   is a vector of parameters.
Accelerated life model, which assumes that the covari-ates are multiplicatively related to the survival time [30], i.e., T = T0exp{ T x} where T0 is the baseline survival time.
Hence, S(y|x) = P r(T > y|x) (4) (5) (6) (7) = P r(T0exp{ T x} > y) = P r(T0 > y   exp{ T x}) = S0(y   exp{  x})
 where S0(y) is the baseline survival function.
Both approaches coincide if the Weibull distribution is used for p(y)1.
Thus, we choose that distribution in this paper, which is given by p(y) =  y 1 exp{ y } (8) where   is the shape parameter and   is the scale parameter.
The corresponding baseline hazards function becomes: h0(y) =  y 1 =  exp( 0)y 1 .
(9)   If   > 1, h0(y) increases with time.
  If   < 1, h0(y) decreases with time.
  If   = 1, h0(y) is constant.
To incorporate covariates x = {x1, ..., xk}, we extend   from exp( 0) to exp{ 0}exp{ 1x1 + ... +  kxk}, i.e., exp{ T x} where we extend  = { 0, ...,  k} and x as {x0 = 1, x1, ..., xk}.
Thus, the probability density function becomes: exp{ exp{ T x}y } p(y) =  exp{ T x}y 1 (10) This probability density function represents the basic proportional hazards model that models the tenure before a transition with associated covariates.
http://data.princeton.edu/pop509/ParametricSurvival.pdf.
  in our notation is p in their notation.
  in our notation is  p in their notation.
1379y c n e u q e r


 + e


 + e


 + e


 + e


 + e






 number of observations for each transition Figure 2: Histogram of number of observations (from 3 to 50) for each job transition m = {a   b}.
In real use cases, the number of observations for each transition tends to follow the power law distribution.
In other words, few transitions are often observed while most transitions are rare events, making it hard to learn parameters of the corresponding hazards model.
To illustrate this, we show the histogram of the number of observations for each transition in the job application data in Figure 2.
To solve the data sparsity issue, we extend the proportional hazards model with a hierarchical Bayesian framework.
The goal of the hierarchical Bayesian framework is to borrow information from other transitions when learning the parameters for transition m. We derive the following hierarchical model, which is illustrated in Figure 3:   For each transition m,  m is sampled from the Gaussian distribution:  m   N ( ,  ) and  m is sampled from the Gaussian distribution:  m   N ( ,  2   ).
Note that   is a (k + 1)-dimensional vector and   is a (k + 1)  (k + 1) matrix, where k is the number of co-variates in the model.
We denote   = ( ,  ,  ,  2   ).
    and   are sampled from N (0, aI) and N (0, b), respectively, and   and  2   are sampled from the in 1(I, c) and the inverse verse Wishart Distribution W  1(1, d), respectively, where I is Gamma distribution   the (k + 1)   (k + 1) identity matrix, and a, b, c, d > 0.
  For each ith observation of transition m with its co-variates xm,i, its tenure ym,i is sampled from the proportional hazards model p(ym,i|xm,i,  m,  m) =  mexp{ T exp{ exp{ T mxm,i}y m 1 mxm,i}y m (11) } m,i m,i Let   = ( ,  1,  1, ...,  M ,  M ) represent parameters that need to be estimated.
The joint likelihood for all variables in the probabilistic model is: L(D,  ) =p ( ) M(cid:2) m=1 p( m,  m| ) Nm(cid:2) i p(ym,i| m,  m, xm,i) (12) data Transition Figure 3: Illustration of dependencies of variables in the hierarchical proportional hazards model.
It shows the ith observation of transition m. ym,i is the tenure which is conditioned on covariates xm,i that are related to this transition and the proportional hazards model.
Each transition m has its own parameters of the hazards model  m,  m.
Models of each transition share information through the prior,   = ( ,  ,  ,  2   ).
Our model contains many hidden variables, some of them being high-dimensional vectors (  and all  m).
Hence, the traditional Bayesian method might be too computationally expensive to learn the model.
Instead we propose an iterative method with a point estimation in each step.
We  rst introduce constants ci, (i = 1, 2, 3, 4) to replace functions of a, b,  ,  2  , respectively, with the same model e ect.
They can be viewed as regularization factors to avoid over tting and can be set by cross-validation in the experiment.
The maximum likelihood estimation of the remaining parameters is shown in Equation 13.
(13)  } (  ,  ,  1,  1, ...,  M ,  M ) = arg max L(D,  ) = arg min{c1|| ||2 M(cid:2) {c3|| m    ||2 {Nm(cid:2) M(cid:2) + c2  + c4( m    )   log(p(ym,i| m,  m, xm,i))}
 m=1 + + m=1 i=1 The steps to solve the previous equation are shown in Algorithm 1.
We  rst initialize  0 and update parameters by following steps 3-5 and step 6 iteratively until convergence.
1 ,  n In steps 3-5, the goal is to estimate parameters of the hazards model  n 1 , ...,  n M , based on the current estimation of the prior  n = ( n   ), where n denotes the iteration index.
Because the parameters  n m for each transition m are independent from each other, we estimate them one by M ,  n   ,  n m,  n

 2: repeat

 for <m = 1,...,M> do  }, n   0  ,  0 Compute the parameters of the hazards model,

 m, based on  n for each transition m.
m and  n  n end for Compute  n+1 based on the hazards model  n n   n + 1 of each transition m with conjugate gradient descent.
m,  n m


 one as: (  n m,  n m) = arg min{c3|| m    n   Nm(cid:2) {log p(ym,i| m,  m, xm,i)}  ||2 + c4( m    n   )
 (14) i=1 We use the following steps in Algorithm 2 iteratively to estimate  n m,  n m.
Algorithm 2 Step 4 in Algorithm 1
 2: repeat
 m , c   0 m based on  n,c Compute  n,c m with conjugate gradient based on  n,c m with conjugate gradi-descent.
m
 Compute  n,c+1 ent descent.
c   c + 1

 7: return  n m,  n m



 The tenure-based decision probability of item jb for user u is de ned as: the probability that user u would make a job transition to jb at time between tb and tb + t, given that the user starts her current position ja at time ta and she did not make the decision up to time tb.
In other words, it is the probability that the survival time T would be between ym,i and ym,i +  t, given that T is not less than ym,i.
We denote the prediction of the tenure-based decision probability by model q as q(ym,i, xm,i).
It is given by q(ym,i, xm,i) = P r(ym,i < T   ym,i +  t|T > ym,i) P r(T   ym,i +  t)   P r(T   ym,i) (15) =
 (16) where P r(T   ym,i) = 1   exp{ y m m,iexp{ T mxm,i}} (17) and each transition m has its own parameters ( m,  m) in model q.
Table 1: The utility set of the recommender system.
There are four types of utilities, depending on whether the system shows the item to the user and whether the user accepts the item.
show:Y show:N accept:Y accept:N uT P uF P uF N uT N
 The major goal of the recommender system is to achieve high utility/user satisfaction.
The user satisfaction is dependent on both the relevance and the time of the recommendation.
While an irrelevant recommendation results in a negative utility, a relevant item could also lead to a negative utility due to the wrong time.
We consider relevant items at the right time as good recommendations.
On the other hand, we consider irrelevant items or relevant item at the wrong time as bad recommendations.
We explore how to use this tenure-based decision probability in two scenarios.
Push-based Scenario In this scenario, the recommender system pushes items to the user proactively regardless of whether the user comes to the website.
The recommendations could be sent to the user by email or other campaign methods.
The challenge is to determine the right time to make relevant recommendations to maximize the user utility/satisfaction.
In Table 1, we show the utility set of the recommender system for di erent types of recommendation.
The utility of model q for a set of recommendation items g is calculated with Equation 18: (cid:3) utilityg(q) = (uT P Ishow,accept + uF P I + uF N I  show,accept + uT N I  show, show,  accept  accept ) (18) I  is the indicator function where I  = 1 if   is true.
The recommendation threshold [7] T hresrec is automatically determined as 2 T hresrec = uF P   uT N uF P   uT N + uF N   uT P (19) where  reasonableness conditions  assume uF P < uT N and uF N < uT P .
It indicates that the utility of a right label is always higher than the utility of a wrong label.
The system could leverage the tenure-based decision probability as a signal in the process.
If the tenure-based decision probability of an item is greater than the threshold T hresrec, the recommendation is presented to the user.
Otherwise, it is not presented.
Pull-based Scenario In this scenario, the recommender systems selects a set of items to recommend to the user when the user comes to the website.
The goal is to select most relevant items to present to the user.
A natural approach is to incorporate the tenure-based decision probability of an item for a user as an additional feature in the hybrid recommender system.
This feature indicates a user s aspiration to make the job transition to the item at the recommendation time.
The hybrid system  rst ranks all candidate items based on
 1381all features that are associated with the user and the item, then selects the top items to present to a user.
In our experiments, we compare the following models.
In this section, we evaluate the performance of the hierarchical proportional hazards model in predicting the transition time.
We  rst list all research questions that we intend to answer, followed by the experimental setup and performance analysis.
Major research questions include:   How accurate is the tenure-based decision probability that is predicted by the hazards model?
Will the model predict a higher probability when the user is likely to transit to new job and a lower probability when the user is not likely to make transitions?
  How accurate is the predicted decision time, compared to the actual decision time in the data?
  Is it important to consider covariates that are associated with the transition?
Does the hierarchical proportional hazards model make more accurate prediction by taking covariates into consideration?
Determining the right recommendation time is a relatively new research topic.
We introduce two metrics to evaluate the accuracy of the tenure-based decision probability and its e ect in the recommendation utility.
The  rst metric is the perplexity of the model.
It is widely used in the evaluation of language models and speech recognition [3].
We assume that the testing data is drawn from the same probability distribution as the training data.
After a probability model q is trained with the training data, the perplexity re ects how well model q predicts the testing data.
The perplexity of the model q is de ned as (cid:3) M(cid:4) Nm(cid:4) (cid:5)
 (cid:2)

 m=1 Nm (20) perplexity(q) = = 2 m=1   (cid:2)
 m=1 i=1 q(ym,i, xm,i) (cid:2)Nm i=1 (cid:2)

 m=1 Nm log2q(ym,i,xm,i) where q(ym,i, xm,i) is de ned in Equation 15.
As we can see, perplexity is the inverse of the probability.
If model q gives higher data likelihood to transitions in the testing data, the corresponding perplexity(q) would be lower.
The lower the perplexity, the better the model.
The second metric is to compare the estimated decision time and the actual one.
It is the same as comparing the estimated tenure ym,i and the actual tenure  ym,i.
After model q predicts the distribution of the tenure, we use the mean of the distribution as the estimated tenure  ym,i.
The absolute error of the estimation is given by |  ym,i   ym,i|.
The mean absolute error (MAE) across all testing data can then be used for analysis and comparison.
M AE(q) = 1(cid:2) i=1 |  ym,i   ym,i|.
The smaller the MAE, (cid:6) (cid:6)
 m=1 Nm
 m=1 Nm the better the model.
H-One is the hazards model that  ts a single set of parameters with no covariates (i.e., the basic Weibull distribution) to the tenure data.
All transitions m = {     } share the same parameters, regardless of the transition s source a and destination b.
H-Source is the hazards model that  ts multiple sets of parameters with no covariates to the tenure data.
All transitions m = {a    } from source a share the same parameters, regardless of the destination b.
H-SourceDest is the hazards model that  ts multiple sets of parameters with no covariates to the tenure data.
All transitions m = {a   b} from source a and destination b share the same parameters.
It only uses the tenure information with no covariates.
H-SourceDestCov further incorporates covariates into the hazards model in H-SourceDest.
In this case, the probability density function and the underlying hazards function change for each user u at time t if values of the associated covariates change.
In this paper, we use the following covariates: 1) about the user u: the user s gender, age, number of connections, number of jobs that the user has changed, average months that the user changes a job; 2) about the item ja or jb: dis-cretized company size, the company age, i.e., the current year minus the year the company was founded; 3) about the relationship between ja and jb: the ra- tio of the company size, the ratio of the company age; whether ja and jb are in the same function, whether they are in the same industry; 4) about the user s aspiration of category b: number of job applications from user u in category b in the last week, last month, last two months, and last three months.
We choose these covariates to show the e ect of the proportional hazards model.
Extensive feature engineering can be applied here to include more useful features/covariates which could be explored in future work.
For all models, we learn parameters for a job transition if the transition is performed by at least ku unique users in the training data.
ku is set to be 5 in the experiment.
If parameters of transitions m = {a   b} are not learned in the training process, average values of parameters of transitions m = {a    } are used to represent parameters of m = {a   b}.
If all parameters of transitions m = {a    } are not learned in the training process, average values of parameters of transitions m = {     } are used to represent parameters of m = {a    }.
In the prediction (ym,i, xm,i) = step, we smooth the probability estimation q max(minThres, q(ym,i, xm,i)) to avoid having a probability that is too low.
minThres is set as 0.001.
 (t) in Equation 15 is set as 3 (i.e., 3 months) for all models during the prediction step.
(cid:3) As positioned earlier in the document, we apply our techniques in the context of a job recommender system and use a real-world dataset from LinkedIn to evaluate our models.
We  rst analyze the user s changing job behavior in recent
 Senior_Project_Manager >Project_Manager Senior_Project_Manager >Senior_Project_Manager Senior_Project_Manager >Program_Manager Senior_Project_Manager >IT_Project_Manager Senior_Project_Manager >Technical_Project_Manager Senior_Project_Manager >Construction_Project_Manager Senior_Project_Manager >Senior_Program_Manager Senior_Project_Manager >Product_Manager Senior_Project_Manager >Business_Development_Manager Senior_Project_Manager >Consultant Transition Senior_Project_Manager >Senior_Project_Manager Senior_Project_Manager >Project_Manager Senior_Project_Manager >Program_Manager Senior_Project_Manager >Project_Director Senior_Project_Manager >Operations_Manager Senior_Project_Manager >Account_Manager Senior_Project_Manager >Manager Senior_Project_Manager >Director Senior_Project_Manager >Senior_Consultant Senior_Project_Manager >Vice_President y t i s n e



 .
.
.
.
.
.
.
y t i s n e



 .
.
.
.
.
.
.
Months Months Figure 4: Density plot of the tenure before job transitions from senior project managers.
(a) tenure before users make the job transition (b) tenure before users start to apply for the new job.
5 years to understand the role of the tenure in the job tran- siting process.
Figure 4 shows the density plot of the tenure before a job transition from senior project managers.
The  rst one shows the tenure before users make the transition and start the new job.
It is clear that di erent job transitions usually happen at di erent tenures.
For example, horizontal transitions from senior project manager to senior project manager are likely to happen at tenures of approximately 18 months while transitions from senior project manager to vice president are likely to happen at tenures of approximately
 stay at the current position longer.
The second plot in Figure 4 shows the tenure before users start to apply for new jobs.
We notice that di erent job applications from the same job position also happen at di erent tenures.
This justi es our motivation that we should take the time factor into consideration when making recommendations.
The goal of the recommender system is to recommend jobs for users to apply.
An actual job transition may or may not happen after a user applies to a job.
Thus, we evaluate our models with the job application dataset and not necessarily the actual position transition data (which is also available).
The dataset is composed of a sample of 11 million job applications over years.
10-fold cross validation is performed.
Here we compare the perplexity of all models in Section 5.2.
As we describe before, the tenure-based decision probability q(ym,i, xm,i) =P r (ym,i < T   ym,i +  t|T > ym,i).
The baseline model, uniform, assigns the uniform distribution to all tenures.
The probability density function is p(ym,i) = where Tunif orm is the number of tenures to consider.
We set Tunif orm = 100, i.e., 100 months.
Tunif orm
 First, we show the perplexity of all models from the 10-fold cross validation of the job application data in Table 2.
In each job application, the user s job before the application and the job that the user applies to are available.
It is clear that all hazards models have lower perplexity than the baseline uniform.
It demonstrates the e ect of modeling the tenure with the hazards model.
Among all hazards models, H-SourceDestCov achieves the lowest perplexity, followed by H-SourceDest, H-Source, and H-One.
H-SourceDestCov  ts the parameters of the proportional hazards model for each m = {a   b} transition and incorporates related covariates.
It shows the importance of considering covariates when modeling the tenure before a transition.
Second, we show the perplexity of di erent degrees of job seekers from a survey data.
The data contains 9k LinkedIn users who were surveyed about their job seeking level in December 2011.
All users categorized themselves into the following  ve categories from active job seekers to passive ones.
1)Aggressively looking: I m actively looking for a new job and sharing my resume; 2) Somewhat looking: I m casually looking for a new job 2-3 times per week to see what is available; 3) Tiptoers: I m thinking about changing jobs and have reached out to close associates but am not actively looking; 4) Explorers: I m not looking for a new job, but would discuss an opportunity with a recruiter to see if the job is interesting to me.
5) Super passive: I m completely happy in my current job and am not interested in discussing any new job opportunities.
The more passive the user, the lower the tenure-based decision probability.
Because the perplexity is the inverse of the likelihood, a good model is expected to have higher perplexity for more passive users.
In the survey data, the destination job or the job category that the user looked for is unknown.
Thus, H-SourceDest and H-SourceDestCov that need the information of the destination are not included in the comparison.
The perplexity of H-One and H-Source for di erent degrees of job seekers is shown in Figure 5.
One can see that the perplexity increases for more passive job seekers and this trend is more pronounced with model H-Source.
The  g-ure also reveals that model H-Source, which learns multiple sets of parameters (one for each source category a), has better predictability for both job seekers and non-job seekers, compared to model H-One.
Uniform H-One H-Source H-SourceDest H-SourceDestCov




 (cid:10)(cid:3)(cid:11)(cid:10)(cid:7)(cid:3)(cid:15)(cid:6)(cid:13)(cid:16)(cid:1)(cid:9)(cid:4)(cid:1)(cid:2)(cid:6)(cid:5)(cid:3)(cid:11)(cid:3)(cid:8)(cid:13)(cid:1)(cid:14)(cid:12)(cid:3)(cid:11)(cid:1)(cid:13)(cid:16)(cid:10)(cid:3)(cid:12)(cid:1) (cid:36)(cid:27)(cid:32)(cid:1) (cid:36)(cid:27)(cid:31)(cid:1) (cid:36)(cid:1) (cid:35)(cid:27)(cid:35)(cid:1) (cid:35)(cid:27)(cid:33)(cid:1) (cid:35)(cid:27)(cid:32)(cid:1) (cid:35)(cid:27)(cid:31)(cid:1) (cid:35)(cid:1) (cid:34)(cid:27)(cid:35)(cid:1) (cid:34)(cid:27)(cid:33)(cid:1) (cid:4)(cid:28)(cid:17)(cid:16)(cid:9)(cid:1) (cid:4)(cid:28)(cid:20)(cid:17)(cid:22)(cid:19)(cid:8)(cid:9)(cid:1)


 .
.
y t i s n e



 .
.
.
model Uniform H One H Source H SourceDest H SourceDestCov (cid:2)(cid:10)(cid:10)(cid:19)(cid:9)(cid:20)(cid:20)(cid:12)(cid:23)(cid:9)(cid:14)(cid:26)(cid:1) (cid:5)(cid:17)(cid:15)(cid:9)(cid:24)(cid:11)(cid:7)(cid:21)(cid:1) (cid:6)(cid:12)(cid:18)(cid:21)(cid:17)(cid:9)(cid:19)(cid:20)(cid:1) (cid:3)(cid:25)(cid:18)(cid:14)(cid:17)(cid:19)(cid:9)(cid:19)(cid:20)(cid:1) (cid:14)(cid:17)(cid:17)(cid:13)(cid:12)(cid:16)(cid:10)(cid:1) (cid:14)(cid:17)(cid:17)(cid:13)(cid:12)(cid:16)(cid:10)(cid:1) (cid:5)(cid:22)(cid:18)(cid:9)(cid:19)(cid:1) (cid:18)(cid:7)(cid:20)(cid:20)(cid:12)(cid:23)(cid:9)(cid:1)






 Absolute difference in months Figure 5: Perplexity of models for di erent degrees of job seekers.
Figure 6: Density plot of the absolute di erence between the estimated tenure and the actual tenure
 Here we compare the estimated tenure  y with the actual tenure y before a transition.
As before, the basic model uniform assigns the uniform distribution to all tenures.
p(ym,i) =
 where Tunif orm is set as 100 months.
Hence, the Tunif orm corresponding estimated tenure is always 50 months.
In Figure 6, we show the density plot of the absolute error between the estimated tenure and the actual tenure, i.e., | y   y|.
The distribution of the absolute error of H-SourceDestCov is closest to 0.
This is con rmed by Table 3 which reports the MAE between  y and y.
All hazards models perform better than the baseline uniform while H-SourceDestCov gives the most accurate estimation of the decision time/tenure, followed by H-SourceDest, H-Source, and H-One.
In order to get a better estimated decision time, we plan to evaluate other estimators (such as the median) in the future work.
In this section, we incorporate the hazards model into the recommender system and evaluate its contribution in di erent scenarios.
In the push-based scenario, the goal is to determine the right time to make relevant recommendations to maximize the user utility.
We use a sample of 6 million job impression data that were collected after the previous 11 million job application data.
The hazards model is trained with the 11 million job application data and predicts the tenure-based decision probability for each impression in the 6 million impression dataset.
An impression might lead to a job application or not, which corresponds to a good recommendation Table 3: Mean absolute error (MAE) between the estimated tenure and the actual tenure Uniform H-One H-Source H-SourceDest H-SourceDestCov




 or a bad one.
The impression item is selected by a hybrid recommender system with decent performance.
The item is assumed to be relevant to the candidate user.
Evaluations with two datasets are presented for each set.
One dataset Impressionall contains all sets of impressions, regardless of whether users applies to any of the impression in a set.
The other dataset Impressionapp contains sets of impressions with at least one application, i.e., a user applies to at least one job in a set of impressions on that day.
The evaluation metric is the utility of the testing data.
The testing data consists of a set of item impressions that the system predicted to be relevant to user u at time t.
The user then choose whether to accept the items presented by the system.
Assume that there are G sets of impressions in the test data.
The average utility utility(q) can be (cid:2)
 g=1 utilityg (q)
 calculated as following: utility(q) = where utilityg(q) for each set of impressions is calculated by Equation 18.
Unlike traditional metrics such as precision@K and recall@K, utility(q) considers both the positive e ect for good recommendations and the negative e ect for di erent types of bad recommendations.
The higher the utility, the better the model.
In addition, we compare the average number of recommendations and the recommendation coverage after  ltering items with q(ym,i, xm,i) > T hresrec .
Coverage is the percentage of sets of impressions that contain at least one recommendation.
Models that have both high utility and high coverage are preferred.
Based on the tenure-based decision probability, the system decides whether or not to present an item (impression) to a user.
The baseline model AlwaysRec shows all impressions to the user.
In the real world scenario, the customized utility set is determined by the application s usage and the users  tolerance for bad recommendations.
In Table 4, we show three sets of utility that correspond to di erent scenarios.
In the  rst utility set, the utility uT P is set to 20 when the system shows an impression and the user applies to it.
When the system shows an impression and the user does not apply to it, the utility uF P is  2.
When the system does not show an impression but the user actually applies to it, the utility uF N is set to  2.
When the system does not show
 all groups of impressions.
Impressionapp contains sets of impressions with at least one application.
In each utility set, the  rst line shows the average utility of the model for each set of impressions.
The second line shows the lift of the model compared to the baseline AlwaysRec.
The third line shows the average number of recommendations.
The fourth line shows the coverage of recommendations.
uT P = 20, uF N = 2 uF P = 2, uT N = 0 Threshold = 0.083 Data AlwaysRec -41.38 Impressionall Impressionapp (24.12) (100%) -31.45 (25.76) (100%) H-One -41.38 (0.00) (24.12) (100%) -31.45 (0.00) (25.76) (100%) H-Source H-SourceDest H-SourceDestCov -37.89 (3.49) (23.11) (91.28%) -29.06 (2.39) (24.73) (91.59%) -38.02 (3.36) (22.79) (97.20%) -29.15 (2.30) (24.39) (97.44%) -37.97 (3.41) (22.62) (99.13%) -29.07 (2.38) (24.20) (99.23%) uT P = 20, uF N = -10 uF P = 2, uT N = 0 Threshold = 0.063 Data AlwaysRec -41.38 Impressionall Impressionapp (24.12) (100%) -31.45 (25.76) (100%) H-One -41.38 (0.00) (24.12) (100%) -31.45 (0.00) (25.76) (100%) H-Source H-SourceDest H-SourceDestCov -40.67 (0.71) (23.89) (98.06%) -31.12 (0.33) (25.54) (98.18%) -40.30 (1.08) (23.73) (98.88%) -30.91 (0.54) (25.37) (98.95%) -39.65 (1.73) (23.55) (99.59%) -30.51 (0.94) (25.18) (99.62%) uT P = 20, uF N = 2 uF P = -10, uT N = 0 Threshold = 0.313 Data AlwaysRec -231.83 Impressionall Impressionapp (24.12) (100%) -230.24 (25.76) (100%) H-One -0.62 (231.21) (0.00) (0%) -1.82 (228.42) (0.00) (0%) H-Source H-SourceDest H-SourceDestCov -15.79 (216.04) (0.78) (6.45%) -17.61 (212.63) (0.87) (6.69%) -26.81 (205.02) (1.43) (26.47%) -28.90 (201.34) (1.59) (28.15%) -71.37 (160.46) (2.91) (66.93%) -73.60 (156.64) (3.21) (68.55%) an impression and the user does not apply to it, the utility uT N is 0.
In this case, users are quite tolerant to bad recommendations with uT P being much higher than uF P .
Model H-One achieves the same utility as AlwaysRec, while the other three models achieve better utility than the baseline.
H-Source has a slightly better utility yet it has the lowest coverage.
In H-One, a single Weibull distribution is  tted to all data from all transitions.
The  tted Weibull distribution has shape   = 0.978 and scale   = 25.93.
As shown in Equation 3, the hazards function is h(y) =  y 1, which is pretty stable for di erent tenure values y when   = 0.978.
In the experiment,  t is set as 3 months in Equation 15.
The resulting tenure-based decision probability of Hone is around 0.10 to 0.11 for di erent tenure values.
Given that the recommendation threshold is 0.083 in this utility set, all impressions are therefore shown to the user in model Hone.
Thus, it performs the same as the baseline model AlwaysRec.
In the second utility set, the utility uF N is set to  10, indicating more utility penalization when the system does not show an impression yet the user would actually apply to it.
In this scenario, H-SourceDestCov wins with the highest recommendation utility and coverage, followed by H-SourceDest, H-Source, H-One, and AlwaysRec.
This indicates that H-SourceDestCov has better predictability of whether the user applies to a job at the recommendation time.
In the third utility set, the utility uF P is set to  10, indicating that the user does not tolerate bad recommendations.
In this case, the best model does not show any recommendation, as in the case of model Hone with coverage of 0%.
All other models have higher utility than AlwaysRec but less utility than Hone.
There is a tradeo  between the utility and the recommendation coverage, which can be tuned in a real-world application.
We discover that the overall utility of the best approach is still negative.
There are two possible reasons behind it.
unbalanced in the impression dataset.
It is challenging for the recommender system to keep good items while  ltering out most bad items.
2) It is true that the user s decision to accept a relevant item is not purely dependent on the time.
Recommender systems also take related factors [6] into account.
A potentially better  ltering signal is to combine the tenure-based decision probability with other probabilities, such as the probability of an item being relevant, the probability of an item being in the right location, etc.
In the Pull-Based Scenario
 In the pull-based scenario, the goal is to select most relevant items to present to the user when the user comes to the site.
The recommendation model is trained with a sample of millions of job application data in one month and tested with a sample of job application data in the following two weeks.
We evaluate the recommender system in the context of a ranking task [4].
For each job application, we  rst apply a heuristic  lter to all open jobs available that day.
First, only open jobs that are in the same geographical region as the user, for example, San Francisco bay area, are retained.
Second, jobs must have a seniority level comparable to the user s current position seniority.
In other words, the system won t recommend entry-level jobs to users in a senior position.
All potential jobs that remain after the heuristic  lter are used in the ranking step.
Similar to other work in rec-ommender systems [4, 28, 34], we use the commonly used IR metrics, precision@K of all testing cases, to compare models.
The task focus is on evaluating a model s performance on ranking relevant items in top positions while ignoring the negative e ect of di erent types of bad recommendations.
The number of recommendations is  xed to be K.
In the experiment, BasicModel with basic features serves as the baseline.
Basic features include similarity-related features between the user pro le (including the user s working experience, education information, etc) and the job information (including the job s title, description, etc).
The following feature groups are compared to the baseline.
Ba-sic+TranProb adds the smoothed transition probability in addition to basic features.
The smoothed transition probability from ja to jb is calculated as following: P (ja   jb) = # ja +J  .
# ja   jb is the number of transitions from # ja jb+  # ja     is the number of all transitions from ja to jb.
ja.
J is the number of jobs and   is the smoothing factor, which is set as 0.1.
Basic+TranProb+Tenure further adds the pure tenure value (such as 8 for 8 months) as an additional feature.
Instead of using the pure tenure value, Ba-(cid:6) (cid:2) 1385(cid:16)(cid:17)(cid:7)(cid:5)(cid:11)(cid:18)(cid:11)(cid:15)(cid:14)(cid:1)(cid:12)(cid:11)(cid:9)(cid:1)(cid:5)(cid:15)(cid:13)(cid:16)(cid:3)(cid:17)(cid:7)(cid:6)(cid:1)(cid:19)(cid:15)(cid:1)(cid:13)(cid:15)(cid:6)(cid:7)(cid:12)(cid:1)(cid:23)(cid:11)(cid:19)(cid:10)(cid:1)(cid:4)(cid:3)(cid:18)(cid:11)(cid:5)(cid:1)(cid:8)(cid:7)(cid:3)(cid:19)(cid:22)(cid:17)(cid:7)(cid:18)(cid:1)(cid:1) (cid:25)(cid:1)(cid:3)(cid:12)(cid:12)(cid:1)(cid:6)(cid:3)(cid:19)(cid:3)(cid:1) (cid:16)(cid:17)(cid:7)(cid:5)(cid:11)(cid:18)(cid:11)(cid:15)(cid:14)(cid:1)(cid:12)(cid:11)(cid:9)(cid:1)(cid:5)(cid:15)(cid:13)(cid:16)(cid:3)(cid:17)(cid:7)(cid:6)(cid:1)(cid:19)(cid:15)(cid:1)(cid:13)(cid:15)(cid:6)(cid:7)(cid:12)(cid:1)(cid:24)(cid:11)(cid:19)(cid:10)(cid:1)(cid:4)(cid:3)(cid:18)(cid:11)(cid:5)(cid:1)(cid:8)(cid:7)(cid:3)(cid:19)(cid:22)(cid:17)(cid:7)(cid:18)(cid:1)(cid:1) (cid:26)(cid:1)(cid:5)(cid:15)(cid:23)(cid:7)(cid:17)(cid:7)(cid:6)(cid:1)(cid:6)(cid:3)(cid:19)(cid:3)(cid:1) (cid:18)(cid:19)(cid:9)(cid:7)(cid:13)(cid:20)(cid:13)(cid:17)(cid:16)(cid:1)(cid:14)(cid:13)(cid:11)(cid:1)(cid:7)(cid:17)(cid:15)(cid:18)(cid:5)(cid:19)(cid:9)(cid:8)(cid:1)(cid:21)(cid:17)(cid:1)(cid:15)(cid:17)(cid:8)(cid:9)(cid:14)(cid:1)(cid:26)(cid:13)(cid:21)(cid:12)(cid:1)(cid:6)(cid:5)(cid:20)(cid:13)(cid:7)(cid:1)(cid:10)(cid:9)(cid:5)(cid:21)(cid:24)(cid:19)(cid:9)(cid:20)(cid:1)(cid:1) (cid:28)(cid:1)(cid:4)(cid:17)(cid:21)(cid:2)(cid:17)(cid:25)(cid:9)(cid:19)(cid:9)(cid:8)(cid:1)(cid:8)(cid:5)(cid:21)(cid:5)(cid:1) (cid:1) (cid:9) (cid:11) (cid:12) (cid:22)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:21)(cid:15)(cid:24)(cid:19)(cid:31)(cid:1) (cid:21)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:20)(cid:15)(cid:24)(cid:19)(cid:31)(cid:1) (cid:20)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:19)(cid:15)(cid:24)(cid:19)(cid:31)(cid:1) (cid:19)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:16)(cid:19)(cid:15)(cid:24)(cid:19)(cid:31)(cid:1) (cid:20)(cid:1) (cid:21)(cid:1) (cid:22)(cid:1) (cid:23)(cid:1) (cid:24)(cid:1) (cid:25)(cid:1) (cid:26)(cid:1) (cid:27)(cid:1) (cid:28)(cid:1) (cid:20)(cid:19)(cid:1) (cid:20)(cid:20)(cid:1) (cid:20)(cid:21)(cid:1) (cid:20)(cid:22)(cid:1) (cid:20)(cid:23)(cid:1) (cid:20)(cid:24)(cid:1) (cid:20)(cid:25)(cid:1) (cid:20)(cid:26)(cid:1) (cid:20)(cid:27)(cid:1) (cid:20)(cid:28)(cid:1) (cid:21)(cid:19)(cid:1) (cid:19)(cid:15)(cid:16)(cid:1)(cid:2)(cid:1)(cid:17)(cid:7)(cid:5)(cid:15)(cid:13)(cid:13)(cid:7)(cid:14)(cid:6)(cid:3)(cid:20)(cid:15)(cid:14)(cid:1) (cid:1) (cid:9) (cid:11) (cid:12) (cid:22)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:21)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:20)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:19)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:16)(cid:20)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:16)(cid:21)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:20)(cid:1) (cid:21)(cid:1) (cid:22)(cid:1) (cid:23)(cid:1) (cid:24)(cid:1) (cid:25)(cid:1) (cid:26)(cid:1) (cid:27)(cid:1) (cid:28)(cid:1) (cid:20)(cid:19)(cid:1) (cid:20)(cid:20)(cid:1) (cid:20)(cid:21)(cid:1) (cid:20)(cid:22)(cid:1) (cid:20)(cid:23)(cid:1) (cid:20)(cid:24)(cid:1) (cid:20)(cid:25)(cid:1) (cid:20)(cid:26)(cid:1) (cid:20)(cid:27)(cid:1) (cid:20)(cid:28)(cid:1) (cid:21)(cid:19)(cid:1) (cid:19)(cid:15)(cid:16)(cid:1)(cid:2)(cid:1)(cid:17)(cid:7)(cid:5)(cid:15)(cid:13)(cid:13)(cid:7)(cid:14)(cid:6)(cid:3)(cid:20)(cid:15)(cid:14)(cid:1) (cid:1) (cid:11) (cid:13) (cid:14) (cid:22)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:21)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:20)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:19)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:16)(cid:20)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:16)(cid:21)(cid:15)(cid:19)(cid:19)(cid:31)(cid:1) (cid:20)(cid:1) (cid:21)(cid:1) (cid:22)(cid:1) (cid:23)(cid:1) (cid:24)(cid:1) (cid:25)(cid:1) (cid:26)(cid:1) (cid:27)(cid:1) (cid:28)(cid:1) (cid:20)(cid:19)(cid:1) (cid:20)(cid:20)(cid:1) (cid:20)(cid:21)(cid:1) (cid:20)(cid:22)(cid:1) (cid:20)(cid:23)(cid:1) (cid:20)(cid:24)(cid:1) (cid:20)(cid:25)(cid:1) (cid:20)(cid:26)(cid:1) (cid:20)(cid:27)(cid:1) (cid:20)(cid:28)(cid:1) (cid:21)(cid:19)(cid:1) (cid:21)(cid:20)(cid:1) (cid:21)(cid:17)(cid:18)(cid:1)(cid:3)(cid:1)(cid:19)(cid:9)(cid:7)(cid:17)(cid:15)(cid:15)(cid:9)(cid:16)(cid:8)(cid:5)(cid:22)(cid:17)(cid:16)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:32)(cid:4)(cid:8)(cid:10)(cid:14)(cid:12)(cid:8)(cid:3)(cid:12)(cid:11)(cid:6)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:32)(cid:4)(cid:8)(cid:10)(cid:14)(cid:12)(cid:8)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:32)(cid:4)(cid:8)(cid:10)(cid:14)(cid:12)(cid:8)(cid:3)(cid:12)(cid:11)(cid:6)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:32)(cid:4)(cid:8)(cid:10)(cid:14)(cid:12)(cid:8)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:32)(cid:4)(cid:8)(cid:10)(cid:14)(cid:12)(cid:8)(cid:3)(cid:12)(cid:11)(cid:6)(cid:1) (cid:2)(cid:5)(cid:13)(cid:9)(cid:7)(cid:32)(cid:4)(cid:12)(cid:5)(cid:10)(cid:3)(cid:12)(cid:11)(cid:6)(cid:32)(cid:4)(cid:8)(cid:10)(cid:14)(cid:12)(cid:8)(cid:1) Figure 7: Precision lift of the hybrid recommender system with di erent feature groups.
(a) performance of all testing data (6435 cases) (b) performance of testing cases that are covered by top transitions (47.7% of all cases) (c) performance of testing cases that are not covered by top transitions (52.3% of all cases) sic+TranProb+TenureProb uses the tenure-based decision probability from hazards model H-SourceDestCov.
In practice, there are several mechanisms for building hybrid recommender systems [2, 29] to use.
We use logistic regression, which is a common practice in industry [17].
It achieves decent performance with low computational complexity.
We compare the precision lift of di erent feature groups by using BasicModel as the baseline in Figure 7.
We show the precision lift of all testing cases, cases that are covered by top transitions, and cases that are not covered.
Suppose that the testing user is working as ja and applies to jb.
This testing case is covered by top transitions if more than ku unique users working with jobs in category a applied to jobs in category b in the training data.
ku is set to be 5.
For example, common destinations of software engineers include senior software engineers, technical leads, consultants, etc.
If a user as software engineer does apply to a job in one of these common destinations, the case is covered by the top transitions.
Otherwise, it is not covered.
In the  rst plot in Figure 7, we observe a 0.5% to 1% lift of all testing cases by adding TranProb and TenureProb features.
The di erence between the model with basic features and the one with Basic+TranProb+TenureProb is signi cant after the top 9 recommendations (p   0.05).
In the second plot in Figure 7 with testing cases that are covered by top transitions, it is clear that the model with Basic+TranProb+TenureProb performs the best.
The model with Basic+TranProb features gives 0.21% lift in precision@5, compared with the baseline BasicModel.
The model with Basic+TranProb+TenureProb gives 1.36% lift in precision@5.
The di erence between the model with basic features and the one with Basic+TranProb+Tenure Prob is signi cant for all top K positions (p   0.05).
On the other hand, the model with the pure tenure value Ba-sic+TranProb+Tenure does not give further improvement, compared to the model with Basic+TranProb.
We observe that the pure tenure value is noisy for hybrid systems that do not capture interactions among features.
First, it is independent of the source job, which is the user s current job.
The same tenure value for users working in di erent jobs does not indicate the same aspiration of changing jobs.
Secondly, it is independent of the destination job.
However, the reality is that the same tenure value indicates di erent level of aspiration for di erent destination jobs.
Thus, it is essential to use the tenure-based decision probability instead of the pure tenure value in hybrid systems such as logistic regression models.
If more advanced hybrid systems, such as gradient boosted tree algorithms are used to capture interactions among features, pure tenure values might perform similarly as the tenure-based decision probability.
In the third plot in Figure 7 with testing cases that are not covered by top transitions, we observe that incorporating TranProb and TenureProb features hurts the performance a little.
It is not surprising because the transition probability and tenure-based decision probability re ect transitions that are shared by most users.
If a user has her own career plan, such as transiting to be a novel writer after working as a software engineer for two years, it won t be captured by the transition probability or the tenure-based decision probability.
Instead, these transitions need to be captured by the user s behavior signals, such as job searches, job clicks, etc.
Besides such job applications are more likely to happen after a user proactively searches the system.
This is an important problem to analyze and study, but beyond the scope of this paper.
We performed research to answer the following question: When is the right time to make a job recommendation and how do we use this inference to improve the utility of a job recommender system?
We proposed using the hierarchical proportional hazards model.
Experiments with the real-world job application data demonstrated the e ective-ness of the hazards model and the importance of considering the time factor in the recommendation process.
This was just the  rst step in exploring the right time to make the recommendation.
More interesting models to leverage the tenure information could be studied and compared with the hazards model.
We plan to also explore other approaches to use the tenure-based decision probability and evaluate it in other domains beyond job recommendations as well.
Acknowledgments We would like to thank Ethan Zhang in LinkedIn for his help and comments.
Part of this work was funded by National Science Foundation IIS-0953908 and CCF-1101741.
Any opinions,  ndings, conclusions or recommendations expressed in this paper are the authors, and do not necessarily re ect those of the sponsors.
