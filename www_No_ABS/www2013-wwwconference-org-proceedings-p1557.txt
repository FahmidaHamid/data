Aggregated search originated from federated search [12], which studies the simultaneous retrieval of information from various separate indexes.
With the increasing amount of different types of online media (e.g.
images, news, video), it is becoming popular for web search engines to present results from a set of speci c verticals dispersed throughout the standard  general web  results, for example, adding image results to the ten blue links for the query  yoga poses .
Retrieving and integrating these various information sources into one interface is called aggregated search (AS) and has become the de-facto search paradigm in commercial search engines.
A key component of AS is vertical selection (VS): selecting relevant verticals (if any) from which items will be selected to appear on the search result page (SERP) alongside the Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
 general web  search results for a given query.
This has been studied in several work [3, 4, 8, 1] and various solutions have been proposed.
Evaluating VS approaches [3, 16, 2, 9,
 date assumes that zero to many verticals are pertinent to a particular query, and aims to compare the quality of a set of selected verticals against an annotated set1.
These type of studies all assume that the annotation set is available and is obtained by either, explicitly collecting labels from assessors [3, 16, 2, 9, 18], or implicitly, by deriving them from user interaction information [9, 5].
Despite the relative success of these evaluation methodologies, the de nition of the relevance of a vertical, given a query, remains unclear.
Di erent work makes di erent assumptions when obtaining the assessments for relevant verticals across a set of queries.
In this paper, the relevance of a vertical for a given query refers to the perceived usefulness of the vertical on a SERP.
The underlying assumptions made when assessing the relevance of verticals may have a major e ect on the evaluation of a SERP.
Consider a user who issues the query  yoga poses  to an AS system that has access to  ve verticals ( news ,  image ,  video ,  shopping  and  blog ).
Prior to viewing the aggregated results, the user may believe that both the  image  and  video  vertical might provide more relevant results.
If such a pre-retrieval evaluation is conducted, the user might annotate those two verticals as relevant.
Conversely, a user who viewed the retrieved results from each vertical might conclude that  video  and  blog  provided the most relevant results.
This may be due to the presence of a blog article that comprehensively describes yoga poses and a highly ranked  video  vertical that contains similar information to an  image  vertical that appears lower down the ranking.
In this case the  image  vertical may seem to provide redundant information.
These scenarios give us some insight into the complexity of de ning the relevance of verticals.
Firstly, pre-retrieval vertical relevance assessments may di er to post-retrieval ones.
This could be due to serendipity ( nding a surprisingly excellent result from a speci c vertical) or to a poorly designed vertical (a poor ranking function within the vertical).
it is possible that making independent vertical relevance assessments does not re ect the characteristics of aggregated search, such as avoiding redundancy (an  image  result containing informa-In addition,
 A set of verticals annotated by a user (or users) for a given query.
AS systems present vertical items embedded within  general web  results, it is not clear whether using  general web  as a reference for deciding the vertical relevance is an appropriate strategy.
Understanding these underlying assumptions when assessing the relevance of verticals is important.
This is because a di erent annotation set (i.e. gold standard) will a ect the metrics that inform us about the performance of di erent VS systems.
Although existing work collects assessments (using di er-ent processes and assumptions) for evaluating VS, to our knowledge, no work has tried to comprehensively understand and compare those assessment processes and assumptions.
This is the focus of this paper.
Speci cally, we employ all of the various strategies present in the literature, to collect vertical relevance assessments, and investigate three main research questions (RQ):   (RQ1) Are there any di erences between the assessments made by users from a pre-retrieval user-need perspective (viewing only vertical labels prior to seeing the  nal SERP) and the assessments made by users from a post-retrieval user perspective (viewing the vertical results in the  nal SERP)?
  (RQ2) When using  general web  results as a reference for making vertical relevance assessments, are these assessments able to predict the users  pairwise preference between any two verticals?
Does the context (results returned from other verticals) in which vertical results are presented a ect a user s perception of the relevance of the vertical of interest?
  (RQ3) Is the preference information provided by a population of users able to predict the  perfect  embedding position of a vertical?
To answer these three research questions, we conducted a set of large-scale user studies using the crowd-sourcing platform Amazon Mechanical Turk.
In Section 2, we formally outline the problem of vertical selection assessment.
Section 3 outlines our experimental design, whereas in Section
 in Section 5 by summarising all the  ndings, discussing the implications of our results and pointing out limitations.
We start by de ning the process involved in collecting vertical relevance assessments.
Second, we enumerate the various components within aggregated search that a ect vertical relevance assessments and outline their relationships.
Thirdly, we review various approaches that derive vertical relevance from the collected assessments.
We then present an analysis of the assumptions made in previous work and discuss how they can a ect the evaluation of aggregated search systems.
We end this section with a summary.
Before formally de ning the vertical relevance assessment process, we  rst list the assumptions made for a SERP P .
Given a set of verticals V = {v1, v2, ...vn}, a SERP P can be denoted as Vp = {vp1, vp2, ..., vpn} where each vpi indicates the position of the vertical block vi on the page.
For consistency with existing work [9], we assume four positions in which verticals can be embedded into the  general web  results: Top of Page (ToP), Middle of Page (MoP), Bottom of Page (BoP), or Not Shown (NS).
When we are only interested in a binary scenario (shown or not), it is assumed that it is best to present the vertical at ToP.
Note that in Vp, multiple verticals can have the same grade (e.g.
two verticals can be simultaneously shown at ToP).
Given a vertical set V = {v1, v2, ...vn}, the vertical relevance It for a search task t is represented by a weighted vector It = {i1, i2, ...in}, where each value ik indicates the importance of vertical vk to search task t. Commonly, It is a binary vector [3, 16], where each element indicates whether or not the vertical is relevant given the search task.
When denoting the best position in which to embed the vertical items in the SERP (ToP, MoP, BoP, NS), a weighted vector It can be used [9, 2].
By assigning diminishing weight according to the embedding position2, each weight ik   It of vertical vk is represented by the corresponding assigned weight of vk s perfect embedding position.
To generate It, user studies must be conducted asking an assessor uj   U = {u1, u2, ...um} to make decisions Aj = {aj1, aj2, ...ajl} over all verticals V .
There are generally two types of assessment ajk: absolute assessments ( what is the quality of vi ) and preference-based assessment ( does vi present better information than vj  ).
As AS is concerned with presenting vertical results integrated within  general web  results, preference assessments [9, 16,
 pairwise assessments l the assessor uj needs to make for Aj is a matter for research, and may be restricted by the budget of a particular study.
Regardless, for each pairwise preference assessment ajk, there are various factors that in uence assessors  decisions.
We discuss these in Section 2.2.
Ultimately, an m   l matrix Mt containing all assessments from all users in U for search task t is obtained.
A con ation method to derive the  nal vertical relevance vector It from the matrix Mt is used.
Di erent methods have been used to derive this  nal vector, which we review in Section 2.3.
After It is obtained, an aggregated search page P can be evaluated based on this information.
Given It, we can evaluate the SERP P based on how Vp correlates with It.
Various metrics can be employed to achieve this.
Precision, recall and the f-measure have been used when It is treated as a binary decision [3, 16].
Recently, risk has been considered and incorporated into risk-aware VS metrics [18].
When allowing multiple embedding positions within a SERP, the distance between Vp and a perfect page V P erf ect derived from It can be used [2].
The further the distance from the perfect page, the worse the performance of the system that generated that SERP P .
p
 This section reviews previous work on making preference assessments for evaluating vertical relevance.
Current work on determining the preference assessments A can be classi ed into two categories: anchor-based and interdependent approaches.
The former assumes that the quality of the anchoring  general web  results serve as a reference criteria for deciding vertical relevance (whether an
 The higher the position, the larger the weight is, i.e.
for the four embedding positions used in our work, weight(ToP) > weight(MoP) > weight(BoP) > weight(NS).
when added to the  general web  results).
This is achieved by asking assessors to assess each vertical vi individually, in an independent pairwise fashion against the  general web  reference page.
A number of work [9, 16, 3] follows this approach.
Interdependent approaches assume that the quality of verticals is relative and dependent on each other.
These approaches gather pairwise preference data over any, and many, possible pairs of verticals v including the  general web  w. Arguello et al s work [2]  ts into this category.
For anchor-based approaches, the number of assessments to be made per assessor, l, equals to the number of verticals n.
For interdependent approaches, l will often be much greater than n (e.g.
1 2   (n + 1)   n in [2]).
Various factors can a ect a user uj when assessing ajk, with respect to a speci c vertical result vk:   (Result Quality) the quality of the retrieved results from vertical vk.
  (Orientation) a user s (uj ) orientation (or preference) to information from a vertical vk.
  (Aesthetic) the aesthetic nature of a vertical vk.
The result quality of the retrieved items from a speci c vertical depends on both the contents of the vertical vk and the ranking function of the vertical vk.
For a given search task t, the more topically relevant items contained in the vertical vk collection, the better the results are likely to be.
More importantly, the higher the relevant items are ranked within the vertical, the better the result quality is.
Either a vertical vk collection with very few relevant items or a poor ranking function can degrade the user s perception of the quality of the vertical vk retrieved results.
A user s orientation to a vertical vk re ects the user s (uj ) own perception of the usefulness (utility) of the vertical to the search task t. The user may have his or her own personalised preference over di erent verticals.
As pointed out in [3, 11], it is not only result quality that satis es a user s need, but items from di erent verticals also satisfy a user s need di erently.
It is the type of information that a ects the user s perception of usefulness (i.e. orientation) for an information need.
Vertical aesthetics represents the aesthetic nature of the vertical vk retrieved results.
For example, it has been demonstrated in [11, 2] that the visually attractive nature of image results tends to increase users engagement on a SERP, compared to those that do not contain images.
The anchor-based and interdependent based approaches use di erent strategies for deriving vertical relevance (It) from the assessments (Mt) for a search task t. For anchor-based approaches, most of previous work [16, 3] rank all the verticals of interest based on the percentage of assessors  preference over a  general web  anchor.
Therefore, a majority preference for a particular vertical leads to the most relevant vertical for a speci c search task.
For interdependent approaches, the Schulze voting method [2, 10] is the most widely used.
For two verticals vi and vj , if more assessors preferred vi over vj than vice versa, then we say that, vi directly beats vj.
A beatpath from vi to vj can be either a direct or an indirect defeat.
The strength of an indirect beatpath is the number of votes associated with its weakest direct defeat.
Finally, vi defeats vj if the strongest (direct or indirect) beatpath from vi to vj is stronger than the one from vj to vi.
All verticals of interest are then ranked by their number of defeats.
When collecting an assessment ajk, current work makes a number of di erent assumptions (dependency of relevance, in uencing factors) to guide the assessments.
Based on the assumptions made, they show the corresponding information to the user for them to make assessments.
We formally review and summarize the underlying assumptions made in a number of studies.
A short summary is given in Table 1.
Traditionally, in federated search [12, 7] (often known as distributed information retrieval), vertical relevance It is assumed to solely depend on result quality, which is determined by the summation of the number of topically relevant items within a vertical collection.
The more topically relevant items the vertical collection contained, the better the given vertical is assumed to be.
When evaluating a SERP P , the quality of the page is determined by evaluating the topical relevance of the items returned (and merged from various verticals), based on traditional information retrieval metrics (e.g.
precision, MAP).
This type of evaluation is heavily focused on topical relevance.
In aggregated search, for example, Zhou et al.
[16] assumed that only vertical orientation contributes to the usefulness of the page.
Therein, the assessors are asked to use the  general web  results as an anchor to assess the usefulness of a given vertical (by only showing the vertical label).
Without viewing the retrieved results or the vertical collection, only when the assessor thinks that the vertical can potentially provide more appropriate results than the  general web , would he/she label it as relevant.
In that research, four assessors are asked for assessments for each vertical.
The vertical relevance It is determined in a binary manner (ToP or None), by using a basic assessor preference thresh-olding approach (e.g.
if 75% of the assessors prefer vi over w, then we label vi as  ToP , otherwise we label it as  NS ).
Finally, VS evaluation is based on the f-measure.
In Arguello et al. [2], although not stated explicitly, it is assumed that the usefulness of the vertical vk is determined by a combination of result quality, orientation and aesthetics.
While viewing results retrieved from each vertical collection using a ranking function unique to the vertical, the assessors are asked to state the preference between any two verticals from V S{w}.
Four assessors are used for assessing each pair.
Di erent from [16], which uses  general web  results as an anchor, the assessments are made between any vi and vj pairs and a voting strategy is used to determine It, i.e. the perfect position of the vertical to be presented.
The quality of the page is then measured by calculating the distance to a reference page (a  perfect  AS page).
In [9, 2], a vertical relevance is assessed by presenting the SERP with the web results and vertical results separately.
In Ponnuswami et al. [9], the assessors are asked to rank the vertical relevance on a scale of 0 to 3, indicating whether it should be shown at BoP, MoP or ToP.
Only one assessor is used.
The di erences between [2] and [9] is that, instead of voting across all verticals, the  general web  retrieved results are used as an anchor to determine the vertical importance.
Work Relevance Dependency In uencing Factors Assessment # Assessors Interdependent Anchor-based Result Quality Orientation Aesthetic Binary Graded Federated Search [12] Zhou et al. [16] Ponnuswami et al. [9] Arguello et al. [2]




















 We are interested in answering three research questions (RQ1 to RQ3).
Given the more formal treatment of the task of aggregated search described in this section, these research questions can be stated as follows:   RQ1 deals with comparing the user perspective ([16] and [9] (binary assessment variant)) during the assessment stage (obtaining ajk).
When asking assessors to make ajk, are there any di erences between the assessments made by only considering orientation (pre-retrieval perspective), and the ones that consider a combination of result quality, orientation and aesthetics (post-retrieval perspective)?
  RQ2 is concerned with comparing the anchor-based approach with an interdependent approach ([9] (binary assessment variant) and [2]) during the collection of all assessments A with respect to vk.
We also examine whether the context of other verticals can a ect the relevance of the vertical of interest.
  RQ3 deals with the positioning of vertical results.
When asking a set of assessors to make assessments ajk using a binary decision (ToP and NS), is it possible to use the fraction of assessors  preference assessments Mt to derive an accurate graded vertical relevance It to indicate the best position for embedding the vertical results (ToP, MoP, BoP and NS)?
This section introduces the methodology for conducting our users studies, followed by a detailed design of each study.
We conducted three studies that follow a similar protocol.
All studies consisted of subjects that pair-wisely assessed the quality of two result sets for a series of search tasks.
All studies have a similar objective, to investigate the correlation between the vertical relevance derived when using one assessment assumption to the vertical relevance derived under another assumption.
Figure 1: Flow Diagram Description of Experimental Protocol for Studies 1 to 3.
The three studies follow a similar protocol shown in Figure 1.
Subjects were given access to an assessment page that consists of a task description, a search task and two search results (tiles), and were asked to make pairwise preference assessments.
Prior to each study, the subjects were presented with a brief instruction, summarizing the experimental protocol and the assessment criteria.
They were told to imagine they were performing a natural information search task.
Given two search result sets originating from two search engines, the subjects were told to select the result set that would best satisfy the search task.
The subjects were then presented with an Assessment Page (ASP) (a screenshot of an ASP is shown in the middle of Figure 2).
The experimental manipulation was controlled via each ASP, as discussed in Section 3.1.3.
Following a search query (e.g.
 living in India ) shown at the top of ASP, the search task description is given in the form of a request for information (e.g.
 Find information about living in India. ).
Under the task description, two search tiles are presented where each tile shows a separate set of search results for the query.
Then the subjects made their selection using a  submit  button.
The subjects (assessors) could choose to perform as many tasks as they wished.
To avoid learning e ects, we ensured that each assessor was not shown the same task more than once.
All studies were performed via a crowd-sourcing platform, Amazon Mechanical Turk3.
The methods employed to collected the data via this platform is described in Section
 o ine.
To lower assessment burden, subjects were unable to browse outside the ASP, i.e. clicking any links within the result page did not redirect them to external web pages.
The snippets on the ASP were the sole source of evidence to assess the SERP quality.
In web search, a vertical is associated with content dedicated to either a topic (e.g.
 nance ), a media type (e.g.
 images ) or a genre (e.g.
 news )4.
In this paper, we are mainly concerned with the latter two types, which is less well-studied than the former.
We use a number of verticals (listed in Table 2).
Those verticals re ect a representative set of vertical engines used in current commercial aggregated web search engines.
Instead of constructing verticals from scratch, we use a representative state-of-the-art vertical search engine for each vertical, as listed in Table 2.
Search tasks were chosen to have a varying number and type of relevant verticals.
From a preliminary study [16, 15], we collected annotations of users  preferred verticals for 320 search tasks (from the TREC million query and web tracks, originally derived from search engine logs).
The preferred verticals re ect the perceived usefulness of a vertical from the user need perspective, without regard to the quality of the vertical results.
This is achieved by instructing assessors to make pairwise preference assessments, comparing each

 https://www.mturk.com A topic-focused vertical may contain documents of various types, standard web pages, images, reviews, etc.
Type media genre Table 2: Verticals Used in this Paper.
Vertical Vertical Engines Document Image Video Recipe News Books Blog Answer Shopping Discussion Google Forums Google Image Google Video Google Recipe Google News Google Books Yahoo!
Blog Google Q&A Google Shopping Scholar Wiki General web Google Scholar wiki.com vertical ltered google.com online images online videos recipe page news articles book review page blog articles answers to questions product shopping page discussion thread from forums research technical report encyclopedic entries standard web pages vertical in turn to the reference  general web  vertical without viewing any vertical results (including the general web).
When making assessments, only vertical names/labels were shown and at least four assessors judged each search task.
We then select 44 tasks from those 320 search tasks.
The selection is to ensure a wide coverage of information needs with di erent preferred verticals, including those with no preferred verticals.
For each of the 11 verticals, we select 3 search tasks where more than 75% of the assessors preferred the vertical.
We also select 11 search tasks where none of the verticals were preferred.
For each task description, to avoid any bias, we ensured that it did not contain any vertical-explicit request (e.g.
 nd images for yoga poses. ).
Twelve representative example tasks (one per preferred vertical) are shown in Table 3.
Although the search task set is not large, it is su cient to investigate certain aspects of vertical relevance, upon which large-scale user studies can subsequently be carried out.
To answer our research questions, each ASP has  ve components that can be manipulated:   search task : the information need (or search task) that assessors encounter;   vertical of interest: the vertical that is presented for assessments;   search result base: the default type of information presented on the SERP for each ASP;   assessment reference: the reference SERP (one of the two result sets on an ASP) against which an assessor will make a preference;   preference option level : the number of options allowed for an assessment (binary or graded) of an ASP.
Search tasks are manipulated to provide a more complete evaluation of AS information needs.
Verticals of interest are manipulated to provide a comprehensive evaluation of various verticals for AS.
Search result base refers to the default type of information provided for assessments and in our study was manipulated for two possible options: search engine description or retrieved search results.
Those two options re ect on di erent in uencing factors for assessments.
The former type re ects on assessors  pre-retrieval user need perspective (orientation) whereas the latter re ects on assessors  post-retrieval user utility perspective (a combination of orientation, result quality and aesthetic).
This relates to RQ1 and a detailed design of this manipulation is described in Study 1.
Assessment reference deals with which information is used as a reference to make the pairwise preference assessments for a vertical.
It is manipulated to investigate whether there is a dependency between (relevant) verticals.
We manipulate this to compare anchor-based approach and interdependent approach for RQ2 and a detailed design of this can be found in Study 2.
Manipulation of the Preference option level provides di erent levels of granularity for assessors to specify their preference based on the quality of two SERPs.
A more  ne-grained option (multi-graded) provides more details than other simple options (binary).
This is manipulated to investigate how much information is lost when assessors are provided with simpler options.
This variable relates to RQ3 and its investigation forms Study 3.
We have  ve independent variables that can be manipulated within an ASP.
However, due to a limited budget, instead of using a full factorial design with all the indepen-
Preferred Vertical Query Table 3: Example Search Tasks.
I am looking for information on the Welch corgi dog.
Find beginners instructions to sewing, both by hand and by machine.
I am looking for cooking suggestions of turkey leftover.
Find music, tour dates, and information about the musician Neil Young.
Find information on the history of music.
Find information about living in India.
Find information on how I can lower my heart rate.
I am looking for sources for parts for cars, preferably used.
Find  reasonable  dieting advice, that is not fads or medications but reasonable methods for weight loss.
Find information on obsessive-compulsive disorder.
Find information about the Sun, the star in our Solar System.
Find the homepage of Ra es Hotel in Singapore.
Image Video Recipe News Books Blog Answer Shopping Discussion welch corgi sewing instructions turkey leftover neil young who invented music living in india lower heart rate used car parts dieting Scholar Wiki General-web Only ocd the sun ra es dent variables, we control four variables when investigating one factor.
We set the four variables to their most common setting, in a typical AS scenario, and study the change in the behaviour of our assessors when the test variable (which we are currently testing) changes.
Except for search task and vertical of interest, the three other independent variables in our study represent the RQs that we wish to answer:   search result base: pre-retrieval user need (by showing only vertical descriptions) or post-retrieval user utility (by showing retrieved vertical results).
  assessment reference:  general web  anchor (showing only  general web ) or all verticals (including both  general web  and all other verticals).
  preference option: binary or multi-graded.
To measure the e ect of the independent variables on users  vertical relevance assessments, we investigate two dependent variables: the inter-assessor agreement (measured by Fleiss  Kappa KF [6]) and the vertical relevance correlation (measured by Spearman correlation).
The inter-assessor agreement focuses on measuring the ambiguity (or di culty) of the vertical relevance assessments.
This can give us insights on whether it is di cult for assessors to draw agreement on assessing vertical relevance.
The vertical relevance correlation measures for two assessment processes, whether one agrees with the other for the search task.
This can give us insights on comparing di erent assessment processes and determining which component of the assessment should be controlled more strictly so that it leads to stronger correlations.
We report the results of these two dependent variables for all of our studies.
As we are mainly interested in measuring assessor agreement over assessed preference pairs, instead of employing metrics (e.g.
overlap measures [14]) to measure inter-assessor agreement on absolute assessments (query-document topical relevance assessment), we used Kappa measure, as preva-lently used in previous work [2].
We select Fleiss  Kappa (denoted KF ) to measures the (chance-corrected) inter-assessor agreement between any pair of assessors over a set of triplets.
This allows us to ignore the identity of the assessor-pair because it is designed to measure agreement over instances labelled by di erent (even disjoint) sets of assessors.
Specifically, when Mt is available, for all the assessments for a particular assessment ajk or a set of assessments (Aj) for all assessors U , we can calculate the Fleiss  Kappa over all pairs.
Therefore, after calculating KF for both assessment processes, we can compare their assessment agreement, to obtain insights into assessment di culty and diversity.
We used Spearman s Correlation as our main tool for our data analysis as it is widely used in IR and it is a powerful statistical method to determine the dependency between two variables of interest (two assessment processes in our work).
Due to space limitation, more in-depth analysis of the data (e.g.
close manual examination) is left for future work.
Our preference assessment data is collected over the Amazon Mechanical Turk crowd-sourcing platform, where each worker was compensated $0.01 for each assessment made.
For each ASP, we collect four assessment points.
Running user studies on Mechanical Turk requires quality control and we used two approaches for achieving this:  trap  HITs and  trap  search tasks.
Both these types of trap are only used to identify careless and/or malicious assessors.
Following [13],  trap  HITs are created following a set procedure.
Each  trap  HIT consists of a triplet (q, i, j), where either page i or j are taken from a query other than q.
We interpreted an assessor preferring the set of extraneous results as evidence of careless assessement.
 Trap  search tasks are de ned as the search task that contains an explicit reference to a preferred vertical (e.g.
 Find information from preferred shopping search results on football tickets ).
An assessor who failed to provide preference to an explicitly speci ed preferred vertical a prede ned number of times was treated as careless assessor.
Careless assessors were  ltered out and all their assessments were discarded.
The actual assessments from the traps were also not used in our analysis.
It is objectively di cult to judge whether one assessor is careless since di erent users might have di erent vertical preferences for the same search task, and the cost associated with di erent types of errors (e.g.
irrelevant verticals, relevant verticals presented at the bottom of the page or bad retrieved results of relevant verticals), as demonstrated by previous work [17, 2].
As we have two di erent  trap  approaches and a large percentage of assessments are  traps 5, we believe that our methodology was able to  lter out large percentage of careless assessors.
Study 1 aims to investigate whether vertical relevance derived from di erent user perspectives correlate with each other.
We controlled the search reference to  general-web  anchor and preference option to binary.
Therefore, we provide a vertical of interest and  general web  together on
 For example, Study 1 (Section 3.2) contains 18.4%  traps  out of all assessments, which means that approximately for every six assessments made, the assessor encountered one  trap .
ence ( left is better  and  right is better ).
To avoid overburdening assessors, we also include an option ( both are bad ) that captures the scenario where a user is confused due to, for example, poor quality of both SERPs.
For the remaining three independent variables search task, vertical of interest and search result base, we used a full factorial design.
We used a total of 44 experimental search tasks that vary in number of preferred verticals, as shown in the upper right in Figure 2.
Eleven verticals of interest are used.
As speci ed above, the search result base variable manipulated the base information for assessments and had two values:  vertical description  and  vertical results .
As shown on the upper left in Figure 2, for  vertical results , the top three items of the vertical search results are returned by the commercial vertical search engine employed.
When making assessments,  vertical results  re ects the post-retrieval user utility for each vertical of interest.
The  vertical description  did not vary across search tasks.
We provided a general description of each vertical that speci ed the item types provided by the vertical and its unique characteristics (e.g.
video results might provide more visually attractive and dynamic results, but may take more e ort to view).
We aimed to provide an objective description of the typical contents of the vertical to avoid any bias.
The vertical relevance assessments derived from  vertical description  re ects a pre-retrieval user need perspective (before retrieving from any verticals, which type of information may satisfy the user needs?
).
Study 1 had 968 unique conditions (44 search tasks   2 search result base   11 verticals of interest).
To ensure the quality of assessments, we manipulated 5  trap  tasks (randomly selected from 11  trap  tasks, one per vertical) and 1  trap  HITs for every search task under each search result base.
We collected four data points for each condition and in total we had 3872 assessments (4744 assessments including all  trap  tasks and HITs).
Study 2 aims to investigate the impact of the context of other verticals to the relevance assessments of a chosen vertical.
Study 2 controlled the preference option to binary and search result base to  vertical results .
For the remaining three independent variables search task, vertical of interest and search reference, Study 2 used a full factorial design.
The search reference had two possible values:  general-web anchor  and  all-verticals , as shown in the lower right of Figure 2.
The former used each vertical of interest with  general web  anchor to form 11 assessment pairs for each search task.
The latter used a full possible space of each vertical of interest and all other verticals (including three  general web  result sets: top-three, top-four-to-six, top-seven-to-ten) to form a total of 91 assessment pairs for each search task.
The assessment pairs of the former is a subset of the latter.
Study 2 had 4004 unique conditions (44 search tasks   91 assessment pairs).
We used the same quality control strategy as for study 1.
In total we had 16016 assessments (19620 assessments including all  trap  tasks and HITs).
Study 3 aims to investigate whether it is possible to derive multi-graded preferences using binary preference from a number of users.
Study 3 controlled the search result base to  vertical results , vertical reference to  general-web anchor .
We use all of the top-ten  general web  results as an anchor in this study.
This is to be consistent with the multi-graded assessments we aim to investigate as described below.
For the remaining three independent variables search task, vertical of interest and preference option, study 2 used a full factorial design.
Speci cally, the preference option is manipulated to be either binary or multi-graded, as shown in the lower left in Figure 2.
Note that this is to compare with the  general web  results.
For the former, assessors were asked for binary assessments (binary preference, i.e. ToP or NS), while for the latter assessors were asked for multi-graded assessments (ToP, MoP, BoP or NS).
Study 2 had 968 unique conditions (44 search tasks   2 preference options   11 verticals) using the same quality control strategy as for study 1.
We obtained 3872 assessments (4744 assessments including  trap  tasks and HITs).
Our goal is to investigate the correlation of vertical relevance when derived from studies with di erent underlying assumptions.
We measure the correlation between two sets of relevance assessments using Spearman s correlation.
In each case, we outline whether this correlation is signi cant6.
We denote the signi cance by N (with p < 0.05).
We report the results that compare user vertical relevance It from di erent perspectives.
Speci cally, whether (1) orientation (pre-retrieval vertical preference) and the (2) topical relevance of post-retrieval search results a ect a user s perception of a vertical relevance.
For (2), following a standard TREC-style evaluation methodology, we collected graded topical relevance assessments (highly, marginally and not relevant) for the top search results returned from the verticals (including  general web ).
Then for each assessment pair (vi, w), we use nDCG(vi)   nDCG(w) to quantify the weighted preference of vi over w based on topical relevance.
We examined the user agreement when assessing the pairwise preference in both a pre-retrieval and post-retrieval scenario.
The Fleiss  Kappa (KF ) obtained for both pre-retrieval and post-retrieval are 0.47 and 0.40, respectively.
In both scenarios, the inter-assessor agreement is not high (moderate).
This indicates the di culty (or ambiguity) of AS in general; di erent users tend to make di erent decisions regarding the relevance of a vertical.
A low KF on a particular query indicates that it is a particularly ambiguous query.
Unexpectedly, we observed that there is even more disagreement between assessors when they are allowed to view the results retrieved from each vertical (on each SERP) (post-retrieval setting).
In that setting, given that the assessors have more information to make their assessments, one would expect more agreement.
However, this is not the case.
A number of reasons may cause this.
Firstly, it should be noted that as we have only four assessors, the di erence in inter-assessor agreement can be substantially a ected by one assessor.
Secondly, and more importantly, it is possible that providing the search results to each assessor increases the di culty and ambiguity of the assessment process.
This may be due to the fact that the user now has to
 We determine the signi cance by using a permutation test.
on a Variety of In uencing Factors (Orientation, Topical Relevance).
Verticals Orientation Topical Relevance Image Video Recipe




 News Books



 Blog Answer



 Shopping Discussion Scholar Wiki















 Average

 take more factors into account when making an assessment (pre-retrieval vertical orientation, item relevance, visual attractiveness).
These factors may lead to more noisy assessments as each assessor may place di erent emphasis on these factors.
We also calculated the Spearman correlation of the inter-assessor agreement (KF ) between the pre-retrieval and post-retrieval assessments.
We found that this correlation is high (0.749), indicating that in both scenarios (pre-retrieval and post-retrieval) the assessors encounter di culty with the same queries.
Furthermore, we report the Spearman correlation of the two in uencing factors (orientation and topical relevance of items) with respect to the post-retrieval vertical relevance for a variety of verticals.
The higher the correlation, the more important the factor is in in uencing the utility of the search results (from the user point of view).
This is shown in Table 4.
We can observe that the average Spearman correlation of orientation (pre-retrieval) and topical relevance with respect to post-retrieval vertical relevance over all verticals is 0.529 (moderate) and 0.356 (low), respectively.
These correlations are not particularly high (but all are signi cant) for both in uencing factors.
Generally, orientation is more highly correlated with the utility of a set of search results than topical relevance.
This demonstrates that neither factor can solely determine the user s perception of the utility of the search results.
In addition, in our data, the type of vertical (orientation) is more important for the search result utility than the topical relevance of the search results.7 When we analyze the orientation of each vertical, we observe that some of the verticals obtain comparatively high correlation ( Video ,  Recipe  and  Shopping ) whereas others obtain comparatively low correlation ( Blog and  Discussion).
This suggests that some verticals are inherently more ambiguous in terms of their usefulness for the search task than others.
For topical relevance, we observe that the topical relevance of retrieved results for the  Image  vertical does not contribute signi cantly to the search results utility.
An in-depth examination showed that this can be explained by the lack of variability of the topical relevance.
We observe that most returned image results are topically relevant.
Conversely, the topical relevance of the items of other verticals ( Blog ,  Discussion ) contributes a larger degree to the utility of a SERP.
This is because for those verticals, the results are too similar to  general web  results and in this case, topical relevance is the most important aspect for search utility (as in traditional web search).
For  Recipe , topical relevance correlates highly both with orientation and search utility.
This is because  Recipe  is more likely to contain relevant results only when user are oriented to that vertical.
Note that due to our selection of vertical search engines (highly performing verticals) where most vertical search results contain topically relevant items for most of the search tasks, our results are biased to this scenario and might not generalize when vertical search engines perform badly.
Table 5: Overlap of the Top-three Relevant Verticals for Pre-retrieval (Orientation) and Post-retrieval (Search Uutility) for the same Search Tasks.
Overlap Num of Tasks Fraction











 Thirdly, as we are more concerned with highly relevant verticals, we investigate whether the top relevant verticals are the same for pre- and post-retrieval scenarios.
We extract the top-three most preferred verticals from both assessment scenarios and compare them.
We calculate the overlap between them and the results are shown in Table 5.
There is generally some overlap between vertical relevance for around 90% of the queries.
In addition, in 56.8% of the search tasks at least two out of three relevant verticals are in common, when relevance is derived from the di erent assessment methods (pre- and post-retrieval assessments).
Finally, we investigate whether there is an aesthetic bias for verticals that present more visually salient results ( Image , Video  and Shopping  in our study).
We compare the number of occurrences of those verticals that appear within the top-three verticals for various search tasks.
Consistent with previous work, we found there is an aesthetic bias in user s perception of the utility of the search results.
There are in total 21 occurrences of those verticals appearing within the top-three verticals for all search tasks in the post-retrieval case, compared with 11 occurrences within the pre-retrieval case.
To summarize, Study 1 shows that both orientation and topical relevance contribute signi cantly to the search result utility, whereas the impact of orientation is more important.
In addition, there is an aesthetic bias to user s perception of the search results utility.
In Study 2, we manipulated the assessment reference for each vertical of interest.
Again, the reference is manipulated by presenting only general-web anchor results (anchor-based approach) in one approach and all vertical results (interdependent approach) in a separate approach.
To derive It using assessments Mt obtained for each search task, we used an existing approach.
For the anchor-based approach, we ranked all the verticals of interest based on the percentage of assessors  preference over  general web  anchor.
For the interdependent approach, we used Schulze voting method [2].
We report the results comparing user s vertical relevance It from both the anchor-based approach and the interdependent approach.
For the former, we vary the quality of the  general web  anchor by using di erent result sets (Web-
items).
We aim to investigate whether there are signi cant di erences between them.
tical Relevance Derived between Anchor-based Approach (using anchors Web-1, Web-2, Web-3) and Interdependent Approach.
Anchor Correlation Web-1 Web-2 Web-3





 Average
 Table 7: Overlap of the Top-three Relevant Vertical for the Anchor-based Approach (Web-1) and the Interdependent Approach on same Search Tasks.
Overlap Num of Tasks Fraction











 We look at the user assessment agreement.
The Fleiss  Kappa (KF ) obtained for the anchor-based and interdependent approaches are 0.40 and 0.42, respectively.
The user assessment agreement is not high (moderate) and, generally, there is not much di erence between the assessment agreement of the two approaches.
The slight increase of user agreement for assessments in the interdependent approach might be due to the comparative ease in assessing some vertical-pairs, over assessing vertical-anchor-pairs.
We show the query-speci c Spearman correlation of the anchor-approach using di erent anchors (Web-1, Web-2, Web-
are shown in Table 6.
We can observe several important trends.
Firstly, the correlation between the anchor-based and interdependent approaches is moderate.
From closer examination, we see many  exchange  between verticals of similar intended level and most of these  exchanges  occur within lowly vertical relevance level.
As we are more concerned with highly intended verticals, similarly to Study 1, we report the overlapped top relevant vertical between the two approaches in Table 7.
Generally the overlap of the top-three relevant verticals between these two approaches is quite high (more than 70% of the search tasks have the same perception of at least two out of three relevant verticals).
We observe that although there are di erences between the approaches that use di erent anchors, the di erences are not large in general (all moderate correlations).
Web-
there is not much di erences between Web-2 and Web-3.
This is quite surprising.
We assumed that the change of topical relevance level of the anchor results8 would result in a change of a user s perception of the results utility.
However as this is not the case, we suspect that this can be explained by the  nding in Study 1, where when presented with a  general web  anchor, it is the type of information that leads to a more signi cant impact on the quality of the result set, indeed more so than topical relevance.
Finally, to demonstrate the interaction between verticals, an analysis of the di erence between the interdependent ranking and anchor-based (Web-1) ranking suggests that context matters, i.e. the relevance of the latter vertical diminishes when the former vertical (context) is shown in advance.
We analyse this by  nding the most frequent discordant pairs of verticals (vi, vj ) within the two approaches.
All the candidate pairs consist of verticals of interest occurring within the top verticals for at least one approach.
We found that most pairs are concordant with each other but there are about 14% of discordant pairs.
Speci cally, there are several distinct discordant pairs that consistently occur for di erent number of top results (3 to 6).
These pairs are ( Answer  ,  Wiki  ), ( Books ,  Scholar  ), ( Answer  ,  Scholar  ).
For ex-
We found that the averaged nDCG values satisfy nDCG(W eb-ample, ( Answer  ,  Wiki  ) pair means that when  Answer   is presented before  Wiki  , the relevance of  Wiki   is diminished.
This might be explained by the fact that once a direct answer is available, reading a long wiki article will provide less utility to the user.
These results demonstrate that the context of other verticals can diminish the utility of a vertical.
This  nding requires further examination.
We investigate how various thresholding approaches can be used to accurately derive multi-graded vertical relevance for the anchor-based approaches.
We also apply this to the Schulze voting method for the interdependent approach [2].
For each search task, based on the multi-graded assessments for each vertical vi (assessed by four independent assessors), we  rst derive the ground-truth of the  perfect  embedding position9 (and corresponding  perfect  page).
To achieve this, we assume that there is a continuous range for each grade ([3, 4] for ToP, [2, 3) for MoP, [1, 2) for BoP and [0, 1) for NS).
We assign each grade the medium of its corresponding range as its weight (3.5 for ToP, 2.5 for MoP,
 grade, we decide the  perfect  position by calculating the expected assessed grade s weight and  nding its corresponding  tted grade range.10 For the anchor-based approaches, we use a set of thresh-olding settings (for binary assessment, this is the fraction of assessors that deem the vertical as relevant) for ToP, MoP, BoP, respectively.
For a given vertical, when the fraction of its assessors  assigned  relevant  is larger or equal to the weight assigned for a given grade, we treat that vertical as that speci c grade.
We vary those thresholding settings for di erent risk-levels: risk-seeking (0.5, 0.25, 0), risk-medium (0.75, 0.5, 0.25) and risk-averse (1, 0.75, 0.5).
As described above, we also use another existing approach (Schulze voting method [2]) for the interdependent approach.
Firstly, we look at the user assessment agreement.
The Fleiss  Kappa (KF ) obtained for binary and multi-graded approaches are 0.40 and 0.35, respectively.
The agreement of multi-graded assessments is not high.11 From a closer examination, we found that this might result from each assessors  unique preference of verticals and their risk-level [18] (i.e. their willingness to take risk to view more irrelevant verticals).
Some of the assessors tend to choose more verticals to be shown at earlier ranking (e.g.
ToP, BoP) while oth-
as the number of assessment grades changes.
Note that this KF agreement is not directly comparable to others
 Note that this  perfectness  of embedding position and page is likely to be sub-optimal.
This is because the multi-grade assessment methodology does not capture the context of other verticals.
For example, when two, one, one and zero assessors assign ToP, MoP, BoP and NS, respectively, we obtain the expected weight of grade (2   3.5 + 1   2.5 + 1   1.5 + 0)/4 = 2.75) and therefore its  perfect  embedding position is MoP (as 2.75   [2, 3)).
timal Pages derived from Binary Assessments and Ground-truth Page derived from Multi-grade Assessments, and Precision (for each grade ToP, MoP and BoP).
Binary Approach Correlation prec(ToP) prec(MoP) prec(BoP) risk-seeking risk-medium








 risk-averse




 Schulze voting




 ers are more careful and select verticals to be shown on the SERP only when they have a high degree of con dence.
Secondly, for each approach used to derive vertical relevance from binary assessment, we obtain its corresponding optimal page (with  general web  results Web-1, Web-
the Spearman correlation of this page with the ground-truth page derived from the multi-grade assessments.
The results are shown in Table 8.
As we are concerned with how each binary approach can be used to derive accurate multi-graded assessment, we also calculate the precision of each binary approach with respect to the multi-grade ground-truth.
We notice several important trends.
Firstly, most of the binary approaches (risk-medium, risk-averse and Schulze voting) are all signi cantly correlated with the multi-graded ground-truth.
However, the correlations are mostly moderate.
It is not surprising that Schulze voting method performs the best, as it uses more assessments (91 assessments) compared with other binary approaches (11 assessments) as well as being more robust to noise.
It is also interesting to observe that the risk-medium approach performed second best, which is consistent with our observation that di erent assessors have di erent risk-levels.
An extreme approach (risk-seeking or risk-averse) is more likely to satisfy only a small subset of assessors while frustrating others.
Secondly, when focusing on the precision of each approach for each grade (ToP, MoP and BoP), we can observe that generally, risk-averse performs best, followed by Schulze voting, risk-medium and risk-seeking approaches.
This is because the risk-averse approach is more careful when selecting verticals; it only selects verticals (as relevant) when highly con dent (large fraction of user s preferences) of this.
Our objective was to investigate whether di erent underlying assumptions made for vertical relevance a ects a user s perception of the relevance of verticals.
Our results indicate that relevant verticals derived from di erent assumptions do correlate with each other.
However, the correlation is not high (either moderate or low in many cases) as each assumption focuses on di erent aspects of vertical relevance.
With respect to RQ1, both orientation (pre-retrieval user need) and topical relevance (post-retrieval topical relevance) correlates signi cantly with the post-retrieval search results utility.
The impact of orientation is comparatively more significant (moderate) than topical relevance (low).
In addition, there is an aesthetic bias to a user s perception of search results utility.
With respect to RQ2, we conclude that the context of other verticals has signi cant impact on the relevance of a vertical.
With respect to RQ3, we found that it is possible to employ a number of binary assessments to predict multi-grade assessments and the correlation of the derived optimal pages is signi cant (moderate).
Using a larger number of assessments (e.g.
Schulze voting) contributes to more accurate estimation of multi-grade assessments.
Our results have important implications for aggregated search and in general, evaluation in IR.
The moderate correlation between di erent vertical assessments indicates the need to reevaluate previous work on vertical selection, based on the assessments (and corresponding assumptions) used.
The conclusion drawn from one type of assessments (e.g.
VS approach A performed better than B) might not hold for another type of assessments.
Researchers need to be careful when drawing conclusions regarding vertical relevance.
Our results have implications for work in vertical selection.
As discovered in Study 1, orientation has a larger impact on user s perception of the search results utility than topical relevance, which implies that vertical evidence derived from the user need perspective (e.g.
query logs) might be more e ective at predicting a user s relevant verticals than collection-based estimation (e.g.
traditional resource selection methods).
In addition, Study 1 implies that for some verticals (e.g.
Video , Recipe  and  Shopping ), the VS system generally would have more con dence in returning them as relevant (due to their orientation).
On the contrary, the VS system should be more careful when returning other verticals (e.g.
 Blog  and  Discussion  results).
We are not saying that some verticals ( Video ) are more useful than others ( Blog  and  Discussion ); we note that it is easier to predict the usefulness of some verticals for an  average  query.
Our results have implications with respect to procuring assessments for aggregated search.
In Study 2, we showed that fewer binary assessments (anchor-based approach) correlate moderately with more binary assessments (interdependent approach).
In Study 3, we showed that moderately correlated multi-graded relevance assessments can be obtained by using a number of binary assessments.
As di erent assessment methodologies involve di ering amounts of e ort (number of assessments, information load when assessing), there is a need for analyzing both the utility and e ort involved in di erent assessment methodologies so that assessments can be obtained in a more e cient way.
In addition, by exploring verticals on aggregated search pages, binary preference of vertical over web results can be ob-tained/derived by mining query logs [9].
Plans for future work include the following: Firstly, although we have shown that topical relevance has signi cant impact on user s perception of search results utility, we have not explored how this impact changes according to the different levels of topical relevance, and how it interacts with orientation.
Similarly, a comprehensive analysis on aesthetic bias is also needed.
Secondly, at the moment we assume a blended presentation strategy, i.e.
interleaving vertical results into the web results (ToP, MoP, BoP and NS).
Other ways of combining results are possible, for example showing blocks of results on the right side of the page.
Finally, the assessments have been obtained by showing only vertical search result snippets to the users, without presenting the actual information items.
As the assessment depends solely on snippet, we should examined the impact of this further.
Acknowledgments This work was partially supported by the EU LiMoSINe project (288024).
