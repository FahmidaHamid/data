In recent years, we have experienced the rise of large knowledge bases (KBs), such as Cyc [23], YAGO [35], DB-pedia [5], and Freebase1.
These KBs provide information about a great variety of entities, such as people, countries, rivers, cities, universities, movies, animals, etc.
Moreover, KBs also contain facts relating these entities, e.g., who was born where, which actor acted in which movie, or which city is located in which country.
Today s KBs contain millions of entities and hundreds of millions of facts.
Yet, even these large KBs are not complete.
Some of them are extracted from natural language resources that 1http://freebase.com Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
inevitably exhibit gaps.
Others are created and extended manually.
Making these KBs complete requires great e ort to extract facts, check them for correctness, and add them to the KB.
However, KBs themselves often already contain enough information to derive and add new facts.
If, for instance, a KB contains the fact that a child has a mother, then the mother s husband is most likely the father: motherOf (m, c)   marriedTo(m, f )   fatherOf (f, c) As for any rule, there can be exceptions, but in the vast majority of cases, the rule will hold.
Finding such rules can serve four purposes: First, by applying such rules on the data, new facts can be derived that make the KB more complete.
Second, such rules can identify potential errors in the knowledge base.
If, for instance, the KB contains the statement that a totally unrelated person is the father of a child, then maybe this statement is wrong.
Third, the rules can be used for reasoning.
Many reasoning approaches rely on other parties to provide rules (e.g., [27, 31]).
Last, rules describing general regularities can help us understand the data better.
We can, e.g.,  nd out that countries often trade with countries speaking the same language, that marriage is a symmetric relationship, that musicians who in uence each other often play the same instrument, and so on.
The goal of this paper is to mine such rules from KBs.
We focus on RDF-style KBs in the spirit of the Semantic Web, such as YAGO [35], Freebase1, and DBpedia [5].
These KBs provide binary relationships in the form of RDF triples2.
Since RDF has only positive inference rules, these KBs contain only positive statements and no negations.
Furthermore, they operate under the Open World Assumption (OWA).
Under the OWA, a statement that is not contained in the KB is not necessarily false; it is just unknown.
This is a crucial di erence to many standard database settings that operate under the Closed World Assumption (CWA).
Consider an example KB that does not contain the information that a particular person is married.
Under CWA we can conclude that the person is not married.
Under OWA, however, the person could be either married or single.
Mining rules from a given dataset is a problem that has a long history.
It has been studied in the context of association rule mining and inductive logic programming (ILP).
Association rule mining [3] is well-known in the context of sales databases.
It can  nd rules such as  If a client bought beer and wine, then he also bought aspirin .
The con dence of such a rule is the ratio of cases where beer and wine was actually bought together with aspirin.
Association rule mining inherently implements a closed world assumption: A rule
 413that predicts new items that are not in the database has a low con dence.
It cannot be used to (and is not intended to be used to) add new items to the database.
ILP approaches deduce logical rules from ground facts.
Yet, current ILP systems cannot be applied to semantic KBs for two reasons: First, they usually require negative statements as counterexamples.
Semantic KBs, however, usually do not contain negative statements.
The semantics of RDF are too weak to deduce negative evidence from the facts in a KB.3 Because of the OWA, absent statements cannot serve as counter-evidence either.
Second, today s ILP systems are slow and cannot handle the huge amount of data that KBs provide.
In our experiments, we ran state-of-the-art approaches on YAGO2 for a couple of days without obtaining any results.
In this paper, we propose a rule mining system that is inherently designed to work under the OWA, and e cient enough to handle the size of today s KBs.
More precisely, our contributions are as follows: (1) A method to simulate negative examples for positive KBs (the Partial Completeness Assumption) (2) An algorithm for the e cient mining of rules.
(3) A system, AMIE, that mines rules on millions of facts in a few minutes without the need for parameter tuning or expert input.
The rest of this paper is structured as follows.
Section 2 discusses related work and Section 3 introduces preliminaries.
Sections 4 and 5 are the main part of the paper, presenting our mining model and its implementation.
Section 6 presents our experiments before Section 7 concludes.
We aim to mine rules of the form motherOf (m, c)   marriedTo(m, f )   fatherOf (f, c) Technically, these are Horn rules on binary predicates.
Rule mining has been an area of active research for the past couple of years.
Some approaches mine association rules, some mine logical rules, others mine a schema for the KB, and again others use rule mining for application purposes.
Association Rule Mining.
Association rules [3] are mined on a list of transactions.
A transaction is a set of items.
For example, in the context of sales analysis, a transaction is the set of products bought together by a customer in a speci c event.
The mined rules are of the form {ElvisCD, Elvis-Book}   ElvisCostume, meaning that people who bought an Elvis CD and an Elvis book usually also bought an Elvis costume.
However, these are not the kind of rules that we aim to mine in this paper.
We aim to mine Horn rules.
One problem for association rule mining is that for some applications the standard measurements for support and con dence do not produce good results.
[36] discusses a number of alternatives to measure the interestingness of a rule in general.
Our approach is inspired by this work and we also make use of a language bias [2] to reduce the search space.
Logical Rule Mining.
Sherlock [32] is an unsupervised ILP method to learn  rst-order Horn clauses from a set of extracted facts for a given target relation.
It uses probabilistic graphical models (PGMs) to infer new facts.
It tackles the noise of the extracted facts by extensive  ltering in a preprocessing step and by penalizing longer rules in the inference part.
For mining the rules, Sherlock uses 2 heuristics: statistical signi cance and statistical relevance.
The WARMR system [11, 12] mines patterns in databases that correspond to conjunctive queries.
It uses a declarative language bias to reduce the search space.
An extension of the system, WARMER [13], modi ed the approach to support a broader range of conjunctive queries and increase e ciency of search space exploration.
ALEPH4 is a general purpose ILP system, which implements Muggleton s Inverse Entailment algorithm [25] in Pro-log.
It employs a variety of evaluation functions for the rules, and a variety of search strategies.
These approaches are not tailored to deal with large KBs under the Open World Assumption.
We compare our system, AMIE, to WARMR and ALEPH, which are the only ones available for download.
Our experiments do not only show that these systems mine less sensible rules than AMIE, but also that it takes them much longer to do so.
Expert Rule Mining.
Another rule mining approach over RDF data [28] was proposed to discover causal relations in RDF-based medical data.
It requires a domain expert who de nes targets and contexts of the mining process, so that the correct transactions are generated.
Our approach, in contrast, does not rely on the user to de ne any context or target.
It works out-of-the-box.
Generating Schemas.
In this paper, we aim to generate Horn rules on a KB.
Other approaches use rule mining to generate the schema or taxonomy of a KB.
[7] applies clustering techniques based on context vectors and formal concept analysis to construct taxonomies.
Other approaches use clustering [21] and ILP-based approaches [9].
For the friend-of-a-friend network on the Semantic Web, [14] applies clustering to identify classes of people and ILP to learn descriptions of these groups.
Another example of an ILP-based approach is the DL-Learner [19], which has successfully been applied [15] to generate OWL class expressions from YAGO [35].
As an alternative to ILP techniques, [37] propose a statistical method that does not require negative examples.
In contrast to our approach, these techniques aim at generating a schema for a given RDF repository, not logical rules in general.
Learning Rules From Hybrid Sources.
[8] proposes to learn association rules from hybrid sources (RDBMS and Ontologies) under the OWA.
For this purpose, the de ni-tion of frequency (and thus of support and con dence) is changed so that unknown statements contribute with half of the weight of the true statements.
Another approach [20] makes use of an ontology and a constraint Datalog program.
The goal is to learn association rules at di erent levels of granularity w.r.t.
the type hierarchy of the ontology.
While these approaches focus more on the bene ts of combining hybrid sources, our approach focuses on pure RDFS KBs.
Further Applications of Rule Mining.
[17] proposes an algorithm for frequent pattern mining in KBs that use DL-safe rules.
Such KBs can be transformed into a disjunctive Datalog program, which allows seeing patterns as queries.
This approach does not mine the Horn rules that we aim at.
Some approaches use rule mining for ontology merging and alignment [10, 24, 30].
The AROMA system [10], e.g.,
 or similar concepts.
4http://www.cs.ox.ac.uk/activities/machlearn/ Aleph/aleph_toc.html 414uses association rules on extracted terms to  nd subsump- tion relations between classes and properties of di erent on-tologies.
Again, these systems do not mine the kind of rules we are interested in.
In [1] association rules and frequency analysis are used to identify and classify common misusage patterns for relations in DBpedia.
In contrast to our work, this approach does not mine logical rules, but association rules on the co-occurrence of values.
Since RDF data can be seen as a graph, mining frequent subtrees [6, 18] is another related  eld of research.
However, as the URIs of resources in knowledge bases are unique, these techniques are limited to mining frequent combinations of classes.
Several approaches, such as Markov Logic [31] or URDF [27] use Horn rules to perform reasoning.
These approaches can be consumers of the rules we mine with AMIE.
RDF KBs.
In this paper, we focus on RDF knowledge bases5.
An RDF KB can be considered a set of facts, where each fact is a triple of the form (cid:104)x, r, y(cid:105) with x denoting the subject, r the relation (or predicate), and y the object of the fact.
There are several equivalent alternative representations of facts; in this paper we use a logical notation and represent a fact as r(x, y).
For example, we write father(Elvis,Lisa).
The facts of an RDF KB can usually be divided into an A-Box and a T-Box.
While the A-Box contains instance data, the T-Box is the subset of facts that de ne classes, domains, ranges for predicates, and the class hierarchy.
Although T-Box information can also be used by our mining approach, we are mainly concerned with the A-Box, i.e., the set of facts relating one particular entity to another.
In the following, we assume a given KB K as input.
Let R =  relation(K) denote the set of relations contained in K and E =  subject(K)    object(K) the set of entities.
Functions.
A function is a relation r that has at most one object for every subject, i.e.,  x : |{y : r(x, y)}|   1.
A relation is an inverse function if each of its objects has at most one subject.
Since RDF KBs are usually noisy, even relations that should be functions (such as hasBirthdate) may exhibit two objects for the same subject.
Therefore, we use the notion of functionality [33].
The functionality of a relation r is a value between 0 and 1, that is 1 if r is a function: f un(r) := #x :  y : r(x, y) #(x, y) : r(x, y) with #x : X as an abbreviation for |{x : X   K}|.
The inverse functionality is de ned accordingly as if un(r) := f un(r 1).
Without loss of generality, we assume that  r   R : f un(r)   if un(r) (FUN-Property).
If that is not the case for a relation r, we can replace all facts r(x, y) with the inverse relation, r (y, x), which entails f un(r )   if un(r ).
For example, if the KB contains the inverse functional relation directed(person,movie), we can create the functional relation isDirectedBy(movie,person) and use only that one in the rule mining process.
Manual inspection shows, however, that relations in semantic KBs tend to be more functional than inverse functional.
Intuitively, this allows us to consider a fact r(x, y) as a fact about x.
Rules.
An atom is a fact that can have variables at the subject and/or object position.
A (Horn) rule consists of a head and a body, where the head is a single atom and the body is a set of atoms.
We denote a rule with head r(x, y) and body {B1, ..., Bn} by an implication B1   B2   ...   Bn   r(x, y) which we abbreviate as (cid:126)B   r(x, y).
One example of such a rule is hasChild (p, c)   isCitizenOf (p, s)   isCitizenOf (c, s) An instantiation of a rule is a copy of the rule, where all variables have been substituted by entities.
A prediction of a rule is the head atom of an instantiated rule if all body atoms of the instantiated rule appear in the KB.
For example, the above rule can predict isCitizenOf(Lisa,USA) if the KB knows a parent of Lisa (hasChild(Elvis,Lisa)) who is American (isCitizenOf(Elvis,USA)).
Language Bias.
As most ILP systems, AMIE uses a language bias to restrict the search space.
We say that two atoms in a rule are connected if they share a variable or an entity.
A rule is connected if every atom is connected transitively to every other atom of the rule.
AMIE mines only connected rules, i.e., it avoids constructing rules that contain unrelated atoms.
We say that a rule is closed if every variable in the rule appears at least twice.
Such rules do not predict merely the existence of a fact (e.g.
diedIn(x, y)    z : wasBornIn(x, z)), but also concrete arguments for it (e.g.
diedIn(x, y)   wasBornIn(x, y)).
AMIE mines only closed rules.
We allow recursive rules that contain the head relation in the body.
Parallels to Association Rule Mining.
Association Rule Mining discovers correlations in shopping transactions.
Thus, association rules are di erent in nature from the Horn rules we aim at.
Still, we can show some similarities between the two approaches.
Let us de ne one transaction for every set of n entities that are connected in the KB.
For example, in Figure 1, we will de ne a transaction for the entities Elvis, Lisa and Priscilla, because they are connected through the facts mother(Priscilla,Lisa), father(Elvis,Lisa), marr(Elvis, Priscilla).
We label the transaction with the set of these entities.
Each atom r(xi, xj) on variables indexed by 1   i, j   n corresponds to an item.
A transaction with label (cid:104)C1, .
.
.
, Cn(cid:105) contains an item r(xi, xj) if r(Ci, Cj) is in the KB.
For example, the transaction (cid:104)Elvis, Lisa, Priscilla(cid:105) contains the items {mother(x3,x2), father(x1,x2), marr(x1,x3)}, since the ground atoms mother(Priscilla,Lisa), father(Elvis,Lisa) and marr(Elvis, Priscilla) are in the KB.
In this representation, association rules are Horn rules.
In the example, we can mine the association rule {mother(x3, x2), marr(x1, x3)}   {f ather(x1, x2)} which corresponds to the Horn rule mother(x3, x2)   marr(x1, x3)   f ather(x1, x2) Transaction Label (cid:104)Elvis,Lisa,Priscilla(cid:105) (cid:104)Barack,Mali,Mich.
(cid:105) (cid:104)Fran cois,Flora,S ego(cid:105) Transaction Items {mother(x3,x2),father(x1,x2),marr(x1,x3)} {mother(x3,x2),father(x1,x2),marr(x1,x3)} {mother(x3,x2),father(x1,x2)} Figure 1: Mining Rules with 3 Variables Constructing such a table with all possible combinations of entities is practically not very viable.
Apart from that, 415it faces a number of design issues (e.g., how to deal with transactions that contain the same entities in di erent orderings).
Therefore, association rule mining cannot be used directly to mine Horn rules.
However, we take inspiration from the parallels between the two types of mining for our system, AMIE.
Model.
Let us consider a given Horn rule (cid:126)B   r(x, y).
Let us look at all facts with relation r (Figure 2).
We distinguish
 true), true facts that are unknown to the KB (NEWtrue), facts that are known to be false in the KB (KBfalse), and facts that are false but unknown to the KB (NEWfalse).
The rule will make certain predictions (blue circle).
These predictions can be known to be true (A), known to be false (C), or unknown (B and D).
When they are unknown to the KB, they can still be true (B) or false (D) with respect to the real world.
KBtrue



 NEWtrue Predictions true false KBfalse known to KB NEWfalse unknown to KB Figure 2: Prediction under Incompleteness Goal.
Our goal is to  nd rules that make true predictions that go beyond the current KB.
In the  gure, we wish maximize the area B, and to minimize the area D. There are two obvious challenges in our context: First, the areas NEWtrue and NEWfalse are unknown.
So if we wish to maximize B at the expense of D, we are operating in an area outside our KB.
We would want to use the areas KBtrue and KBfalse to estimate the unknown area.
This, however, leads to the second challenge: Semantic KBs do not contain negative evidence.
Thus, the area KBfalse is empty.
We will now present di erent measures that address these challenges.
Support.
The support of a rule quanti es the number of correct predictions, i.e., the size of A.
There are several ways to de ne the support: It can be the number of instantiations of the rule that appear in the KB.
This is what our analogy to association rule mining [3] suggests (Section 3).
This measure, however, is not monotonic if we add atoms to the body.
Consider, for example, the rule marriedTo( x, y)   marriedTo( y, x) If we add hasGender(x,male) to the body, the number of instantiations that are in the KB decreases.
If we add an atom with a fresh variable, e.g., hasFriend(x,z), to the body, the number of instantiations increases for every friend of x.
This is true even if we add another atom with z to make the rule closed.
Alternatively, we can count the number of facts in one particular body atom.
This de nition, however, depends on the choice of the body atom, so that the same rule can have di erent supports.
We can also count the number of facts of the head atom.
This measure decreases monotonically if more body atoms are added and avoids equivalent rules with di erent support values.
With this in mind, we de ne the support of a rule as the number of distinct pairs of subjects and objects in the head of all instantiations that appear in the KB: supp( (cid:126)B   r(x, y)) := #(x, y) :  z1, ..., zm : (cid:126)B   r(x, y) where z1, ..., zm are the variables of the rule apart from x and y.
Head Coverage.
Support is an absolute number.
This means that a user who thresholds on support has to know the absolute size of the KB to give meaningful values.
To avoid this, we also de ne a proportional version of support.
A naive way would be to use the absolute number of support, as de ned in the previous paragraph, over the size of the KB.
In this case, however, relations that do not have many facts (either because of the incompleteness of the KB or because of their nature), will not be considered in the head of rules, i.e.
we will not learn rules predicting such relations.
Therefore, we propose to use the notion of head coverage.
This is the proportion of pairs from the head relation that are covered by the predictions of the rule hc( (cid:126)B   r(x, y)) := supp( (cid:126)B   r(x, y)) #(x(cid:48), y(cid:48)) : r(x(cid:48), y(cid:48)) Negative Examples.
The central challenge of our setting is to provide counterexamples for the rule mining.
These can take the role of KBfalse, so that we can estimate the areas NEWtrue and NEWfalse.
There are several approaches to this problem: The standard con dence, the standard positive-only learning evaluation score of ILP, and our new partial completeness assumption.
Standard Con dence.
The standard con dence measure takes all facts that are not in the KB (i.e., NEWtrue and NEWfalse) as negative evidence.
Thus, the standard con -dence of a rule is the ratio of its predictions that are in the KB, i.e., the share of A in the set of predictions: supp( (cid:126)B   r(x, y)) conf ( (cid:126)B   r(x, y)) := #(x, y) :  z1, ..., zm : (cid:126)B The standard con dence is blind to the distinction between  false  and  unknown .
Thus, it implements a closed world setting.
It mainly describes the known data and penalizes rules that make a large number of predictions in the unknown region.
We, in contrast, aim to maximize the number of true predictions that go beyond the current knowledge.
We do not want to describe data, but to predict data.
Positive-Only Learning.
For cases where the KB does not contain negative examples, Muggleton has developed a positive-only learning evaluation score for ILP [26], [22].
It takes random facts as negative evidence: Score = log(P )   log
 Rsize + 2

 Here, P is the number of known true facts covered (A in the  gure), R is the number of randoms covered, Rsize is the total number of randoms and L is the number of atoms in the hypothesis.
The intuition is that a good rule should cover many positive examples, and few or no randomly generated examples.
This ensures that the rule is not overly general.
Furthermore, the rule should use as few atoms as possible, and thus achieve a high compression.
This measure is implemented (among others) in the ALEPH system.
evidence by the partial completeness assumption (PCA).
This is the assumption that if r(x, y)   KBtrue for some x, y, then  y )   KBtrue   NEWtrue   r(x, y )   KBtrue : r(x, y (cid:48) (cid:48) (cid:48) In other words, we assume that if the database knows some r-attribute of x, then it knows all r-attributes of x.
This assumption is certainly true for functional relations r, such as birth dates, capitals, etc.
Thanks to the FUN-Property (see Section 4), it is also true for inverse-functional relations, such as owns, created, etc.
The assumption is also true in the vast majority of cases for relations that are not functional, but that have a high functionality.
Even for other relations, the PCA is still reasonable for knowledge bases that have been extracted from a single source (such as DBpedia and YAGO).
These usually contain either all r-values or none for a given entity.
PCA Con dence.
Under the PCA, we normalize the con dence not by the entire set of facts, but by the set of facts of which we know that they are true, together with the facts of which we assume that they are false.
If the head atom of the rule is r(x, y), then this set is just the set of facts {r(x, y(cid:48)) : r(x, y(cid:48))   K}.
Thanks to the FUN-Property, the PCA is always applied to the  rst argument of the head atom: pcaconf ( (cid:126)B   r(x, y)) := supp( (cid:126)B   r(x, y)) #(x, y) :  z1, ..., zm, y(cid:48) : (cid:126)B   r(x, y(cid:48)) We show in our experiments that the PCA con dence iden-ti es much more productive rules than the other measures.
After having outlined the basic de nitions and the mining model in Sections 3 and 4, we now outline the core algorithm of our framework and its implementation.
Goal.
Our goal is to mine rules of the form de ned in Section 3.
One of the main problems of any mining approach is to  nd an e cient way to explore the search space.
The naive algorithm of enumerating all possible rules is infeasi-ble for large KBs.
Hence, we explore the search space by iteratively extending rules by mining operators.
Mining Operators.
We see a rule as a sequence of atoms.
The  rst atom is the head atom and the others are the body atoms.
In the process of traversing the search space, we can extend a rule by using one of the following operators:
 This operator adds a new atom to a rule.
The new atom uses a fresh variable for one of its two arguments.
The other argument (variable or entity) is shared with the rule, i.e., it occurs in some other atom of the rule.
This operator adds a new atom to a rule that uses an entity for one argument and shares the other argument (variable or entity) with the rule.
This operator adds a new atom to a rule so that both of its arguments are shared with the rule.
By repeated application of these operators, we can generate the entire space of rules as de ned in Section 3.
The operators generate even more rules than those we are interested in, because they also produce rules that are not closed.
An alternative set of operators could consist of OD and an operator for instantiation.
But these operators would not be monotonic, in the sense that an atom generated by one operator can be modi ed in the next step by the other operator.
Therefore, we chose the above 3 operators as a canonic set.
Algorithm.
We mine rules with Algorithm 1.
The algorithm maintains a queue of rules, which initially just contains the empty rule.
The algorithm iteratively dequeues a rule from the queue.
If the rule is closed (see Section 3), the rule is output, otherwise, it is not.
Then, the algorithm applies all operators to the rule and adds the resulting rules to the queue (unless they are pruned out, s.b.).
This process is repeated until the queue is empty.
We parallelize this process by maintaining a centralized queue, from which the threads dequeue and enqueue.
We do not feed predictions of the rules back into the KB.
All measures (such as con dence and support) are always computed on the original KB.
Output r q = (cid:104)[](cid:105) Execute in parallel: while  q.isEmpty() do Algorithm 1 Rule Mining













 end for

 end while 17: end function end for end if end if for all operators o do q.enqueue(r(cid:48)) r = q.dequeue() if r is closed   r is not pruned for output then for all rules r(cid:48)   o(r) do if r(cid:48) is not pruned then Pruning.
If executed naively, our algorithm will have prohibitively high run-times.
The instantiation operator OI , in particular, generates atoms in the order of |R|   |E|.
We  rst observe that we are usually not interested in rules that cover only very few facts of the head relation.
Rules that cover, for example, less than 1% of the facts of the head relation can safely assumed to be marginal.
Therefore, we set   = 0.01 as a lower bound for the head coverage.
We observe that head coverage decreases monotonically as we add more atoms.
This allows us to safely discard any rule that trespasses the threshold (Lines 11 and 12).
The monotonicity of head coverage gives us another opportunity to prune: If a rule B1   ...  Bn   Bn+1   H does not have larger con dence than the rule B1   ...   Bn   H, then we do not output the longer rule.
This is because both the con dence and the head coverage of the longer rule are necessarily dominated by the shorter rule.
This way, we can reduce the number of produced rules (Lines 6 and 7).
Last, we never enqueue a rule that is already in the queue.
It is expensive to check two rules for equality.
However, it is easy to compute measures such as head coverage, con -dence, and PCA con dence for each rule.
Two rules can 417only be equal if they have the same values for these mea- sures.
This restricts the rules that have to be checked.
If a rule is duplicate, we do not enqueue it (Lines 11 and 12).
We can be sure that any potential duplicates will still be in the queue.
This is because the length of the rules increases monotonically: When we dequeue a rule with n atoms, no rule with n + 1 atoms has ever been dequeued.
Thus, when we apply the operators to the rule with n atoms, and generate a rule with n + 1 atoms, any potential duplicate of that new rule must be in the queue.
Projection Queries.
No matter what operator is applied in particular, the algorithm needs to choose a relation for the new atom that is added to the rule.
In addition, the instantiation operator OI also allows the choice of an entity.
In order to select only relations and entities that will ful ll the head coverage constraint, we rely on the KB to answer projection queries.
These are queries of the form SELECT ?x WHERE H   B1   ...   Bn HAVING COUNT(H)  k where B1, ..., Bn are atoms and k is a natural number.
H is the projection atom on which we project.
?x is the selection variable.
It is a variable that appears in one or more atoms at the position of one of the arguments or at the position of the relation (as it is common in SPARQL6).
Such queries select an entity or relation x such that the result of the query H   B1   ...   Bn on the KB contains more than k distinct query answers for H.
Using Projection Queries.
Projection queries allow us to select the relationship for the operators OD, OI, and OC in such a way that the head coverage of the resulting rule is above  .
This works by  ring a projection query of the form SELECT ?r WHERE H   B1   ...   Bn  ?r(X, Y ) HAVING COUNT(H)  k where X and Y are variables or constants, depending on the type of atoms that the operator generates.
The results for ?r will be the relations that, once bound in the query, ensure that the support of the rule B1   ...   Bn ?r(X, Y )   H is greater than k. If we choose k equal to   times the number of facts of the relation of H, then the head coverage of the resulting rules will be greater than     which is what we want.
For the instantiation operator OI, we  rst  re a projection query to select relations, and then  re projection queries to retrieve entities.
This way, projection queries allow us to choose the relationships and entities for the operators in such a way that the head coverage for the new rules is guaranteed to be above  .
Next, we discuss how to implement projection queries e ciently.
SQL and SPARQL.
Projection queries are essential for the e ciency of our system.
Yet, standard database implementations do not provide special support for these types of queries.
Assuming that the KB K is stored as a three-column table (i.e., each fact is a row with three elements), the projection query template in SQL would be: Implementation SELECT ?x FROM K AS H, K AS B1, .
.
.
Bn WHERE H.xi = Bj.xm, .
.
.
GROUP BY(H.x1, H.xr, H.x2) HAVING COUNT(*)   k where ?x is replaced with a reference to any of the introduced columns.
The WHERE clause lists all variables that are shared between any two atoms in the rule, i.e., all join columns and conditions between atom tables.
Since SELECT can only select variables that appear in the GROUP BY statement, the above template is for the case where ?x appears in H. The case where ?x does not appear in H will require a nested query.
Our experience shows that already running the non-nested query on a database of a few million facts can easily take several minutes on an o -the-shelf RDBMS.
Hence, e cient SPARQL engines such as RDF-
jection query template is: SELECT ?x
 H.x1, H.xr, H.x2 .
B1.x1, B1.xr, B1.x2 .
.
.
.
Bn.x1, Bn.xr, Bn.x2 .
} GROUP BY H.x1 H.xr H.x2 HAVING COUNT(*)   k Again, this is only for the case where ?x appears in H. RDF-
we would need extensive postprocessing of query results to compute a projection query   already in the case where ?x is in H.
In-Memory Database.
We have implemented a vanilla in-memory database for semantic KBs.
Our implementation indexes the facts aggressively with one index for each permutation of subject, relation, and object.
Each index is a map from the  rst item to a map from the second item to a set of third items (e.g., a map from relations to a map from subjects to a set of objects).
This allows retrieving the instantiations of a single atom in constant time.
The existence of a query answer can be checked naively by selecting the atom with fewest instantiations, running through all of its instantiations, instantiating the remaining atoms accordingly, and repeating this process recursively until we  nd an instantiation of the query that appears in the KB.
Select queries are similar.
Projection Queries.
Algorithm 2 shows how we answer projection queries.
The algorithm takes as input a selection variable ?x, a projection atom H = R(X, Y ), remaining atoms B1, ...Bn, a constant k, and a KB K. We  rst check whether ?x appears in the projection atom.
If that is the case, we run through all instantiations of the projection atom, instantiate the query accordingly, and check for existence.
Each existing instantiation increases the counter for the respective value of ?x.
We return all values whose counter exceeds k. If the selection variable does not appear in the projection atom, we iterate through all instantiations of the projection atom.
We instantiate the query accordingly, and  re a SELECT query for ?x.
We increase the counter for each value of ?x.
We report all values whose counter exceeds k.
Summary.
We have identi ed projection queries as the crucial type of queries for rule mining.
Since standard database systems and standard SPARQL systems provide no speci -cally tuned support for these queries, we have implemented 418a vanilla in-memory database, which has speci c support for projection queries.
Our entire implementation is in Java.
Algorithm 2 Answering Projection Queries function SELECT(?x, R(X, Y )   B1   ...   Bn, k, K) map =   if R   ?x   X   ?x   Y   ?x then for all instantiations r(x, y) of R(X, Y )   K do q = B1   ...   Bn In q, replace R by r, X by x, Y by y if exists instantiation q   K then map(value of ?x) + + end if else end for for all instantiations r(x, y) of R(X, Y )   K do q = B1   ...   Bn In q, replace R by r, X by x, Y by y for all x   SELECT ?x FROM K WHERE q do map(x) + + end for end for end if return {x : map(x)   k} end function


 Experiments.
We conducted 3 groups of experiments: In the  rst group, we compare AMIE to two popular, state-of-the-art systems that are publicly available, WARMR [11,
 compare the standard con dence to the novel PCA con -dence that we have introduced in this paper (Section 4).
In the third group of experiments, we run AMIE on di erent datasets to show the applicability of the system.
Settings.
By default, AMIE  nds all rules whose head coverage exceeds the default threshold of   = 1%.
AMIE ranks the resulting rules by decreasing PCA con dence.
There is no need to deviate from this default con guration when a user runs AMIE.
There are no parameters to tune.
All experiments with AMIE on all datasets are run in this setting, unless otherwise mentioned.
For some experiments, we want to compare AMIE s run-time with other systems.
To have an equal basis, we make AMIE simulate the metrics of the competitor systems.
AMIE can threshold on support, head coverage, con dence, and PCA con dence, and she can rank by any of these.
AMIE can also count the support not on two variables, but on a single variable.
AMIE can also output non-closed rules.
Since this is just a choice of what to output, it does not in u-ence runtime.
All experiments with all systems are run on a server with 48GB RAM and 8 CPUs.
We always mine rules without constants (i.e., without the instantiation operator), unless otherwise mentioned.
Knowledge Bases.
We run our experiments on di erent KBs.
In all cases, we removed the rdf:type relationship, because it in ates the size of the KBs.
We are aware that the rdf:type relationship can be very helpful for rule mining.
However, currently no approach (including ours) makes spe-ci c use of it.
We plan to make use of it in future work.
Furthermore, we removed all facts with literals (numbers and strings) from the KBs.
Literal values (such as geographical coordinates) are shared by only very few entities, which makes them less interesting for rule mining.
Evaluations.
In all experiments, our goal is twofold: First, we want to produce as many predictions as possible beyond the current KB.
Second, the percentage of correct predictions shall be as large as possible.
The particular challenge is that we want to evaluate predictions that go beyond the current KB.
We are not interested in describing the existing data, but in generating new data.
Therefore, we proceed as follows: We run the systems on an older dataset (YAGO2 [16]).
We generate all predictions, i.e., the head atoms of the instantiated rules (see Section 3).
We remove all predictions that are in the old KB.
Then we compare the remaining predicted facts to the successor of that dataset (YAGO2s [34]).
A prediction is  correct  if it appears in the newer KB.
A prediction is  incorrect  if it has a highly functional or highly inverse functional relation and contradicts an existing fact in the newer KB, e.g., a di erent birth place.
For all other predictions, we manually validated the facts by checking a sample of 30 of them against Wikipedia pages.
This classi es the remaining predictions as  correct  or  incorrect    except for a few cases where the fact is  unknown , such as the death place of a person that is still alive.
The ratio of correct predictions out of the correct and incorrect predictions yields the precision of the rule.
Outlook.
We note that with the project of predicting beyond current knowledge, we are entering a new, and very risky area of research.
We do not expect Horn rules to have extraordinary precisions in the unknown region.
Rules can only yield hypotheses about possible facts.
In this section, we compare AMIE to WARMR and ALEPH.
For each system, we conduct 3 experiments: We  rst compare the usability of the competitor system to AMIE.
Then, we compare their runtimes.
Last, we compare their outputs.
Usability.
WARMR is a system that uni es ILP and association rule mining.
Similar to APRIORI algorithms [4], it performs a breadth rst search in order to  nd frequent patterns.
WARMR generates Datalog queries of the form  ?
  A1, A2, ..., An , where Ai are logical atoms.
To discover frequent patterns (as in association rule mining), we need to have a notion of frequency.
Given that WARMR considers queries as patterns and that queries can have variables, it is not immediately obvious what the frequency of a given query is.
Therefore, the user needs to specify the predicate that is being counted by the system (the key predicate).
In the usual scenario of market basket analysis, e.g., the system counts customer transactions.
In a scenario in which the database is a KB, one solution is to count entities.
Since the key predicate determines what is counted, it is necessary that it is contained in all queries.
Therefore, we add a predicate entity(x), which we  ll with all entities of the KB.
AMIE does not require such a choice.
For WARMR, the user needs to provide speci c information about which predicates can be added to a query, which of their variables can be fresh, and which arguments of predicates are allowed to be uni ed (type declarations).
In contrast, AMIE requires none of these.
AMIE simply takes as input the KB in triple format.
user can de ne which predicates and arguments should be instantiated with constants (we call this mode MODE1).
WARMR then checks all the constants appearing in the facts of that speci c predicate and argument and afterwards uses them in the queries.
MODE1 naturally entails an increase of the branching factor in the search space and an explosion in the number of candidates that need to be evaluated.
Alternatively, WARMR allows the user to set a maximum number of constants to be used for each predicate and argument (MODE2).
Unfortunately, though, it does not provide a way for the user to in uence the selection of these constants.
In other words, there is no guarantee that the constants that WARMR will use are the most promising ones.
WARMR produces rules as output.
These rules are not necessarily connected.
For example, WARMR mines isMarriedTo(B,C),   isLeaderOf (A,D)   hasAcademicAdvisor (C,E) This rule is not only nonsensical from a semantic perspective, but also redundant, because the second atom does not in uence the implication.
Therefore, the user has to  lter out these rules from the output.
Thus, we conclude that the broader mission and the broader applicability of WARMR entails that much more con gura-tion, acquaintance, and expert knowledge is needed to make it mine Horn rules on semantic KBs.
Runtime.
YAGO2 [16] contains around 940K facts about
 data in a time period of 1 day.
Therefore, we created a sample of YAGO2.
Randomly selecting a number of facts from the initial dataset could break the interesting links between the entities.
Therefore, we randomly selected 10,000 seed entities and included their 3-hop neighborhood.
This yielded 14K entities and 47K facts.
This sample contains all available information in a radius of 3 hops around the seed entities, but much less information about the entities at the periphery of the subgraph.
Therefore, we restricted the values for the key predicate to the seed entities only.
Since the sample is much smaller than the original KB, we lowered the support threshold to 5 entities.
We ran AMIE with these parameters on the sample.
AMIE mined her rules in 3.90 seconds.
WARMR, in contrast, took 18 hours.
We also ran both systems allowing them to mine rules with constants.
AMIE completed the task in 1.53 minutes.
WARMR in MODE1 for all relations did not terminate in 3 days.
Therefore, we ran it also only for the relations diedIn, livesIn, wasBornIn, for which it took 48h.
We also ran WARMR in MODE2.
To have reasonable runtimes, we allowed WARMR to  nd constants only for one predicate (diedIn).
We also restricted it to  nd only 20 constants.
WARMR ran 19 hours.
Table 3 summarizes the runtime results.
We conclude that AMIE is better suited for large KBs than WARMR.
This is because WARMR is an ILP algorithm written in a logic programming environment, which makes the evaluation of all candidate queries ine cient.
Constants no yes
 18h (48h) / (19.3h)
 3.90s 1.53min Table 3: Runtimes on YAGO2 Sample Results.
After  ltering out non-connected rules, WARMR mined 41 closed rules.
AMIE, in contrast, mined 207 closed rules, which included the ones mined by WARMR.
We checked back with the WARMR team and learned that for a given set of atoms B1, ...Bn, WARMR will mine only one rule, picking one of the atoms as head atom (e.g., B1   ...  Bn 1   Bn).
AMIE, in contrast, will mine one rule for each possible choice of head atom (as long as the thresholds are met).
In other words, AMIE with the standard support and con dence measures simulates WARMR, but mines more rules.
Furthermore, it runs orders of magnitude faster.
Especially for large datasets for which the user would have needed to use complicated sampling schemes in order to use WARMR, AMIE can be a very attractive alternative.
Even for smaller datasets with rules with constants, AMIE can provide results while WARMR cannot.
Moreover, AMIE comes with metrics that go beyond the standard con dence and the standard support.
We will show later that these improve the quality of the results.
Usability.
ALEPH can be run with di erent commands that in uence the search strategy.
We chose the induce command, which runs fastest.
For running ALEPH, the user has to specify the target predicate for learning (the head predicate of the rules).
In the following, we ran ALEPH successively with all predicates of the KB as targets.
In addition, the user has to specify a series of type and mode declarations (similar to WARMR), which will be used as a language bias in order to restrict the search space.
In addition, the user needs to provide ALEPH with  les containing the background knowledge and positive examples for the target predicate.
In contrast, AMIE requires no such input.
It will run on a KB without any prespeci ed choices of predicates.
YAGO2 full YAGO2 Sample Facts 948k 47k
 4.96s to > 1 day 0.05s to > 1 day
 3.62min 5.41s Table 4: Runtimes ALEPH vs. AMIE Runtime Relations < 5min isPoliticianOf, hasCapital, hasCurrency < 5min dealsWith, hasO cialLanguage, imports <19min isInterested, hasMusicalRole hasAcademicAdvisor, hasChild > 1 day isMarriedTo, livesIn, worksAt, isLocatedIn > 1 day Table 5: Runtimes of ALEPH on YAGO2 Runtime Relations < 2min diedIn, directed, hasAcademicAdvisor < 2min graduatedFrom, isPoliticianOf, playsFor < 2min wasBornIn, worksAt, isLeaderOf < 1.4h exports, livesIn, isCitizenOf actedIn, produced, hasChild, isMarriedTo > 1 day Table 6: Runtimes of ALEPH on YAGO2 Sample Runtime.
We ran AMIE and ALEPH on YAGO2 [16].
For ALEPH, we used the positive-only evaluation function with Rsize = 50 and we considered only clauses that were able to explain at least 2 positive examples, so that we will not get grounded facts as rules in the output.
For a fair comparison, we also instructed AMIE to run with a support threshold of 2 facts.
AMIE terminated in 3.62 minutes, and found rules for all relations.
ALEPH ran for one head relation at a time.
For some relations (e.g.isPoliticianOf ), it terminated in a few seconds.
For others, however, we had to

 at a time.
Some examples need little processing time, others block the system for hours.
We could not  gure out a way to choose examples in such a way that ALEPH runs faster.
Hence, we used the sample of YAGO2 that we created for WARMR.
Again, runtimes varied widely between relations (Table 6).
Some relations ran in a few seconds, others did not terminate in a day.
The runtimes with constants are similarly heterogenous, with at least 7 relations not terminating in 1 day.
Results.
We compared the output of ALEPH on the head relations for which it terminated to the output of AMIE on these head relations, on the sample dataset.
ALEPH mined 56 rules, while AMIE mined 335 rules.
We order the rules by decreasing score (ALEPH) and decreasing PCA con dence (AMIE).
Table 7 shows the number of predictions, and their total precision as described in Section 6.1.
We show the aggregated values at the points where both approaches have produced around 3K, 5K and 8K predictions.
AMIE s PCA con dence succeeds in sorting the rules roughly by descending precision, so that the initial rules have an extraordinary precision compared to ALEPH s.
AMIE needs more rules to produce the same number of predictions as ALEPH (but she also mines more).
We suspect that ALEPH s positives-only evaluation function manages to  l-ter out overly general rules only to some extent.
ALEPH will mine, e.g, livesIn(A, C),isLocatedIn(C, B)   isPoliti-cianOf (A, B).
The problem is that ALEPH generates counterexamples by randomly using valid constants for variables A and B.
This means that the probability of creating a random example in which B is the place of residence of the speci c person A is very low.
System Top n Predictions Precision























 Table 7: Top Rules of ALEPH vs. AMIE
 In this section, we compare the standard con dence measure to the PCA con dence measure.
We ran AMIE with the default head coverage threshold on the YAGO2 dataset.
It contains nearly 500K entities and 948K facts.
We sort the rules  rst by descending PCA con dence, and then by descending standard con dence, and look at the top rules.
For each rule, we evaluated the predictions beyond YAGO2 as described in Section 6.1.
Figure 8 uses aggregated predictions and aggregated precision to illustrate the results.
The nth dot from the left tells us the total number of predictions and the total precision of these predictions, aggregated over the  rst n rules.
As we see, ranking the rules by standard con dence is a very conservative approach: It identi es rules with reasonable precision, but these do not produce many predictions.
Going down in the list of ranked rules, the rules produce more predictions   but at lower precision.
The top
 sion of 32%.
If we rank the rules by PCA con dence, in contrast, we quickly get large numbers of predictions.
The top
 of 39%.
The top 30 rules produce 3 times more predictions than the top 30 rules by standard con dence   at comparable precision.
This is because the PCA con dence is less conservative than the standard con dence.
Figure 8: Std.
Con dence vs. PCA Con dence Discussion.
The precision of the rules is in the range of
 known region will be correct.
Still, even imperfect rules can be useful: If, e.g., a human checks the facts before they are added, then reducing the number of false predictions is a great advantage.
If games with a purpose are employed, then the rules can help pre-select candidate facts.
If multiple sources are combined, then rules can contribute evidence.
If reasoning approaches are used, then rules can be taken into consideration according to their estimated performance.
Finally, the precision is better if standard con dence is used.
Predicting Precision.
The con dence measures can serve to estimate the actual precision of a rule.
In Table 9, we rank the mined rules by their precision and report the average absolute error of the standard and PCA con dence weighted by the number of predictions produced by the rules.
We can observe that, on average, the PCA con dence estimates the precision of the rules better than the normal con dence.
Thus, reasoning approaches can use the PCA con dence as a weight for the rule.
Top 20 rules Top 30 rules All rules Con dence PCA Con dence





 Table 9: Average Absolute Error to Precision We also note that our rules are insightful.
Table 10 shows some of the rules we mined.
Being able to mine reasonable rules on semantic KBs of this size is an achievement beyond the current state of the art.
isCitizenOf (x, y)   livesIn(x, y) hasAdvisor (x, y)  graduatedFrom(x, z)   worksAt(y, z) wasBornIn(x, y)  isLocatedIn(y, z)   isCitizenOf (x, z) hasWonPrize(x, G. W. Leibniz)   livesIn(x, Germany) Table 10: Some Rules by AMIE
 As a proof of concept, we ran AMIE on YAGO2 [16], YAGO2 with constants, and DBpedia [5].
We chose an older version of DBpedia (2.0), so that we can evaluate the output to a newer version of DBpedia (3.8).
Due to the large number of relations in DBpedia 2.0, there is an enormous number of rules to be found.
We show the time taken to mine rules with 2 atoms.
We provide also the number of predicted facts that are in the newer version of the KB but
 duce rules with or without constants in a reasonable time.
Dataset
 YAGO2 const DBpedia Entities


 Facts Runtime Rules


 3.62min 17.76min 2.89min


 Hits





 Table 11: AMIE on Di erent Datasets All rules and results are available at http://www.mpi-inf.
mpg.de/departments/ontologies/projects/amie/.
In this paper, we have presented an approach for mining Horn rules on large RDF knowledge bases.
We have introduced a formal model for rule mining under the Open World Assumption, a novel measure to simulate counterexamples, and a scalable algorithm for the mining.
In contrast to state-of-the-art approaches, our system (AMIE) requires no input other than the KB, and does not need con gurations or parameter tuning.
As our extensive experiments have shown, AMIE runs on millions of facts in only a few minutes and outperforms state-of-the-art approaches not only in terms of runtime, but also in terms of the number and quality of the output rules.
Our con dence measure can reasonably predict the precision of the rules.
In our future work, we plan to consider also the T-Box of the KB in order to produce more precise rules.
We also aim to explore the synergies when several rules predict the same fact, and extend the set of rules beyond Horn rules, so that even more complex facts and hidden knowledge can be predicted.
