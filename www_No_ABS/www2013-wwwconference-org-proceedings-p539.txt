The popularity of online social networks has grown enormously in recent years.
Users of the most popular social network, FacebookTM, now number greater than a billion1.
This popularity has increased interest in analyzing the properties of these networks.
In [2, 13, 21] the authors investigate structural measures of online social networks, including degree distribution and clustering coe cient.
Large social networks, as well as search engines, provide a public interface as part of their service.
Estimating structural measures of the network using only these public interfaces is a research question that has received much attention in recent studies.
Search engine public interfaces have been used in [6, 8] to estimate corpus size, index freshness, and density of duplicates, and in [7] estimate the impressionrank of a webpage.
Online social network public interfaces have been used in [13, 14, 25] to estimate the assortativity co-e cient, degree distribution, and clustering coe cients of online social networks, as well as in [14, 15] to estimate the number of registered users.
In practical scenarios, the underlying social network may be available only through a public interface.
The public interface of most social networks provides the ability to retrieve a list of a user s connections ( friends ).
By applying this function iteratively to a random member of the connection list one can e ectively perform a random walk on the network.
Although the public interface allows us to store the social network locally, this practice is considered impractical due to high time/space/communication cost and often violates the terms of use agreement.
In light of this, in this paper we proceed under the assumption that (1) only external access to the social network is available; and (2) only a small number of users/nodes can be sampled.
The main
 on-Facebook 539insight o ered by this work is that, even under these limita- tions, our algorithms achieve a good estimation accuracy of the network s structural measures.
This work focuses on two particular structural measures.
The  rst measure is called the clustering coe cient.
The second measure is the size of the network.
Namely, the number of registered users in the network2.
The clustering coe cient comes in two main  avors, (1) the network average clustering coe cient [12]; and (2) the global clustering coe cient [12].
Both measures are important for the understanding of the network structure.
First, we introduce the local clustering coe cient of a node in a graph as the ratio of the number of edges between its neighbors to the maximal possible number of such edges.
The network average clustering coe cient of a graph is the local clustering coe cient averaged over the set of nodes in the graph.
The global clustering coe cient of a graph is the ratio of the number of triangles (ordered triples of di er-ent nodes in which are all nodes connected) to the number of connected triplets (ordered triples of di erent nodes in which consecutive nodes are connected).
The size of the network is one of the basic structural measures.
The network size can determine the worth of a network (for business development).
For certain applications in business development and advertisement, the size of a social network subpopulation is extremely important.
For example, the number of users of an online product or the number of potential users for a product.
The subpopulation fraction (which can also be estimated e ciently [15]) and the network size can determine the size of the subpopula-tion.
Although some networks report their size periodically, the di erence between consecutive reports can be more than ten percent.
Moreover, even if this number is reported every day, an unbiased independent estimate would be bene cial.
This work contains three main contributions.
The  rst and principal contribution is the  rst external access estimator for the global clustering coe cient.
The second contribution is an improved external access estimator for the network average clustering coe cient.
The third contribution is an improved external access estimator for the network size.
The rest of this paper is organized as follows.
Section 2 surveys related work.
Section 3 provided preliminaries and notations.
Section 4 details our clustering coe cient estimators.
Section 5 details our network size estimator.
Section 6 reports our experimental results.
We conclude the paper in Section 7.
We consider the social network as an undirected graph where nodes and edges are represented by users and friendship connections.
Although the algorithms presented in this paper are correct for general graphs, the structure of social networks renders them even more e ective.
Both the network average and the global clustering coe -cient (also known as transitivity) are a long studied classical computer science problem.
The running time of the naive algorithm for computing them is O(n3) for dense graphs (where n is the number of nodes in the graph), and it is considered impractical for large graphs.
For the global cluster-
connected component and isolated users are neglected.
ing coe cient, the most challenging part of the computation is counting the total number of triangles, since computing the number of connected triplets is done in linear time.
To this end, the computation of global clustering coe cient and the computation of the number of triangles is equivalent.
We provide references for a partial list (most recent) for several directions for estimating the number of triangles.
Alon et al. [3] provided an exact algorithm for the counting the number of triangles.
The running time of this al-2   +1 ) = O(E1.41), where   < 2.376 is the gorithm is O(E exponent of matrix multiplication.
Avron [4] provided an estimator based on numerical matrix-vector multiplication using O(log2 n) samples, each of which requires O(|E|) time (where E is the set of nodes in the graph).
Both these algorithm access the entire graph.
Buriol et al. [10] provided an approximate solution to the global clustering coe cient in the streaming model.
The streaming models allows the algorithm to have a single pass on the input while (1) reading the edges in arbitrary/vertex ordered appearance (di erent algorithms) and (2) use constant amount of space.
Becchetti et al. [9] provided an algorithm for the network average clustering coe cient in the streaming model.
In contrast to [3, 4] these works assume there is no random access to the graph.
However, the streaming algorithms access each edge at least once.
Schank et al. [27], provided estimators for both the global and network average clustering coe cient which only uses a sample of the nodes.
However, unlike our work, the algorithms assume there is an e cient way to sample nodes with distribution that is tailored to the clustering coe cient.
Speci cally, for the network average clustering coe cient the sampling distribution is the uniform distribution and for the global clustering coe cient each node vi with degree di is sampled proportionally to di(di   1).
In contrast, the algorithms provided in this work do not even assume the number of nodes is known and does not require a tailored sampling distribution.
Another research direction [13, 25] addresses the problem of estimating the local clustering coe cient with external access3.
In these papers, the graph can only be accessed via the exploration of nodes that lie on the frontier of previously explored nodes.
Ribeiro et al [25] explored the graph using a random walk.
Gjoka et al. [13] explored the graph using Metropolis-Hastings random walk that generates uniform samples from the nodes set.
In both these papers, the computation requires augmenting the set of explored nodes, S, with further exploration of S s ego network.
An ego network of a set of users S, is the set of users S(cid:3) that contains all the users in S and all their (immediate) friends [13, 28].
In this work, we perform a random walk but remove the requirement of exploring the ego network.
This di erence is illustrated in Figure 1.
The random walk contains three nodes v1, v2, v3.
Our approach requires the exploration of the nodes v1, v2, v3 (marked by a thick circle), the ego network approach requires additional exploration of the nodes v4, v5, v6.
In total the ego network requires exploration of all the nodes v1, v2, .
.
.
, v6 (marked by solid  ll).
In section 6, we show that the algorithm provided in this paper
 cient, but provides an accurate de nition of the network average clustering coe cient.
540va vb vc in random walk in ego network visible by random walk and ego network visible by ego network only beyond reach visible by neither v3 v5 v7 v1 v2 v9 v4 v6 v8 number of samples needed to guarantee convergence for a  xed accuracy is O(n1/4 log n) [15].
In some applications the size of a subpopulation needs to be estimated.
This subpopulation is de ned by a property of the user s pro le.
For example, the number of registered users who use a speci ed online product.
Estimating the size of a subpopulation requires multiplying the total size of the network by the ratio the target nodes to the total nodes which could also be estimated by the random walk [15].
In this work, we improve the network size estimation algorithms by using not only the visited node ids, but also the adjacency list of each of the visited nodes.
This is done by counting node collision one step before they actually occur.
Namely, two nodes on the random walk (enough nodes apart) that share a connection.
We call this collision a neighbor collision.
Figure 1: An example of a random walk with its corresponding ego network augmentation.
outperform competing approaches [25, 13] on all the social networks we study.
Another method for estimating the clustering coe cient from a random walk was presented in [14].
This algorithm uses only the ids of nodes visited by a random walk and does not assume any prior information.
In contrast, the algorithms in this paper assume not only the node ids are visible, but also their list of friends (adjacency list).
Practically, if this assumption holds, it renders [14] uncompetitive.
In this work, two estimators are provided for the clustering coe cient.
The  rst for the network average clustering coe cient and the second for the global clustering coe -cient.
Both estimators use samples taken from a random walk on the graph.
Namely, not only that the algorithms do not access the entire graph, they do not even have random access to the graph s nodes and edges.
The only assumption is that a random walk can be performed via the public interface, and the visited node ids along with their list of friends (adjacency list).
This is the case for many social networks.
Indeed, the act of performing a random walk at all in an online social network typically necessitates having access to this information.
Both [14, 15] provide estimators for the total number of registered users in the network.
These algorithms use only the node ids visited on the random walk and do not assume any prior information on the graph.
The underlying idea in both papers is to count node collision, a pair of indices (k, l) such that the same node appears in the kth and lth location of the random walk.
Nodes on the random walk are highly correlated when their index distances (|k   l|) are short, which increases the probability of a node collision.
To ensure a uni ed probability of collision across all node pairs, a collision is counted only if the nodes appear a signi cant number of steps apart.
These works di er in the way they select these pairs.
In [15] the estimator chooses all pairs in which both k and l are a multiple of a parameter m, while [14] chooses all pairs in which m   |k   l|.
Choosing all pairs [14] is practically better, but harder to analyze.
The convergence of social network like graphs is very fast and depends on the degree distribution.
For example, if the node degrees are distributed according to a Zip an distribution n and parameter   = 2, then the with maximum degree of  

 We denote by G(V, E) the social network s underlying undirected graph, where V = {v1, v2, .
.
.
, vn} is the set of nodes (users) and E is the set of edges (friendship connections).
Additionally, we denote by di the degree of node i=1 di = 2|E|.
The vi and the sum of degrees by D = maximum degree of a node in the graph is noted by dmax = i=1 di.
maxn We denote by an n  n matrix A the adjacency matrix for graph G. Namely, Ai,k = Ak,i = 1 if node vi is connected by an edge to node vk and 0 otherwise.
We assume no self loops, thus Ai,i = 0 for all i.
(cid:2) n Definition 1.
A triplet of nodes (vj , vi, vk) is called connected if vj is connected to vi, vi is connected to vk, and j < k. Formally, if Aj,i = 1, Ai,k = 1, and j < k.
Definition 2.
A triangle is a connected triplet (vj, vi, vk) in which vj and vk are connected.
Formally, if Aj,k = 1.
(cid:2) (cid:2) Following these de nitions, a triplet of nodes is connected if j < k and Aj,iAi,k = 1 and it is a triangle if j < k and Ai,jAi,kAj,k = 1.
For a speci c node vi, the number of connected triplets (vj , vi, vk) is thus Aj,iAi,k.
Note Aj,iAi,k = di(di 1)/2 since there are di(di 1)/2 that choices for j < k in which both Aj,i = 1 and Ai,k = 1.
For a speci c node vi, the number of (vj , vi, vk) triangles is denoted by li = Ai,j Ai,kAj,k (it is also the number of edges between neighbors of vi) .
(cid:2) j<k j<k j<k Definition 3.
The local clustering coe cient [12] for node vi, denoted by ci, is de ned as the ratio of the number of (vj , vi, vk) triangles to the number of (vj , vi, vk) connected triplets.
Formally, ci = 2li di(di   1) Note that ci   [0, 1].
In the case where di = 1 or di = 0, we have ci = 0.
Definition 4.
The network average clustering coe cient [12], denoted by cl, is de ned by n(cid:3) cl =
 n ci i=1
 noted by cg, is de ned as the ratio of the total number of triangles to the total number of connected triplets.
Formally, (cid:2) (cid:2) i=1 li i=1 di(di   1)
 n n cg = Note that a set of three nodes {vj , vi, vk} forms three different triangles4 one is counted in lj , a second in li, and a third in lk.
The  rst step of the estimation algorithms is to generate a random walk.
A random walk with r steps on G, denote by R = (x1, x2, .
.
.
, xr), is de ned as follows: start from an arbitrary starting node vx1 , then move to one of the neighboring nodes uniformly at random (with probability 1 ) and repeat r   1 times.
We use Pr [A] to denote the prob-dxi ability that event A occurred.
We denote the distribution induced by R, as  R = (Pr [xr = 1] , Pr [xr = 2] , .
.
.
,Pr [ xr = n]) .
The probability Pr [xr = i] after many random walk steps converges to pi (cid:2) di/D and the vector   = (p1, p2, .
.
.
, pn) is called the stationary distribution of G.
In our estimators, we assume that x1 is drawn from the stationary distribution5.
This assumption is valid because we can always perform an initial random walk from an arbitrary node to draw a starting node from the stationary distribution.
The actual number of steps needed to converge to the stationary distribution depends on the mixing time of G.
There are several de nitions of mixing time, many of which are known to be equivalent up to constant factors.
All definitions take an  parameter to measure the distance between the stationary and the induced distribution.
Both the book [17] and the survey [19] provide excellent overview on random walks and mixing times.
We denote the mixing time of graph G by   () or   ( is assumed to be a small constant).
We use the following de nition: Definition 6.
Let R = (x1, x2, .
.
.
, xr) be a random walk.
Then, let the distance between   and  R be the maximum difference between the probability of drawing a speci c node xr over all possible choices of nodes x1 and xr.
Namely, d(r) = n n max x1=1 max i=1 |pi   Pr [xr = i]|.
We have   () = min {r | d(r)   }.
be r = log2 n for the Facebook network, r = 3 log2 n for the DBLP and youtube networks, and r = 10 log2 n for the Live Journal network.
Both the low mixing time and the relatively high value of the clustering coe cients enable the clustering coe cient estimation algorithms in this paper to provide accurate result with relatively low number of samples.
Notations are summarized in Table 1.
n
 vi di
 r xk pi   li cl cg  cl  cg  n   () dmax underlying undirected graph number of nodes in the graph adjacency matrix for G (cid:2) degree of node vi the sum all nodes degrees node in G n i=1 di total number of steps in the random walk the index of kth node in the random walk p(xk = i) = di
 the stationary distribution (p1, p2, .
.
.
, pn) number of edges between neighbors of vi network average (local) clustering coe cient global clustering coe cient cl estimation cg estimation n estimation mixing time i=1 di maxn Table 1: Summary of notations


 We now present the main observation used in both network average and global clustering coe cient estimators.
Given a random walk (x1, x2, .
.
.
, xr), we de ne a new variable  k = Axk 1,xk+1 for every 2   k   r   1.
For any function f (xk) the following holds6: E [ kf (xk)] = = = i=1 n(cid:3) n(cid:3) n(cid:3) i=1 i=1 piE [ kf (xk)|xk = i] di


 2li d2 i 2li di f (vi) f (vi).
(1) Social network graphs are known to have low mixing times and constant clustering coe cients (which are not extremely small).
Recently, Addario-Berry et al [1] proved rigorously that the mixing time of Newman-Watts [23, 24] small world networks is  (log2 n).
Mohaisen et al. [22] provide numerical evaluation of the mixing time of several networks.
The authors claim that  the mixing time is much larger than anticipated .
However, Table 1 and Figure 2 in their paper show that to have d(r)   0, the number of steps should
 of three nodes, in which case cg is de ned by three times the ratio of the total number of triangles to the total number of connected triplets.
time bound is tighter with this assumption.
The  rst equality holds due to the law of total expectation.
The second equality holds because there are d2 i equal probability combinations of (xk 1, vi, xk+1) out of which only 2li form a triangle (vj , vi, vk) or a reverse triangle (vk, vi, vj).
Notice that in a triangle or a reverse triangle vj is connected to vk (Aj,k = 1).
The third equality holds due to algebraic manipulation.
To estimate cl, we introduce two variables.
First, we de-
 ne  l as a weighted sum of  js,  l = 1  1 .
r 2 dxk Second, we de ne  l as the sum of the sampled nodes reciprocal degrees,  l = 1 r
 tering and f (vi) = di for the global clustering estimator.
r 1 k=2  k (cid:2)
 dxk r k=1 .
(cid:2)
 (cid:4) (cid:4) compute  l and  l expectation.
(cid:5) n(cid:3) E [ l] = E E [ l] = E  k
   1 (cid:5) dxk n(cid:3)
 dxk = i=1

 2li di(di   1) n
 = i=1 di

 di = n(cid:3) i=1 ci =

 From the above equations we can isolate cl and get that: n(cid:3) i=1 cl =
 n ci = E [ l] E [ l] Intuitively, both  l and  l converge to their expected values and the estimator  l/ l converges to cl as well.
Definition 7.
Let  cl be the estimator for cl, de ned as follows:  cl (cid:2)  l  l .
Lemma 1.
For any    1/8 and     1 we have: Pr[cl(1   )    cl   cl(1 + )]   1     (cid:7) when the number of samples, r, satis es: (cid:6) r   rl   O
 ncl   () .
Proof.
The proof  rst  nds the number of step, rl, which guarantees both  l and  l be within /3 approximations to their expected values with probability at least 1    /2.
See Appendix A for more details.
Since the probability of  l or  l deviating from their expected value is at most  /2, the probability of either  l or  l deviating is at most   (using the union bound).
Then, we use the fact that (1  )cl   (1   
 (1 + 
 E [ l] E [ l]    l  l   (1 + 
 (1   
 E [ l] E [ l]   (1 + )cl to complete the proof.
Note that for social network like graph the mixing time is assumed to be relatively low (for Newman-Watts networks   () = O(log2 n) [1]), D = O(n) and cl is a small constant.
Thus, the number of steps needed is linear in the mixing time,   ().
To estimate cg, we introduce two variables.
First, we de-r 1  ne  g as a weighted sum of  js,  g = 1 k=2  kdxk .
r 2 Second, we de ne  g as the sum of the sampled nodes degrees minus one,  g = 1 r k=1 dxk   1.
(cid:2) Using linearity of expectation and Eq (1) it is easy to r (cid:2) compute  g and  g expectation.
E [ g] = E [ kdxk ] = E [ g] = E [dxk   1] = n(cid:3) n(cid:3) i=1

 i=1 n(cid:3) i=1

 di = 2li di D (di   1) = di 2li n(cid:3) i=1 di(di   1)

 From the above equations we can isolate cg and get that: cg = 1(cid:2) i=1 di(di   1) n n(cid:3) i=1 2li = E [ g] E [ g] .
Intuitively, both  g and  g converge to their expected values and the estimator  g/ g converges to cl as well.
Definition 8.
Let  cg be the estimator for cg, de ned as follows:  cg (cid:2)  g  g .
Lemma 2.
For any    1/8 and     1 we have: Pr[cg(1   )    cg   cg(1 + )]   1     (cid:7) when the number of samples, r, satis es: Ddmax i=1 di(di   1) n r   rg   O (cid:2) (cid:6) cg   () .
The proof is similar to the proof of Lemma 1, except the number of steps rg that guarantees convergences for  g and  g is di erent.
See Appendix B for more details.
Both estimators presented in this section are consistent.
Formally, as the number of samples, r, grows the estimators converge to the true value.
This also implies the estimators are asymptotically unbiased.
In this section we present an estimator for the graph size (number of nodes).
The estimator uses observations of node pairs which are  far away  from each other in the random walk (as in Ref [14]).
This assumption is needed to ensure both nodes in a pair are (approximately) uncorrelated: each drawn from the stationary distribution7.
Speci cally, the estimator examines node pairs whose index distance is greater than a threshold m. Formally, I = {(k, l) | m   |k   l|   1   k, l   r} .
The estimator counts weighted neighbor collisions.
A neighbor collision is a pair of indices (k, l) such that vxk and vxl share a common neighbor.
Formally, let Ai be the set of vertices adjacent to vi.
Thus, Ai   Aj is the set of nodes neighboring both vi and vj.
Given a random walk (x1, x2, .
.
.
, xr), |.
Note that if we de ne a new variable  k,l = |Axk (k, l)   I, then (cid:7)2 (cid:5) (cid:4)   Axl (cid:6) di
 dj
 |Ai   Aj| 1 didj = dj
 .
n(cid:3) j=1 n(cid:3) j=1 n(cid:3) (cid:2) i=1
  k,l
 dxl dxk (cid:2) = n i=1 n j=1 |Ai   Aj| = n To see why j consider the following combinatorial proof.
For a node vk, the number of connected triplets (vi, vk, vj ) with no restrictions on i and (cid:2) j is d2 k. Thus, the total number of connected triplets is k=1 d2 k. Alternatively, for nodes vi and vj the number of connected triplets (vi, vk, vj ) is |Ai   Aj|.
Thus, the to-(cid:2) (cid:2) tal number of connected triplets can also be expressed by n i=1 Next, we de ne  n to be the averaged value of  k,l j=1 |Ai   Aj|.
over all possible choices of (k, l)   I. Namely,
 dxk dxl n (cid:2) j=1 d2 n (cid:3) (k,l) I  n =

  k,l
 dxl dxk .
mate introduced by this correlation, but increasing m means fewer observations of node pairs and a larger estimator variance.
However, note that we again bene t from the fast-mixing nature of social graphs, and m need only be of the order O(log2 n).
of (k, l)   I.
Formally, over all possible choices  n =

 .
|I|  n = (cid:2) be e ciently computed for every k in O(1), using a cumu-k=1 dxk , lative sum precomputation.
Speci cally, if Bq = then q r(cid:3) l=1
 dxl (cid:10) Br   B(l+m)+ + B(l m)  (cid:11) .
To compute  n one must  rst construct an inverted index of neighboring nodes.
In document-term view, each node is a document containing adjacent nodes as terms.
Speci -cally if vj is a neighbor of xk then k is a term in vj .
The running time of creating an inverted index is linear in the
 d number of terms (O(rdmax) worst case and O(r (cid:2) D ) ex-i pected).
Then, the entry for vj holds a list Lj of all indices in which vj is a neighbor.
Thus, |I|  n = j=1 Cj, where (cid:2) .
To e ciently compute Cj Cj = in O(|Lj|), a precomputation Bq(j) = should be used (similarly to the computation of  n).
(cid:2) (k,l) I|k Lj l Lj
 dxk dxl q k Lj (cid:2)
 dxk n i=1 n


 We demonstrate the e ectiveness of the estimators by experimenting with social networks with known structure.
Datasets statistics are enclosed in Table 2.
Network
 Orkut Flickr Live Journal n



 D/n



 cl



 cg



 Table 2: Networks statistics In all our datasets we perform the following: (1) if the original network is directed, the direction is removed (the edge is made undirected); (2) only the network s largest connected component is retained and the rest of the nodes/users are dropped.
All the datasets we use are publicly available9.
DBLP In the  Digital Bibliography and Library Project  (DBLP[18]) dataset each entry is a reference to a paper which contains a title and a list of authors.
In the corresponding network each node is an author and an edge between two authors represent co-authorship of one or more papers.
We used a snapshot taken Oct 01,
 Orkut Orkut is a general purpose social network.
The dataset contains a partial snapshot (11.3% of the nodes) taken during 2006 by [21].
In this social network the friendship connections (edges) are undirected.
Flickr Flickr is an online social network with focus on photo sharing.
The dataset contains a partial snapshot taken during 2006 2007 by [20].
In this social network the friendship connections (edges) are directed.
licly and http://konect.uni-koblenz.de/networks/{orkut-links, ickr-growth,soc-LiveJournal1} [16], respectivly.
http://dblp.uni-trier.de/xml/ available at dxk dxl (cid:3) (k,l) I n(cid:3) (cid:5) dxk dxl (cid:6) dj
 (cid:7)2 (cid:4) (cid:4) Due to linearity of expectation, we have E [ n] = E E [ n] = E  k,l dxk dxl
 dxl dxk (cid:5) n(cid:3) = n(cid:3) = i=1 j=1 j=1 di
 (cid:7)2 (cid:6) n(cid:3) j=1 dj
 dj
 dj di = n Notice that n = E [ n]/E [ n].
Intuitively, both  n and  n converge to their expected values and the estimator  n/ n converges to n as well.
Definition 9.
Let  n be the estimator for n, de ned as follows:  n (cid:2)  n  n .
Prior art algorithm [14, 15] count the number of node collisions, C, and estimates n by  n/C.
A node collision is a pair of indices (k, l) such that such that xk = xl.
In contrast  n counts neighbor collision and estimates n by  n/ n.
Lemma 3.
The neighbor collision estimator,  n (de ni-tion 9), has con dence intervals tighter than the node collision estimator.
Proof.
Formally, C = 1|I| (k,l) I 1xk=xl where 1xk=xl is 1 if xk = xl and 0 otherwise.
The key observation is that (cid:9) (cid:8) 1xk+1=xl+1 | xk, xl
 =  k,l
 dxl dxk .
(cid:2) This stems from the combinatorial argument that (a) there are dxk dxl equally likely joint node transitions from xk and | of xl to xk+1 and xl+1; and (b) in only  k,l = |Axk them xk+1 = xl+1 holds.
Note that, xk is uncorrelated with xl when (k, l)   I.
Using this observation we have, (cid:9)   Axl (cid:8) 1xk+1=xl+1 | xk, xl .
 n =

 (cid:3) (k,l) I This is the Conditional Monte Carlo estimator8 of C, which guarantees Var [C]   Var [ n] [26](Section 5.4).
n i=1 (cid:2)
 d
 i The straight forward computation of  n and  n running time is O(r2) and O(r2d2 max) respectively.
However, a careful implementation can reduce this complexity to O(r) and O(rdmax) respectively.
For  n the expected running can be reduced to O(r First, we de ne (l+m)+ to be min {r, l + m} and (l m)   to be max {l   m, 1}.
For the computation of  n instead of (cid:2)(l+m)+ multiplying the value of 1 by each dxk separately, it is mul-dxl k=(l m)  dxk .
The sum in turn, can tiplied by the sum of
 k = 1 which holds only for a negligible fraction of the pairs.
focus on journals and blogs.
The dataset contains a partial snapshot of the nodes taken by [5].
In this social network the friendship connections (edges) are directed.
The x-axis in our  gures is the percentage of mined nodes (number of mined nodes over the total number of network nodes).
The y-axis is the relative estimated value (estimate value over the true value).
We display [5%, 95%]-con dence intervals for all  gures.
A [5%, 95%]-con dence interval of random variable z, is de ned as the interval [L, U ] such that Pr [z   L] = 0.05 and Pr [z   U ] = 0.95.
Thus, Pr [z   [L, U ]] = 0.9.
To estimate the con dence interval, each simulation was run independently 100,000 times.
The values L and U are estimated by the 5th and 95th percentile values respectively.
In subsections 6.2 and 6.3 we compare the prior art algorithms method with the random walk approach described in this work.
For comparison we consider the following approaches: (1) the estimator based on random walk combined with ego network exploration described in [25] (labeled RW Ego network); and (2) the estimator based on Metropolis-Hastings sampling with ego network exploration described in [13] (labeled MH Ego Network).
The estimator described in subsection 4.1 is labeled random walk.
In the random walk estimator (our approach) the number of mined nodes is exactly the random walk s length, while in the Ego network algorithms (prior art) the mined nodes include the (sampled) walk nodes as well as their neighbors.
In subsection 6.4 we compare prior art node collision estimator [14, 15] (labeled node collision) with the new proposed neighbor collision estimator (labeled neighbor collision).
Figure 2 displays con dence intervals for all algorithms and datasets.
The proposed random walk estimator sig-ni cantly outperforms ego network estimators.
Speci cally, using only 1% of the network size, the con dence intervals of the random walk estimator are about  fty percent tighter for the DBLP network and four times as tight for the Orkut, Flickr, and LiveJournal networks.
The exact numbers are enclosed in Table 3.
Network
 Orkut Flickr LiveJ random walk [0.967, 1.033] [0.916, 1.085] [0.891, 1.111] [0.951, 1.054] MH Ego RW Ego [0.942, 1.051] [0.583, 1.468] [0.557, 1.415] [0.816, 1.200] [0.910, 1.073] [0.426, 1.658] [0.064, 2.023] [0.645, 1.329] Table 3: Network average clustering [5%,95%]-con dence interval for 1% mined nodes.
In this subsection there is no prior art algorithm for comparison.
To have a baseline, we retro t the ego network estimator for computing the global clustering coe cient.
The global clustering coe cient can be viewed as a weighted sum of local clustering coe cients.
The ego network sampling es  1) timators multiplies each observed cxk by wk = dxk (dxk and divide the total by the sum W = (cid:2) Figure 3 displays con dence intervals for all algorithms and datasets.
The proposed random walk estimator sig-wk.
k ni cantly outperforms ego network estimators by an even greater margin when compared with the network average clustering coe cient estimators.
The curve for metropolis hasting ego network in missing in the Flickr graph because all the values are greater than 8, which demonstrate the estimator s ine ciency.
In the LiveJournal graph, one can see the upper 95% curves are even increasing.
These curves converge only after 5% of the network is sampled.
Using only 1% of the network size, the con dence intervals of the random walk estimator are about three times tighter for the DBLP network and ten times tighter for the Orkut network.
The ego network estimators for the Flickr and LiveJournal networks are extremely inaccurate in the [0.1%, 2%] range.
The exact numbers are enclosed in Table 4.
Network
 Orkut Flickr LiveJ random walk [0.869, 1.180] [0.892, 1.130] [0.922, 1.078] [0.620, 1.523] MH Ego RW Ego [0.659, 1.919] [0.424, 2.711] [0.212, 10.07] [0.235, 4.275] [0.609, 1.485] [0.317, 3.068] [0.176, 1.588] [0.246, 3.051] Table 4: Global clustering [5%,95%]-con dence interval for 1% mined nodes.
In this subsection we compare the node collision and neighbor collision estimators.
In all estimators the number of mined nodes is exactly the random walk s length.
We used m = 2.5%r as the separation parameter for all estimators.
Namely, we used about 95% of the maximum number of (k, l) pairs (|I|   0.95r2).
In Figure 4 we see that the neighbor collision estimator outperforms the node collision estimator.
The node collision estimator and neighbor collision estimator are  n/C and  n/ n respectively.
The performance of the estimators depend on the variance of  n, C, and  n.
The performance of the neighbor collision reduces the variance of one factor, but retains the variance of  n.
Therefore, we see a di erent performance impact on these   1 x+x2   +x2k datasets.
Moreover, the fact that explains why the neighbor collision estimator has a greater impact on performance in the early stages of convergence when r is small.
1 x Using only 1% of the network size, there was a signi cant accuracy improvement in the DBLP network, a noticeable improvement for the Orkut network, and negligible improvement for the Flickr and LiveJ networks.
The exact number are enclosed in Table 5.
The second column is prior art node-collision estimator; the third column is the proposed new neighbor collision estimator; and the fourth column is the con dence bound improvement10.
We presented algorithms for estimating the (1) network average clustering coe cient; (2) global clustering coe -cient; and (3) the number of registered users.
These algorithms use the information collected by random walk, namely, the ids of the visited nodes along with their adjacency list.
95% con dence implies a (0.384 0.221)/0.384 improvement and the change in the 5% con dence from 0.752 to 0.815 implies a (0.815   0.752)/(1   0.752) improvement.
545e u l a v n o i t a m i t s e e v i t a l e
 e u l a v n o i t a m i t s e e v i t a l e














 DBLP network RW Ego network MH Ego network Random walk




 Percentage of mined nodes Flickr network RW Ego network MH Ego network Random walk




 Percentage of mined nodes e u l a v n o i t a m i t s e e v i t a l e
 e u l a v n o i t a m i t s e e v i t a l e











 Orkut network RW Ego network MH Ego network Random walk




 Percentage of mined nodes LiveJournal network RW Ego network MH Ego network Random walk




 Percentage of mined nodes Figure 2: Estimation of the network average clustering coe cient con dence interval vs. the percentage of mined nodes.
Network
 Orkut Flickr LiveJ Node [0.752, 1.384] [0.849, 1.187] [0.846, 1.203] [0.780, 1.232] Neighbor [0.815, 1.221] [0.860, 1.161] [0.843, 1.208] [0.785, 1.218] improvement [25.4%, 42.5%] [7.30%, 13.9%] [1.91%, 2.40%] [2.27%, 6.03%] Table 5: Network size [5%,95%]-con dence interval for 1% mined nodes.
For the clustering coe cients algorithms we showed that (1) for social-network like graphs these algorithms considerably outperform prior art (sampling the ego network of each sampled node); and (2) an analytic bound on the number of steps required for convergence.
For the number of registered users algorithm we showed, both analytically and experimentally, that the new suggested algorithm is strictly more accurate than prior art node collision algorithms.
Ego network algorithms sample all the adjacency lists of nodes in the random walk, while the random walk estimator samples only two nodes from this list (previous and next node of the random walk).
Investigating between these two extremes might give rise to further improvement.
