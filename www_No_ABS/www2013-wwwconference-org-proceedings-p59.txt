The Transport Layer Security (TLS) protocol provides secure channels between browsers and web servers, making it fundamental to user security and privacy on the web.
As a Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
critical step, TLS1 enables clients to verify a server s identity by validating its public-key certi cate against a set of trusted root authorities.
If that validation fails browsers cannot distinguish between actual attacks and benign errors (such as a server miscon guration).
Instead, browsers display a warning and ask the user to decide whether continuing is safe.
Unfortunately, multiple studies have shown the proclivity of users to click through browser warnings, thus negating any security provided by TLS [22, 43, 44].
One reason is the prevalence of warnings even under benign scenarios.
User attention is  nite and excessive warnings tire users out, leading to  click-whirr  responses that just dismiss all warnings without due thought [19].
Improvements in warning design do not help here as they provide bene t only if users pay attention to each and every warning [44].
Unfortunately, user attention is also shared : any website that triggers a TLS warning depletes the pool.
For example, even if bank.com is cautious in its TLS deployment, warnings due to incompetentsite.com can still tire users and train them to click through all warnings.
It remains a tragedy of the commons that no individual web site has su cient incentive to conserve user attention.
We study TLS errors that trigger browser warnings.
Based on our study, we give recommendations on improving the validation logic to treat the shared attention pool more respectfully.
For our discussion, we use the broad term false warning to refer to any TLS-related dialog box raised during the lifetime of connection unless it represents an indicator of an actual man-in-the-middle (MITM) attack.
This includes errors due to server miscon guration (e.g., incomplete cer-ti cate chains) as well as self-signed certi cates and name validation errors.
We discuss the errors we study in more detail in Section 5.2.
We base our study on an extensive data set containing TLS activity of more than 300,000 users, collected passively at egress points of ten operational network sites over a nine-month period.
Di erent from prior TLS analyses relying on active scans (e.g., [12, 46]), our data set re ects what
 to the TLS protocol as used on the web, and not the TLS protocol in its full generality.
59users actually perceive as they browse the web, including accounting for the heavy-tailed nature of website popularity.
Compared to a previous study of a passive collection [18], our work encompasses a notably larger user population and focuses on the user s perspective.
Our results indicate a clear opportunity, and need, for reducing false warnings.
When examining all 3.9 billion TLS connections in our data set, we  nd that 1.54% of them trigger a false warning, an unacceptably high number since benign scenarios are orders of magnitude more common than attacks.
In Section 6, we give concrete suggestions to reduce the number of end-user warnings, based on an extensive analysis of the cases triggering them.
A novelty of our work concerns the use of browser logic for certi cate validation, including all its quirks and optimizations.
TLS implementations in browsers have evolved along with speci cations and exploits over the past  fteen years.
We noticed signi cant di erences between results returned by browser code compared to the results of using the OpenSSL libraries relied on by previous work [18, 46]: we were able to validate 95.97% of the chains in our database, as opposed to 88.16% with OpenSSL.
Section 4 further discusses the subtleties of certi cate validation in browsers.
In summary, we make the following contributions: \bullet We discuss how browsers validate TLS certi cates and highlight the importance of relying on browser code for such measurement studies.
We identify scenarios where the browser libraries di er from generic libraries like OpenSSL (Section 4).
\bullet Using passive network measurement on a population of about 300,000 users over a nine-month period, we measure the frequency and nature of TLS errors on the web (Section 5).
\bullet Based on our measurement, we make concrete recommendations to browser vendors to reduce the amount of false warnings (Section 6).
Our analysis code is available online [1].
During our research, we also identi ed and reported two security and privacy bugs in Firefox s implementation of TLS [32, 33].
We structure the rest of the paper as follows: after discussing related work in Section 2, Section 3 revisits TLS and introduces the terminology we use.
Section 4 discusses how browsers validate certi cates along with scenarios in which their behavior diverges from libraries like OpenSSL.
Section 5 explains our measurement infrastructure and the errors we study.
Finally, we discuss the results and provide recommendations in Section 6 before concluding in Section 7.
Warnings Science.
Krosnick and Alwin s dual path model represents a standard model to understand human behavior when faced with questions [20].
According to this model, humans rely upon two distinct strategies when presented with a question.
Users who optimize read and interpret the question, retrieve relevant information from long-term memory, and make a decision based on their disposition and beliefs.
In contrast, users who satis ce do not fully understand the question, retrieve only salient cues from short-term memory, and rely on simple heuristics to make a decision.
Grosklags et al. extend this model to argue that security interface designers should treat user attention as a  nite resource, a lump of attention shared by all [4].
Consuming user attention should happen infrequently, and uncontrolled consumption can lead to a tragedy of the commons scenario.
Repetitive warnings cause habituation: once users click through the same warning often enough, they will switch from reading the warning to quickly clicking through without reading (i.e., satis cing).
Users pay less attention to each subsequent warning, and this e ect carries over to other, similar warnings [4].
The link between repetition and satis cing has been observed for Windows UAC dialogs, Android install-time warnings, and browser security warnings [11, 14, 28, 44].
Usability of Security Warnings.
In 2005, an eye tracker based study by Whalen et al. found that users rarely pay attention to  passive  security indicators such as the lock icon in web browsers [48].
Dhamija et al. challenged users to recognize phishing attacks and found that 23% of their subjects ignored phishing warnings while 68% ignored the active, interstitial TLS warnings [8].
Similarly, Sunshine et al. found users clicked through active warnings [44].
Sunshine et al. proposed an improved warning design based on existing warning design literature, and observed noticeably lower click-through rates with their new design.
Nevertheless, a large number of users still clicked through the new warnings, and the authors suggested research on reducing or eliminating browser warnings.
Our work constitutes a step in that direction.
Sotirakopoulos et al. replicated the Sunshine study in 2010 and found that users learned how to bypass the new warning design [43].
Further, they noted that user studies comparing new warnings with old warnings exhibit a bias towards users not accustomed to the new warnings.
Their results indicate that habituation, and not warning design, is the main cause of high click-through rates in TLS warnings.
TLS Measurements.
The past years witnessed a noticeable increase of security incidents involving certi cate authorities, rendering the global certi cate infrastructure an attractive subject of study.
The Electronic Frontier Foundation (EFF) popularized the study of SSL infrastructure by publishing certi cate data sets obtained from actively scanning the entire IPv4 address space on port 443 in mid-2010 and in early 2012 [12], yielding 5.5 million [18] and
 Section 3, servers can rely on the SNI extension to dispatch the correct certi cate for a given domain.
IP address scans miss these certi cates.
They also cannot reliably determine if the names in the certi cate match the DNS names users use to access the site.
Holz et al. [18] provide a comprehensive measurement of the TLS infrastructure.
In addition to incorporating the 2010 EFF data set, the authors crawl the top one million Alexa domains from di erent vantage points, as well as gather cer-ti cate and connection data via passive network monitoring of a German research network.
They  nd that for their active scan sets about 60% of the chains validate.
Vratonjic et al. [46] also crawl the top one million Alexa sites and extract 300,000 certi cates (including 48% duplicates), of which only 16% validate.
Our work di ers in scale and goals.
We characterize TLS behavior as seen for 300,000 users, on the wire.
Studies relying on the Alexa lists su er from the biases of the Alexa dataset [49].
Active scans and measurements based on rankings give equal weight to all websites, which undermines their accuracy due to the long-tailed nature of tra c on the web.
that browsers use for validating certi cates.
Two examples illustrate the importance of recreating the browser validation logic correctly.
First, previous work used the OpenSSL libraries, which do not cache previously seen intermediates.
This may result in a higher number of chain errors than that experienced by end users.
Second, Holz et al. focused only on chain validation, and ignored name comparison for their passive measurement.
Validating the name in the certi cate with the DNS label that the user wanted to connect to is a critical component of the validation process, and the only protection TLS o ers against a MITM attack.
We explore these subtleties further in Section 4.4.
Evolving TLS Trust Mechanisms.
Recent work has also explored alternatives to the CA trust system.
Perspectives [47] o ers a SSH-like trust model to the existing PKI infrastructure.
Perspectives and its followup Convergence [6] both rely on network views for trusting a certi cate.
Our study makes similar assumptions, and implicitly trusts all certi cates seen on the network backbone.
Other proposals for alternate trust models include the Cer-ti cate Transparency project [23], the Country-based trust model [42], and the Sovereign Keys proposal [45].
While novel trust models hold the promise of reducing false warnings, they are still nascent and widespread adoption will take time.
Our work focuses on the TLS landscape of today, but we hope our measurements can in uence the development of these proposals.
In this section we give an overview of the TLS ecosystem, de ne terminology that we will use for the rest of the paper, and discuss the state of TLS support in browsers and web servers.
We also discuss the need for warnings in browsers and the status quo of browser TLS warnings.
TLS aims at providing end-to-end encryption for communication over the Internet.
It uses public-key cryptography for the initial key exchange, followed by symmetric encryption for the rest of the protocol.
The initial public-key handshake requires the client to authenticate the server s public key through an out-of-band mechanism.
After authenticating the server, client and server negotiate a cipher suite and a symmetric key to use for future communication.
The SSL protocol (TLS s predecessor) originated as a mechanism for encrypted communication on the web.
Despite its design as a generic transport layer mechanism, the web remains its main user.
Clients are usually browsers, and servers typically web servers such as Apache httpd and Microsoft IIS.
Server authentication occurs via a certi cate signed by a trusted certi cation authority.
Below we go into the details of TLS as used in the web.
As a running example, we consider the case of a user Alice that wants to connect to bob.com via TLS.
bob.com relies on the Honest certi cation authority to authenticate to Alice.
Concretely, when Alice visits https://www.bob.com, her browser connects to www.bob.com over port 443 where the server responds with a certi cate.
Then, the browser validates that a trusted certi cation authority signed it, and checks that it pertains to www.bob.com and no other host.
If these checks succeed, the browser uses the public key in the certi cate to setup a secure channel with www.bob.com.
Server authentication is critical to TLS  guarantees against an active network attacker.
Certi cation authorities, or cer-ti cate authorities, or simply CAs, provide this functionality on the web.
At the minimum, CAs authenticate a server s public-key by signing a certi cate tying a particular public key to one or more DNS labels.
For example, in the certi cate presented by www.bob.com, the Honest authority certi es Bob s public-key as belonging to www.bob.com.
The user agents (browsers) ship with a set of  trusted  CAs called the root store.
Server authentication proceeds only if an authority in the root store signed the presented certi cate.
Intermediate Authorities.
A CA in the trusted root store can also create and sign certi cates for other intermediate CAs; the trust relationship is transitive.
For example, Bob can present a certi cate signed by Carol, and Carol one signed by Honest.
The browser trusts Bob s certi cate if Honest is part of the root store.
This Bob\rightarrow Carol\rightarrow Honest path forms a certi cate chain.
The intermediate certi cate can be part of the certi cate sent by the web server, or the web server (Bob) can provide a URL for an intermediate (Carol) via the Authority Information Access (AIA) certi -cate extension.
This reduces bandwidth use since the browser can cache common intermediates.
It also makes the TLS server con guration easier, because the server operator does not have to worry about providing a correct certi cate chain from the intermediate and up.
Authenticating Servers.
A critical assumption of TLS lies in the correctness of certi cates issued by an authority.
In particular, Honest must only issue a certi cate for www.bob.
com after validating that the public-key in question actually belongs to the owner of www.bob.com.
Typically, CAs rely on email to the domain to verify ownership.
Since email is not a secure mechanism, an attacker on the path between the authority and the owner of the website (bob.com) can easily receive a certi cate for the same (bob.com).
Extended validation (EV) certi cates, indicated in the browser URL bar by a distinctive green color and the name of the entity owning the certi cate, involve further checks, such as physical presence requirements.
It is not clear users understand the di erence between regular domain validated (DV) and EV certi cates.
An attacker with a DV certi cate can present it in place of the legitimate domain s EV certi cate, and the web browser will accept it.
Only the missing green bar in the browser interface would indicate the absence of an EV certi cate.
Web servers ask the CA for a certi cate tying the public key to their DNS label.
When Alice connects to the web server, the server presents this certi cate, and Alice then continues with the rest of the session.
Name-based virtual hosting complicates this simple scenario.
For example, consider the case of a web server that hosts both bob.com and example.com.
When the server receives a connection from Alice s browser, it needs to know which domain Alice wants to connect to so that it can present the correct certi cate.
The Server Name Indication (SNI) extension [10] allows a client to indicate the intended domain, allowing the server to return the appropriate certi cate.
Apache s httpd supports SNI since 2009, while Microsoft s IIS added support in 2012.
As we discuss in Section 5.1, we rely on SNI support in browsers (not servers) for our study.
below.
As the most common client-facing component of TLS, web browsers exert a tremendous in uence on the evolution of TLS.
By controlling the root certi cate store, browsers determine the list of CAs that the web relies on to provide security.
Furthermore, by supporting speci c cipher suites and TLS extensions browsers in uence their widespread adoption.
As of this writing, all desktop browsers support TLS 1.0, only Google Chrome supports TLS 1.1, and no desktop browser supports TLS 1.2 by default.
Further, all modern desktop browsers support SNI.
For mobile devices, Android supports SNI since version 3.0 and iOS supports SNI since version 4.0.
Current versions of all major browsers, except for Mozilla Firefox, support the AIA extension.
All major browsers also cache any valid intermediate certi cates seen in the past.2
 Relevant to our work is the behavior of browsers in case of a failure during server authentication.
In addition to a man-in-the-middle (MITM) attack, authentication failures also occur in a wide variety of benign scenarios (Section 5.2).
It is di cult for browsers to distinguish malicious scenarios from benign ones.3 Instead, browsers present users with a warning page informing them of the error, and warning of a possible MITM attack, for all authentication errors.
Browsers also allow users to bypass the warning, and continue with their session; in e ect, forcing the users to distinguish a benign scenario (false warning) from a malicious one a distinction most users cannot make.
Warnings raised due to TLS errors belong to two broad categories.
First, there exist interstitial warnings shown when the top-level page contains an error.
This has been the focus of previous warnings research in browsers.
Another class of warnings occur when secondary resources, e.g., images, scripts, etc., result in a TLS error.
Browsers currently show a mixed content warning when secondary resources on a page fail to load due to a TLS error.
Recall the Lump of Attention model (Section 2).
Our study assumes that mixed content and top-level page warnings both consume user attention.
Over-consumption of user attention is an externality on the security of the whole TLS ecosystem.
Understanding the reasons for TLS warnings provides us with insight into the current state of TLS, as well as concrete guidance on areas to focus on for improvement.
Reducing the number of false warnings raised by browsers is key to improving assurance in the TLS ecosystem.
Rare warnings encourage optimizing behavior over satis cing and push users to understanding the warnings before making an informed decision.
This work focuses on understanding the prevalence of TLS errors to enable reducing the number of warnings, not on improved warning design.
Previous work on warning usability also stressed the importance of reducing the number of warnings [43, 44].
even in Firefox s private browsing mode (Bug 808331 [33]).
support [16], browsers can make this distinction and show an error instead of a warning.
Like most complex web standards, certi cate validation logic in browsers evolved simultaneously with and ahead of speci cations like X.509 [7, 41].
Browsers need to support a wide variety of erroneous behaviors, and need to balance security, usability, standards, and backwards compatibility.
In cases of underspeci ed behavior, browsers can behave di er-ently from standard system libraries like OpenSSL, GnuTLS, and SChannel.
In some cases, browsers intentionally deviate from the speci cation for backwards compatibility.
In this section, we go into the details of how the Network Security Services (NSS) [36] library, used by Firefox (and Chrome on Linux), validates a certi cate.
We also discuss the subtleties of reproducing this behavior for our analysis.
For ease of exposition, we break down certi cate validation into three separate steps: chain building (Section 4.1), chain validation (Section 4.2), and name validation (Section 4.3).
In reality, these steps do not execute sequentially and often intertwine.
We end the section with a comparison of the OpenSSL library (used in previous work) and NSS (the library we rely on).
After receiving a certi cate from the web server, the browser needs to generate an appropriate permutation of cer-ti cates that chains up to a trusted certi cate.
The set of trusted certi cates in the root store changes over time, and our measurement infrastructure needs to ensure that it uses the correct root store based on the timestamp of the connection.
Ideally, the web server correctly presents the whole chain, including any intermediates, in the reply sent to the browser.
In practice, this is often not the case: servers may only send the end-host certi cate, not include any chain, present an incomplete chain, include additional unneeded certi cates, contain duplicate certi cates, or have the wrong order.
To the best of our knowledge, all major browsers cache a valid intermediate certi cate seen in a connection, and reuse it to validate connections in the future.
Browsers try to build a valid certi cate chain using the information the server sent as well as any other intermediate certi cates in cache.
Such caching implies that the browser s ability to validate a speci c certi cate depends on the current state of its certi cate store.
A user visiting a website which does not supply all necessary certi cates will see a warning if the browser has not seen the missing intermediate in the past.
This is a widespread problem.
In our data, 8.13% of the valid chains exhibited this behavior.
Instead of including the required intermediate as part of the certi cate chain, websites can include a URI in the AIA  eld that points to the intermediate.
Browsers either reuse existing intermediates, or download them from the URI listed.
Unfortunately, Firefox lacks AIA support, and Chrome o ers preliminary support.4 Internet Explorer supports the AIA extension, and Microsoft properties commonly rely on it.
Chain building can also face the opposite problem: extra certi cates give the library multiple paths to choose.
Browsers di er in their behavior for such a scenario.
Firefox chooses one path, and raises a warning if the chosen path does not work.
While trying to follow a single path to its end,
 for AIA fetches.
paths, and uses any path that succeeds.5
 At the end of chain building, the browser has found a permutation of certi cates, starting from that of the website and ending at a trusted certi cate in the root store.
The browser then proceeds to check this chain for expiration, revocation, and name/length constraints.
Expiration.
Certi cates are valid for  xed periods.
The Not Before and Not After  elds of the certi cate encode this information.
For each certi cate in the chain, the browser veri es that the current date falls in between the period de ned in the certi cate.
Since we run our analysis o ine after the connection took place, it is critical that we use the appropriate time when validating a certi cate chain.
Revocation.
Malicious actors can steal private keys, or exploit vulnerabilities in certi cate issuance systems to get certi cates for DNS labels that they do not control.
Worse, attackers can also issue themselves an intermediate certi -cate, allowing them to MITM arbitrary tra c.
Certi cate revocation lists (CRLs) [7] and the OCSP service [41] provide a mechanism to check the validity of an intermediate or leaf certi cate.
The browser needs to check every certi cate in the chain for revocation.
For extreme cases, like the recent DigiNotar incident [24], browsers hardcode a list of untrusted certi cates [35].
A notable exception here applies to Chrome, which relies on its own distribution mechanism for certi cate revocation information [21] and does not make any CRL or OCSP requests.
Name and Path Length Constraints.
Certi cate Authorities can place usage limits on the intermediate certi -cates they issue.
The path length constraint limits the number of intermediate certi cates below the issued certi cate.
A number of zero means that an intermediate cannot issue any intermediate certi cates.
Similarly, name constraints can limit the intermediate to only issue certi cates for certain sub-domains.
For example, an intermediate constrained to *.example.com cannot issue certi cates for *.bank.com.
All modern browsers support name and path constraints, but since authorities rarely employ it, browser support remains relatively untested.
After a browser has built a certi cate chain it deems valid, it checks that the hostname the user tried to connect to matches a name in the certi cate.
Note that this is the only defense against MITM attacks, and as such represents a critical step of the certi cate validation process.
An attacker can always get a perfectly valid chain for his own attacker.com domain, and present it when the user tries to connect to bank.com.
Only the name veri cation check prevents a successful man-in-the-middle attack.
The Common Name (CN)  eld in the certi cate subject contains the domain name(s) for which it is valid.
For ease of administration, common names can contain wildcards to cover all sub-domains (e.g., a certi cate for *.paypal.com).
NSS  name validation function restricts the occurrence of asterisks in the certi cate subject to the initial part of a domain name.
Further, the asterisk only matches one
 behavior.
level of names.
For example, *.example.com cannot match one.two.example.com.
The Subject Alternative Name (SAN)  eld enables a cer-ti cate to include a list of names, instead of just one.
This allows an owner of multiple domains to share the TLS infrastructure.
For example, YouTube serves a certi cate valid for (amongst others) *.google.com as well as *.youtube.com.
In our data, we have certi cates listing up to 545 di erent names in this  eld.
RFC 2818 [39] and RFC 6125 [40] describe how HTTP uses TLS and speci es that clients should only consider the last (most speci c) common name  eld in a certi cate subject.
It also requires clients to ignore the common names if the SAN extension is present.
A novelty of our work concerns the use of TLS libraries to emulate browser behavior.
Speci cally, we opt to use NSS instead of OpenSSL to validate certi cate chains.
While OpenSSL serves as an all-purpose low-level cryptography library for easy and deep access to cryptographic routines, NSS provides a higher level TLS abstraction in the browser context.
Firefox and Google Chrome rely on the NSS libraries for SSL/TLS.
For example, the chain-building algorithm of OpenSSL is strict and can reject chains with super uous certi cates.
In contrast, NSS maintains its own database to keep track of any valid intermediate certi cates encountered in the past, self-signed site certi cates added by the user, and cases where a user permanently overrides a security error.
In addition, NSS contains a hard-coded list of root certi cates.
During certi cate validation, NSS tries to use all available certi cates to build a valid chain.
NSS  chain resolution algorithm is lenient and can accept chains rejected by OpenSSL.
This divergence resembles the divergence in HTML parsing in browsers and parsing libraries.
For backwards compatibility and usability reasons, browsers need to be more forgiving of HTML syntax than most libraries.
Similarly, the NSS library needs to be more forgiving than a library like OpenSSL.
The di erence in chain validation directly a ects the results of any measurement study.
Using NSS, we were able to validate 95.97% of all the di erent chains we saw.
In contrast, OpenSSL was only able to validate 88.16% of the unmodi ed chains.
Furthermore, OpenSSL does not o er any builtin functionality to check if a certi cate validates for a given host-name.
Checking the hostname against the certi cate is the only defense against MITM attacks.
Previous work either skipped name validation [18] or wrote a custom validation function [46].
Validating a host name to a certi cate is nontrivial.
Recently, Georgiev et al. found a number of critical vulnerabilities in certi cate validation due to developers having to implement their own code for host name validation, instead of relying on the library [15].
Fahl et al. presented similar  ndings in Android applications [13].
Having discussed the modus operandi of browser validation, we now study the prevalence of TLS errors on the web.
We brie y explain our passive monitoring infrastructure in Section 5.1 and refer to Amann et al. for further details [2].
Section 5.2 presents a categorization of the errors we study.
Finally, we present and discuss our results in Section 6.
The ICSI networking group collects TLS/SSL session and certi cate information from ten research, university, and government networks.
These networks represent a user base of about 300,000 users.
This data collection began in early 2012 and the number of contributing sites has steadily increased.
Overarching goals of this data collection e ort include enabling empirical research of the TLS ecosystem as well as helping to understand its evolution and design.
Amann et al. provide a full introduction to the data collection infrastructure [2].
Infrastructure.
Each of our data providers operate an internal network from which TLS connections originate to the Internet.
As the tra c crosses the network border, the Bro network monitor [37] inspects the tra c for policy violations and intrusions.
Bro s dynamic protocol detection identi es SSL/TLS tra c independent of the transport-layer port [9].
At each site, we provide the operators with a script that, for each TLS/SSL connection, logs the SNI extension header value (if available), the complete server certi cate chain, and the timestamp of the connection.
Due to privacy concerns, our script does not record any information that identi es a client system directly.
Every hour, the script uploads the ASCII-formatted log les to a storage machine at ICSI.
Some sites process nearly two million SSL/TLS connections at peak hours.
Data.
Our data covers a period of nine months, ranging from February to November 2012.
We successfully captured a total of 11.5 billion SSL connections on all ports.
Of these, 10.2 billion connections connect to port 443 (the default HTTPS port).
We further  lter these connections by removing connections due to grid computing, connections that resumed a previous session and did not exchange any certi cate, and connections that did not have the SNI  eld set.
This leaves us with 3.9 billion connections that exchange at least one certi cate and exhibit a SNI value.
The total number of distinct SNIs in our  nal data is 9.8 million.
The total number of distinct certi cates is 496,742.
Reproducing Browser Validation Logic.
Using NSS outside the browser context poses a number of challenges.
Because the developers of NSS geared the library towards browsers, it lacks convenient APIs for standalone usage.
NSS does not come with extensive documentation and example code; requiring aspiring users to dig deep into the code base.
Furthermore, NSS is aimed at browsers and lacks some of the functionality needed for large-scale analysis.
We developed wrapper libraries to facilitate certi cate validation with NSS, OpenSSL (for comparison), as well as a NSS patch which allows veri cation of large numbers of certi cate chains.
Our code is freely available online under an open source license [1].
We used NSS 3.13.6 with the aforementioned patch to generate all numbers.
In this study, we focus on a subset of errors that cause an overridable warning to appear, i.e., a warning that allows users to continue despite a TLS error.
In Firefox, users can only override errors related to certi cate validation.
Similar to the structure in Section 4, we classify these errors based on where they occur, namely, during chain building, chain validation, and name validation.
Recall that the three phases discussed above are only for exposition, and do not correspond to any modularization in Figure 1: Certi cate validation error  owchart.
The root and intermediate store contains all the valid intermediates in our full dataset.
the NSS code.
As a result, our classi cation of errors also does not directly correspond to NSS error codes.
Figure 1 presents the algorithm we use for translating the NSS responses into our categorization.
We expand on this further below.
An error during chain building occurs if the browser cannot  nd a permutation of certi cates that links a certi cate for the website to a trusted root.
is unable to create a chain from the server certi cate to a trusted certi cate authority.
This typically happens when the server certi cate issuer is neither present in the NSS root store, nor is it one of the valid intermediates we saw throughout our experiment.
is a certi cate with an unknown issuer whose subject and issuer are the same.
We created a separate category for this error due to its prevalence.
Personal use devices, such as routers, music players, and disk drives, commonly use self-signed certi cates.
We use the NSS is_root  ag to classify certi cates as self-signed.
This is the same  ag used by the Firefox browser to identify self-signed certi cates for its warning page.
either include all the intermediates it needs to chain back to a trusted root, or include an AIA  eld pointing to the requisite intermediate certi cates, or just hope that the missing intermediates are present in the user s cache.
Among Load Certi cateRoot & Interm.
CA Storeis_root?Firefox validation functionNSS error?Expired Cert orExpired IssuerUntrusted or Unknown IssuerNSS name matchingExpired Certi catematches?UnknownIssuerNon-overridable ErrorValid Certi cateCerti cate for wrong domainYesNoYesNoYesYesNoNoYesNoSNIBegin ValidationSelfsigned Certi cate64the major browsers, only Firefox does not support the AIA extension and may fail to build a working chain in the absence of a needed intermediate certi cate.
Measuring the prevalence of this error is subtle since Firefox caches all valid intermediates it has seen in the past, even across browser restarts.
We bound this error by testing all unique chains with caching turned on and caching turned o .
The exact number of errors experienced by each user depends on the individual user s browsing history.
Since our data does not allow us to identify individual users, exact measurement is impossible.
These errors map directly to the individual phases discussed in Section 4.2.
valid for a speci c period.
If a server sends a certi cate that is no longer valid, but was valid in the past, NSS classi es it as an expired certi cate.
While most servers renew their certi cates before they expire, we also  nd several that fail to renew before the expiration date.
sons, CAs use revocation for administrative reasons.
Chrome maintains its own revocation list, free of revocations caused by administrative reasons [21].
In contrast, Firefox and Internet Explorer check CRLs and use OCSP requests to check the status of certi cates.
Our measurements allow us to bound the impact of revocation, and individual design decisions (e.g., Chrome s decision) on user visible warnings.
A name validation error occurs when a name is not found in the certi cate matching the domain that the user connected to.
Figure 2 illustrates our classi cation algorithm that further breaks down a name validation error into the subcategories we explain below.
We focus on possible changes in the browser name validation logic that could ameliorate these errors.
does not work for www.bank.com and vice versa.
In the past, browser developers turned down requests to change this behavior [29].
Our study helps empirically measure the impact of this decision.
Note that we reuse the NSS name validation function, and do not write our own validation function for this category.
asterisk in a name can only match one level of names in the initial part of the DNS label.
A more permissive function that matches asterisks to an arbitrary number of sub-domains (while still ensuring that it is the same TLD+1) could accept more certi cates and reduce the number of warnings shown to users.
We measured this via our own implementation of such a relaxed matching algorithm, which is available online as part of our code release [1].
sub.example.com receives a certi cate for example.com, it is arguably a lower threat than an invalid certi cate chain.
Note that browsers already do not fully isolate sub-domains; e.g., the cookie policy does not isolate sub-domains.
Arguably, a name validation error in which the SNI and the presented certi cate share the registered domain is lower risk than if the presented certi cate is for a totally di erent domain.
Identifying the registered domain in a given DNS label is tricky: each top-level domain (e.g., .in) has its own policy on the su xes under which users can directly register names.
For example, the registered domain for test.example.in is example.in, but it is not gov.in for example.gov.in.
This is because .in allows registrations under both the .in as well as .gov.in su xes.
We use the Mozilla maintained public su x list to identify the registered domains for a given DNS label [38].
the standard [39], Firefox ignores multiple common names in a certi cate and chooses the last common name in the certi cate.
Firefox also ignores the common name  eld if the subject alternative name  eld is present.
We measure the impact of this behavior by manually extracting all the names in a certi cate and, for each, directly calling the name validation function used by Firefox.
In addition to the errors discussed above, a number of other errors, which we seldom encounter, are not overridable by user.
Examples for these errors are invalid encoded cer-ti cates, name constraint errors, or path length errors.
Since we focus only on user-overridable errors, we ignore them.
We assume that the network monitor does not encounter man-in-the-middle attacks.
Practically, this means that an active network attacker near the web server can a ect our measurements.
We deem this a reasonable assumption since CAs already make a similar assumption while issuing DV certi cates.
We collect data from a large number of academic and research institutions, representing nearly 300,000 users.
The data collected may not represent the global TLS ecosystem.
As part of our agreement, the data we collect cannot identify individual users.
Thus, our data may over-represent a single user or a group of users.
We only look at connections using the SNI extension.
All modern browsers send the SNI extension.
38% of connections in our data do not use the SNI extension.
The warnings for this fraction could diverge from rest of the connections.
As we noted in Section 5.2.1, due to the caching of intermediates, we can only bound the errors in chain building.
Similarly, Firefox allows users to cache certi cate error overrides and to import additional root CAs.
Thus, our error measurement may not represent the warnings shown to users.
Our model assumes that top-level warnings and mixed-content warnings consume the same user attention budget.
If users separate these two warnings, our numbers might not apply directly.
Unfortunately, the network monitor cannot easily distinguish top-level loads from secondary loads.
Further, mixed content warnings also occur due to including HTTP content in a HTTPS page.
Our measurements do not measure the impact of these errors on the user attention budget.
98.46% of the  ltered connections validate correctly, im- plying a false warning rate of 1.54%.
The massive di erence in the base-rates of hijacked connections versus connections that occur in benign scenarios makes the 1.54% error rate crushing.
For example, consider what happens if an attack occurs only once in a million connection attempts.
A 1.54% false warning rate means that the million connections cause
 in multiple outputs.
Error Connections Certi cates











 Table 1: Break up of benign errors into categories.
The connection column indicates percentage of all erroneous connections.
is not surprising that humans train themselves to ignore the warnings, thus clicking through the one true warning.
Reducing the false warnings rate is critical to improving TLS security.
In this section, we discuss our results in full details based on the error categorization we presented in Section 5.2.
For each error category, we measure the number of connections we see the error for.
Users access some erroneous services an overwhelming number of times.
To reduce the impact of such services, we also measure the number of certi cates we see for each error category.
Note that a single certi cate corresponds to multiple connections, and thus can fall into multiple categories.
We structure the discussion into three parts:  rst, we discuss errors caused by server miscon gurations/errors.
This includes chain validation errors (Section 6.1) and name validation errors (Section 6.2).
Another class of errors occurs due to browser design decisions, such as AIA and revocation support.
We measure and discuss the impact of these decisions in Section 6.3.
Based on our analysis, we also make concrete recommendations for reducing warning fatigue.
Our recommendations center around three approaches: warning design to help focus user attention on high-risk events, browser modi cations to conserve user attention, and technical innovations to ease TLS deployment and reduce errors.
Results.
Table 1 breaks up the benign errors we see into the categories de ned in Section 5.2.
The  rst column lists the number of errors as a percentage of total connection errors, and the second column lists the number of certi cates that manifest the particular error.
Note that a particular certi cate can occur multiple times in the second column: e.g., the same certi cate can raise a name validation error in one connection and an expired certi cate error in another.
Below, we analyze these results and provide recommendations.
Unknown Issuer and Self-Signed Certi cates.
The overwhelming majority (73.50%) of erroneous connections involve unknown issuers or self-signed certi cates.
This indicates that a large number of websites opted out of the CA infrastructure.
Unfortunately, an unknown issuer also represents a high-risk scenario.
Reducing the severity of the warnings in such cases is infeasible.
Instead, we emphasize technical measures to reduce the prevalence of such warnings in benign scenarios.
One of the reasons administrators opt-out of the CA infrastructure is the perceived cost of buying a valid certi cate from a trusted authority.
Recently, StartCom, a certi cate authority trusted by all modern browsers, started o ering free TLS certi cates for simple use-cases [26].
Recommendation 1: We urge the community to advocate the use of free TLS certi cates via authorities like StartCom [26].
Such advocacy, or evangelism, previously saw success in pushing for web standards as well as the ongoing push for mobile web standards [27, 34].
Anecdotal evidence suggests low awareness of these free certi cates.
In some scenarios, the current CA infrastructure does not o er the  exibility needed.
For example, a router manufacturer does not know the DNS label that the router will map to, and thus cannot get a certi cate in advance.
Recommendation 2: We also suggest increasing the momentum on new standards like DNS-based Authentication of Named Entities (DANE) [17], which communicates public keys via DNSSEC.
This allows the site or device in question to declare its public-key without relying on any issuer.
Our measurements also indicate the powerful usability advantages of network-view based approaches such as Convergence [6].
These systems can massively reduce the number of false warnings, and thus make actual attacks stand out.
Unfortunately, these solutions involve contacting a  notary  server when connecting to a domain.
This is a notable privacy and performance issue.
Recent research aims to achieve Convergence-like guarantees in a privacy preserving and high performance manner [2], but further research is needed.
Matches when adding or removing 'www' from sni?Mark aswww mismatch (3a)Other CNs in SubjectMatches with NSS name matching?Mark as matching with multiple names (3d)Matches with relaxed algo?Mark as matching with relaxed algo.
(3b)SNI, Certi cateMatches with relaxed and add or remove www?Mark as matching with relaxed algo + www (3a + 3d)Matches with registered domain matching?Mark as registered domain match (3c)SNI, list of TLDsNoNoNoNoYesYesYesYesYesNoInputOutput66Error Connections Certi cates Multiple Names Relaxed Match Relaxed with WWW TLD Match









 Table 2: Break up of name validation errors into subcategories, as a percentage of total name validation errors.
Expired Certi cates.
As Table 1 demonstrates, expired certi cates are the most common form of erroneous certi -cates (Column 2 Table 1).
We examined the number of connections accessing an expired certi cate and found that the median is four accesses, and the third quartile lies at twelve accesses.
This indicates that expired certi cate errors do not occur in popular services, but are common in the long tail.
To better understand the access patterns of expired cer-ti cates, we examined all certi cates that occur in at least one connection with a timestamp larger than the Not After value.
We then computed  , the di erence of the connection timestamp to the certi cate s expiration date.
Since multiple connections may retrieve the same certi cate, we see more than one   per certi cate, and thus summarize all connections accessing the same certi cate with the minimum, maximum, and median of the   values for each certi cate.
For the minimum/median/maximum estimators, the  rst quartile lies at 2.8/5.2/6.8 days and the median at 35.8/52.8/64.7 days.
In other words, 25% of all expired certi cates are accessed only for a week after their expiry.
This suggests that 25% of domains causing an expired certi cate error renew their certi cate within a week of expiry.
From a cryptographic standpoint, an expired certi cate is no weaker than a valid one.
Using expired certi cates does not a ect con dentiality and integrity of the communication, and raising a warning adversely a ects the user attention budget.
This raises the question: why not accept all expired certi -cates, regardless of the expiration time?
Domain ownership on the web is not constant.
Ignoring expiration dates can allow past owners to serve visitors using an old certi cate.
We make the following recommendation: Recommendation 3: Accept certi cates that expired in the last week without an interstitial warning.
Rely on an info-bar instead.
Since expired certi cates are low-risk, consuming user attention for such a scenario is not compelling.
Instead, an info-bar, informing the user that the website will stop working in a week can warn the website administrator, without tiring out users.
The attack discussed above can also occur for one week in our proposal.
We believe that the need to conserve user attention trumps the low risk of such an attack.
Results.
Table 2 breaks down the name validation errors into the subcategories we de ned in Section 5.2.3.
The numbers denote the percentage of all name validation errors: e.g., 1.17% (7.92%) of all connections (certi cates) with name validation errors involved a WWW mismatch.
Unlike the previous table, a given connections can occur in more than one category.
Below, we discuss the results further.
As seen in Table 1, name validation errors form the second most common category of errors.
Note that these errors occur even in newer systems like Convergence.
We  nd that Firefox s restrictive policy on multiple names has low impact on user attention.
WWW mismatches also have a low impact in the number of connections, but a much higher impact when only looking at certi cates.
We consider name validation errors caused by WWW mismatches low risk.
Recommendation 4: Tolerate WWW mismatches in the certi cate validation logic.
Alternatively, browser vendors should show a di erent  low-risk  warning in such scenarios.
50.40% (7.24%) of connections (certi cates) with name validation errors validate if we switch to matching multiple levels with a \ast .
Accepting www mismatches increases this number to 51.51% (13.87%).
The wide prevalence of such errors indicates a misunderstanding: website administrators are not aware of the browser s limited glob expansion strategy.
In one of the bugs we  led during this work, a NSS developer also suggested switching to a relaxed matching scheme [32].
While the standard recommends against a relaxed name validation scheme, it does not prohibit it [40].
Recommendation 5: Use a more relaxed name validation algorithm that accepts multiple levels for an asterisk.
A signi cant number of errors occur where the certi cate and the connection targets match in their registered domain.
We consider this a low risk scenario and make the following recommendation: Recommendation 6: Modify the warning for sub-domain mismatches, and help focus user attention on the high-risk scenarios.
For example, the warning shown when the admin.bank.com server presents a certi cate for www.bank.com should indicate a lower risk than the warning shown when the bank.com server presents a certi cate for the unrelated attacker.com.
While a full manual analysis of the remaining errors is di cult, it appears that a large number of errors occur due to content distribution networks (CDNs) such as Akamai, EdgeCast, CloudFlare.
Popular websites like Facebook rely on CDNs to serve content.
We  nd a number of connections with a SNI value of facebook.com but a server certi cate for a CDN such as Akamai.
We believe that the reason for the prevalence of these errors is the di culty of detecting and diagnosing such errors.
Consider an image load with an onerror event handler that logs load failure.
The browser s error event does not provide any information about the cause of a load error.
Thus, the certi cate error at the CDN, likely caused due to a miscon guration, is indistinguishable from a missing image (a 404) or an error in the user s network connection.
We posit that this makes it di cult for large-scale websites such as Facebook to detect and diagnose these intermittent TLS issues with their CDN providers.
Recommendation 7: Browsers should provide the onerror event with information about the certi cate validation error, if any.
This information allows the website administrator to log and track down any issue.
Connections Number







 Table 3: Impact of browser design decisions on false warnings.
Recommendation 9: Switch to separate administrative and security revocation lists, with distinct warnings for each.
Since the number of connections using certi cates in the security revocation list is small, browsers should consider errors due to the security revocation lists a hard fail, and not consume the user attention with an overridable warning.
In the past, Facebook raised a similar concern with browser handling of script errors, and browser vendors modi ed code to accommodate Facebook s need to diagnose such errors [3].
As TLS achieves wider  always-on  deployment, easily diagnosing errors will become critical.
Results.
Table 3 outlines the results of our measurement of the impact of AIA, caching, and revocation lists on false warnings.
The  rst two rows measure the impact of intermediate caching and AIA fetching: 21,449,989 connections fail with both disabled, 1,623,047 fail with just intermediate caching disabled.
The next two rows measure the impact of revocation lists used: the third row measures the connections that fail due to Chrome s CRL, while the last row measures the connections that fail with the normal CRLs.
We discuss the results further below.
Incomplete Chains.
Recall that incomplete chains can still verify due to cached certi cates.
To measure the impact of caching of intermediate certi cates, we disabled caching and tried to validate all unique chains in our data.
This caused 8.13% of the valid, unique chains (or 29,661 chains) to fail validation.
The AIA extension allows a server to send an incomplete chain, but include a URL to fetch the requisite intermediates from.
Among the major browsers, only Firefox does not fetch intermediates mentioned in this  eld.
To measure the impact of this decision, we took the 29,661 chains that failed due to a missing intermediate, and tried to validate them with AIA fetching enabled.
We found that 98.48% of chains that did not validate with caching disabled successfully validated with AIA fetching enabled.
Disabling AIA support puts an unnecessary burden on end user attention budget.
Despite being valid, each of the 19,826,942 connections and 29,211 certi cates can cause a TLS warning on a clean cache.
Problems with enabling AIA support include possible privacy implications.
Alternative approaches like preloading the browser with all intermediate authorities can also achieve similar results, without the privacy impact [31].
Recommendation 8: Enable AIA support or preload all known intermediate authorities in the browser cache.
Revoked Certi cates.
CAs use revocation for administrative as well as security reasons.
While Firefox uses the CRL as published by CAs, Google Chrome relies on its own revocation list.
Currently, Chrome s revocation list contains
 root authorities in our database have 917,284 certi cates.
As seen in Table 3, we see  ve times the certi cates present in CRLs compared to certi cates present in Chrome s list.
This di erence translates to nearly thirty three times as many errors.
It is not clear what browser behavior for the administrative revocations should be.
While the CRL format o ers a  eld to describe the reason for revocation, most authorities do not use it.
In our data, 70.9% of the CRL entries do not include a reason.
Further research into the causes of these revocations is needed to shed light on this issue.
Browsers do not consider the dangers of habituation when showing a warning.
This, coupled with the prevalence of false warnings, reduces the security of the TLS protocol, as users train themselves to click through warnings.
By measuring the prevalence of di erent types of false warnings, we provide a framework for browsers to reevaluate their current warning mechanisms and conserve user attention.
We also presented a number of concrete recommendations based on our analysis.
We have shared our data and results with browser vendors, and already received positive and encouraging feedback.
We would like to thank Adrienne Porter-Felt, Matthew Finifter, Michael McCoyd, Kurt Thomas, Paul Pearce, Je  Hodges, and Warren He for taking time to read drafts of this paper.
We would also like to thank Brian Smith, Nasko Oskov, and Adam Langley for taking time to answer our queries about browser internals.
This research was supported by Intel through the ISTC for Secure Computing; by the Air Force O ce of Scienti c Research under MURI grant numbers 22178970-4170 and FA9550-08-1-0352; by the National Science Foundation under grant numbers OCI-1032889, 0831501-CT-L, CCF-0424422, and 0842695; by a fellowship within the Postdoc-Programme of the German Academic Exchange Service (DAAD); and by the O ce of Naval Research under MURI Grant Number N000140911081.
Any opinions,  ndings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily re ect the views of the NSF, the AFOSR, the ONR, the DAAD, or Intel.
