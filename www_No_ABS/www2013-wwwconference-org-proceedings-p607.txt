Social media services such as Twitter1 and Facebook2 are increasingly used to communicate and exchange opinions

 https://twitter.com/ http://www.facebook.com/ Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
about celebrities, politicians, products, companies, stocks and events [17, 24].
These opinion-rich resources attract attention from disciplines to understand the opinions of social media users.
For example, the aggregated sentiments of tweets about politicians are used to predict poll ratings [24].
Asur and Huberman [3] exploit Twitter sentiment and content to forecast box-o ce revenues of movies, outperforming traditional market-based predictors.
Various applications demonstrate the e ectiveness of sentiment analysis in understanding opinions contained in social media.
Methods for automatically classifying sentiments expressed in product and movie reviews have been extensively studied for years [13, 20], and can roughly be divided into supervised and unsupervised sentiment analysis [25].
The supervised methods train a robust sentiment classi er from manually labeled training data.
In social media, it is time and labor consuming to obtain sentiment labels, which are essential for supervised sentiment analysis algorithms.
Given large-scale unlabeled data which can be easily collected in social media, we propose to study unsupervised sentiment analysis.
A traditional way to perform unsupervised sentiment analysis is the lexicon-based method [24, 36, 37].
These methods employ a sentiment lexicon to determine overall sentiment polarity of a document.
Lexicon-based unsupervised sentiment analysis becomes di cult due to the distinct features of social media data.
First, texts in social media are short, thus we lack su cient aggregated information to measure overall sentiment of a post [14].
Second, new expressions, like  it s coooool  and  good 9t :) , are frequently used and fast-evolving in social media.
They are not standard, but are more acceptable in social media.
Third, users may use di erent words to express their opinions in distinct domains.
It is di cult to de ne a universally optimal sentiment lexicon to cover words from di erent domains [23].
Thus it is challenging for lexicon-based methods to accurately identify the overall sentiment polarity of social media posts, which are short, unstructured, fast-evolving, and domain-speci c, though they provide convenience in instant communications for human beings.
Abundant emotional signals are observed in social media.
Emotional signals are any information that could be correlated with sentiment polarity of a document or the words in the document.
For example, when communicating in the physical world, it is common for people to supplement vocal interaction with gestures and facial expressions.
Similarly, in social media, users develop visual cues that are strongly associated with their emotional states.
These cues, known as emoticons (or facial expressions), are widely used to show
 use emoticons, they are e ectively marking up the text with an emotional state [22].
In this case, an emoticon is considered as an emotional signal.
Another example of emotional signals is the consistency theory [1], which is well-established in social sciences and was introduced to model people s emotions [20].
Emotion consistency theory suggests that words that often co-occur show the same sentiment orientation, especially when the posts are short.
Although manually labeling data is costly, massing vast quantities of unlabeled data is easy in social media.
In this paper, we exploit emotional signals contained in social media data for e ective sentiment analysis in an unsupervised manner.
Speci cally, we investigate the following problems: Are the emotional signals available in social media potentially useful for sentiment analysis?
How can the emotional signals be explicitly represented and incorporated into an unsupervised sentiment analysis framework?
Is the integration of emotional signals helpful for real-world sentiment analysis applications?
The main contributions of this paper are summarized as follows:   Formally de ne the problem of unsupervised sentiment analysis with emotional signals;   Verify the existence of representative emotional signals with statistical hypothesis testing, and propose a uni ed way to model the emotional signals;   Present a novel framework to incorporate the emotional signals into unsupervised sentiment analysis; and   Empirically evaluate the proposed framework on real-world Twitter datasets and elaborate the e ects of the emotional signals on sentiment analysis.
The remainder of this paper is organized as follows.
In Section 2, we review existing literature related to our work.
In Section 3, we formally de ne the problem we study.
In Section 4, we conduct an exploratory study to examine the potential impacts of emotional signals with social media datasets.
In Section 5, we propose an unsupervised sentiment analysis framework which considers di erent types of emotional signals in a uni ed way.
In Section 6, we report empirical results on real-world datasets.
In Section 7, we conclude and present the future work.
Sentiment analysis has been a hot topic for quite a few years [20].
Recently, as an e ective tool to understand opinions of the public, sentiment analysis is widely used in various social media applications [27], including poll rating prediction [24], stock market prediction [4], event analysis [18], behavioral targeting [38], etc.
Similar to conventional sentiment analysis on product and movie reviews, most existing methods in social media can fall into supervised learning methods [10, 15] and unsupervised learning methods [4, 18,
 data produced by social media services, unsupervised learning becomes more and more important in real-world social media applications.
The most representative way to perform unsupervised sentiment analysis is the lexicon-based method.
The methods rely on a pre-de ned sentiment lexicon to determine the general sentiment polarity of a given document.
The existing methods can be generally divided into three categories.
The  rst is to employ a group of human annotators to manually label a set of words to build the sentiment lexicon, e.g., General Inquirer [31] and MPQA [37].
The second is dictionary-based methods [2, 26], which employ a dictionary, e.g., WordNet, to learn sentiment orientation of a word from its semantically/linguistically related words mined from the dictionary.
The third is called corpus-based methods [23, 34, 39], which infer sentiment orientation of the words from a given corpus by exploring the relation between the words and some observed seed sentiment words/information, and then build a domain-dependent sentiment lexicon.
Di erent from traditional lexicon-based methods, we perform unsupervised sentiment analysis from a novel perspective.
The proposed framework considers both post and word-level sentiment-related contextual information, i.e., emotional signals, in a uni ed framework.
The proposed framework makes use of the valuable emotional signals to compensate the problem of lack of label information in social media.
Some e orts have been made to explore the e ects of emotional signals on sentiment analysis.
Zhao et al. [40] employed the emoticon related tweets to train a naive Bayes classi er for sentiment classi cation.
Bordy and Diakopou-los [6] showed that the lengthening of a word is strongly associated with its sentiment.
Li et al. [19] used the sentiment knowledge learned from one domain to facilitate sentiment analysis on another domain.
However, the proposed methods rely on one domain-dependent emotional signal to some extent.
As we discussed in the experiment, performance of some emotional signals, e.g., emoticons, is not stable when used on datasets from di erent domains.
Di erent from previous methods, we present the  rst quantitative study analyzing the impacts of emotional signals that are ubiquitous in social media.
We further provide a novel unsupervised sentiment analysis framework to make use of the interpreted emotional signals in a uni ed way.
One distinct feature of social media data is that it often provides additional information other than text.
An example of social media data is illustrated in Figure 1.
Traditional sentiment analysis methods work with  at  attribute-value data in the form of a post-word matrix, as shown in the left part of the  gure.
They assume that posts are independent and identically distributed (i.i.d.).
This assumption does not hold true in social media.
Unlike traditional platforms, social media contains emotional signals that are highly correlated with the sentiment polarity of posts and words, as shown in the right part of the  gure.
We study social media data that consists of a collection of posts with emotional signals.
This is a general setting in social media.
The posts can be a set of tweets, Facebook updates, Yelp comments, Amazon product reviews, etc.
The emotional signals could be any information correlated with sentiment of a post or words in the post.
The emotional signals can roughly be divided into two categories, emotion indication and emotion correlation, as de ned below.
De nition 1 (Emotion Indication): Emotion indication is de ned by the emotional signals that strongly re ect the sentiment polarity of a post or a word and can be easily collected from social media.
For example, emoticons correspond to sentiments expressed in posts, and they are frequently used on di erent social media platforms.
The in-608w1 w2     wj     wn p1 p2 p3   pi   pm Post   Word Matrix p p p p post-level p w w w w w word-level Emotion Correlation (cid:45) (cid:47) LOL post-level Sentiment Lexicon word-level Emotion Indication Figure 1: An Example of Social Media Data tuition is that it is unlikely for a user to include a negative emoticon in a post expressing something positive.
As shown in the bottom right corner of Figure 1, we have post-level emotion indication, including emoticons, product ratings, restaurant stars, etc., and word-level emotion indication, including some publicly available sentiment lexicons.
De nition 2 (Emotion Correlation): Emotion correlation is de ned by the emotional signals that re ect the correlation between posts or words.
For example, we can build a connection between two words in a post with emotion consistency theory [1].
The theory suggests that two frequently co-occurring words should have similar sentiment polarity.
The intuition is that it is unlikely that people will mix negative and positive words together in a short post.
As shown in the top right corner of Figure 1, we have post-level emotion correlation, like a post-post social network, text similarity between two posts, etc., and word-level emotion correlation, like consistency theory, synonym relation in WordNet, co-occurrence information in Wikipedia, etc.
m n be the post-word content matrix, where m is the number of posts and n is the number of distinct words in the posts.
The entry at the ith row and jth column of a matrix A is denoted as A(i, j).
A(i, ) and A( , j) denote the ith row and jth column of a matrix A, respectively.
(cid:4)A(cid:4)F is the Frobenius norm of a matrix A, and (cid:4)A(cid:4)F = Notations: Let X   R (cid:2)(cid:3)m (cid:3)n i=1 j=1 A(i, j)
 .
Generally, as stated by Speriosu et al. [30], sentiment analysis requires three stages: (1) topic-based message retrieval; (2) subjectivity classi cation; (3) polarity sentiment classi- cation.
This paper, like most previous work in sentiment analysis [10, 21, 30], focuses on the last stage of the process   polarity sentiment classi cation.
With the terminologies de ned above, we now formally de ne our task as following: Given a corpus of social media posts X and available emotional signals, including post and word-level emotion indication, and post and word-level emotion correlation, our task is to automatically infer the sentiment labels of the posts.
A motivation for this work is that emotional signals could be strongly correlated with the sentiment in a post or a word.
Table 1: List of Emoticons
 :-) :-( Positive Negative :) :( : ) : ( Before proceeding, we  rst introduce real-world data used in this work and investigate whether the observed emotional signals have any potential impact on sentiment analysis.
Two publicly available tweet datasets are used in our study, i.e., Stanford Twitter Sentiment and Obama-McCain Debate.
Now we introduce the two datasets in detail.
The  rst dataset used in the experiment is Stanford Twitter Sentiment (STS).3 Go et al. [10] created a collection of 40,216 tweets with polarity sentiment labels to train a sen timent classi er.
The tweets in the dataset are crawled between April 6, 2009 and June 25, 2009 via Twitter API.4 We include all the tweets and their corresponding sentiment labels in the dataset for experiment.
The second data set is Obama-McCain Debate (OMD).5 This dataset consists of 3,269 tweets posted during the presidential debate on September 26, 2008 between Barack Obama and John McCain [29].
The sentiment label of each tweet was annotated through Amazon Mechanical Turk6.
Each tweet was manually labeled by at least three Turkers.
The majority of votes for a tweet is taken as a gold standard.
We follow a standard procedure for data preprocessing.
The unigram model is employed to construct the feature space, term presence is used as the feature weight.
No stemming or removing stop-words is performed for both datasets.
Next we introduce a sentiment lexicon used in our study.
Sentiment Lexicon: A widely used manually labeled sentiment lexicon, i.e., MPQA Opinion Corpus7 (MPQA), is used in this study.
There are 2718 positive and 4902 negative words in the sentiment lexicon.
We study the potential impact of two representative emotional signals, emoticon and emotion consistency, on the sentiments via statistical hypothesis testing.
Emotion indication suggests that the sentiment of a post is likely to be consistent with its indication information.
We use the emoticons listed in Table 1 to validate whether this hypothesis holds in the two datasets.
For each of the two datasets, two groups of tweets with equal size are selected.
One group is the tweets with positive emoticons, the other is tweets randomly selected from the whole dataset.
We construct two vectors sp and sr, which represent the sentiment polarity of the tweets in the two groups, respectively.
We form a two-sample one-tail t-test to validate the existence of positive emotion indication.
We test whether or not there is su cient statistical evidence to support the hypothesis that the sentiment polarity of the


 http://www.stanford.edu/~alecmgo/cs224n/ http://apiwiki.twitter.com/ https://bitbucket.org/speriosu/updown/src/ 5de483437466/data/

 https://www.mturk.com/ http://www.cs.pitt.edu/mpqa/opinionfinder_1.html
 Verify Emotion Indication and Emotion Correlation Emotional Signal Positive Emoticon Negative Emoticon Emotion Consistency

 5.2464e-008 1.7909e-007 9.0032e-008 2.5338e-004 1.2558e-003 3.0698e-008  rst group is larger than that of the second.
The null hypothesis is H0 :  p    r   0, and the alternative hypothesis is H1 :  p r > 0.
In the formulations,  p and  r represent the sample mean of sentiment polarity of the tweets in the two groups, respectively.
Similarly, for each of the two datasets, we construct two vectors sn and sr in terms of negative emoticons.
One group is the tweets with negative emoticons, the other is tweets randomly selected from the whole dataset.
The null is H0 :  n    r   0, and alternative hypotheses is H1 :  n    r < 0, where  n and  r represent the sample mean of sentiment polarity of the tweets in the two groups, respectively.
The t-test results, p-values, are summarized in the middle two rows of Table 2.
The results show that there is strong statistical evidence, with signi cance level   = 0.01, to reject the null hypothesis in both tests on the two datasets.
In other words, the results validate the hypothesis that emotion indication is clearly correlated with the sentiments expressed in social media data.
Emotion consistency theory suggests that the sentiments of two co-occurring words have higher probability to be consistent than those of two random words.
We use hypothesis testing to validate whether this social theory still holds in the two datasets.
We  rst de ne the sentiment di erence score between two words as Dij = ||wi   wj||2, (1) where wi and wj represent sentiment polarity of the words, which are determined by the MPQA sentiment lexicon.
Then, we construct two vectors sc and sr with an equal number of elements.
Each element of the  rst vector sc is calculated by Eq.
(1), where wi and wj are words co-occurring in the same post.
Each element of the second vector represents the sentiment di erence score between wi and another randomly selected word wr.
We form a two-sample one-tail t-test to validate the existence of emotion consistency.
We test whether there is su cient evidence to support the hypothesis that sentiment di erence of the  rst group is less than that of the second.
The null hypothesis is H0 :  c    r   0, and the alternative hypothesis is H1 :  c    r < 0, where  c and  r represent the sample means of sentiment di erence scores in the two groups, respectively.
The t-test results, p-values, are summarized in the last row of Table 2.
The results show that there is strong evidence, with signi cance level   = 0.01, to reject the null hypothesis on the two datasets.
In other words, we validate the existence of emotion correlation in social media data.
By verifying the existence of the emotional signals in social media data, it paves the way for our next study of modeling the emotional signals for sentiment classi cation.
In this section, we  rst discuss how to explicitly model the two categories of emotional signals and propose a novel framework to make use of the Emotional Signals for unsupervised Sentiment Analysis (ESSA).
Post-level Emotion Indication: As we discussed, post-level emotion indication strongly re ects the sentiment polarity of a post.
The key idea of modeling post-level emotion indication is to make the sentiment polarity of a post as close as possible to the emotion indication of the post.
It can be formulated as minimizing the following loss function: (cid:4)U(i, )   U0(i, )(cid:4)2
 m c is the post-sentiment matrix, U0   R (2) where U   R m c represents the emotion indication matrix, and c is the number of sentiment classes for posts.
Our task is polarity sentiment classi cation, i.e., c = 2.
For example, U0(i, ) = (1, 0) represents that the post contains positive emotion indication, and U0(i, ) = (0, 1) negative indication.
U0(i, ) = (0, 0) represents unknown, i.e., there is no emotion indication in the post.
To avoid impacts brought by unknown elements of U0, the loss function for all the posts can be formulated as Ru I = (cid:4)G u (U   U0)(cid:4)2
 (3) where Gu   {0, 1}m m is a diagonal indicator matrix for post-level emotion indication, i.e., Gu(i, i) = 1 represents that the i-th post contains emotion indication, Gu(i, i) = 0 otherwise.
This loss function incurs a penalty if the learned sentiment polarity is inconsistent with the emotion indication contained in the data.
Word-level Emotion Indication: It has been validated in [35] that the overall sentiment of a post is positively correlated with the sentiments of the words in that post.
By modeling word-level emotional signals, we have the potential to utilize the valuable information in the sentiment analysis framework to infer sentiment polarity of a post.
Similar to modeling the post-level emotion indication, we propose to make the sentiment polarity of a word as close as possible to the word-level emotion indication.
It can be formulated by minimizing the following loss function: (cid:4)V(i,  )   V0(i,  )(cid:4)2
 (4) and considering all the words, it can be formulated as Rv I = (cid:4)G v (V   V0)(cid:4)2
 (5) where Gv   {0, 1}n n is a diagonal indicator matrix to represent whether the word contains word-level emotion indication or not, V   R n c is the word-sentiment matrix, and

 n c is the word-level emotion indication matrix.
This category of emotional signals re ect correlation between data points, i.e., posts or words.
We propose to construct a graph to represent geometric structure of the data.
In the graph, nodes represent data points, and edges represent correlation between the data points.
Now we introduce how to model the emotion correlation in detail.
post-level emotion correlation, we construct a post-post graph Gu.
In the graph, nodes represent posts in the corpus and edges represent the a nity between the posts.
The adja-(cid:4) cency matrix Wu   R m m of the graph Gu is de ned as if ui   N (uj) or uj   N (ui) otherwise .
(6) where uj is a post in the corpus, and N (uj ) represents the k-nearest neighbors of the post.
Many metrics, e.g., textual similarity and social network information, can be adopted to obtain nearest neighbors of a post, and further de ne the adjacency matrix.
(i, j) =

 u The key idea is that if two nodes are close in the graph, their labels are also close to each other.
This intuition is consistent with traditional supervised sentiment analysis, in which it is assumed that sentiment labels of two posts are more likely to be consistent when their textual similarity is high [25].
It can be mathematically formulated as minimizing the following loss function: m(cid:5) m(cid:5) (cid:4)

 Ru


 = (cid:4)U(i,  )   U(j, )(cid:4)2 u   W

 u i=1 j=1
 T r(U T r(U
 TLu

 u (i, j) = (7) where T r( ) is the trace of a matrix, Lu = Du   Wu is the Laplacian matrix [11] of the constructed graph Gu, and Du   m m is a diagonal matrix where Du(i, i) = j=1 Wu(i, j).
This loss function will incur a penalty if two posts are close in the graph but have di erent sentiment labels.
(cid:3)m Word-level Emotion Correlation: Similar to the interpretation of the post-level emotion correlation, we construct a word-word graph Gv.
In the graph, nodes represent distinct words in the corpus and edges represent the a n-ity between words.
Adjacency matrix Wv   R n n of the constructed graph Gv is de ned as v (i, j) = if vi   N (vj ) or vj   N (vi) otherwise .
(8) where vj is a word in the corpus, and N (vj ) represents the k-nearest neighbor of the word.
This matrix can also be formulated according to various metrics, like co-occurrence information, semantic similarity computed by WordNet, Wikipedia, or search engine, which have been extensively studied in Nature Language Processing literature [14].
The basic idea here is to build a latent connection to make sentiment labels of two words as close as possible if they are close in the graph Gv, and this goal can be achieved by minimizing the following loss function: Rv C = T r(V TLv
 (9) where Lv = Dv   Wv is the Laplacian matrix of Gv.
vised Sentiment Analysis Supervised learning methods have been widely used for sentiment analysis [25].
They treat sentiment classi cation as a two-topic (positive and negative sentiment) classi cation problem, and learn a classi er based on manually labeled data.
To avoid the time-consuming and expensive labeling work, emotional signals are employed in the proposed unsupervised framework to guide the learning process.
Under this scenario, with the interpretation of the two categories of emotional signals, we propose a matrix factorization based framework for unsupervised sentiment analysis.
The proposed method is built on the orthogonal nonnega-tive matrix tri-factorization model [8] (ONMTF).
The basic idea of the ONMTF model is that data instances can be clustered based on the distribution of features, and features can be clustered according to their distribution of data instances.
The principle of ONMTF is consistent with topic modeling in text mining, e.g., PLSI [12], in which each document can be represented as a mixture of the latent topics, and each word can be generated from the latent topics.
The ONMTF model is to approximate the input post-word matrix with three factor matrices that assign cluster labels to posts and words simultaneously by solving the following optimization problem: min
 O = (cid:4)X   UHV T(cid:4)2
 s.t.
U



 (10) n c + and V   R where X is the input post-word content matrix, and U   m c are orthogonal nonnegative matri-
+ ces indicating low-dimensional representations of posts and words, respectively.
The orthogonal and nonnegative conditions of the two matrices U and V enforce the model to provide a hard assignment of cluster label for posts and words.
c c + provides a condensed view of X.
While supervised sentiment analysis methods use manually labeled information to train a classi er, motivated by [26], we treat unsupervised sentiment analysis as a clustering problem, and employ emotional signals as prior knowledge to guide the learning process.
In particular, to ensure the learned latent topic space to be sentiment space, we introduce emotional signals to constrain the matrix factorization based framework from both post and word sides.
Our proposed unsupervised sentiment analysis framework can be mathematically formulated as solving the following optimization problem: min
 +  v I(cid:4)G J = (cid:4)X   UHV (V   V0)(cid:4)2 F +  u s.t.
U

 v T(cid:4)2 F +  u C T r(U

 I (cid:4)G TLu u (U   U0)(cid:4)2 U) +  v C T r(V
 TLv
 I ,  v I ,  u C,  v (11) where  u C are all positive regularization parameters which control contributions of post and word-level emotion indication, and post and word-level emotion correlation, respectively.
Note that we focus on studying the e ects of emotional signals on sentiment analysis performance, but not ways to combine them.
We can simply combine these emotional signals with equal weight in the general framework.
The orthogonal and nonnegative conditions of U and V provide a hard assignment of sentiment polarity to posts and words simultaneously.
With the optimization results, the sentiment polarity of a post ui can be inferred by f (ui) = arg maxj {p,n} U(i, j).
The optimization problem in Eq.
(11) is not convex with respect to the three variables U, H and V together.
There is no closed-form solution for the problem.
Next, we introduce an alternative scheme to solve the optimization problem.
It is di cult to give a closed-form solution for the optimization problem in Eq.
(11).
Motivated by [8], we now introduce an alternative algorithm to  nd optimal solutions for the three variables U, H, and V. The key idea is to optimize the objective with respect to one variable, while  xing others.
The algorithm will keep updating the variables until convergence.
Now we introduce the algorithm in detail.
Optimizing the objective function in Eq.
(11) with respect to H is equivalent to solving JH = (cid:4)X   UHV T(cid:4)2
 min
 (12) Let  H be the Lagrange multiplier for constraint H   0, the Lagrange function L(H) is de ned as follows: L(H) = (cid:4)X   UHV F   T r( H H ).
By setting the derivative  HL(H) = 0, we get



 T(cid:4)2



 (13) (14) The Karush-Kuhn-Tucker complementary condition [5] for the nonnegativity constraint of H gives  H (i, j)H(i, j) = 0 ; (15) thus, we obtain





 V](i, j)H(i, j) = 0.
(16) Similar to [8], it leads to the updating rule of H, (cid:6) H(i, j)   H(i, j) [UT XV](i, j) [UT UHVT V](i, j) .
(17)
 Similar to the computation of H, optimizing the objective function in Eq.
(11) with respect to U leads to the updating rule of U, (cid:7)(cid:8)(cid:8)(cid:9) [XVHT +  u U(i, j)   U(i, j) I GuU0 +  u [UHVT VHT +  u I GuU +  u CWuU + U  C DuU + U + U ](i, j) U ](i, j) (18) The details are given in Appendix A.
Similarly, optimizing the objective function in Eq.
( 11) with respect to V leads to the updating rule of V, V(i, j)   V(i, j) (cid:7)(cid:8)(cid:8)(cid:9) [XT UH +  v I Gv V0 +  v [VHT UT UH +  v I GvV +  v CWv V + V  C DvV + V + V ](i, j) V ](i, j) (19) The details are given in Appendix B.
In summary, we present the computational algorithm of optimizing Eq.
(11) in Algorithm 1.
In the algorithm, we conduct initialization for indicator matrix, Laplacian matrix, and the three matrices to be inferred from line 1 to 3.
T is the number of maximum iterations.
The three matrices are updated with the updating rules until convergence or reaching the number of maximum iterations.
The correctness and convergence of the updating rules can be proved with the standard auxiliary function approach [28].
I ,  v I ,  u C ,  v
 Algorithm 1: ESSA: Exploring Slang Sentiment Words for Sentiment Analysis Input: {X, U0, V0,  u Output: V





 Update H(i, j)   H(i, j) [UT UHVT V](i,j) [UT XV](i,j) (cid:10) [XVHT + u
 GuU0+ u
 [UHVT VHT + u
 GuU+ u
 WuU+U  Du U+U +

 ](i,j) ](i,j) [XT UH+ v
 Gv V0+ v
 [VHT UT UH+ v
 Gv V+ v
 Wv V+V  Dv V+V +

 ](i,j) ](i,j) (cid:6) Update U(i, j)   U(i, j) (cid:6) Update V(i, j)   V(i, j)

 t = t + 1
 10: end while
 In some social media applications, it is possible that more emotional signals from multiple sources are available.
For example, product ratings from Amazon, restaurant ratings in Yelp, etc.
are potentially correlated with the sentiment polarity of the posts.
These sources could be useful to be included in the proposed framework as post-level emotion indication information.
Also, as we discussed, for word-level emotional signals, WordNet, Wikipedia or other Web resources could be useful to build the word-word graph as word-level emotion correlation.
The proposed framework can be easily extended to incorporate multiple emotional signals by solving the following optimization problem:
 (cid:5)  s1Ru  s2Rv (cid:5) (cid:5) (cid:5)
 I,s1 + min I,s2 s1 SI,U  s3Ru C,s3 + s2 SI,V  s4Rv C,s4 , + s3 SC,U s4 SC,V .
.
s.t.
U



 (20) where O is the objective function de ned in Eq.
(10).
The second term is to introduce post-level emotion indication information from multiple sources SI,U , where s1 represents an emotional signal from the sources, Ru I,s1 represents the loss function de ned in Eq.
(3) for the signal s1, and  s1 is the corresponding positive parameter to control contribution from the emotional signal.
Similarly, we de ne the other three loss terms in the formulation to integrate word-level emotion indication, post and word-level emotion correlation from multiple information sources, respectively.
The optimization problems in Eq.
(20) can be solved with a similar algorithm as that we introduced in Section 5.4.
We do not discuss the details since that our focus is to illustrate how to make use of the emotional signals in this paper.
In this section, we conduct extensive experiments to evaluate the proposed framework ESSA and the factors that could a ect the framework.
Through the experiments, we aim to answer the following two questions,
 other unsupervised sentiment analysis methods?
of sentiment analysis performance?
We begin by introducing the experimental setup, and then compare the performance of di erent unsupervised sentiment analysis methods.
Finally, we study the e ects of the emotional signals on the proposed framework.
We follow the standard experiment settings [20] to evaluate the performance of sentiment analysis methods.
In particular, we apply di erent methods to perform unsupervised sentiment classi cation8 on social media datasets.
Sentiment classi cation accuracy is used as the performance metric.
To avoid bias brought by di erent corpora, STS and OMD introduced in Section 4.1 are used in the experiments.
The manually annotated sentiment polarity is considered as the gold standard.
For general experiment purposes, we choose emoticons, sentiment lexicon, textual similarity and word co-occurrence as post-level emotion indication, word-level emotion indication, post-level emotion correlation and word-level emotion correlation, respectively.
Emoticons are the ones listed in Table 1, and sentiment lexicon is the MPQA introduced in Section 4.1.
The latter two emotional signals are discussed in Section 5.2, and we empirically set k = 20 for k-nearest neighbor de ned in Eq.
(6) and (8).
There are four parameters involved in the experiments, including  u C in Eq.
(11).
All the parameters are positive.
They control the contributions of di erent emotional signals to the general model.
For general experiment purposes, we empirically set  u I =  v C = 1, which means the emotional signals are simply combined with equal weight.
The impacts of the parameters on the learning model will be further discussed in Section 6.4.
C =  v I =  u I ,  v I ,  u C,  v We now study the bene ts of utilizing emotional signals over other unsupervised methods, accordingly answering the  rst question above.
We compare our proposed method ESSA with the following three categories of methods,   Traditional Lexicon-Based Methods: These methods employ a word-matching scheme to perform unsupervised sentiment classi cation.
In particular, sentiment polarity of a word is obtained from the pre-de ned sentiment lexicon, i.e., +1 for positive, and 1 for negative.
The overall sentiment score of a post is computed as the summation of sentiment scores of the words in the post.
We employ two widely used manually labeled sentiment lexicons in the experiment.
The  rst is General Inquirer9 (GI), and the second is MPQA introduced in Section 4.2.
According to di erent lexicons used, we denote the two methods as GI-Label and
 a supervised learning method.
Following the terminology used in sentiment analysis literature [20], we consider the task of determining sentiment polarity of a post without extra human e orts during learning process as unsupervised sentiment classi cation.
http://www.wjh.harvard.edu/~inquirer/ Table 3: Sentiment Classi cation Accuracy of the Unsupervised Methods on the Datasets Method GI-Label MPQA-Label
 K-Means
 MoodLens

 STS (gain) OMD (gain)















 MPQA-Label.
In addition, Taboada et al. [32] propose LBM to incorporate intensi cation and negation to re ne the sentiment score for each document.
This is the state-of-the-art lexicon-based method for unsupervised sentiment analysis.
  Document Clustering Methods: Unsupervised learning has been extensively used in text mining.
We choose the most representative clustering method, K-Means, as a baseline method in this study.
In addition, we test the clustering performance of a basic ONMTF [8] method, which is a variant of our proposed method without any emotional signals.
We set the number of clusters as two in both methods.
As a common initialization for clustering methods, we randomly assign initial centroids and initial class indicator matrix for K-Means and ONMTF, respectively.
  Methods Incorporating Emotional Signals: Although we  rst present a quantitative study of emotional signals and provide a uni ed model to incorporate emotional signals, some e orts have been made to use some speci c emotional signals, i.e., emoticons and sentiment lexicons.
We denote the methods as MoodLens and CSMF in the experiment.
MoodLens [40] utilizes available emoticons in a corpus as noisy label information to train a naive Bayes classi er, and apply the trained classi er to infer sentiment polarity of other posts.
CSMF [26] proposes to learn from lexical prior knowledge from domain-independent sentiment terms and domain-dependent unlabeled data.
The experimental results of the methods are presented in Table 3.
In the table,  gain  represents the percentage improvement of the methods as compared to our  rst baseline method GI-Label.
In the experiment, each result denotes an average of 10 test runs.
By comparing the results of di erent methods, we draw the following observations: (1) From the results in Table 3, we can observe that our proposed framework ESSA consistently outperforms other baseline methods on both datasets.
Our method can generate better results than the state-of-the-art methods LBM, MoodLens, and CSMF.
We apply two-sample one-tail t-tests to compare ESSA to the best baselines LBM, MoodLens, and CSMF.
The experiment results demonstrate that the proposed model performs signi cantly better (with signi cance level   = 0.01) than the three methods.
(2) The performance of ESSA is better than the  rst and second categories of methods, which are based on text in-
emotional signals positively helps improve sentiment classi- cation performance.
ESSA outperforms the third category of methods, which also make use of emotional signals.
This validates the excellent use of emotional signals in the proposed framework for sentiment analysis.
(3) Generally, among all the three categories of baseline methods, the document clustering methods achieve the worst performance.
This demonstrates that, without any prior knowledge in the learning process, pure text clustering methods cannot achieve good performance for sentiment analysis.
(4) The methods that incorporate emotional signals show superior performance in the experiment.
However, it is also noted that the baseline GI-Label achieves even better performance than MoodLens on OMD dataset.
This demonstrates that the performance of sentiment analysis, which relies on only one speci c emotional signal as prior knowledge, is not stable on all the datasets.
In summary, with the help of emotional signals, our proposed framework always outperforms the lexicon-based methods, traditional text clustering methods, and the methods incorporating emotional signals.
In the next subsection, we investigate the e ects of di erent emotional signals on the sentiment analysis framework.
In this subsection, we study the e ects of the emotional signals on our proposed framework, accordingly answering the second question asked in the beginning of Section 6.
We  rst compare the performance of the proposed framework with only one emotional signal on the two datasets.
The results are plotted in Figure 2.
In the  gure, the  rst four methods represent performance of the proposed framework with one emotional signal, i.e., post and word-level emotion indication, post and word-level emotion correlation, respectively.
The last is our proposed method with four emotional signals.
From the  gure, we observe that, with the integration of all the four di erent emotional signals in a uni ed way, the proposed framework ESSA achieves better performance than those with only one emotional signal.
Among the emotional signals, word-level emotion indication achieves good performance on both datasets.
This observation is consistent with traditional unsupervised methods, which consider that the quality of the sentiment lexicon is the most important factor for sentiment analysis.
The post and word-level emotion correlations have comparable performance.
The post-level emotion indication performs di erently on the two datasets.
To further explore the e ects of di erent emotional signals on unsupervised sentiment analysis, we employ a  knockout  technique in the experiment.
Knockout-based methods have been widely used in many areas, like gene function analysis [9], to test the overall performance variance brought by one process or one component when it is made inoperative in the framework.
We conduct experiments to compare the di erences brought by knocking out one and two emotional signals from the framework.
Note that knocking out three terms is the same as the  rst set of experiments we conducted in this subsection.
Our proposed framework is general.
We can knock out some of the emotional signals from the framework by setting the corresponding parameters  u C to zero.
The results are summarized in Table 4.
In the table,  loss  indicates the per-C, and  v I ,  u I ,  v y c a r u c c
 n o i t a c i f i s s a
 l






 Post Indication Word Indication Post Correlation Word Correlation

 Dataset
 Figure 2: ESSA on the Datasets Sentiment Classi cation Accuracy of centage decrease of the methods as compared to the framework  Default  with all the emotional signals.
The middle four columns are the parameter settings, and the last two columns are the classi cation results on the two datasets.
From the table, we can draw the following observations: (1) After knocking out any of the emotional signals, performance of the proposed framework decreases.
This demonstrates that all the emotional signals we study are useful for the proposed framework.
(2) Generally, knocking out emotion indication incurs more performance decrease than knocking out emotion correlation.
This suggests that emotion indication might be more important than emotion correlation information.
Among the two signals, knocking out word-level emotion indication incurs consistently signi cant performance decreases on both datasets.
In this subsection, we study the e ects of the important parameters on the proposed framework.
Parameters of the Four Signals: In previous subsections, for general experiment purposes, we empirically set equal weights for the emotional signals.
Now we take a closer look at the e ects of the parameters  u C, and  v
 on the framework.
We consider one emotional signal at a time, and vary the corresponding parameter, denoted as  , to adjust its contribution to the general framework.
The experiment results on the two datasets are plotted in Figure 3(a) and 3(b), respectively.
I ,  u I ,  v From the  gures, it can be seen that: (1) The general trends of the performance of the emotional signals are similar with the variation of parameter settings.
Generally, we can set the parameters between 0.1 and 1 to achieve a relatively good performance.
(2) With di erent parameter settings, word-level indication achieves relatively good results on both datasets, and post-level indication performs di er-ently on the two datasets.
This observation is consistent with our discussion in Section 6.3.
Parameters of the Two Categories of Signals: We now examine the parameters to control emotion indication and emotion correlation information.
In particular, we set equal weights to the signals in the same category, i.e.,  u
  v I =  I ,  u C =  C.
The classi cation accuracy of C =  v
  u











  v











 STS (loss) OMD (loss)





















 y c a r u c c
 n o i t a c i f i s s a
 l












 Correlation    

 1e 3 1e 3




 Indication    
 Figure 4: ESSA on STS Dataset Sentiment Classi cation Accuracy of Default Knock Out One Term Knock Out Two Terms  u











  v











 Post Indication Word Indication Post Correlation Word Correlation





 y c a r u c c
 n o i t a c i f i s s a
 l t n e m i t n e


 1e 4 1e 3 1e 2
 Parameter  


 (a) STS Dataset Post Indication Word Indication Post Correlation Word Correlation





 y c a r u c c
 n o i t a c i f i s s a
 l t n e m i t n e


 1e 4 1e 3

 Parameter  


 Table 5: Optimal Sentiment Classi cation Results on the two Datasets (b) OMD Dataset Figure 3: Performance Variation of the Emotional Signals with Di erent Parameters ESSA on the two datasets with di erent settings of  I and  C are plotted in Figure 4.
In Figure 4, performance of ESSA improves as  I and  C increase, and reaches a peak at  I = 1 and  C = 0.1.
When  I > 1 or  C > 0.1, the performance of ESSA declines.
Generally, the performance is not sensitive to  C.
The results further demonstrate that the proposed framework can achieve a relatively good performance when setting the parameters in the range of 0.1 to 1.
Similar results have been observed on the OMD dataset; we omit the results owing to lack of space.
Optimal Results: As emotion indication appears to be more important than emotion correlation information, we Method GI-Label
 ESSA-opt STS (gain) OMD (gain)





 try to place higher weights on the two emotion indication signals.
In Table 5, we summarize the performance of GI-Label, our proposed method ESSA, and ESSA with optimal parameters (1, 1, 0.3, 0.3) on STS and (1, 0.3, 0.5, 0.5) on OMD.
As compared to GI-Label, we can achieve 21.40% and 17.87% improvement on the two datasets, respectively.
The performance of ESSA-opt is better than that of ESSA.
This implies that although the performance of our method is relatively good, it can be further improved by analyzing the importance of emotional signals, and place higher weights on the relatively more important signals.
where Texts in social media are short, fast-evolving, and informal, which presents challenges to sentiment analysis.
Meanwhile, we show that there are emotional signals available in social media data.
In this paper, we investigate a novel problem of interpreting emotional signals for unsupervised sentiment analysis.
In particular, we  rst conduct exploratory study on two Twitter datasets to verify the existence of emotional signals.
The post and word-level emotion indication and emotion correlation are then employed as regularizers to a matrix tri-factorization based unsupervised sentiment analysis framework.
Extensive experiments are conducted, and the results demonstrate the e ectiveness of the proposed framework as well as the roles of di erent emotional signals in sentiment analysis.
There are many potential future extensions of this work.
It is interesting to investigate the contributions of other emotion indication information available in social media, like product ratings and restaurant reviews.
It is also interesting to study other emotion correlation information, like spatial patterns and homophily e ect [33], to measure the sentiment orientation of social media posts as well.
In addition, utilizing such models for real-world applications, e.g., analyzing sentiments of crowd s responses in a hyperlocal community [16], is also a promising direction.
Acknowledgments We truly thank the anonymous reviewers for their pertinent comments.
This work is, in part, supported by ONR (N000141110527) and (N000141010091).
Optimizing the objective function in Eq.
(11) with respect to U is equivalent to solving JU = (cid:4)X   UHV +  u min
 CT r(U
 s.t.
U TLu

 Let  U and  U be the Lagrange multipliers for constraints U   0 and UT U = I, respectively; the Lagrange function L(U) is de ned as follows: T(cid:4)2 F +  u U)   T r( U U L(U) = (cid:4)X   UHV TLu (U   U0)(cid:4)2 ) + T r( U (U CT r(U I (cid:4)G +  u
 u

 By setting the derivative  UL(U) = 0, we get

 + 2 u





 u   W u + 2 u u

 (23) With the KKT complementary condition for the nonneg-ativity constraint of U, we have  U (i, j)U(i, j) = 0 ; thus, we obtain
 +  u


 u   W u



 )U + U U ](i, j)U(i, j) = 0, +  u u
 (24) (25) T(cid:4)2 F +  u I (cid:4)G u (U   U0)(cid:4)2
 (31) With the KKT complementary condition for the nonneg-
u



 (U   U0)    u
 u   W u
 (26)




    u
 Let  U =  +   U , where  + U (i, j) = (| U (i, j)|+ U (i, j))/2 U (i, j) = (| U (i, j)|    U (i, j))/2 [7], we get   and  



 +  u u


 U0 +  u u
 U +  u
 +  u u

  
 u
 + U )](i, j)U(i, j) = 0.
(27) which leads to the updating rule of U, (cid:7)(cid:8)(cid:8)(cid:9) [XVHT +  u I GuU0 +  u [UHVT VHT +  u I GuU +  u U(i, j)   U(i, j) U ](i, j) CWuU + U  C DuU + U + (28) U ](i, j) .
Optimizing the objective function in Eq.
( 11) with respect min
 to V is equivalent to solving JV = (cid:4)X   UHV +  v s.t.
V TLv
 C T r(V

 T(cid:4)2 F +  v I(cid:4)G v (V   V0)(cid:4)2
 (29) We introduce two Lagrange multipliers  V and  V for the constraints; the Lagrange function is de ned as follows: L(V) = (cid:4)X   UHV TLv CT r(V +  v I(cid:4)G T(cid:4)2 F +  v V)   T r( V V v (V   V0)(cid:4)2

 ) + T r( V (V
 By setting the gradient  VL(V) = 0, we get
 (30)
 + 2 v



 v   W v

 UH + 2 v v


 (21) ativity constraint of U, we have  V (i, j)V(i, j) = 0 thus, we obtain
 +  v


 v   W v


 UH +  v
 )V + V V ](i, j)V (i, j) = 0, v
 (32) (33)
 (22) where



    v



 v


 (V   V0)    v

 v   W v
 (34)
 Let  V =  +   V , where  + V (i, j) = (| V (i, j)|+ V (i, j))/2 V (i, j) = (| V (i, j)|    V (i, j))/2, we get   UH +  v V0 +  v
 v
  
 v
 UH +  v v


 V +  v
 and  



 v
 + V )](i, j)V (i, j) = 0.
(35) which leads to the updating rule of V, V(i, j)   V(i, j) (cid:7)(cid:8)(cid:8)(cid:9) [XT UH +  v I GvV0 +  v [VHT UT UH +  v I GvV +  v V ](i, j) CWvV + V  C DvV + V + (36) V ](i, j) .
