With the rapidly growing amount of information available on the WWW, it becomes necessary to have tools to help users to select the relevant part of online information.
To satisfy this need, recommender systems have emerged, e.g., there are popular rec-ommenders for movies1, books2, music3, etc.
Recommender are becoming a viable alternative and complement to search engines in helping users to  nd objects of interest.
Typically, in a recom-mender system, a set of users interact with a set of items.
The interactions vary, e.g., from users providing explicit scores for movies or books, to users listening to songs multiple times, to joining a community or favoriting a photo.
We generically refer to all types of interactions in which users endorse items as ratings.
The ratings expressed by users on items are stored in a rating matrix, which is typically extremely sparse [1, 10].
The classical task of a rec-ommender is to predict the rating for user u on a non-rated item i based on the known ratings.
Matrix Factorization (MF) [13, 8] based models are the state-of-the-art methods for recommender systems.
MF factors the rating matrix into two low rank matrices that represent latent factors for users and items.
The model based on these factor matrices is then used for rating predictions.
The typical setting in recommender systems is based on interactions between two types of entities.
However, increasingly, there are social ecosystems where multiple entity types coexist and interact with each other and across a variety of contexts, leading to multiple rating matrices.
In other words, entities can have interactions in a Heterogeneous Information Network (HIN).
Generally, in a heterogeneous network, entities from any two entity types can have interactions, with a weight (rating) indicating the level of endorsement.
For example, in a social media service like LinkedIn4, there are entities of types user, company, university, etc., and there are interactions in the form of user-user, user-company, company-university, etc.
The recommendation problem we study in this paper is how to recommend entities of one type to those of another, e.g., users to users (contacts), universities to companies (hiring), or professors to companies (expertise), leveraging the feedback data from the various interactions to predict the weight (rating) on interactions that have yet to happen.
Recommendations in heterogeneous information networks can be valuable for applications like feed ranking.
For instance, consider personalizing the news feeds in Facebook, Google+ or LinkedIn, where any entity can have news updates and entities from different types can get engaged in interactions, includ-1www.net ix.com 2www.amazon.com 3www.last.fm 4www.linkedin.com
 ranking based on content but also the predicted importance of the appropriate entity.
E.g., if a student is more interested in certain companies, this can be factored in the way news feeds from various entities are ranked, for that student.
Here, predicting the importance of one entity for another requires a recommendation model that can work on heterogeneous networks.
Figure 1 illustrates the  schema  of a sample heterogeneous information network.
Figure 1: Schema of a sample Heterogeneous Information Network.
Collective Matrix Factorization (CMF) [17, 9] has been proposed to address the recommendation problem in heterogeneous networks.
In CMF, every entity has a latent factor and interactions between two entities are governed by their corresponding latent factors.
The latent factor of an entity is learnt based on the observed interaction data from all the contexts in which this entity is involved in interactions.
However, a main issue with CMF is that entities share the same latent factor across different contexts.
This is particularly problematic in two cases.
First, suppose an entity e is cold-start in one context c. That is, e participates in very few interactions (ratings) in context c. Latent factors for entity e will be learnt mainly based on the interaction data from other contexts c(cid:48) where e is not cold-start, and therefore the factors are not properly learned for the cold start entities in the context c. Second, suppose a context has signi cantly more interaction data compared to another context.
Then the dominant context will dominate the learning process for the latent factors for entities shared in these two contexts.
In this case, the latent factors for the shared entities are not learnt properly for the dominated context, even for non cold start entities in the dominated context.
Recall that we use rating as a general term to include the real valued item ratings in Epinions5 and Flixster6 and binary rating values such as joining a community in Facebook7 and LiveJournal8 or adding a photo to your favorite list in Flickr9.
Also, visit counts on a Web page or the number of interactions among two entities are also indicators of ratings (weights) on these interactions.
In other words, any type of user behavior demonstrating her evaluation (or 5www.epinions.com 6www. ixster.com 7www.facebook.com 8www.livejournal.com 9www. ickr.com endorsement) of an entity can be regarded as a rating (binary or real values).
In this paper, we propose a context-dependent matrix factorization model, HETEROMF, that extends CMF and considers a general latent factor for every entity type and a context-dependent latent factor for every context in which the entity is involved.
HET-EROMF learns a general latent factor for every entity and transfer matrices for every context, to convert the general latent factors into context-dependent latent factors.
To test the effectiveness of our proposed method, we conduct a detailed set of experiments on two real life datasets from Epinions and Flixster.
Our results demonstrate that HETEROMF substantially outperforms CMF, particularly for cold-start entities and for contexts where the size of the interaction data is dominated by other contexts.
There has been a large body of recent work on link prediction in heterogeneous information networks [21, 19].
We review these works in detail in Section 3, but note here that their main focus is analyzing how topological structures in heterogeneous networks affect link (relationship) formation and using this to predict whether (and, in some cases, when) an entity will form a relationship with another.
As such our goal and methodology are different from theirs.
The main goal of this paper is to learn the latent factors governing the behavior of entities in different contexts (rather than using topological structures), and address the issues mentioned for the state-of-the-art CMF methods.
In this paper, we make the following contributions:   We introduce the novel HETEROMF model, a generalized CMF based model that considers general latent factors for entities as well as context speci c latent factors for the contexts in which entities are involved in interactions.
  We use a transfer matrix to convert base latent factors into context speci c latent factors.
Transfer matrices are learnt per context.
  HETEROMF is particularly helpful for cold start entities, and for the contexts that are dominated by the interactions from other contexts.
  We perform experiments on two real life data sets from Epin-ions and Flixster.
Experimental results show that HETEROMF achieves substantial RMSE gain compared to CMF, particularly for cold start entities, and for the contexts dominated by other contexts.
The rest of the paper is organized as follows: Preliminaries and problem de nition are discussed in Section 2, followed by some of more recent related works in Section 3.
Our proposed HETEROMF model is introduced in Section 4.
Also we discuss the inference algorithm for HETEROMF in Section 4.
In Section 5, we present our experimental results on real life datasets.
Finally, we conclude the paper and discuss some future work in Section 6.
In this section, we review some preliminaries and formally state the problem studied in this paper.
A heterogeneous information network (HIN) G consists of N entity types denoted by U = {U1, ..., UN} and   contexts denoted by L = {L1, .., L }.
Each context Ll consists of interactions among entities from two participating entity types Un and Um, where Un, Um   U.
For example movie ratings is an instance of a context in which entities of type user interact with entities of 644type movie and the interactions result in interaction weights that we generically call ratings.
Note that the two participating entity types of a context can be the same: e.g., in the context of social networks both entity types are user.
Similarly, more than one context can bring about interactions between the same pair of entity types: e.g., a social network (with explicit links) as well as a co-authorship network (based on common published papers) are two contexts which relate users with users.
The observed interactions in a context Ll are stored in a context-speci c rating matrix Rl.
Rl is typically a very sparse matrix.
Every cell in this matrix, rl u,v, denotes the rating (interaction weight) observed from entity u   Un on entity v   Um.
Here Un and Um are the entity types participating in the context Ll.
The set of all rating matrices corresponding to the various contexts is denoted R.
We next formally state the problem we study in this paper.
(PROBLEM STUDIED).
Given a heterogeneous information network G = (cid:104)U,L,R(cid:105) , a context Ll   L consisting of interactions among Un   U and Um   U, and entities u   Un and v   Um such that rl u,v using the observed ratings in R.
u,v is unknown, predict rl Figure 2: Graphical model representing MF.
Matrix Factorization (MF) is one of the common techniques for model-based recommendation.
MF has been proposed in order to perform predictions for a single user-item rating matrix, for a single context, unlike the setting in this paper.
In MF, each user and each item is associated with a K dimensional latent factor vector [6]: the latent factor of user u is denoted Uu and stored as the uth row of user factor matrix U.
The latent factor of item i is denoted Vi and stored as the ith row of item factor matrix V .
In order to learn the latent factors of users and items, [13] employs probabilistic matrix factorization to factor the user-item matrix into the product of user and item latent factors.
The conditional probability of the observed ratings is de ned as: N(cid:89) M(cid:89) (cid:104)N(cid:16) u=1 i=1 (cid:17)(cid:105)IR u,i p(R|U, V,  2
 Ru,i|U T u Vi,  2 r (1) where N (x| ,  2) is the normal distribution with mean   and u,i is the indicator function that is equal to 1 if variance  2, and I R u has rated i and equal to 0 otherwise.
Also, zero mean Gaussian priors are assumed for user and item factors: M(cid:89) i=1 N(cid:89) u=1 p(U| 2
 N (Uu|0,  2 UI), p(V | 2
 N (Vi|0,  2
 (2) Figure 2 presents the graphical model representing matrix factorization.
The latent factors of users and items are learnt in MF using the observed rating matrix.
To predict the rating of user v on item j in the test phase, the inner product of learnt latent factors Uv and Vj is computed as the predicted rating.
The matrix factorization based method, essentially considered the state-of-the-art method for recommendation, has been recently extended to incorporate other factors in the factorization of the rating matrix: these include modeling at multiple scales [3], incorporating users with similar rating patterns [6], and taking the times-tamps into account [7].
The last approach [7] won the Net ix grand $1M prize10.
Matrix factorization is the basis for building extended models such as collective matrix factorization, and our proposed model, HETEROMF.
10http://www.net ixprize.com/ In this section, we review some related work on matrix factorization, collective matrix factorization and recommendation and link prediction in heterogeneous information networks.
As discussed in the previous section, matrix factorization is proposed for single context domains, where there is only one rating matrix.
However, users can be involved in interactions across multiple contexts.
In this case, one could  t the rating matrix in each context separately.
However, this approach would not take advantage of any correlations between contexts.
In other words, information from one context does not propagate to another context.
This approach is called separate matrix factorization (SMF) and we use SMF as one of our baseline models in our experiments.
Singh and Gordon [17] proposed Collective Matrix Factorization (CMF) for learning in multi-context domains.
CMF decomposes the rating matrix in every context into a product of latent factor matrices of the entities from the two participating entity types of the context.
Whenever an entity type participates in more than one context, the latent factors for that entity type are shared among the contexts in which this entity participates.
Figure 3 shows an example graphical model representing a CMF model.
In this model, there are two contexts (with observed ratings R and O) and three entity types (U, V, Z).
E.g., it could represent users (U) rating movies (V ) and books (Z).
The graphical model representing CMF for more than two contexts is simply a generalization of the one shown in Figure 3.
Figure 3: Graphical model representing a simple Collective Matrix Factorization (CMF), with only two contexts.
is learned based on the observed ratings from the contexts in which this entity type participates.
However, a main issue with CMF is that entities share the same latent factor across different contexts.
We conjecture that this is particularly problematic in two cases.
First, latent factors for entities that are cold-start in a context will be learned mainly based on the data from other contexts where it is not cold-start, and therefore the factors are not properly learned for the cold-start context.
In practice, cold start entities are entities that have very few (normally less than 5) observed ratings that they participate in.
Second, if a context has more interaction data compared to another context, then the dominant context will dominate the learning process for the latent factors for entities shared in these two contexts.
In other words, the latent factors for all entities in the shared entity type are learnt mainly based on the dominating context and the dominated context has very little effect on the learned latent factors.
Therefore, the latent factors are not properly learned for representing the dominated context.
In this paper, we address these issues by introducing context-dependent latent factors besides having general factors for entities in different entity types.
CMF is our main competitor in the experiments and we show that our proposed model addresses the above issues with CMF and substantially outperforms it.
Collective matrix factorization has also been used in [9].
Lippert et al. [9] consider user attributes (e.g., gender, age, etc.)
as different contexts.
However, in recent papers [24, 2, 4] user attributes (features) are considered as the prior for user latent factors, and a transfer matrix [24] is used to generate a latent factor using user attributes.
In our research, we do not assume we have access to entity attributes.
However, we use the same idea as in [24, 2, 4] to generate context-speci c latent factor using the general latent factor for the entity and a context-dependent transfer matrix.
Recently, Yang et al. [22] employed collective matrix factorization for recommendation in social rating networks where there is a rating matrix between users and items and a social network among users.
The proposed model in this paper considers the social network and user ratings as two contexts and decomposes each context into the product of latent factors of the entities corresponding to the participating entity types of that context.
The model proposed in [22] can be represented by the graphical model demonstrated in Figure 3 by setting Z = U and letting O denote social relations.
Note that the social network in this paper is considered to be undi-rected.
Among other things, the authors showed that their approach leads to better prediction accuracy than using the ratings alone or using the soial network alone.
There is an important body of research on link prediction in heterogeneous information networks [21, 23, 19, 14, 18].
These works particularly focus on how topological structures in heterogeneous networks affect the relationship building and whether an entity engages in an interaction with another entity or not.
Yu et al. [23] and Sun et al.
[18] used the concept of  meta-path ,  rst introduced in [20], to de ne features for a potential interaction between entities a and b, and further used these features to learn a regression function to compute the probability of a link (interaction).
In the meta-path based approach, a set of path patterns from entity a to b is selected and the number of such paths is computed to determine the path-speci c features.
Computation of paths between two entities is performed on the  y (memory-based) which requires exploring the HIN and makes the meta-path based methods slower in prediction compared to model-based approaches such as CMF that do not require to access the raw data after the learning phase.
Meta-path based methods also have a training phase to learn the regression weights to combine the various topological features to compute the probability of an interaction.
Shi et al. [16, 15] proposed a model to use the labeled data from other related (heterogeneous) sources to help in predicting the target task even if they have different feature spaces and distributions.
This paper proposes a solution and discusses the conditions where this is possible and highly likely to produce better results.
This model uses spectral embedding to unify the different feature spaces of the target and source data sets, even when they have completely different feature spaces.
The principle is to cast into an optimization objective that preserves the original structure of the data, while at the same time, maximizes the similarity between the two [16].
Next, a sample selection strategy is applied to select only those related source examples.
Finally, a Bayesian-based approach is applied to model the relationship between different output spaces.
While these works are very interesting, they mainly deal with transferring feature spaces from a domain to another domain, rather than learning from interactions in other contexts which is our main focus.
In this section we introduce our proposed model, HETEROMF, that extends collective matrix factorization and incorporates context dependent latent factors for entities, in their interactions in different contexts.
As discussed before, the main problem with CMF models is that the latent factors for entities of an entity type are shared among all the contexts that this entity type participates in.
Recall that this is particularly problematic for cold-start entities, and for contexts dominated by other contexts.
To address these issues, we propose HETEROMF, a generalized context dependent collective matrix factorization based approach.
In our proposed model, each entity of every entity type has a base latent factor.
For each context in which this entity type participates, entities of that type have a context speci c latent factor.
To elaborate on the intuition,suppose that in a domain, users can rate movies and books.
In this example, users have some general factors representing their general rating behavior.
However, the factors governing users  behavior in the context of movies is different from her factors in the context of books.
Context speci c factors depend on the base factors and can be derived from the base factors of an entity.
In HETEROMF, a transfer matrix is used to transfer the base factors to the context speci c factors in each context.
The following is the list of latent factors used in HETEROMF:   Latent factors for entities of type Un are denoted by Un, n   [1, N ].
The latent factor for an entity u   Un is denoted by Un,u.
  Entities of an entity type have their own context speci c latent factors in the contexts Ll this entity type participates in n. In and the context speci c latent factors are denoted by U l HETEROMF, context speci c latent factors U l n are generated using the base latent factors Un and a context speci c transfer matrix M l n. The context speci c latent factor for an entity u   Un and for context Ll is denoted by U l n,u.
n and U l   Every context Ll has two entity types.
Therefore every context Ll is associated with two context-dependent entity latent factors U l m. In some cases such as social relations, we can have n = m. Note that for each context, there are two separate transfer matrices M l m, unless the context is an undirected network (n = m).
It should be noted that if a network is undirected, then M l n and M l n = M l m.
context Ll are generated using the context speci c latent factors for the entities whose entity types participate in that context, as follows: u,v   N (U Rl (cid:48)l n,uU l r,l) m,v,  2 (3) In this equation and in what follows, we use M(cid:48) to denote the transpose of matrix M. Context speci c latent factors U l n are generated using the product of the base latent factors Un and a context n,u is a k1-dimensional column speci c transfer matrix M l vector and Un,u is a k2-dimensional column vector, then M l n is a k2   k1 matrix that converts the base latent factor to a context speci c latent factor.
M l n should be learned in the training phase.
n. If U l n,u   N (M l U l l,nI) nUn,u,  2 (4) In the above Equation, I is the identity matrix.
Similar to regular MF, every base latent factor has a zero-mean normal prior.
Note that, if the attributes for different entity types (e.g., age and gender for users or location for companies) were available, we could use them as the mean of the normal distribution for prior, instead of a zero mean normal prior.
Un,u   N (   0 ,  2 nI) (5) Figure 4 demonstrates the graphical model representing the HET-EROMF model.
In this graphical model,  n denotes the variance for the distribution of base latent factors Un,  l,n is the variance for context speci c latent factors U l n, and  r,l is the variance for the observed ratings in the context Ll.
be dominated.
Although the base factors for the shared entity type can be dominated, notice that the transfer matrices are learned per context, leading to a proper learning of the context speci c latent factors and resolving the shared latent factors  issues in CMF.
Using the graphical model demonstrated in Figure 4 , the complete data likelihood (joint likelihood) in HETEROMF is computed as follows: (cid:89) (cid:0)P (U l l  (cid:89) l P (R,  | ) = P (Rl|U l n, U l m,  r,l) n|Un, M l n,  l,n)   P (U l m|Um, M l m,  l,m)(cid:1) P (Un| n) (6)  (cid:89) n In the above equations, we have:   = { n n, l l,n, l l,m, l r,l, M =  l{M l n, M l m}}   = { lU l n, lU l m, nUn}, R =  l{Rl} It should be noted that if Rl is an undirected network, then M l m and therefore U l n = m,u.
Using Equations (3)-(6), the log-M l likelihood of the complete data is computed as follows: n,u = U l (cid:19)IR,l u,v (cid:0)rl u,v U

   1
   1
  2 r,l l n m v U l u U l (cid:18) 1 (cid:88) (cid:88) (cid:88) (cid:18) 1 (cid:88) (cid:88) (cid:0)U l (cid:18) 1 (cid:88) (cid:88) (cid:0)U l (cid:88) (cid:88) u Um u Un  2  2 l,m l,n l l   1
 n,u   M l nUn,u m,u   M l (cid:18) 1 mUm,u (cid:0)Un,u r,l m,v (cid:48)l n,uU l (cid:1)2+log  2 (cid:19) (cid:1)2 + kl log  2 (cid:19) (cid:1)2 + kl log  2 (cid:19) (cid:1)2 + kn log  2 l,m l,n n (7) n u Un  2 n In the above equations, I R,l u,v is an indicator that returns 1 if entity u has a relation with entity v in the context Ll, and returns 0 otherwise.
Also, kl is the dimensionality of latent factors in context Ll, and kn is the dimensionality of factors for entity type Un.
Figure 4: The graphical model representing HETEROMF.
HETEROMF is particularly helpful for entities that are cold-start in a context but are active in other contexts.
HETEROMF uses the base factors of those entities and transfers them to the context spe-ci c latent factors using the transfer matrix for that context, without being dominated by the latent factors from the contexts in which these entities are not cold-start.
Also, even if a context is dominated by another context, the context speci c latent factors will not
 We use expectation maximization (EM) to  t HETEROMF and learn the latent factors and model parameters.
In the E step, we compute the expected log-likelihood with respect to the latent variables (E |R, (L)).
In the M step, we maximize the expected likelihood with respect to the model parameters ( ) to compute the model parameters.
The EM iterations are repeated until convergence.
The expected log-likelihood is computed as follows:
  2 r,l = E |R, (L) = (cid:88) (cid:88) (cid:88) (cid:18) l u U l n v U l m   1
 (cid:18) (cid:80) t   1
 E |R,  (cid:1)2 + V ar[Sl u,v] (cid:0)rl u,v   (cid:91) Sl (cid:32)  2 r,l u,v kl log  2 l,n+ n[t, ]Un,u)2(cid:1)(cid:19) (cid:33) log  2 r,l + l (cid:88) (cid:88) (cid:0)(U l u Un n,u[t]   M l (cid:32) (cid:88) (cid:88) (cid:0)(U l u Um m,u[t]   M l  2 l,n l   1
 E |R,  (cid:18) (cid:80) (cid:88) (cid:88) t n u Un   1
 (cid:18)  2 l,m (cid:80) t kn log  2 n + (cid:33) l,m+ kl log  2 m[t, ]Um,u)2(cid:1)(cid:19) (cid:0) (cid:92)Un,u[t]
 (cid:19) + V ar(cid:2)Un,u[t](cid:3)(cid:1) m,v, (cid:100)Sl  2 n In the above equation, Sl u,v = U (cid:48)l n,uU l u,v is the sample u,v.
Also
 u,v, V ar[Sl u,v] is the sample variance of Sl mean of Sl Un,u[t] is the tth element in the vector representing Un,u
 We use Gibbs sampling in the E step.
We draw T samples for all the latent variables and compute the suf cient statistics (Monte Carlo means and variances of the latent variables) to be used in the M step.
In the E step, we sample the latent variables from their distributions given the rest of random variables.
For example, to sample Un,u, we sample from P (Un,u|rest).
This probability is embedded in the complete data likelihood and since all distributions are normal, P (Un,u|rest) is also normal.
Generally, if f (x) is a multivariate normal density function with mean   and variance-covariance matrix  .
Then, we have: (cid:18) d dx (cid:19)   =   log f (x) |x=0 and   =   (cid:18) d2 dx2 log f (x) (cid:19) 1 Now, for latent variables Un and U l n we use the above lemma to compute the mean and variance of the normal density functions to sample these latent variables from: V ar[Un,u|rest] = E[Un,u|rest] = V ar[Un,u|rest] (cid:18) 1
  2 n (cid:19) 1 (cid:19) n,u (cid:88) (cid:18) (cid:88) l Cn l Cn
 (cid:48)l n M l n  2 l,n
 (cid:48)l n U l  2 l,n (9) (10) In the above equations, Cn is the set of contexts in which entity type Un is involved.
Similarly, the mean and the covariance matrix for U l n,u is computed as follows:
 E |R,  ((U l M l to improve readability in Eq.
n [t, ](cid:92)Un,u (cid:3).
n[t, ]Un,u )2) = (cid:0) (cid:92) n [t, ]Cov(cid:2)U l n,u [t] M l (cid:48) l n [t, ]   2M l n,u [t] M l U l n,u [t], Un,u n [t, ]V ar[Un,u ]M (cid:1)2 +V ar[U l (8), we used n,u [t]]+ (cid:19)IR,l u,v V ar[U l n,u|rest] = (cid:18) 1  2 l,n
 (cid:19) 1 (11) (cid:48)l m,v U l m,vU  2 r,l (cid:88) (cid:18) (cid:88) v U R,l u v U R,l u (cid:19) (12) m) that E[U l n,u|rest] = V ar[U l n,u|rest] m,v rl u,vU l  2 r,l + M l nUn,u  2 l,n In the above equations, U R,l denotes the entities (from U l u have relation with u in the context l.
In the M step, we maximize the expected likelihood, E |R, (L), with respect to model parameters ( ) to compute the updated values for the model parameters.
To do so, we set the derivative of E |R, (L) with respect to every model parameter to zero and compute the model parameters as follows: (cid:80) (cid:80) u U l n v U l (cid:80)  2 n = (cid:80) u Un u Un (cid:80) t u,v m |Rl| (cid:18)(cid:0)rl u,v   (cid:100)Sl (cid:0) (cid:92)Un,u[t] (cid:80) (cid:18) kn|Un|
 t E |R, ((U l kl|Un| (cid:1)2 + V ar[Sl u,v] (cid:19)IR,l u,v + V ar(cid:2)Un,u[t](cid:3)(cid:1) (13) (14) (cid:19) n,u[t]   M l n[t, ]Un,u)2) n,u[t](cid:91)Un,u + Cov[U l (cid:18) (cid:88) (cid:0) (cid:92)U l (cid:18) (cid:88) (cid:0)(cid:91)Un,u u Un   u Un (cid:48) (cid:91)Un,u n,u[t], Un,u](cid:1)(cid:19)(cid:48) + V ar[Un,u](cid:1)(cid:19) 1 (15) (16)  2 l,n = M l n[t, ] = Now, we continue to the next EM iteration using the updated model parameters.
We continue performing E and M steps until convergence of the learned parameters.
In this section, we  rst describe the datasets used in our experiments and our experimental setting and design, and then present the experimental results.
One of the bottlenecks to research in heterogeneous network analysis has been the lack of publicly available datasets featuring a large number of entity types, numerous contexts, and rich interaction data.
Many previous papers on heterogeneous information networks have tended to use bibliographic datasets [19, 23].
These datasets contain the entity types, authors, institutions, publications, and venues, to name a few.
However, there are no explicit ratings in these datasets, and the contexts in bibliographic networks are not real context where entities interact.
Ideal datasets for this research, particularly for recommendations research, would be the real heterogeneous networks from online social media services such as
 types such as users, universities, companies, etc.
and these entities interact in several contexts.
However, due to lack of public data available for such heterogeneous networks featuring many entity types and multiple contexts, we use two publicly available data sets from Epinions.com and Flixster.com.
These two datasets are in fact social rating networks [5] and each one consists of two contexts: a social network among users, and an item rating matrix.
In this subsection we brie y introduce these two datasets.
Epinions.com is a product reviewing website in which users can express trust on other users besides writing reviews on various products.
We used the version of the Epinions dataset12 published by Richardson and Domingos [12].
The social relations in Epinions are in fact trust relations, which are directed.
Flixster.com is a social networking service in which users can rate movies and create a social network.
The social relations in Flixster are friendship relations and undirected.
The Flixster data set has been crawled by Jamali and Ester [5] and has been made publicly available for the research community13.
Ratings in Flixster and Epinions are real values in the range [1,5].
The social relations in both data sets are binary, indicating whether or not a social relation exists.
General statistics of the Flixster dataset and the Epinions data set are shown in Table 1.
Between these two datasets, we capture both directed and undirected social networks and two contexts, one involving binary ratings and the other real ratings.
Table 1: General statistics of the Flixster and Epinions Social Relations Statistics Users Ratings Items Flixster Epinions
















 We implemented the algorithms in R and in C: R scripts are used to handle the input matrices and high level routines, and C is mainly used for more complex processing.
Our experiments were run on a single core of a multi-core machine with an Intel Xeon CPU X5570
 our implementation of HETEROMF consumed only 1GB memory on the largest dataset (Flixster).
We perform 5-fold cross validation in our experiments.
In each fold we have 80% of data as the training set and the remaining 20% as the test set.
The evaluation metric we use in our experiments is RMSE, de- ned as follows: (cid:115)(cid:80) (ru,v  (cid:98)ru,v)2 (u,i)|Rtest |Rtest|
 (17) where Rtest is the set of all entity pairs (u, v) in the test data.
Note that RMSE values for different contexts are computed separately and Rtest in the above equation is the test data for a speci c context.
We report the results for different contexts in both Epin-ions and Flixster separately.
To evaluate the performance of our proposed model, we consider three comparison partners, i.e., competing approaches: 12http://alchemy.cs.washington.edu/data/epinions/ 13www.sfu.ca/ sja25/datasets/   HeteroMF: The context-speci c factorization based model proposed in this paper.
  CMF: The collective matrix factorization method [9].
  SMF: Separate matrix factorization, where different contexts are learned separately using separate latent factors.
No information is propagated across contexts.
In the datasets used in our experiments, we only have entity types of user, product, and movie.
Entity type user is the only entity type that is shared among two contexts.
To perform a comprehensive set of experiments and evaluate the strength of our model in all the aspects and issues that we identi ed for CMF, we design and perform different sets of experiments.
We report experimental results on three kinds of users:   AllUsers: All the users in the system.
  Cold Start: Cold-start users for a speci c context who are users that have rated less than 5 (but more than zero) items in one context, and 5 or more ratings in the other context.
  Inactive: Users who have no ratings in a context, but have 5 or more ratings in the other context.
These users are particularly important for the case that the latent factors of a user are properly learned in a context and now this user wants to start expressing ratings in a new context.
Transferring the learnt factors across contexts to model the rating behavior for these users is very important.
The three kinds of users above cover key settings which we believe should both highlight the advantage of our proposed model and expose its limitations, if any.
In both datasets, as such none of the ratings or the social relations dominate each other.
To overcome this, we simulate a dataset where one context dominates another one, by selecting a subset of the ratings in each dataset to represent a context.
In Epinions, if we only consider the category of  online-store", then the ratings (22K) will be dominated by the social relations (508K).
Similarly in Flixster, if we only consider the movies from the  Horror" genre, then the ratings (245K) will be dominated by the social relations (26M).
In our experimental results we refer to these data sets as Epinions-dominant and Flixster-dominant.
In this subsection, we report our experimental results on the different sets of experiments introduced in the previous subsection for both Flixster and Epinions.
Epinions.
Figure 5 compares the RMSE of the comparison partners for different sets of users in both the contexts   rating and trust, for Epinions.
In both contexts, HeteroMF outperforms the comparison partners.
Notice that HeteroMF s improvement over CMF is substantially more than the latter s improvement over SMF.
Figure 6 shows RMSE improvement of HeteroMF over CMF for various kinds of users.
It can be easily seen that HeteroMF achieves a substantial RMSE improvement over CMF for cold start users and inactive users, compared with all users.
In the rating context, the RMSE gain for cold-start users (4.9%) is more than 2.5 times the RMSE gain for all users, and the RMSE gain for inactive users is more than 1.6 times the RMSE gain for cold-start users.
Similar behavior is exhibited in the trust context.
The absolute value of the RMSE gain of HeteroMF for each kind of users is more than for the rating context.
But the increase in the RMSE gain when we go from all users to cold-start users to inactive users is more modest compared to the rating context.
Figure 6: Comparison of RMSE improvement for cold start users, all users, and inactive users in Epinions.
(b) Trust Figure 5: RMSE results for comparison partners in different contexts for Epinions.
Flixster.
Figure 7 shows the results for the Flixster dataset.
As shown in this  gure HeteroMF outperforms all the comparison partners for all three sets of users in both contexts.
Unlike Epinions, Het-eroMF s RMSE gain over CMF is comparable to the latter s RMSE gain over SMF.
Figure 8 depicts how the RMSE gain of HeteroMF over CMF varies depending on the kind of users.
It clearly shows that similar to the case for Epinions, HeteroMF archieves substantial RMSE gain for cold start users and inactive users, compared with all users.
Analysis.
Experimental results on cold start users and inactive users show that CMF can not properly learn the latent factors for entities that have not expressed enough ratings in one context, but have many ratings in another context.
This is mainly due to the fact that the latent factors for users are shared across different contexts in CMF.
For cold start users in a context, their latent factors are dominated by the other context.
On the other hand, HeteroMF learns general latent factors for users and context speci c latent factors in rating and social contexts.
Transfer matrices are used to convert a general latent factor to a context speci c factor.
In other words, the main advantage of HETEROMF over CMF is that HETEROMF decomposes the latent factors of an entity into a general latent factor and a context dependent transfer matrix.
General factors are learnt based on the observations in all contexts.
However, the transfer matrix is learnt for a speci c context only.
In HETEROMF, even if a user has no ratings it does not matter because his general factors are learnt based on other contexts and to tailor this factor to a context dependent one HETEROMF uses a transfer matrix that is properly tuned for this speci c context and is in charge of translating general factors into context speci c factors.
Dominated Contexts.
Figure 9 presents the RMSE for the dominated context (rating) in Epinions-dominant.
As shown in this  gure and in Figure 10, HeteroMF achieves a substantial RMSE improvement over CMF even for all users in Epinions-dominant on the dominated context, namely rating.
HeteroMF outperforms CMF by 11% in the rating context which is very impressive, compared to less than 2% for the Epinions  complete dataset.
Similar results are achieved for Flixster-dominant (see Figures 11 and 10).
CMF vs. SMF.
There are some interesting and somewhat surprising results shown in Figures 9 and 11 in addition to those discussed earlier.
In both datasets, SMF outperforms CMF in the rating context!
This shows that when a context dominates another context, it is bene cial for the dominated context to be learned separately from the dominating context.
Indeed, by learning the dominated context along with the dominating context, CMF suffers on the dominated context, compared with SMF.
So far, all the experiments we have discussed convincingly highlight the weaknesses of CMF exactly as we outlined in the earlier sections and precisely under the settings discussed, w.r.t.
different kinds of users and different contexts.
What is a context?.
It should be noted that there are different genres in Flixster and different product categories in Epinions which can potentially be considered as different contexts.
Syntactically, we can of course regard them as contexts.
Can we expect the same kind of behavior from these  contexts  that we observed for the rating vs. so-cial/trust contexts in our experiments above?
To test this, we performed experiments on these settings and the results were not striking, in that the RMSE gain of HeteroMF over CMF was not substantial (Even for some genres/categories, CMF performed slightly better.).
We believe that this is mainly due to the fact that although different genres can potentially represent different contexts, in reality users  behavior toward them tends to be very similar.
Therefore, direct propagation of information from one context to another one (as is done by CMF) is not going to harm cold-start users.
In other words, if a user is cold start in one genre but active in another genre, he/she is actually not a cold-start user and his/her ratings in the active context happen to faithfully capture his behavior in the
 Figure 8: Comparison of RMSE improvement for cold start users, all entities, and inactive users in Flixster.
(b) Social Figure 7: RMSE results for comparison partners in different contexts in Flixster.
so-called cold-start context, with high accuracy.
E.g., there is not a great difference in the rating behavior of  Thriller  movies compared to  Comedy  movies.
However, social relations and ratings are fairly independent and are genuinely separate contexts.
Indeed, we can see the effect of multiple contexts much better in this setting, as shown in our experiments.
Similar remark hold for the Epinions dataset.
In our experiments, CMF converged in about 50 iterations, while HETEROMF took about 100 iteration to converge.
Table 2 compares the actual average running time for an EM iteration in both HETEROMF and CMF on all datasets.
As shown in this table, an EM iteration in CMF, on an average, runs more than 4 times faster than a corresponding EM iteration in HETEROMF, for all datasets used in our experiments.
Slower iterations in HETEROMF are mainly due to the fact that HETEROMF considers context-speci c factors.
Also, to facilitate the propagation across contexts, in the E step we  rst sample context-speci c factors, then the base factors, and then we do one more round of sampling for context-speci c factors to propagate the information from the observed data to the base factors and from the base factors back to the contexts.
Note that although CMF is faster than HETEROMF in the learning phase, both methods are equally fast in the prediction (test) phase, when they simply use the learned latent factors.
In real industrial strength applications, substantial accuracy improvements for cold-start entities and dominated contexts, that are achieved by HETEROMF compared to CMF, tend to be very important for new user engagement and for controlling information propagation from Figure 9: RMSE results for comparison partner in the dominated context (rating) for Epinions-dominant, where a context (rating) is dominated by another one (trust).
large contexts to much smaller sized contexts.
Thus, the increased learning time is a price that may be worth paying in practice.
It is worth noting, however, that the learning phases in both HET-EROMF and CMF are highly parallelizable, which may allow us to save on learning time signi cantly.
Traditional recommender systems focus on interactions between users and items in a single context and use past interactions, expressed as ratings, to make predictions about future ratings users may give items they have not interacted with before.
Methods based on matrix factorization are the state of the art for making these predictions.
However, in heterogeneous information networks, entities of different types interact with each other, often across a variety of contexts.
This leads to multiple rating matrices.
Collective matrix factorization is the state of the art for rating predictions in such settings.
We identi ed certain fundamental issues with the way in which CMF models and approaches the rating prediction problem in this setting.
We proposed a context-dependent matrix factorization model, HETEROMF, that considers a general latent factor for entities of every entity type and context-dependent latent factors for every context in which the entities participate.
HET-EROMF learns a general latent factor for every entity and trans-
ferent datasets.
HeteroMF 34min.
18min.
220min.
116min.
7.5min.
4min.
48min.
26min.
Dataset Epinions Flixster Epinions-dominant Flixster-dominant Figure 10: Comparison of RMSE improvement for cold start users and all users in the dominated context (ratings).
The results are for both Epinions and Flixster for the case that a context (rating) is dominated by another one (social or trust).
Figure 11: RMSE results for comparison partner in the dominated context (rating) for Flixster-dominant, where a context (rating) is dominated by another one (social).
fer matrices for every context, to convert the general latent factors into a context-dependent latent factor.
HETEROMF is particularly helpful for cold-start entities and contexts that are dominated by other contexts.
The transfer matrices in HETEROMF are learned per context and prevent the learnt factors for a context from being dominated by other contexts.
Also, for entities that are cold start in a context, HETEROMF uses the product of the base latent factor, learned from observations for this entity in other contexts, and the transfer matrix, learned from the observations for all entities in this context, to generate a proper context-speci c latent factor.
We performed comprehensive experiments on two real datasets from Epinions and Flixster.
Both data sets feature interactions between users and interactions between users and items (products or movies) in two different contexts.
Experimental results demonstrate that HETEROMF substantially outperforms CMF, particularly for cold-start entities and for contexts where interactions in one context are dominated by those of other contexts.
Additionally, our experimental analysis convincingly highlights the weaknesses of CMF exactly as we outlined in the technical sections, w.r.t.
different kinds of users and different contexts.
This work suggests several interesting directions for future research.
All interactions considered in this paper are binary, where a pair of entities (from the same or different types) are involved.
There are real applications where the  arity  of interactions can be higher.
As an example, in Amazon, products are reviewed by reviewers, and both products and reviews may be rated by raters.
Here, a rating on a review is really an interaction between three entity types   rater, reviewer and product.
Tensor factorization models and their extensions have been used by Moghaddam et al. [11] for predicting helpfulness of reviews.
It is interesting to enhance tensor factorization models to account for multipe interaction contexts.
Another direction is incorporating entity attributes.
For simplicity and generality, in this paper we do not assume access to entity attributes.
However, the HETEROMF framework can take advantage of user demographics, movie genres and actors, and product specs, when available.
Extending our experiments to incorporate these is interesting.
Finally, we note that the features extracted in meta-path based approaches [20, 19] can also be used as features in HETEROMF.
