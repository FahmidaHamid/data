Digg [10] is a social news website that allows people to submit articles for sharing their favorite web pages (e.g.
blogs or news articles) and to vote the articles posted by others.
When a Digg user  nds an interesting web page with which he wants to share, he can submit an article to Digg so that   Corresponding author.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
Digg score Submission title & link to the web page
 The physics behind your favorite science fiction theme thunes io9.com -- When you think about science fiction them tunes, chances are there are a few that are especially stiming and heroic.
Star Wars, 2001: A Space Ody... 7 hr 55 min ago via mikiopez share save Digging button Burying button User id Brief description Figure 1: Components in a Digg submission other users can read his article and vote either thumbs up (also called digging) or thumbs down (also called burying) for the article.
Each article in Digg consists of a user id, its submission title, a brief description and the link to the interesting web page as shown in Figure 1.
Digg service displays not only the submitted articles with a lot of  diggings  but also new submissions with their Digg scores where the Digg score of a submission is de ned as the number of diggings subtracted by the number of bury-ings.
Digg service currently lists the Digg articles in its front page without considering each user s topic preference.
Helping users to  nd the most interesting Digg articles tailored to each user s own interests is very useful, but it is not an easy task to classify the submissions according to their topics so that the submitted articles are recommended di erently to each user based on his own topic preference.
Another challenge in Digg service is the problem of cold-start recommendations [21, 25] which occurs when the voting histories and submitted articles of users are not su cient.
Other popular websites such as Facebook [11] and CiteU-Like [6] not only allow users to vote for the messages and the papers posted by other users respectively, but also post the voting scores which can be utilized to infer the topic preferences of users.
Thus, our work in this paper can also be used to enhance the quality of recommendation systems for Facebook and CiteULike as well.
In our paper, we propose DIGTOBI which is a personalized recommendation system for DIGg arTicles using prOb-aBIlistic modeling.
Our probabilistic model is a generalization of the probabilistic latent semantic indexing (PLSI) in [12] which assumes that the description in each submission has its own topic relevance model and each word in the description is selected by following the word distributions of its related topics.
Since recommendation algorithms can be naturally derived in a principled manner by utilizing probabilistic modeling, it is another reason why we decide to apply the probabilistic modeling approach to the Digg article recommendation.
We develop a generative model from a unifying viewpoint such that the description in each submission is produced by 691a topic mixture model and each user votes thumbs up for each submission based on his topic preference.
Since Digg service provides us only the dug articles and does not provide the buried articles by users, we could not utilize the votes of thumbs down in our model.
If we blindly apply the PLSI model to Digg, we cannot fully utilize each user s digging history and submitted articles together.
Thus, we introduce not only a topic mixture model of generating the descriptions in the submitted articles, as the PLSI model does, but also another topic model of producing the histories of digging and writing by each user, and apply both topic models into our probabilistic model.
In our probabilistic model, we assume that every user writes the descriptions in his submissions according to his topic preference.
Furthermore, we assume that when a user votes for submissions, the submissions with the similar topic relevances to his own topic preference have high chances of being voted for.
The traditional recommendation algorithms tend to o er users the articles with high scores which are probably preferred by most of users.
However, users are interested in the relevant articles with low scores to their topic preferences as well.
Thus, our model also considers the relevant articles with low Digg scores to be important.
It is possible that the articles with high Digg scores may be dug by many users simply because they have more chances to be displayed in Digg service, and the others have no chance of being voted for at all.
In our model, when an article with a small Digg score is dug by a user, we assume that the article has more similar topic relevance to the user s topic preference.
This assumption enables our model to capture the topic preference of each user precisely and discover the interesting articles to each di erent user, even if the articles have low Digg scores.
The contributions of this paper are as follows:   We develop the personalized recommendation system called DIGTOBI which utilizes our novel probabilistic generative model.
The model is suitable for representing the activities in Digg service as well as the other websites which allow users to vote the contents posted by other users.
  We improve the quality of recommendations by reducing the bias of the collaborative  ltering which mainly recommends the popular articles with high Digg scores.
  We present the EM algorithm which estimates the model parameters maximizing the likelihood of our probabilistic model used by DIGTOBI.
  We also introduce the recommendation algorithms for both warm-start and cold-start naturally derived from our probabilistic model of DIGTOBI in a principled manner.
  Our performance study with Digg data con rms the e ectiveness of DIGTOBI compared to the traditional recommendation algorithms.
The rest of this paper is organized as follows.
After discussing related work in Section 2, we provide the de nitions to de ne our problem and present the problem formulation in Section 3.
We next propose a generative probabilistic model and its EM algorithm in Section 4.
Then, we present our recommendation algorithms in Section 5.
Finally, the performance study is provided in Section 6 and we summarize our paper in Section 7.
Model-based algorithms build their models based on the behaviors of users and utilize the models to predict the users  preferences on unseen items.
In [22], it was shown that recommendations using probabilistic modeling outperform other approaches in terms of precision.
The probabilistic matrix factorization technique in [23] was also developed for movie recommendations in Net ix [20] to predict user ratings on movies.
However, these algorithms utilize only the history of ratings or votings for the items generated by users and do not consider additional hints such as the textual content of the items for recommendations.
More complex probabilistic models were later proposed in various recommendation applications.
In [13, 17, 26], recommendations utilizing the PLSI in [12] were investigated.
The LDA model, introduced in [4], is generalized to model both latent topics and hidden communities between users in [1, 2].
However, these algorithms make recommendations by utilizing either the user s past ratings on items or the textual content of items, but not both.
In [28], a system called CTR was proposed to recommend scienti c papers to each user in CiteULike [6].
CiteULike is a specialized search engine for searching the technical papers and allows people to share their favorite papers by voting thumbs up for the papers.
To make recommendations by utilizing both of user s votes and the content of papers, they combine the matrix factorization [23] and the LDA model [4] together, and show that CTR outperforms the recommendations based on either matrix factorization or the LDA model only [28].
While both CiteULike and Digg service allow the users to post their votes for each document, CiteULike does not allow the users to post the descriptions of why they like.
Digg service not only allows the users to submit the descriptions of web documents, but also posts the Digg scores.
Thus, our probabilistic model is more general in that we consider both Digg scores and user descriptions, while CTR in [28] does not considered both of them.
If we want to use the CTR model for recommending Digg articles, we can extend it by ignoring the Digg scores and the descriptions posted by users.
In [5], recommending URLs in Twitter messages was studied by exploiting the social network of users and the popularity of the URLs in Twitter.
They simply represent Twitter messages of a user as a bag-of-word for content-based recommendations without considering any sophisticate user modeling, while our work utilizes probabilistic modeling.
To recommend the articles with hot topics in Digg service, HotDigg which is a probabilistic model based recommendation system was proposed recently in [14].
However, Hot-Digg aimed to recommend the articles on recent hot topics to general users using the Digg scores and the descriptions of submissions only, while we aims to provide personalized recommendations in this paper.
We  rst provide the de nitions used for de ning our recommendation problem and next present the problem formulation.
Let D = {d1, ..., dn} be a collection of the Digg article ids submitted to Digg service.
Let U = {u1, ..., um} be a set of
 iPhone, Apple, Samsung iPhone, AppStore, Samsung Samsung, iPhone, AppStore, Baker Sherlock, 221B, Apple, Baker D(u) W (di) d1 d2 d3 d4 d5 d6 d7 (a) Warm-start data set d3,d4 d1,d2,d3 Apple, iPhone, Sherlock Sherlock, Holmes, iPhone si






 User u1 L(u) d5 u2 u3 u4 User u5 u6 L(u) D(u) d2,d3,d4 W (di) si U (di) iPhone, AppStore, Samsung d8 d9 Baker, Apple (b) Cold-start data set

 u2,u3 Figure 2: An example of users and articles Digg user ids.
A user can submit an article which consists of the user id as well as the title, a brief description and the link to the interesting web page of the submitted article.
Let D(ua) denote the set of Digg article ids which are submitted by the user ua   U and let W (di) denote the bag-of-words appearing in either the title or the description of the article di   D. The number of words in W (di) is denoted by Ni and we use wij (1 j Ni) to represent the j-th word appearing in the article di   D. For each article di   D, we generate the bag-of-words W (di) by deleting the stop-words from its original title and description.
Let W = {w1, ..., w } be the vocabulary which is the set of distinct words occurring in at least an article di   D. We de ne n(di, w) to denote the number of occurrences of the word w   W in W (di).
Digg users can vote thumbs up or thumbs down, called digging or burying respectively, for each Digg article.
Every article di   D has a Digg score si of an integer which is the number of diggings subtracted by the number of buryings voted for di.
Let L(ua) denote the set of article ids in D for which the user ua   U votes thumbs up.
For burying, we cannot obtain the list of articles for which users vote thumbs down and thus we utilize the history of diggings only.
Let U (di) denote the set of users in U who dug the article di   D.
Finally, we refer to a user ua   U to whom Digg articles are recommended as an active user.
Problem de nition: Assume that we are given a collection D of Digg articles with Digg scores and a set of users U with the history of diggings for each user in U .
The top-K Digg article recommendation problem is de ned as follows: Problem 1.
For an active user ua   D and a set of candidate articles C which are not submitted nor dug by the user ua yet, the problem is to  nd the top-K Digg articles which the user ua would like the most among the candidate articles in C.
Example 3.1.: Consider a set of users U ={u1,...,u4} and a set of Digg articles D={d1,...,d7} in Figure 2(a).
The articles dug by each user are presented in the column of L(u).
We can see that there exist two topics of  smartphone  and  Sherlock Holmes .
The topic of  smartphone  is much more popular than that of  Sherlock Holmes  in the Digg articles.
Thus, the articles on  smartphone  usually obtain higher scores and have more chances to be listed in the front page of Digg service.
Suppose that we recommend the top-1 article for the user u3 who posted the article d6 and voted thumbs up for d3 and d4 both of which are submitted by u2.
Considering the articles he dug and submitted, we can see that he obviously wants Seen article Unseen article Seen user Warm-start Cold-start type 2 Unseen user Cold-start type 1 Cold-start type 3 Figure 3: Four types of recommendations to read the articles about  smartphone .
If we simply consider only the other articles submitted (or voted) by the user u2, who submitted the articles that u3 mainly dug, we would recommend the article d5 which is posted by u2.
However, the user u3 prefers the topic of  smartphone  and it is better to recommend the article d2 on  smartphone  rather than the article d5 which is about the topic of  Shelock Holmes .
Now, suppose that we want to recommend the top-1 article for the user u4 who submitted an article d7 which contains more words referring to  Sherlock Holmes  than  smartphone .
From the history of his diggings, we may think that he is interested in the articles on  smartphone  since he dug d2 and d3.
Due to their high scores, the articles on  smartphone  generally have more chances to be displayed in the front page of Digg service and thus the reason why u4 dug them is probably because he has actually seen the articles d2 and d3 in the front page.
However, considering the contents of d7 submitted by the user u4, recommending the article d5, which is related to the topic  Sherlock Holmes , is also important to the user u4.
The top-K recommendation problem is classi ed into four categories based on whether the active users, the candidate articles to be recommended, or both of them are included in the training data, which is used to learn the parameters of models, as illustrated in Figure 3.
  Warm-start recommendation: This is the case when both of the active users and the candidate articles are seen (i.e., the active users and candidate articles were included in the training data used for learning the model).
  Cold-start recommendation of type 1: It is the recommendation of seen candidate articles to an unseen active user (i.e., the active user was not included in the training data).
  Cold-start recommendation of type 2: This refers to the recommendation of unseen candidate articles (i.e., the candidate articles were not included in the training data) to a seen active user.
  Cold-start recommendation of type 3: It is the case of recommending unseen candidate articles to an unseen active user.
Previous works have shown the e ectiveness of topic mixture models in clustering text collections by representing hidden topics with conditional probability distributions[4,
 do not consider the ratings of text documents provided by users in order to get a clue for the topic preferences of users.
To model both writing and digging behaviors of users, we use a model structure with the mixtures of conditional probability distributions by generalizing the PLSI model in [12] to consider the digging behaviors of users in Digg service.
d z w
 Du w|z ~  : Multinomial Figure 4: A graphical model Observed data: We assume that our generative model produces the following observed data: (1) the bag-of-words W (di) for every Digg article di D, (2) the list D(ua) of Digg article ids submitted by every user ua U , (3) the list L(ua) of Digg article ids dug by every user ua U .
Hidden topics: We assume that there exist t number of major topics denoted by the integers from Z={1, 2, ..., t} in a collection of Digg articles D. We let wij be the j-th word appearing in the article di   D and let a random variable zij be the hidden variable to represent one of the t number of topics according to which the word wij is chosen.
Note that we do not know in advance the actual label with which we can identify the topic zij.
Conditional probability distribution functions (PDFs): We introduce the following three conditional PDFs to represent the topic relevance models of articles, topic preference models of users as well as word selection models of topics: (1) The topic relevance models of articles: We introduce  (z|d=di) which is the conditional PDF with which we select the topic z   Z for a given Digg article di   D. It is a multinomial distribution over the topics in Z satisfying  (z=zk|d = di) = 1 for every di   D, (1)
 zk Z (2) The topic preference models of users: We de ne  (z|u=ua) that is the conditional PDF with which a user ua   U chooses the topic z   Z.
It follows a multinomial distribution over the topics in Z and thus we have  (z=zk|u = ua) = 1 for every ua   U , (2)
 zk Z (3) The word selection models in topics: We use  (w|z=zk) to represent the conditional PDF from which the word w   W is drawn, given the topic zk   Z.
It is also a multinomial distribution over the words in W which satis es
 wj  W  (w=wj |z = zk) = 1 for every zk   Z (3) As long as it is clear from the context, we denote  (z|d=di),  (z|u=ua) and  (w|z=zk) by  (z|di),  (z|ua) and  (w|zk) respectively for the sake of simple representation.
Figure 4 illustrates the graphical representation of our proposed mixture model.
Note that pa and pv, both of which will be dicussed in Section 4.2, denote the probabilities of submitting an article and digging an article by a user respectively.
Our generative model includes two independent generative processes.
The  rst process considers the behavior of writing Digg articles by users.
The second one represents how Digg users dig the articles written by other users.
Both processes are illustrated below: Writing Digg articles: Each Digg article di   D(ua) is produced by the user ua   U with repeating the following steps while choosing the words stochastically:   The user ua decides to write the Digg article di   D(ua) by following the Bernoulli distribution with the success probability computed by the function EXP-KL( (z|di);  ,  (z|ua)) where   is a constant in our model.
As the multinomial distributions  (z|di) and  (z|ua) become similar, the EXP-KL function generates high probability values.
Similarly, as they become dissimilar, it produces low values closer to 0.
We will discuss the EXP-KL function in the next section.
  Each word in W (di) is selected by repeating the following two steps Ni times.
topic zij Z by following the conditional PDF  (z|di).
is chosen according to the conditional PDF  (w|zij).
Digging Digg articles: A user ua determines whether he digs each Digg article di D(ua) or not by following the Bernoulli distribution with the success probability of EXP-KL(  (z|di);  /si,  (z|ua)) where si is the Digg score of di and   is a constant in our model.
Since the Digg articles with high scores have more chances to be shown to each user, if the article di has a high Digg score si, the user ua tends to dig di with a higher probability than the Digg articles with small Digg scores in the formulation of EXP-KL( (z|di);  /si,  (z|ua)).
We will next introduce the EXP-KL function used in our model and discuss its property.
Given two multinomial distributions, we propose to utilize the exponential KL-divergence (EXP-KL) function in our probabilistic model in order to obtain higher success probabilities for Bernoulli distributions [30] as the two multi-nomial distributions become similar to each other.
Given a scalar value   and a t-dimensional multinomial distribution  , the exponential KL-divergence function EXP KL( ;  ,  ) over the t-dimensional multinomial distribution   is de ned as EXP KL( ;  ,  ) =  e KL[ || ], (4) where KL[ || ] is the Kullback-Leibler (KL) divergence between   and  , which is presented in [7] as KL[ || ] = t
 i=1  i   log( i/ i), (5) and   is the parameter which determines the steepness of the EXP-KL function.
The EXP-KL function generates the probability density of   when  = .
The probability densities calculated by using EXP-KL decrease with increasing the distance between   and  .
Furthermore, with a large  , the probability densities decrease faster when the distance between   and   grows.
We next show how the EXP-KL function is utilized in our model in details.
user ua U , whose topic preference is  (z|uz), submits the article di D, of which topic relevance is  (z|di), with the probability of EXP KL( (z|di);  ,  (z|ua)) =  e KL[ (z|ua)|| (z|di)], (6) where   is a constant in our model.
With a small  , it becomes more probable that an article with a quite di erent topic relevance of  (z|di) from its author s topic preference is submitted.
Thus, by setting a small value to  , we can allow Digg users to submit the articles with diverse topic relevances.
The probability of digging an article by a user: A user ua U , whose topic preference is  (z|ua), digs the article di D with Digg score si, whose topic relevance is  (z|di), with the probability of EXP KL( (z|di);  /si,  (z|ua)) =   si e ( /si) KL[ (z|ua)|| (z|di)], (7) where   is a constant such that with a small value of  , it becomes more probable that a user ua with the topic preference of  (z|ua) votes thumbs up for the article di with a quite di erent topic relevance of  (z|di) from his topic preference  (z|ua).
Furthermore, since the articles with high Digg scores not only are interesting to many users but also have more chances to be displayed in the front page of Digg, such articles will be dug by many users with higher probabilities.
For the article di with the Digg score si, by using the steepness parameter ( /si) in the EXP-KL function, the users tend to dig the articles with larger Digg scores in our model.
Let D and U be a set of Digg articles and a set of Digg users respectively.
For each Digg article di   D, we have a bag-of-words W (di) and a Digg score si.
For each Digg user ua   U , let D(ua) and L(ua) be the set of articles that the user ua submitted and the set of articles that ua dug respectively.
Let ppost(di|ua) and pdigg(di|ua) represent the probability that ua summits the Digg article di and the probability that ua votes thumbs up for di respectively.
Since each user ua   U posts the Digg articles in D(ua) and digs those in L(ua) independently in our model, the likelihood L of the Digg data becomes
 ua U      
 di Du ppost(di|ua)       
 di Lu pdigg(di|ua)    .
    Since each word in W (di) is sampled independently after the user ua decides to submit the article di, we have ppost(di|ua) = EXP KL( (z|di);  ,  (z|ua))   Y wij  W (di) p(wij |di).
Furthermore, if we marginalize p(wij|di) with the random variable zij, p(wij|di) becomes Pzk Z  (w=wij|zk)  (z=zk|di).
Finally, since each article in L(ua) is dug by ua independently by following the distribution EXP-KL( (z|di);  /si,  (z|ua)), we obtain the likelihood as follows
 ua U
 di D(ua)  e KL[ (z|ua)|| (z|di)]
 di D(ua)  
 zk Z  (wj |zk) (zk|di)   
 wj  W n(di,wj )
 di L(ua) ( /si)e ( /si) KL[ (z|ua)|| (z|di)], (8)
 ua U
 ua U where n(di, wj) denotes the number of appearances of the word wj   W in the article di.
Assume that the observed data is generated from our generative model.
Let   denote our initially-unknown model parameters, which consist of the distributions  (w|zk) for every zk   Z,  (z|di) for every di   D and  (z|ua) for every ua   U .
We wish to  nd the model parameters   such that the likelihood L in Equation (8) is maximized.
This is known as the Maximum Likelihood (ML) estimation [19] for computing  .
In order to estimate  , we generally introduce the log-likelihood function de ned as log L =
 ua U
 di D(ua)
 wj  W n(di, wj ) log X zk Z  (wj |zk) (zk|di)     X ua U     X ua U
 di D(ua) KL[ (z|ua)|| (z|di)]
 di L(ua) (1/si)   KL[ (z|ua)|| (z|di)]
 ua U
 di D(ua) log   + X ua U
 di L(ua) log( /si).
(9) The likelihood function is considered to be a function of the parameters   for the Digg data.
Since log L is a strictly increasing function, the parameters of   which maximize log-likelihood of log L also maximize the likelihood L [31].
Note that the parameters  (z|d),  (z|u) and  (w|z) are probability values and thus we have the constraints of Equations (1) (3).
Using these constraints, we calculate the model parameters   with maximizing the log-likelihood log L in Equation (9).
The e ect of   and  : Note that KL-EXP( (z|uz)|| (z|di)) in the log-likelihood of Equation (9) can be represented as  H[ (z|ua)]   Pz log  (z|di) where H[ (z|ua)] is the entropy of  (z|ua).
It is known that the entropy of multino-mial distribution is maximized when the distribution is uniform [7].
Since KL-EXP( (z|uz)|| (z|di)) is multiplied by   and   in Equation (9), with large   and  , maximizing the entropy terms increases the log-likelihood of Equation (9) more than maximizing the other terms in Equation (9) does.
Thus, when   and   are large, the distribution of  (z|ua) becomes closer to the uniform distribution.
Furthermore, when both of   and   are zeros, our model becomes the original PLSI model in [12] which is a special case of our model.
Without any prior knowledge to the model parameters, we can apply the maximum likelihood estimator to compute all the parameters by applying the EM algorithm [8].
An
 p(k+1)(zij =zk|di, wij ) =  (k)(w=wj |zk) (k)(z=zk|di) Pz   Z  (k)(w=wj |z ) (k)(z=z |di) M-step:  (k+1)(w=wj |zk) = Pdi  D n(di, wj )   p(k+1)(z=zk|di, wj ) Pw   W Pdi  D n(di, w )   p(k+1)(z=zk|di, w )  (k+1)(z=zk|di) =  (k+1)(z=zk|ua) = Pwj  W n(di, wj )   p(k+1)(z=zk|di, wj ) +  (k)(z=zk|ua) + ( /si) Pu   U (di )  (k)(z=zk|u ) Pz   Z {Pwj  W n(di, wj )   p(k+1)(z=z |di, wj ) +  (k)(z=z |ua) + ( /si) Pu   U (di )  (k)(z=z |u )} hQdi  D(ua )  (k+1)(z=zk|di)  Qdj  L(ua )  (k+1)(z=zk|dj ) /sj i1/( |Du|+Pdj  L(ua )  /sj ) Pz   Z hQdi  D(ua )  (k+1)(z=z |di)  Qdj  L(ua )  (k+1)(z=z |dj ) /sj i1/( |Du|+Pdj  L(ua )  /sj ) Figure 5: The formulas for E-step and M-step (10) (11) (12) (13) EM algorithm performs the iterations with the two steps of an expectation step (E-step) and a maximization step (M-step).
In the E-step, the probability distributions of the hidden variables are computed by using the current estimate of parameters, and in the M-step, the parameters maximizing the log-likelihood are calculated by utilizing the expectation computed in the E-step.
The parameters estimated in the M-step are then used in the E-step of the next iteration.
The E-step: This step calculates the expectation of the hidden variables.
Each hidden variable is the topic zij which is chosen for selecting the word wij (i.e., the j-th word occurring at di).
Let p(zij=zk|di, wij) be the probability that a word wij is generated from the topic zk in the Digg article di.
The formula to compute p(k+1)(zij=zk|di, wij) in the E-step of the (k+1)-th iteration using the model parameters  (k) computed in the k-th iteration is presented in Figure 5.
The M-step: In order to  nd the parameters  (k+1) maximizing Equation (9), we apply the method of Lagrange multipliers [3].
The obtained formulas for the M-Step to update the model parameters   at the (k+1)-th step are listed in Figure 5.
Note that the topic preference  (z=zk|ua) of the user ua is calculated in the form of geometric mean, which is commonly used to compute the average of ratio values [29], with the topic relevances  (z=zk|dj) of the Digg articles written and dug by the user ua.
We iterate the E-Step and M-Step until we obtain the convergence of the log-likelihood in Equation (9).
Since our EM algorithm only guarantees to  nd a local maximum of the likelihood, we perform multiple trials and choose the best one among the local optima found.
Once the parameters   in our model are estimated, recommendations can be made by utilizing the model parameters.
Top-K warm-start recommendation: To recommend the top-K Digg articles, for a user ua and an article di, we predict the preference of the user ua for an article di using the KL divergence between  (z|ua) and  (z|di) as Score(ua, di) = 1/KL[ (z|ua)|| (z|di)] (14) and recommend the top-K scored articles among the candidates.
It is because the KL divergence between  (z|ua) and  (z|di) increases as both of  (z|ua) and  (z|di) become more di erent.
Note that since we should recommend the articles with similar topic preferences to the user s preference regardless of the articles  Digg scores, we simply utilize KL[ (z|ua)|| (z|di)] only for warm-start recommendations.
Top-K cold-start recommendations: We make cold-start recommendations of the three types mentioned in Section 3.2 as follows.
  For the type 1, we estimate the topic preference  (z|ua) of the active user ua unseen in the training data and compute Score(ua, di) in Equation (14) by using  (z|di) of the candidate article di seen in the training data and the estimated  (z|ua) for top-k recommendation.
  For the type 2, if an article di in the candidate set is unseen in the training data, we  rst estimate  (z|di), and compute Score(ua, di) using the estimated  (z|di) and the topic preference  (z|ua) of the active user ua seen in the training data.
  For the type 3, we estimate both of  (z|ua) and  (z|di) to compute Score(ua, di) in Equation (14).
We next present how to estimate  (z|ua) for an unseen user ua and  (z|di) for an unseen Digg article di.
Computing  (z|ua) for an unseen user ua:When an unseen user ua is not included in the training data but the articles submitted or dug by ua participate in the data, given the model parameters  (z|di) of those articles di, the probability that ua posts the articles in D(ua) and diggs those in L(ua) for the unknown distribution  (z|ui) can be computed by using Equation (8) as
 di D(ua) e KD[ (z|ua)|| (z|di)]
 di L(ua) e ( /si)KD[ (z|ua)|| (z|di)], (15) where  (z|di) is the topic preference of the article di which exists in the data.
By Lagrangian method, we can derive the optimal distribution of  (z|ua), which maximizes the probability in Equation (15), as follows  (z|ua) =
 Z(ua)
 di L(ua)  (z|di)  di D(ua)  
  (z|di) /si     |D(ua )|+Pdi  L(ua )  /si
 , (16)
 User z1 z2 u1 0.47 0.52 u2 0.87 0.13 u3 0.81 0.19 u4 0.25 0.75 u5 0.94 0.06 Topic Topic Doc z1 z2 Doc z1 z2 d1 0.11 0.89 d5 0.43 0.57 d2 0.87 0.13 d6 0.70 0.30 d3 0.96 0.04 d7 0.31 0.69 d4 0.93 0.06 d8 0.99 0.01 d9 0.65 0.35 (a)  (z|u) (b)  (z|d) Topic Topic Topic Word z1 z2 Word z1 z2 Word z1 z2 Sherlock 0 0.41 Baker 0.08 0.18 Samsung 0.21 0 Holmes 0 0.20 iPhone 0.35 0 AppStore 0.14 0
 (c)  (w|z) Seen Unseen user user u5 Doc u3
 d1 0.76 -d2 90.7 -d3 --d4 -
d5 3.17
 d6 -
d7 1.86 u4 ---


-d8 2.60 0.34 d9 - 2.98

 (d) scores Alg.
Training Warm-start Recommendation Cold-start Type 1 Type 2 Type 3

 HotDigg HOTDIGG-EM HOTDIGG-W - - -

Baseline - BASE-W BASE-C1 BASE-C2 BASE-C3 Figure 7: The implemented algorithms k=1  (z=k|ua) Figure 6: The resulting model parameters and scores where Z(ua) is the normalization factor to make Pt = 1.
Since the articles written by ua are not generally contained in the training data when the author ua is not in the training data, the set D(ua) of the articles submitted by ua is usually empty.
Computing  (z|di) for an unseen article di: For an unseen Digg article di in the training data, which was submitted by a seen user uj and dug by seen users U (di), we can formulate, by using Equation (8), the probability that di is generated to include the words in W (di), posted by uj and dug by the users in U (di) as follows:  e KD[ (z|ua)|| (z|di)]

  (w|z ) (z |di) w W (di) z Z
 u U (di) ( /si)e ( /si)KD[ (z|u)|| (z|di)].
(17) To compute  (z|di) maximizing the above probability, we should develop another EM algorithm requiring heavy computation.
Thus, we approximate  (z|di) by performing only the  rst iteration of the EM algorithm with initializing  (z|di) uniformly and calculate it as
 Z(di)  
 w W (di)  (w|z) Pz Z  (w|z ) +  (z|uj ) +   si X u U (di)  (z|u)    (18) , where Z(di) is the normalization factor to make Pt = 1.
Our experiments show that executing only a single iteration of the EM algorithm estimates good  (z|di)s enough for cold start recommendations of both type 1 and type 3.
k=1  (z=k|di) Example 5.1.: Consider the Digg articles and the users shown in Figure 2.
We assume that the number of topics t is
  (z|u),  (z|d) and  (w|z) after our EM algorithm  nishes.
Note that the hidden topics z1 and z2 represent the topics of  smartphone  and  Sherlock Holmes  respectively.
Warm-start recommendations: Let us  nd the top-1 article to recommend to the user u3 among the candidate set C={d1,d2, d5,d7} which are not submitted nor dug by u3.
The scores of the articles in C according to Equation (14) are provided in Figure 6(d).
As we discussed in Example 3.1, the user u3 showed his interest in the topic of  smartphone .
Since the article d2 is on the topic  smartphone  and obtained the highest score among the articles in C, we recommend d2 to u3 as the top-1 article.
Cold-start recommendations of type 1: The values of  (z|u5) for an unseen user u5 according to Equation (16) are presented in Figure 6(a).
Since u5 dug the articles d2,d3 and d4 on the topic  smartphone  that is represented by z1,  (z1|u5) has the highest score as expected.
Thus, among the candidate articles C={d1,d2,d5,d7} which are seen and not dug by u5, d6 has the highest score and is thus recommended as the top-1 article to u5.
Cold-start recommendations of type 2: Let C={d8,d9} be the candidate articles which are unseen in the training data.
The values of  (z|d8) and  (z|d9) are shown in Figure 6(b).
As expected from the content of d8,  (z1|d8) has the highest probability representing that d8 is related the most to the topic  smartphone .
Thus, the article d8 obtains the highest score among the articles in C for the user u3 and u5.
Furthermore, since d9 is mainly dug by the users interested in the topic of  smartphone  which is represented by z1, we can see that  (z1|d9) >  (z2|d9).
Cold-start recommendations of type 3: The recommendation scores Score(ua, di) between the unseen user u5 and the unseen articles {d8, d9} are shown in Figure 6(d).
Among the unseen articles, d8 on the topic  smartphone  is recommended to u5 as the top-1 article since u5 is interested in the same topic but d9 is related to another topic.
We empirically evaluated the performance of our proposed algorithms.
All experiments reported in this section were performed on the machine with Intel(R) Core(TM)2 Duo
 following algorithms were implemented using GCC Compiler of version 4.1.3.
  DIGTOBI: We implemented our proposed EM algorithm in Section 4.5 and the top-K recommendation algorithms in Section 5.
  CTR: Since CTR [28] combines the matrix factorization and the LDA model, and is shown to outperform the recommendations based on either matrix factorization or the LDA model only [28], we selected CTR as the state-of-the-art for this application.
We downloaded the implementation of CTR in C language available at http://www.cs.princeton.edu/ chongw/citeulike/.
In [28], they proposed the recommendation algorithms for warm-start and cold-start of type 2 only.
To deal with cold-start of type 1 and type 3, we estimated the latent vector ui of the i-th user to maximize the likelihood of the CTR model (Equation (7) in [28]) as follows: ui = (    I + B) 1 A (19) where B is a matrix such that Bxy = Pj cijvjxvjy and A is a vector such that Ax = Pj cijrijvjx.
Note that vj is the latent vector of the j-th item estimated by the CTR model and the other parameters (i.e., cij, rij and  u) are the given values.
[5] as well.
It was proposed to recommend Twitter messages using only the text messages and cosine similarity without any domain speci c knowledge.
They do not apply any user modeling method but simply represent Twitter messages of a user as a bag-of-word for content-based recommendations.
Thus, this recommendation algorithm does not need the training phase.
  HOTDIGG: It is the implementation of HotDigg recommendation algorithm in [14].
It recommends Digg articles without considering each user s preference.
  MEM: We also implemented the simple memory-based recommendation algorithm in [24] which works for warm-start recommendations only.
  BASE: This is the implementation of the baseline algorithm which is capable of both warm and cold start recommendations by selecting K articles randomly among the candidate articles.
All algorithms for warm and cold start recommendations are categorized in Figure 7 where each empty entry denotes that its corresponding algorithm cannot handle the case represented by its column.
In our experiments, the train phases of all algorithms were performs 10 times for  nding local maxima with the termination condition used by CTR in [28] and we chose the best one as the model parameter values.
We downloaded 120,896 Digg articles submitted or dug by
 ing Digg API available at http://developers.digg.com/.
The number of diggings, which are represented by the pairs between those downloaded users and articles, is 680,971.
We removed the stop words appearing in more than 80% of all articles.
Furthermore, we also deleted the words occurring in less than 3 articles since such words do not provide any clue for topical clustering.
All words in Digg articles were stemmed by using the stemmer library in Lucene [16].
We refer to this data as ORG-DATA.
We selected a subset of diggings from ORG-DATA to generate the test data sets and the rest of the other data is used as the training data to estimate the model parameters.
We generated the test data sets as follows.
  TEST-W1: For warm-start recommendations, we selected 10,000 diggings of 100 users from ORG-DATA by the following steps: We  rst chose a seed user from ORG-DATA randomly and selected another 99 test users from ORG-DATA by choosing each user, who has the least common diggings with the users selected already, one by one greedily.
Then, we extract 100 diggings of each selected user randomly.
We found 7,479 number of distinct dug articles in the extracted diggings for all test users and used them as the candidate articles for recommendations.
  TEST-W2: For warm-start recommendations, we selected another set of 10,000 diggings randomly.
We  rst choose 100 users randomly from ORG-DATA and next extracted 100 diggings for each selected user randomly.
We also used distinct dug articles in the extracted diggings as the candidate articles for recommendations.
The number of candidate articles was 4,887.
  TEST-C1: For cold-start recommendation of type 1, we chose 40 new users who are not included in ORG-DATA but have dug at least 10 articles in ORG-DATA.
We used the articles dug by the 40 new users as the candidate articles for recommendations.
Note that we could not select more test data for cold-start recommendations because there are a small number of new users who have dug enough articles.
  TEST-C2: For cold-start recommendations of type 2, we chose 40 users from ORG-DATA randomly and for each user, we downloaded 10 more Digg articles which are dug by the user but not included in ORG-DATA.
Then, the newly downloaded 400 articles were used as the candidate articles for recommendations.
  TEST-C3: For cold-start recommendations of type 3, we downloaded 40 new users with 10 diggings for each user such that both of the users and their dug articles are not included in ORG-DATA.
The downloaded 400 new articles are used as the candidate articles for recommendations.
We conducted our experiments with varying the number of recommendations K, the number of hidden topics t, the parameters   and   which are the constants used in the exponential KL divergence distributions in Section 4.
The default values of these parameters are: K=30, t=100,  =106 and  =106.
Quality measures: We computed three basic quality measures called recall-at-K, precision-at-K [27] and average hit-rank [9].
(The recall-at-K is also known as hit-rate [9].)
With the top-K recommendations for a test user u, let h be the number of correctly matched articles among the top-K recommended articles and nT (u) be the number of articles dug by the user u in the test data.
Assume that d1, ..., dh are the h number of correctly matched articles by recommendations.
Let si and pi denote the Digg score of di and the rank of di among the top-K recommended articles respectively.
Then, the recall-at-K and precision-at-K for u are h/nT (u) and h/K respectively.
The average hit-rank is calculated as 1/nT (u)   Ph i=1 1/pi which measures the e ectiveness of ranking for each test user.
As the dug articles by a test user appear with higher ranks in the top-K recommended articles, this measure becomes larger.
Thus, the high values of average hit-rank are more desirable.
Digg articles with high scores tend to be exposed in the front pages of Digg service and thus get more chances of being dug.
However, it is also desirable to recommend the relevant articles with low Digg scores to user s preference.
Thus, we revised the above three goodness measures and also calculated those new measures to show that DIGTOBI does not simply select popular articles but  nds each user s favorite articles among the low scored articles as well.
To have better scores for the correctly recommended articles with small Digg scores, when si denotes the Digg score of the correctly matched article di, the weighted recall-at-K is calculated as 1/nT (u)   Ph i=1 1/si which is the sum of the inverse of the Digg score for every correctly recommended article.
Similarly, the weighted precision-at-K and weighted average hit-rank are calculated as 1/K   Ph i=1 1/si and 1/nT (u)   Ph i=1 1/(pi si) respectively.
t i a n o s c e r
 i
 t i a n o s c e r p i d e t i h g e

 t i a n o s c e r
 i











 k n a r t i h e t a r e v













 t a l l a c e




































 (a) Precision-at-K (b) Average hit-rank (c) Recall-at-K










 k n a r t i h e t a r e v a d e t i h g e





 1e-005






 t a l l a c e r d e t i h g e
































 (d) Weighted precision-at-K (e) Weighted average hit-rank (f) Weighted recall-at-K Figure 8: Top-K Digg article recommendations with varying K (TEST-W1)











 k n a r t i h e t a r e v















 t a l l a c e
































 (a) Precision-at-K (b) Average hit-rank (c) Recall-at-K Figure 9: Top-K Digg article recommendations with varying K (TEST-W2) Warm-start recommendations: We  rst evaluate the quality of warm-start recommendations using TEST-W1.
Figures 8(a) (c) show precision-at-K, average hit-rank and recall-at-K of the six warm-start recommendation algorithms listed in Figure 7 respectively with varying K from 1 to 120.
The graphs illustrate that DIGTOBI-W for every K outperforms the other recommendation algorithms in terms of every quality measure.
As expected, HOTDIGG and BASE are the worst performers since both of them are not personalized recommendation algorithms.
As we increase K, since we have more chances to answer the right articles correctly, both recall-at-K and average hit-rank of all algorithms grow gradually.
The precision-at-K of DIGTOBI-W is the largest when K=1 and decreases gradually as K is increased.
However, the precision-at-K of the other algorithms increases with growing K. This is because DIGTOBI-W has good characteristics of making the correct answers to have higher ranks while the other algorithms do not.
For the same reason, the performance improvement of our algorithm DIGTOBI-W to the other algorithms becomes better with respect to the average hit-rank rather than the recall-at-K for a  xed K. For instance, when K=10, DIGTOBI-W shows better performance than CTR-W by 2.32 times with the recall-at-K, but with the average hit-rank, DIGTOBI-W outperforms CTR-W by 3.07 times.
With the same experiments, we also plotted the three new weighed quality measures in Figure 8(d) (f).
The log scale was used in the y-axis.
The graphs show that the recommendations by DIGTOBI-W show better qualities than those by the other algorithms for every K. COS-W and CTR-W are the second and the third best performers respectively.
For example, when K=10, the modi ed precision-at-K of DIGTOBI-W is 1.92 times higher than that of COS-W and the modi ed average hit-rank of DIGTOBI-W is 1.89 times better than that of COS-W.
Furthermore, when K=10, the modi ed precision-at-K of DIGTOBI-W is 23.9 times higher than that of CTR-W and the modi ed average hit-rank of DIGTOBI-W is 40.5 times better than that of CTR-W.
Thus, we conclude that DIGTOBI-W recommends the relevant articles to each user s preference e ectively even though they have low Digg scores.
We also tested with TEST-W2 and plotted the precision-at-K, average hit-rank and recall-at-K in Figure 9(a) (c).
The quality of recommendations shows similar trends with the results of using TEST-W1.
Since the graphs for the weighted quality measures also show similar trends, we do not present the graphs with TEST-W2 here.
In general, the values of all quality measures with TEST-W2 are smaller than those with TEST-W1.
The reason is as follows: For TEST-W1, since we selected the users having a small number of common diggings as possible, it is more likely that the candidate articles not dug by a test user ua is the one in which ua is actually not interested.
However, for TEST-W2, since we selected the test data randomly, the candidate articles probably include the articles which are not dug by a test user ua but relevant to the preference of ua.
Even though such articles are recommended to the user ua, we have to regard them as incorrect answers.
Thus, the values of all quality measures with TEST-W2 become smaller than those with TEST-W1.
Cold-start recommendations: Using TEST-C1, we show the recall-at-K and precision-at-K of DIGTOBI-C1, CTR-

-t a l l a c e

 i t a n o s c e r
 i


























 t a l l a c e

 i t a n o s c e r
 i
























 t a l l a c e

 i t a n o s c e r
 i

























 (a) Type 1 (b) Type 2 (c) Type 3 Figure 10: Top-K cold-start recommendations with varying K














 t a l l a c e













 The number of topics t=200 t=100 t=40 t=10 t=5 t=2
 t a l l a c e





  =106/ =106  =106/ =104  =106/ =108  =103/ =103  =1/ =1










 ) n m i ( e m i t n o i t u c e x
 Figure 11: Execution time varying t Figure 12: Recall-at-K varying t Figure 13: Recall-at-K varying ( , ) C1, COS-C1 and BASE-C1 with increasing K from 1 to 30 in Figure 10(a).
Note that MEM cannot handle any type of cold-start recommendation.
We can see that DIGTOBI-C1 makes the best recommendations to the test users in TEST-C1, even though the test users are not considered in the phase of learning model parameters.
For every value of K, CTR-C1 shows the second best performance in terms of both recall-at-K and precision-at-K.
With TEST-C2, we evaluate the qualities of cold-start recommendations of type 2 by DIGTOBI-C2, CTR-C2, COS-C1 and BASE-C2, and plot both quality measures in Figure 10(b).
Remember that the type 2 recommends the Digg articles, which are not seen in the training data, to the seen users included in the training data.
The graph shows that DIGTOBI-C2 also outperforms the other algorithms for cold-start recommendations of type 2.
Figure 10(c) shows the recall-at-K and precision-at-K of DIGTOBI-C3, CTR-C3, COS-C3 and BASE-C3 using TEST-C3 for cold-start recommendation of type 3.
Here, we recommend Digg articles to the test users in TEST-C3 where both articles and test users are not included in the training data.
The graph shows that COS-C3 is better than DIGTOBI-C3 with K 5 but our algorithm DIGTOBI-C3 shows better performance with the other values of K.
Execution time for estimating model parameter: In Figure 11, with varying the number of topics t from 2 to 200, we plotted the running times of the inference algo- rithms DIGTOBI-EM and CTR-TR.
The graph shows that as the number of topics t is increased, the execution time of our inference algorithm DIGTOBI-EM grows linearly with t. However, the speed of CTR-TR slows down very fast as t becomes larger.
We conclude that DIGTOBI-EM outperforms the variational EM algorithm of the LDA model used in CTR-TR in terms of speed for estimating model parameters.
Varying t: With varying K from 1 to 30 and the number of topics t from 2 to 200 together, we measured the quality of recommendations by our recommendation algorithm DIGTOBI-W in terms of the recall-at-K with the test data TEST-W1 as shown in Figure 12.
The graph shows that DIGTOBI-W obtains the best quality of recommendations when t 100 and the quality of recommendations does not improve any more with t>100.
Thus, we use t=100 for the default value in our experiments.
Varying   and  : To  nd the best values for the constants   and   in our probabilistic model presented in Section 4.2, we varied   and   together and plotted the recall-at-K with our recommendation algorithm DIGTOBI-W in Figure 13.
The quality of recommendations by our algorithm was the best when  =106 and  =106.
Thus, we set the default values of both   and   to 106 in our experiments.
We presented DIGTOBI, a personalized recommendation system for Digg articles using a novel probabilistic modeling.
Utilizing the observations that Digg users submit their Digg articles and vote thumbs up for the Digg articles submitted by others depending on their topic preferences, we designed our generative model to describe the probabilistic processes of submitting and digging articles by each user.
Our model improves the quality of recommendations by enabling the relevant articles with low Digg scores as well as high Digg scores to be considered important.
We developed the EM algorithm for learning the best model parameters in our probabilistic model.
We also provided e ective warm-start and cold-start recommendation algorithms utilizing our model parameters.
By performance study, we con rmed the e ec-tiveness of DIGTOBI by comparing the performance with the traditional recommendation algorithms.
Acknowledgment This work was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea govern-ment(MEST) (No.
2012-0000111).
This was also supported by Next-Generation Information Computing Development Program through the National Research Foundation of Ko-rea(NRF) funded by the Ministry of Education, Science and Technology (No.
2012-033342).
