Millions of people rely on cloud services in their daily activities: people search for information, work on documents, listen to music, watch videos, manage their picture libraries, chat with friends and buy goods.
The quintessential requirement of these services is to provide hyper low latency.
Imagine the expectations of a user who simultaneously accesses a service to search for information, publishes a blog entry,  Work was done while the author was visiting Google Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
edits her video or updates a document real time while being on a video call.
These users expect near-instant response in both up and down link interactions between them and services.
Even slight delays frustrate users and encourage them to seek out alternatives.
For example, [14] indicates that optimal wait time is 0.1 seconds, and users start abandoning web page, if it is not presented within that window.
In her interview to CNET, Marissa Mayer mentioned, that any increase in the latency causes search queries to be abandoned.
Amazon found that 100 ms increase in load time of Amazon.com decreases sales by 1%.1 Engineers make it their mission to improve service running time even by a few milliseconds.
As millions of people use these services each day, lower latency translates into signi cant savings for the society as a whole.
Thus, latency is a critical factor for the success of any cloud service and the key to user experience.
Cloud services operate in warehouse-sized data centers and run on clusters of machines to handle user requests.
These systems, in turn, distribute work to ever larger number of machines and subsystems for data procession and machine learning.
These systems handle failures, heavy loads, spam and attacks by dynamically managing resources, sometimes sharing resources across services.
As a result the overall systems that handle cloud services tend to be fairly complex.
Even for a single service one can observes signi cant variations of the latency.
In Figure 1 we plot distribution of latencies for 2 back end services, we also refer to observed latency distribution as latency pro le.
Notice, that for the service on the left latency can be anywhere between 0 and
 ity of requests take around 50-60 ms, signi cant fraction of requests takes longer than 100 ms.
Cloud service providers address latency in a variety of ways.
They typically have dashboards that track multiple measurements, including latency.
This gives some visibility into how latency varies over time, number of failures or fatal symptoms.
Our focus is however on normal operation of the cloud services.
Engineers routinely develop, test, and launch new code.
Often newly launched or modifed services, disrupt the performance of shared services they depend on.
Given that such changes are often coordinated by di erent teams, engineers need  ne grained visibility into latency.
In particular they need to  nd what explains the changes in the latency pro le, so they can tweak and  x if needed.
Motivated by this, we address the problem of explaining the latency pro le of any service.
In general, there has been 1http://www.speedawarenessmonth.com/ does-latency-really-matter/
 very little research on latency performance of cloud services.
Some of the recent work focuses on modeling the call tree of complex services and trying to predict latency [18, 13,
 ing latency pro le in a way that is useful to engineers and network monitors.
We study this problem and make the following contributions:   We develop a general approach to understanding the latency pro le of services.
In particular, we model services as black boxes, so our framework is applicable to any service, notwithstanding its semantics or subsystems called.
Also, we focus on analyzing the latency pro le directly in terms of the measurable attributes, e.g., origin of request, machine that service was running on, CPU rate.
This turns out to be what engineers need, as we explain in Section 2.
  We propose what we call the multidimensional f measure, and use it, given latency interval, to  nd a subset of monitored attributes that explains it.
This measure is combinatorial and generalizes the well known (one-dimensional) f measure used in information retrieval area to our problem.
We propose algorithms to use this measure not only to explain any given interval of latency, but also to explain the entire range of latencies of the service by segmenting it into smaller intervals.
Our overall algorithm uses dynamic programming to select small subset of intervals that provide insight into reasons for latency variations.
  We use real data from 2 large internet services, as well as several synthetic data sets for experimental study.
We use synthetic data to study robustness and performance of our algorithms.
Application of the framework to real data sets showed that analysis discovers interesting patterns.
In what follows, in Section 2 we introduce our approach to understanding latency variations for a  xed service and de ne multidimensional f measure.
In Section 3 we formally de ne problems.
We present our algorithms for single interval analysis in Section 4.In Section 5 we present algorithm that helps to understand the whole range of latency variation for the  xed service.
Section 6 contains detailed experimental study.
There are many web sites, for instance Amazon, Ebay or Google, each o ering multiple services each supported by umpteen number of backends.
Each service receives hundreds of millions of requests a day.
Conceptually, each such service invocation can be represented by a call tree [18]; in order to ful ll the request, each service typically calls other services which in turn can call others.
Dependent services can be executed in parallel or sequentially, synchronously or asynchronously.
The main observation is that even for a  xed service, latency varies signi cantly over the many times it is invoked.
Figure 1 illustrates latency variation of real world services.
There are many reasons for these variations: the size of the request svaries from small to large; sometimes the answer to user query is in the cache, other times on the disk; each instance of the service may call a variable number of sub services; systems use a combination of techniques to deal with load, from moving slower operations to asynchronous mode to dynamically adjusting computing and other resources; there are outright resource failures; etc.
Furthermore, there are implicit dependencies across services as they share computing, storage or network resources.
Our goal is to develop methods to understand latency variations.
We start with two requirements.
  The service has to be treated as a black box.
First, even for a  xed service for which we have the source code, the precise call tree is an unknown and might depend on the request.
Even using detailed monitoring system, call trees are di cult to reconstruct [18].
In our case, we wish to be able to understand the latency variations even if we can not reconstruct trees.
Second, we would like to avoid assumptions required, e.g., la-tencies of dependent services are independent random variables.
Finally, we wish to be agnostic of the service internals.
Cloud services run hundreds of services and these evolve over time.
By viewing services as black boxes and being agnostic to their internal semantics, our approach will be general.
  The reasons for the variations in latency need to be understandable to humans, for example e.g., in terms of few of the monitored attributes.
Imagine an engineer building services.
She is trying to foresee potential bottlenecks and faults, and designs, implements and
 the system, the latency of the service will vary from request to request.
In order to verify or improve the latency of the service, the engineer has to verify impact of multiple factors.
Veri cation of impact of a single factor (including the impact of her code on the latencies of other services) needs a signi cant amount of work and time, including connecting with other development teams.
Verifying many factors or combinations of factors is even more time consuming.
So, in practice, it would be of a great help to provide a small number of potential factors to verify.
Further, engineers prefer these factors to be monitored attributes that they can understand and reason about directly.
This in particular means that regression based models are not very useful.
For example, linear regression outputs a linear combination of attributes as potential explanation of latency variation.
These vectors are notoriously di cult to interpret in terms of the data and underlying patterns, even if they contain only few arguments, e.g.,  search requests are slow if and only if
 Our approach is as follows.
Consider some  xed service.
The service is called millions of times, and for each call, we rely on monitoring systems in place (e.g., X-Trace [7, 6], Dapper [20]) to gather data about executions of the service.
With each execution we associate a set of possibly related attributes, derived from the service invocation itself, or invocation of any of dependent services.
We lose the structure and precedence constraints, and focus on the set of attribute values.
For example, instead of reconstructing call tree as in [18], we concentrate our attention on values of attributes associated with the service itself (e.g., request size, response size, service name, custom annotations) and values for attributes that are relevant to the execution (e.g., CPU load, disk load), as well as the latency for that request.
The output of our analysis will be a small set of attributes.
Multidimensional f measure.
For now assume that each request is a set of binary attributes (we will later see how to reduce the problem to this case).
Let us focus on a speci c latency interval I and say set F of attributes is the reason the latency is in interval I.
For example, if request originates from USA and has request size of 15 bytes it is processed in 50-75 msec.
1, .
.
.
, f i Let ri = (f i m,  i) be request to the service, where f i j is the value of feature fj observed for the request ri, and  i = 1 if latency Li   I, and 0 otherwise.
A principled approach is as follows:   Since the attributes F need to explain the latency learn the best prediction algorithm A on interval, F = (f1, f2, .
.
.
, fk) that maps each request ri to 1 or 0 depending on whether latency for request ri is in I or not, respectively.
  Any such A will not predict precisely the latency interval I.
That is, along with true positives tp: k) = 1 &  i = 1}, tp = {ri : A(f i 2, .
.
.
, f i 1, f i there will be false negatives f n: f n = {ri : A(f i 1, f i 2, .
.
.
, f i k) = 0 &  i = 1}, and there will be false positives f p, de ned as k) = 1 &  i = 0}.
f p = {ri : A(f i 2, .
.
.
, f i 1, f i Frequently in machine learning and data mining, the quality of prediction is measured by the f measure [21], F M (A) is de ned as follows:
 precision   recall precision + recall |tp| |tp|+|f p| and recall = .
(1) |tp| |tp|+|f n| .
where precision = Intuitively, A(F ) is a binary predictor, and f measure is a proxy of how well the binary  feature  A(F ) is correlated If every request in the interval I has with the interval.
A(F ) = 1 and no request outside of I gets A(F ) = 1, then F provides the best explanation for the interval existing in the data.
In our case, as we argued earlier, engineers wish output set F to directly determine the interval of interest I, and not via some sophisticated function A that may be di cult to interpret.
Hence, we rephrase the problem directly in terms of the attribute values.
We modify the one-dimensional f measure that applies to A(F ) to a multidimensional f measure that applies to many binary features.
Definition 1.
For  xed interval I and a set of features F we de ne the multidimensional f measure as follows:
 mprecision(I, F )   mrecall(I, F ) mprecision(I, F ) + mrecall(I, F ) (2) We de ne true positives mtp, false negatives mf n and false positives mf p as follows: (cid:94) (cid:94) (cid:94) f i
 f i
 f i
 (cid:94) (cid:94) (cid:94) mtp = {ri : f i
 mf n = {ri : f i
 mf p = {ri : f i
 , .
.
.
, f i k = 1 &  i = 1} , .
.
.
, f i k = 0 &  i = 1} , .
.
.
, f i k = 1 &  i = 0} Then mprecision = |mtp| |ntp|+|mf n| .
|mtp| |mtp|+|mf p| and mrecall = Multidimensional f measure has many desirable properties.
For example, 0   Q (I, F )   1.
Adding feature fa which correlates perfectly with one of the features in F does not change the function, that is, Q (I, F ) = Q (I, F (cid:48)) where F (cid:48) = {F, fa}.
On the other hand, Q (., .)
does not capture certain inverse relationships.
For example, if fa is the complement of fb, that is, any tuple with fa = 1 (= 0) means fb = 0 (= 1, respectively), then Q (I,{fa, fb}) is same as Q (I, fa).
In our application, in order to overcome such situations we add inverts for binary features.
Similarly to f measure, multidimensional f measure is not convex and hard to optimize.
In particular, consider example described in Table 2.
Here we are interested in interval I = {1}.
The score Q (., .)
of single feature f1 is greater than score of any other single feature available, i.e., Q (Li = 1, f1) > Q (Li = 1, f2), however features f2 and f3 taken together are perfect predictor for I: Q (Li = 1, f1) < Q (Li = 1,{f2, f3}).
705f1







 f2







 f3
















 Table 1: Non-monotonicity of Q (., .)
Reduction to the Binary Case.
In our analysis, we will use the multidimensional f measure applied to binary features, however attributes of requests are often not binary.
Attribute values can be translated to binary format in many di erent ways, e.g., binary or unary encoding, split into folds of equal length or mass.
Di erent binary feature formation will result in di erent capabilities of the analysis.
We use the following encoding process: for categorical attributes, we create separate feature for each attribute value.
For continuous attributes, the attribute value range is split between several features, each feature corresponding to an interval of value.
For a binary feature we include feature itself and its complement, to be able to detect situations when absence of some factor is decisive.
For example, requests of size 15 kb and not from USA are processed within 50-75 msec.
Observe that since the range of values of attribute are split into non-overlapping features we have: Lemma 1.
Let f1 and f2 be features that correspond to the same attribute, then if Q (I, f1) > 0 and Q (I, f2) > 0, then Q (I,{f1, f2}) = 0.
Hence, no two features f1 and f2 that correspond to the same attribute will be in the multidimensional f measure based output we generate.
We model the workload of a service as a sequence of requests R. Each request ri has m features F = (f1, f2, .
.
.
, fm) and observed latency Li.
W.l.o.g, we assume that each feature is binary, because of the reduction.
Given the largest observed L = arg maxi{Li} that is seen in practice, each latency Li falls in the range [0, L].
Definition 2.
We say the subset of features F     F explains latency interval I if F   maximizes Q (., .)
on I: F   = arg maxA F Q (I, A).
We refer to F   as explanation.
The entire range [0, L] is not likely to be explained by the same set of features.
Hence, we approach it in two steps: (1) for  xed latency interval and scoring function  nd set of features that form explanation of the interval; (2) given large set of intervals with explanations, select (small) subset of intervals that provides concise summary for interesting patterns found in the data.
We formalize these problems as follows.
Problem 1.
[Single Interval Analysis] For  xed interval I and scoring function Q (., .)
 nd the explanation F  , s.t., F   = arg maxA F Q (I, A).
Problem 2.
[Latency Range Analysis] {I1, I2, .
.
.
, Il}, s.t., total score (cid:80)l Split the intervals i=0 maxA F Q (Ii, A) is entire latency domain into non-overlapping maximized over all possible splits of latency domain.
Both problems have interesting variations.
For instance, in Problem 1 we are considering the case in which only one explanation is found for the interval, however one can easily extend this formulation to the case, in which single interval can have up to k explanations.
For Problem 2, one can consider choosing overlapping intervals.
However, in practice we observed that even without overlaps one can detect feature sets that have overlapping latency intervals.
In this paper we consider only versions of problems as de ned above.
kur

 In this section, to solve Problem 1, we adopt and evaluate two classical algorithms: branch-and-bound [11, 17] and forward feature selection [5, 15].
Branch-and-Bound Algorithm.
This algorithm is effectively a backtracking algorithm that uses branch-and-bound approach to reduce the search space.
The pruning for exhaustive search relies on two observations.
First, recall of a set of features F is always lower or equal to the recall of any subset of features F (cid:48)   F .
Thus, if we have a lower-bound   on acceptable Q (., .)
for an interval, then we can use that to lower bound acceptable recall r, and prune candidate sets: r    
 does not hold for precision: combination of features can, and often does have higher precision than any individual feature of that set.
Nevertheless we can avoid selecting subsets of nearly identical features, by following the branch if support of the corresponding explanation reduces signi cantly, while still preserving recall.
More formally, let SI be the support of the interval I and R(f1, f2, .
.
.
, fi)   R be a subset of all requests that have features f1, .
.
.
, fi satis ed, Suppose, that explanation with precision   exists.
Thus such explanation would have support of at most   = |SI|/ .
Indeed, any explanation which has support more than  , can not possibly have precision of  .
We use this observation to obtain a bound on how much each added feature should reduce the support of requests in order to achieve aimed precision  .
We show that the set can be populated in such a way that adding feature fi+1 to  rst i features, reduces the support |R(f1, .
.
.
, fi)| by at least     |R(f1, .
.
.
, fi)| k   i We formalize and prove this in the following lemma.
Lemma 2.
Suppose explanation contains a set of features (f1, f2, .
.
.
, fk) and precision of an explanation is at least  .
Then there exists an ordering l1, .
.
.
, lk, s.t., for all i   0 |R(l1, .
.
.
, li)|   |R(l1, .
.
.
, li+1)|   R(l1, .
.
.
, li)   |SI|/  Proof.
Fix t   0 and suppose sequence l1, .
.
.
, li satisfying the lemma has been built for all i   t. Obviously when t = 0, such condition is trivially true.
Let l1, .
.
.
, lt be one such order, and without loss of generality assume lj = j for j   t. Let Ti = SI (f1, .
.
.
, fi).
We have Ti   Ti 1 for all i > 0.
Therefore since Tk    , there exists j   t such that (3) |Tj|   |Tj+1|   (Tt    )/(k   t) k   i
 |Tt   R(fj+1)| = |Tj+1| + |(Tt   R(fj+1) \ Tj|.
Now subtracting former from later we have: |Tt| |Tt R(Fj+1)| = |Tj| |Tj+1|+|Tt\Tj| |(Tt R(fj+1)\Tj| Using the fact that |Tt \ Tj|   |(Tt   R(fj+1) \ Tj| we have |Tt|   |Tt   R(Fj+1)|   (Tt    )/(k   t) Hence feature lt+1 = fj+1, satis es the conditions of the lemma.
Forward Feature Selection Algorithm.
We have presented an e cient branch and bound approach which guarantees global optimality.
However, if we allow suboptimal solutions, it is possible to improve running time even further.
We present intuitive greedy algorithm based on forward feature selection: start with empty set of features F   = {} and expand it by adding a feature fi s.t.,
 fi})   fi = arg max fi F We keep growing F   while Q (I, F  ) is strictly growing.
The intuition for this method rests on two properties of multidimensional f measure.
First, as we have observed before, recall of single feature is always greater or equal to the recall of any super set.
Secondly, given subset of requests R(cid:48), set of features F (cid:48) and the number of requests in the interval I we can calculate global recall.
Let split point ri   [0, L] be a point that separates latency range into smaller intervals.
Assume we have s potential split points {ro = 0, r1, r2, .
.
.
, rs = L}.
Let  (ri, rj) = maxA F Q ([ri, rj), A) be the score of the interval [ri, rj).
The goal is to select subset of split points {r  k} 2 , .
.
.
, r  i+1).
Notice, we do not make any assumptions about the shape of the function
 to maximize total score (cid:80)k 1 i=1  (r  i , r  1 , r  This problem can be solved e ciently using the following dynamic programming formulation.
Let D(i) denote the best score for a solution that covers interval [0, ri), with initial state D(0) = 0.
The update step is: D(i) = max 1 j<i ( (rj, ri) + D(j)) (4) In other words, to construct solution for [0, rj) we search for such a pair i, j, s.t.,  (rj, ri) + D(j) is maximized.
We repeat iterative step s times.
This dynamic programming gives O(|s|2) running time solution.
Proof that D(i) indeed  nds the best score at each step i is a simple application of induction argument.
Consider smallest i such that there exists a solution D(cid:48)(i) > D(i) then we consider the last interval that spans j and i in D(cid:48)(i).
By induction hypotheses D(j) is optimal and thus D(i)   D(j) +  (j, i), which contradicts with our assumption.
Problem variations.
This problem has several variations.
For instance, we implicitly assume that every interval of [0, L] that was not included into  nal solution has  ( , ) = 0.
However, one can penalize for gaps in the  -nal solution by making implicit score negative.
Considering formulation in which intervals in  nal solution are allowed to overlap is particularly interesting.
It can be solved by considering slightly di erent dynamic programming formulation: let D(i, j, k) denote the best solution with k intervals, that covers interval [0, ri), and the latest point which has overlap is j.
We do not explore this modi cation further in this paper.
We test our framework on two types of input: (1) synthetic and (2) real data.
For the absence of labeled data, we use synthetic data to evaluate performance, robustness and running time of our algorithms.
We run our algorithms on real data to learn more about abilities, perspectives and utility.
Generation.
There are multiple ways one can obtain synthetic data for experiments.
For instance, one can modify data collected from real services:  x service, obtain data set, then take one feature, modify it s values, and  translate  changes to the latency value for each request instance in the data set.
This approach requires extensive knowledge of structure of the service together with relations between di erent parameters: does change of single attribute value a ects only latency value?
does it a ect any other attributes?
Another approach is to modify running service in order to obtain data, this approach cannot be carried out in practice for majority of services.
Therefore, we generate synthetic data to model situations in which irregular latency values occur when several factors occur simultaneously.
For the data set we generate 2 types of requests: Base requests correspond to normal state of the system, i.e., system behaves as expected.
We assume that their latencies follow some normal distribu-tion2 with  xed parameters.
The other type of requests contains a pattern or co-appearance of particular values for some set of features.
Further, we assume that for each pattern latency is coming from a particular normal distribution, e.g., if request i originates from USA and has request size of 100KB or more, then Li   N ( j,  2 j ).
It is only natural to expect that system behaves di erently under di erent conditions.
Potentially, synthetic data set can contain multiple patterns, patterns can be overlapping or not in terms of features or latency intervals.
To generate data, we  x distribution for base requests N , number of patterns p, each with prede ned distribution {Nj}, and the size of the data set (number of requests n and number of binary features m).
Data generation is straightforward and on the higher level is as follows.
First, m features are generated: we generate attributes, each consisting of 3 to 6 binary features, together with multi-nomial distributions, according to which values of the attributes (and features) will be sampled.
Second, we generate patterns, where pattern is essentially the bag of features Pk = {fa, fb, .
.
.
, fc}.
Finally, we sample requests by sampling values of the attributes.
If sampled request i contains the pattern, then we sample it s latency from corresponding
 tribution, however it does not change the results aside from changing the latency scale to normal.
Latency intervals of planted patterns are close together Latency intervals of planted patterns nearly match Figure 2: Tests on synthetic data: quality of analysis as latency associated with patterns  1  and  2  are brought closer and closer together.
Requests with no pattern found in them are labeled with  None .
Each row represents independent experiment.
The left column shows ground truth, middle column contains output for branch-and-bound algorithm while the right most column shows results forward feature selection.
The branch-and-bound algorithm successfully solves  rst and second inputs.
Forward feature selection, solves the  rst input perfectly,  nds almost perfect solution for the second one.
Both methods fail to detect both patterns when latency associated with patters is virtually identical.
The right graphs shows average quality measure as function of the number of noisy features.
Figure 4: The left graph shows average quality measure as the number of features grows.
The right plot shows running time of two algorithms as the number of features grows.
tency from N .
The description of the process can be found in Algorithm 1.
We further extend our generation process in order to be able to test robustness of our algorithms.
We generate number of noisy features, each associated with some particular pattern: it co-occurs (has value 1) with the pattern with probability p, if pattern is absent it occurs with probability 1   p.
F   generateF eatures(m) P   generateP atterns({N1, .
.
.
, Ni}) for i   {1, .
.
.
, n} do Algorithm 1 Synthetic Data Generation











 13: end procedure ri   instantiateRequest(F ) if pk   f indP attern(ri,P) then Li   sampleLatency(Nk) Li   sampleLatency(N ) else end if end for return {R, F,P} Synthetic Data Set.
Each synthetic data set consists of 1000 generated requests, each described by m attributes and g noisy features as de ned in Section 6.1.
Default number of (binary) features is 70, except for experiment in which we vary number of features in order to compare running times of two approaches.
Default number of noisy features is g = 15, except for experiment in which we vary g in order to see its in uence on the algorithms  performance.
Level of noise p is constant and is set to 0.9 in all experiments.
Each attribute consists of [3..5] features, number of features per attribute is selected uniformly at random.
Each data set has 2 planted patterns:  0  and  1 .
Each pattern consists of [2..4] features.
Base requests or requests in which analysis did not detect any patterns are labeled as  None .
We  nd that this setup closely mimics the type of request data observed in real world.
All  gures describing performance of the algorithms contain averaged out quality scores de ned below.
To obtain a data point on the quality of analysis, we run each of our algorithms 5 times, and take the average.
For each point on the diagrams we also plot standard deviation as con dence interval.
Figure 2 shows generated latency pro les and analysis outputs produced by the framework.
Each row, of three, represents analysis result for a distinct data set.
The  rst column corresponds to the ground truth, the second column corresponds to the branch and bound based analysis results, and the third column shows forward feature selection based analysis results.
In a series of experiments below we investigate how well our algorithms work when we vary one parameter at a time: number of noisy features, number of features, or separation of patterns.
Quality score.
Result of our analysis is essentially clustering, where requests are assigned to groups.
To measure success rate of the analysis we match each of the ground truth planted patterns pi with the best matching cluster Cj from the algorithm output.
We then compute f measure for clustering results.
For that we,  rst compute total number of requests G that are true positive (e.g., request contains planted pattern and analysis placed it to the corresponding cluster).
Then we compute overall precision and recall p = G/|   C| and r = G/|   P|, respectively.
We compute f measure as in Eq.
1.
Experiment 1.
Pattern separation.
In this experiment we want to explore when our algorithms will be able to discover planted patterns, e.g., do latency interval and its speci c pattern must be well separated from any other requests or will our analysis be able to detect pattern when it is mixed with others?
To test this we run series of trials: in each data set we plant 2 patterns.
In the  rst trial latency intervals corresponding to patterns are well separated (see Figure 2, row 1), we proceed experiments by bringing them closer and closer together to the point when they are almost equal (see Figure 2, row 3).
The results of experiment are highlighted in Figure 2 and e ect to the quality of analyses is shown in Figure 3.
In most cases branch-and-bound algorithm produces slightly better results, that is to be expected given that it e ectively searches the whole hypothesis space.
It is also interesting that in a few points greedy algorithm provided better results.
We explain this by the fact that our target metric (comparison with ground truth) is di erent from the metric we seek to maximize   total f measure based on the interval selection.
Experiment 2.
Noisy features e ect.
It is intuitive to think that as the number of features increases, it might get harder for algorithms to discover patterns.
Even more so for noisy features, as they are designed to confuse our methods.
In this experiment we vary number of noisy features, in order to see how robust our algorithms are, and results are shown on Figure 3.
Performance of two algorithms is comparable, and the quality of results does not degrade or depends on the number of noisy features.
Experiment 3.
Running time.
From the previous experiment we can see that branch-and-bound algorithm in general performs slightly better than forward feature selection.
However, it is signi cantly slower as the number of features grows (see Figure 4).
In practice, both methods are very easy to implement using map-reduce framework: on the map step separate the search space by features, on the reduce step choose the combination of features that scored the best.
Running time analysis.
In the worst case scenario branch-and-bound algorithm can run exponential time, whereas forward feature selection algorithm running time is bounded by O(m2|R|), where m is the number of attributes and |R| is number of requests.
In Figure 4 we show the running time as the number of features increases.
In practice we found that the running time of branch-and-bound highly varies: in some cases it terminated quicker than forward feature selection, however tests that we performed indicate exponential running time trend.
In order to obtain more intuition about usefulness, perspective of the framework we test it on several data sets that are obtained from several backend services of a large search engine.
Algorithms do detect unusual and interesting patterns in the data.
Each data set contains requests sent to a single service.
Traces were collected by Dapper [20] tracing
 service, each trace describes invocation of one of the services related to the request.
To obtain requests, we take traces, and group them by request.
Attributes for the dataset are also obtained from traces, e.g., request and response sizes, service name, custom annotations, observed CPU and disk loads, latency.
Depending on the service, the number of attributes is di erent, starting from 50.
We translate values of attributes to binary format as described in Section 2.
First data set contains 1850 requests, each having 640 features.
It s latency pro le can be found in top row of Figure 5.
One can see that requests form 2 groups: one group has latency of around 100 ms or less, the second group of requests is signi cantly slower.
Both methods identi ed slower group of requests.
While we are not able to go into greater detail regarding the service, we mention that the explanation produced for the slower requests indicated that the culprit for low performance were particular type of operation occurring several layers below in the execution stack.
In addition to that branch and bound identi ed slowest of requests can be explained by the same operation but for requests with session.
Second data set contains 1500 requests each having 140 features.
It s latency pro le indicates 3 distinct peaks and can be found in bottom row of Figure 5.
While again we cannot disclose lower level details, we mention here that analysis results of two methods while being a little bit di erent have the same bottom line: there is single event, occurrence of which causes latency to fall into range of 2 peaks on the right, while additional event allows to distinguish between right and left peaks (its absence and presence, respectively).
Note, that in this particular case the quicker fraction of requests is uniform and was described by single pattern (same pattern for both methods).
There are multiple ways to form intervals.
One simple approach is to greedily form all possible intervals.
If every request ri has distinct latency Li, then we end up with |R|2 of intervals.
The other extreme would be to generate only few good candidates.
However, it is hard to know what is a  good  interval, and how to detect it automatically.
We leave this direction open to further research.
Instead, in our experiments we use local minima approach that generates potential split points by building latency histogram for the service and adding all local minima into the set.
Set of intervals is formed by taking all pairs of split points.
Set of split points is also used by dynamic programming.
Cloud and web services abound, for instance Amazon Web Services, Google and Bing.
Nearly all providers of such services have dashboards tracking vital statistics of the systems for detecting anomalies, failures and also monitoring performance measures (such as QPS, etc).
Latency of services is one of metric to track.
There are several low-overhead techniques that help to monitor large scale services.
Tools, such as X-trace [7, 6] and Dapper [20] allow RPC level data collection.
Traces or RPC calls capture time and path of requests, and allow rich statistical analysis.
There is very little prior work on latency analysis in large scale systems.
Path pro ling [2], modeling [3], or call tree reconstruction [13] became a prominent directions in latency
 services, building prediction models.
In [19] authors develop approach to di erentiate between anomalies and behavioral changes.
However, they do not help to explain which attributes have played major role in some particular latency range.
In contrast, our focus here is on explaining the latency variations and we take a combinatorial approach of identifying subset of monitored attributes that engineers can later troubleshoot.
There are many general statistical and data mining tools that apply to the problem of explaining an observed feature (e.g., latency).
One is based on correlation of features [9].
However, in our case we want to be able to detect synergy between di erent features, that is while separate features might not appear to be correlated with performance metric, together they can serve as a prefect explanation for the interval.
Moreover, single set of features can be explaining only some interval of latencies, and not the whole range.
Another approach uses decision trees [17].
There are also approaches that combine correlation and decision trees [4].
One can consider  nding the explanation for a  xed interval to be feature subset selection [10] problem: select a subset of at most m features from set of features of size n, s.t,.
the score is maximized.
Here is conceptual di erence between our problem, and feature selection problem.
While in feature selection the goal is to select a set of features, s.t., some family of algorithms works well on data sets of some particular type.
In our case we are interested in selecting set of features that optimizes the score on a particular data set.
We are not concerned about over tting, or the fact that selected set of features is useless for analysis of the other data set.
Our approach is derived from f measure.
f measure is frequently employed in machine learning, also in feature selection, to evaluate results [8].
f measure is known to be non-convex, and hard to optimize.
There are number of studies to optimize f measure for family of methods, e.g., [16, 22] We proposed a multidimensional f measure which is even more challenging to compute.
We believe this measure is of inherent interest and other uses for this measure will be found.
Algorithms we adopted and evaluated for  nding explanation for the  xed interval are classical branch-and-bound [11, 17], and greedy forward feature selection [5, 15].
For branch-and-bound we exploit properties of f measure in order to signi cantly reduce the search space.
The latter algorithm does not bound to  nd optimal solution, however can be used in practice when running time is crucial.
Along with feature selection frequent itemset and association rule mining are relevant.
Their goal is to  nd subsets of features that frequently co-occur together.
Algorithms such as a-priori [1] and it s modi cations relay of support of generated sets and usually applied to complete data sets.
Association rules appear to be a natural solution, in which we build one association rule for each interval of interest.
However, in our case, feature set found for the interval can be also frequent outside of the interval.
Or set of features can be infrequent on the scale of the data set, but be a perfect predictor for the interval of latency.
Most importantly, association rules express causation relation, however in our case we do not want to restrict ourselves to this kind of relationship between features and latency attribute.
Cloud services are essential for modern online world, and users perceive latency as critical.Latency varies a lot due to variety of factors.
There is very little prior work on latency analysis in large scale systems.
We addressed the problem of understanding the latency pro le and explaining it in terms of few, monitored attributes.
We proposed a combinato-rial quantity that we call the multidimensional f measure and presented algorithms to use that to identify the suitable subset of attributes that explain latency.
Understanding the latency pro le of cloud services is a fundamentally important problem, and much remains to be done.
There is a growing trend in data mining that the output of analysis be meaningful to the end user.
For example, in rank based data mining, there has been recent focus on picking rows and columns that explain the rank of the matrix rather than looking at linear combinations, because the rows and columns correspond to samples and features respectively which are easier to reason for end users [12].
Our work adds to this perspective.
Also, the multidimensional f measure, like the standard one-dimensional version, is dif- cult to handle computationally.
It will be interesting to obtain approximations that are more e cient to compute.
We also believe this measure will  nd other applications.
