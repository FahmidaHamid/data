Algorithms developed for graph-based recommendation are very popular among web services; for instance, Amazon uses co-purchasing information to recommend products to its customers, IMDB recommends movies to its visitors based on the information such as director, cast, and ratings, and Google uses the web-graph and the user histories for Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
personalized web search.
The recommendations are usually made based on user preferences, either explicitly expressed or based on what she has been looking at recently.
These preferences are used as the objects of known interest to seed the algorithms.
One of the common problems of popular recommendation algorithms is the pollution of top recommendations with many similar items, i.e., redundancy.
It is typically not interesting to be recommended slight variations of the same product if you have a wide interest.
The redundancy problem is solved via result diversi cation, which has gained a lot of attention in many  elds recently [1, 8, 12, 14, 16, 19, 20,
 ing a set of items which are related to the query, but also dissimilar among each other.
The problem of recommending a diversi ed set is inherently qualitative and is evaluated di erently in various contexts [3, 4, 7, 23].
Most diversi cation studies in the literature rely on various assumptions, e.g., objects and queries are categorized beforehand [22], or there is a known distribution that spec-i es the probability of a given query belonging to some categories [1].
In the context of information retrieval or web search, since the search queries are often ambiguous or multifaceted, a query should represent the intent of an average user with a probability distribution [22].
Intent-aware methods in the literature aim to cover various relevant categories with one or more objects, or as TREC de nes its diversity task,  documents are judged on the basis of the subtopics, based on whether or not a document satis es the information need associated with that subtopic  [6].
In this work, we assume that the graph itself is the only information we have, and no categories or intents are available.
We are interested in providing recommendations based on a set of objects of interest.
The recommended items should be related to the user s interests while being dissimilar to each other.
This particular problem has attracted a lot of attention recently, and many algorithms and evaluations have been proposed [5, 8, 13, 14, 16, 20, 24, 25].
Evaluation of algorithms  quality is one interest of the paper.
Usually, algorithms are evaluated by expressing the problem as a bicriteria optimization problem.
The  rst criteria is related to relevancy, e.g., the sum of the personalized PageRank scores, and the second is related to diversity, e.g., the density or the expansion ratio of the subgraph formed by the recommended set.
These two criteria are either aggregated (often with a simple linear aggregation) or they are considered simultaneously with Pareto dominance (where the solutions are in the relevancy-diversity objective space).
inappropriate.
Indeed, we design query-oblivious algorithms for the two popular combinations of objectives that return most of the recommendations without considering the user s interests, yet, perform the best on these commonly used measures.
We argue that a result diversi cation algorithm should be evaluated under a measure which tightly integrates the query in its value.
The goodness measure proposed in [20] has such a property; however, it is shown to be dominated by the relevance.
We propose a new measure called expanded relevance (exprel(cid:2)) which computes the coverage of the relevant part of the graph.
We show that the query-oblivious algorithms cannot optimize exprel(cid:2).
We also investigate various quality indices by computing their pairwise correlations.
This highlights that the goodness measure is highly correlated with the sum of ranking scores.
That is the algorithms that perform well on goodness produce results sets which are not much di erent from top-k relevant set.
The exprel(cid:2) measure we propose appears to have no high correlation with other measures.
To optimize exprel(cid:2) of the result set, we propose a greedy algorithm BestCoverage.
Because of the submodular properties of exprel(cid:2), BestCoverage is a (1  1/e)-approximation algorithm with complexity O(kn  ), where k is the number of recommended items, n is the number of vertices in the graph, and   is the maximum degree.
We propose a relaxation of BestCoverage with complexity O(k  ), where   is the average degree of the graph.
We experimentally show that the relaxation carries no signi cant harm to the expanded relevance of the results.
(cid:2) (cid:2) (cid:2)


 We target the problem of diverse recommendation on graphs assuming that the user has a history or speci ed interests in some of the items.
Therefore, the objective is to return a set of items which extend those interests.
Let G = (V, E) be an undirected graph where V = {v1, .
.
.
, vn} is the vertex set and E is the edge set.
Given a set of m seed nodes Q = {q1, .
.
.
, qm} s.t.
Q   V , and a parameter k, return top-k items which are relevant to the ones in Q.
With diversity in mind, we want to recommend items not only relevant to Q, but also covering di erent aspects of the query set.
We de ne a random walk on G arising from following the edges (links) with equal probability and a random restart at an arbitrary vertex with (1   d) teleportation probability.
The probability distribution over the states follows the discrete time evolution equation: pt+1 = P pt, (1) where pt is the vector of probabilities of being on a certain state at iteration t, and P is the transition matrix de ned as: (cid:2) (1   d) 1 n + d 1 (1   d) 1 n ,  (v) , if (u, v)   E otherwise, P(u, v) = (2) where  (v) is the degree of the vertex v   V .
If the network is ergodic (i.e., irreducible and non-periodic), (1) converges (cid:2) to a stationary distribution   = P  after a number of iterations.
And the  nal distribution   gives the PageRank scores [2] of the nodes based on centrality.
In our problem, a set of nodes Q was given as a query, and we want the random walks to teleport to only those given   nodes.
Let us de ne a prior distribution p if v   Q otherwise.
  1/m,
 If we substitute the (1/n)s in (2) with p , we get a variant of PageRank, which is known as personalized PageRank (PPR) ortopic-sensitive PageRank [10].
PPR scores can be used as the relevance scores of the items in the graph.
Note that the rank of each seed node is reset after the system reaches to a steady state, i.e.,  q   Q,  q   0, since the objective is to extend Q with the results.
such that (v) = (3)   p PPR is preferred as the scoring function in our discussions because (i) some of the methods in the experiments are variants of PPR which compute relevant but diverse set of results, (ii) some measures and objective functions are de ned on the stationary distribution of PPR, and (iii) alternative scoring functions and probability distributions on graph produce similar results to PPR.
On the other hand, the discussions on evaluations and some diversi cation techniques are independent of the preferred scoring function, hence we believe that the discussions will still interest the majority of the readers.
We classify the diversi cation methods for the recommendation problem based on whether the algorithm needs to rank the items only once or multiple times.
Diversi cation by query re nement.
This set of algorithms rank the items k times to select the results one by one, and re ne the search at each step.
GrassHopper [24] is a well-known diversi cation algorithm which ranks the graph k times by turning the highest-ranked vertex into a sink node at each iteration.
Since the probabilities will be collected by the sink nodes when the random walk converges, the algorithm estimates the ranks with the number of visits to each node before convergence.
GrassHop-per uses matrix inversion to  nd the expected number of visits; however, inverting a sparse matrix makes it dense, which is not practical for the large and sparse graphs we are interested in.
Therefore, we estimate the number of visits by iteratively computing the cumulative ranks of the nodes with PPR.
GSparse [13] employs an incremental ranking approach similar to GrassHopper, but the algorithm disconnects the selected node from the graph instead of converting it into a sink node.
After executing the ranking function, the graph is sparsi ed for the next iteration by removing all the edges of the highest ranked node.
This way, the graph becomes less dense around the selected nodes, hence, the remaining nodes at these regions will attract less visits during the random walk.
The process is repeated until k nodes are selected.
Recently, manifold ranking has become an alternative to personalized PageRank and several diversi cation methods were proposed based on the idea of turning highly ranked nodes into sinks [5, 8, 25].
Aside from the ranking strategy, manifold ranking with sink points is quite similar to GrassHopper when the probabilities are estimated with cumulative scores.
Since the manifold ranking is a di erent 716(cid:3) ranking of the graph, we carry out our experiments based only on PPR by leaving the discussion of using manifold ranking instead of PPR open for the time being.
Diversi cation by vertex selection.
The following algorithms run the ranking function once, then carefully select a number of vertices to  nd a diverse result set.
DivRank [16] adjusts the transition matrix based on the number of visits to the vertices so far using a variant of random walks, called vertex-reinforced random walks (VRRW) [18].
It assumes that there is always an organic link for all the nodes returning back to the node itself which is followed with probability (1    ): if u (cid:6)= v otherwise, w(u,v)    (u) , 1    , p0(u, v) = (cid:2) (4) where w(u, v) is equal to 1 for (u, v)   E The transition matrix Pt at iteration t is computed with , and 0 otherwise.
(cid:3) Pt(u, v) = (1   d) p   (v) +d p0(u, v)  t(v) z V p0(u, z)  t(z) , (5)   (v) is given in (3), and  t(v) is the number of vis-where p its of vertex v up to iteration t. It ensures that the highly ranked nodes collect more value over the iterations, resulting in the so called rich-gets-richer mechanism.
In each iteration of VRRW, the transition probabilities from a vertex u to its neighbors are adjusted by the number of times they are visited up to that iteration t. Therefore, u gives a high portion of its rank to the frequently visited neighbors.
Since the tracking of  t(.)
is nontrivial, the authors propose to estimate it with cumulative ranks (CDivRank), i.e., the sum of the scores upto iteration t, or, since the ranks will converge after su cient number of iterations, with pointwise ranks (PDivRank), i.e., the last score at iteration t   1.
A recently proposed algorithm, Dragon [20], employs a greedy heuristic to  nd a near-optimal result set that optimizes the goodness measure, which punishes the score when two neighbors are included in the results (see (15)).
We will investigate this measure more in the upcoming section.
Frequently visited nodes tend to increase the ranks of their neighbors because of the smoothing process of random walks [16].
Based on this observation, algorithms using local maxima have been proposed.
The Relaxed Local Max-ima algorithm (k-RLM) [13] incrementally includes each local maxima within top-k2 results to S until |S| = k by removing it from the subgraph for the next iteration.
Let us  rst review some classical measures for computing the relevance and diversity of the results with respect to the query.
The measures are important since either they are typically used as  or a part of  the objective function of the diversi cation method, or the results are evaluated based on those measures.
Normalized relevance: The relevancy score of a set can be computed by comparing the original ranking scores of the resulting set with the top-k ranking list [20], de ned as (cid:3) (cid:3)k v S  v i=1  i rel(S) = , (6) 1   does not denote estimated or predicted relevance scores.
(cid:3)k (cid:3) i=1  i is preferred over where   is the sorted ranks in non-increasing order.1 Nor-v S  v since malization with the distribution of scores in a random walk depends on the graph size, query, connectivity, etc., and normalized scores are comparable among di erent settings.
Di erence ratio: A diversi ed result set is expected to be somewhat di erent than the top-k relevant set.
Because the highly ranked nodes increase the ranks of their neighbors [16], the top-k results, recommended by the original PPR, is not diverse enough as shown in [19] and in our experiments.
Nevertheless, the original result set has the utmost relevancy.
This fact can mislead the evaluation of the experimental results.
Therefore, we decided to measure the di erence of each result set from the set of original top-k nodes.
Given  S to be the top-k relevant set, the di erence ratio is computed with di (S,  S) = 1   |S    S|
 .
(7) nDCG: We use normalized discounted cumulative gain (nDCG), for measuring the relevancy as well as the ordering of the results.
It is de ned as nDCGk =  s1 +  1 +  si log2 i  i log2 i , (8) i=2 i=2 (cid:3)k (cid:3)k where   is the relevancy vector (e.g., stationary distribution of a random walk),   is the sorted   in non-increasing order, and si   S is the ith point in result setS .
(cid:6)-step graph density: A variant of graph density measure is the (cid:6)-step graph density [20], which takes the e ect of indirect neighbors into account.
It is computed with (cid:3) dens(cid:2)(S) = u,v S,u(cid:5)=v d(cid:2)(u, v)
 , (9) where d(cid:2)(u, v) = 1 when v is reachable from u within (cid:6) steps, i.e., d(u, v)   (cid:6), and 0 otherwise.
The inverse of dens(cid:2)(S) is used for the evaluation of diversity in [16].
(cid:6)-expansion ratio: As an alternative to density, expansion ratio and its variant (cid:6)-expansion ratio [14] measure the coverage of the graph by the solution set, computed with:  (cid:2)(S) = |N(cid:2)(S)| n , (10) where the expansion set with 1-distance neighbors is de ned as N (S) =S   {v   (V   S) :  u   S, (u, v)   E}, and the (cid:6)-step expansion set is de ned in [14] as: N(cid:2)(S) = S   {v   (V   S) :  u   S, d(u, v)   (cid:6)}.
(11) Note that the intent-aware measures, such as intent-aware expected reciprocal rank (ERR-IA) [4],  normalized discounted cumulative gain ( -nDCG@k) [7], intent-aware mean average precision (MAP-IA) [1], are not included to the discussions, but they are important measures for evaluating the diversity of the results when data and queries have some already known categorical labels.
Our problem has no assumptions of a known distribution that speci es the probability of an item belonging to a category.
s s n n e e d d



 top-90%+random top-75%+random top-50%+random top-25%+random All random better



 rel rel





 (a) rel vs. dens2







    









 top-90%+greedy- 2 top-75%+greedy- 2 top-50%+greedy- 2 top-25%+greedy- 2 All greedy 2 better



 top-%+random top-%+greedy- 2 other algorithms l l

 e e r r p p x x e e







 rel rel





 (b) rel vs.  2







 k k (c) exprel2

 Figure 1: Evaluation of top-%+random (red) and top-%+greedy- 2 (blue) methods versus other algorithms (gray) based on selected relevance/diversity measure pairs and combined exprel2 measure.
The other algorithms include GrassHopper, DivRank, Dragon, k-RLM, GSparse, and BestCoverage, but they are not highlighted here since we do not want to prematurely compare those against each other.
Maximum Marginal Relevance (MMR) [3] is the most popular diversi cation method that optimizes a bicriteria objective, marginal relevance, which is a linear combination of independently measured relevance and novelty.
The method greedily and implicitly optimizes the following objective assuming that the similarity of all items to the query items are already computed in  : (cid:4) fMM R(S) = (1    )  v     (cid:4) v S u S max v S u(cid:5)=v sim(u, v), (12) where   is the importance of relevance over novelty and sim is a similarity metric.
The problem with (12) is that two di erent measures are aggregated without taking their compatibility into account.
The same premise is also valid for any type of linear aggregation of a relevance and a diversity measure.
For example, [14] tries to optimize the following diversi ed ranking measure: (cid:4)
 fL(S) =  v +   v S n , (13) where   is the tradeo  between relevance and diversity, and the diversity of the result set is measured with the expansion ratio.
Similarly in [15], relevance part is scaled with (1   ).
Other bicriteria objectives include max-sum diversi cation, which reduces to MaxSumDispersion problem, max-min diversi cation, which reduces to MaxMinDispersion problem, etc.
For example, k-similar diversi cation set problem [21] is de ned based on MaxSumDispersion as: fM SD(S) = (k 1)(1 ) div(u, v), (14) (cid:4) (cid:4) (cid:4)  v +2  v S u S v S u(cid:5)=v where div(u, v) can be selected as a weighted similarity, tf/idf cosine similarity, or the Euclidean distance depending on the problem.
We refer the reader to [9] for more information on objectives and distance functions.
We argue that bicriteria optimization is inappropriate, and hence, the diversi cation methods that seem to optimize both criteria are problematic.
Let us return back to our original problem: the items in a graph structure are ranked based on a given query and a ranking method (e.g., PPR), and our aim is to rerank those items so that we can include more results from di erent aspects of the query and reduce redundancy of top-k relevant set.
Suppose that we work on the web graph and we want to diversify the results of a search engine which displays k = 10 results to the user.
Do you think the quality of the top-k list would improve if we replace some results from the end of the list with random web pages?
We design two query-oblivious algorithms for the two popular combinations of objectives, which are monotonous (e.g., linear or quadratic) aggregations of max-sum relevance and max-sum diversity (graph density dens or expansion ratio  ) objectives.
The algorithms will return some of the results without considering the user s interests, yet, will perform the best on the following commonly used measures:   top-%+random: returns a given percentage of the results (e.g., 50%, 75%, etc.)
from top-k, and the rest randomly from the search space.
  top-%+greedy- 2: returns a given percentage of the results (e.g., 50%, 75%, etc.)
from top-k, and try to maximize  2 with the rest of the results without taking the query into account.
To prove our point, we compute the normalized relevance (rel) and selected diversity measure (dens2 and  2) of the results for the diversi cation methods in the literature and for the query-oblivious algorithms.2 We  t a multivariate Gaussian on top of the results to show the mean and moments of the distribution when two objectives are considered simultaneously.
A result which further minimizes dens2 and maximizes rel and  2 is favorable and better.
This is shown with an arrow in the Figs.
1(a) and 1(b).
nario 3 queries and k = 20.
Comparisons of query-oblivious methods on given bicriteria measures and exprel2 for other datasets and query types are provided in the supplementary material: http://bmi.osu.edu/hpc/data/Kucuktunc13WWW/randoms.pdf
 as other algorithms with respect to rel vs. dens2 evaluation.
Figure 1(b) similarly shows the results of top-%+greedy- 2 as well as other algorithms with respect to rel vs.  2 evaluation.
Here, query-oblivious methods seem to recommend the best result sets when a bicriteria evaluation is used.
Yet, we know that those algorithms are designed to trick the evaluation, as well as produce useless results in user s point of view.
Using only the  rst half of top-k results gives a normalized relevance score greater than or equal to 0.5 since the ranks are sorted in non-increasing order.
Furthermore, the ranks has a power-law distribution that makes rel much higher than 0.5.
Therefore, the relevance objective is mostly satis- ed.
We further argue that no matter which relevance and diversity measures are selected, there always exists a query-oblivious algorithm which optimizes both measures in a meaningless way, useless in practice but looks great on the paper.
This is the problem of evaluating result diversi cation as a bicriteria optimization problem with a relevance measure that ignores diversity, and a diversity measure that ignores relevancy.
As a result of our experiments on bicriteria optimization, we argue that we need a combined measure that tightly integrates both relevance and diversity aspects of the result set.
It is reasonable to design the combined measure based on the query, the rankings, and the graph structure we already have.
The goodness measure [20] is a step towards a meaningful combined measure.
It penalizes the score when two results share an edge, meaning that they are neighbors and they possibly increase their ranks by feeding each other during the random walk.
The measure is computed with of the search space.
Therefore, the items having separate expansion sets will increase the coverage.
However, coverage is not the only aspect of exprel(cid:2).
The proposed measure also takes the ranking scores into account, and hence the quality of the covered part.
The e ect of each result is limited with the given (cid:6) parameter, i.e., a result covers only its neighbors in the graph if (cid:6) = 1, or neighbors of neighbors if (cid:6) = 2.
Higher values of (cid:6) are generally not preferred since the expansion set tends to cover most of the graph in those cases.
An important property of exprel(cid:2) measure is that query-oblivious algorithms cannot optimize it.
Because, the highest ranked items are mostly not diverse enough, and the rest of the results (randomly selected independent of the query) will not contribute much to the measure.
Figure 1(c) shows that neither top-%+random (red) nor top-%+greedy- 2 (blue) can optimize the measure while the diversi cation algorithms (gray) can score higher.
This proves the validity of the measure for diversi cation.
Table 1: Correlations of the di erent relevance, diversity, and combined measures.
Pearson correlation scores are given on the lower triangle of the matrix.
High correlations are highlighted.
nDCG di  dens1 dens2  1  2 goodness exprel
 exprel
 rel   l e r


 n     -0.95 -0.80 i d  
 s n e d
 s n e d

 -0.76  

 -0.76
   (cid:4) fG(S) = 2 i S (cid:4)  i   d i,j S   (1 d) A(j, i) j (cid:4) (cid:4)  j j S i S   p (i), (15)
   -0.25 -0.19
 -0.30 -0.01  
   -0.25 -0.19
 -0.31 -0.03
   where A is the row-normalized adjacency matrix of the graph.
However, we will show in Section 3.5 that goodness is highly dominated by relevance, which re ects negatively on the results of Dragon in the experiments.
We present a combined measure of the (cid:6)-step expansion ratio ( 2) and relevancy scores (rel), which are two popular diversity and relevance measures in the literature, in order to quantify the relevant-part coverage of the graph: s s e n d o o g
 l e r p x e
 l e r p x e

 -0.90

 -0.21 -0.21  

 -0.28

 -0.01 -0.03
  

 -0.13





   (cid:6)-step expanded relevance: (cid:4) exprel(cid:2)(S) =  v v N(cid:2)(S) (16) where N(cid:2)(S) is the (cid:6)-step expansion set of the result set S, and   is the PPR scores of the items in the graph.
This new measure explicitly evaluates the diversity of the results in terms of coverage with the given set.
In other words, when two results are close to each other in the graph, their expansion sets intersect narrowing the covered part
 We investigate the mentioned relevance, diversity, and combined measures by computing their pairwise correlations based on the results of the algorithms given in Section 2.3 as well as the query-oblivious top-%+random methods given in the previous section.
Table 1 shows the correlations of 10 measures as scatter plots as well as their correlation scores.3
 dataset and with k = 20.
The results are consistent across various datasets, scenarios, and k values.
A complete comparison set is provided in the supplementary material: http://bmi.osu.edu/hpc/data/Kucuktunc13WWW/corr.pdf
 nDCG although the latter considers the order of the results.
rel is also anti-correlated with di  , meaning that as the ratio of results other than top-k start to increase, the normalized relevance decreases accordingly.
For the graph diversity measures, (cid:6)-step expansion ratios ( 1 and  2) are highly correlated among each other.
On the other hand, graph density-based measures (dens1 and dens2) do not seem to have any high correlation with other measures.
Among the combined measures, goodness is highly correlated with rel.
This highlights that the goodness measure is dominated by the sum of ranking scores, meaning that algorithms that perform better on goodness do not return results that are much di erent from the top-k results of PPR.
The proposed exprel(cid:2) measure, on the other hand, appears to have no high correlation with any of the other relevance or diversity measures, proving that it is something di erent than the already known measures.
Although the expanded relevance is based on both rel and expansion ratio ( ), very low correlation is observed in the results.
Our strategy so far was to review the attempts to  nd a good objective function for the result diversi cation problem on graphs.
We have shown that a bicriteria optimization of relevance and diversity can be tricked, and a combined measure should be constructed carefully.
The proposed exprel(cid:2) measure seems to cover both aspects of the intended objective, yet cannot be optimized by the query-oblivious algorithms.
We argue that this novel measure can be naturally used as an objective function of a diversi cation algorithm.
Given a graph G = (V, E), a vector of ranking scores   (stationary distribution of PPR scores in our case) computed based on the query setQ, and the number of required results k, our objective is to maximize the expanded relevance (exprel(cid:2)) of the result set S: (cid:3) (cid:4) ) = argmax S(cid:2) V |S(cid:2)|=k v N(cid:2)(S(cid:2) )  v, (17) exprel(cid:2)(S S = argmax S(cid:2) V |S(cid:2)|=k (cid:3) where N(cid:2)(S problem as exprel(cid:2)-diversi ed top-k ranking (DTR(cid:6)).
) is the (cid:6)-step expansion set.
We refer to this However, it is not hard to see that the objective of  nd-ing a subset of k elements that maximizes the expanded relevance is NP-hard.
Assuming the graph G and the ranking scores   are arbitrary, DTR(cid:6) is a generalization of the weighted maximum coverage problem (WMCP) which is NP-Complete [11].
WMCP is expressed as a set O of objects oi with a value  i and z sets of objects rj   O, R = {r1, r2, .
.
.
, rz}.
The problem is to select a subset of R, P   R such that |P| = x which maximizes oi {rj :rj P}  i.
The key of the reduction for (cid:6) = 1 is to construct an instance of DTR(cid:6) with a bipartite graph G = (V = R   O, E) where (rj, oi)   E i  oi   rj.
We set  rj = 0,  oi =  i and k = x.
The solutions of DTR(cid:6) are dominated by sets S where all the vertices are in R. Indeed, since  rj = 0, rj there is no advantage in selecting a vertex in O.
The rest of the reduction is obvious for (cid:6) = 1.
For other values of (cid:6), the reduction is similar, except each edge of the bipartite graph is replaced in a path of (cid:6) edges.
(cid:3) Note that the proposed objective in (17) is independent of ordering since the function is de ned over an unordered set.
This is usually reasonable because there is an assumption that users will consider all k results [1, 14, 20].
In practice, di erent users may stop at di erent number of results, hence, several DCG-based metrics are commonly used to compute the importance of returning results in an ideal ordering.
The near-optimal solutions that we will present in the following section can still output an ordered set of results based on the marginal utility of each selected item at the moment of its inclusion.
Although the optimal solution of the proposed objective function (see (17)) is NP-hard, we will show that a greedy solution that selects the item with the highest marginal utility at each step is the best possible polynomial time approximation for the problem.
Let us de ne the marginal utility for a given vertexv and result set S as g(v, S), such that g(v, ) = exprel(cid:2)({v}) be-v(cid:2) V (cid:2)  v(cid:2) where fore any results are selected, and g(v, S) = = N(cid:2)({v})  N(cid:2)(S) represents the (cid:6)-step expansion set of (cid:3)
 vertex v without the items that have already been covered by another result.
In other words, g(v, S) is the increase on the exprel(cid:2) measure if v is included to the result set, i.e., exprel(cid:2)(S   {v}) =exprel (cid:2)(S) +g (v, S).
(cid:3) ALGORITHM 1: BestCoverage Input: k, G,  , (cid:3) Output: a list of recommendations S
 while |S| < k do  }     argmaxv g(v, S) v S   S   {v return S Algorithm 1 incrementally selects the item with the highest marginal utility in each step, then includes it to the result set S. This way, the items that contribute the most to the expanded relevance of the  nal results are greedily selected as a solution to the given optimization problem.
In order to show that the greedy algorithm solves the problem quite well, we  rst prove that the exprel(cid:2) is a submodular function: Definition 4.1.
(Submodularity) Given a  nite set V   R is submodular if and only if V , a set function f : 2 for all subsets S and T such that S   T   V , and j   V \ T , f (S   {j})   f (S)   f (T   {j})   f (T ).
Lemma 4.2. exprel(cid:2) is a submodular function.
The proof of the lemma follows directly from the de ni-tions of submodularity and exprel(cid:2).
Greedy algorithms are known to generate good solutions when maximizing submod-ular functions with a cardinality constraint and were used in [1, 14].
  (cid:3) Theorem 4.3.
[17] For a submodular set function f , let be the optimal set of k elements that maximizes f (S), and
 be the k-element set constructed greedily by selecting an
 element one at a time that gives the largest marginal increase to f .
Then f (S Corollary 4.4.
BestCoverage is an (1   1/e)-approx-imation algorithm for the exprel(cid:2)-diversi ed top-k ranking problem.
)   (1   1/e)f (S (cid:3)   ).
720(cid:2)  
 BestCoverage (BC) is a (1   1/e)-approximation for maximizing exprel(cid:2) with complexity O(kn  ) where n is the number of vertices in the graph, k is the number of recommended objects, and   is the maximum degree of the graph.
Obviously, the implementation in Algorithm 1 can be improved by storing the marginal utility for every vertex at the expense of O(n) space, and updating only the vertices that to S would a ect.
However, for (cid:6) = 2, the inclusion of v the number of vertices to be updated is |N4({v  })|, which is O( 4) in the worst case.
Initializing the marginal utility incurs a cost of O(n  ).
Once a vertex is added to setS , the impact of its distance (cid:6) neighbors must be adjusted.
For a given vertex, adjusting its impact costs O(  ).
For each neigh-iteration of the algorithm the impact of at most   bors need to be adjusted.
Though, each vertex adjusts its (cid:2)}) adjustments.
impact only once, so there are O(min{n, k  Finally, selecting the vertex with maximal marginal utility requires O(n) operations4 per iteration.
The overall complexity of the algorithm is O(n  + kn).
+ min{n, k  (cid:2)}  (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:3) (cid:3) (cid:3) vertices where k ALGORITHM 2: BestCoverage (relaxed) Input: k, G,  , (cid:3) Output: a list of recommendations S
 Sort(V ) w.r.t  i non-increasing S1   V [1..k ], i.e., top-k  v   S1, g(v)   g(v,  )  v   S1, c(v)   Uncovered while |S| < k do     argmaxv S1 g(v) v  } S   S   {v S2   N(cid:2)({v  }) (cid:3)   S2 do for each v (cid:3) ) =Uncovered then S3   N(cid:2)({v (cid:3)})  u   S3, g(u)   g(u)    v(cid:2) c(v )   Covered if c(v (cid:3) = k (cid:2) return S (cid:3) (cid:3) With this optimization, most of the time is spent on initializing the marginal utility.
We experimentally found that results of PPR the returned results are chosen from top-k is proportional to k and the average de-ranks, where k gree of the graph.
We propose a relaxation of BestCov-erage which only considers including in the result set the (cid:2) top-k  highest ranked vertices solely based on the relevance scores where   is the average degree of the graph.
All the vertices of the graph still contributes to marginal utility.
The complexity of the relaxed version drops to (cid:2)}) since the cost of the com-O(min{n, k  putation of the initial marginal utility is now asymptotically dominated by the cost of adjusting them.
Algorithm 2 gives the relaxed BestCoverage algorithm with all mentioned improvements.
The impact of the relaxation on the quality of the solution will be discussed in Section 5.3.
+k min{n, k  (cid:2)}  (cid:2)
 reach a better complexity, but we require the extract-max and decrease-key operations which are incompatible.
In the experiments we use one graph instance for each targeted application area, i.e., product recommendation on shopping websites, collaborator and patent recommendation in academia, friend recommendation on social networks, and personalized web search.
The graphs are publicly available at Stanford Large Network Dataset Collection5.
In summary, amazon0601 is the Amazon product co-purchasing network collected on June 2003. ca-AstroPh is the collaboration network between authors of the papers submitted to arXiv astrophysics category.
cit-Patents is the citation network between U.S. patents granted between 1975 and
 cial network, and web-Google is the web graph released in
 The mentioned graphs are relabeled, converted into undi-rected graphs.
The properties of the graphs are given in Table 2.
Note that   is the average degree of the graph, D is the diameter of the graph, i.e., maximum undirected shortest path length, D90% is the 90-percentile e ective diameter, and CC is the average clustering coe cient.
Table 2: Properties of graphs used in experiments.
  D D90% CC















 Dataset amazon0601 ca-AstroPh cit-Patents soc-LiveJournal1 web-Google


 We generate the queries for the experiments based on three di erent real-world scenarios: Scenario 1: A random vertex in the graph is selected as the query.
This scenario represents the case where the system does not have any information on the user.
For product recommendation, the user can be visiting a product page without signing in to the system.
For academic recommendation tasks, a professor can be looking for collaborators.
Scenario 2: A random vertex v along with 10 100 vertices within two distance to v are selected as a query.
In this scenario, v and the selected vertices represent an area of interest.
For example, the user can be searching for a product within a category, or interested in an academic  eld.
In a social network, the friend list of a person can be used as the query for friend suggestion.
Scenario 3: 2 to 10 random vertices are selected as di erent interests of the user, and a total of 10 to 100 vertices around those interests are added to the query set.
Multiple areas of interest is the most common use case for these applications where users are registered to the system and already have a search or purchase history.
For each dataset, 750 queries were generated, where the average number of the seed nodes varies between 1 and 50 for the scenarios 1 and 3, respectively.
In total 3,750 query sets representing di erent real-world cases were used in the experiments.
721l e r f f i d











 amazon0601, combined





 amazon0601, combined PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse

 BC1 (relaxed) BC2 (relaxed)





 soc-LiveJournal1, combined PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse
 BC1 (relaxed)





  




 amazon0601, combined BC1 (relaxed) BC2 (relaxed) PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse











 ca-AstroPh, combined PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse

 BC1 (relaxed) BC2 (relaxed)

 k


 k


 k


 k
 soc-LiveJournal1, combined Figure 3: Coverage ( 2) of the algorithms with varying k. BestCoverage and DivRank variants have the highest coverage on the graphs while Dragon, GSparse, and k-RLM have similar coverages to top-k results.
k


 k
 Figure 2: Normalized relevance (rel) and di erent ratio (di  ) scores with varyingk .
Dragon and GSparse return results around 70% similar to the top-k relevant set, this is generally not enough to improve the diversity of the results.
We experiment with the algorithms given in Section 2.3, the datasets described in Section 5.1, and the queries de ned in Section 5.2.
For the methods that use the ranking scores of PPR, we  x d = 0.9 and the number of PPR iterations to 20 in order to be consistent between di erent queries.
For the VRRW computation of DivRank methods, we set   = 0.25 and the number of iterations to 50 since VRRW usually takes more iterations to converge.
All ranking functions are implemented e ciently with sparse matrix-dense vector multiplication (SpMxV) operations.
On amazon0601, ca-AstroPh, and soc-LiveJournal1 datasets, we observed that the results of di erent scenarios are similar.
Hence, we combine the scenarios and display the results on all queries6.
Also note that the results of BC2 and its relaxation are omitted from the plots of soc-LiveJournal1 dataset because of the impractical runtimes.
Normalized relevance (rel) and di erence ratio (di  ) plots in Figure 2 show that Dragon and GSparse methods almost always return the results having 70% similar items to top-k relevant set, and more than 80% rel score.
A low rel score is not an indication of being dissimilar to the query (unless rel   0); on the other hand, since the scores have a power-law distribution, a high rel score usually implies that the algorithm ignored the diversity of the results and did not change many results in order to keep the relevancy high.
The actual di  measures are also given in Figure 2.
highlighted in the text.
The complete set of plots for each dataset, scenario, and measure is provided in the supplementary material: http://bmi.osu.edu/hpc/data/Kucuktunc13WWW/results.pdf amazon0601, combined



 l
 e r p x e





 PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse

 BC1 (relaxed) BC2 (relaxed)










 soc-LiveJournal1, combined PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse
 BC1 (relaxed)


 k


 k Figure 4: Expanded relevance (exprel 2) with vary ing k. BC1 and BC2 variants mostly score the best, GrassHopper performs high in soc-LiveJournal1.
Although PDivRank gives the highest coverage on ama-zon0601 (Fig. 3), it fails to cover the relevant parts.
Based on the expansion ratios ( 2) in Figure 3, BestCov-erage and DivRank variants, especially PDivRank and BC2, have the highest scores, hence the highest coverage on the graphs with their diversi ed result set.
Dragon, GSparse, as well as k-RLM have expansion ratios similar to the top-k results, meaning that these algorithms do not improve the coverage of the given graphs enough.
GSparse reduces the expansion ratio even more than the top-k set, proving that it is inappropriate for the diversi cation task.
It is important to note that  2 scores are meaningless by itself since query-oblivious greedy 2 algorithm would maximize the coverage.
Figure 4 shows the proposed expanded relevance scores (exprel
 icantly better than the other algorithms, where GrassHop-per is able to score closer to BestCoverage only in soc-LiveJournal1 dataset.
Although DivRank variants perform the highest based on expansion ratio (see Figure 3), their results are shown to be unable to cover the relevant parts of the graph as they score lower than BestCoverage variants.
For cit-Patents and web-Google datasets, we report the results on queries of scenarios 1 and 3 separately.
Here we omit the results of scenario-2 queries since they are in between scenarios 1 and 3.
These plots share the conclusions we have made so far based on the results on previous three datasets; however, they present di erent behavior based on the chosen scenario, so we provide a deeper analysis on those.
ca-AstroPh, combined
 soc-LiveJournal1, combined GSparse
 BC1 (relaxed) PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM


 p

 BC1 (relaxed) BC2 (relaxed)


 k
 web-Google, scenario 1 PPR (top-k) GrassHopper Dragon
 g PDivRank CDivRank k-RLM GSparse
 k cit-Patents, scenario 1 PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse

 BC1 (relaxed) BC2 (relaxed)















 ) c e s ( e m i t

 ) c e s ( e m i t

 cit-Patents, scenario 3 PPR (top-k) GrassHopper Dragon PDivRank CDivRank
 k k-RLM GSparse

 BC1 (relaxed) BC2 (relaxed)
 web-Google, scenario 3 PPR (top-k) GrassHopper Dragon PDivRank CDivRank
 k k-RLM GSparse

 BC1 (relaxed) BC2 (relaxed)
 l
 e r p x e








 l
 e r p x e





 k

 web-Google, scenario 1












 k




 k


 k
 Figure 5: Expanded relevance (exprel 2) with varying k. BestCoverage variants perform higher than usual on cit-Patents dataset with scenario-1 queries because of the low average degree (  = 8.7) and low clustering coe cient (CC = 0.09) of the graph.
The relaxed algorithms perform closer to their originals, meaning that they were both e cient and e ective on this type of sparsely connected graphs.
 


 web-Google, scenario 1 BC1 (relaxed) BC2 (relaxed) PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse

 cit-Patents, scenario 1 BC1 (relaxed) BC2 (relaxed) PPR (top-k) GrassHopper Dragon PDivRank CDivRank k-RLM GSparse











 k


 k
 Figure 6: Coverage ( 2) of the algorithms with varying k. DivRank variants appear to be implicitly optimizing the size of the expansion set, without considering whether those results are still relevant to the query (cf.
corresponding exprel
 Figure 5 shows that the exprel
 dataset vary based on the scenario chosen to generate the queries.
In fact, the results are higher than normal for scenario-1 queries.
This is because of the low average degree (  = 8.7) and low clustering coe cient (CC = 0.09) of the graph.
Also note that the relaxations of BC1 and BC2 perform closer to BC1 and BC2, meaning that the relaxed algorithms are both e cient and also e ective on this type of sparsely connected graphs.
It is also more clear on plots in Figure 6 that DivRank variants implicitly optimize the expansion ratio ( 2) of the Figure 7: Running times of the algorithms with varying k. BC1 method always perform better with a running time less than GrassHopper and DivRank variants, while the relaxed versions score similarly with a slight overhead on top of the PPR computation.
results, but without considering whether those results are still relevant to the query.
As a striking example of scenario-
see an algorithm to perform the best with respect to the size of the expansion set, but almost the worst with respect to the relevancy of the same set (see Figure 5).
With the runtime experiments shown in Figure 7, we also con rm that the relaxed variants of BestCoverage perform closer to their originals (see Figure 4) with an order of magnitude or more gain in e ciency.
In all cases, even in soc-LiveJournal1, which is the largest dataset in our experiments, the BC1 method always performs better with a running time less than GrassHopper and DivRank variants, while the relaxed version scores closer enough with a running time slightly higher than the original PPR computation.
Therefore, in terms of the running times, the e cient algorithms are generally ordered according to PPR  k-RLM   BC1(relaxed)   Dragon   BC1.
Con rming the observation in [16], DivRank variants are more e cient than GrassHopper for k > 10.
Runtime of BC2 depends on the dataset properties while its relaxed variant has comparable running times to DivRank variants.
Both BC2 and its variant has a very high runtime on ca-AstroPh since this dataset has the highest average degree (  = 42.2) and the clustering coe cient (CC = 0.63), hence, eachexprel 2 computation is more costly than the ones on other datasets.
Intent-aware results Among the  ve datasets we selected for the experiments, cit-Patents has the categorical information.
One of the 426 class labels was assigned to each patent, where those classes hierarchically belong to 36 subtopics and 6 high-723e g a r e v o c s s a
 l







 e g a r e v o c c p o b u
 t i






 e g a r e v o c c p o
 i









 k



 k



 k
 (a) Class coverage (b) Subtopic coverage (c) Topic coverage ) s s a c ( l l l a c e r -







i t ) c p o b u s ( l l a c e r -








i ) c p o t ( l l a c e r -












k


 k


 k
 (d) S-recall on classes (e) S-recall on subtopics (f) S-recall on topics Figure 8: Intent-aware results on cit-Patents dataset with scenario-3 queries.
PPR (top-k) Dragon PDivRank CDivRank k-RLM

 BC1 (relaxed) BC2 (relaxed) AllRandom PPR (top-k) Dragon PDivRank CDivRank k-RLM

 BC1 (relaxed) BC2 (relaxed) AllRandom level topics7.
Here we present an evaluation of the intent-oblivious algorithms against intent-aware measures.
This evaluation provides a validation of the diversi cation techniques with an external measure such as group coverage [14] and S-recall [23].
Intents of a query setQ is extracted by collecting the classes, subtopics, and topics of each seed node.
Since our aim is to evaluate the results based on the coverage of different groups, we only use scenario-3 queries that represent multiple interests.
One measure we are interested in is the group coverage as a diversity measure [14].
It computes the number of groups covered by the result set and de ned on classes, subtopics, and topics based on the intended level of granularity.
However, this measure omits the actual intent of a query, assuming that the intent is given with the classes of the seed nodes.
Subtopic recall (S-recall ) has been de ned as the percentage of relevant subtopics covered by the result set [23].
It has also been rede ned as Intent-Coverage [25], and used in the experiments of [22].
S-recall of a result set S based on the set of intents of the query I is computed with (cid:4) S-recall(S, I) =

 Bi(S), i I (18) where Bi(S) is a binary variable indicating whether intent i is found in the results.
We give the results of group coverage and S-recall on classes, subtopics, and topics in Figure 8.
The algorithms GrassHopper and GSparse are not included to the results since they perform worse than PPR.
The results of AllRan-dom are included to give a comparison between the results of top-k relevant set (PPR) and ones chosen randomly.
As the group coverage plots show, top-k ranked items of PPR do not have the necessary diversity in the result set, hence, the number of groups that are covered by these items are the lowest of all.
On the other hand, a randomized method brings irrelevant items from the search space without considering their relevance to the user query.
The re-
sults of all of the diversi cation algorithms reside between those two extremes, where the PDivRank covers the most, and Dragon covers the least number of groups.
However, S-recall index measures whether a covered group was actually useful or not.
Obviously, AllRandom scores the lowest as it dismisses the actual query (you may omit the S-recall on topics since there are only 6 groups in this granularity level).
Among the algorithms, BC2 variants and BC1 score the best while BC1 (relaxed) and DivRank variants have similar S-recall scores, even though BC1 (relaxed) is a much faster algorithm than any DivRank variant (see Figure 7).
In this paper, we address the problem of evaluating result diversi cation as a bicriteria optimization problem with a relevance measure that ignores diversity, and a diversity measure that ignores relevance to the query.
We prove it by running query-oblivious algorithms on two commonly used combination of objectives.
Next, we argue that a result di-versi cation algorithm should be evaluated under a measure which tightly integrates the query in its value, and presented a new measure called expanded relevance.
Investigating various quality indices by computing their pairwise correlation, we also show that this new measure has no direct correlation with any other measure.
In the second part of the paper, we analyze the complexity of the solution that maximizes the expanded relevance of the results, and based on the sub-modularity property of the objective, we present a greedy algorithm called BestCoverage, and its e cient relaxation.
We experimentally show that the relaxation carries no sig-ni cant harm to the expanded relevance of the solution.
As a future work, we plan to investigate the behavior of the exprel(cid:2) measure on social networks with ground-truth communities.
Acknowledgments This work was supported in parts by the DOE grant DE-FC02-
and OCI-0904802.
