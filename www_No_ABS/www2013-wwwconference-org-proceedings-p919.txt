Online content sharing services are a popular mechanism for users to  nd and share content; sites exist to share content such as business recommendations (e.g., Yelp, TripAd-visor), news articles (e.g., Digg, reddit), multimedia content (e.g., Flickr, YouTube), apps (e.g., iOS App Store, Google Play), and URLs (e.g., StumbleUpon, del.icio.us).
Generally, these sites allow users to create accounts, declare friendships, and upload and rate content.
The sites  extreme popularity is evidenced by the massive amounts of content that are uploaded: YouTube receives over 72 hours of new video uploaded every minute [35], and Yelp boasts reviews on over 889,000 businesses worldwide [47].
To locate relevant and trustworthy content from among this massive set Copyright is held by the International World Wide Web Conference Committee (IW3C2).
IW3C2 reserves the right to provide a hyperlink to the author s site if the Material is used in electronic media.
of uploaded content, users are encouraged to rate content, with highly rated content receiving more prominent placement.
The most highly rated content typically appears on the front page of the site or is listed more highly in search results, garnering signi cant attention and tra c.
Unfortunately, the increasing popularity of online content sharing sites has made them an attractive target for manipulation.
For example, malicious users often attempt to ensure that their content is more highly ranked (or that others  content is more lowly ranked).
On certain sites, such manipulation can have signi cant  nancial consequences: Recent studies have shown that increasing a business s overall rating on Yelp by one star can lead to 9% increase in revenue [19], explaining the numerous instances of rating manipulation that have been observed [1, 26, 30, 32, 33].
In general, manipulation on content rating sites is enabled by two separate attacks:   Malicious users can create multiple identities (i.e., Sybils [10]), and use these identities to provide positive ratings on their own content or negative ratings on others  content [30, 32].
This is exacerbated by the fact that accounts are typically free to create, requiring only an email address and a solved CAPTCHA [42].
  Malicious users can  buy  positive or negative ratings from otherwise legitimate users by o ering small compensation in exchange for ratings [1,33].1 This is made worse by the fact that most content only receives a few ratings, making it possible to greatly in uence the overall ranking with just a few additional ratings.
Such manipulation is undesirable for the site operator (whose reputation is negatively impacted by successful manipulation) as well as honest end users (who depend on the site to locate relevant and trustworthy content).
In this paper, we present the design and implementation of Iolaus,2 a system that is designed to be run by the site operator to mitigate the e ect of rating manipulation via the creation of multiple identities or the  buying  of ratings.
Iolaus works using two techniques: weighing ratings and relative ratings.
First, Iolaus leverages the structure of the
 the particular site: for example, businesses can o er discounts for Yelp ratings [1], and users can o er reciprocal ratings for Flickr favorites [15].
laus provided essential aid to Heracles by helping to defeat the Hydra, a multi-headed monster who would grow two heads each time an existing head was cut o .
919social network to bound the in uence over the overall rating that malicious users can achieve via the creation of multiple identities.
Iolaus assigns personalized weights to each rating, and selects the weights using a multi-commodity max  ow formulation.
Doing so ensures that the total weight of a single (human) user s ratings is bounded, regardless of the number of identities she creates.
Second, Iolaus uses the fact that most users provide few ratings to reduce the e ectiveness of  buying  ratings.
Instead of using a single rating directly as a raw score (e.g., content C gets !!!
), Iolaus transforms the user s rating to a ranking relative to all of the user s other ratings (e.g., C is in the top 10% of content).
Since most legitimate users provide few ratings,  buying ratings from random users provides signi cantly less bene ts in Iolaus than it does today.
We demonstrate the e ectiveness of Iolaus using three techniques.
First, using microbenchmarks, we show that Iolaus has su ciently low CPU and memory overhead to allow it to be practically deployed to the content sharing sites of today.
Second, using synthetically generated simulation data and social network data from YouTube, we demonstrate that Iolaus performs as expected, strictly bounding the in uence of malicious users and reducing their ability to  buy  ratings from random legitimate users.
Third, we collect a complete dataset of businesses in two cities from Yelp, covering roughly 2m ratings on over 39k businesses provided by 1.5m users.
We validate that Iolaus does not adversely a ect the rankings for honest users in absence of malicious behavior, and is able to defend against multiple identity and purchased-rating attacks when applied to Yelp.
We now brie y cover related work, encompassing Sybil attack prevention and fake rating detection.
Due to the attractive attack vector that free accounts provide, there is signi cant research interest in mitigating Sybil attacks.
Traditional defenses against Sybil attacks rely on either trusted central authorities or tying identities to resources that are hard to obtain, such as social security numbers [5], mobile phones [24], or crypto-puzzles [2, 4, 6].
Recently, researchers have explored analyzing the structure of social networks as a mechanism for locating Sybil identities [9, 20, 29, 37, 44, 45] (a more extensive background is provided in [39]; we review the details relevant to Iolaus here).
Unfortunately, there are two drawbacks to using existing Sybil defense schemes in content rating sites.
First, existing schemes make the assumption that the honest region of the social network is densely connected with few internal small cuts [41] (formally, that the honest region is fast-mixing [25]).
Recent work [18, 21] has cast doubt on this assumption, suggesting that existing Sybil detection schemes may end up accepting many Sybils or preventing honest users from interacting with each other [41].
Second, most pieces of content have few ratings; allowing even a small number of fake identities into the system can allow an attacker to  control  the rating for many items (for reference, SybilLimit [44] accepts O(log n) Sybils per attack edge).
Instead of trying to explicitly label identities as Sybil or non-Sybil, other approaches have focused on mitigating Sybil attacks in content rating services.
Such systems are known as Sybil tolerant systems [39].
For example, DSybil [46]  nds trusted users in the network (referred to as guides), and has provable optimality guarantees.
However, DSybil can only provide recommendations for users who have submitted a su cient number of ratings, which is often a small fraction of the population in practice.
For example, in our Yelp data (fully described in Section 7), only 15% of users have provided more than 5 reviews.
Also, DSybil is designed for rating systems where objects can only be either good or bad; Iolaus targets content rating systems that allow users to provide more  ne-grained ratings.
SumUp [38] is another Sybil tolerant system that inspired our design.
SumUp uses tokens passed over the social network in order to determine whether users  votes will be counted.
While SumUp is conceptually similar to Iolaus, SumUp unfortunately has three weaknesses that Iolaus addresses: First, SumUp assumes that the region of the social network surrounding the user requesting the vote (called the envelope) is free of malicious users; if a malicious user is nearby, they receive many tokens and can issue many votes.
Second, outside of the envelope, SumUp allows manipulation by malicious users: Honest users with multiple links are only allowed to place a single vote, while malicious users who divide their attack links across multiple accounts can potentially place multiple votes.
Third, SumUp was not designed to address the  buying  of ratings from otherwise honest users.
We demonstrate in Section 7 that Iolaus addresses these drawbacks and outperforms SumUp on real-world data.
Additionally, signi cant research has explored using data-mining techniques to detect and characterize rating manipulation.
Systems have been built that use a variety of different inputs, including linguistic characteristics [27], user behavior [16,17,23], sets of recommended items [7], and common sets of user-reviewer pairs [43].
While these techniques can detect certain rating manipulation today, they rely on particular characteristics of malicious behavior.
Regardless, such techniques could be used in combination with Iolaus.
We expect Iolaus to be deployed by the operator of a content rating site, such as Yelp or Flickr; we shall refer to this entity as the operator.
Iolaus is designed to replace the existing content rating aggregation logic that the operator uses (i.e., instead of taking the average or performing review  ltering [49], the operator would instead query Iolaus).
We assume that the operator collects ratings by a set of user accounts (referred to as identities) on a set of content objects; a user providing a rating on a given piece of content is referred to as a rater.
We assume that non-malicious users provide honest ratings, with the exception of a small fraction of  bought  ratings.
We assume that the operator also provides the ability for users to declare  friends  and that friendship requires the approval of both parties; many content rating services (e.g., Yelp, Flickr, YouTube) already have such a social network.
Similar to prior work [9, 37, 44, 45], we assume that links to a non-malicious user take e ort to form and maintain.
In other words, a malicious user cannot obtain an arbitrary number of links to non-malicious users.
Note that we make 920no assumptions about the di culty of obtaining identities (a single person may have many identities), or the structure or links between the malicious identities.
As a result, each (human) user has a cut in the network between identities that she owns and identities owned by other (human) users; while she can create identities and links on her side of the cut, she cannot unilaterally increase the size of her cut.
We assume that the operator provides input to Iolaus:   Social network Iolaus takes as input the list of social links between the identities.
We assume this is represented as an undirected graph G = (V, E), and that this graph is connected.
  Ratings Iolaus also takes as input the set of user ratings, represented by (identity, content, rating) tuples.
identity represents the user identity, content represents the content being rated, and rating represents the identity s rating.
The goal of Iolaus is to aggregate the ratings placed on content while ensuring that malicious users gain little additional in uence by creating multiple identities or  buying  ratings.
We make three observations that motivate Iolaus s design:
 rating aggregate schemes provide a single, global, aggregated rating for each piece of content (e.g., a business is !!!
on Yelp).
We take an alternate approach, allowing a personalized aggregated rating for each identity.
Such an approach naturally captures legitimate di erences of opinion (content ratings are, after all, opinions), and certain sites already provide personalized content ratings (e.g., Digg [36], Net ix [3]).
We refer to the identity for whom we are calculating the aggregate rating as the collector.
make a binary choice to either accept or reject each identity s rating when aggregating (e.g., Yelp s distinction between  ltered and un ltered reviews, SumUp s allowing or denying of votes).
Instead, we weigh each identity s rating, and allow di erent identities to have di erent weights.
ratings as absolute (e.g., content C gets !!!).
Given that most identities rate few objects, this approach does not consider the amount of information each rater has provided (e.g., an identity who has only rated a single piece of content  counts  the same as an identity who has rated hundreds).
In Iolaus, we transform raw ratings into relative ratings before aggregation.
In the following two sections, we describe how Iolaus chooses to weigh and interpret ratings, enabling it to defend against Sybil attacks and the  buying  of ratings.
Iolaus defends against multiple identity (Sybil) attacks through the weighing of ratings.
Consider the set of raters R   V on a single content object.
Instead of taking the



 (a)



 (c) (b) Figure 1: (a) A social graph, (b) malicious user A conducts a Sybil attack by splitting her identity, (c) malicious user A conducts a Sybil attack by creating a Sybil cluster.
average of all ratings to be the aggregate rating, Iolaus uses a weighting function w(r)   (0,  ) that assigns a positive weight to every rater r   R. The aggregated rating is then simply the weighted average of these ratings !r R w(r)   vr !r R w(r) where vr is the rating of rater r. For existing systems which weigh all ratings equally, w(r) = 1 for all r.
The key challenge, then, is to select a weighting function that limits the ability for malicious users to gain additional aggregate weight through Sybil attacks (where a user s aggregate weight is the total weight of the subset of her identities in R).
We also desire to select a nontrivial weighting function, which we de ne as a weighting function that assigns a nonzero weight to all identities.3 Below, we  rst formally de ne a Sybil attack in Iolaus s context, before detailing the properties we would like a weighting function to have.
Finally, we describe the weighting function in Iolaus.
Formally, suppose that a malicious user controls a set of identities I   V .
Consistent with prior work [45], we label the cut (I, V \ I) as the attack cut (and the links along the cut as attack links), as these links signify links between the malicious user and identities controlled by other users.
By our assumptions in Section 3, the number of attack links is bounded, but the number of identities in I and the number of links between these identities are unbounded.
As a result, a malicious user is able to perform three actions as part of a Sybil attack, depicted in Figure 1:
 lowed to create any number of identities.
cious user is allowed to create links arbitrarily between identities she controls.
tually know if a given rating was placed by a malicious or non-malicious identity; allowing a weighting function to give large numbers of identities 0 weight may discard most of the useful ratings.
(a)
 (b)
 (c) Figure 2: (a) a simple social graph consisting of three nodes a VC and two raters; V1 and V2, (b) same graph, but a new rater, V3, is added to the network, (c) same graph, but now V1 decides to split her identity by creating a new node, V3.
is allowed to assign her end of her attack links to any of the identities she possesses.
For example, if the malicious user possesses malicious identities A1.
.
.A n, and she has two attack links to non-controlled identities B and C, she can assign any of her Ai identities to be her endpoint of the attack links.
Ideally, we would like to select a weighting function that is Sybil-proof, meaning the weighting function ensures that a malicious user can gain no additional aggregate weight by conducting a Sybil attack.
Formally, assume we have social networks G and G", where G" is the same as G except that malicious user A has conducted any number of Sybil attack actions (described in Section 4.1).
For example, G and G" may be the graphs shown in Figure 1 (a) and Figure 1 (b) or (c).
A Sybil-proof rating system would ensure that the aggregate weight assigned to raters that A controls is the same in both G and G".
Unfortunately, Sybil-proof weighting functions on real-world networks are forced to be trivial, meaning they assign a weight of 0 to all raters that have multiple distinct paths to the collector (which, in practice, is almost all raters).
To see why, consider the example shown in Figure 2 (b), where V C is the collector and V 1, V 2, and V 3 are the raters.
Consider rater V 3, who has two distinct paths to V C. V 3 could be (a) a legitimate, non-malicious identity, (b) part of a Sybil attack by rater V 1, who splits her identity when linking to V 2 as shown in Figure 2 (c), or (c) part of a Sybil attack by rater V 2, who splits her identity when linking to V 1.
In either of the latter cases, each of V 1 and V 2 should get the same (aggregate) weight as in the network shown in Figure 2 (a).
Thus, any weighting function that is Sybil-proof must assign V 3 a weight of 0.
As a result, requiring a weighting function to be Sybil-proof precludes nontrivial weighting functions in practice.
Instead, we must relax our requirements.
We relax the requirement of our weighting function from being Sybil-proof to being Sybil-bounded.
A Sybil-bounded weighting function is one where, given a social network G and malicious user A, there exists a bound BA > 0 such that under any Sybil attack by A, the aggregate weight received by A s raters is always less than BA.
In other words, a malicious user may be able to get some additional weight through Sybil attacks, but there exists a bound on the total weight the malicious user will be able to receive, regardless of the number of identities A creates.
Compared to a Sybil-proof weighting function, a Sybil-bounded weighting function is strictly weaker (as malicious users can gain additional weight via Sybil attacks).
However, we demonstrate below that (a) we can construct Sybil-bounded weighting functions that are nontrivial, and (b) we can select a weighting function that has tight bounds (leaving little additional weight to be gained via Sybil attacks).
Our goal now is to ensure that the weighting function is Sybil-bounded (i.e., that aggregate weight of the identities that the malicious user controls is bounded, regardless of how the malicious user conducts a Sybil attack).
To do so, Iolaus expresses the problem of assigning weights as a multi-commodity max  ow [11] problem,4 viewing the social network as a graph with all links having unit capacity, and with the raters each sourcing a di erent  ow, and with the collector serving as all  ows  sink.
We take the amount of  ow that each rater is able to source as that rater s weight.
We choose multi-commodity max  ow as it naturally has the Sybil-bounded property that we desire [34].
To see why, recall that the maximum  ow between any two sets of nodes is de ned by the minimum cut in the graph between the source and sink [13].
The attack links represent such a cut,5 implying that the total  ow and therefore total weight of the attacker is bounded, since the size of the attack cut is bounded by our assumptions in Section 3.
Thus, regardless of how the malicious user conducts a Sybil attack, the aggregate weight of the attacker s ratings is bounded.
Moreover, using multi-commodity max  ow also ensures that multiple malicious users gain no bene t from collusion.
To see how, suppose that there are two malicious users.
Without collusion, the two are each bounded by their respective set of attack links; should they collude, they are bounded by the union of their attack links.6
 Ensuring the presence of bounds limits the potential impact of a Sybil attack, but to be useful in practice, we would like to ensure the bounds are tight.
Formally, we would like to minimize the di erence between the assigned weights and the bound; doing so ensures that the malicious users can gain the least amount of weight by creating additional identities.
Ideally, we would like to solve the multi-commodity max  ow problem using a linear solver such as CPLEX [8] or GLPK [14].
Unfortunately, expressing the problem solely as a linear maximization problem does not provide any guarantees about the tightness of the bounds to the assigned weights: to the linear solver, any solution which maximizes
 gregate  ow between multiple source/sink pairs, with  ows competing with each other for links  capacity.
the attacker s identities and the sink.
as the two users may have attack links to each other that become internal once they collude.
!/"



 !/"




  

 !/#



 !/#



 !/"




 !/"
 !/"
 !/"

 !/#
 !/#
 !/#

 !/# (a) (b) (c) (d) (e) Figure 3: Example of determining weights in Iolaus.
Shown are (a) the social network with collector V C and raters A, B, D and E (shaded), (b) paths selected for each rater, (c) resulting weights after normalizing D  B link, (d) weights after then normalizing B   V C link, and (e)  nal weights for each rater.
the total  ow throughput is su cient.
As a result, such a solver may output solutions that have a very uneven distribution of the total weight across sources.
For example, in the graph in Figure 2 (a), the solver may give V 2 weight 2 (along its two paths to V C) while giving V 1 weight 0.
Instead, Iolaus uses an approximation of max  ow which results in more even distribution of capacity between raters and provides tight bounds on Sybil attacks, described below.
For each rater r   R, Iolaus determines the max  ow between r and the collector (ignoring all other raters), and derives a set of non-intersecting paths Pr for this  ow.
When multiple options for Pr exist, Iolaus selects arbitrarily between them.
Next, Iolaus considers the graph where all raters attempt to send 1 unit of  ow along each of their paths (i.e., for all r in R, each path in Pr is initially assigned weight 1).
Since all links have unit capacity, there may be certain links that are over capacity (i.e., multiple raters have paths using that link).
To resolve these situations, Iolaus normalizes the  ow along these links by reducing the amount of  ow proportionally.
Formally, if a link is used by raters {r1, r2, ...rn} with weights {w1, w2, ...wn}, each wi is normalized with w"i = j=1 wj wi!n where w"i represents the value of wi after normalization.
Iolaus normalizes links from the least-overcapacity to the most-overcapacity.
Doing so ensures that malicious users are  rst bottlenecked at their attack cut before a ecting any non-malicious users.
To see why, recall that all of the paths begin at a rater but end at the single collector.
Thus, the highest bottlenecks occur around the collector; links away from the rater are less likely to be over capacity.
As an example of Iolaus s weighting in practice, consider the social network shown in Figure 3 (a), with collector V C and raters A, B, D, and E (C exists in the social network but has not given a rating).
Iolaus  rst determines a set of non-intersecting paths with maximum  ow for each rater; these are shown in Figure 3 (b).
At this point, there are two links that are overcapacity: B   V C has total weight 3 and D B has total weight 2.
Thus, Iolaus  rst normalizes D B (reducing one of D s paths and E s single path to weight

 B   V C (reducing B s path to 1 2 and both of the previously reduced paths to 1
 point, all links are at or below capacity; the total weight of each rater s path is the weight for that rater (Figure 3 (e)).
We observe that this weighting function provides Iolaus s Sybil resilience by providing a Sybil-bounded weighting system.
For example, if node A in Figure 3 (a) were to attempt a Sybil attack, she would not be able to increase her aggregate weight beyond 1, regardless of the number of identities, or links between these identities, that she creates.
She is always bounded by her attack cut of 1.
So far, we have described how Iolaus defends against multiple identity attacks; we now detail how Iolaus defends against the  buying  of ratings.
Preventing the  buying  of ratings is one of the most di cult challenges facing content rating systems today: Since there is no cost for placing a rating, it is extremely hard to determine if a particular rating was indeed legitimate or the result of some form of out-of-band compensation.
This challenge becomes worse by the fact that most content only receives a few ratings, making it possible to greatly in uence the overall ranking with just a few additional ratings.
The fact that being placed highly on certain content rating sites (e.g., Yelp, TripAdvisor) can have positive  nancial consequences [19] only further encourages compensation for positive ratings.
To the best of our knowledge, no previous work has directly addressed the issue of dishonest ratings by legitimate users.
Since placing a rating costs nothing to the identity, there is little to dis-incentivize the identity from doing so.
In Iolaus, we add a virtual cost to placing a rating through the use of relative ratings.
At a high level, relative ratings consider how content relates to other content the identity has rated.
To transform an identity s raw rating to a relative rating, we  rst consider all of that identity s ratings on other content objects.
The relative rating is then simply the ranked score (between 0 and 1) relative to all of the identity s other ratings.
For example, consider an identity who has provided 923ratings !!!!!
for content object c1 and !!
for content objects c2 and c3.
We observe that the identity ranked c1 higher than two other content objects; it is therefore in the  top third  of content objects for this identity.
The relative rating for c1 is therefore the midpoint of the top third of objects: 0.833 (the midpoint of [0.66,1]).
Similarly, we observe that the identity ranked content objects c2 and c3 in the  bottom two-thirds  of content objects, but we do not know their order.
Thus, the relative rating of c2 and c3 are both assigned to 0.333 (the midpoint of [0,0.66]).
Formally, suppose that the identity provided raw ratings {r1, r2, ...rn} on content objects {c1, c2, ...cn}.
For simplicity, assume these are sorted by ri.
Each content object ci, then, is assigned the relative rating i   0.5 n with the exception that any set of content objects that have the same raw rating are then assigned the average of all relative ratings with the same raw rating.
Examples of converting raw to relative ratings for three di erent users are shown in Table 1.
Note that all of user U3 s raw ratings are the same, so all end up with the same relative rating.
We now turn to examine how using relative ratings reduces the impact of  buying  of ratings.
Consider an identity who is about to give a positive rating on a content object.
Without relative ratings, the identity s positive rating would be viewed just like any other identity s rating, and there is no cost to the identity for providing the positive rating.
In fact, without relative ratings, the identity could provide positive ratings on a number of content objects (i.e.,  selling  her ratings multiple times) without any impact.
With relative ratings, the impact of  buying  ratings from a large number of identities is dramatically decreased.
Since most identities provide few ratings (e.g., the average number of ratings per identity is less than two in our Yelp dataset), buying a positive rating from a random identity is unlikely to result in a high relative rating (as the n for most identities is quite small, meaning the resulting relative rating will be much lower than a similar rating placed by a legitimate identity who has placed more ratings).
Moreover, with relative ratings, placing a new rating causes some of the identity s other ratings to change, since Rating Raw !!
!!!!
!
!!
!!!
User # r1,1 r1,2 r2,1 r2,2 r2,3 r2,4 !!!!!
r2,5 !!!!!
r3,1 !!!!!
r3,2 !!!!!
r3,3 !!!!!
r3,4 !!!!!
Transformed Relative





















 Table 1: Example of converting raw ratings to relative ratings for three users.
Raw ratings are  rst converted to transformed ratings; any transformed ratings with the same raw rating are then averaged.
inserting new rating into the ordered list of the identity s ratings a ects the number of overall ratings (n), as well as the order of some of the ratings (i).
Thus, providing a strongly positive rating of a new content object causes the relative view of other positive ratings to be lowered, ensuring that the identity can not simply repeatedly  sell  her ratings in exchange for compensation while providing the same bene t to all content items.
Instead, to have the same e ect as a single positive rating today, a user must simultaneously rate a large number of content objects negatively; this makes it much more di cult for malicious users to  buy  ratings from otherwise honest users.
In summary, the two parts of Iolaus work together to strengthen content rating sites.
The use of max  ow-based techniques ensures that users gain little bene t from creating multiple identities.
The use of relative ratings reduces the e ectiveness of  buying  positive ratings from random users, who generally do not have a signi cant rating history.
We now discuss a few deployment issues with Iolaus.
Underlying network As discussed in the design section, Iolaus assumes existence of an underlying social network and will not be applicable to services that lack such network.
Fortunately, most services today either directly have the social network or allow users to import their friends from other social networks such as Facebook and Twitter.
Disconnected users In Section 3, we noted that Iolaus assumes that the underlying social network is a connected graph.
This assumption is not unique to Iolaus (all social network-based Sybil defense systems make a similar assumption [28,38,44,45]).
In order to allow users who are not connected in the social network (e.g., guest users), Iolaus could be modi ed to create a  virtual  account for the user, with random links placed temporarily to allow rating calculation.
Rating interpretation Due to the use of relative ratings, the  nal ratings calculated by Iolaus will be a real-valued numbers between 0 and 1 (rather than, say, a number of stars).
One potential concern is over how users will interpret such values.
This range can trivially be mapped to any desirable range by a simple percentile conversion (e.g., the top 15% of content items receive !!!!!
).
Additionally, the ratings in Iolaus are personalized, meaning di erent users may see di erent rankings for the same content object.
While this will clearly require an explanation to the users, existing sites such as NetFlix [3] and Digg [36] already provide personalized content ratings (implying that users do accept personalized ratings).
Impact on non-malicious users Another potential concern about using Iolaus is that it may change the current ranking of businesses, potentially for the worse.
We evaluate this e ect in Section 7, demonstrating that Iolaus does not adversely impact the rankings for non-malicious users.
We now turn to evaluate the performance of Iolaus.
We implemented Iolaus in C++ and Python.
The implementation is divided into two parts: one that locates paths in the social network, and one that uses those paths and the rating history to calculate the rating.
social network is expensive, and na ve implementations can easily result in poor scalability.
To avoid this poor scal-ability, Iolaus is implemented using Canal [40], a system that approximates credit payments in large credit networks.
Canal uses landmark routing-based techniques to e ciently locate disjoint paths in large networks; we modi ed Canal to disable the credit transactions, and only use Canal to quickly  nd paths.7 The remainder of the Iolaus implementation consists of code that interacts with Canal, calculates weights, and transforms raw ratings into relative ratings.
This part is implemented in 2,650 lines of Python.
Social networks In the subsequent evaluation, we use both real-world social networks and synthetic social networks of varying sizes.
Table 2 gives the statistics of the networks.
The synthetic networks are generated using nearest neighbor method [31], with prescribed number of nodes, probability of adding new nodes, and number of random pairs connected.
The resulting networks have been shown [31] to have characteristics close to real-world social networks.
The real-world social networks come from two large content rating sites: YouTube and Yelp.
First, we use the social network of YouTube users [22], as originally used in the SumUp evaluation [38].
Unfortunately, the YouTube data set only contains the social network, and does not contain content ratings.
Second, we collect data from Yelp containing both social network information and content ratings from two cities: Boston and San Francisco.
Speci cally, we  rst determined the set of all businesses on Yelp located within the each city; this totaled 9,228 businesses in Boston and 30,339 in San Francisco.
Then, we collected all ratings on these businesses; this totaled 278,719 ratings from 82,846 users in Boston and
 nally, we collected all of the social connections of these users; this resulted in a network of 383,557 users connected together with 888,335 links in Boston and 1,111,254 users and
 As Iolaus assumes that the social network is a connected graph, we only consider users located in the largest connected component (LCC) [22] of each Yelp graph.
The LCC encompasses the vast majority of the data: In Boston, it covers 327,515 (85.3%) users connected by 883,179 (99.4%) links and providing 190,042 (68.1%) ratings.
In San Francisco, it covers 1,303,086 (82.7%) users connected by 3,912,279 (99.8%) links and providing 1,303,086 (78.7%) ratings.
Simulating Sybil attacks Similar to prior studies [38], we simulate Sybil attacks by injecting malicious nodes and adding attack links (links from malicious nodes to non-malicious nodes).
We refer to non-malicious nodes who are linked to by malicious users as attacked nodes.
Inspired by
 three threads for creating universes, and sixteen threads for  nding paths.
only un ltered reviews are used by Yelp in determining a business  score.
We collected both  ltered and un ltered reviews.
Network YouTube Yelp Boston Yelp San Francisco Synthetic 1 Synthetic 2 Synthetic 3 Synthetic 4 Nodes 1.1 m 383 k 1.1 m 10 k 100 k 600 k Links 5.8 m 890 k 3.9 m 29 k 280 k 8.11 m 1 m 12.3 m Average degree






 Table 2: Statistics of the social networks used for evaluating Iolaus.
The synthetic networks are measurement-calibrated synthetic social networks [31].
prior work [41] we examine three di erent attack strategies for selecting attacked nodes: Random Attacked nodes are chosen randomly.
k-closest Attacked nodes are chosen randomly among the k closest nodes (by hop distance) to the collector.
This represents a targeted attack on a particular collector.
k-highest Attacked nodes are chosen randomly from among the k highest degree nodes in the network.
This represents the most e ective attack for being close  for many collectors.
Note that we control the  power  of the attacker by varying k; a smaller k implies that the attacker can better target her attack (e.g., a small k in k-closest implies the attacker is able to obtain attack links very close to the collector).
Simulating  bought  ratings We also simulate the  buying  of ratings by malicious businesses in Yelp.
To do so, we select random non-malicious users to provide  bought  ratings; each one of these users is simulated to provide one additional highly positive rating on the Yelp business that is trying to manipulate the ratings.
Comparing against SumUp and Yelp We compare the performance of Iolaus to SumUp [38] and a strawman version of Yelp s rating.
For SumUp, we use the original code (obtained from the SumUp authors) and con gured to the default values9 prescribed in the original paper [38].
In practice, Yelp has a review  ltering mechanism designed to block attacks, but its design is deliberately obfuscated [48].
As a result, we are unable to compare Iolaus directly against Yelp s  ltering mechanism (as we do not know how it would perform when we introduce Sybil and rating-buying attacks).
We begin by examining the amount of CPU time and memory required to determine an aggregate rating in Iolaus.
Io-laus is designed to be parallelized; it can be con gured to use multiple cores, and distributed across multiple machines, to
 However, since attackers can split identities on attack links (  4.1), the link pruning optimization in SumUp will only make it harder for honest users to  nd paths (Sybils can split their attack links across multiple identities, thereby avoiding the e ects of pruning).
Hence, we turn o  this feature to make the comparison to SumUp fair.
925e c n e u l f n i l i b y







 Iolaus (random) SumUp (random) Iolaus (k-highest) SumUp (k-highest)
 Number of non-malicious raters

 Iolaus (k-closest) SumUp (k-closest)
 Number of non-malicious raters


 Number of non-malicious raters
 (a) (b) (c) Figure 4: Sybil in uence as the number of non-malicious raters is varied, for di erent attack strategies on the YouTube graph with 100 attack links.
The graphs show (a) random attacked nodes, (b) k-closest attacked nodes, and (c) k-highest degree attacked nodes, with k = 200.
speed up computation time.
We evaluate Iolaus deployed to a single machine with dual 8-core hyper-threaded Intel Xeon
 Using the di erent networks, we select a single collector and a variable number of raters randomly from among all nodes.
We then measure the time required to determine the aggregate rating, repeating the experiment 20 times and reporting the average.
Figure 5 presents the results of this experiment.
We observe that even when 100 users place a rating, the time required to determine the aggregate rating is under 5ms in all networks.
In practice, most businesses would take substantially less: in our Yelp dataset, only 8% of businesses have more than 100 ratings.
Moreover, the site operator could easily cache the calculated ratings, either with a  xed timeout or until a certain number of new ratings are provided.
In Iolaus, Canal stores the social network in memory.
As a result, the memory requirements of Iolaus are determined by the memory requirements of Canal.
On a similarly con gured server to ours, Canal has been shown [40] to scale to networks containing hundreds of millions of links.
We now compare Iolaus directly against SumUp.
As SumUp was only designed to mitigate the e ect of Sybil attacks (and not rating-buying attacks), we only examine Sybil attacks here; in the following section, we examine both Sybil attacks and rating-buying attacks on our Yelp data set.
We use the YouTube social network graph that was used in the original evaluation of SumUp [38].
While Iolaus is a weighing system which assigns a weight to every rater, SumUp either accepts or rejects a user s rating outright.
Thus, directly comparing the two systems is not immediately straightforward.
To make head-to-head comparison, we need a single performance measure which  ts both systems.
To do so, we consider SumUp also as a weighing system, which assigns weights 0 or 1 to raters that are rejected or accepted, respectively.
We then de ne the metric Sybil in uence as Sybil in uence = Aggregate weight of Sybils Aggregate weight of all raters
 We  rst examine the e ect of number of non-malicious raters on Sybil in uence when the number of attack links is  xed.
As the number of non-malicious raters increases, with a  xed number of attack links, we expect that both SumUp and Iolaus have lower Sybil in uence.
In this experiment, we select a random collector and 100 attack links, and vary the number of non-malicious raters.
We repeat the experiment
 Figure 4 presents the results of this experiment when using the random, k-highest degree, and k-closest attack link strategies, with k = 200 (note that the k-closest scenario represents a very strong attacker, as there are over 82,000 total users).
For all cases, Iolaus outperforms SumUp in reducing the impact of Sybils.
The underlying reason is that in SumUp, for the random and k-highest degree attacked nodes, the Sybil raters are able to use each of the 100 attack links to get one rater accepted, allowing the Sybils to have signi cant in uence.
In the case of the k-closest nodes strategy, Sybils are able to be part of SumUp s  envelope  around the collector, enabling them to cast multiple votes per attack link.
With Iolaus, the Sybils  100 attack links are forced to compete with all of the non-malicious raters  links.
Sybils in Iolaus still manage to receive signi cant weight as they are very close to the collector, but have substantially lower in uence than SumUp.
With most content objects having few ratings, improved performance with few non-malicious raters is extremely important.
) s m ( e m
 i





 Synthetic 1 Synthetic 2 Synthetic 3 Synthetic 4 Yelp Boston Yelp SF YouTube








 Number of ratings representing the fraction of the total weight controlled by the Sybils.
Thus, the smaller the Sybil in uence value is, the better the system is at mitigating Sybil attacks.
Figure 5: Average Iolaus running time for gathering up to 100 ratings in di erent networks.
926e c n e u l f n i l i b y







 Iolaus (random) SumUp (random) Iolaus (k-highest) SumUp (k-highest)
 Number of attack links

 (a) Iolaus (k-closest) SumUp (k-closest)
 Number of attack links (b)


 Number of attack links
 (c) Figure 6: Sybil in uence as the number of attack links is varied, for di erent attack strategies on the YouTube graph with 100 non-malicious raters.
The graphs show (a) random attacked nodes, (b) k-closest attacked nodes, and (c) k-highest degree attacked nodes, with k = 200.
We now examine the impact of the number of attack links on the resulting Sybil in uence.
We expect that as the number of attack links increases, the Sybil in uence should increase linearly.
In this experiment, we select a random collector, 100 random non-malicious raters, and vary the number of attack links.
As before, we repeat the experiment 20 times and report the average.
Figure 6 presents the results of this experiment for all three attack strategies.
We observe that Iolaus has lower Sybil in uence than SumUp under all three cases.
The reason for the superior performance is the same as before: in SumUp, the Sybil raters are able to use each of the attack links to get one rating accepted for random and k-highest attacks, and multiple ratings accepted for the k-closest attack.
In Iolaus, the Sybil raters must compete with the aggregate links of the non-malicious raters.
We now evaluate Iolaus on real-world data (including both social network and content ratings), examining Iolaus s resilience to Sybil attacks and rating-buying attacks.
In this section, we use the Yelp data sets from Boston and San Francisco, described in Section 7.1.
g n i t a r s u a o l









 We begin by examining the impact of using Iolaus on the overall ranking performance.
In other words, how much does using Iolaus for aggregating ratings a ect objects  rankings, even when Sybil and rating-buying attacks are not occurring?
We use two approaches to address this question: First, we examine the global ranking of businesses; we compare these rankings to Yelp s current ranking.
Second, we examine the per-collector ranking of businesses by comparing to ground-truth rankings provided by users.
In order to compare two rankings, we use the metric Area under the Receiver Operating Characteristic (ROC) curve or A".
In brief, this metric compares two ordered lists and represents the probability that the relative ranking of two items is in the same order in both lists [12].
Therefore, the A" metric takes on values between 0 and 1: A value of 0.5 represents no correlation between the lists, with higher values indicating a better match and 1 representing a perfect match between the two lists.
To examine the global ranking, we  rst rank all 9,228 Yelp Boston businesses using Iolaus for 10 randomly selected collectors.
We then take the average of the Iolaus ranking across these 10 collectors to be the overall ranking of each business.
Finally, we compare the order of ranked businesses in Iolaus to Yelp s order.
We  nd that Iolaus s order compares to Yelp s order with an A" of 0.88.
This indicates a strong agreement between the two orders, indicating that Iolaus does not signi cantly impact the ordering when Sybil and rating-buying attacks are not occurring.
A scatterplot of the two rankings compared is presented in Figure 7.
Next, we compare the ranking error of Yelp, SumUp, and Iolaus.
To do so, we  rst select a set of 500 users who have ranked at least 10 businesses.
For each of these users, we calculate the Yelp, SumUp, and Iolaus rating of the businesses that user has rated, excluding the user s own rating.
Each of these ratings are essentially predicted ratings; we then com-


Yelp rating


 City Boston San Francisco Yelp Filtered SumUp



 Iolaus

 Figure 7: Scatterplot of Iolaus ratings versus Yelp s ratings for all Yelp Boston businesses.
For the sake of accuracy, Yelp s ratings are not rounded to half-hops (as they typically are on Yelp s site).
A strong agreement between the two ratings is observed.
Table 3: Accuracy (A") of di erent systems in predicting users  rankings of businesses.
All systems perform similarly, showing that Iolaus does not sig-ni cantly altering the rankings of businesses in Yelp.
927t n e m e v o m g n k n a r .
i g v







 SumUp (Boston) SumUp (SF) Iolaus (Boston) Iolaus (SF)
 Number of attack links

 t n e m e v o m g n k n a r .
i g v








 SumUp (Boston) SumUp (SF) Iolaus (Boston) Iolaus (SF)
 Number of bought ratings


 Figure 8: Average ranking movement of Iolaus and SumUp under di erent numbers of attack links.
Figure 9: Average ranking movement of Iolaus and SumUp under di erent numbers of  bought  ratings.
pare the predicted ratings to the actual ratings provided by the user, and measure the di erences using A".
Table 3 presents the results of this experiment for Yelp data in both Boston and San Francisco.
We observe that all three systems are comparable, with Iolaus performing slightly worse.
This indicates that Iolaus does not dramatically change the rankings of businesses.
We now investigate Iolaus s performance on the Yelp dataset under Sybil attacks.
For these experiments, we simulate Sybils placing highly positive ratings on a target business, and use the k-highest degree attack strategy with k = 200.
Even though Figures 4 and 6 suggest that k-closest attack is the strongest, this attack is targeted at a particular collector.
To in uence the ranking for many collectors, Sybils are best served by attacking high-degree nodes.
Unfortunately, we cannot directly compare the SumUp s score with Iolaus s score (recall that SumUp s score is in terms of stars, whereas Iolaus s score is transformed to the unit interval).
Thus, we compare the relative score of di er-ent businesses.
To make the results comparable across cities and repetitions of the same experiment, in this section, we only consider businesses with exactly 10 ratings.
To measure the impact of the Sybil attack, we  rst select a target business from the lowest-ranked 25% of businesses with 10 ratings.
The target business is the business that is trying to conduct a Sybil attack or  buy  ratings to increase its ranking.
We then select a list of businesses to compare the target business against.
We select these business with a wide distribution of ranks up to 20 businesses with an 2!
interval resulting in a list of 111 average rating in each 1 businesses (not all intervals contain 20 businesses).
Finally, we measure the impact rating manipulation by measuring the di erence (in terms of the number of places) the target business moves up in the ranking of 111 businesses after manipulation.
We refer to this metric as ranking movement; lower ranking movement is better (an ideal system, of course, would allow 0 ranking movement).
Figure 8 shows the average ranking movement for 10 target businesses conducting Sybil attacks, averaged across 10 randomly selected collectors.
With SumUp, the target business is able to signi cantly change the ranking, making itself appear much more highly ranked.
This manipulation is possible as SumUp allows the Sybils to place an additional rating with each additional attack link.
However, Iolaus manages to much more tightly bound the Sybils  in uence, allowing signi cantly less ranking manipulation.
Next, we investigate the ability for Iolaus to defend against rating-buying attacks.
In these experiments, we do not add any Sybils or attack links, but instead, select a varying number of random non-malicious users to provide  bought  ratings.
We simulate the non-malicious users providing highly positive reviews on a business.
To evaluate the impact of this attack, we use the same businesses as in 7.4.2, and measure the impact of the attack using ranking movement.
Figure 9 presents the results of this experiment.
As before, the results are the average across the same 10 collectors as in 7.4.2.
We observe that, without any resistance to rating-buying attacks in SumUp, malicious users are able to greatly in uence the overall ranking the business receives.
However, with Iolaus, the overall impact on the target business s ranking is much lower, as the relative ratings reduce the impact of the purchased ratings.
Comparing Figures 8 and 9, we observe that rating-buying is a much stronger attack than Sybil attack, and has greater impact on  nal ratings.
This result is expected, as bought ratings come from legitimate users who are likely well-integrated into the social network.
However, we can see that Iolaus performs much better against such attacks in comparison to SumUp, which was not designed to protect against rating  buying. 

 We have presented Iolaus, a system that is designed to be deployed by the operator of an online content rating site and can defend against multiple-identity (Sybil) attacks and the  buying  of ratings.
Iolaus is built using two techniques.
First, Iolaus uses the weighing of di erent ratings to ensure that the total in uence that any (human) user can have is bounded, regardless of the number of identities that the user creates.
Second, Iolaus converts raw ratings into relative ratings, dramatically reducing the impact of the buying of ratings in practice.
An evaluation demonstrated that Iolaus has low overhead and can be applied to the online content rating systems of today.
We thank the anonymous reviewers for their helpful comments.
We also thank Giorgos Zervas for his assistance with collecting the Yelp data.
This research was supported by a Google Faculty Research Award, NSF grant IIS-0964465, and an Amazon Web Services in Education Grant.
