In spite of the success of distributed systems like the World Wide Web, a large share of today s information available on computers is not made available to the outside, but it remains secluded on personal computers stored in (cid:2)les, emails and databases (cid:151) information that we will call PC data in the following.
In theory, peer-to-peer networks are ideally suited to facilitate PC data exchange  Research for this work was performed while A. Wranik was a master s student at AIFB.
Copyright is held by the author/owner(s).
  she retains meta-information about what other peers know;   she might not even ask the others about their knowledge, but observe it from communication;   she does not have a (cid:2)xed schema, but easily builds up new schematic or taxonomic knowledge structure;   she then decides to ask one or a few peers based on how she estimates their coverage and reliability of information about particular topics.
1http://kmr.nada.kth.se/el/ims/md-lomrdf.html
 SWAP platform (Semantic Web And Peer-to-peer) and for this platform we have developed an original algorithm, REMINDIN  (Routing Enabled by Memorizing INformation about Distributed INformation), that
 on a given triple query, hence avoids network (cid:3)ooding;

 swered which queries successfully.
In contrast to, e.g.
[2, 19], this is a lazy learning approach [3] that does not advertise peer capabilities upfront, but that estimates it from observation (cid:151) the main advantage being that a dynamic semantic topology is made possible by adapting to user queries.
We evaluate the algorithm on a simulation platform with a structure that is aligned to the structure of the original system.
Thereby, we evaluate the hypotheses that
 estimate capabilities from observation of queries.
In particular, this effect is achieved as meta-information is accumulated over time;
 information being available and queried changes;
 effectiveness.
We conclude with a survey of related work and an embedding of our work into some overall objectives for self-organizing information systems.
The EU IST project SWAP (Semantic Web And Peer-to-peer) features two case studies.
Both build on top of the SWAP platform exploiting its principal features as outlined in Section 3.
The IBIT case study is about sharing of databases and documents between cooperating tourism organization on the Baleares, a group of Spanish islands in the Mediterranean.
Some of the features of the case study include that the de(cid:2)nition of a unique global schema or ontology is not possible, that their topics are under drift and that the knowledge management support to be provided by the peer-to-peer must deal with this (cid:3)exibility.
In SWAP Bibliography case study, we will explore the sharing of Bibtex information between peers of researchers.
Bibtex will be locally harvested from (cid:2)les and stored in the SWAP local node repository.
Then one may search on the own peer as well as in the network in order to retrieve the appropriate bibliographic data.
This scenario is particularly interesting for further investigation, because (i) it is small enough to be realistic and successful; (ii) bibtex data have a stable interesting core, but also greatly varying additional (cid:2)elds as each user may de(cid:2)ne his own bibtex entries; (iii) bibtex data can never be fully captured in a centralized repository, because one repository such as DBLP can only re(cid:3)ect a small set of topics (e.g., databases and AI, but not organizational issues of knowledge management).
To make such case studies realistic it is necessary to effectively and ef(cid:2)ciently locate the appropriate peer that can answer particular questions.
In the following, we (cid:2)rst survey the SWAP platform, then we describe the algorithm we have conceived to solve the localization problem, viz.
REMINDIN .
Table 1: Data structures and parameters Data structures


 pmax 2 N+ hmax 2 N+
 (cid:190) 2 R+ ^ (cid:190)   1 randomContri  bution 2 f0::1g tc 2 f0::1g Local node repository (ontology) Query Meta data object for a speci(cid:2)c peer and resource Con(cid:2)guration Parameter The maximum number of peers selected for query forwarding The maximum number of hops a query is allowed to travel (the horizon of the query) The mean of a distribution The standard deviation of a distribution A proportion of peers which are selected randomly instead of by the algorithm Parameter for contribution of the overall con(cid:2)dence value to the overall rating Parameters observed during runtime

 selectedPeersQ Overall con(cid:2)dence into a peer Con(cid:2)dence into knowledge of a speci(cid:2)c peer about a speci(cid:2)c resource A set of peers to forward query Q to

 The SWAP platform is built on JXTA.
It features (among others) a set of modules for information extraction from the local peer, for information storage and for query routing.
Information and Meta information Information at each peer is stored in a local node repository.
In our implementation these are RDF(S) statements in Sesame [5].
We here recollect that each RDF(S) statement consists of a subject, a predicate and an object.
A statement may describe either data, e.g.
(TBL isAuthorOf WeavingTheWeb)2, or conceptual information, e.g.
(University subClassOf Organization).
The SWAP storage model3 (cf.
[4]) does not just capture some statement like the two examples just given, but it also provides meta-information about these statements in order to memorize where the statement came from and how much resource-speci(cid:2)c con(cid:2)-dence and overall con(cid:2)dence is put into these statements and peers, respectively.
The SWAP model for meta-information consists of two RDFS classes, namely Swabbi and Peer.
For these classes, several properties are de(cid:2)ned to provide the basis for the social metaphors outlined above and speci(cid:2)ed further below.
Their corresponding data structures are summarized in Table 1.
Swabbi (M O): Swabbi objects are used to capture meta-infor-mation about statements and resources.
They comprise the following properties:   hasPeer (M O:peer) : This property is used to track which peer this Swabbi object is associated with.
  Resource-speci(cid:2)c Con(cid:2)dence (M O:RC): This con(cid:2)dence value indicates how knowledgeable a peer is about a speci(cid:2)c resource on a scale from 0 to 1.
High con(cid:2)dence is expressed
 though they are very useful and indeed exploited in the SWAP platform.
3http://swap.semanticweb.org/2003/01/ swap-peer# 641by values near 1 and low or no con(cid:2)dence is expressed by values near or equaling 0.
best answers the question.5 Thus, the Swabbi object can capture for each rdf:Resource how much con(cid:2)dence one assigns to the remote peer concerning matters of the particular resource.
The link between rdf:Resource and Swabbi is given by property hasSwabbi.
The reader may note that when we speak about (cid:147)con(cid:2)dence assigned to a remote peer concerning a particular statement(cid:148), this is equivalent to the longer formulation (cid:147)con(cid:2)dence assigned to a remote peer concerning the subject of a particular statement(cid:148).
Thus, we gather con-(cid:2)dence meta-information around resources as anchors and avoid inef(cid:2)cient rei(cid:2)cation.
Peer (P ): For each statement we have to memorize which peer it originated from.
Information about a peer, e.g.
its name, is speci-(cid:2)ed by instances of the class Peer.
The Swabbi links via hasPeer to Peer.
In particular, each peer also memorizes and updates how much he con(cid:2)des overall into the other one:   Overall Con(cid:2)dence (P:OC): Some peers may be more knowledgeable than others.
This peer attribute is used to measure the overall con(cid:2)dence on a scale from 0 to 1, with 1 indicating that the remote peer is knowledgeable and 0 in dicating the opposite.
Knowledgeable peers are the ones that provide a lot of information in general.
We here consider two querying modes of the SWAP platform.
First, we have a general query language, SeRQL [6], which was conceived by Broekstra et al. and which combines advantages of languages such as RQL [11], RDQL [15] and QEL [18].
Second, to reduce complexity of the simulation and get a better experimental grip at what peers do ask in the simulation environment, we have restricted the general SeRQL queries to the parts that it consists of, viz.
queries for triples.
Comparably to TAP [13], we query by getData(s,p,o) (1) With s; p; o being either concrete URIs or (for o only) literals.
In addition, s; p; o may be a wildcard  *  with the intuitive meaning that any URI or literal would match here.
For instance, getData( ; uri2;  ) would match triples like (uri bill; uri2; uri  hillary) and (uri   ronald; uri2; uri   nancy).
This is a reasonable simpli(cid:2)cation, as all SeRQL queries are eventually compiled to sets of such triple queries and since even such a simple querying mechanism allows comprehensive information requests.
Peer-to-peer system are computer networks.
The decentralized governing principles of peer-to-peer networks resemble social networks to a large extent.
As mentioned before, a core task in such a network is (cid:2)nding the right peer among the multitude of possible addressees such that this peer returns a good answer to a given question.
To do this effectively and ef(cid:2)ciently, REMINDIN  builds on social metaphors of how such a human network works: We observe that a human who searches for answers to a question may exploit the following assumptions4:
 any way exhaustive or without exceptions.
if he/she knew answers to our previous questions.
about a speci(cid:2)c domain, he/she will probably be well informed about a similar, e.g.
the next more general, topic, too.
independently of the domain.
persons is not measured on an absolute scale.
Rather, it is often considered to be relative to one s own knowledge.
REMINDIN  builds on the metaphors of peer-to-peer networks being like a human social network and adopts the above mentioned assumptions in an algorithmic manner.
REMINDIN  consists of three major phases realizing these assumptions.
Peer selection of REMINDIN  is based on assumptions (1) and (2).
Query relaxation of REMINDIN  weakens the conditions that must be met such that we select a peer (assumption (3)).
Statement evaluation modi(cid:2)es our estimation of the general profoundness of a peer s knowledge (4) as well as its topic speci(cid:2)c profoundness (5).
These phases are embedded in the following into the overall, high level network protocol.
Its answers are pre-REMINDIN  consists of several steps executed locally and across the network when forwarding as well as answering queries and when receiving responses.
Assuming the user of a peer issues a query to the peer network, the query is evaluated: Locally against the local node repository.
sented.
Across the network: Forwarding.
Simultaneously, peer selection (algorithm 1) is invoked to select a set of peers which appear more promising than the others to answer the given query.
If it cannot select any peers for the given query, the query relaxation (algorithm 3) will be used to broaden the query until either all peers can be selected or eventually all known peers are returned.
The original query is then send to a subset of the selected peers according to their strength.
The message containing the query has a unique id and stores the id s of visited peers (message path) to avoid cycles.
Across the network: Answering Queries.
When a peer receives a query, it will try to answer it and it will store an instance of Peer in its local repository referencing the querying peer.
A meta object is created for each resource the query was about.
The answer is returned directly to the querying peer.
We just return an answer if it is not empty.
However, for the peers selected by the querying peer the peer rating algorithm is invoked even if they have no answers.
If the number of maximum hops is not reached yet, the query will be forwarded to a selected set of peers (cid:151) using the same peer selection described before.
Receiving Responses.
On the arrival of answers at the querying peer, relevant answers are selected with the statement selection algorithm and included into the repository.
The answering peer and the included statements are rated according to the statement evaluation (algorithm 4).
We here brie(cid:3)y survey the just mentioned algorithms, before we go into more details in Sections 4.3 to 4.5.
edge.
In future versions one may consider properties like latency, costs, etc.
selection is based on observations of remote peers  knowledge.
Statements from the local node repository that match the query constitute the basis yielding meta-information about where they came from.
Thus, these statements help to identify the set of most knowledgeable peers.
Often, this procedure alone does not result in a suf(cid:2)cient number of peers to forward the query to.
Then, the query relaxation algorithm is applied to the query.
Based on the resulting set of statements and peers, we combine the P:OC value into each peer as well as the M O:RC values, which may vary for each statement and peer, in order to derive a ranking according to algorithm 2.
The result of algorithm 1 is an ordered set of peers to forward a query to (see Section 4.3 for details).
Query relaxation (algorithm 3): As just outlined, a query to the local node repository may not directly match any of its statements.
Following observation (3), REMINDIN  relaxes the given query subsequently targeting peers with similar knowledge (see Section 4.4 for details).
Statement selection: Often the answer of a query contains more information than one wants to retain in the local node repository.
Then, the user must either manually determine which information to store or the system must provide an automatic mechanism.
Currently SWAP supports only manual statement selection.
For evaluation of REMINDIN in our simulation, we have not retained any statement of any answer at all in order to test REMINDIN with the worst-case assumption.
Update overall (P:OC) and resource-speci(cid:2)c (M O:RC) con(cid:2)-dence values (algorithm 4): The P:OC and M O:RC values a peer assigns to remote peers and its associated statements are updated separately on the basis of the received answers.
The number of statements returned is measured against the statements matching the original query already known by the querying peer.
This measure is combined with the existing ratings in order to adjust the P:OC and M O:RC values according to algorithm 4 (see Section 4.5 for details).
Evaluating a query against the local node repository returns a set of statements matching the query.
For each statement we retrieve its meta data, viz.
a set of meta objects which comprise resource-speci(cid:2)c con(cid:2)dence values for each peer s knowledge about the particular statement and overall con(cid:2)dence values for each peer.
The remote peers (local peer is omitted) are sorted according to their strength.
Up to pmax best rated peers are returned as targets for the query.
If REMINDIN  was not able to select suitable remote peers until then, REMINDIN  would relax the query and repeat the procedure.
Algorithm 1 formalizes this procedure.
It is called with the ontology O of the peer considering the query for forwarding, a query queue Q containing only the given query Q as an and an empty queue.
Algorithm 1 uses Algorithm 2 as subroutine.
Table 2 summarizes all auxiliary functions and procedures.
Relaxation of a query can be achieved in a number of ways.
We exploit the following considerations, which are also summarized in Table 3.
Table 2: Auxiliary Functions and Procedures Algorithm 1 performQuery(O; Q)
 retrieveMetadata(O; S; P )
 retrieveAllMetadata(O; S)
 rankPeers(selectedPeers) !
rankedPeers Evaluate getData(Q) on local node repository O returning statements S Retrieves from the local repository the meta data object for the subject of the speci(cid:2)c statement S and peer P ; if the subject does not have a Swabbi attached, retrieveMetadata queries the object for hasSwabbi Generalizes retrieveMetadata to all peers and returns sets of metadata, too Algorithm 2 rates each peer P that is found on the queue selectedPeers in a pairing with con(cid:2)dence values and returns the ranked queue rankedPeers Algorithm 3 determineState(Q) !
state newQuery(O; Q; state) Returns the current state of the query according to Table 3 Returns queue of relaxed queries update( ; (cid:190); v)
 !
[0; 1] invUpdate( ; (cid:190); v) !
iu Algorithm 4 v 2 R+; u 2 [0::1] Update map a given value v onto a value between 0 and 1.
The actual outcome depends on the function used in update v 2 [0; 1]; iu 2 R+ invUpdate reverses the mapping done by Update.
The mapping is a means to keep the overall/resource-speci(cid:2)c con(cid:2)dence value between 0..1
 one knows he had statements about the same subject-object combination, but with other predicates (states 1-3).
combination, if one knows he had statements about the same subject alone, but maybe with other predicates (state 4).
he had statements about the object, but where the object appeared in the subject position (state 5).
he had statements about the superproperty (state 6).
(a) the subject is a class and one knows the peer was knowledgeable about the superclass (state 7a), or (b) the subject is an instance and one knows the peer was knowledgeable about a class the subject is an immediate instance of (state 7b).
(i.e. in RDF these are rdf:resource, rdfs:class, rdfs:property, rdf:type, etc.)
cannot be relaxed further.
Algorithm 3 implements these considerations.
It exploits Table 3 in order to derive a(n often single-element) set of relaxed queries.
One may note in particular: (i) multiple relax queries exist when one asks for superproperties of a given property or immediate types
 Require: LocalNodeRepository O, Queue of Queries Q, Queue of peers A SQ :=performQuery(O; Q) for all S 2 SQ do MO :=retrieveAllMetadata(O; S) for all M O 2 MO do










 12: end for


 16: end if
 end for end for selectedPeers.push((M O:peer; M O:RC)) Algorithm 2 Peer Rating: rankPeers(selectedPeers) Require: Queue of pairs selectedPeers
 (P; RC) 2 selectedPeersg = fP1 : : : Png for all RC 2 RC do




 7: end for
 strength(P ) := tc   P:OC + (1  tc)   end for where strength(P1)   : : :   PjPj

 jRCj PRC2RC RC of a subject; (ii) implicitly this relaxation is recursively applied in Algorithm 1; and, (iii) there remain other options for query relaxation; (cid:2)rst tests revealed that the above ones give quite good results for later-on selecting an appropriate peer to send the original query to.
In general, however, further exploration and optimization of the current design choices are desirable.
State





 7a 7b
 Table 3: Query relaxation order Query (s; p; o) (s; p;  ) ( ; p; o) (s;  ; o) ( ;  ; o) ( ; p;  ) (s;  ;  ) (s;  ;  ) Relaxed Query (s;  ; o) (s;  ;  ) ( ;  ; o) (s;  ;  ) (o;  ;  ) ( ; super(p);  ) (super(s);  ;  ) (class(s);  ;  )


 con(cid:2)dence values The algorithm updateValues updates the overall con(cid:2)dence values one memorizes about a peer P (P:OC), and it updates the Algorithm 3 Query Relaxation: relaxQuery(O; Q) Require: O; Q state := determineState(Q) Q := newQuery(O; Q; state) return Q resource-speci(cid:2)c con(cid:2)dence values M O:RC one memorizes about a pair of a peer P and a resource.
The algorithm consists of three major parts.
First, it quanti(cid:2)es what the local peer knows in O about the original query Q in the measure localAnswer and it quanti(cid:2)es what the remote peer P knows about the same query Q in the measure remoteAnswer (lines 1 to 3).
Second it compares the ratio remoteAnswer localAnswer with different numbers that depend on the mean   and standard deviation (cid:190) of all statements with regard to the  average  query (lines 6,10,14,18).
Thereby,   and (cid:190) have been found by counting results of observed queries and assuming a Gaussian distribution.
Correspondingly, in the third step, one increases or decreases or does not touch the P:OC values (lines 9,13,17,21,24,25) and the M O:RC values attached to subjects (or objects, if subjects are not found in O) of statements (lines
 ular on the size of the result set as compared to the local result.
An interesting special case happens when a remote peer has been asked directly by the local peer, but when it has not returned an answer.6 REMINDIN  then assumes after a certain time that the queried peer has no answer at all and correspondingly, the P:OC and M O:RC values are downgraded.
Thus, even if the remote peer is very knowledgeable, but unwilling to answer or overfreight with queries, the remote peer will be considered as a less worthy candidate for querying (cid:151) hence, a simple form of load balancing will be achieved, too.
Though our plans for the SWAP bibliography case study will involve the participation of several dozens and up to 100 researchers (cf.
Section 2), even this number will be too small to actually evaluate REMINDIN .
In addition, it will be dif(cid:2)cult to investigate crucial parameters of REMINDIN  without jeopardizing the running of the overall network.
Hence, we opted for evaluating REMIND-IN  by simulating a peer-to-peer network with plausible datasets of statements and query routing by REMINDIN .
To this end, we here discuss the data source on which we have based the local node repositories of the individual peers, viz.
the DMOZ open directory and its RDF dump7 (Section 5.1).
We brie(cid:3)y discuss the assignment of statements to peers (cid:151) mostly modeling human editors of DMOZ as peers (Section 5.2).
We describe the queries that are generated and sent around (Section 5.3), the initial con(cid:2)guration of the peer-to-peer network (Section 5.4), and the evaluation measures (Section 5.5) we consider subsequently to assess REMINDIN .
DMOZ, the open directory project, manually categorizes Web pages of general interest into a topic hierarchy.
For each topic one or several editors are responsible to de(cid:2)ne subtopics or related topics and to contribute links to outside Web pages to the topic pages of DMOZ.
For this semi-structured data source, there exists an RDF dump comprising a small schema and many instances.
The main classes of the DMOZ data set are Topic, Alias, and ExternalPage:
 7http://rdf.dmoz.org/ 644overall/resource-speci(cid:2)c con(cid:2)dence: // Large increase of resource/overall con(cid:2)dence updateV alueRC := COVER   cover updateV alueOC := COVER // Moderate increase of resource/overall con(cid:2)dence updateV alueRC := cover updateV alueOC := 1 Algorithm 4 Update updateValues(O; P; Q; S;  ; (cid:190)) Require: O; P; Q; S;  ; (cid:190)


 localAnswer
   + 1








 14: else if cover > 1


 18: else


 22: end if




 if S 2 O then




 end if
 33: end for // Do nothing, no de(cid:2)nitive conclusion for this range!
updateV alueRC := 0 updateV alueOC := 0 // Decrease of resource/overall con(cid:2)dence updateV alueRC :=  cover 1 updateV alueOC :=  1 M O :=retrieveMetadata(O; S; P )
 update(invUpdate( ; (cid:190); M O:RC)+ update(invUpdate(P:OC) + updateV alueOC ) COVER then updateV alueRC ) Table 4: Survey of DMOZ Open Directory structure realized as RDF schema and instances

 entity Example Number Topic Property Class Property Topic a class Schema Top/Arts symbolic, related Property domain Top/Arts Property range Topic, Alias a class Top/Arts link rdf:type symbolic, related symbolic, related narrow, narrow1 editor subClassOf Peer Instances (cid:147)http://www.
w3.org/People/ Berners-Lee/(cid:148) rdf:type (cid:147)Top/Computers/Internet/(cid:148) (cid:147)Top/Arts/(cid:148) related (cid:147)Top/ Business/Arts and Enter-tainment(cid:148) (cid:147)Top/Arts/Movies(cid:148) ClassOf (cid:147)Top/Arts(cid:148) sub-







Table 5: Major statistical parameters Property Mean No.
of topics / editor No.
of links / topic No.
of links / editor No.
of queries Expected no.
of answers / query / peer




 Standard deviation



 Topic The resource Topic has properties for link,8 containing a reference to an ExternalPage and to an editor, viz.
an editor of the topic.
The properties related, symbolic and narrow describe relations to other topics and aliases.
Alias The resource Alias has properties for Title and Target.
Target is a relation to another Topic.
ExternalPage has the properties Title and Description The data source has some interesting properties rendering it adequate for our evaluation purposes: (1) There are many relations other than taxonomic ones between the topics (cid:151) in contrast to many other datasets.
(2) Each topic has at least one editor, many have several (cid:151) implying a natural way to assign statements to peers.
(3) Topics are  populated  with many links.
The DMOZ hierarchy is available in pure RDF only.
To enhance its semantic description, we have converted it to RDFS.
We converted the topics to instances of rdfs:class.
narrow and nar-row1 were converted into rdfs:subClassOf.
The properties link were interpreted as rdf:type of the topics they belong to.
For instance, http://www.w3.org/People/Berners-Lee/
 by categorization into link, link1, link2.
We have merged these three again into one property.
The analogous case is true for symbolic, etc.
is then an instance of http://dmoz.org/Computers/ Internet/History/People/Berners-Lee,_Tim/.
In order to handle the sheer size of the DMOZ hierarchy, we included only the (cid:2)rst three levels of the hierarchy in our experiments.
The properties of the remaining data source are summarized in Table 4.
All of the 1657 topics in the (cid:2)rst three levels of the DMOZ hierarchy have one or more editors assigned to them.
Everybody can become an editor of a category in DMOZ.
DMOZ encourages users to (cid:147)choose a topic you know something about and join(cid:148).
Hence, we assume that editors who edit a topic (which became classes in RDF(S)) also store links they have assigned to a topic locally.
Since, a topic can have more than one editor, not all of the links need to come from one editor alone.
Finally, editors may also add links to other topics.
Thus, they are probably also informed about the related topic but to a lesser extent.
These assumptions have led us to the following distribution of instances in our simulation.
We represent one editor by one peer, thus we have 1100 peers.
Assuming that an editor is not the source of all instances within  his  topic ( his  class) we choose randomly 70% of the direct instances within  his  class and assigned them to the peer s local node repository.
In addition, we considered all classes directly related to  his  class (via subClassOf, via related, etc.)
and we randomly assigned 12% of the direct instances of these directly related classes to the peer s local node repository.
Thus,
 ther impression of the resulting information distribution, we list the number of topics which have i editors.
755 topics have 1 editor; 333 topics have 2 editors; 204 topics have 3 editors; .
.
.
; 44 topics have 6 editors; .
.
.
;14 topics have 10 editors ;1 topic has 32 editors.
Queries are generated in the experiments by instantiating the blueprint ( ; < rdf : type >; topic), with topics arbitrarily chosen from the set of topics that had at least one instance.
Thus, generated queries retrieved all instances of a topic (cid:151) considering also the transitivity of the subclassOf-relationship to subtopics.
I.e.
we generated 1657 different queries.
We had two different scenarios for evaluating the effectiveness of REMINDIN .
In the (cid:2)rst set of scenarios, we continuously choose from the 1657 queries and evaluated right away the results.
In the second set of scenarios, we partitioned the set of 1657 queries into two sets of equal size.
There were two phases.
First, there was a  learning phase  where the peer network was confronted with the (cid:2)rst set 828 queries.
Then, there was an explicit  test phase , in which one could observe how the peer network would readjust to the second set of queries.
Initial con(cid:2)guration of peer to peer network simulation The simulation is initialized with a network topology which resembles the JXTA network.
10 peers connect to 1 rendezvous peer randomly and the rendezvous peers connect to the central JXTA peer.9 Hence, in the beginning the only remote peer visible to the peers is its rendezvous peer.
During the simulation any peer can become visible to any other peer in the network if it knows its unique identi(cid:2)er.
The identi(cid:2)ers are propagated with the queries.10 This assumption is valid, since we focus on the semantic routing of queries rather than the technical routing.
In the simulation, peers were chosen randomly and they were given a randomly selected query to question the remote peers in the network.
The peers decided on the basis of their local node repository which remote peers to send the query to.
Each peer used REMINDIN  to select up to pmax = 2 peers to send the query to.
As a baseline we compared REMINDIN  to a naive algorithm.
In this case a peer selected randomly up to pmax peers to send the query to.
A peer that received a query tried to answer the query.
Each query stores the path that it is forwarded along and if a peer had appeared in this path, it was deselected.
In some evaluation scenarios, we have integrated a randomContribution.
The randomContribution percentage of selected peers were randomly exchanged again randomly selected ones known by the querying peer.
Each query was forwarded until the maximal number of hops (hmax) is reached.
In our experiments, we have not considered the leaving or joining of nodes, so far.
There are many criteria to evaluate algorithms for peer-to-peer systems.
In [10] we summarize many of them.
For our evaluation we rely on two major measures.
Recall R. Recall is a standard measure in information retrieval.
In our setting, it describes the proportion between all relevant statements in the peer network and the retrieved ones.
R = jretrievedj jrelevantj
 downloaded from Suns servers in the initialization phase of a peer
 ble direct addressee of a query(cid:148) a synonymous to each other Table 6: Standard parameter in evaluation Parameter   (cid:190) pmax hmax tc randomContribution P eers Value






 We use recall to assess the effectiveness of REMINDIN , i.e. to measure to which extent one may retrieve statements from the peer-to-peer network based only on local knowledge about possibly relevant peers.
Network load.
This (cid:2)gure can be measured with different sub-parameters.
Messages per query traces to what extent the network is being (cid:3)ooded by one query.
The number of average hops can indicate how goal-oriented a query is routed and how fast an answer may be returned.
We use the network load, and messages per query in particular, to assess the ef(cid:2)ciency of our approach.
Our simulations show that REMINDIN  reaches a signi(cid:2)cant higher recall than the naive baseline.
In particular, peer selection is improved by query relaxation and some random selection of peers.
Before we present the (cid:2)nal evaluation results, we here summarize the major hypotheses we wanted to investigate.
recall than the naive algorithm.
over time, such as measured in terms of messages per query and number of hops.
new queries.
ering just the original query to select peers.
tiveness of the peer selection.
cape over (cid:2)tting.
In Table 2 we de(cid:2)ne the different parameters of the algorithm.
In case we did not state otherwise, they were set to the values given in Table 6.
In the naive approach the peer has used the same parameters as REMINDIN  (cid:151) except that all the peers were chosen randomly.
Points in all the graphs represent averages for 1000 queries.
Hypothesis 1: Figure 1 summarizes the comparison between RE-MINDIN  and the naive approach.
In this scenario we used 20,000 queries and 50% of all queries.
The naive approach produced an average of 600 messages per query and had a constant recall of approximately 20%.
The recall of REMINDIN  without random contribution increases steadily over time and reaches a recall of
 about 18 queries per peer, a fairly low number.
REMINDIN  with a
 Comparison of Distribution Parameters and Relaxation Algorithm ) s t n e m e t a t
 ( l l a c e












 REMINDIN' with Random Naive algorithm

 No.
of Queries







 ) s t n e m e t a t
 ( l l a c e


 REMINDIN' without Relaxation Mean 1 - std.
dev.
1 Mean 20 - std.
dev.
10 Mean 40 - std.
dev.
10 Mean 20 - std.
dev.
70

 No.
of Queries
 Figure 1: The proposed algorithm provides better results in terms of recall than the baseline.
Messages and Hops Figure 3: Using relaxation to broaden the set of selected peers is especially useful when previously unknown queries are introduced (here: after 30,000 queries).
The parameters of the distribution affect the effectiveness of the peer selection.
) s t n e m e t a t
 ( l l a c e

















 y r e u
 r e p s e g a s s e
 f o .
o



 No.
of Queries

 Messages



 Figure 2: The number of messages decreases over time (with standard parameter setting).
The recall increases with time for all numbers hmax from 3 to 7.
The contribution of additional recall is highest for hmax between 3 and 4.
) s t n e m e t a t
 ( l l a c e


 Compariston of Overall confidence contribution Overall confidence contribution 1,0 Overall confidence contribution 0,1




 No.
of Queries Figure 4: Peer selection based on overall con(cid:2)dence only is less effective mixed accounts of overall and resource con(cid:2)dence.
little random contribution to the peer selection produces even better results.
After 20,000 queries it reaches a recall of almost 80%.
Hypothesis 2: Figure 2 illustrates a simulation run for REMIND-IN  with a random contribution of 20%.
Note that we plot the number of queries on the left hand side against the average recall and on the right hand side against the number of messages per query.
Figure 2 depicts the number of messages needed to reach the recall, in average 200.
Hence REMINDIN  increases the recall by 300% while requiring only one third of the messages per query as compared to the baseline of approx.
600.
We observe that the recall contribution decreases with the number of hops.
The recall increases by a large margin from three hops to four hops accounting for 25% of the total recall, while the recall increases only 7% from six to seven hops.
This suggests that one could decrease the number of hmax from seven to (cid:2)ve without sig-ni(cid:2)cantly changing the overall recall, but producing less network load.
Intriguingly, the overall recall increases over time while the number of messages per query remains about the same.
The number of messages comes down when the peers have built up their model, since they agree then who is knowledgeable about which topic.
Hypothesis 3: We cannot con(cid:2)rm hypothesis three, at least not for the basic algorithm without random contribution.
As Figure 3 demonstrates for different parameters   and (cid:190), the recall degrades to 20% when we introduce new queries after 30,000 queries (cf.
the second scenario for generating queries in Section 5.3).
However, we note that the introduction of completely new queries rarely happens in real world applications.
Then, Figure 4 is more promising.
Here, peer selection was randomized to 20%.
The result was that the recall retains 27% and the adaptation occurs rather quickly.
It seems that the random contribution helps to avoid over(cid:2)tting!
Hypothesis 4: Figure 3 nicely exempli(cid:2)es the effect of the query relaxation algorithm.
In the beginning the peer selection without relaxation works almost as good as with relaxation.
When new queries arise, REMINDIN  with relaxation performs signi(cid:2)cantly better than without.
Hypothesis 5: Figure 3 contrasts the effects of different parameters and query relaxation algorithm on the peer selection.
The hypothesis is con(cid:2)rmed.
However, the consequence of the parameters are less severe than the application of the query relaxation algorithm.
In particular the simulation runs suggest, that within certain ranges they do no harm.
As expected a setting with COVER not matching the actual distribution (13;533 ) COVER = 2:7) as in case (40; 100 ) COVER = 1:25) rates peers with minor knowledge to good and thus hinders the identi(cid:2)cation of the real champions.
Figure 4 concentrates on parameter tc, the contribution of the 647overall con(cid:2)dence value to the overall peer rating during peer se- lection.
This (cid:2)gure is of particular interest, because one could argue to store only the information if a peer is knowledgeable or not.
As we can see from the diagram the inclusion of the con(cid:2)dence rating increases the achievable recall and adapts better to new queries.
This test was performed with a 20% random contribution.
Nevertheless, it is still interesting to note that overall con(cid:2)dence alone does not fare too bad, either.
REMINDIN' with Random Selection Recall with no random contribution Recall with 20% random contribution ) s t n e m e t a t
 ( l l a c e




















 No.
of Messages - No.
of Hops




 Figure 5: Selecting some of the peers (20%) randomly enhances recall.
Hypothesis 6: Most of our hypotheses were supported with most strength when we combined our algorithm with a proportion of randomly selected peers.
To motivate this result we want to recall an observation from human interaction.
It happens sometimes that we meet a previously unknown person and she provides us with a yet new view on the world or on a certain topics.
Figure 5 analyzes the observation in more detail.
We put side by side the average recall with and without random contribution (20%), which we have averaged over the (cid:2)rst and last 5,000 messages.
It is obvious that the achievable recall of REMINDIN  without random contribution reaches a certain level and does not increase further.
Note that in average just 87 messages per peer were needed to get to this recall.
The difference is yet more obvious in the case of the last 5,000 messages then the (cid:2)rst 5,000.
However, with the introduction of randomness the recall can be enhanced substantially!
We consider three areas of research related to our work.
The (cid:2)rst is the general research in peer-to-peer systems.
The second area deals with semantic peer-to-peer systems and the third area of related work is chosen with respect to our query relaxation algorithm.
General research in peer-to-peer system concentrates either on ef(cid:2)cient topologies for these networks or on distribution of documents.
The small-world-effect (cf.
[2]) is one example how those topologies can be exploited to establish a connection between two nodes ef(cid:2)ciently.
In contrast to our work the content of a node is advertised to all neighbors, and thus needs updates when a nodes content changes.
The algorithm ensures that a given query is forwarded to a node with the most neighbors.
There are a number of other P2P research system which are related to the question of how to allocate documents within a peer-to-peer network.
They mostly require equally shaped keys for nodes and their contents [23] [26], thus once a key for the searched content has been created, the address and thus the root to the target peer can be easily found.
One problem with this system is that it generates a substantial overhead when nodes join and leave the network.
In [1] an algorithm is proposed which replicates documents on different peers in a way that joining and leaving produces less overhead, but ef(cid:2)cient structured search for documents is still possible.
In contrast to our work they examine how a known resource can be found with least possible messages.
They do not provide a solution how a relevant resource can be found in the (cid:2)rst place.
This is the question examined by the second group of related works.
EDUTELLA [18] is a peer-to-peer system based on the JXTA platform, which offers very similar base functionality as the SWAP system.
In [19] they propose a query routing mechanism based on super peers.
Peers which have topics in common are arranged in a hypercube topology.
This topology guarantees that each node is queried exactly once for each query.
Our algorithm is not based on an explicit topology, thus it does not generate any overhead to establish it.
Our simulations illustrate that we need much less queries than the number of peers to reach most knowledgeable peers.
Furthermore most information is in the reach of four to (cid:2)ve hops which is advantageous in terms of expected response time.
They do not provide any test on the performance of their algorithm.
Within the proposed hypercube topology all peers are equal, while we can distinguish between more or less knowledgeable peers.
In [8] a Semantic Overlay Network (SON) is introduced.
Resources are clustered into a topic hierarchy and peers subsequently join a SON.
The SONs a peer joins depend on the clustering result of the local knowledge.
In contrast to our work a peer actively joins peers which have assigned themselves to a certain SON.
We establish connections to remote peers based on the queries.
While in our case resources are organized in a graph they use a hierarchy.
Hence, they cannot exploit other relations than hierarchical ones to (cid:2)nd other promising peers.
They do not weight the connections.
In [27] an algorithm is presented which concentrates on load balancing between the peers.
While they are interested in querying peers equally often we concentrate on the selection of the most knowledgeable peers.
However, our algorithm adapts in a self-organizing way to peer overloading, while they use leading nodes to calculate different measures and reassign categories depending on results of their algorithm.
Regarding our query relaxation algorithm, a lot of research has been done in the (cid:2)eld of query relaxation in the context of cooperative databases (cf.
[7, 17]).
In those contexts queries are relaxed according to a similarity function in case a given query does not result in answers when posted to a database.
In [22] the similarity of two concepts is determined by the length of the shortest path between them, which is interesting for non hierarchical taxonomies with multiple concept inheritance.
We exploit the relations of the knowledge structure to (cid:2)nd relevant peers rather than map a query between different schema.
To our knowledge this approach has not yet been applied to peer-to-peer networks.
The principle of self-organization has been discussed for a long time as a paradigm for introducing order into complex systems without centralized control.
In recent years one could see that this principle has found its entry into different types of engineering applications (cf., e.g., [25]) (cid:151) in particular ones that involve the Web, such as identi(cid:2)cation of communities for better harvesting and classi(cid:2)cation of information [12] or ones that use self-organization in peer-to-peer networks [1].
In theory, the possibilities of self-organizing appear to be open-ended with ideas ranging up to social systems of human and machine agents that form networks with enormously effective communication structures (cid:151) as one knows, e.g., from Milgram s experiment on six degrees of separation in 1967 [16].
Though the idea of transferring such commu-648nication principles from the original social networks to comparable technical networks like Peer-to-Peer networks has been ventilated for some time (cf.
[20]), corresponding research has not taken a serious stance at it.11 To this end, we have devised REMINDIN , a highly original algorithm to (cid:2)nd peers in a semantic peer-to-peer network based on social metaphors.
The algorithm comprises a peer selection algorithm based on con(cid:2)dence ratings, query relaxation and observation of useful responses given by other peers.
The algorithm provides signi(cid:2)cantly better results than its naive counterpart.
Our experiments with REMINDIN  have shown intriguing results: (1) some randomness in peer selection helps escape over(cid:2)t-ting and improves effectiveness of REMINDIN , (2) self-organized learning by the network reduces the network load over time, and, (3) parameter settings play a role, but the behaviour of REMIND-IN , is rather elastic to their setting.
Acknowledgement Research reported in this paper has been partially (cid:2)nanced by EU in the IST project SWAP (IST-2001-34103); see swap.semanticweb.
org.
We thank all our colleagues in the SWAP project and at AIFB for fruitful discussions.
