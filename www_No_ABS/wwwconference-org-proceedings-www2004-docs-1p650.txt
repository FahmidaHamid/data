RDF [1] meta-data makes  exible statements about resources that are uniquely identi ed by URIs.
RDF statements are machine-processable and machine-understandable, and statements about the same resource can be distributed on the Web and made by different users.
RDF schemata [2] are extensible and evolvable over time by using a new base URI every time the schema is revised.
The Copyright is held by the author/owner(s).
distribution of RDF statements provides great  exibility for annotating resources.
However, distributed RDF documents on Web pages are hard to discover.
That is, obviously, just because you put an RDF document on your Web site does not mean that others can  nd it, much less issue structured queries against it.
One approach is to crawl all possible Web pages and index all RDF documents in centralized search engines,  RDF Google  if you wish, but this approach makes it dif cult to keep the indexed RDF up to date.
For example, it currently takes Google many days to index a newly created Web page.
Further, this approach has a large infrastructure footprint for the organization providing the querying service, and is a centralized approach on top of technologies (RDF, the Internet itself) that were intentionally designed for decentralized operation.
One choice for non-centralized RDF repositories is Edutella [12] which provides an RDF-based meta-data infrastructure for P2P applications.
It uses a Gnutella-like [17] unstructured P2P network which has no centralized index or predictable location for RDF triples.
Instead, RDF queries are  ooded to the whole network and each node processes every query.
Measurement studies [20, 21] show that Gnutella-like unstructured P2P networks do not scale well to a large number of nodes.
This is because their  ooding mechanism generates a large amount of unnecessary traf- c and processing overhead on each node, unless a hop-count limit is set for queries   but then the queries cannot guarantee  nding results, even if these results exist in the network.
An Edutella successor [13] provides better scalability by introducing super-peers and schema-based routing; however, it requires upfront de nition of schemas and designation of super peers.
This paper presents a scalable and distributed RDF triple repository named RDFPeers for storing, indexing and querying individual RDF statements, and which does not require the de nition of an RDF schema before inserting RDF triples into the network.
RDF triple storage providers self-organize into a cooperative structured P2P network based on randomly chosen node identi ers.
When an RDF triple is inserted into the network, it will be stored three times, based on applying a globally-known hash function to its subject, predicate, and object values.
Queries can then ef ciently be routed to those nodes in the network where the triples in question are known to be stored if they exist.
Our distributed triple repository consists of many individual nodes called RDFPeers that self-organize into a multi-attribute addressable network (MAAN) [4] which extends Chord [22] to ef -ciently answer multi-attribute and range queries.
However, MAAN only supported predetermined attribute schemata with a  xed number of attributes.
RDFPeers exploits MAAN as the underlying
 and load balancing techniques.
Figure 1 shows the architecture of RDFPeers.
Each node in RDFPeers consists of  ve components: the MAAN network layer, the RDF triple loader, the local RDF triple storage, the native query resolver and the RDQL-to-native-query translator.
The underlying MAAN protocol contains three classes of messages for (a) topology maintenance, (b) storage, and (c) search.
(a) The topology maintenance messages are used for keeping the correct neighbor connections and routing tables and include JOIN/LEAVE, KEEPALIVE and other network-structure-stabilizing messages.
(b) The STORE message inserts triples into the network.
(c) The SEARCH message visits the nodes where the triples in question are known to be stored, and returns the matched triples to the requesting node.
The RDF triple loader reads an RDF document, parses it into RDF triples, and uses MAAN s STORE message to store the triples into the RDFPeers network.
When an RDFPeer receives a STORE message, it stores the triples into its Local RDF Triple Storage component such as a relational database.
The native query resolver parses native RDFPeers queries and uses MAAN s SEARCH message to resolve them.
There can be a multitude of higher-level query modules on top of the native query resolver which map higher-level user queries into RDFPeers  native queries, such as an RDQL to Native Query Translator.
Figure 1: The Architecture of RDFPeers

 MAAN [4] uses the same one-dimensional modulo-2m circular identi er space as Chord, where m is the number of bits in node identi ers and attribute hash values.
Every node in MAAN is assigned a unique m-bit identi er, called the node ID, and all nodes self-organize into a ring topology based on their node IDs.
The node ID can be chosen locally, for example by applying a hash function to the node s IP address and port number.
In Chord, bundles of related attribute-value pairs such as  name: John, age: 27  are called  resources , a term we will avoid in this paper because of its different meaning in RDF.
Note that for RDFPeers  use of MAAN, a  bundle of related attribute-value pairs  is always synonymous with  an RDF triple .
Unlike Chord in which these bundles can only be stored and looked up by one unique key, they can be stored and looked up by any attribute value in MAAN.
Chord uses SHA1 hashing [11] to assign each key a unique m-bit identi er.
MAAN uses the same hashing for string-valued attributes.
However, for numeric attributes MAAN uses locality preserving hash functions to assign each attribute value an identi er in the m-bit space.
Here, we refer to the hashing image of the key in Chord as well as to the hashing image of the attribute value in MAAN as  the key  which is an identi er in the circular m-bit space.
Suppose we have an attribute a with numeric values v   [vmin, vmax].
(Note that in RDFPeers, the only attributes that can have numeric values are the objects given that subjects and predicates are always non-numeric URIs in RDF.)
A simplistic locality preserving hash function we could use is H(v) = (v vmin) (2m 1)/(vmax vmin), where v   [vmin, vmax].
Key k is assigned to the  rst node whose identi er is equal to or follows k in the identi er circle.
This node is called the successor node of key k, denoted by successor(k).
Similar to Chord, each node in MAAN maintains two sets of neighbors, the successor list and the  nger table.
The nodes in the successor list immediately follow the node in the identi er space, while the nodes in the  nger table are spaced exponentially around the identi er space.
The  nger table has at most m entries.
The i-th entry in the table for the node with ID n contains the identity of the  rst node s that succeeds n by at least 2i 1 on the identi er circle, i.e. s = successor(n+2i 1), where 1   i   m and all arithmetic is modulo 2m.
MAAN uses Chord s successor routing algorithm to forward a request of key k to its successor node.
If a node n receives a request with key k, the node searches its successor list for the successor of k and forwards the request to it if possible.
If it does not know the successor of k, it forwards the request to the node j whose identi er most immediately precedes k in its  nger table.
By repeating this process, the request gets closer and closer to the successor of k. Since the  ngers on each node are spaced exponentially around the identi er space, each hop from node n to the next node covers at least half the identi er space (clockwise) between n and k. The average number of hops for this routing is O(log N ) for a network with N nodes.
MAAN stores each bundle of attribute-value pairs on the successor nodes of the keys for all its attribute values.
Suppose each bundle has M pairs <ai, vi> and Hi(v) is the hash function for attribute ai (Note that M is always 3 in RDFPeers, a1 is always subject, a2 is always predicate, and a3 is always object.)
Each bundle of attribute-value pairs will be stored at node ni = suc-cessor(H(vi)) for each attribute value vi, where 1   i   M.
A STORE message for attribute value vi is routed to its successor node using the above successor routing algorithm.
M nodes store the same bundle consisting of M attribute-value pairs, each by keying on a different attribute.
Thus, the routing hops for storing a bundle of attribute-value pairs is O(M log N ) for bundles with M attributes.
Since numeric attribute values in MAAN are mapped to the m-bit identi er space using locality preserving hash function H, numerically close values for the same attribute are stored on nearby nodes.
Given a range query [l, u] where l and u are the lower bound and upper bound respectively, nodes which contain attribute value v   [l, u] must have an identi er equal to or larger than successor(H(l)) and equal to or less than successor(H(u)).
Suppose node n wants to search for bundles with attribute value v   [l, u] for attribute a. Node n composes a SEARCH message and uses the successor routing algorithm to route it to node nl, the successor of H(l).
The search message has parameters k, a, R, and X. k is the key used for successor routing, initially k = H(l).
a is the name of the attribute we are interested in, R is the desired query range [l, u] and X is the list of bundles of attribute-value pairs discovered in the range.
Initially, X is empty.
When node nl receives the search message, it searches its local sets and appends those sets that satisfy the range query for attribute a to X in the message.
Then it checks whether it is the successor of H(u) also.
If true, it sends back the search result in X to the requesting node n. Otherwise, it forwards the search message to its immediate successor ni.
Node ni repeats this process until the message reaches node nu, the successor of H(u).
Thus, routing the search message to node nl via successor routing takes O(log N ) hops for N nodes.
The next sequential forwarding from nl to nu takes O(K) , where K is the number of nodes between nl and nu.
So there are total O(log N + K) routing hops to resolve a range query for one at-
identi er space, K is N   s where s is the selectivity of the range query and s = (l   u)/(vmax   vmin).
MAAN supports multi-attribute and range queries using a single-attribute-dominated query resolution approach.
Suppose X are the bundles of attribute-value pairs satisfying all sub-queries, and Xi are the bundles satisfying the sub-query on attribute ai, where
 of X.
This query resolution approach  rst computes a Xk which satis es one sub-query on attribute ak.
Then it applies the sub-que-ries for other attributes on these candidate bundles and computes the intersection X which satis es all sub-queries.
Here, we call attribute ak the dominant attribute.
In order to reduce the number of the candidate sets which do not satisfy other sub-queries, we carry all other sub-queries in the SEARCH message, and use them to  l-ter out the unquali ed bundles of attribute-value pairs locally at the nodes visited.
Since this approach only needs to do one iteration around the Chord identi er space for the dominant attribute ak, it takes O(log N + N   sk) routing hops to resolve the query, where sk is the selectivity of the sub-query on attribute ak.
We can further minimize the routing hops by choosing the attribute with minimum selectivity as the dominant attribute, presuming, of course, that the selectivity is known in advance; in that case, the routing hops will be O(log N + N   smin), where smin is the minimum range selectivity for all attributes in the query.
Although the simplistic locality preserving hash function above keeps the locality of attribute values it does not necessarily produce uniform distributions of hashing values if the distribution of attribute values is not uniform.
Consequently, the load balancing of resource entries can be poor across the nodes.
To address this problem, we proposed a uniform locality preserving hashing function in MAAN which always produces uniform distribution of hashing values if the distribution function of input attribute values is continuous and if the distribution is known in advance.
(The former condition is satis ed for many common distributions, such as Gaussian, Pareto, and Exponential distributions.)
Suppose attribute value v conforms to a certain distribution with continuous and monotonically increasing distribution function D(v) and pos-dv , and v   [vmin, vmax].
We can sibility function P (v) = dD(v) design a uniform locality preserving hashing function H(v) as follows: H(v) = D(v)   (2m   1).
RDF documents are composed of a set of RDF triples.
Each triple is in the form of subject, predicate, object.
The subject is the resource about which the statement was made.
The predicate is a resource representing the speci c property in the statement.
The object is the property value of the predicate in the statement.
The object is either a resource or a literal; a resource is identi ed by a URI; literals are either plain or typed and have the lexical form of a unicode string.
Plain literals have a lexical form and optionally a language tag, while typed literals have a lexical form and a datatype URI.
The following triples show three different types of objects, resource, plain literal, and typed literal, respectively.
@prefix info: <http://www.isi.edu/2003/11/info#> @prefix dc: <http://purl.org/dc/elements/1.1/> @prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix xmls: <http://www.w3.org/2001/XMLSchema#> .
.
.
<info:rdfpeers> <dc:creator> <info:mincai> .
<info:mincai> <info:mincai> <foaf:name> "Min Cai" .
<foaf:age> "28" <xmls:integer> .
In order to support ef cient queries on distributed RDF triples, we exploit the overlay structure of MAAN to build a distributed index for these triples.
In the STORE message one of the three attribute values is designated as the destination of the routing, and we store each triple three times, once each based on its subject, predicate, and object.
Each triple will be stored at the successor node of the hash key of the value of the routing key attribute-value pair.
Since the value of attribute  subject  and  predicate  must be a URI which is a string, we apply the SHA1 hash function to mapping the subject value and predicate value to the m-bit identi er space in MAAN.
However, the values of attribute  object  can be URIs, plain literals or typed literals.
Both URIs and plain literals are strings and we apply SHA1 hashing on them.
The typed literal can be either string types or numeric types, such as an enumeration type or a positive integer respectively.
As discussed above, we apply SHA1 hashing on string-typed literals and locality preserving hashing on numeric literals.
For example, to store the  rst triple above by subject, RDFPeers would send the following message in which the  rst attribute-value pair ( subject , info:rdfpeers) is the routing key pair, and key is the SHA1 hash value of the subject value.
STORE {key, {("subject", <info:rdfpeers>), ("predicate", <dc:creator>), ("object", <info:mincai>)}} where key=SHA1Hash("<info:rdfpeers>") This triple will be stored at the node which is the successor node of key.
Figure 2 shows how the three triples above are stored into an example RDFPeers network.
It also shows the  nger tables of example nodes N 6 and N 14 for illustration.
Figure 2: Storing three triples into an RDFPeers network of eight nodes in an example 4-bit identi er space that could hold up to 16 nodes.
(In reality a much larger identi er space is used, such as 128 bits.)
Since nodes might fail and network connections might break, the triples stored on its corresponding successor nodes are replicated on its neighbors in Chord identi er space.
This can be done by setting the parameter Replica Factor in MAAN.
Whenever a node receives a triple storing request, it will not only store the triple locally but also store it to as many of its immediate successors as the above parameter dictates.
If any node fails or its connection breaks, its immediate successor and predecessor will detect it by checking the KEEPALIVE messages.
If the node does not come back to life after a timeout period, nodes will repair the ring structure using the
 successor node of the failed node will restore its replicas to its new predecessor.
Based on the above triple-storing scheme, we de ne a set of native queries which can be ef ciently resolved via MAAN s multi-attribute range queries.
These native queries include atomic triple patterns, disjunctive and range queries, and conjunctive multi-predi-cate queries.
An atomic query pattern is a triple pattern in which the subject, predicate, or object can each either be a variable or an exact value.
The eight resulting possible queries are shown in Table 1.
Q1 is the most general and most expensive query which matches all triples.
Since there is no restriction whatsoever on this triple pattern, we have to propagate this query to all nodes, which takes O(N ) routing hops for a network with N nodes.
We can use MAAN s routing algorithm to resolve queries Q2 through Q8 since we store each triple three times based on its subject, predicate, and object hash values.
In these seven query patterns, there is always at least one value which is a constant, and we resolve the query by routing it to the node responsible for storing that constant, that node then matches these triples against the pattern locally and returns them to the requesting node.1 For example, in Figure 2 if node N 6 asks the native query (<info:mincai>, <foaf:name>, ?name), we hash on info:mincai and get the hash value  1 .
Then N 6 routes it to the corresponding node N 1 (via N 14).
N 1  lters triples locally using this pattern, and sends back the matched triple <info:mincai>, <foaf:name>,  Min Cai  to N 6 (via N 5).
No.
Query Pattern Cost

 (?s, ?p, ?o) (?s, ?p, oi) Query Semantics  nd all possible triples
 log N given object oi of any predicate,  nd the subjects and predicates of matched triples log N given predicate pi,  nd the subjects and objects of the triples having this predicate log N given object oi of predicate pi,  nd the subjects of matched triples log N given subject si,  nd all predicates and objects of the resource identi ed by si log N given subject si,  nd its predicate which has object oi
 (?s, pi, ?o)
 (?s, pi, oi)
 (si, ?p, ?o) (si, ?p, oi)


 (si, pi, ?o) log N given subject si,  nd its object (si, pi, oi) log N return this triple if it exists otherwise return nothing of predicate pi Table 1: The eight possible atomic triple queries for exact matches.
The cost is measured in the number of routing hops needed to resolve each query.
which case we would have to use O(n) messages, see Section 7.2.
RDFPeers  native queries support constraints on variables in the triple patterns.
Q9 extends the above atomic queries with a constraint list which limits the domain of variables.
::= TriplePattern  AND  ConstraintList

 TriplePattern ConstraintList ::= OrExpression ( &&  OrExpression)* OrExpression Expression ::= Expression ( ||  Expression)* ::= Variable (NumericExpression NumericExpression ::=( > | < | = | != | <= | >= ) | StringExpression)+ NumericLiteral StringExpression ::= ( = | != )Literal Literal ::= PlainLiteral|URI|NumericLiteral Variables can be either string-valued or numeric.
Constraints can limit the domain of string values by enumerating a set of either allowed or forbidden constants.
Numeric variables can additionally be limited to a set of disjunctive ranges.
(a) (?s, dc:creator, ?c) AND ?c= Tom  || ?c= John  (b) (?s, foaf:age, ?age) AND ?age > 10 && ?age < 20 for variable ?x and ?x   Sd As discussed in Section 3, MAAN can ef ciently resolve range queries by using locality preserving hashing.2 In addition to specifying a single range, Q9 can also specify a set of disjunctive ranges for attribute values.
For example, a user can submit a range query i=1[li, ui].
Obviously, this kind of disjunctive range query could simply be resolved by issuing one query for each contiguous range and by then computing the union of the results.
For a query with d disjunctive ranges, this takes d  O(log N + N   s), where s is the aggregate selectivity of the d ranges.
So the number of hops in the worst case increases linearly with d and is not bounded by N. We can optimize this by using a range ordering algorithm which sorts these disjunctive query ranges in ascending order.
Given a list of disjunctive ranges in ascending order, [li, ui], 1   i   d where li   lj and ui   uj iff i   j, the query request will be  rst routed to node nl1, the successor node of H(l1) which is the key corresponding to the lower bound of the  rst range.
Node nl1 then sequentially forwards the query to the successor node of the upper bound H(u1) if it itself is not the successor node of H(u1).
Then node nu1 uses successor routing to forward the query to node nl2, the successor node corresponding to the lower bound of the next range [l2, u2], which in turn forwards the query to the successor node of H(u2).
This process will be repeated until the query reaches the successor node of H(ud).
This optimized algorithm exploits the locality of numeric MAAN data on the Chord ring and the ascending order of the ranges, reduces the number of routing hops, especially for cases where d is large, and bounds the routing hops to N. Disjunctive exact-match queries such as ?c   {T om, John} present a special case of the above disjunctive range queries where both the lower bound and upper bound of the range are equal to the exact-match value, and we use the same algorithm to resolve them.
In addition to atomic triple patterns and disjunctive range queries, RDFPeers handles conjunctive multi-predicate queries which describe a non-leaf node in the RDF graph by specifying a list of edges for this node.
They are expressed as a conjunction of atomic
 upfront RDF Schema information: if say an Integer-valued object of some triples in reality only ever has values 1 through 10, RDF-Peers can use a hash function that yields better load balancing for these triples.
653triple patterns or disjunctive range queries for the same subject vari- able.
Q10 consists of a conjunction of sub-queries where all subject variables must be the same.
TriplePatterns := (Q3|Q4|Q9)+ := TriplePatterns  AND  ConstraintList native RDFPeers queries above; however, we have not yet written such a translator and it may be inef cient for some queries, especially for joins.
This section informally describes how the example RDQL queries from the Jena tutorial (http://www.hpl.hp.com-/semweb/doc/tutorial/RDQL) would be resolved.
In Q10, we restrict the sub-query Q9 to be the Q3-style triple pattern with constraints on the object variable.
Thus Q10 describes a subject variable with a list of restricting predicate, object or predicate, object-range pairs.
(?x, <rdf:type>, <foaf:Person>) (?x, <foaf:name>, "John") (?x, <foaf:age>, ?age) AND ?age > 35 To ef ciently resolve these conjunctive multi-predicate queries, we use a recursive query resolution algorithm which searches candidate subjects on each predicate recursively and intersects the candidate subjects inside the network, before returning the search results to the query originator.
The search request takes the parameters q, R, C, and I, where q is the currently active sub-query, R is a list of remaining sub-queries, C is a set of candidate subjects matching current active sub-query, and I is a set of intersected subjects matching all resolved sub-queries.
Initially, q is the  rst sub-query in this multi-predicate query, R contains all sub-queries except q, C is empty and I is the whole set.
Suppose the sub-query q for predicate pi is vli   oi   vui, where vli and vui are the lower bound and upper bound of the query range for the object variable oi, respectively.
When node n wants to issue a search request, it  rst routes the request to node nli = successor(H(vli)).
The node nli receives the request, searches its local triples corresponding to predicate pi, appends the subjects matching sub-query q to C, forwards this request to its immediate successor nsi unless it is already the successor(H(vui)).
Node nsi repeats this process until the search request reaches node nui = successor(H(vui)).
When node nui receives the request, it also searches locally for the subjects matching sub-query q and appends them to C. It then intersects set I with set C, and pops the  rst sub-query in R to q.
If R or I is empty, it sends the query response back with the subjects in I as the result; otherwise, it resolves sub-query q.
This process will be repeated until no sub-queries remain or I is empty.
This recursive algorithm takes O( (log N + N   si)) routing hops in the worst case, where k is the number of sub-queries and si is the selectivity of the sub-query on predicate pi.
However, it intersects the search results on different predicates in the network and will terminate the search process before resolving the query on all predicates if there are no matches left, i.e.
I is empty.
Thus, we can further reduce the average number of expected routing hops by sorting the sub-queries in ascending order of selectivity presuming the selectivity can be estimated in advance.
For example, in the above three-predicate query, the sub-query on rdf:type might match many subjects, while foaf:age matches far fewer and foaf:name matches only a handful.
After sorting the sub-queries, we resolve foaf:name  rst, then rdf:age, and  nally rdf:type.
kP i=1

 RDQL [10] is a query language for RDF proposed by the developers of the popular Jena Java RDF toolkit [8].
RDQL operates at the RDF triple level, without taking RDF Schema information into account (like RQL [7] does) and without providing inferencing capabilities.
As such, it is the type of low-level RDF query language that we want RDFPeers to support well.
It is our intuition that it is possible to translate all RDQL queries into combinations of the (1) SELECT ?x WHERE (2) SELECT ?x, ?fname WHERE (3) SELECT ?givenName (?x, <vcard:FN>, "John Smith") (?x, <vcard:FN>, ?fname)
 (?y, <vcard:Family>, "Smith"), (?y, <vcard:Given>, ?givenName) (4) SELECT ?resource WHERE (?resource, <inf:age>, ?age) AND ?age>=24 (5) SELECT ?resource, ?givenName WHERE (?resource, <vcard:N>, ?z), (?z, <vcard:Given>, ?givenName) (6) SELECT ?resource, ?familyName WHERE (?resource, <inf:age>, ?age), (?resource, <vcard:N>, ?y), (?y, <vcard:Family>, ?familyName) AND ?age>=24 Query (1) translates directly into Q4, so that it can be resolved in log N routing hops in a network of N nodes.
Similarly, query (2) translates directly into Q3, taking log N hops.
To resolve query (3) , we  rst issue a Q4-style query and then use its query result as constraint to issue a Q9-style disjunctive query with Q3-style triple patterns.
Since all the predicate values in the two triple patterns are known, these two native queries can be resolved in 2  log N hops.
Query (4) is a typical Q9-style range query with the constraint on the object value.
Since its predicate value is known, we can route the query to the node which stores the triples with predicate inf:age in log N hops.
Our native queries do not include join operations, so that we decompose join queries into multiple native queries.
Query (5) can be resolved via two Q3-style queries, and by then joining the  rst triple set s object with the second triple s subject, 2 log N routing hops.
(However, note that these two Q3-style queries might generate large-size messages if the predicates vcard:N or vcard:Given are popular.).
Query (6) can be resolved by  rst issuing the same query as for the previous RDQL example for the  rst triple pattern.
Then we use the query result as a constraint for variable ?resource and resolve the second triple pattern as a Q9-style disjunctive range query.
Finally, we use the second query result as a constraint for variable ?y and again resolve the third triple as a Q9-style query, which in the aggregate takes 3   log N hops.
We implemented the MAAN layer of RDFPeers in Java and measured its performance on a real-world network of up to 128 nodes in a previous paper [4].
We also measured the number of neighbors per node against the network size.
Similar to Chord, the number of neighbors at each node increases logarithmically with the network size, so that the node state in MAAN scales well to a large number of nodes; for example, in a hypothetical network of eight billion nodes (one for each human on Earth) each node would maintain just thirty-three IP connections.
We measured the number of routing hops against the network size for both exact-match queries and for range queries.
The experiment results show that for exact-match queries, the number of routing hops in the worst case is O(log N ) and the average routing hops is log N/2.
However, for range queries whose selectivity si >  %, meaning that they select more than one node, the routing hops increase linearly with network size.
This is optimal in the sense that si of total N nodes have to be visited by the search queries presuming we want to evenly balance the load to the nodes.
We implemented an RDF/XML triple loader based on the Jena Toolkit 2.0 to measure the number of routing hops in a simulation (measuring the query cost); we also studied the number
 simulator (measuring the storage cost).
The number of routing hops taken to resolve a query is the dominant performance metric for P2P systems.
Figure 3 shows our simulation result for atomic triple patterns from 1 node to 8192 nodes on a logarithmic scale, which matches our theoretical analysis.
Figure 3: The number of routing hops to resolve atomic triple patterns Q2 through Q8.
We also compared two disjunctive range query resolution algorithms: the simple algorithm vs. range ordering algorithm.
Figure 4 shows the simulation result for up to 1000 disjunctive exact-match values (si =  %) in a network with 1000 nodes.
Figure 5: The number of routing hops to resolve disjunctive range queries (0.1% selectivity) in a network with 1000 nodes.
Literals in the RDF dump of the  Kids and Teens  catalog of the Open Directory Project (http://rdf.dmoz.org).
There are two RDF  les for this catalog: kt-structure.rdf.u8.gz and kt-content.rdf.u8.gz.
The former describes the tree structure of this catalog and contains
 contains 123,222 triples.
Figure 6 shows that only 10 to 20 URIs and literals (less than 0.1%) occur more than a thousand times.
Figure 4: The number of routing hops to resolve disjunctive exact-match queries in a network with 1000 nodes.
Figure 5 shows the result for up to 1000 disjunctive ranges with
 periments, we can see that the range ordering algorithm takes less routing hops to resolve a range query than the simple algorithm, and that its routing hops are indeed bounded by N.
Literals Even today s cheapest PCs have a surprising storage capacity, each can store well over ten million RDF triples by dedicating
 triples in RDF such as those with the predicate rdf:type may occur so frequently that it becomes impossible for any single node in the network to store all of them.
That is, in practice, triples may not hash around the Chord identi er circle uniformly due to the nonuniform frequency count distribution of URIs and literals.
Figure 6 shows the frequency count distribution of the URIs and Figure 6: The frequency count distribution of URIs and literals in the ODP Kids and Teens catalog.
Table 2 lists the URIs and literals which occur more than 1000 times in kt-structure.rdf.u8.gz.
For example, since each URI as a predicate value will be stored at only one node, this node has the global knowledge about the frequency count of this predicate value.
We deal with predicate values that become overly popular by simply no longer indexing triples on them.
Each node de nes a Popular Threshold parameter based on its local capacity and willingness (subject to some minimum community expectation).
Each node keeps counting the frequency of each predicate value.
If a predicate value occurs more than Popular Threshold times, the node will refuse to store it and internally makes a note of that.
If the node receives a search request with the overly popular value for the predicate, it sends a refusal message back to the requesting node and the requesting node must then  nd an alternative way of resolving the query by navigating to the target triples though either the subject or object values.
This approach will add O(logN ) to that node s total query cost in hops.
We limit subject and object values in the same way.
We are aware that this still makes the node with popular URIs a hotspot for query messages which can be addressed by querying nodes caching which queries were refused in
 instances in the world are the subclass of some class .
However, these queries are so general and would return so many triples that we suspect they would rarely be of use in practice anyway (in analogy to the English language, where the words  a  and  the  occur frequently but provide little value as search terms).
For the above query, you could alternatively gather the class URIs for which you want to look for instances for, then traverse to the instances via that set of URIs by issuing a Q4-style query.
Frequency URI or literal







 rdf:type dc:Title http://dmoz.org/rdf/Topic http://dmoz.org/rdf/catid http://dmoz.org/rdf/lastUpdate http://dmoz.org/rdf/narrow http://dmoz.org/rdf/altlang dc:Description Type predicate object object predicate predicate predicate predicate object Table 2: URIs and literals that occur more than one thousand times in kt-structure.rdf.u8.gz Figure 7 shows the minimum, average, and maximum number of triples per node with Popular Threshold from 500 to 32,000.
In this experiment, we store both ktstructure.rdf.u8.gz and ktcontent.rdf.-u8.gz (total 142,772 triples) into a network of 100 physical nodes (and the standard Chord log(100)=6 virtual nodes per physical node for trading off load balancing against routing hops).
When Popular Threshold=32,000, there are no overly popular URIs or literals being removed and there is an average of 4303 triples per node.
However, the load is unevenly balanced   the minimum number of triples per node is 700 while the maximum number of triples per node is 36,871.
When Popular Threshold is set to 500, there are
 and there are an average of 2352 triples per node.
The minimum number of triples per node is 688 while the maximum number of triples per node is reduced to 4900   which we believe at less than an order of magnitude difference is acceptable load balancing.
Although limiting overly popular URIs and literals greatly reduces the difference between the maximum and minimum number of triples per node, the triples are still not uniformly distributed around all nodes.
This is because the frequency count distribution of non-popular URIs and literals remains nonuniform even after removing overly popular values.
We propose a preliminary successor probing scheme inspired by the  probe-based  node insertion techniques of [5] to further achieve a more balanced triple storage load on each node.
In Chord, the distribution of node iden-ti ers is uniform and independent of the data distribution.
In this successor probing scheme, we use a sampling technique to generate a node identi er distribution adaptive to the data distribution.
When a node joins the network, it will use SHA1 hashing to generate Probing Factor candidate identi ers.
Then it uses Chord s successor routing algorithm to  nd the successors corresponding to these identi ers.
All the successors will return the number of triples which would be migrated to the new node if it joined there, and the new node will choose the identi er that gives it the heaviest load.
The cost of this technique is that it increases the insertion time of a triple from log N to P robing F actor   log N. It is our intuition that log N is a good setting for the probing factor.
Figure 8 shows the minimum, average and maximum number of triples per node with Probing Factor from 1 to 9 in a network with 100 physical nodes.
The Popular Threshold is set to 1000 in this experiment.
If there is no successor probing, the most loaded node has 7.2 times more triples than the least loaded node.
If each node probes 9 nodes when it joins, the node with the heaviest load only has 2.6 times more triples than the node with the lightest load   which further reduces load imbalances to much less than an order of magnitude.
We can further improve load balancing with a background virtual node migration scheme proposed in [14], subject to the limitation that it cannot distribute the load for a single overly popular value.
Figure 7: The number of triples per node as a function of the threshold of popular triples (100 physical nodes with 6 virtual nodes per physical node).
Figure 8: The number of triples per node as a function of the number of successor nodes probed (100 physical nodes, Popular Threshold=1000).
Many centralized RDF repositories have been implemented to support storing, indexing and querying RDF documents, such as RDFDB [19], Inkling [9], RDFStore [3] and Jena [8].
These centralized RDF repositories typically use in-memory or database-sup-ported processing, and  les or a relational database as the back-end RDF triple store.
RDFDB supports a SQL-like query language, while Inkling, RDFStore and Jena all support SquishQL-style RDF query languages.
Centralized RDF repositories are very fast and can scale up to many millions of triples.
However, they have the same limitations as other centralized approaches, such as a single processing bottleneck and a single point of failure.
Edutella [12] and its successor super-peer-based RDF P2P network [13] were discussed in Section 1.
Super-peers are often desirable in order to place the load unevenly among heterogeneous nodes, but our 656scheme can achieve the same effect more  exibly by nodes host ing more or fewer Chord virtual nodes according to their capacity.
Recent structured P2P systems use message routing instead of  ooding by leveraging a structured overlay network among peers.
These systems typically support distributed hash table (DHT) functionality and offer the operation lookup (key), which returns the identity of the node storing the object with the key [16].
Current proposed DHT systems include Tapestry [23], Pastry [18], Chord [22], CAN [15], and Koorde [6].
In these DHT systems, objects are associated with a key which can be produced by hashing the object name.
Nodes have identi ers which share the same space as the keys.
Each node is responsible for storing a range of keys and corresponding objects.
The DHT nodes maintain an overlay network with each node having several other nodes as neighbors.
When a lookup (key) request is issued from one node, the lookup message is routed through the overlay network to the node responsible for the key.
Different DHT systems construct different overlay networks and employ different routing algorithms.
They can guarantee to  nish lookup in O(log N ) or O(dN 1/d) hops and each node only maintains the information of O(log N ) or d neighbors for a N nodes network where d is the dimension of the hypercube organization of the network.
Therefore, they provide very good scal-ability as well as failure resilience.
However, these DHT systems only provide single key based lookup and do not ef ciently support multi-attribute and range queries, nor do they provide RDFPeers  triple storage load balancing.
We would like to perform further experiments measuring cost in terms of message sizes rather than just in the routing hops that are the customary P2P performance metric, and to implement the RDQL-to-RDFPeers-Native-Queries translator that we have only sketched in this paper.
We would like to be able to bound the size of initital query results, so that e.g.
only the  rst one-hundred matches are returned with the note  there are roughly 4,000 more matches, would you like to retrieve them? .
We have not yet implemented triple deletions in RDFPeers, only triple insertions.
We would also like to improve load balancing using a background virtual node migration scheme, and to add (binary and other non-meta-) data storage support on top of RDFPeers.
In conclusion, RDFPeers advances the state of the art of P2P RDF systems by guaranteeing that query results will be found if they exist, by not requiring upfront schema de nition, by not relying on super-peers, and by balancing the triple-storing load between the most and least loaded nodes.
Its storage cost in neighborhood connections is logarithmic to the number of nodes in the network, and so is its processing cost in routing hops for all insertion and most query operations, thus enabling distributed RDF repositories of truly large numbers of participants.
The successor probing technique of Section 7.3 was inspired by discussions with Shahram Ghandeharizadeh and Antonios Daskos about load balancing techniques.
We gratefully acknowledge feedback from the anonymous reviewers, Stefan Decker, and Geoff Pike, and AFOSR funding under grant F49620-01-1-0341.
