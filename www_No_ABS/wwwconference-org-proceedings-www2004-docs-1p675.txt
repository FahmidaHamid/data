It has become increasingly dif cult for users to  nd information on the WWW that satis es their individual needs since information resources on the WWW continue to grow.
Under these circumstances, Web search engines help users  nd useful information on the WWW.
However, when the same query is submitted by different users, most search engines return the same results regardless of who submits the query.
In general, each user has different information needs for his/her query.
For example, for the query  Java,  some users may be interested in documents dealing with the programming language,  Java,  while other users may want documents (cid:3)He is currently working for HITACHI, Ltd., Software Division.
Copyright is held by the author/owner(s).
related to  coffee.  Therefore, Web search results should adapt to users with different information needs.
In order to predict such information needs, there are several approaches applying data mining techniques to extract usage patterns from Web logs [40, 8, 11,
 is not suf cient for performing the personalization tasks.
Furthermore, Shahabi and Chen [37] have pointed out that the item association generated from Web server logs might be wrong because Web usage data from the server side are not reliable.
Therefore, these techniques are not so appropriate for Web personalization.
Another novel information systems designed to realize such adaptive systems have been proposed that personalize information or provide more relevant information for users.
As far as we know, three types of Web search systems provide such information: (1) systems using relevance feedback [10], (2) systems in which users register their interest or demographic information, and (3) systems that recommend information based on users  ratings.
In these systems, users have to register personal information such as their interests, age, and so on, beforehand, or users have to provide feedback on relevant or irrelevant judgements, ratings on a scale from 1 (very bad) to 5 (very good), and so on.
These types of registration, feedback, or ratings can become time consuming and users prefer easier methods.
Therefore, in this paper, we propose several approaches that can be used to adapt search results according to each user s information need.
We then compare the retrieval accuracy of our proposed approaches.
Compared with our prior works [41, 44], we scrutinize user s browsing history in one day closely and it allows each user to perform more  ne-grained search by capturing changes of each user s preferences without any user effort.
Such a method is not performed in typical search engines.
This paper is organized as follows: In Section 2, we review related work focusing on personalized search systems.
In Section 3, we propose novel approaches to providing relevant information that satis es each user s information need by capturing changes in user s preferences without user s effort.
In Section 4, we present the experimental results for evaluating our proposed approaches.
Finally, we conclude the paper with a summary and directions for future work in Section 5.
As described in Section 1, there are several types of search systems that provide users with information more relevant to their individual needs.
For example, we review hyperlink-based personalized Web search, personalized Web sites, and recommender systems.
The  eld of Web information retrieval focuses on hyperlink structures of the Web, for example with Web search engines such as Google1 [6] and the CLEVER project [18].
To address several problems with these engines, i.e., (1) the weight for a Web page is merely de ned, and (2) the relativity of contents among hyperlinked Web pages is not considered, we proposed several approaches to re ning the TF-IDF scheme for Web pages using their hyperlinked neighboring pages [42, 43].
In personalized Web searches, the hyperlink structures of the Web are also becoming important.
The use of personalized PageRank to enable personalized Web searches was  rst proposed in [32], where it was suggested as a modi cation of the global PageRank algorithm, which computes a universal notion of importance of a Web page.
The computation of (personalized) PageRank scores was not addressed beyond the original algorithm.
Haveliwala [13] used personalized PageRank scores to enable  topic sensitive  Web searches.
Experiments in this work concluded that the use of personalized PageRank scores can improve a Web search.
However, no experiments based on a user s context such as browsing patterns, bookmarks, and so on were conducted.
Therefore, it is not clear if search results obtained using this approach actually satisfy information needs that is different user by user.
In addition, the number of hub vectors used was limited to 16 due to the computational requirements.
In order to address this problem, Jeh and Widom [20] proposed an approach that can scale well with the large size of hub vectors to realize personalized Web searches.
On the other hand, Chang et al. [7] proposed algorithms for creating  personally customized authority documents  to correspond more closely to the user s internal model following the conventions of Kleinberg s HITS algorithm [23].
Link topology and the structure and contents of Web pages are often used in the construction of a personalized Web site.
In this section, we review the framework of these systems with regard to  Link Personalization,  and  Content Personalization. 
 This scheme involves selecting the links that are more relevant to the user and changing the original navigation space by reducing or improving the relationships between Web pages.
E-commerce applications use link personalization to recommend items based on the buying history of clients or some categorization of clients based on ratings and opinions.
Users who give similar ratings to similar objects are presumed to have similar preferences, so when a user seeks recommendations about a certain product, the site suggests those recommendations that are most popular for his/her class or those that best correlate with the given product for that class.
At the E-commerce site for Amazon.com2, this approach has been taken to an extreme by constructing a  New for you  home page and presenting it to each user, with new products that the user may be interested in.
Additionally, Amazon.com uses implicit recommendations via purchase history and/or explicit recommendations via  rate it  features to generate recommendations of products to purchase.
In a recent study, Tsandilas and Schraefel [46] proposed a system that automatically adapts links in the browsed pages based on their relevance to the weighted topics speci ed by sliders that users can manipulate.
In general, content personalization is done when pages present different information to different users.
The difference between this and  Link Personalization  described in Section 2.2.1 is subtle because part of the contents (i.e., the link anchors) presents different information when links are personalized.
However, content personalization is referred to when substantial information in a Web page is personalized, unlike link anchors.
For example, Bharat et al. [4] presented  Krakatoa Chronicle , an interactive personalized newspaper on the WWW that allows for interactive personalization, browsing and layout control.
Moreover, My Yahoo!3 [28] or My Netscape4  lters the information that is relevant to the user, showing only sections and details in which the user may be interested.
The user may explicitly indicate his/her preferences, or preferences may be inferred (semi) automatically from his/her pro le or from his/her navigation activity.
At these sites, users choose a set of  modules  from a large set including weather, news, music and so on, and further personalize these modules by choosing a set of attributes of the module to be perceived.
The approach followed in these applications is that the users should be able to  construct  their own pages and even the layout may be customized.
However, users have to input their preferences or demographic information based on the prior questionnaire.
Systems related to personalization on the Web seems to be mainly based on text retrieval.
However, personalized systems in the  eld of multimedia are also being developed [16, 30, 25, 39, 9, 17].
These systems also require explicit users  inputs to obtain relevant information.
In summary, the aforementioned systems have two problems: (1) the users  loads become high because these systems heavily rely on the users  inputs; (2) these sites cannot adapt to the changes in users  preferences unless the users change their previously registered preferences by themselves.
It has become increasingly dif cult to search for useful information on the Web because the amount of information on the Web continues to grow.
Therefore, we get the feeling of being overwhelmed by the number of choices.
This situation is often referred to as  information overload.  As one of the most promising approaches to alleviate this overload, recommender systems have emerged in domains such as E-commerce, digital libraries, and knowledge management.
These systems provide personalized suggestions based on user preferences.
Recommender systems collect user feedback in the form of ratings for items in a given domain and exploit similarities and differences among pro les of several users in determining how to recommend an item.
There are two prevalent approaches to constructing recommender systems   collaborative  ltering-based and content-based recommendation.
Collaborative  ltering-based recommendation is the most successful recommendation technique to date.
The term collaborative  ltering was coined by Goldberg et al. [12].
Collaborative  ltering means that people collaborate to help one another perform  ltering by recording their reactions to documents they read.
Based on this concept, Goldberg et al. developed a system called Tapestry that is one of the earliest implementations of collaborative  ltering-based recommendation.
This system is used to  lter email and it allows users to annotate messages.
The collaborative  ltering provided by Tapestry was not automated, and users were required to formulate 1http://www.google.com/ 2http://www.amazon.com/ 3http://www.my.yahoo.com/ 4http://my.netscape.com/ 676complex queries in a special query language designed for the task.
In addition, this system relied on explicit opinions of people from a close-knit community, such as a group of of ce workers.
However, recommender systems for large communities generally cannot depend on everyone knowing each other.
Therefore, the framework in Tapestry is not appropriate to systems for large communities.
Rating-based automated collaborative  ltering is quickly becoming a popular approach to reducing information overload by providing personalized recommendations for information, products or services.
For example, the k-nearest neighbor collaborative  ltering-based systems are achieving widespread success on the Web.
The GroupLens research system [33, 24], which  lters Usenet news,  rst introduced an automated collaborative  ltering system using the k-nearest neighbor-based algorithm.
In this algorithm, a subset of appropriate k users is chosen based on their similarity to the active user, and a weighted aggregate of their rating is used to generate predictions for the active user.
GroupLens then recommends Usenet news articles to these active users.
While the Tapestry and GroupLens mentioned above rely on explicit ratings, some systems rely on implicit ratings.
For example, Morita and Shinoda [31] exploit  time-spent-reading  as a measure of implicit ratings.
PHOAKS (People Helping One Another Know Stuff) [45] also uses implicit ratings to construct a recommender system by examining Usenet news postings to  nd  endorsements  of Web sites.
It then creates a listing of the top Web sites endorsed in each newsgroup.
Some recommender systems also explore user preferences transparently without any extra effort from the users like the recommender systems relying on implicit ratings described above.
For example, Letizia [26, 27] and WebWatcher [21] infer user preferences by observing user-browsing behavior.
However, the main shortcomings in Letizia and WebWatcher are that they maintain persistent and slowly-changing user models and overlook the fact that different browsing sessions by the same user or even a single session may involve different user interests and goals.
Moreover, Kelly and Teevan [22] have published a nice summary with regard to the systems using implicit measures.
In addition, at the E-commerce sites such as Amazon.com, CD-now.com and MovieFinder.com, automated collaborative  ltering systems have been used with considerable success.
Moreover, in the  eld of audio, Ringo [38] uses collaborative  ltering techniques to provide users with recommendations for music albums and artists.
A content-based approach provides recommendations by comparing representations of content contained in an item with representations of content that the user is interested in.
In this approach, a model of user ratings is  rst developed.
Algorithms in this category use probabilities and envision the collaborative  lter-ing process by computing the expected value of a user prediction given the user s ratings on other items.
The model building process is performed by three different machine learning algorithms: (1) Bayesian network [5], (2) clustering [3, 5], and (3) rule-based models [35].
The systems described in Section 2.3.1 only provide recommendations based on collaborative  ltering.
However, some systems provide better recommendations by combining collaborative  lter-ing with content information.
Fab [2] uses relevance feedback to simultaneously construct a personal  lter along with a communal  topic   lter.
Web pages are initially ranked by the topic  lter and then sent to user s personal  lters.
The user then provides relevance feedback for that Web page, and this feedback is used to modify both the personal  lter and the originating topic  lter.
Basu et al. [3] integrate content and collaboration in a framework where Query User Browsing World Wide Web Provide relevant Web pages Browsing history Select relevant Web pages Update profile User profile Web browser Figure 1: System overview.
they treat recommendation as a classi cation task.
Melville et al.
[29] overcome drawbacks of collaborative  ltering systems in their recommender system by exploiting content information of items already rated.
In recent study on recommender systems, Schafer et al. [36] introduce a new class of recommender system that provides users with personalized control over the generation of a single recommendation list formed from a combination of rich data using multiple information resources and recommendation techniques.
As we described in Section 2.1, hyperlink-based personalized search systems have a problem in that they do not clarify whether their search results actually satisfy each user s information need.
This is because personalization based on a user s context, i.e., browsing patterns, bookmarks, and so on is not performed.
The personalized Web sites described in Section 2.2 have the following shortcomings: (1) users have to rate items or adjust sliders to obtain relevant information in  Link Personalization  described in Section
 2.2.2, the load on users becomes high because they have to answer questionnaires in advance to register their personal preferences or demographic information, and they have to change their registered information by themselves if their interests change.
In addition, the recommender systems described in Section 2.3 have the potential to provide serendipitous recommendations if users are only willing to rate items.
However, in actuality, most users are unwilling to rate items even though user s ratings for items are key factors to achieving better recommendations.
As a result, the accuracy of recommendations may be poor.
We do not necessarily believe that approaches based on user ratings provide users with more relevant information that satis es each user s information need.
Therefore, search system should directly and exactly capture the changes in each user s preferences without any user effort in order to provide more relevant information for each user.
In order to construct such a system, we propose several approaches to adapting search results according to each user s information need.
Unlike the research studies described in the previous section, our approach is novel because it allows each user to perform a  ne-grained search by capturing the changes in each user s preferences without any user effort.
Figure 1 shows an overview of our system.
When a user submits a query to a search engine through a Web browser, the search engine returns search results corresponding to the query.
Based on the search results, the user may select a Web page in an attempt to satisfy his/her information need.
In addition, the user may access more Web pages by following the hyperlinks on his/her selected Web page and continue to browse.
Our system monitors the user s browsing history and updates his/her pro le whenever his/her browsing page changes.
When the user submits a query the next time, the search results adapt based on his/her user pro le.
[Ephemeral preferences]





 Browsing history of N days ago Browsing history of 2 days ago Browsing history of 1 day ago Browsing history of today (0 day ago) (1)
 (1)
 (r)
 hp(r) (r)
 (n ) bh
 (n ) bh
 1(cur) (cur)
 1st browsing history in today th r browsing history in today th n bh browsing history in today current session : Web page : Window Figure 2: User s browsing history in today and N days before today.
In the following sections, we explain how to construct a user pro le in the  update pro le  component illustrated in Figure 1.
In our approach, the user pro le is constructed implicitly.
In other words, a user does not need to perform explicit efforts such as feedback, ratings and so on in order to construct his/her pro le.
We construct each user pro le based on the following two methods: (1) Pure browsing history, and (2) Modi ed collaborative  ltering.
Browsing History In this method, we assume that the preferences of each user consist of the following two aspects: (1) persistent (or long term) preferences, and (2) ephemeral (or short term) preferences.
In persistent preferences, the user pro le is incrementally developed over time and it is stored for use in later sessions.
The information exploited for constructing the pro le usually comes from various sources, so it relies on different aspects of the user.
On the other hand, in ephemeral preferences, the information used to construct each user pro le is only gathered during the current session, and it is immediately exploited for executing some adaptive process aimed at personalizing the current interaction.
In our prior works [41, 44], user s searches and browsing activities fall into one logical session.
However, users usually do different tasks in one day and they may well do several searches and browsing activities in that time period.
Therefore, it is necessary to analyze user s browsing behavior in one day in more detail.
In our methods, we assume that user s preferences are constructed by accumulating his/her past consider-per, and ephemeral preferences, per shows a user pro le constructed exploiting the user s browsing history of Web page from N days ago.
Figure 2 illustrates the user s browsing history in today and N days before today.
Here, we introduce the concept of window size in order to construct per, and de ne Sj (j = 0; 1; 2; (cid:1) (cid:1) (cid:1) ; N ) as the number of Web pages the user browsed on the j th day.
 j = 0  means  today  as shown in Figure 2.
In this  gure, we consider that users perform nbh different searches before the current session cur in today.
In other words, the curth session, that is the newest session in today, is subsequent to the nbh th session.
Therefore, the relation between nbh and cur is de ned by the following equation: preferences.
Therefore, we construct each user pro le   ing both persistent preferences,   today.
  cur = nbh + 1: cess.
At  rst, we denote the feature vector today is constructed through the following pro-hp(r) of browsed Web In each day,   page hp(r) (hp = 1; 2; (cid:1) (cid:1) (cid:1) ; S0) in the rth (r = 1; 2; (cid:1) (cid:1) (cid:1) ; nbh) session as follows: hp(r) = (whp(r) t1 ; whp(r) t2 ; (cid:1) (cid:1) (cid:1) ; whp(r) tm ); where m is the number of distinct terms in the Web page hp(r), and tk (k = 1; 2; (cid:1) (cid:1) (cid:1) ; m) denotes each term.
Using the TF (term frequency) scheme, each element whp(r) hp(r) is de ned as follows: of tk whp(r) tk = chp(r) (cid:1) tf (tk; hp(r)) s=1 tf (ts; hp(r))  m ; (1) where tf (tk; hp(r)) is the frequency of term tk in each browsed Web page hp(r), and chp(r) is a constant that shows to what extent our system re ects the contents of the Web page on each user pro le.
We de ne constant chp(r) as follows: chp(r) = 

 (2) where dr denotes the time spent reading normalized by the number of terms in Web page hp(r), and threshold T h is set to 0.317 based on our preliminary experiments.
We then de ne partial user pro le (r) at the rth browsing history in today as follows: (r) = (p(r) t1 ; p(r) t2 ; (cid:1) (cid:1) (cid:1) ; p(r) tm ); and de ne each element p(r) tk using Equation (1) as follows: p(r) tk = =
 (r)

 (r)

 hp=1
 hp=1 whp(r) tk chp(r) (cid:1) tf (tk; hp(r)) s=1 tf (ts; hp(r))  m : (3) (br) obtained by browsing Moreover, we also de ne user pro le   history up to the current session as follows: (br) = (p(br) t1 ; p(br) t2 ; (cid:1) (cid:1) (cid:1) ; p(br) tm ):
            Using Equation (3), each element p(br) tk is also de ned as follows: nbh p(br) tk = p(r) tk r=1 r=1 nbh =
 (r)
 hp=1 chp(r) (cid:1) tf (tk; hp(r)) s=1 tf (ts; hp(r)) :
  m hp(cur) of browsed Web Similarly, we denote the feature vector page hp(cur) (hp = 1; 2; (cid:1) (cid:1) (cid:1) ; S0) in the current session as follows: hp(cur) = (whp(cur) t1 ; whp(cur) t2 ; (cid:1) (cid:1) (cid:1) ; whp(cur) tm ); where m is the number of distinct terms in the Web page hp(cur), and tk (k = 1; 2; (cid:1) (cid:1) (cid:1) ; m) denotes each term.
Using the TF (term frequency) scheme, each element whp(cur) hp(cur) is de ned as follows: of tk whp(cur) tk = chp(cur) (cid:1) tf (tk; hp(cur)) s=1 tf (ts; hp(cur))  m : (4) where tf (tk; hp(cur)) is the frequency of term tk in each browsed Web page hp(cur), and chp(cur) is a constant that shows to what extent our system re ects the contents of the Web page on each user pro le de ned as well as Equation (2).
Then, we de ne partial user (cur) obtained at the current session in today as follows: (cur) = (p(cur) t1 ; p(cur) t2 ; (cid:1) (cid:1) (cid:1) ; p(cur) tm ); and de ne each element p(cur) tk using Equation (4) as follows: pro le   : (5) p(cur) tk = =
 (cur)

 (cur)

 hp=1
 hp=1 whp(cur) tk chp(cur) (cid:1) Using   (br) and   (cur),   today = x  (br) + y   m (cur); tf (tk; hp(cur)) s=1 tf (ts; hp(cur)) today is constructed as follows: where x and y are constants that satisfy x + y = 1.
In order to emphasize the current session, we assign larger weight to y than x.
In other words, y is larger than 0.5, and x is smaller than 0.5 under the condition, x + y = 1.
per considering persistent preferences.
In order to do that, we set the window size per is denoted as fol-Additionally, we also construct user pro le   N (N = 1; 2; (cid:1) (cid:1) (cid:1) ; 30).
The user pro le   lows: per = (pper t1 ; pper t2 ; (cid:1) (cid:1) (cid:1) ; pper tm ); and each element pper tk is de ned as follows: pper tk =


 hp=1 whp tk (cid:1) e(cid:0) log 2 hl (d(cid:0)dtk init ); (6) (7) log 2 hl (d(cid:0)dtk init ) is a forgetting factor under the assump-where e(cid:0) tion that user s preferences gradually decay as days pass.
In this factor, dtk init is the day when term tk initially occurs, d is the number of days following to dtk init, and hl is a half-life span parameter.
The half-life span hl is set to 7.
In other words, we assume that user s preferences reduce by 1/2 in one week.
We also assume that each user browsed SN pages on each day.
This value SN is Item that prediction is computed item 1 item 2 item i item I Active user user 1 user 2

 user a user U








 Figure 3: User-item ratings matrix for collaborative  ltering.
different user by user.
Therefore, we normalize pper tk using SN as today de ned by Equation (5), and per de ned by Equation (6), we  nally construct the user pro le as follows: shown in Equation (7).
Using   = a  = a  per + b  per + bx  today (br) + by  (cur); (8) (9) where a and b are constants that satisfy a + b = 1, and x and y are constants that satisfy x + y = 1 as described at Equation (5).
Modi ed Collaborative Filtering Algorithm In this section, we  rst brie y review the pure collaborative  l-tering algorithms, especially neighborhood-based algorithms, and then describe how to construct user pro les using the modi ed collaborative  ltering algorithms.
Algorithm Collaborative  ltering can be represented as the problem of predicting missing values in a user-item ratings matrix.
Figure 3 shows a simpli ed example of a user-item ratings matrix.
In the neighborhood-based algorithm [15], a subset of users is  rst chosen based on their similarity to the active user, and a weighted combination of their rating is then used to produce predictions for the active user.
The algorithm we use can be summarized in the following steps:
 This similarity between users is measured as the Pearson correlation coef cient between their rating vectors.
user.
These users form the neighborhood.
neighbor s ratings.
In step 1, Sa;u, which denotes similarity between users a and u, is computed using the Pearson correlation coef cient de ned below: Sa;u =

 i=1(ra;i (cid:0) (cid:22)ra) (cid:2) (ru;i (cid:0) (cid:22)ru) i=1(ra;i (cid:0) (cid:22)ra)2 (cid:2) 
 i=1(ru;i (cid:0) (cid:22)ru)2 ; (10) where ra;i is the rating given to item i by user a, and (cid:22)ra is the mean rating given by user a, and I is the total number of items.
In step 2, i.e., neighborhood-based methods, a subset of appropriate users is chosen based on their similarity to the active user, and a weighted aggregate of their ratings is used to generate predictions for the active user in the next step 3.
In step 3, predictions are computed as the weighted average of deviations from the neighbor s mean: pa;i = (cid:22)ra +  n u=1(ru;i (cid:0) (cid:22)ru) (cid:2) Sa;u n u=1 Sa;u ;
                    Term weight that prediction is computed Term weight that prediction is computed term 1 term 2


 user 1 user 2 term i
 Active user user a
 term T


 term 1 term 2


 user 1 user 2 term i
 term T

 term T+1 term T+2 term T+v

 Active user user a




 user U


 user U

 (a)
 (b)
 Figure 4: User-term weights matrix for modi ed collaborative  ltering [(a) when each user browsed k Web pages, (b) when each user browsed k + 1 Web pages].
where pa;i is the prediction for active user a for item i. Sa;u is the similarity between users a and u as described at Equation (10), and n is the number of users in the neighborhood.
laborative Filtering Algorithm In the pure collaborative  ltering algorithms described in Section
 construction of a user pro le, we can consider a user-term weights matrix like that shown in Figure 4(a).
In addition, based on the pure collaborative  ltering algorithms described in Section 3.2.1, we can apply their predictive algorithms to predict a term weight in each user pro le.
In other words, since each user pro le is computed based on term weights in a Web page the user browsed and the browsed pages are different according to each user, the pro le is constructed in the form of a user-term weights matrix with missing values, as illustrated in Figure 4.
This is very analogous to the user-item ratings matrix used in the pure collaborative  ltering algorithms.
Therefore, we expect that a more accurate user pro le is constructed since these missing values are predicted using the algorithms in collaborative  ltering.
In this approach, we propose the following two methods: (1) user pro le construction based on the static number of users in the neighborhood, and (2) user pro le construction based on dynamic number of users in the neighborhood.
(1) User Pro le Construction Based on the Static Number of Users in the Neighborhood In this method, our proposed algorithms are explained in the following steps (note the similarity to the collaborative  ltering algorithms described in Section 3.2.1):
 This similarity between users is measured as the Pearson correlation coef cient between their term weight vectors unlike the rating vectors described in Section 3.2.1.
user.
These users form the neighborhood.
and (cid:22)wa is the mean term weight regarding user a, and T is the total number of terms.
In step 2, i.e., neighborhood-based methods, a subset of appropriate users is chosen based on their similarity to the active user, and a weighted aggregate of their term weights is used to generate predictions for the active user in the coming step 3.
In this step, the number of selected users is  xed to n for any user.
That is why we call this method  static.  In step 3, predictions are computed as the weighted average of deviations from the neighbor s mean: pa;i = (cid:22)wa +  n u=1(wu;i (cid:0) (cid:22)wu) (cid:2) Sa;u n u=1 Sa;u ; where pa;i is the prediction for the active user a for weight of term i, Sa;u is the similarity between users a and u as described at Equation (11), and n is the number of users in the neighborhood.
(2) User Pro le Construction Based on Dynamic Number of Users in the Neighborhood In this method, our proposed algorithms are explained in the following steps (note the similarity to the collaborative  ltering algorithms described in Section 3.2.1, and aforementioned static ap-proach):
 bor algorithms [19].
The similarity between user a and these clusters is measured as the Pearson correlation coef cient between their term weight vectors.
than the threshold.
We consider the centroid vectors of these selected clusters as the neighborhood of the active user.
term weights using centroid vectors of clusters.
In step 1, Sa;g, which denotes similarity between users a and centroid vectors of clusters g, is computed using the Pearson correlation coef cient, de ned below:
 Sa;g = neighbor s term weights In step 1, Sa;u, which denotes similarity between users a and u, is computed using the Pearson correlation coef cient, de ned below: Sa;u =

 i=1(wa;i (cid:0) (cid:22)wa) (cid:2) (wu;i (cid:0) (cid:22)wu) i=1(wa;i (cid:0) (cid:22)wa)2 (cid:2) 
 i=1(wu;i (cid:0) (cid:22)wu)2 ; (11) where wa;i is the weight of term i regarding user a computed based on term frequency in a browsed Web page de ned by Equation (4),
 i=1(wa;i (cid:0) (cid:22)wa) (cid:2) (wg;i (cid:0) (cid:22)wg) ; (12)
 i=1(wa;i (cid:0) (cid:22)wa)2 (cid:2) 
 i=1(wg;i (cid:0) (cid:22)wg)2 where wa;i is the weight of term i regarding user a computed based on term frequency in a browsed Web page de ned by Equation (4), and (cid:22)wa is the mean term weight regarding user a, and T is the total number of terms.
In step 2, several clusters are chosen based on their similarity to the active user, and a weighted aggregate of their term weights is used to generate predictions for the active user in the next step
 user.
That is why we call this method  dynamic.  Therefore, it is
         expected that this method allows each user to perform more  ne-grained search.
In step 3, predictions are computed as the weighted average of deviations from the neighbor s mean: pa;i = (cid:22)wa +  n g=1(wg;i (cid:0) (cid:22)wg) (cid:2) Sa;g n g=1 Sa;g ; where pa;i is the prediction for the active user a for term weights i, Sa;g is the similarity between users a and centroid vectors of clusters g as described at Equation (12), and n is the number of centroid vectors of clusters in the neighborhood.
We conducted experiments in order to verify the effectiveness of the three approaches: (1) relevance feedback and implicit approaches, (2) user pro les based on pure browsing history as described in Section 3.1, and (3) user pro les based on the modi ed collaborative  ltering algorithm described in Section 3.2.
While users have to provide feedback explicitly in relevance feedback, users do not have to provide any effort in our proposed methods (2) and (3) since our system implicitly captures changes in user s preference.
The experiments were implemented using Perl on a workstation (CPU: UltraSparc-II 480MHz(cid:2) 4, Memory: 2GBytes, OS: Solaris8).
We used 50 query topics that were employed as test topics in the TREC WT10g test collection [14].
Note that we only used query topics of the test collection, and did not use the contents of the test collection.
In summary, we change the each of 50 topic descriptions into query keywords that the subjects can easily submit to the search engine Google.
After the subjects submit these queries to Google, our system reorders the search results according to each user s pro le constructed by the methods described in Section 3.
In our experiments, we observed the browsing history of 20 subjects for 30 days.
The subjects browsed 12 Web pages in one day on average.
In addition, the number of terms in user pro les accumulated during the 30 days is about 810,000.
In the following, let the hth Web page in the search results and the user pro le as , respectively.
Then, the fea-rph , is de ned by Equation (9) be rph and   ture vector of the hth Web page rph in the search results, de ned as follows: rph = (wrph t1 ; wrph t2 ; (cid:1) (cid:1) (cid:1) ; wrph tm ); where m is the number of distinct terms in the Web page rph, and tk(k = 1; 2; (cid:1) (cid:1) (cid:1) ; m) denotes each term.
We also de ne each element wrph rph based on the TF (term frequency) scheme as tk follows: of wrph tk = tf (tk; rph) s=1 tf (ts; rph) ;  m where tf (tk; rph) is the frequency of term tk in the rph.
The sim-and the feature rph is computed by rph ) between the user pro le   vector of the hth Web page in search results the following Equation.
ilarity sim(  ; ; sim(  rph ) =   j  rph (cid:1) j (cid:1) j rph j : (13) Based on the value obtained by Equation (13), the search results are adapted to each user according to his/her pro le.
These results are compared with the search results of Google [6].
We then evaluate the retrieval accuracy using R-precision [1].
We employed 30 as the value of R because users tend to take a look at the  rst 30 documents retrieved.
Relevance feedback [34] is the most popular query reformulation strategy.
In a relevance feedback process, the user is presented with a list of the retrieved documents and marks those that are relevant after examining them.
The basic idea is to reformulate the original query vector new such that it gets closer to the term-weight vector space of the relevant documents.
In our experiments, we use the Rocchio formulation de ned as follows: org into new query vector new = (cid:11) org + (cid:12) jDrj  j (cid:0) (cid:13) jDnj  j ;  j 2Dn  j 2Dr where Dr and Dn are the set of relevant and non-relevent documents as identi ed by the user among the retrieved documents, respectively, and jDrj and jDnj are the number of documents in the sets Dr and Dn, respectively.
We set (cid:11), (cid:12) and (cid:13) that are tuning constants to 1, 1 and 1, respectively.
In other words, the subjects provide both positive and negative feedbacks.
We believe that the new query vector new obtained by the user s judgement, whether the retrieved documents are relevant or new as not, re ects the user s preferences.
Therefore, we treat new as an initial preference of a user to construct a user pro le.
In this case, using (cur) de ned by Equation (9), and employ Equation (9), the user pro le   per + bx    = a  is de ned as follows: (br) + by new : (14) and constructed user pro le   We asked each subject to judge if the top 30 search results returned by Google according to the query keywords are relevant or not, based on Equation (14).
In this experiment, we varied the number of feedbacks F B that each subject provided from 1 to 3.
Figures 5 to 7 show the R-precision when the values of a and b are varied such that these values satisfy a + b = 1 under the condition that the numbers of feedbacks for the top 30 search results are 1, 2, and 3.
In this approach, each user pro le is constructed as mentioned in Section 3.1.
The user pro le   per + bx    = a  is de ned as follows: (br) + by  (cur): Figure 8 shows the R-precision when the values of a and b are varied such that these values satisfy a + b = 1.
Filtering In this approach, when the user browses a new Web page, new terms are added to his/her user pro le.
However, other users do not always browse the same pages, so missing values occur in the user-term weights matrix as illustrated in Figure 4.
These missing values are predicted using the algorithms described in Section
 vector re ects the user s preferences.
Let this user-term vector with (cur) de ned by predicted value be Equation (9), and employ pre as an initial preference of a user to construct a user pro le.
In this case, using Equation (9), the user pre as   pre.
We treat pro le   is de ned as follows:   = a  per + bx  (br) + by pre: (15) Figures 9 to 12 show the R-precision of static approaches when the values of a and b are varied such that these values satisfy a + b = 1
                                 ) % i i ( n o s c e r p -







 x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.147, y=0.853   a=0.619, b=0.381   Google  ) % i i ( n o s c e r p -






Window size (days)






  x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.145, y=0.855   a=0.611, b=0.389   Google 





 Window size (days) Figure 5: R-precision obtained using relevance feedback-based user pro le (F B = 1).
Figure 7: R-precision obtained using relevance feedback-based user pro le (F B = 3).
) % i i ( n o s c e r p -







 x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.142, y=0.858   a=0.604, b=0.396   Google  ) % ( i i n o s c e r p -






Window size (days)






  x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.148, y=0.852   a=0.617, b=0.383   Google 





 Window size (days) Figure 6: R-precision obtained using relevance feedback-based user pro le (F B = 2).
Figure 8: R-precision obtained using pure browsing history-based user pro le.
under the condition that the numbers of neighbors n are 5, 10, 15, and 20, respectively.
In addition, Figure 13 shows the R-precision of dynamic approaches.
In this section, we discuss the results obtained using each approach discussed in Section 4.2.
Note that, in Figures 5 to 13, the R-precision of Google is constant because it does not depend on the window size.
In these  gures, we compare the following two cases: (1) where user s browsing activities fall into one logical session [44]; and (2) where user s browsing activities in one day are analyzed in more detail.
The precisions in the former case are obtained when each user pro le is constructed by Equation (8) based on the values of a and b.
On the other hand, the precisions in the latter case are obtained when each user pro le is constructed by Equation (9) based on the values of a and b that bring the best result in the former case, and the values of x and y.
In the relevance feedback-based user pro le shown in Figures 5 to 7, we found that a user pro le that provides search results adaptive to a user can be constructed when a window size with about 18 days is used regardless of the number of feedbacks.
As mentioned in Section 4.2.1, we used query vector reformulated by relevance feedback as an initial preference of a user.
However, we could not observed signi cant improvement in precision even if the number of feedbacks increases.
We consider that this effect is caused because the initial preference of a user is absorbed by persistent preferences constructed using the window size.
In addition, it is valid that we conducted experiments by examining the number of feed-backs from 1 to 3 since the precision is not improved largely in this range.
In the user pro le based on pure browsing history shown in Figure 8, we found that a user pro le that provides search results adaptive to a user can be constructed when a window size with about 15 days is used.
This approach can achieve about 3% higher precision than the relevance feedback-based user pro le, and the result shows that the user s browsing history strongly re ects the user s preference.
In addition, in the user pro le based on modi ed collaborative  ltering shown in Figures 9 to 13, we found that a user pro le that provides search results adaptive to a user can be constructed when a window size with about 10 days is utilized.
In user pro le construction based on the static number of users in the neighborhood described in Section 3.2.2(1), the best precision is obtained in the case of n = 5 as illustrated in Figure 9; in other words, the 5 nearest neighbors of each user are taken.
Therefore, as shown in Figures 9 to 12, we found that it is not so effective to adapt search results to each user even if more nearest neighbors are used.
In addition, the user preferences of not only a certain user but also other users are exploited in this approach.
We consider that this method obtained higher precision than the aforementioned approaches.
In user pro le construction based on the dynamic number of users in the neighborhood described in Section 3.2.2(2), we could obtain the best precision in all of our experimental results in the case of x = 0:129 and y = 0:871 in Equation (15) as shown in Figure 13.
In this method, the neighborhood of each user is determined by the centroid vectors of clusters of users, and the number of the clusters is different user by user.
Therefore, we believe that this method allows each user to perform more  ne-grained search compared with static method.
The best precision of any of the methods is obtained when x is smaller than 0.2 and y is larger than 0.8 under the condition that x + y = 1 as described at Equation (5).
This shows that search results that adapt to each user can be provided by focusing on the current session than the browsing history in today.
Moreover, when
 % i i ( n o s c e r p -







 x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.153, y=0.847   a=0.622, b=0.378   Google  ) % i i ( n o s c e r p -






Window size (days)






  x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.151, y=0.849   a=0.620, b=0.380   Google 





 Window size (days) Figure 9: R-precision obtained using modi ed collaborative  ltering-based user pro le (static, n = 5).
Figure 11: R-precision obtained using modi ed collaborative  ltering-based user pro le (static, n = 15).
) % i i ( n o s c e r p -







 x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.154, y=0.846   a=0.623, b=0.377   Google  ) % i i ( n o s c e r p -






Window size (days)






  x=0.4, y=0.6   x=0.3, y=0.7   x=0.2, y=0.8   x=0.1, y=0.9   x=0.156, y=0.844   a=0.624, b=0.376   Google 





 Window size (days) Figure 10: R-precision obtained using modi ed collaborative  ltering-based user pro le (static, n = 10).
Figure 12: R-precision obtained using modi ed collaborative  ltering-based user pro le (static, n = 20).
the window size is small in this case, the large  uctuation in precision is observed.
Therefore, we found that it is necessary to use a little larger window size in order to construct the user pro le that appropriately captured user s persistent and ephemeral preferences.
Furthermore, the precision obtained by each of our proposed methods can outperform the precision obtained by Google as shown in Figures 5 to 13.
We believe that our proposed methods can perform a  ne-grained search for each user that typical search engines can not perform.
In this paper, in order to provide each user with more relevant information, we proposed several approaches to adapting search results according to each user s information need.
Our approach is novel in that it allows each user to perform a  ne-grained search, which is not performed in typical search engines, by capturing changes in each user s preferences.
We conducted experiments in order to verify the effectiveness of the approaches: (1) relevance feedback and implicit approaches, (2) user pro les based on pure browsing history, and (3) user pro les based on the modi ed collaborative  ltering.
We evaluated the retrieval accuracy of these approaches.
The user pro le constructed based on modi ed collaborative  ltering achieved the best accuracy.
This approach allows us to construct a more appropriate user pro le and perform a  ne-grained search that is better adapted to each user s preferences.
In the future, if broadband networks spread widely, information is expected to be provided in a variety of forms such as music, movies and so on.
In addition, more information will be provided for mobile terminals such as cellular phones, PDAs, or terminals in cars for Intelligent Transportation Systems (ITS).
We believe that the technique proposed in this paper can be applied to situations where users require more relevant information to satisfy their information needs.
In future work, we plan to conduct experiments with a greater number of subjects and attempt to improve our proposed approaches by using a longer term of the user s browsing history in order to achieve much more adaptive search for each user.
