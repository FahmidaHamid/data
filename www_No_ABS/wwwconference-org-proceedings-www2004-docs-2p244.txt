Augmenting a collection of digital photographs with contextual information about the images it contains is often bene cial   especially as images, like other multimedia documents, are inherently hard to index or search otherwise.
Users can utilize these contextual cues when browsing the collection.
However, it is tedious to add such context manually.
Advancements in technology have made it feasible to add location as well as time information to digital photographs, namely the exact coordinates and time where each photo was taken.
Using time and location, we can augment the photographs with additional contextual information.
We have developed [1] a system for organizing, browsing and generating metadata for geo-referenced photo collections.
Figure 1 shows all the di erent metadata facets the system automatically generates, as they appear in the opening screen of the interface.
The interface was produced using the Flamenco toolkit [2].
When browsing the collection, users can  lter the photos based on any of the metadata facets and their combination.
As shown in Figure 1, the metadata in each facet is divided into groups.
For example, the Location facet is divided into countries.
Clicking on one country will advance the user to the next screen,  ltering the collection to show pictures from the selected country.
Clicking on  Clear  in the Weather Status facet will similarly restrict the collection to photos that were taken in clear weather.
Copyright is held by the author/owner(s).
Figure 1: The system s metadata facets (Clicking on any link displays respective photos).
In Figure 1 we only see the  rst level grouping for each facet.
For some facets, further re nements of the groups are available.
For the Location facet, once users click on a country, e.g.
 United States , they are able to further re ne their  lter to, e.g.,  San Francisco .
Any combination of  lters is also possible.
Users can restrict the viewed set, for example, to photos taken in San Francisco, when the weather was clear, in near-freezing temperature (Temperature facet,  20 40  group).
The metadata we generated thus adds value to any photo collection: users have plenty of additional contextual information when they browse and search for photos.
Moreover, this value is added without any user intervention: our system utilizes the location and time data embedded in the photographs to generate all the other metadata.
In this paper we address the problem of  nding available sources for relevant and useful contextual information.
We show how we get the information from the various sources, and how we adapt it for the user interface.
All the metadata we generate is available either from o -the-shelf geographic datasets, or from various web based sources.
This section describes the metadata facets, how we generated each, and how we use them in the interface.
Location.
An o -the-shelf geographical dataset enables us 244to query with a (latitude,longitude) pair to get the con taining country, province/state, and (for the United States only) county, city (if any) and park (if any).
We can use the query results to generate a location hierarchy, for example, a Country   State   City hierarchy.
Alternatively, we can  rst group the photos into geographic clusters that are expected to make sense to users, but do not necessarily correspond to the administrative division.
Then we can assign names to these clusters using the aforementioned dataset.
In [1] we show how the latter method applies to personal photo collections.
Given an location hierarchy, users can click through and navigate, at various levels of granularity, to photos from a speci c location.
Figure 1 shows the  rst level of this hierarchy, the country level.
Clicking on any country will show the next level down the hierarchy for this country.
Time of Day.
Knowledge about the time of day a photo was shot can be used when searching for an image in a collection (e.g., one remembers a certain photo was taken late at night).
In most cases, however, users set their camera clock once, usually when they operate the camera for the  rst time.
The pitfall appears when the user travels to a di erent time zone.
Most of the users do not bother resetting their camera s clock, resulting in timestamps that inaccurately portray the time the picture was taken.
This problem can be solved given the location information where each photo was taken and the original time zone according to which the camera clock was set.
This information is su cient to compute the local time for each photo, using a geographical dataset containing the world s time zones.
The dataset can be queried by the photo coordinates, returning the correct time zone for the photo.
Given an exact, dependable local time, we can utilize it to help the user search for photos by  time of day .
Users are not likely to remember the exact hour each photo was taken.
Therefore, we group photos by the major parts of the day, as shown in Figure 1: Morning, Afternoon, Evening, etc.
Users can click any of the groups to  lter the photo collection accordingly.
Light Status.
People s perception of the time is sometimes not derived from the local time, but rather from the daylight status.
For example, people may recall a certain picture was taken when it was dark outside; around sunset; before sunrise; etc.
Given the local time and location for each photo, we can  nd how many minutes away from the sunset and sunrise each picture was taken.
The data source we use is the US Naval Observatory web service1.
The service returns sunset and sunrise times for a (year, latitude, longitude) query.
Each reply contains data for a full year, and can be reused across di erent photos in the same latitude and longitude.
As shown in Figure 1, we group photos into day, dusk ; night and dawn.
Users can click on one of these groups to  lter pictures according to the daylight status.
In our current implementation, the dusk category includes all photos taken within one hour before or after sunset; the night category includes all photos taken one hour after sunset to one hour before sunrise, and so on.
Weather Status and Temperature.
Often, people can  lter photos using weather information: they recall a certain event occurred on a stormy night (even if it was indoors), another event on a clear day, etc.
In addition, people may remember the outside temperature at the time the picture was taken ( it was freezing! ).
We use the Weather Underground2 web service to get weather information.
Historic data can be queried by a (zip-code, date) pair or a (weather station, date) pair for weather outside the United States.
We have geographic datasets that allow us to translate any (latitude, longitude) pair into a zip code or weather station.
The results of a query to the server can be used for all photos taken in the same day and same area, reducing the required number of queries.
The weather data we get for each day is an hourly report of the weather conditions (e.g.,  rainy ,  clear ) and temperature.
We annotate each photo with all weather conditions that appear between two hours before and after the photo.
The temperature is computed as the average of temperatures measured in the hours around the photo time.
In the interface, users can click on a temperature range (20 40, 40 60, etc.)
or on a speci c weather condition to limit their search for photos, as shown in Figure 1.
Additional Facets.
Other metadata facets that appear in Figure 1 are: elevation   available either from the GPS data or from an earth elevation model; season (autumn, winter, spring, summer)   by the date in which the photo was taken.
We also show the time zone (o set from GMT) as a separate category in addition to using it to compute local time.
We have implemented a web service to supply a subset of the metadata described in this paper to users.
The service can be queried by latitude and longitude, or by latitude, longitude and time.
The reply consists of place names, local time, and daylight status data.
To use this web service, contact the authors.
As of today, the service does not support weather as our current data source is a private company.
We showed some practical ways to automatically add meta-data to geo- and time-referenced photographs using web-available and o -the-shelf data sources.
This metadata serves as contextual information, when browsing and searching for photographs in a collection.
We are working on conducting user experiments to test the usefulness of the meta-data.
Additional metadata can be automatically generated using available image processing techniques, for example in-door/outdoor categorization, number of faces in the image, and prominent colors.
Finally, the metadata we describe is not speci c to photographs - it can be used for other types of geo-temporal collections, e.g.
geo-referenced news reports.
