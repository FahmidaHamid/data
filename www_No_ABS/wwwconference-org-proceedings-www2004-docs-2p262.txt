Web page indices only cover a fraction of the accessible web.
All of these resources are speci ed in terms of their Universal Resource Locator (URL), a string that speci es a protocol, a host and path to locate the resource.
Web indexers typically work by  rst retrieving a document and processing it.
This process often yields the URLs of additional documents that can be retrieved and processed in subsequent iterations.
As web resources are often hyperlinked to more than a single page, this process creates a growing list of documents to be spidered   documents whose URLs are known but which have not yet been retrieved and processed.
Work on focused crawling can partially help in addressing this bottleneck (e.g., [1]) by addressing areas that need more coverage.
Techniques that examine just the URLs can also target this bottleneck, as the source document need not be retrieved.
Often the URL itself is quite informative, as human experts can glean a large amount of information from it without needing to examine the actual contents of the resource.
An example URL shows this intuition: http://cs.cornell.edu/Info/Courses/Current/CS415/CS414.html Given categories such as course, faculty, project, and student, it is easy to guess that the page belongs to the course category.
Whereas much published work on categorization ignores the URL as a source of information, we examine how to make maximal use of this single resource.
Our system thus performs web page classi- cation using only the URL in a two-stage process.
Copyright is held by the author/owner(s).
A URL is  rst divided to yield a baseline segmentation: its components as given by the URI protocol (e.g., scheme :// host / path-elements / document .
extension), and further segmented wherever one or more non-alphanumeric characters appear (e.g., faculty-info faculty info).
We further break the baseline segments with some processing to arrive at a re ned segmentation: if a transition between uppercase, lowercase and digits was observed.
Two approaches were used to break the re ned segments down further.
Information content reduction uses information content as a criterion for splitting.
This algorithm examines all possible partitions of the chunk and calculates the sum of the information content (IC) of each partitioning, de ned as its negative log probability of occurrence, .
To calculate the IC for partition elements, their probability is needed.
We estimate such probabilities using data from the WebBase project, which provides the document frequency of tokens over 39 million web pages.
   A partitioning that has a lower IC sum than other partitionings can be said to have a lower amount of uncertainty, and is a more probable parse of the chunk.
A similar approach has been applied [2] to Chinese word segmentation.
The system  nds the partition with the minimal IC and compares it with the IC of the string as a series of characters (using unigram character probabilities).
If the minimum scoring partition has lower information content than the chunk as a series of characters, then the chunk is further broken down into the partition s segments.
Otherwise the chunk is kept as a single segment.
Title token based  nite state transducer (FST) tries to simultaneously split and expand segments based on previously-seen web page titles.
Consider the URL fragment  cs , which might correspond to  computer science  in a majority of the training pages  title in which it appears.
If the same URL fragment  cs  is encountered in the testing corpus, it is automatically expanded to  computer science .
To associate a fragment with a sequence of title words in the training corpus, a weighted non-deterministic  nite-state transducer is employed.
The transducer has a small set of rules that associate a score with certain moves that match or skip letters in the title tokens with corresponding letters in the segment.
An expansion in the must cover all letters in the segment to be considered valid.
The expansion or segmentation that scores highest is used as the expansion for a particular instance.
The rules that are used are listed in Table 1.
As an example, given the computer nytimes and title tokens  New York Times , the FST selects the following series of transitions: (  k  
 s), as it has the maximal score 12, and outputs .
Then, if the e   w 
 o  e  r 
 i   m  ! "$#&%('*)
             FST Rule




 Score Output




 Table 1: Rules for the title expansion weighted FST.
URL fragment  nytimes  is encountered in the testing corpus, the words  new york times  would be substituted for the fragment.
The resulting set of tokens is fed to the SVM to classify.
As SVM  machine learner 	 needs numeric features and not lexical tokens, each unique token is assigned an ID and the simple counts of the token in the set are used as the feature s value.
To test the effectiveness of the system, we evaluate on the We-bKB corpus, commonly used for web classi cation experiments.
The WebKB corpus consists of web pages collected from four universities, classi ed into seven categories.
We employ a subset of the WebKB, containing 4,167 pages (the ILP 98 dataset [3]), in which each page is associated with its anchor words (text from the hyperlinks that point to the page).
The classi cation was set up as a series of binary classi cation tasks, done in the same manner as [4]: using only the student, faculty, course and project categories, adjusting the cost factor to account for the unbalanced proportion of negative instances to positive ones, and performing leave-one-university-out cross-validation for training and evaluation.
We would like our evaluation to answer three questions: 1) what is the performance of a URL-only based system, 2) what is the performance of a non-source document system (i.e., anchor text plus URL features) and 3) whether URL features can improve the performance of source document systems.
To answer these questions, we test different con gurations of the system using the following features: (U)RL text - the web page s URL fragments.
This is really four different feature sets generated by the techniques used for segmentation / expansion of the URL.
U , U , U and U correspond respectively to the baseline, re ned, information content reduction and title-based FST splitting algorithms.
(A)nchor text - all tokens of the text contained in anchors pointing to the web page.
(T)itle text - all tokens in the web page s  Page Te(X)t - all tokens of the source document s text body (excluding tags in the  head title tag.
).
Separate features and counts are maintained for any token that appears in different feature sets (e.g.,  cs  appearing in the title as well as in the URL), allowing us to independently assess the measure, which is de ned as the harmonic mean of the precision impact of each feature set.
Performance is measured using the F and recall of the classi er.
Table 2 shows the F values for each SVM con guration for the four classes, macro-averaged over all four universities.
About 73% (3,078 pages) in the ILP dataset belong to the default other category.
A majority-class classi er categorizes all pages as for all four categories.
The performance of the inductive learner FOIL-PILFS (FP) as reported in [3], is a fairer other, receiving 0 F comparison.
This system used both the page text and anchor text as features, although formulated with frequency cutoffs.
Course (245)












 Faculty (153)












 Project (84)












 Student Macro Avg (558)

























 Con guration (# of pages)












 Table 2: F for different SVM con gurations on the four page classi cation task using the ILP 98 WebKB dataset.
We make the following observations about the performance of the systems from these experiments on this task: Appropriate use of URL alone proves about three-fourths as The more complex segmentation / expansion methodologies effective using the page text itself and exceeds the performance of systems using the page title or its anchors words.
in the original U do impact the performance of the system, but less so.
We  nd that IC reduction and the FST expansion make changes segmentation in only 12.7% and 18.6% of the cases, respectively.
As these methods only affect a small percentage of the URLs (unlike the change from the baseline to the re ned URL parsing), their power to enhance performance is similarly limiting.
Using both of non-source document techniques (i.e., anchor text and URLs) fails to improve results further than the best URL only based approach.
Unfortunately as well, the URL only features also fail to improve the performance of knowledge-rich classi ers that have access to all available features.
We have quanti ed the performance of web page classi cation using only the URL feature.
This ubiquitous feature of web pages, when treated correctly, exceeds the performance of some source-document based features.
The effect of anchor text, a recent topic for IR research, underperforms the URL-based systems, even though the ILP dataset is highly interconnected (10,945 interlinks for the
  cation problems have less interconnection, and 2) most general websites have more of a need for word segmentation methods (e.g., www.countrymusic le.com).
These results have encouraged us to assess the scalability of our technique on a larger problem based on Open Directory Project (ODP) categories as classi cation targets.
