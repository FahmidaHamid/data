It is well known that the world wide web may be considered as a huge and global information center.
A web site usually contains great amounts of information distributed through hundreds of pages.
Without proper guidance, a visitor often wanders aimlessly without visiting important pages, loses interest and leaves the site sooner than expected.
This consideration is at the basis of the great interest about web information mining both in the academic and the industrial world.
Usually, three types of data have to be managed in a web site: content, structure and log data.
Content data consist of whatever is in a web page; structure data refer to the organization of the content; usage data are the usage patterns of web sites.
The application of the data mining techniques to these different data sets is at the basis of the three different research directions in the  eld of web mining: web content mining, web structure mining and web usage mining [5].
In this paper, we are interested in the web usage mining domain, which is usually described as the   This work has been supported by the Ministero dell Istruzione, dell Universit`a e della Ricerca (MIUR) in the framework of the FIRB Project  Middleware for advanced services over large-scale, wired-wireless distributed systems (WEB-MINDS)  Copyright is held by the author/owner(s).
process of customizing the content and the structure of web sites in order to provide users with the information they are interested in, without asking for it explicitly [3, 4].
Various personalization schemes have been suggested in the literature.
The novelty of our strategy for personalizing the content of a web site is that we address all the following issues: i) a two-phase classi cation approach is used rather than a single-phase one; ii) both user-provided data and browsing patterns are taken into account; iii) both users and contents are classi ed.
In this section we describe our novel web usage mining strategy.
It consists of two phases: in the  rst one a pattern analysis and classi cation is performed by means of an unsupervised clustering algorithm, using the registration information provided by the users.
In the second one a reclassi cation is iteratively repeated until a suitable convergence is reached.
Reclassi cation is used to overcome the inaccuracy of the registration information and it is accomplished by the log analysis and content management modules, based on the users  navigational behavior.
We use an unsupervised clustering procedure for partitioning the feature space built upon the user-provided data into a certain number of clusters (each one representing a class) that group together users appearing to be similar.
In order to choose the optimal number of clusters, we maximize the generalization capability of the system as de ned in [2].
We propose the use of Autoclass C [1], a fuzzy unsupervised clustering algorithm based on the Bayesian theory.
Each cluster is described through a likelihood function depending on some parameters.
Given the number of classes, the Autoclass C Search module estimates such parameters on the training data and  nds the partition of the feature space that maximizes the log-likelihood value.
Once the optimal number of clusters has been chosen, the classi- cation is performed by the prediction module of Autoclass C. By using the Bayesian rule and the likelihood function of each class, it attributes a user to that class which exhibits the maximum a pos-teriori probability.
If a new user registers itself to the web site, it is classi ed according to the same scheme.
Eventually, if a user explicitly changes the data in its registration form, it is classi ed again using the Autoclass C prediction module.
The reclassi cation phase is based on the interaction of each user with the web site.
We assume that the interaction can be performed in three different ways: queries containing some keywords, searches among directories, navigation of some pages.
All the material on the web site is managed by the content management module of the system, which associates each resource (a keyword, a directory, a news headline or an article) to a speci c content category.
On the other hand the
 Site navigation SOAP/XML Response SOAP/XML Request Registration form Web Server Webserver Log Users Database Items Database Webservice User Autoclass C Classification Server Reclassifier Classification System Figure 1: System architecture log analysis module records all the activities of the users.
In order to use these information for reclassifying users we need to attribute each category to a speci c user class.
This can be accomplished by considering the  rst classi cation performed by Autoclass C and counting the number Ni of times in which the users of the i-class requested resources belonging to a speci c category, over a time interval T .
Each category is then attributed to the class that maximizes Ni.
This way of classifying the content categories can suffer the inaccuracy of the  rst classi cation.
However, if the time interval T is wide enough and the percentage of correctly classi ed users is acceptable (say, greater than 50%), also the classi cation of the categories can be considered reliable.
Now, a reclassi cation can be performed, by considering the resources that each user requested in a prede ned time interval (reclassi cation period).
If the majority of the requested contents belong to a class different from the initial one, the user is reclassi ed.
The whole reclassi cation process will lead to convergence if, after a suitable number of reclassi cations, the number of reclassi ed users goes to zero.
Figure 1 shows at a glance the overall architecture of the system.
We have used an experimental commercial web site called pari-are.com, usually visited by hundreds of users a day, which gives information about entertainment in the metropolitan area of Naples (www.pariare.com).
The system has been tested for a period of six weeks.
During this time the percentage of reclassi ed users has been tracked together with the percentages of transitions from a class to another one.
The users, already registered to the web site when the experimentation started, have been initially classi- ed using Autoclass C. First of all, we have determined the optimal number of clusters for classifying the users.
The initial data set was made up of 2682 users.
It was divided into a training and a testing set respectively made up of 1282 and 1400 users.
The features used to classify the users are: (1) age; (2) sex; (3) category of places in which users prefer to go; (4) number of times per week in which users go out; (5) preferred day of the week to go out; (5) the Pari-apoli parameter (a measure of the degree of interest towards the virtual community of Pariare, evaluated as the normalized number of the information  elds  lled in the registration form); (7) type of entertainment users are looking for.
Figure 2 shows how the percentage of reclassi ed users converges to zero, with respect to both the sample users and all users.
Figure 3.a shows the distribution of the users among the classes produced by Autoclass C on the same day of the last reclassi cation, while  gure 3.b shows the distribution of the users among the classes after the last reclassi cation.
The comparison between the two distributions shows the bene ts of adopting a classi cation strategy that takes into account both user-provided data and navigational behavior of the users: such a strategy can best  t the actual preferences of the users.
All users Sample users %










 Time

 Figure 2: Percentage of reclassi ed users vs time a b Figure 3: Distribution of users among classes produced a) by Autoclass C at the time of the last reclassi cation; b) by the last run of the reclassi cation algorithm

 In this work we have introduced an interesting solution based on pattern recognition techniques, in order to classify a web user, based on its interaction with the web site.
Several experiments have been performed and their results have been discussed.
An offline processing approach has been chosen for the classi cation task because it s easy to verify that the users do not change their preferences so frequently to justify the burden of an online processing.
We are planning to keep working on (a) a generalization of the proposed strategy in order to manage the structure of a web site; (b) the introduction of ontologies in order to automatically capture the web page contents from a semantical point of view; (c) a redesign of the system for a full compatibility with the web services standards; (d) the comparison of the proposed solution with the other ones presented in the literature and/or in the commercial areas.
