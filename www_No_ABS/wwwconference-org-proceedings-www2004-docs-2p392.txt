We have discovered a new technique that can drastically a ect (and perhaps completely crack) one of the major bottlenecks associated with web-based information retrieval systems that are driven by eigenvector ranking schemes the primary example is the PageRank mechanism that drives Google.
The bottleneck is the need to update importance rankings of pages to account for the continual changes that occur in the web s structure when pages are added or deleted and links are created or destroyed.
At last report, Google uses several days for this computation (because they use brute force and start from scratch each time an update is Copyright is held by the author/owner(s).
attempted).
Consequently, updating can only be a orded every few weeks.
Our solution harnesses the power of iterative aggregation principles for Markov chains to allow for much more frequent updates to the valuable ranking vectors.
Our primary goal is to adapt the theory of exact [7] and approximate aggregation [8] to e ciently solve the updating problem.
Suppose the Markov transition matrices and distributions at times t and t + 1 are respectively given by Qm m and  T = ( 1,  2, .
.
.
,  m) at Pn n and  T = ( 1,  2, .
.
.
,  n) at time = t + 1.
Quantities Q, P, and  T are known while  T is unknown, and m 6= n because states may be added or deleted.
Partition (and perhaps reorder) the state space S = G   G for the chain at time t + 1 so that P has the partitioned form time = t Pn n =



   All newly added states go into G along with some of the preexisting states.
The idea is to leave the g states in G unaggregated while the n   g states in G are aggregated into a single superstate.
Let { i}n i=g+1 be conformably ordered with { i}n i=g+1, and approximate (what, in the theory of stochastic complementation [7], is known as) the censored distribution sT 2 with sT

 ( g+1, .
.
.
,  n) , i=g+1  i Pn so the exact aggregated transition matrix (of stochastic com-plementation) is approximated by the (g+1) (g+1) matrix A   eA =  P11 esT

 P12e

 where e is the vector of all ones.
If e T = (e 1, .
.
.
,e g,e g+1 ) is the stationary distribution of eA, then the aggregation theorem [7] yields an approximation tothe updated distribution,  T   e T = e 1, .
.
.
,e g |e g+1esT
 This approximation is further re ned with a smoothing step e T P = (xT | yT ), where (xT | yT ) is a vector partitioned according to the G and G sets.
Then the process is iterated by restarting the procedure with
 esT Interestingly, this procedure always converges to the PageR-ank vector.
ability to identify an optimal choice for the partition S = G   G, and this is a main facet of future research.
Extensive testing seems to be the best way to produce practical heuristics for determining the appropriate partition for a given dataset.
In fact, on several small datasets, we have experiments showing the numerical feasibility of the updating algorithm (see section 2.2).
References [2, 5] prove that (1) this updating algorithm converges to the PageRank vector for all partitions S = G   G, and (2) there always exists a partition such that the convergence rate of the updating algorithm is strictly less than the convergence rate of the Google s power method.
We have experimented with a variety of datasets that were extracted as subsets of the Web.
However, we describe just two case studies with typical characteristics and outcomes.
NCstate.dat contains 10,000 pages obtained from a crawl that started with the NCSU homepage.
This small web has n = 10, 000 pages and l = 101, 118 links.
California.dat is a topical net of n = 9664 pages pertaining to the query topic of  California.  It has l = 16, 150 links.
Tables 1 and 2 compare the aggregation updating algorithm with Google s current method for updating PageRank, which is called full recomputation since the power method is started from scratch.
We report the number of iterations and the total computation time required by each method.
Table 1: Comparison of updating methods on NCstate.dat (n = 10, 000, l = 101, 118) Iterative Aggregation Full Recomputation Iterations Iterations Time



























 Time






 Time





 Table 2: Comparison of updating methods on California.dat (n = 9, 664, l = 16, 150) Iterative Aggregation Full Recomputation Iterations Iterations Time



 These tables show the speedups (as much as a factor of 10, on some other datasets) that are obtainable with this updating method.
In e ect, most of the work done by the updating algorithm is done on the very small aggregation matrix of size |G| + 1.
For example, for California.dat with |G| = 1500, the aggregation algorithm converges in just 14 iterations and 1.42 seconds compared to the 176 iterations and 9.63 seconds required by the power method because most of the work was done on a 1, 501   1, 501 matrix, rather than a 9, 664 9, 664 matrix.
Tables 1 and 2 also show the crucial role that |G| plays in the speedups achieved, and l a u d s e r i g o l

 l a u d s e r i g o l

















 residual for iterative aggregation algorithm residual for power method


 iteration


 residual for iterative aggregation algorithm residual for power method


 iteration


 Figure 1: Norm of residual vector for abortion.dat for |G| = 50 (upper) and |G| = 5 (lower) thus, choosing |G| becomes an issue.
Examine Figure 1.
The upper pane shows the norm of the residual vector for the updating algorithm applied to another dataset abortion.dat with |G| = 50, which creates a good choice for G and provides a factor of 6 speedup.
The lower pane shows the norm of the residual vector for the same dataset with |G| = 5, which creates a bad partition and causes the updating algorithm to take nearly as much time as the notoriously slow power method.
The slippery problem of choosing a good partition of the chain s states is an active area of research.
By the WWW 2004 conference, we hope to have: (1) tested this updating algorithm on larger datasets, such as those used in [3, 4, 6], (2) made progress toward understanding and determining the partitioning of states into G and G, and (3) created code that incorporates this updating algorithm with the other PageRank acceleration techniques.
