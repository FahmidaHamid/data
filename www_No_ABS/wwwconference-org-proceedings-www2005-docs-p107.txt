Developing Web search mechanisms depends on addressing two central questions: (1) how to  nd related Web pages, and (2) given a set of potentially related Web pages, how to rank them according to relevance.
To evaluate the effectiveness of a Web search mechanism in  nding and ranking results, measures of semantic similarity are needed.
In traditional approaches users provide manual assessments of relevance, or semantic similarity.
This is di cult and expensive.
More importantly, it does not scale with the size, heterogeneity, and growth of the Web   subjects can evaluate sets of queries, but cannot cover exhaustively all topics.
The Open Directory Project1 (ODP) is a large human-edited directory of the Web, employed by hundreds of portals and search sites including Google.
The ODP classi es millions of URLs in a topical ontology.
Ontologies help to make sense out of a set of objects.
Once the meaning of a set of objects is available, it can be usefully exploited to derive semantic relationships between those objects.
Therefore, the ODP provides a rich source from which measurements of semantic similarity between Web pages can be obtained.
An ontology is a special kind of network.
The problem of evaluating semantic similarity in a network has a long history in psychological theory [22].
More recently, semantic similarity became fundamental in knowledge representation where special kinds of networks or ontologies are used to describe objects and their relationships [6].
Many proposals estimate semantic similarity in a network representation by computing distance between the nodes.
These frameworks are based on the premise that the closer the semantic relationship of two objects, the closer they will be in the network representation.
However, as it has 1http://dmoz.org 107been discussed by a number of sources, issues arise when attempting to apply distance-based schemes for measuring object similarities in certain classes of networks where links may not represent uniform distances [19].
In ontologies, certain links connect very dense and general categories while others connect more speci c ones.
To address this problem, some proposals estimate semantic similarity in a taxonomy based on the notion of information content [19, 12].
In these approaches, the semantic similarity between two objects is related to their commonality and to their di erences.
Given a set of objects in an  is-a  taxonomy, the commonality of two objects can be estimated by the extent to which they share information, indicated by the most speci c class in the hierarchy that subsumes both.
The meaning of the individual objects can be measured by looking at the classes rooted at each of the topics.
Ontologies are often equated with  is-a  taxonomies, but ontologies need not be limited to these forms.
For example, the ODP ontology is more complex than a simple tree.
Some categories have multiple criteria to classify subcategories.
The  Business  category, for instance, is subdivided by types of organizations (cooperatives, small businesses, major companies, etc.)
as well as by areas (automotive, health care, telecom, etc.).
Furthermore, the ODP has various types of cross-reference links between categories, so that a node may have multiple parent nodes, and even cycles are present.
While semantic similarity measures based on trees are well studied [5], the design of well-founded similarity measures for objects stored in the nodes of arbitrary graphs is an open problem.
A few empirical measures have been proposed, for example based on minimum cut/maximum  ow algorithms [13], but no information-theoretic measure is known.
The central question addressed in this paper is how to estimate semantic similarity in generalized ontologies, such as the ODP graph, taking advantage of both their hierarchical ( is-a  links) and non-hierarchical (cross links) components.
In the next section we introduce a novel graph-based measure of semantic similarity.
To the best of our knowledge this is the  rst information-theoretic measure of similarity that is applicable to objects stored in the nodes of arbitrary graphs, in particular topical ontologies and Web directories that combine hierarchical and non-hierarchical components such as Yahoo!, ODP and their derivatives.
Section 3 compares the graph-based semantic similarity measure to the tree-based one, analyzing the di erences between the two measurements and presenting an evaluation against human judgments of Web page similarity.
We show that the new measure predicts human responses to a much greater accuracy.
Having validated the proposed semantic similarity measure, in Section 4 we begin to explore the question of applications, namely how text and link analyses can be combined to derive measures of relevance that are in good agreement with semantic similarity.
We consider various combinations of text and link similarity and discuss how these correlate with semantic similarity and how well they rank pages.
We  nd that surprisingly, classic text-based content similarity is a very noisy feature, whose value is at best weakly correlated.
We discuss the potential applications of this result to the design of semantic similarity estimates from lexical and link similarity, and to the optimization of ranking functions in search engines.
Lin [12] has investigated an information theoretic de ni-tion of similarity that is applicable as long as the domain has a probabilistic model.
This proposal can be used to derive a measure of semantic similarity between topics in an  is-a  taxonomy.
According to Lin s proposal, the semantic similarity between two topics in a taxonomy is de ned as a function of the meaning shared by the topics and the meaning of each of the individual topics.
In a taxonomy, the meaning shared by two topics can be recognized by looking at the lowest common ancestor, which corresponds to the most speci c common classi cation of the two topics.
Once this common classi cation is identi ed, the meaning shared by two topics can be measured by the amount of information needed to state the commonality of the two topics.
Likewise, the meaning of each of the individual topics is measured by the amount of information needed to fully describe each of the two topics.
In information theory [3], the information content of a class or topic t is measured by the negative log likelihood,   log Pr[t].
The semantic similarity between two topics t1 and t2 in a taxonomy is then measured as the ratio between their common meaning and their individual meanings as follows:  T s (t1, t2) =
 log Pr[t1] + log Pr[t2] where t0(t1, t2) is the lowest common ancestor topic for t1 and t2 in the tree, and Pr[t] represents the prior probability that any page is classi ed under topic t. Given a document d classi ed in a topic taxonomy, we use t(d) to refer to the topic node containing d. Given two documents d1 and d2 in a topic taxonomy the semantic similarity between them is estimated as  T s (t(d1), t(d2)).
To simplify notation, we use  T s (d1, d2) as a shorthand for  T s (t(d1), t(d2)).
From here on, we will refer to measure  T s as the tree-based semantic similarity.
The tree-based semantic similarity measure for a simple taxonomy is illustrated in Figure 1.
In this example, documents d1 and d2 are contained in topics t1 and t2 respectively, while topic t0 is their lowest common ancestor.
In practice Pr[t] can be computed o ine for every topic t in the ODP by counting the fraction of pages stored in the subtree rooted at node t (subtree(t)), out of all the pages in the tree.
This measure of semantic similarity has several desirable properties and a solid theoretical justi cation.
It is a straightforward extension of the information-theoretic similarity measure [12], designed to compensate for the fact that the tree can be unbalanced both in terms of its topology and of the relative size of its nodes.
For a perfectly balanced tree  T s corresponds to the familiar tree distance measure [10].
In prior work [14, 15, 16] we computed the  T s measure for all pairs of pages in a strati ed sample of about 150,000 pages from across the ODP.
For each of the resulting 3.8 109 pairs we also computed text and link similarity measures, and mapped the correlations between these and semantic similarity.
An interesting result was that these correlations
 larity in a taxonomy.
Figure 2: Illustration of a simple ontology.
were quite weak across all pairs, but became signi cantly stronger for pages within certain top level categories such as  news  and  reference.  However, because  T s is de ned only in terms of the hierarchical component of the ODP, it fails to capture many semantic relationships induced by the ontology s non-hierarchical components (symbolic and related links).
As a result, the tree-based semantic similarity between pages in topics that belong to di erent top-level categories is zero even if the topics are clearly related.
This yielded an unreliable picture when all topics were considered.
Let us now generalize the semantic similarity measure to deal with arbitrary graphs.
We wish to de ne a graph-based semantic similarity measure  G s that generalizes the tree-based similarity  T s to exploit both the hierarchical and non-hierarchical components of an ontology.
A topic ontology graph is a graph of nodes representing topics.
Each node contains objects representing documents (pages).
An ontology graph has a hierarchical (tree) component made by  is-a  links, and a non-hierarchical component made by cross links of di erent types.
For example, the ODP ontology is a directed graph G = (V, E) where:   V is a set of nodes, representing topics containing documents;   E is a set of edges between nodes in V , partitioned into three subsets T , S and R, such that:   T corresponds to the hierarchical component of the ontology,   S corresponds to the non-hierarchical component made of  symbolic  cross-links,   R corresponds to the non-hierarchical component made of  related  cross-links.
Figure 2 shows a simple example of an ontology graph G.
This is de ned by the sets V = {t1, t2, t3, t4, t5, t6, t7, t8}, T = {(t1, t2), (t1, t3), (t1, t4), (t3, t5), (t3, t6), (t6, t7), (t6, t8)}, S = {(t8, t3)}, and R = {(t6, t2)}.
In addition, each node t   V contains a set of objects.
We use |t| to refer to the number of objects stored in node t (e.g, |t3| = 4).
The extension of  T s to an ontology graph raises two questions.
First, how to  nd the most speci c common ancestor of a pair of topics in a graph; second, how to extend the de nition of subtree rooted at a topic for the graph case.
An important distinction between taxonomies and ontolo-gies such as the ODP graph is that edges in a taxonomy are all of the same type ( is-a  links), while in the ODP graph edges can have diverse types (e.g.,  is-a ,  symbolic ,  related ).
Di erent types of edges have di erent meanings and should be used accordingly.
One way to distinguish the role of di erent edges is to assign them weights, and to vary these weights according to the edge s type.
The weight wij   [0, 1] for an edge between topic ti and tj can be interpreted as an explicit measure of the degree of membership of tj in the family of topics rooted at ti.
The weight setting we have adopted for the edges in the ODP graph is as follows: wij =   for (i, j)   T , wij =   for (i, j)   S, and wij =   for (i, j)   R. We set   =   = 1 because symbolic links seem to be treated as  rst-class taxonomy ( is-a ) links in the ODP Web interface.
Since duplication of URLs is disallowed, symbolic links are a way to represent multiple memberships, for example the fact that the pages in topic  Society/Issues/Fraud/Internet  also belong to topic  Com-puters/Internet/Fraud.  On the other hand, we set   = 0.5 because related links are treated di erently in the ODP Web interface, labeled as  see also  topics.
Intuitively the semantic relationship is weaker.
Di erent weighting schemes could be explored.
As a starting point, let wij > 0 if and only if there is an edge of some type between topics ti and tj.
However, to estimate topic membership, transitive relations between edges should also be considered.
Let ti  be the family of topics tj such that either i = j or there is a path (e1, .
.
.
, en) satisfying:



 t0t1t2d2d1t2t1t4t3t5t6t7t8TSREdge Type109The above conditions express that tj   ti  if there is a directed path in the graph G from ti to tj, where at most one edge from S or R participates in the path.
The motivation for disregarding multiple non-hierarchical links in the transitive relations that determine topic membership is both practical and conceptual.
From a computational perspective, allowing multiple cross links is infeasible because it leads to a dense topic membership, i.e., every topic belongs to almost every other topic.
This is also not robust because a few unreliable cross links make signi cant global changes to the membership functions.
More importantly, considering multiple cross links in each path would make the classi cation meaningless by mixing all topics together.
Considering at most one cross link in each membership path allows us to capture the non-hierarchical components of the ontology while preserving feasibility, robustness, and meaning.
We refer to ti  as the cone of topic ti.
Because edges may be associated with di erent weights, di erent topics tj can have di erent degree of membership in ti .
In order to make the implicit membership relations explicit, we represent the graph structure by means of adjacency matrices and apply a number of operations to them.
A matrix T is used to represent the hierarchical structure of an ontology.
Matrix T codi es edges in T , augmented with 1s on the diagonal:
 Tij = if i = j,   if i 6= j and (i, j)   T ,
 otherwise.
We use additional adjacency matrices to represent the non-hierarchical components of an ontology.
For the case of the ODP graph, a matrix S is de ned so that Sij =   if (i, j)   S and Sij = 0 otherwise.
A matrix R is de ned analogously, as Rij =   if (i, j)   R and Rij = 0 otherwise.
Consider the operation   on matrices, de ned as [A B]ij = max(Aij, Bij), and let G = T   S   R. Matrix G is the adjacency matrix of graph G augmented with 1s on the diagonal.
We will use the MaxProduct fuzzy composition function (cid:12) [8] de ned on matrices as follows:2 [A (cid:12) B]ij = max k (Aik   Bkj).
Let T(0) = T and T(r+1) = T(0) (cid:12) T(r).
We de ne the closure of T, denoted T+ as follows: T+ = lim r  T(r).
ij = 1 if tj   subtree(ti), and T+ In this matrix, T+ ij = 0 otherwise.
Note that the computation of the closure T+ converges in a number of steps which is bounded by the maximum depth of the tree T, is independent of the weight  , and does not involve the weights   and  .
Finally, we compute the matrix W as follows: W = T+ (cid:12) G (cid:12) T+.
The element Wij can be interpreted as a fuzzy membership value of topic tj in the cone ti , therefore we refer to W as the fuzzy membership matrix of G.
equivalent to MaxMin composition.
As an illustration, consider the example ontology in Figure 2.
In this case the matrices T, G, T+ and W are de ned as follows:



 t1







 t1







 t1 t2 t3 t4 t5 t6 t7 t8 t1 t2 t3 t4 t5 t6 t7 t8


 subtree(t1) subtree(t2) subtree(t3) subtree(t4) subtree(t5) subtree(t6) subtree(t7) subtree(t8)

 t1







 t2

 .5

 .5


 t1  t2  t3  t4  t5  t6  t7  t8  t2







 t2




 .5



 t1







 t3







 t3







 t4







 t4







 t5







 t5







 t6







 t6







 t7







 t7







 t2







 t3







 t3







 t4







 t4







 t5







 t5







 t6







 t6







 t7











 t8







 t8







 t7









 t8









 t8







 The semantic similarity between two topics t1 and t2 in an ontology graph can now be estimated as follows:
  G s (t1, t2) = max log(Pr[t1|tk] Pr[tk]) + log(Pr[t2|tk] Pr[tk]) The probability Pr[tk] represents the prior probability that any document is classi ed under topic tk and is computed as: k .
tj V (Wkj   |tj|)
 , Pr[tk] = where |U| is the number of documents in the ontology.
The posterior probability Pr[ti|tk] represents the probability that
 any document will be classi ed under topic ti given that it is classi ed under tk, and is computed as follows:
 tj V (min(Wij, Wkj)   |tj|) tj V (Wkj   |tj|) Pr[ti|tk] = .
s is a generalization of  T s .
In the special case when G is a tree (i.e., S = R =  ), then ti   is equal to subtree(ti), the topic subtree rooted at ti, and all topics t   subtree(ti) belong to ti   with a degree of membership equal to 1.
If tk is an ancestor of t1 and t2 in a taxonomy, then min(Wk1, Wk2) = 1 and Pr[ti|tk]  Pr[tk] = Pr[ti] for i = 1, 2.
In addition, if there are no cross-links in G, the topic tk whose index k maximizes  G s (t1, t2) corresponds to the lowest common ancestor of t1 and t2.
The proposed graph-based semantic similarity measure was applied to the ODP ontology.
The portion of the ODP graph we have used for our analysis consists of more than half million topic nodes (only World and Regional categories were discarded).
Computing semantic similarity for each pair of nodes in such a huge graph required more than 5,000 CPU hours on IU s Analysis and Visualization of Instrument-Driven Data (AVIDD) supercomputer facility.
The computational component of AVIDD consists of two clusters, each with 208 Prestonia 2.4-GHz processors.
The computed graph-based semantic similarity measurements in compressed format occupies more than 1 TB of IU s Massive Data Storage System.
After computing the graph-based semantic similarity, we dynamically computed the less computationally expensive tree-based semantic similarity on the same ODP topic pairs.
s ,  G s >  T The  rst question to ask of the newly proposed graph-based semantic similarity de nition is whether it produces di erent measurements from the traditional tree-based similarity.
The two measures are moderately correlated (Pearson coe cient rP = 0.51).
To dig deeper, we map in Figure 3 the distributions of similarities.
Each ( T s ) coordinate encodes how many pairs of pages in the ODP have semantic similarities falling in the corresponding bin.
By de nition  T s is a lower bound for  G s .
Signi cant numbers of pairs yield  G s , indicating that the graph-based measure indeed captures semantic relationships that are missed by the tree-based measure.
The largest di erence is hard to observe in the map because it occurs in the  T s = 0 bins.
Here there are many pairs in di erent top-level categories of the ODP, which are related according to non-hierarchical links.
s and  G s , Figure 3 also shows the average graph-based similarity h G s i as a function of  T s .
The relative di erence is as large as
 s = 0.32.
The inset highlights the largest di erence, which occurs for  T
 To better quantify the di erences between  T s = 0.
Knowing that tree-based and graph-based measures give us quantitatively di erent estimates of semantic similarity, we conducted a human-subjects experiment to evaluate the proposed graph-based measure  G s .
As a baseline for comparison we used Lin s tree-based measure  T s .
The goal of this experiment was to contrast the predictions of the two semantic similarity measures against human judgments of Web pages relatedness.
Thirty-eight volunteer subjects were recruited for a 30 minute experiment conducted online.
Subjects answered 30 questions about similarity between Web pages.
For each Figure 3: Top: 200   200 bin histogram showing the distributions of 1.26   1012 pairs of pages according to tree-based vs. graph-based semantic similarity.
Colors encode numbers of pairs on a log scale.
Bottom: Averaging of  G s bin highlights the di erence between the two similarity measurements.
s for each  T question, they were presented with a target Web page and two candidate Web pages (see Figure 4).
The subjects had to answer by selecting from the two candidate pages the one that was more related to the target Web page or by indicating that neither of the candidate pages was related to the target.
A total of 6 target Web pages randomly selected from the ODP directory were used for the evaluation.
For each target Web page we presented a series of 5 pairs of candidate Web pages.
To investigate which of the two methods was a better predictor of human assessments of Web page similarity, the candidate pages were selected with controlled di erences in their semantic similarity to the target page.
Given a target Web page pT , each pair of candidate pages pC
 2 used in our study satis ed the following two con ditions: Condition 1:  T Condition 2:  G s (pC s (pC

 s (pC s (pC


 ror of the percentage of correct predictions by tree-based vs. graph-based semantic similarity, as determined from the assessments by the N subjects.
The fact that the con dence intervals do not overlap is equivalent to using a t-test to determine that the di erence in average accuracy is statistically significant at the 95% con dence level.
(4.2%, 7.2%)


  T s  G s

 Having validated our semantic similarity measure  G s , let us now begin to explore its applications to performance evaluation.
Using  G s as a surrogate for user assessments of semantic similarity, we can address the general question of how text and link analyses can be combined to derive measures of relevance that are in good agreement with semantic similarity.
An analogous approach has been used in the past to evaluate similarity search, but relying on only the hierarchical ODP structure as a proxy for semantic similarity [7,
 Let us start by introducing two representative similarity measures  c and   based on textual content and hyperlinks, respectively.
Each is based on the TF-IDF vector representation and  cosine similarity  function traditionally used in information retrieval [20].
For content similarity we use:  c(p1, p2) = 1   ~p c ~p c 1 k   k~p c k~p c 2 k
 where (p1, p2) is a pair of Web pages and ~p c is the TF-IDF i vector representation of pi, based on the terms in the page.
Noise words are eliminated [4] and other words are con ated using the standard Porter stemmer [18].
For link similarity measure we de ne: 1   ~p   ~p   1 k   k~p   k~p   2 k  (p1, p2) =
 where ~p   is the link frequency inverse document frequency i (LF-IDF) vector representation of page pi.
LF-IDF is analogous to TF-IDF, except that hyperlinks (URLs) are used in place of words (terms).
A page link vector is composed of its outlinks, inlinks, and the pages s own URL.
Link similarity is a measure of the local undirected clustering coe cient between two pages.
A high value of   indicates that the two pages belong to a clique of pages.
Related measures are often used in link analysis to identify a community around a topic.
This measure generalizes co-citation [21] and bibliographic coupling [9], but also considers directed paths of length L   2 links between pages.
Such directed paths are important because they could be navigated by a user or crawler.
Outlinks were obtained from the pages themselves, while inlinks were obtained from a search engine.4 One could of course explore alternative content and link similarity measures, however our preliminary experiments indicate that other commonly used measures such as TF-
with special permission.
Figure 4: A snapshot of the experiment setup for our user study.
The pages displayed are those of Table 1.
The use of the above conditions guarantees that for each question the two models disagreed on their prediction of which of the two candidate pages is more related to the target page.
The pages in the 30 triplets were chosen at random among all the cases satisfying the above conditions.
To ensure that the participants made their choice independently of the questions already answered, we randomized the order of the options.
Table 1 shows an example of a triplet of pages used in our study, corresponding to the question in the snapshot of Figure 4.
The users were presented with the target and candidate pages only   no information related to the topics of the pages was shown to the users.
The semantic similarity between the target page and each of the candidate pages in our example, according to the two measurements is as follows:  T s (pC  G s (pC

 s (pC s (pC

 For this triplet of pages, the tree-based method predicts that pC


  T s (pC made by the graph-based method pC 1 should be preferred over pC



 s (pC s (pC s (pC To test which of the two methods was a better predictor of subjects  judgments of Web page similarity we considered the selections made by each of the human-subjects and computed the percentage of correct predictions made by the two methods.
Table 2 summarizes the statistical results.
This comparison table shows that the graph-based semantic similarity measure results in statistically signi cant improvements over the tree-based one.3

 Page URL pT http://www.muppetsonline.com/ Topic Arts Performing Arts Puppetry Muppets http://www.theentertainmentbusiness.com/sesame.htm Arts Television Programs Children s Sesame Street Characters Arts Performing Arts Circus Juggling Clubs and Organizations College Juggling Clubs pC
 pC
 http://www.yale.edu/yags/ s and  G based cosine similarity and the Jaccard coe cient do not qualitatively alter the observations that follow.
Once text and links were extracted from the 1.12   106 Web pages of the ODP ontology,  c   [0, 1] and     [0, 1] were computed for each of 1.26   1012 pairs of pages.
Semantic similarities  T s were measured as well.
Two
 s ) and ( c,  ,  G s ) were generated to analyze the relationships between the various similarity measures.
We focus on the latter, graph-based semantic similarity in the following analysis.
The computation of these histograms (and the one for ( T s ), cf.
Section 3.1) required approximately 4,000 additional CPU hours on the AVIDD facility.
s ,  G The massive data thus collected allows us to study how well di erent automatic similarity measures based on observable features (content and links) approximate semantic similarity.
We considered a number of simple functions f ( c,  ) including:   various linear combinations f =  c + (1    )  for 0       1, of which we report the cases   = 0 (f =  ),   = 0.2,   = 0.8, and   = 1 (f =  c);   the product f =  c ;   the step-linear function f =  cH( ), where H( ) = 1 for   > 0 and 0 otherwise; and other functions omitted for space considerations.
Figure 5 plots the Pearson and Spearman correlations between  G s and these functions, versus a threshold on  c.
The Pearson correlation coe cient rP tells us the degree to which the values of each function f ( c,  ) agree with  G s .
We can see that the correlations are rather weak,
 page pairs.
If we restrict the analysis to pairs that have content similarity  c above a minimum threshold, the correlations can become much stronger.
It is meaningful to use a  c threshold because in applications such as search engines, the pages to be ranked are those that are retrieved from an index based on a match, typically between pages and a user query or some other model page.
It is interesting to observe that the functions that rely heavily on content similarity (f =  c + (1    )  for high  ) perform particularly poorly at predicting semantic similarity.
They are at best weakly correlated with  G s unless one applies a very high  c threshold.
This is rather surprising because prior to the introduction of link based importance measures such as PageRank [1] content was the sole source of evidence for ranking pages, and content similarity is still widely seen as a central component of any ranking algorithm.
The Pearson correlation assumes normally distributed values.
Since the similarity functions de ned above have mostly exponential distributions, it is worth to validate the above results using the Spearman rank order correlation coe cient rS, which is high if two functions agree on the rankings they produce irrespective of the actual values.
This is reasonable in our setting because from a search engine user perspective, what matters is the order of the hit pages and not the values used by the ranking function.
The Spearman correlation data in Figure 5 con rms the above observations, with even more striking evidence of the noisy nature of content similarity.
One can see a clear separation between the poor rankings produced by functions that depend linearly on  c and the relatively good rankings produced by functions that either do not consider  c or that scale  c by  .
The above analysis highlights an extremely low discrimination power of lexical similarity.
This might suggest a  ltering role for lexical similarity, in which all pages below a small threshold would not be considered while above the threshold only link-based measures would be used for the sake of ranking.
While such a bold strategy must be scrutinized carefully, it could lead to a signi cant simpli cation of ranking algorithms.
Let us  nally illustrate how the proposed semantic similarity function can be used to automatically evaluate alternative ranking functions.
This makes it possible to mine through a large number of alternative functions automatically and cheaply, reserving user studies for the most promising candidates.
We want to compare the quality of a ranking
 di erent functional combinations of content and link similarity.
We omit the region N < 105 where GSR is constant for all f up to the resolution of our histogram bins.
Let us thus de ne a generalized sliding ratio score as follows: GSR(f, N ) = (i,j):rank f (i,j)=1

  G s (i, j)  G s (i, j) Figure 5: Pearson (top) and Spearman (bottom) correlations between graph-based semantic similarity  G s and di erent functional combinations of content and link similarity, applying increasing thresholds on content similarity.
function to the baseline ranking obtained by the use of semantic similarity.
The sliding ratio score [17, 11] compares two rankings when graded quality assessments are avail-able.5 This measure is de ned as the ratio between the cumulative quality scores of the top-ranked pages according to two ranking functions.
We can generalize the sliding ratio in the following ways:   use a page as a target rather than an arbitrary query, as is done in  query by example  systems;   use  G s as a reference ranking function;   sum over all pages in an ontology such as the ODP, each used in turn as a target, thus covering the entire topical space and eliminating the dependence on a single target.
are available, one resorts to precision and recall; the sliding ratio score is a more sophisticated measure enabled by more re ned semantic similarity data.
(i,j):rank (i,j)=1  G s where (i, j) is a pair of pages, f is a ranking function to be tested, and N is the number of top-ranked pairs considered.
Note that for any f , GSR(f, N )   1 as N tends to the total number of pairs.
The ideal ranking function is one such that GSR(f, N )   1 for low N as well.
In simplistic terms, GSR(f, N ) tells us how well a function f ranks the top N pairs of pages.
The generalized sliding ratio score can be readily measured on our ODP data for any f ( c,  ).
Only pairs with  c > 0 are considered, since typically in a search engine only pages matching the query are retrieved.
In Figure 6 we plot GSR(f, N ) versus N for the simple combination functions f ( c,  ) introduced in Section 4.1.
Consistently with the correlation results, the functions that depend heavily on content similarity rank poorly.
Again this is only an illustration of how the  G s measure can be applied to the evaluation of arbitrary ranking functions.
In this paper we introduced a novel measure of semantic similarity for Web pages that generalizes the well-founded information-theoretic tree-based semantic similarity measure to the general case in which pages are classi ed in the nodes of an arbitrary graph ontology with both hierarchical and non-hierarchical components.
This measure can be readily applied to mine semantic data from topical ontologies and Web directories such as Yahoo!, the ODP and their derivatives.
Similarity is commonly viewed as an example of relation satisfying the following three conditions: -0.100.10.20.30.40.50.60.70.80.900.10.20.30.40.50.60.70.80.91Pearson correlation c  c H( ) 0.2  c + 0.8  0.8  c + 0.2  c-0.100.10.20.30.40.50.600.10.20.30.40.50.60.70.80.91Spearman rank correlation c threshold c  c H( ) 0.2  c + 0.8  0.8  c + 0.2  c0.10.20.30.40.50.60.70.80.911e+051e+061e+071e+081e+091e+101e+111e+121e+13Generalized Sliding Ratio ScoreN c  c H( ) 0.2  c + 0.8  0.8  c + 0.2  c114  Maximality:  (a, b)    (a, a) = 1.
  Symmetry:  (a, b) =  (b, a).
  Triangular Inequality:  (a, b)    (b, c)    (a, c).
These conditions are adaptations of the minimality, symmetry and triangle inequality axioms of metric distance functions.
The de nition of  G s proposed in this paper satis es maximality and symmetry but not the triangular inequality condition.
With su cient computational resources, a new measure of semantic similarity satisfying the triangular inequality principle can be computed by applying an adaptation of Dijkstra s shortest path algorithm [2] to  G s :  (0)(i, j) =  G s (i, j)  (r+1)(i, j) = max ( (r)(i, j), max k  (i, j) = lim r   (r)(i, j) ( (0)(i, k)    (r)(k, j))) While in many cases the lower limit imposed by the triangular inequality appears to be intuitive, many authors have argued against it.
Tversky [22] illustrates this position with an example about the similarity between countries:  Jamaica is similar to Cuba (because of geographical proximity); Cuba is similar to Russia (because of their political a nity); but Jamaica and Russia are not similar at all.  This example  ts the case of Web pages and their topics, suggesting that the triangular inequality should not be accepted as a cornerstone of similarity models.
Computing the graph-based semantic similarity measure is a computationally expensive task, both in terms of space and time.
While matrices T, G, T+ and W are sparse and easy to store, codifying the graph-based semantic similarity measure  G s for the ODP topics required the use of 5,712 dense matrices, each one of size 571, 148   100.
The time complexity for computing the semantic similarity for n topics is O(n3) in the worst case; the actual complexity depends on the density of the W matrix.
Some of the techniques adopted to deal with the time complexity of the problem include indexing the sparse structure of the matrices for fast access and using a software vector register to compute the MaxProduct fuzzy composition function e ciently.
Our approach may not scale easily to ontologies much larger than the ODP graph as it is today.
However, approximations of  G s may be computed in reasonable time if appropriate heuristics are applied (e.g., via use of thresholds).
We have shown that the proposed semantic similarity measure predicts human judgments of relatedness with signi -cantly greater accuracy than the tree-based measure.
Finally we have undertaken a massive data mining e ort on ODP data in order to begin to explore how text and link analyses can be combined to derive measures of relevance in agreement with semantic similarity.
The methodology described here to evaluate ranking algorithms based on semantic similarity can be applied to arbitrary combinations of ranking functions stemming from text analysis (e.g.
LSA, query expansion, tag weighting, etc.
), link analysis (e.g.
authority, PageRank, SiteRank, etc.
), and any other features available to a search engine (e.g.
freshness, click-through rate, etc.).
Yet the applications of the proposed semantic similarity measure are broader than just Web search.
Classi cation, clustering and resource discovery also rely on semantic mining of features that can be extracted automatically.
The main, surprising result of our initial analysis with the graph-based semantic similarity is that the classic text-based TF-IDF cosine similarity is an extremely noisy feature, un- t for ranking Web pages.
While it seems helpful to  lter out pages with very low lexical similarity (  < 0.05), text-based measures do not seem to help in ranking the remaining pages.
On the contrary they are very poorly correlated with semantic similarity, possibly re ecting the extent to which ambiguous terms mislead the search process.
While this result helps to explain why early search engines did so poorly and validates the use of link-based measures such as PageR-ank, the seemingly unredeemed quality of content similarity is unexpected.
The implication must be a revisitation of the role of content similarity in ranking Web results.
We are currently exploring alternative ways to approximate semantic similarity by integrating (rather than combining) content and link similarity.
The correlation plots in Figure 5 suggest that content may play a positive role in  ltering hits, if not in ranking them.
s and  T s is more accurate than  T In future work the semantic similarity measure must be further validated through user studies.
The study presented here focuses on cases where  G s disagree, and thus it tells us that  G s but is too biased to satisfactorily answer the broader question of how well  G s predicts assessments of semantic similarity by human subjects in general.
It is possible that alternative weighting schemes for the di erent types of links in the ODP ontology may lead to measures with improved accuracy.
The evaluations outlined here have focused on purely local text and link analysis.
For example, we have not looked at the role of more global link and text analysis techniques such as PageRank and latent semantic analysis (LSA) in improving the quality of ranking by favoring authoritative pages or improving content similarity.
These are also directions for future work.
Due to the growing number of emerging Web search techniques and the scale of the Web, automatic evaluation mechanisms are crucial.
In the light of the availability of rich semantic information sources, like the ODP ontology, we have proposed a reliable method for the algorithmic detection of semantic similarity between Web pages.
The proposed approach will provide insight for better understanding the limitations of existing search techniques and inspire the development of new and more powerful Web search tools.
We are grateful to E. Milios, S. Chakrabarti, J. Klein-berg, L. Adamic, P. Srinivasan, and N. Street for many helpful comments; to R. Bramley for sharing his expertise in scienti c computing; to the ODP for making their data publicly available; to Google for their permission to use the Web API extensively; and to IU s Research and Technical Services (especially S. Simms) for technical support.
Nihar Sanghvi carried out some of the early data collection.
This work was funded in part by NSF Career Grant IIS-
data analysis have been funded in part by NSF Grant CDA-
mendations expressed in this paper are those of the authors and do not necessarily re ect the views of the National Science Foundation.
