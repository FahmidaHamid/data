A continuing challenge facing modern search engines is that of determining and satisfying a user s needs based only on very short text queries.
Such queries can be imprecise and often re ect a user s own ambiguity while performing a search.
One frequently mentioned approach to addressing this problem is for search engines to help users re ne their search by suggesting alternative queries in response to a user input.
Unfortunately, this can be a di cult problem in itself, with many solutions relying on mining a large text corpus to uncover semantically similar terms.
Work completed while author was visiting Microsoft Re-In this paper we explore the possibility of discovering such semantically similar queries by instead mining the query   search, Silicon Valley Campus.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
stream received by a search engine.
The central idea we use is to infer that two query strings are semantically related if they are temporally correlated (i.e., if their popular-ities over time behave similarly), thus reducing the need to understand query terms at a linguistic level.
We mention that like other techniques for  nding semantically related queries, this approach has applications such as expanding user search and suggesting keywords to advertisers.
However, we believe using temporal correlation for these purposes also has the following unique advantages:   Query context.
By using temporal correlation, our approach implicitly  understands  why a query is interesting at a particular time.
For example, as the query chocolate becomes popular in February, our approach will suggest other Valentine-related queries, since those queries are also popular at the same time.
  Rapid adjustment.
Similarly, our approach also has the ability to adjust quickly to news events, as queries related to an event will begin to appear immediately in a search engine query stream.
In order to automate the process of  nding semantically similar queries using temporal correlation, we must  rst formalize a measure of temporal correlation, demonstrate that our measure e ectively  nds semantically related queries, and be able to compute our measure e ciently given the scale of a search engine query stream.
Along these lines, we do the following: Devise a formal measure of temporal correlation.
We do this by  rst de ning the frequency of a query q over a particular time unit i as the ratio of the number of oc-curences of q in i to the total number of queries in i.
Our measure of the temporal correlation between two queries p and q over a span of many time units is then the standard correlation coe cient of the frequencies of p and q.
This is a value between  1 and 1 with larger values indicating stronger correlation.
Evaluate the e ectiveness of our measure.
We evaluate our measure by testing it over two large query streams.
The  rst query stream covers a seven month period in 2004 and includes the daily aggregate totals of each of 33,986,136 distinct queries (over 5 billion total) received during that period.
The second data set covers an overlapping two month period in 2004 and, for each of 15,248,106 distinct queries (over 1 billion total) received in that period, lists the exact x 10 5
 y c n e u q e r














 income tax tax returns h&rblock federal income tax taxact www.irs.gov 1040ez forms efile freetaxusa.com Figure 1: The frequency function of income tax and the queries with the highest correlation with income tax.
x 10 3

 y c n e u q e r





 T W Th
 Sa
 T W Th
 Sa walmart target petsmart circuit city bed bath and beyond sam s club best buy sears realtor.com Figure 2: The frequency function of walmart and the queries with the highest correlation with walmart.
times that these queries were received 1.
We  nd that our measure of temporal correlation uncovers a wide range of semantically related queries, from the expected to the more surprising.
As might be expected, our measure allows us to identify semantically related queries that are  event driven  those queries whose frequencies vary greatly near a speci c event, such as a holiday or a news item.
As one of many examples, we show in Figure 1 the frequency function of the query income tax over time as well as the other queries that best correlate with it.
Intuitively, the pronounced change in frequency around an event (in this case April 15) makes  nding semantic relationships possible.
More surprisingly, however, our technique can discover interesting relationships even among nonevent driven queries whose frequencies do not change greatly over the long term.
One example here is that of walmart, whose frequency function and highest correlated queries are shown in Figure 2.
While the frequency function of walmart may not appear unusual, showing only that it is more popular during the day than at night, it is in fact distinctive enough such that it correlates very well with other large retailers.
We also  nd this to be true for queries in many other areas; for example, newspapers, airlines, and banks among others also tend to have high correlation among themselves.
Our approach does have several weaknesses that prevent
 threshold of popularity; for details see Section 3.
it from being e ective in isolation.
For example, it cannot handle the large fraction of queries that appear only a small number of times, and generates false positives on others.
Overall, however, we believe that this approach can be combined with complementary query re nement methods and text mining techniques to form a larger and more e ective query re nement system.
Develop a method to e ciently implement our measure.
Given a particular query q, we would like to  nd all other queries that have high temporal correlation with q e ciently, perhaps in real time when q is presented to a search engine.
Unfortunately, the sheer size of these query streams makes this a challenge.
The naive approach would require storing for each of n queries their frequencies for each of d time units, as well as making a linear pass through all of this data for each input query q, which could be prohibitively expensive in both space and time.
Borrowing from classical techniques in low-dimensional embeddings and nearest neighbor algorithms [4, 5, 6], we demonstrate a particularly simple and easily implemented approach to  nd approximate top-correlated queries in much less space and time.
Our technique requires storing only 128 bits of data for each query, and a linear pass through these 128 bits for an expected 1
 makes real-time processing of input queries feasible.
The idea of using temporal similarity to  nd semantic similarity was previously and independently studied by Vla-chos et al. [8].
They use a measure of temporal similarity based on the Euclidean distance between the demands over time of two queries, and describe an approach to  nd the most similar queries to a given query using the several best Fourier coe cients of each query s demand function.
They also describe a method for detecting bursts in a query s demand function.
Their emphasis is on their techniques and they report only limited experimental results on the semantic relationships they are able to  nd.
While our measure is similar, our contributions include a much more extensive evaluation of this measure as well as an e cient method for computing our measure.
We also list some examples of other recent approaches to de ning and extracting semantic similarity in queries.
Daum e and Brill [3] suggested that queries are related if they share a large fraction of their search results.
Earlier, Beeferman and Berger [1] suggested using clickthrough data to group queries, saying that two queries are similar if users selected the same document after searching for each of them.
Wen et al. [9] and Cui et al. [2] also used clickthrough data to  nd correlations between terms in user queries and terms in the documents that are selected from those queries (as well as other techniques), while Kraft and Zien [7] suggested an approach based on crawled anchortext.
The results produced by these techniques are mostly complementary to ours.
However, our techniques only require a time-stamped query stream as input; no linguistic analysis or additional information regarding the search results is necessary.
We  rst de ne and motivate our measure of temporal correlation in Section 2.
We go on to evaluate its e ectiveness in Section 3, and then describe how to e ciently implement it in Section 4.
Finally, we discuss future work in Section 5.
x 10 3 In this section we motivate and de ne our measure of temporal similarity.
We  rst introduce the notion of the frequency function of a query.
Assume some discretization of time into time units.
Let Xq,i be the frequency of query q during the ith nq,i Ni , where nq,i is the number of occurrences of time unit, or query q during the ith time unit and Ni is the total number of queries during the ith time unit.
De nition: The frequency function of a query q over d time units is the d-dimensional vector Xq = (Xq,1, .
.
.
, Xq,d).
If we think of the frequency Xq,i of a query in a particular time unit as a random variable, we can then de ne the similarity of two queries as the correlation coe cient of their frequency functions: De nition: For a particular query q, let Xq,i be its frequency function,  (Xq) be its mean frequency, and  (Xq) be the standard deviation of its frequency.
Then the similarity of two queries p and q is the correlation coe cient of their frequency functions, or Xp,i    (Xp) Xq,i    (Xq) (cid:3)(cid:2) (cid:2) (cid:1) (cid:3) .
d i  (Xp)  (Xq) The correlation of two random variables is a standard measure of how strongly two variables are linearly related.
It always lies between  1 and 1, with 1 indicating an exact positive linear relationship between them and  1 indicating an exact negative linear relationship.
The correlation of a variable with itself is 1, while the correlation of two independent random variables is 0.
Correlation therefore naturally captures our intuitive notion of temporal similarity.
To illustrate this, in Figure 3, we plot the frequency functions of two pairs of queries and note that they show high correlation coe cients.
While this de nition appears straightforward, it does contain some important features.
First, note that the frequency function of a query is the density of that query in a given time unit as opposed to simply the number of occurrences of that query in a given time unit.
This normalizes out the e ects of the natural variation over time of query stream volume, and prevents some pairs of queries from showing arti cially high correlation simply because the total number of queries per time unit is much larger during the day than overnight, and much larger on weekdays than on weekends.
As an example, we compare in Figure 4 the highest correlated queries with southwest airlines our techniques (see Section 4)  nd when we use density and when we use the number of occurrences.
Another important point about our measure is that we use the correlation of the frequency functions as opposed to the covariance, another common measure of similarity.
The covariance fails to normalize for the variance in frequency functions, and thus queries with high variance falsely appear to be temporally related to many other queries.
Walmart Sears













 Days of August x 10 4 Scott Peterson Modesto Bee






 y c n e u q e r
 y c n e u q e r
















 Days of August Figure 3: (top) The frequency functions of sears and walmart in August, correlation 0.92; and (bottom) the frequency functions of scott peterson (accused murderer) and modesto bee (his local newspaper), correlation 0.94.
orbitz travelocity united airlines american airlines frontier airlines expedia www.fafsa.ed.gov sprintpcs.com att mortgage calculators holiday inn expedia continental wells fargo Figure 4: Top correlated queries with southwest airlines using (L) frequency, and (R) number of occurrences.
search engine.
We had access to two data sets from this query stream: The  rst data set runs from February 1, 2004 through August 31, 2004 and includes the daily aggregate totals of each of the 33,986,136 distinct queries that appeared at least 10 times on at least one day.
The second, more detailed, data set runs from August 1, 2004 through September 25, 20042 and, for each of the 15,248,106 distinct queries that appeared at least 10 times in this period, gives the exact times that these queries were received.
The results that we extract from these data sets demonstrate that our technique is able to detect a variety of often surprising semantic relationships among queries, though with some shortcomings.
We  rst discuss the details of our experimental technique in Section 3.1, before presenting a summary of some of these results in Section 3.2.
In this section we evaluate the e ectiveness of our measure using query data from the U.S. market of the MSN
 through 18th of August due to a data collection error.
Before we can run our experiments, we need to  x the parameters of our measure.
The main parameters are:   De nition of time unit.
Our measure assumes a dis-cretization of time, but how long should each unit be?
one hour?
one day?
one week?
Too  ne a scale threatens to drop all correlations well below any reasonable threshold, but too coarse a scale creates meaningless correlations.
  Dimension d. Our measure runs for a certain length of time (or, equivalently, over a certain number of time units).
What length of time should we study?
one week?
one month?
one year?
  De nition of meaningful correlation.
Once the pairwise correlations have been computed, what value of correlation suggests semantic similarity?
Our detailed dataset allows us to experiment with the length of the time unit.
In Figures 21 through 26 (at the end of this paper), we consider two input queries   disney and republican national convention   for three, six, and twenty-four hour time units over a period of two months.
For each length of time unit and input query, we plot the frequency function and list the most correlated queries along with their correlations.
Notice that the results for event driven queries, such as republican national convention, seem to be better with longer time units, while queries with more periodic frequency functions, such as disney, perform best with shorter time units.
This makes intuitive sense, since the important changes in frequency for event driven queries are visible only over long time scales, while the interesting variations for periodic queries tend to occur on a daily or weekly basis.
The period of time over which we compute our measure can also a ect the results, though less so than the length of time unit.
In general, we found that event driven queries, such as greeting cards (Figure 6), produced better results over longer time frames while more periodic queries, such as sears (Figure 17), performed better in the shorter ones.
This is because a longer time frame is needed to capture the peaks for an event driven query such as greeting cards, while the pattern for sears is established in a short amount of time.
In fact, longer time frames may be harmful for periodic queries, since an outlier in a single time unit can severely diminish the correlation coe cient.
Finally, the quality of our results varies as we  ne-tune our notion of meaningful correlation.
In general, we found that a correlation of 0.9 is a necessary (but not su cient) predictor of semantic similarity.
We  rst present a sample of the positive results returned by our technique.
We again roughly divide these into those that are event driven, and those that are more periodic over time.
Figures 5 through 9 present the frequency functions and top correlated results for six event driven queries.
In each of these cases, the frequency function of the query spikes near some event (as described in the captions).
Intuitively, these distinctive patterns make it easy for our technique to isolate semantically related (though linguistically unrelated) queries, whose frequency functions show similar behavior, and our technique appears to work particularly well for these queries.
To expand on several examples, note that as February is Black History Month, the query alice walker (Figure 5) correlates exclusively with other famous African Americans.
The query greeting cards (Figure 6), whose frequency function has large peaks around holidays, is temporally related to online electronic greeting card sites.
The best correlated results for convicted murderer scott peterson (Figure 7) include court tv, laci peterson (his murdered wife), and modesto bee (his hometown newspaper).
Finally, the query superbowl (Figure 8) correlates with other Super Bowl-related people and events, including terms that are not linguistically similar, such as tom brady (a football player), janet jackson (the halftime show performer), and pepsi commercial (a commercial aired during the game).
More interestingly, our technique is also able to produce interesting results for some classes of nonevent driven queries, and we show ten such examples in Figures 10 to 19.
These results might be considered surprising, given that the frequency functions of these queries are not as visually distinctive as those of event driven queries.
However, it turns out they still contain enough structure for us to  nd interesting correlations.
A comparison of cnn (Figure 12), disney (Figure 14), and sears (Figure 17), for example, shows that the news service is most popular on weekdays (August 1 was a Sunday), the children s entertainment source is more popular on weekends, and the large retailer is fairly constant, thus allowing us to separate these categories.
We can also see more subtle di erences: note that though both the Atlanta Journal-Constitution newspaper ajc (Figure 10) and cnn are weekday queries, ajc is most popular in the morning, while searches for cnn are spread throughout the day, allowing our technique to separate newspapers from television news sources.
Thus even these less pronounced temporal features are useful in uncovering semantic relationships.
Other examples we show include queries for banks (bankone, Figure 11), airlines (southwest airlines, Figure 18), and reference services (dictionary, Figure 13, and yellow pages, Figure 19), among others.
While these examples show that temporal correlation shows promise in  nding semantic similarity, it is important to note that it does not provide a complete solution to the problem of query re nement.
In order to develop a general measure of the e ectiveness of our technique, we analyzed the 300, 000 most popular queries during the month of August using three hour time units (this includes all queries that were searched for at least 500 times).
Among these, a weighted 20% reported a correlation above 0.9 with at least one other query (the weighting is done by popularity of the queries).
Of the 100 most popular of these queries, for a weighted 70%, at least three of their top ten correlations were judged to be in fact semantically related3.
Thus while we can make reasonable suggestions for some fraction of input queries, many others are not temporally similar enough to other queries for our technique to be useful.
This is particularly the case for queries with low total frequency.
Further, as our analysis shows, our approach also suggests many false positives.
Overall, then, temporal correlation would be
  nd no systematic way to evaluate the results and thus clas-si ed them manually.
x 10 5
 y c n e u q e r














 Date results: michael jordan martin luther king jr jackie robinson ella fitzgerald malcolm x frederick douglass maya angelou langston hughes gwendolyn brooks Figure 5: alice walker results for 2/1-8/31, 24 hour time unit; all listed results are famous African Americans.
(Most popular in February, which is Black History Month.)
x 10 4





 y c n e u q e r









 Date results: free e-cards egreetings.com free cards american greetings bluemountain.com yahoo cards www.hallmark.com email cards msn greetings Figure 6: greeting cards results for 2/1-8/31, 24 hour time unit; bluemountain is an online greeting card site.
(Spikes occur on holidays.)
x 10 4






 y c n e u q e r
















 Days of August results: court tv laci peterson dictionary modesto bee scott peterson trial peterson trial washington mutual bank free clip art thesaurus Figure 7: scott peterson results for 8/1-8/31, 3 hour time unit; the Petersons were from Modesto.
(Spikes occur on days of important testimony in the trial.)
x 10 3








 y c n e u q e r









 Date results: superbowl commercials superbowl halftime show superbowl xxxvii superbowl 2004 nfl half time show superbowl-ads.com janet jackson pepsi commercial tom brady Figure 8: superbowl results for 2/1-8/31, 24 hour time unit; Tom Brady was the Super Bowl MVP.
(The Super Bowl was played on February 1.)
y c n e u q e r









 x 10 3 results:














 Days of August weather channel national weather service weather underground intellicast.com accu weather twc nbc6.net click10 msn weather Figure 9: weather results for 8/1-9/25, 3 hour time unit; twc is the Weather Channel.
(Hurricane Charley made landfall on August 13.)
x 10 4






 y c n e u q e r
















 Days of August results: cincinnati enquirer times union boston herald baltimore sun pittsburgh post gazette bb&t ny daily news detroit free press washingtonpost.com Figure 10: ajc (Atlanta Journal-Constitution) results for 8/1-9/25, 3 hour time unit x 10 4








 y c n e u q e r
















 Days of August results: fleet charter one bank usajobs wachovia bank chevy chase bank bankofamerica usaa air tran amsouth Figure 11: bankone results for 8/1-9/25, 3 hour time unit; all results other than usajobs and air tran are banking related.
x 10 3
 results:
 y c n e u q e r



















 Days of August fox news cbs news drudge abc news msnbc news grainger wpvi aol www.ups.com Figure 12: cnn results for 8/1-9/25, 3 hour time unit x 10 3









 y c n e u q e r
 results: websters dictionary thesaurus free translation dictionary.com register to vote spanish dictionary free clip art















 Days of August Figure 13: dictionary results for 8/1-9/25, 3 hour time unit x 10 4






 y c n e u q e r
















 Days of August results: barbie.com postopia.com noggin.com cartoon network neopets.com pbs kids nickjr bratz.com yugioh.com Figure 14: disney results for 8/1-9/25, 3 hour time unit; all listed results are children s sites x 10 4






 y c n e u q e r









 Date results: amc ravemotionpictures.com movie listings www.movifone.com regalcinema.com movies.com local movies harkins.com www.movietime.com Figure 15: movies results for 2/1-8/31, 24 hour time unit; AMC and Harkins are theater chains.
x 10 4 y c n e u q e r






















 Days of August results: cheap tickets hotwire www.orbitz.com hotels.com boat trader southwest airlines www.costco.com niagra falls ata airlines Figure 16: priceline results for 8/1-9/25, 3 hour time unit y c n e u q e r
 y c n e u q e r


















 x 10 4 results:







 Days of August






 barnes and noble walmart jcpenny dell.com comp usa circuit city u haul office max lowe s Figure 17: sears results for 8/1-9/25, 3 hour time unit x 10 4 results:














 Days of August orbitz travelocity united airlines american airlines frontier airlines expedia www.fafsa.ed.gov cheap tickets netflix Figure 18: southwest airlines results for 8/1-9/25, 3 hour time unit x 10 3









 y c n e u q e r
















 Days of August results: zip codes msn yellow pages www.whitepages.com yahoo yellow pages us postal service switchboard social security federal express anywho.com Figure 19: yellow pages results for 8/1-9/25, 3 hour time unit; switchboard and anywho are Internet phone directories.
most successful when deployed in conjunction with complementary query re nement techniques, and combined with text mining techniques to help  lter out false positives.
In this section, we describe our approach to e ciently  nd all queries that have high correlation with a given input query.
A naive approach to this problem would be to simply compute all correlations with the input query.
For a query stream with n queries and d time units, this would require storing dn values and making a linear pass over all of this data for each input query.
In order to  nd these correlations in real time, we adapt techniques from the theory of embed-dings [6] and nearest neighbor algorithms [5] to  nd the approximate correlations of queries and thus dramatically reduce the time and space complexity of the computation.
We stress that in developing our approach, the emphasis is on simplicity and practicality of implementation.
Recall that the correlation of two queries p and q is: (cid:3)(cid:2) (cid:2) (cid:1)
 d Xp,i    (Xp) Xq,i    (Xq) i  (Xp)  (Xq) (cid:3) , where Xp,i is the frequency of p in time i.
This can be interpreted as the dot product  Xp    Xq of the scaled and normalized frequency vectors  Xp,i =
 d Xp,i    (Xp) .
 (Xp) Note that this is cos  pq, where  pq is the angle between  Xp and  Xq.
Our goal can be restated as  nding, for a given input query q, those queries p for which cos  pq is largest, or equivalently, for which  pq is smallest.
Our approach proceeds in two steps:
 bits per query, for a reasonably small constant  , by de ning a mapping v( ) : R d   {0, 1}  such that the fraction of bits where v(  Xp) and v(  Xq) agree is roughly proportional to  Xp    Xq, the correlation of queries p and q.
(We chose   = 128, i.e., 16 bytes per query, for a total of only 240 MB for 15,000,000 queries, which  ts easily into memory.)
of only a small fraction of queries ( 1 776 in our case) in  nding the top correlations for a given input query q, by examining only those queries p that seem likely to have high correlation with q based on the  rst k <   bits of v(  Xp).
Our approach  rst de nes a mapping v( ) : R d   {0, 1}  that represents each frequency vector Xq as a string of   bits, v(  Xq), for some   (cid:4) d (the parameter   depends on the desired accuracy of the approximation but not on the original dimension d; we chose   = 128).
This reduces the amount of storage required from  (dn) integers to a mere  n bits.
We do this using random hyperplanes in a manner similar to that of [4, 5, 6].
Our mapping v( ) is de ned by   random vectors {r1, .
.
.
, r }   R d drawn from a Gaussian distribution, which we interpret as normal vectors to hyperplanes.
For a particular query q, the ith coordinate of s t n e m e e r g a f o n o i t c a r f d e t c e p x

















 Correlation Figure 20: The probability a query is returned by our technique versus the correlation of that query with the input query.
v(  Xq) is the sign of the dot product  Xq   ri.
The sign essentially records the side of the random hyperplane on which the vector  Xq falls.
We claim that this embedding preserves our ability to  nd highly correlated queries, since for any two vectors  Xp and  Xq, the random variable  pq, denoting the fraction of bit agreements between v(  Xp) and v(  Xq), has expectation 1    pq   and low variance.
To verify the expectation, note that the probability that v(  Xp) and v(  Xq) agree in the ith component (i.e., that sign(  Xp   ri) = sign(  Xq   ri)) is simply 1    pq/ , or the probability that two vectors with an angle  pq between them are on the same side of a random hyperplane.
The low variance follows from the observation that each random vector ri is chosen independently and a standard Cherno  bound argument.
Thus if we are interested in  nding queries whose correlation is at least a given threshold   with an input query, we can simply return those queries whose embeddings agree on a fraction p  = 1   arccos( )/  of bits.
As an example, when   = 0.9 (the threshold used throughout this paper), we have p  = 0.8564.
Figure 20 shows the probability that two queries p and q of a particular correlation cos  pq have  pq   0.85 for   = 128.
Note the somewhat sharp thresh-for two queries p and q with correlation at least 0.9, old: Pr[ pq   0.85]   0.62 while for two queries p and q with correlation at most 0.8, Pr[ pq   0.85]   0.07.
Online Implementation: One important feature of our proposed embedding is that it can be implemented in an online fashion using just O( n) integers.
In each time unit, we keep the exact value of the frequency of each query.
At the end of the jth time unit, our algorithm generates the next random coordinate rij of each of the   random vectors It stores the current value of all  n dot products of ri.
the form ri   Xp, i.e., it updates the sum k=1 ri,kXp,k.
It also tracks the mean frequency of each the n queries after (cid:4)d each time unit.
This information is su cient to compute k=1 ri  (Xp    (Xp))).
Since normalizing the random sign( vector ri and dividing the sum by the variance of Xp do not a ect the sign of the result, the method described does in fact compute the mapping v( ) de ned above.
(cid:4)j We mention that all results presented in this paper were computed using the technique presented in this section.
Using the embedding technique above, we can now  nd the (approximate) highest correlated queries above a certain threshold to an input query q using just O( n) bit comparisons by simply computing the number of bit agreements between v(  Xp) and v(  Xq) for all queries p.
Considering that we only want to return queries with correlation above the given threshold  , we can reduce the running time of our technique even further by limiting the number of queries p that we examine.
In particular, we examine only those queries p that seem likely to have high correlation with q based on the  rst k bits of v(  Xp).
We create 2k buckets indexed by all strings in {0, 1}k and store each query q in the bucket indicated by the  rst k bits of its embedding v(  Xq).
For each bucket b, we de ne a bucket b(cid:1) as close to b if their indices agree in at least a   fraction of the bits, for some parameter     p .
Given an input query q, we only search for high-correlation queries p in the bucket of q and in buckets close to the bucket of q.
(Note that we still compare all   bits for the queries in these buckets, so that we eliminate false positives generated by this process.)
The intuition is that queries whose embeddings agree in at least a fraction p  of their bits will likely agree in at least a fraction   of their  rst k bits, so that we still  nd most correlated queries.
By only searching through close buckets, however, we greatly reduce the number of queries for which we have to perform bit comparisons.
For the parameters we recommend, with k = 20,   = 0.9, and   = 0.85, each query with correlation above   will fall into a close bucket with probability 0.68.
Combined with the loss induced by the correlation estimate, this implies that an expected 0.42 fraction of queries with correlation 0.9 are returned by our technique (with better expectations for higher correlations).
Further, for any given bucket, only 1351 of the 220 = 1048576 buckets are close, meaning that in expectation we only need to examine about 1/776 of the queries.
For n = 15, 000, 000, this comes out to only 19, 330 queries, and we note that in our experiments we did not generally search through more than 40, 000 queries.
There are a number of future directions to consider for this work.
In our current approach, we divide a query stream into bins, where bins correspond to time units, and aggregate query information within these bins.
It would be interesting to generalize this approach to other notions of bins beyond time units, possibly as follows:   Regionalization.
Using the client IP address information available in query logs, we can further restrict the idea of bin to be not just a time unit, but also a geographic region.
This may allow us to  nd correlations unique to a particular area.
  Time zones.
Again using client IP addresses, we can instead count how often queries occur within local time intervals (e.g., how often a query q occurs between 6 am and 9 am local time), allowing us to study and possibly remove the e ect of time zones.
It is also interesting to consider how to determine which pairs of highly correlated queries are semantically related and which are false positives.
Our current approach uses a 0.9 threshold to determine semantic similarity and admits many false positives.
An alternative approach might be to run a clustering algorithm on the weighted complete graph whose nodes are queries and whose edges are the correlation estimates of the corresponding endpoints.
Unfortunately, this may be prohibitively expensive computationally.
Further, one weakness of our current approach is that it is limited to queries that are common enough to have nontrivial frequency functions.
An open question is whether it is possible to produce meaningful results for those queries that occur very rarely.
More generally, we note that because query streams are often proprietary, their potential for improving search is still largely untapped, and that much research is still left to be done in this area.
We are grateful to Robert Ragno for processing and providing us with the two month query stream.
We would also like to thank Dennis Fetterly, Mohammad Mahdian, Mark Man-asse, Frank McSherry, Chris Meek, Marc Najork, Madhu Sudan, and Kunal Talwar for useful discussions, as well as the anonymous referees for very helpful suggestions.
