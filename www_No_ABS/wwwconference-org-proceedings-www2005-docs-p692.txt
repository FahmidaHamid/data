XML (Extensible Markup Language) [5] processing can be a signi cant runtime overhead in XML-based infrastructural middleware such as Web Services application servers.
[28,
 its verboseness.
For example, well-formed pairs of named marking-up tags for XML elements contribute to its human-friendliness and vender-neutrality, but require extra computation in processing.
The computation speci c to XML includes variable representations for the same tag, the handling of namespaces, tolerance for multi-character encod-ings, etc.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
This paper proposes a novel mechanism for e ciently processing XML documents in most cases.
Its notable feature is to remember the documents processed previously and to use those processed results to deal with a new XML document.
Incoming XML documents that share very similar parts with previously-processed documents can be processed very quickly with this feature.
Even though this feature adds some overhead in processing strange XML documents (those which are not similar to the documents processed before) compared to normal XML processing, the gain from the speedup for similar documents can easily compensate for the overhead where there is repetitive processing as in situations like Web Services middleware.
Given a new XML document as a byte sequence, the XML parser proposed in this paper, in most cases, does not analyze most of the XML syntax in the document but just compares the byte sequence with the ones that were previously processed.
The parser then reuses the resultant parse events stored during the previous processing.
Only the parts di ering from the previously-processed documents are processed in the normal way for XML parsing.
It remembers the byte sequences in a DFA (Deterministic Finite Automaton), where each state transition has a byte sequence and its resultant parse event.
In addition, the parser remembers processing contexts in DFA states so that it can partially parse unmatched byte sequences.
The parsing process normally follows state transitions in the DFA by matching byte sequences.
If no states to transit to are found, it partially parses the unmatched byte sequence until it  nds a resultant state from which it can transit to existing states.
Then it continues to make transitions in the DFA.
The notable feature of our DFA structure is its  safety  and  e ciency  in reusing parse events from previously-processed XML documents.
The safe reuse means that the resultant parse events conform to the XML speci cation [5,
 and reject ill-formed ones.
E cient reuse means that it should reuse as many parse events as possible from previous parsing while minimizing computation costs for the reuse.
Less reuse can cause extra partial parsing, which is costly, and higher reuse computation cost could cancel the bene ts of reuse.
We need to  nd good trade-o s for e cient reuse, since aggressive reuse sometimes increases the computation cost for reuse, and vice versa.
We carefully designed the strategy for constructing DFAs so that they can  nd a good trade-o  point for e ciency.
Several improvements have been created for e ciently processing XML documents using application-speci c information available from their schemas, such as DTDs.
A few investigated optimization of lexical analysis [8, 9].
However, schema-based techniques cannot capture the optimizations from byte-level resemblances among documents, especially in pre x-namespace binding and in the representations of tags, since they are not speci ed in schemas.
Most of the schema-based optimization e orts are focused on higher-level XML processing rather than on lexical analysis of XML documents serialized as byte sequences.
For an example of XML document validation, XSM [20] uses cardinality constraint automata specialized by accepting schemas, but it assumes SAX events are the input of the automata, not low-level byte sequences.
We implemented in Java an XML parser named Deltarser based on the described mechanism.
Our SAX implementation complies with the JSR 63 [24] (Java API for XML Processing 1.1) standard speci cation.
We conducted some experiments and observed its advantages over ordinary XML parsers in certain representative scenarios which we believe cover the majority of practical Web Service usages.
Though this paper focuses on the SAX implementation, the same technology is easily applied to other streaming parsers.
In fact, our pull-parser implementation complies with the JSR
 and we observed e ciency similar to the SAX implementation.
The rest of the paper is organized as follows: In Section 2, we specify the overheads in XML parsing and explain why there should be opportunities for reducing these overheads in many practical cases.
We describe the design and implementation of our XML parser, Deltarser, in Section 3 and show its e ectiveness through the experimental results in Section 4.
Finally, we conclude this paper with Section 5.
XML (Extensible Markup Language) [5] is heavily used in XML-based infrastructural middleware such as Web Services [22, 10] application servers, and its processing can be a signi cant runtime overhead.
The reason why the processing overhead of XML is high lies in its verboseness.
Middleware The cost of XML parsing has a large impact on the execution performance of recent XML-based middleware [28,
 documents to construct data objects for its application programs or for its own use.
For example, a Web Service application server for service applications in Java receives SOAP messages encoded in XML and deserializes them into Java objects while it reads its settings from a  le, whose format is also de ned in XML by JSRs [16, 17].
Web Service middleware uses XML heavily since XML is a key construct of Web Services.
Web Services are enabling technologies for vender-independent distributed environments where loosely coupled servers can interconnect to each other.
In such environments, standard speci cations de ne most of things to be written in the XML-based languages recommended in the speci cations.
For example, messages passed in Web Services are enveloped according to SOAP [22], which is a protocol using XML for messaging.
In addition to messaging, there are a number of other places where XML is used in Web Services middleware.
For publishing available Web Services, the services are described in WSDL [10] (Web Services Description Language), which speci es the format for service descriptions.
Con guration  les like webservice.xml for application servers are often described in XML, as de ned in JSR 109 [16] and JSR

 The computations speci cally required to process XML documents include tolerance for various character encodings, variable length data, ignorable white spaces, line break normalization, the handling of namespaces, and the creation of parsed result objects.
Figure 1 shows the normal processing model in conventional XML parsers for SAX [24].
Figure 1: Processing stages in normal XML parsers for SAX.
First, an XML parser needs to convert the character en-codings, since the external encoding, the encoding format in which an XML document is encoded, may be di erent from the internal encoding, the encoding format used in a program.
For example, an XML document is often encoded in UTF-8, while a Java program handles characters in UTF-16.
An XML parser must convert the original UTF-8 encoded characters into UTF-16 encoded characters in order to use the characters in the middleware or to pass them to application programs.
Processing XML documents requires the recognition of token delimiters like  <  and  >  [5] since XML data objects normally have varying lengths.
Like most programming languages, an XML document must be  parsed  to recognize lexical tokens, even though the syntax is relatively simple and easy to analyze.
This is extra runtime overhead compared to e cient wire formats with  xed-length structures [6].
XML allows ignorable spaces in its tags.
For example, a start tag: <doc language="Japanese"> can also be written as: < doc language =  Japanese  > White spaces, tabs, new lines, and carriage returns are allowed in many places.
It means that there are a variety of ways to express a tag with the same meaning.
An XML parser must skip such ignorable spaces.
This adds an overhead cost since it requires testing whether or not each character data is one of these ignorable characters.
The normalization of line separators is also a task handled in an XML parser.
The XML speci cation allows lines to Lexical analyzerbytesSyntax analyzer < > QNAME n:doc QNAME xmlns:n = VALUE uri:n1 TEXT \r\n </ > QNAME n:doc TEXT \r\n lexicaltokensCharacter encoding & line separator convertercharacters<n:docxmlns:n= uri:n1 >\r\n \r\n</n:doc>StartTagname= n:doc , attributes={ .. }Texttext= \r\n EndTagname= n:doc Texttext= \r\n parsereventsNamespace handling & SAX events constructionSAXeventsStartElementname= n:doc  ..EndElementname= n:doc StartPrefixMappingprefix= n , uri= uri:n1 StartDocumentEndDocumentbe separated by single LF characters, by CR LF character sequences, or by single CR characters.
However, internally these separators are always converted to single LF characters.
An XML parser must detect LFs, CR LF pairs, and CRs to convert all of them to LFs.
An XML document may use namespaces [4] to avoid collisions among tag names or attribute names, so an XML parser must handle namespaces for documents using them.
Since XML namespaces are scoped within elements, name-space handling involves stacked map management for matching each namespace pre x to its namespace URI.
For example, the nested elements: <n:doc xmlns:n="uri:n1"> <n:title xmlns:n="uri:n2"/> <n:item/> </n:doc> have the same namespace pre x  n  but they must be resolved to di erent namespace URIs, uri:n1 for doc and item, but to  uri:n2  for title.
Finally, an XML parser needs to construct parsed result objects so that it can pass them to its users (middleware or application programs) through an API like SAX.
For example, with SAX 2.0 [24], an application subclass overrides a method startElement() in the class ContentHandler.
A SAX parser is responsible for creating String objects for its namespace, local name and quali ed name parameters, and Attributes objects for its attributes parameter to pass them through this interface.
Processing On balance, we believe there should be a lot of opportunities to optimize the processing of XML documents.
Even though optimizing for general cases is hard to do, optimizing for special cases is possible.
For example, if we knew all the messages were formed in a certain way, we could optimize the parsing process for such XML documents.
In an environment of Web Service application servers, we can expect that most of the messages will be generated by machines.
In particular, RPC-style request-response messages are often generated by middleware with XML serial-izers.
When accessing Web services in client code, proxy classes and frameworks provided by middleware handle all of the infrastructure coding.
For example, a C# client uses the .NET framework to access Web Services, and a JAX-RPC client may use the javax.xml.rpc.Call instances implemented by some particular vendor.
Though formatting styles are di erent for various programming languages, implementation vendors, or versions, the same XML serializer implementation generates the same kind of service requests and responses with di erent parameters and return-values in very similar byte sequences.
This is because such XML serialization is performed by a certain runtime library or by proxy code generated by a certain tool provided by middleware or a development environment.
As a result, recurring SOAP messages often form very similar byte sequences except for the contents of elements representing di erent parameter values, as long as they are sent by application programs with the same infrastructural mid-dleware.
A key challenge in optimizing XML processing is to preserve the interoperability of the XML documents.
We can do anything in closed environments using XML as the wire format, but it is expected that XML is mainly used in open environments, where there may be many participants conforming to the XML speci cations [5].
An optimized XML parser must not reject or be broken by XML messages in forms unexpected by the optimization.
In addition to the compatibility, another key challenge is to make optimizations tolerant of implementation changes in infrastructural middleware.
An optimization for a limited set of XML serializer implementations can easily be obsolete and ine ective, since they are easily changed by new implementation versions or by new implementation vendors.
We designed an XML parser named Deltarser, which can e ciently and safely process XML documents similar to previously processed documents.
The e ciency for similar documents applies in situations like Web Service application servers, where middleware needs to process a lot of similar documents generated by other middleware.
In addition, the parsing of Deltarser is  safe  in the sense that it checks the well-formedness of the processed documents.
From the viewpoint of users, Deltarser looks just like an XML parser implementation and has the same functionality as normal XML parsers such as the Apache Xerces [27] implementation.
In fact, the SAX implementation of Deltarser complies with JSR 63 [24], which is a standard API for XML processing in Java.
Applications or middleware using XML parsers through the standard API can easily be changed to use Deltarser without modifying the code.
In the best cases, given a new XML document as a byte sequence, Deltarser does not analyze most of XML syntax in the document, but just compares the byte sequence with those that were already processed.
The parser reuses the processed results stored in memory for the matching parts.
Figure 2 depicts the abstract view of SAX processing with Deltarser.
Figure 2: Processing stages in Deltarser for SAX.
The key ideas and technologies we developed for Deltarser are as follows: Byte-level matching for XML processing It makes use of byte-level matching for the most parts of the document to be processed.
Since we take the context of the XML document into consideration, we can reliably compare XML documents by only doing byte-level matching.
bytesByte sequence matcher and event diff calculator<n:docxmlns:n= uri:n1 >\r\n \r\n</n:doc>SAXeventsStartElementname= n:doc  ..EndElementname= n:doc StartPrefixMappingprefix= n , uri= uri:n1 StartDocumentEndDocumentLexical analyzerSyntax analyzerCharacter converterSAX constructionPartial parserEvents producerRecordedeventsGeneratedeventsRecordedeventsMatchedpartsMatchedpartsDifferentpartsdifferentialinformationRemembering processed documents in a DFA For ef- ciently remembering and comparing previously processed documents, it remembers the byte sequences of the processed documents in a DFA (Deterministic Finite Automaton) structure.
Each state transition in the DFA has a part of a byte sequence and its resultant parse event.
Partial parsing It partially processes XML parsing only the parts that di er from the previously-processed documents.
Each state of the DFA preserves a processing context required to parse the following byte sequences.
Incremental well-formedness checking It reliably checks the well-formedness of the incoming XML documents even though it does not analyze the full XML syntax of those documents.
Deltarser s partial XML processing for di erences checks whether or not the entire XML document is well-formed.
It retains some contextual information needed for that processing.
In the rest of this section,  rst, we introduce the fundamental framework of the automaton used to extract di er-ences from incoming documents and how to incrementally construct the automaton.
We go on to explain how to process the partial results.
Finally, we describe how to e -ciently notify the applications of the SAX events.
The main action of Deltarser is byte-level comparison, which is much faster than actual parsing.
When feeding the actual XML document to this state machine, we have only to compare the byte sequence of each state and the incoming document.
Applying naive byte-level comparison to XML documents gives rise to a serious problem.
We might misinterpret the document because the byte-level representation of some XML fragment is not uniquely interpreted based on the information currently in view of the XML infoset, i.e., the same byte sequence can be interpreted with di erent semantics, which depend on the current context.
Let us look at the following example.
<x:a xmlns:x="ns1"> </x:a> <x:a xmlns:x="ns2"> </x:a> Let us focus on both of the end tags.
Although they match exactly, they have di erent semantics in the XML view.
This is because the namespace declarations are di erent.
In order to address this problem, we must take context into consideration when matching XML documents at the byte level.
We rely on Proposition 1 below to process XML documents.
In preparation for presenting the proposition, we de ne a context, C = (E, N, D, l), which consists of E, a sequence of elements to which it currently belongs; N , all of the name-space de nitions that are currently visible; D, all declared entities of the document; and l   {0, 1, 2, 3, 4, 5}, the location in the document, where l = 0 means the beginning of the document, l = 1 means either a document declaration or a document element has not occurred, l = 2 means a document declaration has occurred but the document element has not, l = 3 means it is now within the document element, l = 4 means it is now after the document element, and l = 5 means the end of the document.
As a special treatment for the uniqueness of initial and  nal states, when l = 0 or l = 5, we de ne all the other components in the context as empty.
This treatment does not cause any problem because at the beginning and the end of the document we do not need any other information than l for that context.
Definition 1.
Let d be an XML document, and p   Integer be the o set in bytes that points to d. By de nition, C(p) is the context of the point p.
Let us consider the following XML document.
<a xmlns:p="xxx"> <b> A </b> </a> In this example, the context at the point of A is E = {a, b}, N = {(pre x = , uri = xxx (cid:48) (cid:48) (cid:48) p (cid:48) )}, D = {}, l = 3.
Proposition 1.
Let ev1 be an event and C1 be a context that ev1 belongs to.
Provided that the document from a certain point, p0, matches with the byte sequence of ev1 for its length and C(p0) is equal to C1, then the parsed event from p0 must be equal to ev1.
Proposition 1 is naturally inferred from the speci cation of
 Strictly speaking, an external entity reference is resolved every time it is about to be parsed, which allows for the possibility that the referred entity might have been changed.
In this paper, however, we do not take this into consideration since it is a very unusual case.
In addition, SOAP does not allow document type declaration.
In order to simplify the character-level interpretation, we assume the character encoding of the document is  stateless .
Both UTF-8 (1 byte is 1 octet) and UTF-16 (1 byte is 2 octets according to ISO/IEC 10646), which are the only encodings XML parsers must support, satisfy this requirement.
Stateless here means that 1) one character directly corresponds to the certain number of bytes; and 2) an XML special character forms a distinct one byte in the encoding.
For other encodings such as ISO/IEC 2022 variants, we can convert them before processing a document (as the normal parsers do).
In addition, such complex encodings are rarely used in XML, and especially for SOAP messages, because such encodings cause many problems for interoperability[3].
Thus, this approach is not a drawback compared to other XML parser implementations.
Automaton In Deltarser, each parse event and its corresponding byte-sequence are stored in one edge of an automaton.
This automaton has two major characteristics: 1) it can directly process byte-level events; and 2) it accepts only well-formed XML documents.
Let us look into how this automaton is constructed.
First, we represent a parsed document as a sequence of events.
Figure 3 shows the static structure of the event classes.
Each event has a one-to-one correspondence to a fragment of the XML document so that it has a byte representation in the actual document.
Note that a context is updated after each event is processed, which consists of a sequence of Start-TagEvent and all of the declared entities.
From the context, we can identify 1) what namespace declarations have been Figure 3: Static structure of an event in a UML diagram.
declared so far; 2) the hierarchy of elements where the event is located; 3) how to resolve entity references; and 4) which part of the document is currently processed.
This information is an integral part of how to construct an automata.
Let us look at the following sample document.
<p:e xmlns:p="urn1">text<x a="ccc" p:b="ddd"/></p:e> This is converted to a sequence of events as follows.
[StartTag: name="e" uri="urn1" {Attributes: } {NSDecls: (prefix="p", uri="urn1")}] [Text: value="text"] [EmptyElementTag: name="x" uri="" {Attributes: (name="a", uri="", value="ccc") (name="b", uri="urn1", value="ddd"}] [EndTag: name="e" uri="urn1"] After converting the document into events, we can construct an automaton by regarding the context itself as its state.
In this step, the same contexts are uni ed into only one state.
The equivalence of contexts is naturally de ned as being all of the items in these context are equal, i.e., all the element in E, all of the declared namespaces in N , all of the entity de nitions in D, and the integer value of l are equal.
We treat the initial and  nal states as special.
The initial state is regarded as the start of the document, i.e., l in its context is must be 0; and the  nal state is regarded as the end of the document, i.e., l in that context must be 5.
Let us look at the process step by step.
First, we de ne all the contexts in the document as states in the automaton.
Next, by tracking the sequence of events that come from the actual document, we can connect these states with the event as edges of the automaton.
In this phase, events that have the same byte representations are regarded as equal, and we do not add duplicated connections with states, because if byte representations and contexts are equal, then the interpreted events are also equal.
Finally, we mark the states where l in the state s context is 0 and 5 as initial and  nal states, respectively.
The above example can be represented as shown in Figure 4.
Although Deltarser compares an incoming document at byte level, it identi es the di erences at the event-level, i.e., whenever it  nds any discrepancies at the byte level, it interprets them as event-level di erences.
Figure 4: Example directed graph that corresponds to a parsed document.
<p:e xmlns:p="urn1">text<y/></p:e> Figure 5: A sample XML document.
Now let us see how a similar document is actually processed.
We suppose that we have the state machine shown in Figure 4 beforehand, and process the sample document shown in Figure 5.
First, we set the current state to the initial state and the current position to the head of the incoming document.
Since the only possible next state is <p:e xmlns:p="urn1">, we compare its byte sequence with the sample document from the current position.
These are exactly the same until the end of the state s byte sequence, and therefore, we move the current state to the next state, E = {urn1#e}, N = {(pre x =(cid:48)(cid:48) p(cid:48)(cid:48), uri =(cid:48)(cid:48) urn1(cid:48)(cid:48))}, D = {}, l = 3, and the current position to the corresponding position.
At this point, the possible next events are text, <x a="ccc" p:b="ddd"/>, or </p:e>.
In order to e ciently compare these with the incoming document, we use a binary search technique.
Provided that the byte sequence of these events was sorted beforehand, we can quickly  nd the appropriate state.
In this case, we select text as the accepted event, and stay in the same state.
Our parser incrementally modi es the original DFA by adding new events made from the byte sequence of a new document when it fails to match the incoming byte sequence with the DFA.
Let us consider this situation by continuing with the example.
On continuing, the possible next events are still the same, text, <x a="ccc" p:b="ddd"/>, or </p:e>, neither of which matches with the incoming documents byte-sequence, <y/>.
Therefore we cannot move to any next state in the state machine.
At this point, we must partially parse the document from the last matched position.
In this example, we parse from the position immediately after text.
Hence, we parse the document from <y/></p:e> with only one event by using the information about the last matched state.
Notice that we also have to check that the parsed result is well-formed.
In this case, we obtain a new event: [EmptyElementTag: name="y" uri="" {Attributes: }] After parsing it, we are able to incrementally add a new edge.
In this example, the context is still the same even after the EmptyElementTag event.
Thus, we only have to add a connection to the same state, as shown in Figure 6.
This process eventually causes a new bifurcation in the state machine, but it should be stressed that this bifurcation leaves the automaton deterministic, because if these byte sequences exactly match with each other, these events must -byte-sequenceEvent-textTextEventPIEventEndTagEventStartTagEventEmptyTagEvent-nameTagEvent-attributesTagWithAttributesEvent-name-valueAttribute1*DocTypeEventCommentEventNameSpaceDecl1*-defined-entitiesContext*11*EntityRefEvent*1<p:e xmlns:p="urn1"> E={urn1#e}, N={(prefix="p", uri="urn1")}, D={}, l=3</p:e><x a="ccc" p:b="ddd"/> text Figure 6: Adding a new edge as a parse event.
be exactly matching under the same context so that we do not have to add a new edge.
In practice, since adding edges inevitably consumes some memory, we should limit the number of edges for one state (i.e. a context).
In particular, text events, processor instruction events, or comment events all lack  patterns,  so that many of those are not worth remembering.
Our Deltarser can limit the number of text events for each context to a certain  xed number, denoted by Mtext.
Next, we can continue to process the rest of the document by byte matching.
The next byte-sequence is </p:e> and it exactly matches an event in the state machine.
Thus, we can move to the  nal state.
Since the document ends here, we have  nished the processing.
It is clear that we can e ciently process the document with byte matching and incrementally process the document by following the above procedure.
However, is this procedure safe?
In other word, does it really ensure accepting only the well-formed documents?
We discuss this question in the next subsection.
Let us  rst state the conclusion.
The automata constructed by the above procedure accepts a document only if it is well-formed.
We call such automata well-formed au-tomata.
This characteristic is essential for the safe processing.
In addition, suppose that the partial parser accepts all well-formed documents, and then the automata is extended to accept these documents.
A formal de nition of a well-formed automaton is that all of the paths in the automaton from the initial state to the  nal state must correspond to a well-formed document.
Whenever the automaton remains well-formed even after it is extended due to incremental processing, then the processed document is certain to be well-formed by de nition, because it corresponds to a valid path from the resulting well-formed automaton.
We do not give rigorous proof here, but sketch why the above procedure assures the automaton remains well-formed.
Context is a key concept in the proof.
Let us suppose we have a well-formed automaton beforehand, and the partial parser adds some events as edges in the automaton, and then we obtain a new distinct path, which consists of the sequence of contexts, C1, ..., Cn, and C1 and Cn must exist in the previous automaton.
This condition is guaranteed by the fact that there is only one initial and one  nal state in a well-formed automaton, so we will share at least the initial and the  nal state for every well-formed document.
By Proposition 1, the interpretation of the incoming byte sequence as XML at C1 is always the same.
Therefore the partial parser can check whether or not the incoming byte sequence at the point of C1 is well-formed, because all of the required information to check it (other than the incoming byte sequence itself) is completely de ned within the context.
Strictly speaking, to prove this statement, we have to check all of the well-formedness rules in the speci cation of XML [5, 4].
However, since we do not need any information from farther ahead in the document during parsing to check the well-formedness (according to the design of XML), we can give the well-de ned context anyway.
Since, according to our de nition, the context has all of the information that a ects the interpretations of incoming byte-sequences, it can always be mapped to (some other) well-de ned context.
Therefore, we can also regard our de nition as a well-de ned one.
Suppose the automaton is still well-formed after adding C1, then we create a new context, C2, and proceed to parse the next incoming byte sequence, and then check if it is well-formed in C2.
Inductively, we can reach Cn that comes from the previous well-formed automaton, and after Cn, since the interpretation of the byte sequence is exactly the same, all of the paths after it must correspond to a part of a well-formed automaton.
Therefore all of the new paths in the extended automaton correspond to well-formed documents.
As for the  rst well-formed automaton, we can construct it by simply connecting from the initial state to the  nal state with the empty element tag event of the document element.
Therefore, the above procedure insures the automaton is well-formed.
When the incoming byte-sequence does not match with any events in the state, we have to partially parse the document.
We require a context in order to parse the document from an intermediate point, which is available in each state of the state machine.
The partial parser parses the byte-sequence for one event and updates the context if required.
The partial parser has few disadvantages compared to the typical non-partial parsers.
We can instantly continue to parse a document since the context has all of the essential information.
Note that we have to provide a special treatment for general entity references.
According to the XML speci cation Section 4.3.2 [5], if all of the entities are well-formed, each logical and physical structure must be properly nested.
Therefore we can regard the replacement text of such an entity reference as one event.
That is, it does not alter the context after the entity reference if it is well-formed.
Eventually, the partial parser only has to treat an entity reference as a distinct event, and check that its replacement text follows the constraints of well-formedness.
While processing an XML document, Deltarser sends SAX events to an application as its output.
To minimize the computation cost for reuse by avoiding object construction as much as possible, it prepares SAX event objects in their  nal form when remembering the processing results to avoid object construction.
For example, a TagWithAttributesEvent instance has an object that implements the Attribute interface required for SAX events.
Since this object is immutable, we can safely reuse it without duplicating it.
StartTagEvent and End-TagEvent have arrays for a startPrefixMapping SAX event and a endPrefixMapping SAX event, respectively, both of which are reusable.
In contrast, we cannot reuse character <p:e xmlns:p="urn1"> E={urn1#e}, N={(prefix="p", uri="urn1")}, D={}, l=3</p:e><x a="ccc" p:b="ddd"/> text <y/>arrays in TextEvent for characters SAX events because applications may alter them.
Thus, Deltarser duplicates them to send to the applications.
This section describes a performance evaluation of our prototype implementation.
First, we conducted some fundamental performance analysis experiments.
Then we applied it to real-world application scenarios of XML parsing for Web services middleware.
We did performance comparisons between our parser and two other XML parsers: Apache Xerces [27] and Piccolo [30].
Xerces is one of the most popular parsers and Piccolo is regarded as one of the fastest SAX parsers.
The experimental environment was using Sun Hotspot Server VM 1.4.2 on Linux Kernel 2.4.18-14, running on an IBM IntelliStation M Pro 6850-60J (Intel Xeon 2.4GHz CPU with 512KB cache) with 2GB of memory.
In this experiment, we set the number of remembered text events in each context (de ned as Mtext in Section 3.4) to
 texts fall into two classes, those that never change (so one string is enough) and those that change almost every time they appear (so there is no bene t from saving them).
First, a fundamental performance analysis was conducted by comparing the total elapsed time with the other XML parsers in two cases.
In the  rst case, the incoming document is highly similar to the previously parsed document, so the parser can skip the parsing and generation of SAX events for a large portion of the XML message.
In contrast, the second case is when the incoming document is completely di erent from the previously parsed documents so that the performance of our parser includes the total of the time for parsing, for creating new automata states, and for generating the SAX events.
We excluded the compilation time of the JIT compiler from the measurements by running the benchmarking program for 10,000 iterations before the measurements.
In Web Service middleware, it is expected that the stable running state continues unchanged for a long time.
Therefore, it is more appropriate to measure the execution time after the JIT compiler has completely compiled the code.
Then we measure the total time to perform 10,000 iterations of parsing XML documents to estimate the average time for parsing one document.
The Cost of Matching In this way we can measure the performance when a large number of XML documents with similar structures are arriving.
In other words, all of the start tags and end tags are matched, but the text content may vary.
We performed the experiment in two cases: the case where all of the text content is the same, and the case where the text content is always di erent.
For Web Services, the structure of the request XML documents is de ned in WSDL.
Therefore, request documents for the same operation are very similar if the documents are generated by the same implementation.
For example, requests for a certain search operation are likely to di er only in the text content.
Hence, in this experiment, we changed just the text content for the incoming documents.
Figure 7: Average elapsed times for parsing an XML document.
Figure 7 shows the results of our experiment.
In this experiment, some XML documents which include Google search responses are used.
We generated some XML documents of various sizes, from 1 KB to 64 KB, by changing the number of search results.
Then we measured the elapsed time for 10,000 iterations, and the average time for one parsing is shown in Figure 7.
 Deltarser (complete match)  and  Deltarser (element only match)  show the complete match and the case when all of text content has changed, respectively.
When our parser receives a similar document, our parser is approximately 90% faster than Xerces and 70% faster than Piccolo.
The Cost of Creating New Automaton Paths Comparing to partially parsing text content, parsing elements is costly in Deltarser, since this creates new states in the DFA.
These costs are in proportion to the number of elements that must be partially parsed.
In order to estimate the cost of partial parsing involving state creation in a DFA, we measured the elapsed time for applying partial parsing to a full XML document.
We used
 message used in the previous experiment.
We also wanted to estimate in how many times Deltarser can compensate for the penalty of partial parsing by processing similar documents.
Therefore we parsed many structurally similar documents with di erent text contents.
This parsing process is identical to  Deltarser (element only match)  in the previous experiments.
Figure 8 shows the cumulative parsing times for a group of similar documents.
The x-axis is the number of similar XML documents that were parsed.
For partially parsing and creating full states for an XML document, it takes 2.32 ms, whereas Xerces parsing takes
 that Deltarser overtakes Piccolo with regard to the total parsing time before 50 similar documents are processed.
Memory Usage We also evaluated memory usage for the number of memorized XML documents.
For this experiment, we temporarily modi ed our parser to force the automaton to store even the same XML document as a new path.
Then we measured the memory usage when it stored many XML documents.
Figure 9 shows the memory usage when many 1 KB and 5 KB XML documents are stored.
The result suggests that the memory consumption is acceptable in such an environment.
(cid:1)(cid:2)(cid:1)(cid:3)(cid:1)(cid:4)(cid:1)(cid:5)(cid:1)(cid:6)(cid:1)(cid:7)(cid:1)(cid:1)(cid:2)(cid:1)(cid:3)(cid:1)(cid:4)(cid:1)(cid:5)(cid:1)(cid:6)(cid:1)(cid:7)(cid:1)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:13)(cid:16)(cid:20)(cid:21)(cid:22)(cid:23)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:3)(cid:7)(cid:8)(cid:9)(cid:10)(cid:3)(cid:7)(cid:11)(cid:12)(cid:4)(cid:7)(cid:13)(cid:7)(cid:14)(cid:5)(cid:4)(cid:15)(cid:9)(cid:16)(cid:6)(cid:7)(cid:17)(cid:10)(cid:15)(cid:18)(cid:24)(cid:13)(cid:25)(cid:10)(cid:13)(cid:26)(cid:27)(cid:18)(cid:10)(cid:10)(cid:9)(cid:28)(cid:9)(cid:16)(cid:8)(cid:13)(cid:28)(cid:15)(cid:29)(cid:25)(cid:26)(cid:13)(cid:25)(cid:16)(cid:20)(cid:13)(cid:28)(cid:13)(cid:12)(cid:13)(cid:14)(cid:15)(cid:16)(cid:9)(cid:14)(cid:28)(cid:30)(cid:16)(cid:12)(cid:29)(cid:15)(cid:10)(cid:31)(cid:23)(cid:8)(cid:13)(cid:28)(cid:15)(cid:29)(cid:25)(cid:26)(cid:13)(cid:25)(cid:16)(cid:20)(cid:10)(cid:9)(cid:12) (cid:28)(cid:13)(cid:15)(cid:13)(cid:16)(cid:12)(cid:29)(cid:15)(cid:10)(cid:31)(cid:23)tends to receive di erent formats of incoming SOAP messages from various clients that serialize the messages with a variety of SOAP implementations such as .NET, Axis, and so forth.
Meanwhile, the client tends to send its request to only one SOAP container and then receives XML messages in a speci c format serialized by a single serializer implementation.
For testing the server-side scenario, mixed messages of the three request operations were used.
We assumed that the searching service is used more frequently (60%) than the other services (20% for each).
For the client-side scenario, our experiment used only response messages for the searching service.
This client scenario is reasonable since a client does not need to use all of the services.
Message Serializers We used two serializer implementations to generate SOAP messages: Apache Axis and Microsoft .NET Framework.
These two serializers generate SOAP messages with di erent namespace pre xes and di erent white spaces for identical operations.
We provided two sets of messages to parse.
The  rst set includes only the Axis version of the request messages.
It results in three  di erent  message groups, which would make Deltarser to generate three distinct paths of state transitions in its DFA.
The second set includes both Axis and .Net versions, resulting in six di erent message groups.
We experimented with two sets of messages on the server-side scenario to see the impact of the numbers of serial-izer variations.
For the client-side scenario, we only experimented with the  rst, Axis-only set of messages.
Parameter Values The parameter values of the three operations in the request and response messages may vary for each message.
For example, the query keyword parameter value varies frequently while the encoding parameter value remains in UTF-8.
We assumed that 4/10 of the parameter values in the searching operation request vary frequently and that all of the parameter values in the other two operations requests vary frequently.
(A total of 57% of the parameter values vary in the server-side scenario.)
Similarly, we assumed that 11/18 of the parameter values in the search responses varied frequently.
(A total of 61% of the parameter values varied in the client-side scenario.)
Experimental Results Figure 10 shows the throughputs of the parsers in the steady state for each scenario.
For reference and to see the best and worst cases of parameter value variability, we measured unrealistic message scenarios for  Deltarser (element only match)  and  Deltarser (complete match) , using the same idea as in Section 4.1.
Also for reference, we measured two unrealistic server-side scenarios of  Server-side (.Net)  and  Server-side (Axis) .
Each of these scenarios uses only single-vender messages.
In the server-side scenarios of  Server-side (.NET and Axis) , Deltarser parses 106% faster than Xerces and 35% faster than Piccolo.
In the client-side scenario, Deltarser parses 126% faster than Xerces and 73% faster than Piccolo.
In addition, we do not see any signi cant negative e ects from the increased number of serializer implementation variations.
Figure 8: Cumulative parsing costs for a group of similar documents.
Figure 9: Memory consumption for storing documents.
A key assumption is that our parser is intended for server-side machines with relatively large memories.
We believe that the result in Figure 9 shows that the memory consumption is acceptable in such an environment.
Even though 64 MB of heap memory are used for 800 documents, it should be rare that one parser needs to handle hundreds of di erent kinds of XML documents without any similarities.
However it would be good to have a function for discarding relatively ine ective automaton paths.
We could employ some well-known cache replacement algorithm such as the LRU (Least Recently Used) algorithm to do so.
We evaluated Deltarser through scenarios based on a real-world application, the Google Web APIs [14].
This is a Web service that allows software developers to access a set of services provided by Google via the SOAP and WSDL standards.
We provided scenarios for server-side and client-side services.
The Google Web Services Google Web Services has three services: searching, returning a cached page, and spelling suggestions.
The corresponding request operations received by the servers are doGoogle-Search, doGetCachedPage, and doSpellingSuggestion, and the corresponding response operations received by the clients are doGoogleSearchResponse, doGetCachedPageResponse, and doSpellingSuggestionResponse, respectively.
Note that the properties of the incoming SOAP messages are di erent between the server side and the client side as regards Deltarser performance.
In this scenario, a server  	          !
"#$ %&'(&)*+,-.-           	               	  

 The problem of computing similarities between two  les has been studied extensively.
E cient di erence extraction implementation is available in many programs like UNIX s di  command.
However, it is not straightforward to apply it for computing the similarity of a message against multiple messages.
Moreover, we need to  nd similar parts extracted from multiple messages, rather than  nding a single, most similar  le.
Manber studied how to e ciently  nd similar  les in a large  le system [21] and presented a tool called sif.
While our parser directly remembers the previously-processed documents in a DFA, sif partitions  les into small parts and then remembers their hash values computed based on their textual representation.
These hash values are used to look up small parts of  les in the  le system which is identical to a small part of a newly-given  le.
The purpose of these hash values is to estimate the overall similarity of each  le in the  le system to the new  le.
Deltarser, however, must take account of processing context for the equality of two document fragments in addition to textual representation.
Though a similar hashing technique is used for looking up identical contexts in Deltarser, it just compares two byte sequences for looking up identical document fragments.
E cient network packet  lters/classi ers [29, 2] often use pattern matching in order to determine appropriate  lters applied to incoming packets.
Since packet formats are not verbose, they do not need to optimize for sender-speci c packet formats.
XML schema-based optimization techniques [20, 8, 9] correspond to the packet  ltering techniques in terms of XML processing because packet formats can be regarded as sche-mas for packets.
Both do not optimize for variable wire representation of XML messages or network packets.
Techniques for compressing a data object like a  le relative to another object is called delta-encoding [1, 19], and have been applied to network data transmission [23, 7, 26, 12], just to mention a few.
Since delta-encoded XML documents have explicit di erential information for previously-received documents, it is more straightforward to reuse the results of previous processing.
However, in order to use delta-encoding, document producers and consumers must make some agreements with each other for encoding methods, which are application spe-ci c.
Without standard speci cations and recommendations for the encoding format, the original content of XML documents cannot extract from the encoded documents.
Such XML documents are no more interoperable in terms of the standard speci cations.
This paper proposed an XML parser named Deltarser, which has a novel mechanism for e ciently processing XML documents in most cases of XML-based infrastructural mid-dleware like Web Services application servers.
Given a new Figure 10: Average throughputs for 100,000 documents in the server/client-side scenarios.
Figure 11: Elapsed times for parsing XML messages in the server-side scenario.
Figure 11 shows the elapsed times for parsing the XML messages before the parsers get to their steady state in the server-side scenarios.
Since the client-side scenario also shows a similar pattern, we did not present those results.
Figure 12 shows the consumed heap memory size in the server-side scenarios.
We observed an approximately 50 KB increase for additional serializer implementation variations by comparing  Deltarser (.NET and Axis)  to  Deltarser (.NET)  or  Deltarser (Axis) .
In our experiments, the creation time for new automaton paths is included in the runtime execution time.
However the cost of creation is relatively large.
It is possible to exclude this overhead from the runtime execution time.
For example, we can update the automaton in a separate thread process, or in a batched process at a time of low system load.
Figure 12: Memory usage in the server-side scenario.
                           


  (cid:1)(cid:2)(cid:3)(cid:4)(cid:2)(cid:5)(cid:6)(cid:7)(cid:4)(cid:4)(cid:8)(cid:9)(cid:8)(cid:10)(cid:11)(cid:2)(cid:9)(cid:12)(cid:13)(cid:3)(cid:5)(cid:2)(cid:3)                      !
"#$%&'()*,+-/.0,12345670

 89**+3456 89**+-.06 89**+345:9;<-/.06XML document in a byte sequence, the XML parser proposed in this paper usually does not analyze the XML syntax but just compares the byte sequences with those which have already been processed.
It reuses the processed results stored before.
The SAX implementation of our parser complies with the JSR 63 standard, and the Java API for XML Processing (JAXP) 1.1 speci cation.
In an experiment with a message for Google Web Services, it parses 126% faster than Apache Xerces and 73% faster than Piccolo at its best.
