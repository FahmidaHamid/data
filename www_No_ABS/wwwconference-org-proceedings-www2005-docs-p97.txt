In the last year there has been a surge of interest about news engines, i.e.
software tools for gathering, indexing, searching, clustering and delivering personalized news information to Web users.
According to a recent survey made by Nielsen NetRatings [20, 24], news browsing and searching is one of the most important Internet activities with more than 28 millions of active U.S. users in October 2004 (see Figure 1).
For instance, Yahoo!
News had an audience which is roughly the half of Yahoo!
Web Search, a third of Google Web Search and a bit more than AOL Web Search.
This is surprising enough if we consider that, for instance, Yahoo News had an audience of about 13 millions users in  the 
 coverage as it provides a di erent perspective and greater depth of information - statistics, pictures, interactive maps, streaming video, and analyst comments,  said Peter Steyn of Nielsen/Netrating.
Certainly, recent events such as SARS, War in Iraq, Terrorism Alerts and other similar dramatic events contributed to di use the use of online news search engines.
The huge amount of news articles available online re ects the users  need for a plurality of information and opinions.
News engines are, then, a direct link to fresh and un ltered information.
Figure 1: Comparing News and Web Search Engines (October 2004, Nielsen/Netratings).
The commercial scenario.
Many commercial news engines are already available such as Google News [22], Yahoo News [30], MSNBot [23], Find-ory [21] and NewsInEssence [26].
Google News retrieves news information by more than 4,000 sources, organizes it in categories and automatically builds a page with the most important news articles for each category.
Besides, it clusters similar pieces of news.
Yahoo news runs analogous services on more than 5,000 sources.
Microsoft recently announced its NewsBot, a news engine that provides personalized news browsing according to di erent pro les built for each user.
Findory proposes a similar personalized service, which relies on patent pending algorithms.
Another important news engine is NewsInEssence, which clusters and summarizes similar news articles.
A complete list of commercial news engine is given in [29].
There is no public available information about the way in which these commercial search engines rank news articles.
Nevertheless, an extensive testing performed by the authors of this paper on these systems showed anecdotal evidences that they take in account several criteria such as freshness, news sources authoritativeness and replications/aggregation of pieces of news.
In this paper we introduce a framework which also exploits these criteria.
The scienti c scenario.
Despite this great variety of commercial solutions for news search engines, we found just a few papers on this subject [4,
 summarizing clusters of related news articles from multiple sources on the Web.
The system aims to generate automatically summaries of news events by using a centroid based summarization technique.
It considers salient terms forming the cluster of related documents, and uses these terms to construct a cluster summary.
QCS [7] is a software tool and development framework for streamlined IR.
The system matches a query to relevant documents, clusters the resulting subset of documents by topic, and produces a single summary for each topic.
The main goal of the above works is to create summaries of clustered news articles.
In [3] a topic mining framework for news data stream is proposed.
In [10] the authors study the problem of  nding news articles on the web that are relevant to the ongoing stream of TV broadcast news.
In [6] a tool to automatically extracting news from Web sites is proposed.
In [8] is proposed and analyzed NewsJunkie, a system that personalizes news articles for users by identifying the novelty of stories in the context of stories users have already reviewed.
Mannilla et al. in [13] introduced the problem of  nding frequent episodes in event sequences, subject to observation-window constrain, where an episode is de ned as a partially ordered collections of events, and can be represented as a directed acyclic graph.
In [2] Atallah et al. proposed an extension of [13] to rank a collection of episodes according to their signi cance.
We remark that the concept of episode does not take into account the entities which produced the episode itself and how episodes aggregate each others.
In this paper, we show that these are crucial features for ranking news stories.
The news engine.
comeToMyHead is an academic news search engine available at http://newsengine.di.unipi.it/ for gathering, indexing, searching, clustering and delivering personalized news information to Web users.
This engine is a running software prototype developed by our research group to investigate many di erent aspects of News engines.
In the context of this paper, we have used this search engine to gather a collection of news articles from many di erent sources over a period of two months.
Our experimental settings are based on the news data collected by comeToMyHead in two months by more than 2000 news sources classi ed in 13 di erent categories, and consists of about 300,000 pieces of news.
Besides, we are currently integrating the ranking strategies proposed in this paper into the production version of the engine.
Figure 2: The comeToMyHead News Engine.
In this paper we discuss the problem of ranking news sources and a stream of news information evolving during the time.
To the best of our knowledge this is the  rst academic paper on this subject, hence we do not have the possibility to compare our results with other ranking methods.
For this reason we had to formalize the problem describing a number of desirable properties we ask to our ranking scheme (Section 3) and to introduce a suitable model for describing interactions between articles and news sources (Section 4).
The ranking algorithm is obtained introducing progressively a number of constraints to match the requested properties and is validated on two intuitive limit cases, which allows us to rule out more intuitive approaches (Section 5).
The  nal algorithm is described in Section 6.
It works online by ranking each piece of news at the time of its emission.
It can also in uence the rank of the news sources.
The complexity of our method is linear with the number of news articles still of interest at a particular time of observation.
Our ranking scheme depends on two parameters,   accounting for the decay rate of freshness of news articles, and   which gives us the amount of source s rank we want to transfer to each posted piece of news.
We studied the sensitivity of the ranks obtained varying these parameters and we saw that our algorithm is robust, in the sense that the correlation between ranks remains high changing the decay rule and the parameter  .
A large experimentation was performed, and in Section 7 we present some of these results.
The results obtained ranking news articles and news sources for each category con rm the ability of our method to recognize the most authoritative sources and to assign an high rank to important pieces of news.
The algorithms proposed in this paper aim to a general ranking schema based on unbiased factors rather then personal consideration like that topic of interest for the user or even ideology.
Like in web search ranking scheme, it is possible to extend our approach introducing a personalization parameter accounting for the personal taste of the user.
Ranking news articles is a rather di erent task than ranking Web pages.
From one side, we can expect a smaller amount of spam since news stories come from controlled sources.
When a piece of news is issued, we can have two di erent scenarios: the news article can be completely independent on the already published stories, or can be aggregated to a (set of) news articles previously posted.
Anyway, we stress that, by de nition, a news article is a fresh piece of information.
For this reason, when a news article is posted there is almost no HTML link pointing to it.
Therefore, HTML link based analysis techniques, such as PageRank [15], can produce a limited bene t for news ranking.
In Section 4 we propose a model which exploits a virtual linking relationship between pieces of news and news sources based both on the news posting process and on the natural aggregation by topics between di erent news stories.
Now, we discuss some desirable properties of ranking algorithms for news articles and news sources before presenting the algorithms designed to match these requests.
Property P1: Ranking for News posting and News sources.
The algorithms should assign a separate rank for news articles and news sources.
Property P2: Important News articles are Clustered.
An important news story n is probably (partially) replicated by many sources.
For instance, consider a news article n originated by a press agency.
The measure of its importance is also expressed by the number of di erent online newspapers which replicate n or extract parts of text from n. The phenomenon of citing stories released by other sources is common in the context of (Web) journals.
From the news engine point of view, this means that the (weighted) size of the cluster formed around n is a measure of its importance.
Property P3: Mutual Reinforcement between News Articles and News Sources.
We can assign di erent importance to di erent news sources according to the importance of the news articles they produce.
So that, a piece of news coming from  Washington Post  can be more authoritative than a similar article coming from say  ACME press , since  Washington Post  is known for producing good stories.
Property P4: Time awareness.
The importance of a piece of news changes over the time.
We are dealing with a stream of information where a fresh news story should be considered more important than an old one.
Property P5: Online processing.
We require that the time and space complexity of the ranking algorithm allows online processing, i.e. at some time the complexity can depend on the mean amount of news articles arriving but not on the time since the observation started.
In Section 6 we de ne an algorithm for ranking news articles and news sources which match the above properties.
The algorithm is progressively designed ruling out easier algorithms which do not satisfy some of the above requirements.
News posting can be thought as a continuous stream process.
For dealing with it, we can exploit a window of observation.
A  rst way to analyze the stream, is to have a window of  xed size.
In this way the maximum size of observed data is constant, but we can miss the opportunity to discover temporal relationship between news articles posted at a time not covered by the current window.
A second way is to use an unbounded time window of observation.
Of course, by adopting this method the size of the observed data increases with the time.
This is a typical situation with data streaming problems where the  ow of information is so overwhelming that it is unfeasible even to store the data or to perform a single (or more than one) scan operation(s) over the data (see [14] and references therein).
This is particularly true for information  ows, since di erent news sources can post independently many stream of news articles.
In Section 5.2 we propose a solution to this problem.
This solution handles the data stream of news information with no prede ned time window of observation.
The solution takes in account a particular decay function associated to any given piece of news.
The algorithms proposed turn out to be tunable, in the sense that we can change the decay parameters according to the categories in which the news posting is classi ed.
In the following, we introduce the model which characterizes news articles and news sources.
Given a news stream, a set of news sources, and  xing a time window  , the news creation process can be represented by means of a undi-rected graph G  = (V, E) where V = S   N and S are the nodes representing the news sources, while N are the nodes representing the news stream seen in the time window  . Analogously, the set of edges E is partitioned in two disjoint sets E1 and E2.
E1 is the set of undirected edges between S and N .
It represents the news creation process, E2 is the set of undirected edges with both endpoints in N and it represents the results of the clustering process which allows to connect similar pieces of news.
The edges in E2 can be annotated with weights which represent the similarity between two pieces of news.
The nodes in S  cover  those in N , i.e.,  n   N,  s   S such that (s, n)   E1.
Figure 3: News Ranking Graph.
To satisfy the property (P2), we de ne a similarity measure among the news articles, which depends on the clustering algorithm chosen and accounts for the similarity among the news stories.
Given two nodes ni and nj we de ne the continuous similarity measure as a real value  ij   [0, 1], with the meaning that  ij is close to 1 if ni is similar to nj.
A simpli ed version provides a discrete similarity measure, which holds 1 if the two news postings are exactly the same (in other words, they are mirrored) and 0 if they are di erent.
are naive approaches that one has to rule out before proposing more sophisticated algorithms.
In particular, these methods do not deal with the news  ow as a data stream, but assumes that they are available as a static data set.
In the next section we introduce algorithms which overcome the limit of those given here.
Let A be the (weighted) adjacency matrix associated with G .
We can attribute an identi er to the nodes in G  so that any source precedes the pieces of news.
We de ne the matrix


   , where B refers to edges from sources to news articles, and bij = 1 i  the source si emitted article nj and   is the similarity matrix.
Assuming one can learn similarity of sources, the matrix A can be modi ed in the upper-left corner incorporating a submatrix taking into account a source-source information.
An important parameter of a news engine is the amount of articles emitted in a short period of time from all the sources in a given category.
This quantity, denoted by news ow(t, c) for time t and category c, is subject to drastic variation over the time as a consequence of great resonance events (for instance, during the  rst days of November 2004 we had a peak in news ow for category  U.S.  due to the Presidential Election).
We remark that this model describes a framework where one can plugin di erent data stream clustering algorithms (see [1, 9] and the references therein) for creating and weighting the set of edges E2.
Starting from the above model, in Section 5 we propose some ranking algorithms which progressively satisfy the properties described in Section 3, and  t the general model for representing news articles and news sources described here.
To evaluate the consistence of the algorithms presented in this section, we consider some limit cases for which the algorithms should show a reasonable behavior.
These limit cases allow us to re ne the algorithms and match the properties described in Section 3.
They are: LC1: A unique source s1 emits a stream of independent news articles with average emission rate 1/ .
We expect the source to have a stationary mean value rank   independent of the time and the size of the observation window  .   should be an increasing function in
 LC2: Two news sources s1, s2, where s1 produces a stream of independent news articles with average rate 1/ , and s2 re-posting the same news stream generated by s1 with a given average delay.
Essentially, the source s2 is a mirror of s1.
Hence, the two sources should have a similar rank.
Any algorithm described in this section satis es only a subset of the properties described in Section 3.
Indeed, they Algorithm NTA1 The naive approach is that a news source has a rank proportional to the number of pieces of news it generates and, conversely, that a news article should rank high if there are many other news stories close to it.
Formally, denoting by r = [rS, rN ]T the vector of sources and news ranks, we can compute them as r = Au, where u = [uS, uN ]T is the vector with all entries equal to one.
Given the structure of A, this means that   rS = BuN , and rN = BT uS +   uN = uS +   uN , that is each source receives a rank equal to the number of news articles emitted by that source, while the single piece of news has a rank proportional to the number of similar news articles.
This algorithm shows a bad behavior in the limit case LC1.
Indeed, the rank rs1 of a unique news source s1, will increase unbounded with the number of observed news articles.
Besides, algorithm NTA1 satis es the properties (P1) and (P2) but not (P3), (P4) and (P5).
Algorithm NTA2 The second algorithm exploits the mutual reinforcement property between news articles and news sources similarly to the way HITS algorithm [12] identi es Web hubs and authorities.
Let us consider the  xed point equation From the block structure of A we get r = Ar.
  rS = BrN (1) rN = BT rS +   rN .
From equation (1), it turns out that in order to have a nonzero solution, r should be a right eigenvector corresponding to an eigenvalue equal to 1, but this is not true in general.
In particular, this does not hold for case LC1 and r = 0 is the only solution of (1).
This algorithm is also not stream oriented like the NTA1.
A major di erence with NTA1 is that NTA2 satisfy the properties (P1), (P2) and (P3).
It is easy to show that the class of non time-aware algorithms do not satisfy at least one of the limit cases de ned in Section 5.
Moreover, the  xed time-window scheme can not explore precise temporal information within a window, and misses the opportunity to discover temporal relationship between news articles released at a time not covered by the current window.
To deal with a news data stream we have to design time-aware mechanisms, which do not use  xed time observation windows over the  ow of information.
The key idea is that the importance of a piece of news is strictly related to the time of his emission.
Hence, we model this phenomenon introducing a parameter   which accounts for the decay of  freshness  of the news story.
This   depends on the category to which the news article belongs.
For instance, it is usually a good idea to consider sport news decaying more rapidly than health news.
We denote by R(n, t) the rank of news article n at time t, and analogously, R(s, t) is the rank of source s at time t.
Moreover, by S(ni) = sk we mean that ni has been posted by source sk.
Decay rule: We adopt the following exponential decay rule for the rank of ni which has been released at time ti: R(ni, t) = e  (t ti)R(ni, ti), t > ti.
(2) The value   is obtained from the half-life decay time  , that is the time required by the rank to halve its value, with the relation e  = 1
 parameter  , expressed in hours, instead of  .
Besides, we discuss how to obtain the formulation of an e ective algorithm for ranking news articles and sources.
We show that naive time-aware algorithms show a bad behavior in many cases, then we re ne them in order to have a complete control of the ranking process.
Algorithms TA1 The  rst class of time-aware algorithms assigns to a news source the sum of the ranks of the news information generated by that source in the past, according to the above decay rule.
The algorithms belonging to this class di ers from each other only for the way of ranking each news article at the time of its  rst posting.
Setting to one the rank of a news article at the time of its initial posting, we have S(ni)=sk R(ni, t) (3)   R(sk, t) =P R(ni, ti) = 1.
Assuming that the source sk did not post any news information in the interval [t, t +   ], we have that the variation of ranks after an elapsed time of   is described by the two following relations R(ni, t +   ) = e R(sk, t +   ) = e   R(ni, t),   R(sk, t), t   ti (4) We note that this algorithm attenuates the e ect of previously issued news articles, and it meets the limit case LC1.
Indeed, assuming case LC1 is satis ed, for the stationary mean value   of the rank of s1, we have   =   + 1, (5) where   = e .
From (5) we derive the mean value of the rank   = 1/(1    ) in the case of a single source emitting independent news articles with average rate 1/ .
We point out that this algorithm satis es Properties (P1), (P4) and (P5) but it does not satisfy (P3) since the rank attributed to a news article does not depend on the rank of the source which posted it.
For accounting Property (P3), we can still consider equation (3), changing the rank attributed to a piece of news when it is released.
For instance, we can de ne the rank of a news story as a portion of the rank of its source just an instant before emitting it.
The algorithm becomes   R(sk, t) =P R(ni, ti) = c lim 0+ R(S(ni), ti     ), S(ni)=sk R(ni, t), where 0 < c < 1.
As a starting point we assume R(sk, t0) = 1, however, with any nonzero initial conditions the limit case LC1 has again a bad behavior.
There is no stationary mean value of the rank even for a single source s1 emitting a stream of independent news articles.
In fact, assuming   to be the stationary mean value of R(s, t), we have   =   + c  , which cannot be solved for   6= 0.
To solve the problem, we change again the starting point in (3) to smooth the in uence of the news source on the rank of the news articles.
Let us set     R(ni, ti) = lim  0+ R (S(ni), ti     ) , 0 <   < 1.
The parameter   is similar to the magic   accounting for the random jump in Google s PageRank [15].
In fact, as for the random jump probability, the presence of   is here motivated both by a mathematical and a practical reason.
From a mathematical view point, the  xed point equation involving the sources, has a non null solution.
From a practical point of view, by changing   we can tune how much the arrival of a single fresh piece of news can increase the rank of a news source.
In fact, let ti 1 be the time of emission of the previous news article from source sk, and let ti be the time of release of ni by sk.
If in the interval (ti 1, ti) no article has been issued by sk, we have R(sk, ti) = e  (ti ti 1)R(sk, ti 1) + R(sk, ti 1) .
For the limit case LC1 the  xed point equation now becomes   =   + ( )        1 which has the solution   = can also deal very easily with the limit case LC2.
1 
 Algorithm TA2 We have seen that the algorithms in the class TA1 satisfy the limit cases and the Properties (P1), (P3), (P4) and (P5).
However, it does not satisfy the Property (P2) since the rank of a news article is not related to the rank of similar ones.
This is a desired property since if an article is known to be of interest there will be a large number of news sources which will post similar pieces of information.
Therefore, a good news ranking algorithm working over a stream of information should also exploit some data stream clustering technique.
Formally, this can be described as follows.
Let us set the rank of a piece of news at emission time to be R(ni, ti) = + R (S(ni), ti     ) +  (ti tj ) ijR(nj, tj) , e (6)    
 lim  0+ tj <ti
 where 0 <   < 1.
In this case the rank of an article is dependent on the rank of the source and on the rank of similar news articles issued previously whose importance has already decayed of a negative exponential factor.
The rank of sources is still R(sk, t) = R(ni, t).
S(ni)=sk Unfortunately, studying the behavior of this algorithm on the limit cases LC2 we obtain that a news source mirroring another, gets a  nite rank signi cantly greater than the rank of the mirrored one.
In order to  x the behavior of the formula assigning ranks to news sources and dealing with the limit case LC2, we modify  a posteriori  the rank of a mirrored source.
In particular, a source which has emitted in the past news stories highly mirrored in the future, will receive a  bonus  acknowledging the importance.
The  nal equation for news sources and news stream becomes

 R(sk, t) = + R(ni, ti) = +  (t ti)R(ni, t) + e  (t ti) X   tj > ti S(ni) 6= sk e R (S(ni), ti     ) +  (ti tj ) ijR(nj, tj) .
e S(ni)=sk S(ni)=sk  
 lim  0+ (7)  ijR(nj, tj) , tj <ti The rank of a news source sk is then given by the ranks of the piece of news generated in the past, plus a factor of the rank of news articles similar to those issued by sk and posted later on by other sources.
The equation for ranking the articles remains the same (see equation 6).
Note that if an article n aggregates with a set of pieces of news posted in the future, we do not assign to n an extra bonus (acknowledging a posteriori the importance of n).
The idea is that we want to privilege the freshness of news posting instead of its clustering importance.
However, the news source which  rst posted an highly aggregating article is awarded of an extra rank, because that news source made a scoop (in journalistic jargon).
This algorithm is coherent with all the desirable properties described in Section 3 but it is more complicated than those analyzed in previous sections, and it is not easy to write down a formula for the stationary mean value of the source.
However, as shown in Figure 4, limit cases LC1 and LC2 are satis ed.
Figure 4: Simulated behavior of the limit cases LC1 and LC2 with   = 0.2.
From below, the two straight lines represent the theoretical values of LC1 with a decay rate   of 60 min and of 20 min.
There is a good agreement between theoretical and actual values of source ranks.
In the upper part the ranks of two sources emitting the same news stream are plotted.
The naive clustering used in comeToMyHead set  ij = 1 if ni and nj are the same, (i.e. they are mirrored).
In our news collection, these cases where very limited.
Hence, by using these values of  ij the result of news sources ranking is highly correlated with the simple counting of the posted news articles.
A more signi cant indication can be obtained by taking a continuous measure of the lexical similarity between the abstracts of the news posting.
These abstracts are directly extracted by the index of the news engine itself.
In our current implementation, the news abstract are represented using the canonical  bag of words  representation.
These abstracts are  ltered out against a list of stop words.
The lexical similarity is, then, expressed as a function of the words in common between news abstracts.
We remark, that dealing with a continuous similarity measure produces a matrix   full and whose dimension increases over the time.
Fortunately, the decay rule allows us to consider only the more recently produced part of the matrix, keeping it with a size proportional to the news ow(t, c), and therefore satisfying the Property (P5).
An interesting feature of our algorithm is the possibility to analyze the behavior of the mean value of the ranks of all the sources, over the time and for each given category.
This measure gives us an idea of the activity of that category and is related with particularly relevant events.
In particular, we de ne the mean value of the rank of all the sources at a given time t, that is
  (t) = .
(8) sk S R(sk, t)
 In Section 7 we discuss this mean value for a particular category.
We performed our experiments on a PC with a Pentium IV 3GHz, 2.0GB of memory and 512Kb of L2 cache.
For space reason, we report just the most important results.
The interested reader can ask the authors for a more extensive testing.
The code is written in Java and the ranking of about 20,000 news pieces requires few minutes, including the computation done by our clustering algorithm.
For evaluating the quality of results, we used the data set collected by comeToMyHead an academic News Search engine, gathering news articles from more than 2000 continuously updated sources.
The data set consists of about 300,000 pieces of news collected over a period of two months (from 8/07/04 to 10/11/04) and classi ed in 13 di erent categories (see Figure 5, 6).
Each article n is uniquely iden-ti ed by a triple < u, c, s >, where u is the URL where the news article is located, c is its category, and s is the news source which produced n. The data set is searchable online at http://newsengine.di.unipi.it.
To allow our ranking algorithm to achieve a stationary behavior, all the experiments, the measurements start from 8/17/04, discarding the  rst 10 days of observation.
Category # Postings Category Business Europe Italia Sci/Tech Sports Top News World





 Software & Dev.
# Postings





 Figure 5: How the news postings gathered in two months by comeToMyHead distribute among the 13 categories.
Category # Sources Category Business Europe Italia Sci/Tech Sports Top News World






 Software & Dev.
# Sources





 Figure 7: For the category  World , the  gure represents the correlations between ranks of news sources obtained with two successive values of   differing for 0.1.
The solid lines are the Kendall-Tau measure, the dashed lines are the Spearman correlation coe cients.
 i 1.
From this plot we can see that Kendall-Tau correlation is a more sensitive measure than Spearman correlation, and that the algorithm is not much sensitive to changing in the parameters involved.
This is a nice property since we do not have a way to establish the optimal choice of these parameters.
It is very important also to compare the source rank obtained with our algorithm with the one obtained with a simpler schema.
For this reason, we compare the mean source ranks over the observed period generated with algorithm TA3 with the naive rank obtained using method NTA1.
We recall that NTA1 assigns to a source a rank equal to the number of news posted.
A matrix of Kendall-Tau correlation values is obtained comparing the two ranks with   varying from 0.1 to 0.9 and for   varying from 5 hours to 54 hours.
In Figure 8 this matrix is plotted as a 3-D graph.
The correlation values show how the algorithm TA3 di erentiates from the naive NTA1.
Figure 6: The number of news sources for the 13 categories (gathered by the comeToMyHead).
Ranking news articles and news sources Sensitivity to the parameters A  rst group of experiments addressed the sensitivity at changes of the parameters.
We recall that our ranking scheme depends on two parameters,  , accounting for the decay rate of freshness of news articles, and  , which gives us the amount of source s rank we want to transfer to each news posting.
As a measure of concordance between the ranks produced with di erent values of the parameters, we adopted the well known Spearman [16] and Kendall-Tau correlations [11].
We report the ranks computed for the category  World  with algorithm TA3, for values of  i = i/10, where i = 1, 2, .
.
.
, 9 and for   = 12 hours, 24 hours and 48 hours.
In Figure 7, for a  xed   the abscissa  i represents the correlation between the ranks obtained with values  i and The second group of experiments addresses the principal goal of the paper, i.e. the problem of ranking news articles and news sources.
Figure 9 shows the evolution of the rank over a period of 55 days of the top four sources in the category  World .
The two plot are obtained choosing   = 0.5 and for two choices of the half-life decay time, that is   = 24 and 48 hours.
RedNova [27] results the most authoritative source, followed by Yahoo!
World[30], Reuters World [28] and BBC News World [17]2.
We observed that the most authoritative sources remains the same changing both   and  .
In Figure 10 we report the top ten news source for the category  World  returned by our algorithm setting   = 24 hours and   = 0.2.
Note that  Yahoo Politics  is considered more important than  BBC News world  due to the
 puter algorithm, and they do not express any opinion of the authors of this paper.
Source RedNova general Yahoo World Reuters World Yahoo Politics BBC News world Reuters Xinhua New York Times world Boston Globe world The Washington Post world # Postings









 Figure 10: Top ten news source for the category  World  (  = 24h and   = 0, 2).
Second column contains the number of news articles posted by each news agency.
Note that  Yahoo Politics  is considered more important than  BBC News world , regardless of the number of news posted.
issues of the same piece of information.
The most important ranking criteria of our algorithm are freshness of news articles and authoritativeness of the news agencies.
Figure 8: A 3-D plot of Kendall correlation between the news source rank vector produced by algorithm TA3, with various values of   and  , and the rank produced by algorithm NTA1 simply counting the news articles emitted.
Posted


 News Source News Abstract RedNova general RedNova general Israeli Airstrike Kills Hamas Militant Frederick Gets 8 Years in Iraq Abuse Case RedNova general Kerry Warns Draft
 RedNova general Possible if Bush Wins Iran Says U.N. Nuclear Ban  Illegal 
 RedNova general Video Shows British
 Yahoo World Hostage Plead for Life Israeli Airstrike Kills Hamas Militant (AP)
 RedNova general Web Site: 2nd U.S.
Hostage
 RedNova general British Hostage in Iraq Killed in Iraq
 Yahoo World
 Pleads for Help Sharon Vows to Escalate Gaza O ensive (AP) Palestinian killed on intifada anniversary Figure 9: Top News Source for the  Word  category, with decay time   = 24h and 48h and   = 0.5.
Note that for the same value of   a greater time of decay   gives us smoother functions and higher value of ranks.
However, it does not change the order of the most authoritative sources.
importance of the news articles posted.
A similar behavior is showed by the other categories, as well.
In Figure 11, 12 we report the top ten news articles for categories  World  and  Sports , using   = 24 hours and   = 0.2.
For space constraint we can not give the top news articles of the other categories present in comeToMyHead.
The news posting in these tables are those which score an higher absolute rank over the period of observation.
Note that our algorithm ranks any posted articles, and for top pieces of news it is common to recognize in the top list re-Figure 11: Top ten news articles during all the observation period for the category  World  (  =24h and   = 0.2).
In Figure 13 and 14, are listed the top ten fresh news articles for the category  World  and  Sports  in the last day of observation.
In these lists it is possible to recognize posting of news articles regarding the same event.
Since these news articles are all fresh, the ranking depends essentially on the rank of the source.
Ranking the news events In Figure 15 the function  (t) de ned in (8) is plotted over the time.
The value at time t represents the mean of the ranks of the sources in the category  Sports , hence peaks may correspond to particularly signi cant events.
Posted
 News Source News Abstract Reuters Argentina Wins First Olympic Gold for 52 Years
 Reuters British Stun US in Sprint Relay Posted
 News Source News Abstract Yahoo Sports Pot Charge May Be Dropped Against Anthony (AP)
 Yahoo Sports Anthony Leads Nuggets Past Clippers (AP)
 NBCOlympics Argentina wins  rst
 NDTV.com Tennis: Top seeded Henman basketball gold loses to Ivan Ljubicic

 Reuters UPDATE 1-Lewis  res spectacular

 Cup Triumph for Europe

 Yahoo Sports Beats Italy, Takes Gold Pot Charge May Be Dropped Against Anthony (AP)
 Reach World Series
 China Daily China s Xing Huina wins Olympic
 women s 10,000m gold El Guerrouj, Holmes Stride Into Olympic History Clash with Red Sox
 Yahoo Sports Court: Paul Hamm Can Keep Olympic Gold (AP)

 Yahoo Sports Nuggets  Anthony Cited for Pot Possession (AP) Reuters Chelsea won t sack me,
 Sox Reach World Series says Mutu

 Yahoo Sports Dolphins Owner Undecided Annus Loses Medal About Coach, GM (AP) Figure 12: Top ten news articles during all the observation period for the category  Sports  (  =24h and   = 0.2).
Figure 14: Top ten news articles the last day of the observation period for the category  Sports  (  =24h and   = 0.2), only fresh pieces of news are present.
Posted
 RedNova general News Source News Abstract
 RedNova general
 Israeli Airstrike Kills Hamas Militant Frederick Gets 8 Years in Iraq Abuse Case Israeli airstrike kills top Hamas leader
 Yahoo Politics Bush Criticizes Kerry on Health Care (AP)
 RedNova general Man Opens Fire at Mo.
Manufacturing Plant
 Yahoo Politics Bush, Kerry Spar on Science,
 Yahoo Politics Health Care (AP) Smith Political Dinner Gets Bush, Carey (AP)
 RedNova general AP Poll: Bush, Kerry Tied

 Yahoo World in Popular Vote Fidel Castro Fractures Knee, Arm in Fall (AP) Boston Globe US Army Reservist sentenced to eight years for Abu Ghraib abuse Figure 13: Top ten news articles the last day of the observation period for the category  World  (  =24h and   = 0.2), only fresh news articles are present.
Evaluating Precision
 Another interesting measure is to consider the quality of ranked news articles.
To perform this evaluation we consider the standard P@N measure over the news stories, de ned as |R| where , R is the subset of the N top P @Nnews = news articles returned by our algorithm, and C is the set of manually tagged relevant postings.
In particular, we  xed a particular time of observation over the data stream of news articles and ranked the pieces of news.
Then, we asked a group of three people to manually assess the relevance on the top articles by taking in account the particular instant of time chosen and the category to which the pieces of news belong.
Only the precision of the  nal algorithm in Section 6 has been evaluated since the earlier variations of the algorithm do not satisfy the mathematical requirements given in Figure 15: For the category  Sports  a plot of the function  (t) is represented.
Pecks correspond to particular signi cant events.
Figure 16: P@N for  U.S.  during the period of observation.
Section 3.
In Figure 16 we report the P@N reported for the top news articles in the category  U.S.  during the period of observation.
In this paper we have presented an algorithm for ranking news articles and news sources.
The algorithm has been constructed step by step ruling out simpler ideas that were not working on intuitive cases.
Our research has been motivated by the large interest in commercial news engine versus the lack of research papers in this area.
An extensive testing on more than 300,000 pieces of news, posted by 2000 sources over two months, has been performed, showing very encouraging results both for news articles and news sources.
The methodology proposed in this paper has a larger application than the ranking of news article and press agency.
We plan to apply the ideas discussed in this paper to other classes of problems such as the problem of ranking publications, authors and scienti c journals.
