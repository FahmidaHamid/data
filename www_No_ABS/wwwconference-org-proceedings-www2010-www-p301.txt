The rapidly growing volume of electronic communication data, such as that derived from email exchange, instant messaging, mobile phones, online games, social networking or social media sites, has been a great bene t to social network analysis, enabling researchers to study networks at very large scales and over extended time periods [19, 15,
 by this explosion of available data has overshadowed two distinct but related problems:  rst, the inference problem, that  real  social ties are not directly observable and hence must be inferred from observations of events, like physical interactions or communication records; and second the relevance problem, that there is no one  true  social network, but rather many such networks, each corresponding to a different de nition of a tie, and each relevant to di erent social processes.
To illustrate the interdependence of the inference and relevance problems, consider three possible de nitions for an edge deriving from observed communication data1: (1) an edge exists between i and j if either has communicated with the other at least once in the past year; (2) an edge exists if each has communicated with the other at least once in the past week; and (3) an edge exists if each has communicated with the other at least once per week for the past year.
Stated in isolation, each of these de nitions is plausible; yet each of them could potentially yield very di erent networks, not only in terms of average density (i.e. number of edges), but also in terms of important structural features like path lengths, local clustering [33] and motifs, degree distribution, and community structure [26].
Moreover, which of these networks is the  relevant  one will in general depend on the research question of interest.
For instance, if one is interested in a process like communication between trusted peers, where the relevant network is only made up of  strong ties , one might prefer de nition (3) above; whereas if one is interested only in short term di usion of information, one might prefer de nition (2); or  nally, if one is interested in communities that persist over extended time intervals, one may prefer de nition (1).
Of course, even these theoretically motivated edge de nitions are unfortunately vague, as
 applies quite generally to observational data [13], not just communication data, and even to networks generated by other methods like surveys [24, 9].
quanti able de nition of tie strength to, say, the transmission of some speci c type of information or in uence; indeed tie strength itself remains an ambiguous concept with multiple, possibly inconsistent de nitions [12, 21].
Nevertheless, the example serves to illustrate that the inference problem (mapping observations to ties) cannot be resolved independently of the relevance problem.
Typically, however, in network analysis research these problems are addressed separately.
That is, the researcher  rst nominates some plausible but ad-hoc de nition of a tie, say in terms of a  threshold  condition for an edge (e.g.
 a tie exists between i and j if and only if they have communicated at least once in the observed data ), and only then analyzes the network corresponding to that de nition.
In other words, rather than asking  For this problem, what is the most relevant network?,  the researcher is asking, in e ect  How is this (ad hoc) network relevant to my problem?  Although in any one instance this approach seems reasonable, because the researcher considers only one possible de nition of the network, he or she has no way of knowing whether other possible de nitions would have been more relevant to the problem at hand.
Moreover, when di erent authors studying di erent data sets make di erent assumptions about how to infer network ties, comparisons across studies cannot be made in a meaningful way.
To address the combined inference/relevance problem, we propose that rather than de ning ties based on intuitions about the data and only then studying the properties of the corresponding network, network analysts should instead de- ne ties explicitly in terms of their relevance to the particular objective of interest.
For example, if one is interested is in social in uence and the di usion of innovations or culture, we propose that the  relevant  network be inferred directly from some observed pattern of in uence.
Alternatively, if the objective is to partition the network into like-minded communities, one could identify the network that best captures the communities with shared beliefs.
Or if one is interested in predicting which pairs are likely to communicate in the future, one might identify the network that best predicts previous communication activity.
In this paper we outline a primitive version of this approach, which proceeds in two stages.
First, we  rst introduce a simple method for inferring networks from pairwise communication data that admits an edge between two individuals only when their communication exceeds a certain threshold   of intensity.
The method is primitive because, in relying on an ad-hoc de nition of a threshold, it su ers from some of the same problems that we seek to resolve.
Nevertheless, as we illustrate with two email data sets one, based on two years of server logs at a major US university [15]); and the other drawn from the publicly available Enron email corpus [29] it is general enough to demonstrate that network structure can change dramatically as a function of the tie de nition.
This dependence is visually apparent in Figure 1, which depicts the largest component in networks for di erent values of the threshold.
Having demonstrated the potential impact of the choice of threshold, we then consider the issue of how to select the  correct  value in terms of its relevance to some empirically observed pattern of interest, where  relevance  is formalized as a prediction task.
To illustrate the method, we again study the same two email datasets, identifying in each case the value of   that best predicts (a) observable individual attributes like gender or status (e.g.
for the University dataset,  status  corresponds to student, faculty, a liate, etc.
), (b) the likelihood of future communication between pairs of individuals, or (c) (for the University data) their co-membership in known communities.
We emphasize that there is nothing special about these particular prediction tasks, which were chosen largely as a matter of convenience given the available data.
Nevertheless, our results highlight the main contributions of our proposed approach:
 edge weights corresponding to about 5 10 reciprocated emails per year over which our set of chosen prediction tasks seem to yield maximum accuracy.
sizeable (  30%) boost in accuracy over na ve approaches of network inference.
values appears to be relatively consistent across both datasets and the various prediction tasks.
The rest of the paper is organized as follows.
Section 2 gives an overview of the related work, highlighting the differences with our approach here.
In Section 3, we introduce the two data sets that we use to illustrate our argument, and describe our method for inferring networks from communication data.
In Section 4, we then study the properties of these families of networks, examining a range of network-and node-level metrics.
Next, in Section 5, we conduct several prediction tasks on the inferred networks.
Finally in section 6, we present our conclusions and discuss directions towards future work.
Use of interpersonal communication for network inference has been of interest to researchers for several decades.
Early work [28] utilized email tra c to infer social networks for the purpose of discovering communities of shared interest.
To arrive at their network, the authors developed a highly customized approach, discarding messages not thought to be relevant to shared interests (e.g.
bulk emails, emails sent from administrative accounts, etc.
), discarding nodes and edges not part of the main connected component, and pruning the main connected component to focus on  core  nodes.
More recent work using email data has focused on the frequency of email exchange as an indicator of relevance.
where in some cases [31, 10, 1] the authors specify a  xed threshold, mapping observed frequencies to binary (i.e. wij   {0, 1}) edge weights, while in other cases directed, weighted edges are constructed [8].
Finally, some authors have applied a time-dependent threshold condition [6, 15, 5] to communication data in order to detect tie creation and deletion in dynamic networks.
Although motivated by di erent research questions, the approaches taken in these studies are consistent with that outlined in the introduction: a single de nition of what constitutes a tie is chosen, largely on the basis of intuitive plausibility, and only the properties of that particular network are considered.
The question of whether other possible de ni-tions might have generated di erent results, and if so, which results are the relevant ones, is therefore rarely raised.
Even based on email server logs at a US university, and (b) the Enron email corpus.
Signi cant changes in topology are observed as the thresholding condition of the network is varied.
where alternative de nitions are considered [15, 17], the purpose is exclusively to serve as a robustness check on the  nd-ings; thus the scope of possibilities is typically limited to within some range of the original choice of threshold.
Most closely related to the current work are two recent studies using mobile phone data [27, 9].
In [27], the authors systematically deleted edges as a function of call frequency in order to investigate the connectivity of the network, and its impact on information di usion.
The main distinction between this study and the current work aside from our broader focus on network properties other than connectivity is that we not only show that di erent choices of threshold generate di erent networks, but also that some inferred networks are more relevant than others with respect to social processes (e.g.
gender and status homophily) of interest.
In [9], the authors use communication data to predict self-reported ties generated by a survey tool.
Although this paper is similar to ours in its emphasis on relevance, [9] treats self-reported ties as the  ground truth,  whereas we make no such assumption.
In this section we  rst describe the two communication datasets and then discuss our method for inferring the social networks from communication events.
We emphasize that this method is by no means completely general indeed, it embodies a number of assumptions that impose ad-hoc restrictions on the range of possible inferred networks.
Nevertheless, it is su ciently general to admit a broad family of networks, all of which are based on the same underlying set of observations but which vary dramatically in structure, as we show in Section 4.
University.
Our  rst dataset is a complied registry of all email (incoming and outgoing, as recorded in server logs) associated with individuals at a large university in the United States, comprised of undergraduate and graduate students, faculty, and sta  spanning over a period of two years (i.e.
in the order: Fall, Spring, Summer, Fall, Spring, Summer).
The emails contain encrypted IDs of the sender and recipi-ent(s) of each email and the timestamp, but do not contain the content.
The dataset also features several (anonymized) personal attributes, including status, gender, age, departmental a liation, number of years in the community, dorm and home zipcode information for the students, as well as course a liations for the students at each semester.
In order to focus on a population of users who use emails as a major communication mode, we have considered only the individuals who have email IDs associated with the university domain (non-university emails were excluded because we did not have complete information about external accounts).
In addition, we excluded individuals who did not send at least one email in each of the six semesters under consideration; thus ensuring that we observed a consistent set of individuals engaged in regular interpersonal communication.
After applying both of these restrictions, our data comprises 19,817 individuals with a total of 1,098,285 emails over the two year period.
Enron.
Our second dataset is a repository of the emails exchanged internally among the employees at the Enron Corporation, obtained through a subpoena as part of an investigation by the Federal Energy Regulatory Commission (FERC) and then made public.
The data set comprises 4,736 individuals (including both Enron executive o cers as well as individuals external to Enron but involved in communication), who sent 1,063,352 emails over the period 1998-2002.
In addition, information about the status of the individuals in the corporation (e.g.,  Director ,  Trader ,  Manager , etc.)
was made available for public use.
In contrast with the University data, no  ltering of the Enron data was required.
For the chosen set of individuals V in both University and Enron, we de ne the weight ws wij.wji of an edge between two individuals i and j as the geometric mean2 of ij =  
 ui and uj ensures that there is no tie if communication and edges over di erent thresholds   , and with respect to the network corresponding to minimum threshold (  = 1).
Results are shown for the University email dataset and the Enron corpus.
the annualized rate of messages exchanged over the span of two and four years respectively, where wij is the number of emails sent per year from i to j.
We then de ne a network G(V, Es;   ) comprising the edges Es between the pairs of nodes i and j in V whose edge weights ws ij exceed a speci ed threshold   .
By systematically varying   , therefore, we can then obtain a family of networks, {G ( 1) , G ( 2) ,  , G ( K )} corresponding to more or less stringent de nitions of what counts as a  relationship .
Having de ned the family of networks {G ( 1) , G ( 2) ,  , G ( K )}, we now investigate the variation in structural characteristics as a function of the threshold   .
To do this, we generate networks for the University and Enron email datasets, for values of   ranging between 0.5 and 503.
For each of these networks, we then consider two sets of features:  network-level  features that capture properties of overall network size and connectivity; and  node-level  features like local clustering, bridging, and connectivity, that characterize individual nodes.
The set of features we have considered is not intended to be exhaustive, nor are they necessarily more revealing of network structure than other possible choices.
Nevertheless, they are commonly studied by network analysts, and are often invoked to justify substantive conclusions about outcomes of interest like the potential for information  ow through a network or the relative in uence of nodes (e.g.
[4]).
We  rst investigate the variation in the network size as a function of the threshold   .
Figure 2 shows the number of edges and (non-singleton) nodes for both email data sets, from which it is clear that the choice of   makes a sizeable between ui and uj is unidirectional.
This eliminates any one-way communications, such as mass bulk emails from an administrator at a university.
both networks are de ned.
This corresponds to   = 0.5, or one email over the period of two years for the University dataset Figure 3: Changes in characteristics of the network components for the two email datasets.
Figure 4: Sizes of di erent network components as a fraction of the entire network, shown over di erent   , for the two datasets.
The colorbar corresponds to the di erent component sizes.
impact on the inclusion and exclusion of both nodes and edges.
For example, by increasing the threshold from   = 1 to   = 5, the number of edges in the network are reduced by an order of magnitude.
There are two notable features apparent in Figure 2:  rst, the drop in the number of edges over increasing   looks strikingly similar in the two datasets; and second the number of nodes included in the two networks diminishes at very different rates.
The explanation for these di erent results is as follows.
The distribution of edge weights is similar between the two datasets; thus the rate at which edges are removed with increasing   is also similar.
The Enron dataset, however, contains many more  peripheral  nodes in the sense that nodes are connected to the core of the network by only a single edge; thus the rate at which nodes become isolates with increasing   is initially much greater than in the University dataset.
This can be seen in Figure 3, which shows the size and number of connected components as a function of the threshold.
Figure 3(a) shows a dramatic drop in the fractional size in both datasets, and Figure 3(b) a correspondingly dramatic increase in the number of disconnected components; but the changes happen at a lower value of the threshold (around   = 5) for Enron.
This can also be seen in Figure 4, which shows, as a function of   , how the sizes of the di erent network components change as a fraction of the entire network.
We observe that for both datasets, at   = 0.5 the majority of the nodes are in the largest component (size   80%).
Initially as   increases, nearly all of the deleted edges disconnect singletons from the giant component, and only after   approaches   10 are larger components disconnected.
A wide variety of structural features of nodes have been used for purposes such as understanding the structure of communities within a population [16, 25, 31], studying the  ow of information between individuals and groups [19], and predicting the relative similarity of friends and strangers [28].
Following prior work, we now consider a selected set of features that can be roughly grouped into three categories: those that measure the reach of a node (node degree, average neighbor degree, size of two-hop neighborhood) [15, 18]; those that measure the closure of the ego network (em beddedness, clustering coe cient) [15, 18]; and those that measure how much the node is bridging communities (network constraint, number of ego components) [4, 22].
We  rst brie y review the de nitions of these features and then present the results for both datasets.
Reach   Node Degree: The degree of a node is de ned as the total number of neighbors, or immediate contacts, given by the set  i = {uj : eij   Es}.
For individual ui   V , ki = (cid:5) i(cid:5).
  Average Neighbor Degree: The average neighbor de-of a node i is de ned as the mean degree gree k(n) over all of its immediate contacts.
i   Size of Two-hop Neighborhood: Size of two hop neighborhood k(2) of a node i is the count of all of the node s neighbors plus all of the node s neighbor s neighbors.
Note that this is a count of the nodes, and therefore is agnostic to how many edges there are between these nodes.
i Closure   Embeddedness: We de ne the embeddedness of a node with respect to its neighborhood as the mean of the ratio between the set of common contacts and the set of all contacts for the node and each neighbor.
It is given as, (cid:2) uj i | i    j| | i    j| Ei =
 ki (1)   Normalized Clustering Coe cient: The clustering co-e cient of a node is a standard notion of local density4 (i.e.  the average probability that two of my neighbors are neighbors of each other ), given by ci = 2|ejm| ki(ki 1) , where ejm are the edges connecting uj, um    i and  i is the  neighborhood  of i.
As we have seen, however, the graphs we are studying vary dramatically in terms of their global density as a function of the threshold; thus it is more informative to see how local density varies relative to global density, rather than in absolute terms.
We therefore de ne the  normalized clustering coe cient  of a node as the ratio of the clustering co-e cient and the graph density: ci (2) Ci = ki/(N   1) ,
 nodes whose clustering coe cients are unde ned for a certain threshold   .
where N is the number of nodes in the graph.
Note that in contrast to ci which varies between 0 and 1, Ci has no upper bound.
Bridging   Network Constraint: We de ne network constraint of a certain node i as given in Burt [4]:   (cid:2)  pij + (cid:7) j i (cid:2) q i,q(cid:4)=j    2  i = piqpqj (3) (cid:7) i wij denotes the amount of di-Here pij = wij/ rect attention that node i gives to node j.
The sum q i,q(cid:4)=j piqpqj is the total amount of indirect attention that i gives to j through some intermediary q.
Thus, as i s contacts become more connected, i s attention becomes more redundant and i s network constraint increases.
This measure is minimized when none of i s neighbors are neighbors with each other, in which case it evaluates to 1 ki .
  Ego Components: Restricting attention solely to a node i s immediate neighborhood (i.e. its neighbors and all the edges between them), this measure  i is a count of the number of connected components that remain when the focal node and its incident edges are removed.
It is maximal if none of the node s neighbors have connections between them and minimal if there is a path connecting all of the node s neighbors that does not include the node itself.
As before, we study these features for both datasets for the family of networks {G ( 1) , G ( 2) ,  , G ( K )}, where   varies between 0.5 and 50.
Figure 5(a f) shows the values of six out of the seven of these features (average neighbor degree behaves almost indistinguishably from two-hop neighborhood, so is omitted for clarity), averaged over the population of non-isolated nodes.
For all of the measures of reach the values are necessarily monotonically decreasing because increasing   can only delete edges, which means every node s degree can only go down.
As can be seen in Figure 5, the average degree of the nodes decreases more sharply in the University than it does in the Enron dataset, though the change in the number of nodes reachable in two hops is very similar across datasets.
In contrast with reach, the measures of bridging do not necessarily change monotonically.
Depending on which edges are deleted those that connect nodes to di erent groups or those that tie groups together both network constraint and the number of ego components can increase or decrease.
Empirically, however, Figure 5 indicates that the overall trends are mostly monotonic: in general, network constraint increases, while number of ego components decreases (where in contrast, the University dataset exhibits a slight increase for low values of   ).
The explanation for these trends appears to be that for low   the graph comprises a number of densely connected components, between which nodes can act as bridges.
As we increase the threshold, however, the bridges between these clusters are preferentially severed, suggesting that bridging edges are not as strong as those within clusters, consistent with Granovetter s conjecture on the strength of weak ties [12].
as a function of   , shown for the University dataset.
 i





   = 0.5   = 5   = 10   = 15   = 20   = 50





 Ei





 ki





 k(2) i





 Ci ci





  i





 threshold correspond closely to de nitions of ties that have been invoked by previous authors:   = 0.5 [10],   = 5 [1], and   = 15 [31] respectively.
That all three choices of   have been made in prior work suggests that all three are defensible; yet Table 1 shows clearly that the networks we would infer from them would have vastly di erent properties, in terms of its density, connectivity, and clustering, among other properties.
Average node degree, for example, varies between k = 39.3 and k = 2.7.
How then should one choose the  correct  value of   ?
Clearly one cannot do so on intuitive grounds alone; nor do Figures 2, 3, and 5 provide much insight the features clearly change, but not in a way that suggests any obviously preferred value of   .
In the next section, therefore, we propose a method for choosing   that depends explicitly on its relevance to some empirically observed pattern or a social process of interest.
As noted in the introduction, if one were interested in, say, social in uence, our proposed approach would be to infer the network that is most relevant to some empirically observed pattern of in uence.
To illustrate this approach, we study features present in our data: the distribution of individual attributes (gender and status), future communication between pairs, and membership in known communities.
In all cases, we formalize our notion of relevance as a prediction task, where the desired value of   is the one that maximizes the prediction of the observed property of interest for the network under consideration.
For example, the homophily principle [23] implies that two individuals sharing the same status (e.g.
undergraduate, graduate student, faculty, sta ) are more likely to have an edge between them.
Rather than choosing some de nition of the threshold on some other grounds, therefore, we propose that the appropriate choice of threshold is the one for which the induced network provides the best predictor of an individual s status, given the statuses of his or her network neighbors (who, in turn, are de ned by that choice of network).
We now specify in more detail the four prediction tasks for which can we empirically evaluate the relevance of the networks: status; gender; future communication activity between pairs; and community membership.
For all of the prediction tasks, with the exception of community detection, we utilize the node s attributes (e.g., a liation, communication activity) and structural features (e.g., degree, normalized clustering coe cient) as well as the corresponding attributes/activities of its neighbors.
In the following subsections, we discuss the prediction techniques for the different tasks in detail.
Figure 5: Changes in aggregated node-level features for the two email datasets.
The change in the measures of closure provide further support for this hypothesis.
Embeddedness shows similar variation with   to network constraint, indicating that as edges are deleted the neighborhoods of adjacent nodes have substantial overlap.
The change in normalized clustering co-e cient, however, is somewhat less intuitive and arises from two competing e ects.
On the one hand, if locally embedded  strong ties  arise out of a process of homophily and triadic closure [15], then one might suspect clustering co-e cient would increase with   , as weaker, less embedded ties are successively pruned away.
On the other hand, if locally embedded edges arise out individuals sharing common  social foci  [11], then dense clusters in the network may be mostly made up of weak ties, in which case clustering would decrease with increasing   .
As Figure 5(d) indicates, we  nd evidence for both of these conjectures: at  rst, the normalized clustering coe cient Ci increases, consistent with Granovetter s [12] intuition that the weakest ties are bridges.
Normalized clustering coe cient, however, peaks around   = 15 for the University dataset and around   = 5 for the Enron dataset, after which it decreases monotonically, suggesting that above a certain threshold most remaining ties are associated with dense clusters, and thus commensurate with Feld s social foci hypothesis [11], that pruning weaker ties reduces clustering.
Table 1 summarizes the results of this section, displaying sample values of   for the features discussed above for the University dataset.
To interpret this table in concrete terms, we note that at least three of these choices of i , k(n),  Node Status / Gender Prediction.
Node status prediction deals with predicting whether an individual (1) in the University email dataset is a student (undergraduate or graduate), faculty, sta , a liate or other; or (2) in the Enron dataset has a designation such as  Director ,  Trader ,  Manager , etc.
within the company.
Similarly, our second prediction task deals with predicting the gender of a particular node.
i = {k  i ,  1 |Ni(a1)|,  2 |Ni(a2)|,  , ,E    q  |Ni(aq)|}, where  j gives the mean edge weight of i with respect to the neighbors having attribute value j (1   j   q) and Ni(aj) is the subset of i s neighbors whose attribute value is j.
In our experiments we also consider an unweighted version, where we set all  j to 1.
Based on the feature vectors f   for all nodes i in the network G (  ), we construct the feature matrix, F    Rd1 |V | i and a vector of the actual homophily attributes (status / gender) of each node i in G (  ), given as, A   R1 |V | , k(2),  i , C   i ,   i ,   .
i i The prediction task over a network G (  ) can now be de- ned as a learning problem where F  and A can be split into training set (F R, AR),   90%, and test set (F S , AS ),   10%, and used in a multi-class Support Vector Machine (SVM) [3] framework (with a Gaussian RBF kernel) to predict the attributes of nodes.
The prediction technique is described as follows.
For every G (  ), we perform a k-fold cross-validation over the training set (F R, AR) to learn the optimal model parameters, including feature weights and the kernel width.
These parameters are then used on the test set (F S , AS ) to predict the node attributes, (cid:8)AS .
Predicting Future Communication.
The purpose of this prediction task is to determine the probability of future communication activity of a certain node (i.e.
the number of emails sent).
To predict activity at time tm+1, we use a similar feature-based representation of a node i in the network G (  ), i.e.
the structural features, and the mean weighted activities of its neighbors from time t0 to tm; but we augment the feature space by also using the node i s communication over the past, from t0 to tm.
Hence the feature vector for prediction at time tm+1 can be written as (cid:7) i,m+1 = {k  f   wij    j,0:m,  i,0,  i,1,  ,  i,m}, where  j,0:m is the j i activity of node j (i.e. number of emails sent by node j) from time t0 to tm and  i,l is the activity of node i at time tl.
i,0:m,E   i,0:m, k(2),  i,0:m, k(n),  i,0:m, C   i,0:m,   i,0:m,   i,0:m, We  t a linear model of communication activity as a function of the node level features F 
 Am =   0:m, i.e. 0:m +   0:m, (4) 0:m are the regression coe cients and   where   0:m is additive noise.
The best t coe cients   0:m are used along with the feature vector at tm+1, to predict future node activity given as (cid:8)Am+1   R1 |V | :(cid:8)Am+1 =  
 m+1 (5) For the prediction of future communication activity in the University dataset, we divide the data over the span of two years into the six di erent semesters and regress over the  rst  ve semesters to predict the activity at the sixth semester.
In the case of the Enron email corpus, we divide the span of activity over four years (1998-2002) into time intervals of ti = 3 months each.
We incrementally train over the duration from t0 to tm, and predict the activity of each node at tm+1, based on the technique discussed above.
Community Detection.
In the  nal prediction task considered, we investigate the correlation between known community structure in the University dataset with that inferred from network topology.
For each threshold   , we  t a stochastic block model [32] to the unweighted network G (  ) using variational Bayesian inference [14].
We then compare the resulting (soft) partition of nodes to the partition given by university a liation of individuals to di erent schools, as reported in the node metadata.
We quantify the correlation between the ground truth and inferred partitions using normalized mutual information as described in section 5.2.
This method for community detection assumes a model in which each node i belongs to one of Z latent groups (or  blocks ), indicated by zi, with probability  ,     1, .
.
.
, Z.
The probability of an edge Aij between nodes i and j depends only on the group assignments zi and zj: if the nodes are in the same group (zi = zj), an edge exists between them with probability  +; if they are in di erent groups (zi (cid:9)= zj), an edge exists between them with with probability  .
Given only the observed edges eij   Es in the graph G (  ), distributions over the group assignments p(zi) are inferred via variational Bayesian inference.
Here we  x the number of groups to Z = 5, corresponding to the number of partitions given by university a liation.
A liations for singletons are assigned a uniform distribution over group assignments, i.e. p(zi =  ) = 1/Z.
We note that, in contrast to the other prediction tasks at the node and edge level, this task involves the global structure of the network.
For the tasks of predicting node status and gender, we the quantify performance via classi cation accuracy, i.e.
fraction of nodes for which the predicted and actual values agree.
Likewise, we quantify agreement between the (real-valued) predicted and actual future communication activity using percent error between the number of future emails predicted and observed.
In the case of community detection, however, the algorithm returns a probability distribution over group membership for each node.
We quantify the agreement between this distribution and the actual group assignment (i.e. af- liation in the University dataset) via normalized mutual information (NMI).
This standard measure for evaluating performance of community detection algorithms [7] is given by the mutual information of the joint distribution over actual and predicted assignments, normalized by the entropy of the marginal distribution over actual distribution.
Con ned to lie between 0 (minimum agreement) and 1 (maxim-ium agreement), NMI is similar to the number of correctly classi ed nodes, but penalizes misclassi ed nodes more heavily.
University.
Prediction results for the University email dataset for the four tasks described above are shown in Figure 6.
First we observe that the predictions using weighted features perform better than the corresponding unweighted version; that is, the frequencies of communication (the edge weights) are informative for all of the prediction tasks, even in the thresholded graphs where infrequent communication is discarded.
Second, we observe that in all cases the ac-nodes) for three di erent prediction tasks on the University email dataset (a) node status (e.g.
undergraduate, graduate, faculty etc.)
and (b) gender prediction, (c) predicting future communication activity and NMI in detection of community structure (i.e. a liation to schools).
Two cases per task (ac) are shown, one with unweighted features and the other with weighted features.
The error bars in the plots (ab) correspond to the k-fold cross validation performed in the prediction process.
The error bars in plot (c) correspond to the deviation in prediction error across all the users at each   .
curacy peaks at a nontrivial value of   , (i.e., at a value greater than the minimum   at which no threshold condition is applied).
This result suggests that there is some optimal balance to be struck between removing noisy edges and retaining su cient information about a node s neighborhood when making predictions.
We note also that the gain associated with discarded edges is nontrivial, corresponding to as much as 30% performance gain over the na ve strategy of retaining all the edges.
Surprisingly, the same rule seems to apply equally to weighted and unweighted networks; that is, even when weights are retained on the edges, one still gains a large boost by discarding the lowest-weight edges.
Third, although the prediction accuracy peaks at di erent numerical values of   (node status and future communication activity peak at   = 7.5, whereas accuracy for gender peaks at   = 10, and community structure peaks at   = 5), the peaks all fall within a relatively small range.
Enron.
With respect to the Enron email corpus, di er-ences in the available data restrict us to just two of the above four tasks: (1) prediction of node status (Figure 7); and (2) prediction of future communication activity of the nodes (Figure 8(a b)).
The results for node status are similar to the University dataset:  rst, the maximum accuracy appears at a nontrivial value of   both for the unweighted features (  = 7.5) and for the weighted features (  = 10); and second, the weighted features improve the prediction accu-racies.
For future communication activity we  nd the accuracy in the prediction of future activity peaks in roughly the same range as for the University data (  = 2.5 to   = 7.5 Figure 7: Mean accuracies in prediction of node status (i.e. designation at the company) for the Enron email corpus; both unweighted and weighted features are shown.
Figure 8: Mean accuracies (over all nodes) in prediction of future communication activity for Enron dataset, (a) unweighted case, and (b) weighted case.
for the unweighted and the weighted cases respectively), as shown in Figure 8(a b).
We also observe that training over extended durations improves the accuracy across all thresholds.
Once again, however, the range of   where the accuracy peaks seems to be reasonably consistent across training set sizes.
To summarize our  ndings, the threshold values that are most predictive for the tasks we have considered are not obvious, either on the basis of intuition (how would one choose   = 10 versus   = 15?)
or from the descriptive statistics present in section 4.2.
Nevertheless, the choice of   has a substantial impact: networks corresponding to optimal values of   perform as much as 30% better than na ve choices (e.g.
de ning an edge whenever two individuals have exchanged at least one email over the entire observation period).
Finally, we observe that as expected, di erent values of   optimize the prediction task for di erent empirical patterns; however, on this point, we also note an intriguing and unexpected secondary  nding that although di erent, the optimal values of   seem to fall in a surprisingly narrow range between   = 5 and   = 10.
A partial explanation for this result may be that the particular prediction tasks we have examined all involve predicting a certain attribute of an individual (status, gender, measure of communication and community membership), given (a) her node features; and (b) corresponding attribute values of her neighbors.
Pos-general principle of homophily [23] that similar nodes are more likely to be connected by social ties than dissimilar nodes in which case the small range of optimal   may not be as surprising as it initially appears.
That the range of optimal   is also similar across datasets is, however, puzzling.
The two datasets were collected several years apart in very di erent organizations, and involved very di erent people who were presumably communicating about very di erent topics.
Therefore there is no a priori reason to suspect that the same, or even a remotely similar de nition of an edge, as re ected by the intensity of reciprocated communication, should satisfy our prediction tasks.
Possibly the observed correspondence is simply a coincidence, and will not generalize to other cases.
If such a  nding does hold, however, it holds out the promise that networks inferred on the basis of one empirically observed pattern are also relevant to other patterns that have not been observed; that, for example, a network inferred on the basis of gender association could be used to predict the di u-sion of social in uence, or that the de nition of a tie relevant to di usion in one network for which di usion data may be available could be applied to another network for which it isn t.
Clearly claims of this nature are speculative; nevertheless, they suggest interesting directions for future research e orts.
Returning to our original motivation, network analysis of communication data takes as input some set of observations and infers from these data a set of relations to which social and psychological meaning is attached.
We argue here that this inference procedure, which heretofore has been de ned in a largely separate and often ad-hoc manner, should be as much a part of the analysis as the measurement of structural features.
In this paper, we have addressed a narrow version of this general problem; that is, how to determine an optimal threshold condition for edges so as to predict particular node attributes (e.g.
gender, status) or behavior.
Starting with a baseline network of communication based on email exchanges in two di erent datasets, we constructed a family of networks by consistently removing edges with weights below a series of speci ed thresholds.
We then studied a range of commonly used descriptive statistics,  nding dramatic di erences in network and node-level features depending on the choice of threshold.
Finally, we introduced a method for selecting among all these possible networks on the basis of a series of prediction tasks.
The prediction accuracies peak in a non-obvious yet relatively narrow  threshold range across both datasets.
We conclude with a discussion of several limitations of the work presented above, as well as possible directions for future studies.
First, and most importantly, the general problem of  data relevance  is considerably more di cult than we have allowed for within our narrow framework.
Obviously, the outcome of any network inference procedure seems likely to be in uenced by the manner in which one generates the family of possible networks to begin with; thus a more general approach than the one we have adopted here might be advisable.
For example, although we have allowed ties to be weighted, these weights refer only to the average frequency of communication, and so capture  strength  at best incompletely; and our use of the geometric mean of email exchanges as the basis on which to apply the threshold condition, although reasonable, is clearly not the only sensible approach.
We have also not allowed ties to be directed, or  multiplex , or to have time varying properties [20]; yet all are arguably important features of real-world social relations.
At a minimum, therefore, it would be desirable to establish methods for inferring weighted, directed, multiplex, and time-varying networks from observational data.
A second, related limitation in this work is that we have used a simple binary threshold function to generate candidate network structures.
One can imagine a more sophisticated means of transforming edge weights via arbitrary functions and learning function parameters while simulate-nously optimizing for predictive performance.
Finally, it is not clear why we  nd such consistency of the optimal choice of threshold across di erent prediction tasks in our experiments, and especially across di erent networks.
Further investigation across a wider range of communication data and prediction tasks may provide insight into whether there is any special signi cance to the range of threshold values observed here.
In closing, we note that although the focus in this paper has been on networks inferred from communication data, social networks may be constructed from other kinds of observable data too, such as the joint participation of actors in scienti c collaborations, social events, informal organizations, corporate boards or even movies.
As with communication data, researchers typically infer the presence of social networks from data of this type by choosing some ad-hoc for example,  i and j will be consid-threshold condition: ered connected if they share at least one group.  And, as with communication data, one may ask how relevant a particular shared a liation is: just because two directors sit on the same board does not necessarily indicate how often they talk or how much they trust each other; nor is it clear what one should infer from the existence of a coauthored paper, a  friend  nomination on Facebook or any similar observation.
Even for network data generated by survey tools, an analogous problem arises: survey respondents presumably apply some criteria for whom they report as a contact; yet because these criteria are generally not known to the researcher (or even necessarily to the respondents themselves), it can be di cult to interpret signi cance of the reported ties [2, 9].
The fundamental issue raised in this paper that is, how to infer relations of social and psychological relevance from observable events and event participant reports is therefore an extremely general one that applies well beyond the scope of communication data, impacting a much wider range of network problems than we have considered here.
Extending the methods introduced here to apply to di erent classes of interactional data, possibly in combination (e.g.
email, mobile phone calls, and a liation data), and to more general classes of network-related phenomena (e.g.
the dynamics of collective social behavior) therefore ought to provide ample opportunities for future work.
We thank Siddharth Suri for assistance with computing some of the node-level features.
