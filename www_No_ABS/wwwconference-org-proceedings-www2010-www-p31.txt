The Internet has become a major advertising medium.
Although a number of di erent factors contributed to this, what distinguishes the Internet advertising from the o ine advertising competitors is its inherently interactive nature.
Measuring e ectiveness of a particular advertising campaign and allocating the advertising budget optimally was and still remains a very challenging task, yet the Internet made the task easier by connecting ad impressions 1 to tangible user actions and artifacts such as posing a search query, clicking on an ad or converting 2.
The simplicity of measuring and attributing user clicks has established the clickthrough rate (CTR) 3 as the current de-facto standard of ad quality for sponsored search.
It is now customary to de ne the advertiser s optimization problem as maximization of the expected number of ad clicks given a certain budget constraint [13, 23, 10].
The conversion rate (CR), de ned similarly as the probability of the user conversion, is another popular ad e ectiveness measure; together with the CTR it is frequently used by the advertisers to measure the return on investment of speci c keywords in the advertising campaign.
Recent empirical studies show that the e ects of online ads cannot be fully captured by the CTR or the CR.
In particular, the sponsored search advertising, as well as the display advertising, can have a signi cant number of indirect e ects such as building the brand awareness [18].
For instance, Lewis and Reiley [20], in cooperation between Yahoo!
and a major retailer, performed a randomized controlled experiment to measure the e ect of the online advertising on sales.
They found that the online advertising campaign had substantial impact not only on the users who clicked on the ads but also on those who merely viewed them.
In another study, comScore [8] reported an incremental  lift  of 27% in
 viewed by the user.
resent a wide range of user activities from buying an item to simply spending a suitable amount of time on the advertiser s website.
times an ad was clicked by users when shown.
well as lift in other important online behaviors, such as the brand site visitation and the trademark searches.
The advertisers seek to understand the impact of their ad not just on the immediate click or conversion, but the likelihood of the eventual conversion in the long term and other long term e ects.
Users take speci c trajectories in terms of the search queries they pose and the websites they browse, and this a ects the sequence of ads they see; conversely, the sequence of ads they see a ects their search and browsing behavior.
This interdependence results in structural patterns in users  behavior; advertisers need new tools and concepts beyond simple aggregates (like the CTR and the CR) to understand them.
What are the systematic ways to help the advertisers reason about structural correlations in the data?
In this paper, we take an advertiser-centric data mining approach.
We start with data that is directly pertinent to the advertiser s campaign, that is, user trajectories that involved ads from the campaign of that advertiser, including ad impressions, clicks and conversions.
Such data can usually be reported to the advertiser, provided it is aggregated and anonymized appropriately.
Next, we build a data mining framework that can help advertisers identify structural patterns in this data.
Our contributions are as follows.
  We propose a graphical model based approach.
We formulate graphs from the data called adgraphs to capture co-occurrences of events adjacent to each other in users  trajectories.
Then, we introduce a variety of ad-factors, where every adfactor is a scoring rule for nodes in the adgraph: these are designed to capture impact of ad nodes on eventual conversion.
For example, we introduce adfactors based on random walks, that, for every event, calculate the long term probability that a certain random walk involving that event would eventually lead to conversion.
Our paper presents highly ef- cient algorithms for constructing adgraphs and computing all adfactors we introduce.
All algorithms were implemented using MapReduce [11] parallel programming model.
  Using data from the sponsored search campaigns of eight di erent advertisers, we study various adgraphs and adfactors.
We validate the adgraph models by showing their statistical  t to the data.
Also, we show interesting empirical properties of the adfactors that provide insights into user behavior with respect to brand vs non-brand ads.
Moreover, we show various natural data mining queries on adgraphs and adfactors that maybe of independent interest to advertisers.
Finally, using adfactors, we show how to e ciently prune the adgraph to localize and depict the in uence of any particular ad by its small neighborhood in the ad graph.
Our approach works by transforming the dataset of users  trajectories into graphs.
This is achieved by pooling data from di erent users.
As a result, adgraphs lose information about speci c users or their trajectories, and only encode aggregate information.
Also, because of the way adgraphs pool data only based on adjacent events, they encode certain independence assumption about user behavior over paths of multiple edges.
We carefully study statistical  t of adgraph models to the data to ensure that this assumption is reasonable.
Pooling this way also results in signi cant compression.
For large advertisers in sponsored search, the number of different queries the advertiser can be matched with is often in tens of thousands, and the number of viewing users can be in millions.
In contrast, adgraphs have more manageable sizes.
Our approach generalizes to di erent settings.
While in this paper we apply it to study user conversions in the sponsored search data, it can equally be used to study trajectories in sponsored search that lead to clicks only, or conversions when both sponsored search and content-based display ad data is available, etc.
There are empirical studies showing that the sponsored search advertising, as well as the display advertising, can have a signi cant number of the indirect e ects such as building the brand awareness and lift in the cross-channel conversions [18, 20].
The prior research attempted to measure impact of an ad on the user conversion by the number of independent paths from the ad to the conversion event [5].
Our work here is a substantial generalization of the prior research, as we apply more advanced PageRank-based measures for analyzing pathways to the user conversion and, more importantly, introduce a generic adgraph/adfactor based framework for reasoning about the structural properties of the users  behaviors.
Mining patterns in the user behavior is not a novel idea.
Market basket analysis using association rule mining [2] is a popular tool used by retailers to discover actionable business intelligence from user level transaction data.
User behavior data has numerous applications, including, but not limited to, improving the web search ranking [1], fraud detection [12] and personalization of the user search experience [25].
In this paper, we mine the user behavior from the perspective of an advertiser running a sponsored search campaign.
There are several standard mining techniques that can be applied to the user-level advertising data such as mining for the frequent itemsets [2] or the frequent episodes in sequences of user actions [22].
However, these do not capture the structural correlations in the data such as the impact of multiple paths between events that our work captures.
A different approach that attempts to capture structural correlations is mining the frequent substructures in graph data [16].
Due to data pooling in our graph construction, patterns that we identify may or may not have high support, because some patterns may combine behavior of multiple users.
Also, we are not interested simply in frequent patterns but in patterns that indicate a high likelihood of the designated action: user conversion.
Further, our approach of using the steady state probabilities of di erent random walks to capture structural correlations di ers from the prior graph mining techniques.
This approach is widely used in other areas including web search [24, 4], personalized video recommendations [6] and user signatures in communication graphs [9].
Our research is closely related to the problem of modeling user search sessions, for which a wide number of solutions have been proposed in the literature, including advanced latent state models such as vl-HMM [7] and Markov models that take into account transition time between user s actions [14].
We intentionally refrained from using complex generative models for the underlying data due to several reasons.
At  rst, generative models often require individual user sessions for training, while, due to privacy reasons, At second, advertisers generally do not have access to information on user actions for which the advertiser s ad was not shown (even at the aggregate level).
Finally, the patterns of user behavior extracted from the data must be easy to communicate and represent, ideally in a graphical form.
This is often not true for generative statistical models.
Our sample covers 8 di erent anonymous advertisers, who were running a sponsored search campaign with Google.
The dataset was collected at user level and includes information on a random sample of users who  converted  with the advertiser within a certain time period of several weeks.
The activity of every user was tracked by a cookie, thus any user who deleted the cookie was later identi ed as a different user.
For every (anonymous) user, the data has the information on all actions of this user before the conversion, where we de ne an action as either a search query issued on Google and for which the advertiser s ad was shown in the paid search results or a click on the advertiser s ad.
In the rest of the paper, we will refer to the  rst action type as an  impression  event (as it resulted in the advertiser s ad impression) and to the second action type as a  click  event.
We emphasize that search queries for which the advertiser s ad was not shown, such as irrelevant search queries, queries on which the advertiser bid too low, or queries for which the advertiser was excluded from the auction due to a daily budget constraint, are not included in our dataset.
While such data might be available in some form to the search engine, it is not reported to the advertisers, e.g.
due to several privacy issues, and therefore we intentionally refrain from including it as an input into our data mining process.
Same applies to the ad position and the competitors  information in the sponsored search auction: advertisers do not observe their ad placement and competitors  ads on an individual query basis.
The information that we assume to be available for every event includes only the event timestamp, the search query issued by the user and the match type (exact or broad 4).
The number of data points for the converted users varied from approximately 30,000 impressions and 10,000 clicks for the smallest advertiser to about 5.8 million impressions and
 di erent user queries in the data varied from approximately 500 for the smallest advertiser to about 27,000 for the largest advertiser.
A special event in our dataset is a user conversion.
User conversions were reported by the advertisers, therefore the exact de nition of what constitutes the conversion event is advertiser-speci c.
In practice, it can vary from visiting a particular web site page or registering on the website to making an expensive purchase online.
We will use the term  conversion path  to represent an ordered sequence of events for a single user that ends in a conversion.
Finally, our dataset also includes data on users who were exposed to at least one ad impression of the advertiser but
 which allows for an imprecise match between a query issued by the user and the keyword the advertiser bids on [10].
bers is due to the fact that we describe the sample of users who eventually converted with the advertiser.
Figure 1: Distance to conversion did not convert within the monitored time period.
As the number of non-converted (yet) users is much larger than the number of converted users, we sampled from the pool of such users randomly with a sampling probability of 1%.
To ensure anonymity of the advertisers in our dataset, we do not report the descriptive statistics table, instead presenting two plots illustrating some of the most interesting properties of the data.
We  rst ask how long (how many searches) does is take for a user to convert with the advertiser (assuming that the user eventually converts)?
The exact value of the statistics depends on how we average data across di erent users.
Figure 1 shows the histogram of the distance to conversion for a randomly selected event in the sample of converted users.
The distance is de ned as the number of future ad impressions for the same advertiser (including the current impression) that this user will get before the conversion.
The data on the plot is slightly distorted (by a small multiplicative random factor for every advertiser) to preserve advertiser anonymity; the distortion does not a ect the main message of the plot.
In about one third of the cases, the user who converts will convert immediately after the observed impression, however a larger fraction (2/3) will be matched to the same advertiser at least one more time before they convert.
Moreover, the distribution has a heavy tail: in about 10% of the observations, the user will be matched to the same advertiser in at least 10 more searches before eventually converting.
The plot also shows that there is a lot of variation across advertisers, therefore our estimates of the distance to conversion have limited generalizability outside of our sample.
What we would expect to generalize is the observation that the interaction between the advertiser and the user is far more complex than a simple  search; click; convert  scenario and many users will be exposed to the advertiser s ad multiple times before they eventually convert.
Finally, Figure 2 presents a plot showing the number of di erent path types of certain length in our conversion data.
The path type is de ned as the equivalence class of all conversion paths that are identical once the timestamps are omitted.
Furthermore, we normalize all values by the number of di erent path types of the length 1, which is essentially the number of di erent user queries that we observed in the conversion data.
In order to understand the plot better, one can think of the two extreme cases of the data generating process.
In the  rst scenario, the data generating process samples new events i.i.d., i.e., the queries that the user issued before do not a ect the queries that the user will use later.
In such setting, the number of di erent path types of the length k (assuming a very large sample size) will grow i.i.d.
Simple Markov Forward Markov Backward Markov RS Markov 1 RS Markov 2 RS Markov 3 Stab.
(RMSE) Stab.
(MAE)













 Model i.i.d.
Simple Markov Forward Markov Backward Markov






 Table 1: Model stability, out of sample  2 LogL (Out) BIC (In) AIC (In)






 RS Markov 1 RS Markov 2 RS Markov 3 Table 2: Model  tness, in and out of sample






 models, the user is assumed to have two di erent possible regimes: the  search  regime representing a regular browsing behavior and the  interested  regime representing the behavior of a user interested in a particular advertiser.
Thus, for every user query we will have two di erent nodes: one for the  search  regime and one for the  interested  regime.
The user always starts in the  search  regime and, once switched to the  interested  regime, always stays there.
We consider three possible signals of the user switching the  regime : clicking on the advertiser s ad ( RS Markov 1 ), using the advertiser s brand name in a search query ( RS Markov 2 ) or a combination of both ( RS Markov 3 ).
We have evaluated all seven models in terms of several criteria: average stability (sampling variance) of the edge weights in the constructed graph (parameter estimates for the i.i.d.
model) and  tness both in and out of sample.
Stability scores were calculated in two forms: the average (across all edges) root mean squared error (RMSE) and the mean absolute error (MAE) of the edge weight estimates in a  ve sample split of the data.
Table 1 shows that, with exception of the i.i.d.
model, the edge weight estimates are quite volatile in our dataset, due to the fact that we have limited number of observations for many node pairs.
6 As the next Section shows, this in fact is not a problem for stability of the corresponding adfactors.
Next, we present the  tness results for all models in Table 2.
We report the statistical model  t to the data in-sample as measured by the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) [3].
We also report the out of sample  t from  ve-fold cross-validation [19] using the log-likelihood as the  tness criteria.
As expected, the i.i.d.
model shows the worst  t by far.
The best  tting model according to all three criteria is the  Backward Markov  model, indicating that the distribution of queries issued by the user varies signi cantly with the distance from the conversion event.
Regime switching models  t slightly better than the  Simple Markov  model.
In this section, we de ne and evaluate a number of ad-factors that capture structural correlations in the conversion path data.
All adfactors are calculated directly on the graph structures we de ned in the previous section, for instance, the same adfactor can be calculated both for a  Sim-
data as shown in Table 2.
This is just another example of the classic bias-variance tradeo .
Figure 2: Number of di erent paths of length k Number of di erent paths of length 1 exponentially with respect to the number of possible user queries (which is often in the order of thousands or even tens of thousands for a large advertiser).
This is clearly not the behavior we see in Figure 2, even taking into account  nite size of our sample (we formally test the i.i.d.
model in the next Section).
On the other hand, a perfect correlation between user searches would imply a  at plot, which is also not the case in our sample.
While there is again signi cant variation across advertisers, we would expect the following observation to generalize: there are strong  structural correlations  between user searches in a single conversion path.
In this section, we formally de ne and evaluate a set of generative statistical models for the conversion path data.
The  rst baseline model we evaluate is a simple i.i.d.
model: every new event in a conversion path is sampled independently from everything that has happened before that.
The number of parameters in the model is equal to the number of di erent user queries in the dataset (minus one).
All others models we evaluate represent user behavior as a random (Markov) walk in some directed graph (adgraph), what makes the models di er is the way the adgraph is constructed.
The adgraph construction involves de ning the set of graph nodes V , de ning the set of graph edges E, and de ning the edge weights wij which represent transition probabilities between nodes i and j.
While de nition of the nodes in the adgraph is model-speci c, all adgraphs that we construct will have three special nodes: the  begin  node representing the start of the conversion (or non-conversion) path for any user, the  conversion  node representing the conversion event and the  null  node representing the state of the users who have not converted within the observation period.
The  null  node is always an absorbing node and the  conversion  node always leads to the  null  node.
The  begin  node has no incoming edges.
Simple Markov.
In a  Simple Markov  adgraph, every graph node is an event (impression or click) and the edge weights are just probabilities of observing the two events consecutively in a conversion path.
We also consider  Forward Markov  and  Backward Markov  adgraphs, in which we incorporate the distance from the  rst user observation (the distance to the last user observation) as a part of the node id, thus allowing the next event to be sampled depending on how many events for the same user we have observed so far ( Forward Markov ) or how many more events we are going to observe before the user converts ( Backward Markov ).
Regime Switching Markov.
We also consider three additional  Regime Switching Markov  adgraphs.
In all three graph.
We present several alternative versions of the adfac-tors and evaluate their properties on the actual data.
The adfactor is calculated for every node in the adgraph and, informally, can be thought of as a measure of structural correlation between this node and the target node (the conversion node).
The simplest adfactor would be a simple edge weight between the pair of nodes in the adgraph.
Such ad-factor would capture a simple correlation between a pair of consecutive events: how often do users who get an ad impression for a particular query click on it?
(clickthrough rate) how often do users who click on the ad convert with the advertiser?
(conversion rate) The more sophisticated adfactors we de ne are expected to capture the structural properties of the adgraph such as: ceteris paribus, the larger the number of the disjoint paths from an event to the conversion is, the higher the adfactor should be, and also, the closer these events are, the higher the adfactor should be.
Three important points should be made about the adfac-tors.
First, while we expect the adfactors to have useful applications (and we show some of the applications in this paper) and be useful for ranking and reporting purposes, we do not and cannot attach any causal meaning to the values.
What adfactors capture are correlations not causations.
This is even true for the simplest of the currently used models of ad performance such as the conversion rate; what the conversion rate says is what fraction of the users converted with the advertiser after clicking on an ad, not what fraction of the users converted with the advertiser because of the ad (some users would have converted anyway even if the ad was not shown; other users who did not convert immediately may have converted later because of the ad).
Establishing causation would require running an actual experiment or, at least, having a good exogenous source of randomness in the data; this is beyond the scope of the paper.
Second, there is no ex-ante measure of quality of an adfac-tor and we are not going to say that one adfactor is always better than another.
What we will say in the rest of the paper is what structural properties of the data the di er-ent adfactors are able to capture.
Third, in order for the adfactors to be practically useful, they should be e ciently computable on large-scale data sets.
To address this issue, we design e cient algorithms for all adfactors we introduce in this paper, using distributed computation paradigm.
In fact, for one of the adfactors (the PPR adfactor), we can directly use a local pushback algorithm developed by Andersen et.
al [4].
For the rest of adfactors, we present suitable adaptations of the pushback algorithm.
LastAd adfactor represents the conversion rate of the corresponding ad: it measures the weight of the direct edge from the corresponding node to the conversion node.
Formally, for any event e (either simple ad impression or ad click), the LastAd adfactor is by the n   n random walk matrix M (M (i, j) = wijP Assume some restart probability   > 0 and a graph given ).
Let I be the identity matrix and ev is the row unit vector whose v-th entry is equal to one.
k wik The Personalized PageRank matrix is de ned as a n by n matrix solution of the following equation ppr  =  I + (1    ) ppr  M.
Fix a node v. The v-th row of the matrix satis es ppr (v, ) =  ev + (1    ) ppr (v, )M.
This is known as the Personalized PageRank (PPR) vector of a node v with restart probability   and it was introduced by Haveliwala [15] as the stationary distribution of a random walk on the graph with   probability restart at node v after each step.
The dual construct to the PPR vector is obtained by taking a single column of the matrix.
The column corresponding to the conversion node c, consists of all PPR contributions for di erent nodes v and the  xed conversion node c and, when written in a row form, solves the following equation ppr ( , c) =  ec + (1    ) ppr ( , c)M T .
This is PageRank contribution (CPR) vector and it is denoted as cpr   ppr ( , c) [4].
The CPR vector naturally captures important structural properties of the graph such as the number of di erent paths from every node v to the conversion node c as well as the lengths of these paths.
A nice property of cpr is that the sum of all cpr s for the node c is equal to the PageRank of the node c, so it can be thought of as a way to divide the PageRank score (which captures the total credit of the conversion node in the graph) into contributions from other nodes.
Moreover, varying the restart probability of the random walk ( ) can be used to  ne-tune the trade-o  between the short-term and the long-term effects of the ads.
The higher the restart probability is, the more the score captures the short-term contribution of the ad as compared to the long-term one.
The eventual conversion adfactor is a limiting case of cpr when the restart probability   converges to zero.
The following proposition says that, after normalization, this adfactor is equivalent to the probability of hitting the conversion node as opposed to hitting the null node in a random walk with no restart.
This adfactor is denoted hit( , c).
Proposition 1.
Let  M be the random walk matrix with the  null  node excluded and assume that the matrix I   M is invertible, where I is the identity matrix.
7 De ne the  hit  vector hit( , c) as a row vector solving the following equation: hit( , c) = hit( , c)  M T + ec.
lastad(e) = number of occurrences of { e, conversion } Then, number of occurrences of e
 PageRank contribution adfactor is de ned as the Personalized PageRank contribution of the evaluated node v to the conversion node c (ppr(v, c)).
Below, we give a formal de nition.
  ppr ( , c)   lim  0 ppr ( , c)   = lim  0 = hit( , c).
every node except for the  null  node has a small probability of transition to  null .
This is a reasonable assumption for our application as the user can always  drop out  with some positive probability.
For comparison purposes, we de ne the visit adfactor which represents the random walk (no restart) visit probability of a node from the  begin  node.
This adfactor is not related to the conversion node but simply captures the likelihood of the event happening in a user conversion path.
Formally, the adfactor is de ned as a row vector hit(b, ) solving hit(b, ) = hit(b, )  M + eb.
Similar to Propositon 1, one can show that = hit(b, ).
  ppr (b, ) lim  0  
 We introduce the MI (j) adfactor, which represents the marginal increase in the probability of hitting conversion from the  begin  node b if we increase the weight of all edges outgoing from the node j by  , allocated in proportion to the current edge weights.
We  rst compute MI (j) in the context of Personalized PageRank with a restart probability  .
Let   ppr (b,c) be the marginal in uence of an edge weight wji on the PPR of the  begin  node for the conversion node.
The adfactor MI (j) can be proxied by the following summation (note that sensitivity with respect to each outgoing edge is weighted proportionally to the current edge weight).
 wji Table 3: Correlation matrix for adfactors.
  = 0.05
 Ev.Conv.
LastAd Visit Pass



 -0.0657
 Ev.Conv.
-0.0614
 LastAd


 -0.0542
 Visit -0.0657 -0.0614 -0.0542

 Pass




 The above observation implies that the MI adfactor is the same as the passthrough adfactor which is the change in hit(b, c) if we remove the node j from the graph and redirect all incoming edges to this node to the  null  node, or formally, Pass(i) = hit(b, i) hit(i, c).
We call the corresponding adfactor the  passthrough  or Pass adfactor, since it captures the value of random walks passing through the evaluated node.
In this part, we introduce the adfactor RE(i) for each node i which is de ned as the change in the probability of hitting conversion starting from the  begin  node b if we remove node i from the graph.
Intuitively, this adfactor captures the change in the probability of reaching conversion if we remove a node i, or the incoming edges of node i. Similar to the MI  adfactor, we de ne the RE  adfactor in the context of a random walk with restart probability   as
 j wji   ppr (b, c)  wji ,
 i MI (j) = wji   ppr (b, c)  wji , RE (i) = We  rst observe that, in the setting of random walks with can be computed by using the following restart  ,   ppr (b,c) Proposition:  wij Proposition 2.
The marginal in uence of an edge weight on the PPR of the sink c with restart at the source node b is given by a product of the PPR of the start node of the edge (i) with restart at the source node b and the PPR of the sink node c with restart at the end node of the edge (j):   ppr (b, c)  wij 1       = ppr (b, i) ppr (j, c).
Using this proposition, we derive a simple closed-form formula for MI (j).
Proposition 3.
The marginal e ect of increasing the weight of the outgoing edges of a node j, MI (j), is equal to: MI (j) = ppr (b, j) ppr (j, c)   .
(1) The proofs are left to the appendix.
An advantage of this closed-form formula is that it lets us apply fast algorithms for computing the MI  adfactor.
The above proposition also implies that, as   tends to zero, the MI adfactor can be computed as follows: Proposition 4.
The marginal e ect of increasing the weight of the outgoing edges from a node j on the hitting probability of conversion, MI(j), is equal to: MI(j) = lim  0 MI (j)   = hit(b, j) hit(j, c).
(2) Using Proposition 2, we can derive a similar closed-form formula for RE(i) which is shown to be equal to Pass(i).
Proposition 5.
The RE  and RE adfactors can be computed as follows: RE (i) = ppr (b, i) ppr (i, c)   .
(3) RE (i)   = hit(b, i) hit(i, c).
RE(i) = lim  0 (4) The proofs are left to the appendix.
The Pass adfactor is a proxy for both MI and RE adfactors, i.e., MI(i) = RE(i) = Pass(i).
As a result, we only report empirical results for the passthrough (Pass) adfactor, and this will imply the same results for the MI and RE adfactors.
Computational e ciency is crucial for successful application of any data mining algorithm to the real world advertising data.
Fortunately, all adfactors introduced in the previous Section can be e ciently computed on large scale graphs using parallel machines.
The key is the observation that the PageRank contribution vectors (cpr   ppr( , c)) can be e -ciently computed using a local algorithm which adaptively examines only a small portion of the input graph near a spec-i ed vertex [4].
We have implemented the algorithm of [4] in the distributed computing environment of MapReduce [11] using the Pregel framework [21].
In the Pregel framework, every node in the graph can perform its local computation and the nodes interact with each other by a periodic exchange of messages.
The cpr computation can be achieved by a simple local algorithm (Algorithm 1), in which every node has state consisting of two variables: the currently accumulated cpr and the residual value obtained from other pushback operation (pushing fraction of the residual to its neighbors over incoming edges) until the value of the residual in each node does not exceed  . Andersen et al [4] proves the following: cpr   ppr( , c), using only 1 Theorem 1.
[4] The following algorithm calculates an  approximation of the PageRank contribution vector for the   + 1 conversion node, i.e.
pushback operations.
Moreover, using this algorithm, one can identify the top k nodes with the maximum PageRank contribution using only O( k Algorithm 1 Local algorithm to calculate cpr   ppr( , c) adfactor of the conversion node c.
Initialization:   ) pushback operations.
cpr(u)   0, resid(u)   1 if conversion node otherwise 0 Main Loop: while  u such that | resid(u)|     do Pushback(u,  ) end while Pushback (u,  ): cpr(u)   cpr(u) +   resid(u) {accumulate   fraction of the current residual} for every incoming edge w   u do resid(w)   resid(w) + (1    ) resid(u) of the current residual to neighbors} dout(w) {distribute 1     fraction end for resid(u)   0 Using Propositions 3 and 5, one can see that calculation of the MI  and RE , and passthrough (Pass) adfactors requires estimating both the Pagerank contribution vector for conversion (i.e, the ppr( , c) value for every node in the graph) and the Personalized PageRank vector of the begin node (the ppr(b, ) value for every node in the graph).
The  approximation of the Pagerank contribution vector can be calculated e ciently using pushback operations in Algorithm 1.
Moreover, a similar pushforward algorithm developed in [17] can be used for calculation of the  approximation of the PPR vector for the begin node.
Using Propositions 3, 4, and 5, by multiplying these two vectors, we get the following theorem: Theorem 2.
There exists a local  approximation algorithm for computing the MI  and RE  using O` 1 RE can be computed using O` 1   push   where  (cid:48) = mini wi,null.
operations.
Moreover, an  approximation for Pass, MI, and  (cid:48)   


 In this section, we present some interesting empirical properties of the adfactors in our dataset.
All experiments were done with the  Simple Markov  graph, except where explicitly speci ed otherwise.
The primary reason we chose  Simple Markov  over other adgraph models is that it simpli es interpretation of the results.
While similar experiments can be performed with other adgraphs, the results and their interpretation would be di erent for every particular adgraph model used.
Table 3 presents correlations between di erent adfactors in our data.
As expected, for a su ciently small value of the restart probability (  = 0.05), the PageRank contribution adfactor is highly (  = 0.9773) correlated to the Eventual Conversion (hit( , c)) adfactor.
There is also a signi cant Table 4: Stability of the adfactors for the top 1000 nodes.
Std.Dev.
Mean



 Std.Dev.
Mean
 Ev.Conv.
LastAd




 Pass
 but much lower correlation between the PPR factor and the Last Ad adfactor (  = 0.7285).
The visit adfactor is almost uncorrelated to the PPR, eventual conversion and the Last Ad adfactors, indicating that the user queries that occur frequently are not necessarily well connected to the conversion event.
Since the passthrough adfactor incorporates the visit adfactor, it is also weakly correlated to the rest of the ad-factors.
All correlations are statistically signi cant at 1% level.
Table 4 shows stability results (the sample standard deviation) for the adfactors of the top 1,000 graph nodes in a  ve-fold sample split.
One can see that the standard deviations of all adfactors are relatively low compared to the mean values suggesting that the adfactors of the most important nodes in the graph are relatively stable in the presence of sampling variance even though the edge weights in the graph can be volatile (Table 1).
In the rest of this Section, we evaluate how adfactors correlate with other node attributes such as brand/non-brand 8, click/impression and broad/exact match.
Note that in all three cases the evaluated attribute is a binary variable, thus, instead of presenting simple correlations, one can deliver better intuition by using ROC curves for the corresponding classi er.
Consider, for instance, Figure 3.
For every adfactor, one can construct a classi er of node  brand-iness  by using the adfactor < T decision rule: if the adfactor is larger than the threshold T , classify it as brand (or non-brand depending on which one is better), otherwise classify it as nonbrand (brand).
Varying values of T , one can achieve di erent (precision, recall) points; all such points constitute the ROC curve.
Figure 3 shows that the PPR adfactor is an excellent predictor of  brand-iness  for impressions (AUC = 0.95509), even stronger than the last ad score (AUC = 0.89930).
At the same time, for clicks the conversion Pass adfactor gives the best predictor of the brand (AUC = 0.87707), although it is an extremely weak predictor for impressions (AUC =
 queries are (naturally) much more likely to convert with the advertiser, than users that search with generic queries, thus the PPR adfactor measuring structural correlation to the conversion event is a good signal of the brand nature of the user query.
Yet, once the user clicks on the advertiser s ad, the signal loses its value, because, once the ad attracted enough user attention, the query that triggered the ad in the  rst place becomes much less important.
The good predictive power of the Pass adfactor on click but not impression  brand-iness  suggests that users are more likely to convert with the advertiser through click on a brand query ad rather than through click on a non-brand query ad, however converting users get equal exposure to both brand and non-brand impressions before they convert.
the edit distance of at most three to the advertiser s name or the brand name, and marked as non-brand otherwise.
The results were manually inspected to ensure that the mapping is reasonable.
(top) and impressions (bottom) Figure 4: ROC curve for click prediction for brand queries (top) and nonbrand queries (bottom) Figure 4 shows that for brand queries the Last Ad adfac-tor and the PPR adfactor are excellent signals of the click attribute; for non-brand queries they predict well for recall of up to approximately 0.6, after which the precision-recall curve becomes  at (until the eventual jump to (1.0,1.0)).
This weird behavior can be attributed to the fact that, in our dataset, we observe a number of rare generic (non-brand speci c) queries, for which click on the ad does not lead to any conversion.
We emphasize that such queries are rare, therefore using the Pass adfactor  lters them out and the Pass adfactor shows excellent predictive power for the non-brand queries in Figure 4.
Next, we compare the PPR and the Last Ad adfactors by using a di erence between the ad rank in both models as a predictor for brand/non-brand, click/impression and Figure 5: ROC curve for (PPR rank - last ad rank) predictor Figure 6: PPR behavior as a function of distance to conversion Figure 7: ROC curve for brand prediction by di er-ent models broad/exact attributes.
Results in Figure 5 suggest that the di erence is a good predictor of the brand attribute; manual inspection shows that this is because the PPR ad-factor ranks brand nodes even higher than the Last Ad ad-factor.
On the other hand, the ROC curves for click and phrase(broad)/exact match prediction are close to diagonal suggesting that there is no systematic di erence in rankings of clicks/impressions and broad/exact match nodes by both methods.
Next, we plot the PPR behavior as a function of the distance to conversion in Figure 6.
The  gure was constructed using the data from the  Backward Markov  model, in which every user query is represented by multiple nodes in the graph, depending on its distance from the conversion node.
Thus, for every query q, one can calculate log (ppr(q at distance d, c))  log (ppr(q at distance 1, c)) 9.
Figure 6 shows average of these results for di erent groups.
Note that for clicks the PPR values at distance two and more from conversion are signi cantly smaller than the PPR values at distance one, suggesting that if the user clicks on the ad and does not convert immediately, the likelihood to convert in the future goes down.
Consistent with our prior observations, the PPR behavior for brand and non-brand clicks is similar.
On the other hand, for non-brand impressions the PPR grows (or at least doesn t decrease) with distance to conversion, indicating that exposure to the advertiser ad on non-brand queries can have a long-term positive correlation with the likelihood of the user to convert.
For brand impressions, the PPR decreases with distance to conversion, although not as strongly as for clicks, again suggesting that, if the user searches for a brand and does not convert soon enough, the likelihood of converting in the future goes down.
Finally, Figure 7 investigates how di erent graph structures a ect the relationship between the PPR adfactor and the brand attribute of the node.
We consider three models:  Simple Markov ,  Backward Markov  and  RS Markov 1 .
sitivity to outliers.
using the PPR adfactor as a predictor for brand.
For  Backward Markov  model we use the observation (from Figure 6) that the PPR of brand nodes decays with distance from conversion while the PPR of nonbrand nodes grows with distance from conversion, thus we use

 (log (ppr(q at distance d, c))   log (ppr(q at distance 1, c))) d=2 as the predictor.
For the  RS Markov 1  model, we would expect similar behavior to hold and the PPR of the brand nodes in the  search  state (before the user clicked on any ads) to be lower than that in the  interested  state (after the user clicked on some ad), while the PPR of the nonbrand nodes in the  interested  state to be higher than that is the  search  state; thus, we construct the predictor as log (ppr(q in search state, c)) log (ppr(q in interested state, c)) .
Figure 7 shows that the  RS Markov 1  model has the best predictive power for the brand attribute, con rming the intuition that user clicks have di erent value in brand and non-brand contexts.
Producing intuitive and concise reports from huge amounts of data is the desired goal for advertisers.
In this section, we discuss various data mining tools that can be developed using our ad factors de ned on the graph models introduced in the paper.
Identifying the top k ads with the largest adfactor.
The simplest type of report one can think of is identifying the top k ads with the largest adfactors in a particular graph model.
The value of such report depends on the particular adfactor and the underlying graph model used.
For instance, in Section 6, we show that the PPR adfactor (in the  Simple Markov  graph) has high but not perfect correlation with the brand attribute of the ad impression.
Identifying the top k impressions with the PPR adfactor can thus be interpreted as identifying the top k impressions (user queries) with the highest  branding  impact: many of these user queries will in fact have the advertiser name or the brand name in them, but some will not and thus can be thought of as  shadow brands .
Due to privacy issues, we cannot show an actual example of such output.
Another interesting example of the top k output is the top k impressions for the Pass adfactor; they can be thought of as the top k user queries associated with the largest revenue to the advertiser if one takes into account the long-term correlations in the graph.
Interestingly, from Figure 3, we know that these are uncorrelated with the brand attribute.
Identifying ads with signi cant long-term e ects not taken into account by the Last Ad model.
Advertisers traditionally rely on the Last Ad reports (click-through and conversion rates) to evaluate ad e ectiveness.
An alternative report we suggest would be to look for ads that are ranked higher with adfactors taking into account the long-term correlations (like PPR) than with the Last Ad adfactor.
One such criteria for ranking is the di erence between the PPR adfactor node rank and the Last Ad adfactor node rank (properties of this criteria are shown in Figure 5).
Another criteria is to look for impressions that either have the PPR growing with the distance from conversion ( Backward Markov  model) or have the PPR in the  search  state higher than in the  interested  state ( RS Markov 1  model).
As Figure 7 shows, the second approach is more biased towards the brand impressions than the  rst one.
Identifying the top k ads with the maximum marginal increase (MI) adfactor.
A popular advertising objective is to maximize the expected number of user conversions given a certain budget constraint.
In a random walk model, we can restate it as maximizing the probability of hitting the conversion node starting from the  begin  node.
A heuristic way to identify the valuable nodes to invest on is to examine a small increase on the bid of a query (or keyword) which will have the maximum effect on the probability of hitting the conversion node.
This small increase on the bid results in a small increase in the weight of incoming edges for this query.
Thus, in order to identify queries for which the increase in their bid results in the maximum marginal increase in the probability of hitting conversion, we can look for the top k ads with the maximum MI adfactor, and the advertiser may consider increasing the bid for queries with large MI.
10 Explaining the adfactor value The adfactor assigned to any particular node in the graph, must be easily explained by a local structure around this node.
For instance, for the PPR (PageRank contribution) adfactor of a node u, one can always consider the top-m neighbor nodes through which the explained node u contributes the largest fraction of the PageRank to the conversion node.
Formally, let  u be the permutation of all neighbors of the node u that arranges them in the decreasing order of wuv ppr (v, c).
We de ne  u(m) as the set of the  rst m nodes in the permutation.
These nodes can be thought of as the most likely next actions of the user after the explained action, assuming that the user is going to convert.
It is straightforward to extend the pushback Algorithm 1 to keep track of the top m contributors for every node, thus one can e ciently generate corresponding reports.
The reports are best represented as graph plots, constructed starting at a seed node s and going up to a distance d in a graph of the top-m neighbors of every node.
Due to privacy reasons as well as the space limit, we omit an example of such plot.
Online advertisers have access to aggregate statistics such as the clickthrough rate, the conversion rate or the lift of their ad campaigns, but seek to understand more sophisticated correlations in users  trajectories of ads seen and users  actions.
Here we introduce an alternative data mining technique for aggregating user-level advertising data.
We de ne various adgraphs to model the data pertinent to the advertiser and propose several adfactors based on stationary probabilities of suitable random walks to quantify the impact of ad events.
We show anecdotal evidence for adfactors and describe their potential data mining applications.
Our research introduces novel primitives for mining advertiser-speci c data for ad e ects.
Adfactors we de ne are succinct, easy to compute and capture many structural properties of
 bidding strategy should also take into account the current bidding landscape (how much do the advertiser and the competitors bid) for a particular keyword.
itives can be developed using adfactors, which may potentially reveal more sophisticated correlations in user behavior, including negative correlations.
Other valuable directions for future research include developing richer graphical models of user behavior, beyond the Markov models in this paper, and adapting adfactors to them.
Zhimin He, and Sissie Hsiao for helping us with the data sets, and Sheng Ma, Fernando Pereira, R. Srikant for interesting discussions.
