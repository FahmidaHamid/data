Social networking sites (e.g., Facebook, MySpace, Friend-ster, Orkut, etc.)
are websites that enable people to share information and communicate with friends online.
At the Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
same time, users typically do not want to share all of their information with everyone, and privacy has emerged as a serious concern.
A growing number of social networking and social media sites allow users to customize their own privacy policies.
For example, Facebook has a  Privacy Settings  page, which allows users to specify which pieces of pro le data each friend is allowed to view.
Facebook also allows users to create friend lists, and then specify whether a piece of pro le data is visible or invisible to all friends in a particular list.
Unfortunately, studies have consistently shown that users struggle to express and maintain such policies [4, 13, 22, 27, 39], due in part to complex and unusable interfaces [39].
On Facebook, for example, the user must manually assign friends to lists; because the average Facebook user has 130 friends [2], the process can be very time-consuming.
Worse, numerous lists may be required since a user s privacy preferences can be di erent for di erent pieces of pro le data (e.g., Home Address vs.
Religious Views).
Clearly, there is a need for something better.
In this paper, we propose the  rst privacy wizard for social networking sites.
The goal of the wizard is to automatically con gure a user s privacy settings with minimal e ort from the user.
The goal of a privacy wizard is to automatically con gure a user s privacy settings using only a small amount of e ort from the user.
The design and implementation of a suitable wizard present a number of di cult challenges.
Ideally, the wizard should satisfy the following requirements:   Low E ort, High Accuracy: The wizard may solicit input from the user.
Research has shown, however, that users have trouble reasoning holistically about privacy and security policies [35, 27].
Thus, the user s input should be simple in form, and also limited in quantity.
At the same time, the settings chosen by the wizard should accurately re ect the user s true privacy preferences.
A naive approach would ask the user to manually con gure her privacy settings for all friends.
While this approach may produce perfect accuracy if carried to completion, it also places an undo burden on the user.
  Graceful Degradation: It is di cult to predict the amount of input that a particular user will be willing to provide.
As the user provides more input, the accuracy of the resulting settings should improve.
However, the wizad should assume that the user can quit at any time.
  Visible Data: In addition to the user s input, the wizard may also use information that it can gather and process con dentiality reasons, however, when assisting a user U , the wizard should only use information that is already visible to U .
Typically, this includes U  s neighborhood : the information visible to U in U  s friends  pro les, and the friend connections among U  s friends.
  Incrementality: The settings constructed by the wizard should gracefully evolve as the user adds new friends.
In response to these challenges, we developed a generic framework for the design of a privacy wizard, which is described in Section 2.
One of the key insights behind our approach is the observation that real users conceive their privacy preferences according to an implicit set of rules.
Thus, using machine learning techniques, and limited user input, it is possible to infer a privacy-preference model (i.e., a compact representation of the rules by which an individual conceives her privacy preferences).
This model, in turn, can be used to con gure the user s settings automatically.
As one instance of the generic approach, we have developed the active-learning privacy wizard described in Section 3.
The wizard implements the privacy-preference model by learning a classi er.
In the classi er, the features used to describe each friend, including community membership, are extracted automatically from the data visible to the user.
The wizard provides very simple user interactions: Leveraging the machine learning paradigm of active learning, it iteratively asks the user to assign privacy labels (e.g., allow or deny) to speci c, carefully-selected, friends.
As the user provides more input, the quality of the classi er improves, but the user can stop at any time.
Further, the wizard adapts gracefully as the user adds new friends.
The basic wizard is extremely simple to use, and well-suited for typical (nontechnical) users.
However, advanced technical users may complain that it does not allow them to view or directly manipulate the resulting privacy-preference model.
Thus, in Section 4 we describe a set of visualization and modi cation tools for advanced users.
To evaluate our solution, we conducted a detailed study of real users.
Using raw privacy preferences, which we collected from 45 real Facebook users, the experiments in Section 5 show two important things: First, our wizard achieves a signi cantly better e ort-accuracy tradeo  than alternative policy-speci cation tools.
On average, if a user labels just 25 (of over 200) friends, the wizard con gures the user s set tings with > 90% accuracy.
Second, communities extracted from a user s neighborood are extremely useful for predicting privacy preferences.
A user s privacy preferences express her willingness (or unwillingness) to share pro le information with each of her friends.
Formally, for a particular user, we will denote the user s set of friends as F .
We will denote the set of information items in the user s pro le as I.
At the lowest level, the user s privacy preferences can be expressed in terms of the function pref : I   F   {allow, deny}.
If pref (i, f ) = allow, this means that it is the user s preference to allow friend f to see pro le item i.
We will use the term privacy preferences to refer to the user s idealized policy; we will use the term privacy settings Figure 1: User K s neighborhood graph, and her privacy preferences toward Date of Birth.
(Shaded nodes indicate allow, and white nodes indicate deny.)
Notice that K s privacy preferences are highly correlated with the community structure of the graph.
to refer to the policy that is actually encoded and enforced by the social networking site.
The privacy settings can also be viewed as a function: setting : I   F   {allow, deny}.
For a particular friend set F and data item set I, the setting accuracy is the proportion of preferences correctly encoded by settings.1
 This section describes the design of a generic privacy wizard.
Motivating the design is the fundamental observation that real social network users actually conceive their privacy preferences based on unique sets of implicit rules.
The details of our user study are postponed to Section 5.1, but the intuition is illustrated with an example.
Example 1.
Figure 1 shows the neighborhood of a sample user K, and her privacy preferences toward Date of Birth.2 Each node in the graph represents one of K s friends; there is an edge between two nodes if there is a friend relationship between them.
In User K s neighborhood network, observe that there are group of nodes clustered together.
(We plotted Figure 1 using the Fruchterman-Reingold force-based layout, which places topologically near nodes close together, and others far apart.)
In social networks research, these groups are commonly called communities.
We have manually denoted some apparent communities on the  gure: G0, G1, etc.
Observe also that User K s privacy preferences tend to break down along the lines of the community structure.
She is willing to share her Date of Birth with the majority of her friends.
However, there are two communities (labeled G20

 are included as an illustrative example.
To protect con den-tiality, we do not include the raw preference data collected from actual study subjects.
.
the preference model as a binary classi er, trained using the friends that the user has labeled.
However, because the user s e ort is limited and unpredictable, it is important that the privacy wizard  ask the right questions,  or intelligently request that the user provide labels to the most informative unlabeled friends.
In the machine learning literature, this scenario, in which the learner can actively query the user for labels, is commonly known as active learning.
In the remainder of this section, we will  rst describe the construction of a classi er for predicting privacy preferences.
Then, we will describe feature extraction, based on visible data, including automatically-extracted communities.
Finally, we will describe the application of a particular active learning technique known as uncertainty sampling [26].
For a particular social network user, it is natural to view the privacy-preference model as a classi er.
Each of the user s friends f can be represented by a vector of extracted features ~x in a feature space ~X (see Section 3.2).
Using a set of labeled training examples (in this case, labeled friends) Flabeled, many well-known algorithms (e.g., Decision Trees, Naive Bayes, Nearest Neighbor, etc.)
can be used to infer a classi er.
(We tried several such algorithms in our experiments.)
In the most general sense, the classi er uses a feature vector representation of a friend to predict the friend s privacy label.
Formally, for a particular data item i   I, the classi er can be viewed as a function of the form [pref : ~X   {allow, deny} The resulting classi er can be used to predict the user s privacy preferences for unlabeled friends in Funlabeled.
It is important to point out that, in the context of the privacy wizard, we will assume that the labels the user assigns explicitly to friends in Flabeled are always correct.
The classi er [pref is only used to con gure the user s privacy settings for friends whom she has not labeled explicitly.
In order to build a reasonable classi er, it is important to select a good set of features.
For the purposes of this work, we considered two main types of features: features based on extracted communities, and other pro le data.
  Community Structure: Let Flabeled and Funlabeled denote the user s labeled and unlabeled friends, respectively.
We can automatically extract a set of communities from the user s full neighborhood (i.e., Flabeled   Funlabeled, and the edges connecting these friends) using techniques described in Section 3.2.1.
Each extracted community can be regarded as a boolean feature (i.e., a particular friend belongs to the community or not).
For example, suppose that we have extracted a community G1 from the network.
If a particular friend belongs to G1, then that friend has feature value G1 = 1; otherwise, G1 = 0.
  Other Pro le Information: There are additional attributes in the user s friends  pro les that can be used as features.
Since our study wizard is implemented in the context of Facebook, we consider the following when they are visible to the user: Gender, Age, Education history (high school and college), Work History, Relationship Status, Political Views, and Religious Views.
These items can be directly translated to features.
For example, Figure 2: Privacy Wizard Overview and G22) with whom she does not want to share this data item.
This suggests that User K has implicitly constructed her privacy preferences according to a set of rules, and that these rules are related to the underlying community structure of her friend network.
Based on this observation, and in response to the requirements outlined in the introduction, we propose a generic framework for constructing a privacy wizard, which is shown in Figure 2.
The framework consists of three main parts:   User Input: The wizard solicits input from the user regarding her privacy preferences.
In the most general case, this is in the form of questions and answers.
At any point, the user may quit answering questions.
  Feature Extraction: Using the information visible to the user, the wizard selects a feature space ~X.
Each of the user s friends can be described using a feature vector ~x in this space.
  Privacy-Preference Model: Using the extracted features and user input, the privacy wizard constructs a privacy-preference model, which is some inferred characterization of the rules by which the user conceives her privacy preferences.
This model is used to automatically con gure the user s privacy settings.
As the user provides more input, or adds new friends, the privacy-preference model and con gured settings should adapt automatically.
Of course, each of these components is quite general.
In the next section, we will describe one speci c instantiation of the framework.
In this section, we will describe a speci c instantiation of the generic framework outlined in the previous section.
In building the wizard, one of our goals was to keep the user interaction as simple as possible.
It is widely accepted that users have di culty reasoning holistically about privacy and security policies [35, 27].
In contrast, it is easier to reason about simple, concrete examples.
Thus, our privacy wizard solicits input from the user by asking her preference (allow or deny) for speci c (data item, friend) pairs (i, f )   I   F .
Without loss of generality, in the remainder of this section, we will assume that the data item i is  xed (e.g., Date of Birth), and the wizard simply asks the user to assign a preference label to a selected friend f   F .
Example 2.
The privacy wizard interacts with the user by asking a series of simple questions.
For example: Would you like to share DATE OF BIRTH with ...
Alice Adams?
(y/n) Bob Baker?
(y/n) Carol Cooper?
(y/n) ...
(Bob Baker) (Carol Cooper) Age Gender G0 G1 G2 G20 G21 G22 G3 Obama Fan Pref.
Label (Date of Birth)


 allow deny


























 ?
Figure 3: Example friend data with extracted features, including community-based features (G0, G1, etc.)
Gender has nominal values {male, f emale}.
In addition, the user s friends  online activities can be used, including Facebook groups,  fan  pages, events, and tagged photos.
For these, we use binary features, which indicate whether a particular friend is a member.
Example 3.
As a simple example, Figure 3 shows a set of labeled friends, using a feature-vector representation.
For example, Bob is a member of the extracted communities G2 and G20, and Alice is a  fan  of Barack Obama.
The user has assigned preference labels to Alice and Bob, but Carol s label is unknown.
In the remainder of this section, we brie y describe how we extract communities from the user s neighborhood network.
In the study of social networks, a network is often said to have a community structure if its nodes can naturally be separated into groups, where the nodes in each group are densely connected, but there are few connections between disparate groups.
For example, in Figure 1, it is easy to see several such communities, some of which we have circled and labeled.
From a sociological perspective, two individuals in the same community are relatively more likely to know one another than two individuals who are not in the same community.
Numerous algorithms have been developed for  nding communities.
(For an extensive survey on the topic, please see [18].)
In this paper, our primary goal is not to develop new community nding algorithms.
Instead, we will simply apply a common algorithm based on the idea of edge between-ness [33].
Please note that, in all cases, this algorithm can be replaced with any hierarchical (agglomerative or divisive) community nding algorithm.
When  nding communities in a social network, it is often di cult to know the right number of communities ahead of time.
For example, in Figure 1, G0, G1, and G3 seem to be well-de ned communities.
Looking at G2, however, it is not immediately clear whether this is a single community, or if it makes sense to further divide it into sub-communities G20, G21, and G22.
This problem can be addressed in several di erent ways.
One option is to partition the network into communities to maximize the modularity score [33].
In this case, the number of communities is automatically selected based on modularity.
For the purposes of this work, it is not necessary to partition the graph into a single set of communities.
Because a user s privacy preferences can be expressed at varying degrees of granularity, it makes sense to retain some hierarchical structure (i.e., larger communities that fully contain several smaller communities).
For example, in Figure 1, we have marked a total of seven communities, but community G2 fully contains three smaller communities.
In the remainder of the paper, we will extract multi-granularity communities according to the following process: (1) First, we partition the full network into communities using the edge-betweenness algorithm and maximizing mod-ularity.
(2) For each resulting community, we discard the surrounding network, and view the community as its own network.
(3) We repeat this process recursively until each community contains a single node.
Observe the community structure is only recalculated when new friends are added.
Typically, this will be done o ine.
For the neighborhood networks typically encountered in online social networks, which contain on the order of several hundred friends, we do not expect the performance of the community nding algorithm to be a major issue.
Ultimately, the accuracy achieved by the wizard depends on two factors: (1) The number of friends that the user labels explicitly (these are always assumed to be correct), and (2) The accuracy of the inferred classi er [pref in predicting the labels of unlabeled friends.
Since the amount of e ort a user is willing to devote to labeling friends is limited and unpredictable, it is important that we be able to learn an accurate classi er with a limited amount of training data.
Motivated by the graceful degradation principle, which aims to achieve the best accuracy possible, with the understanding that the user may quit labeling friends at any time, we have chosen to address this problem using an active learning paradigm known as uncertainty sampling [26].
Uncertainty sampling consists of two phases:
 the user to label.
ard uses the labeled examples to build the actual clas-si er ([pref), which is used to con gure the user s settings.
The sampling phase works as follows.
Initially, all of a user s friends are unlabeled.
The sampling proceeds in rounds.
During each round, the wizard selects the k unlabeled friends about which it is most uncertain, and asks the user to assign labels to these friends.
The process terminates after all friends have been explicitly labeled, or when the user abandons the process, whichever comes  rst.3 The uncertainty of a class label is traditionally measured by training a classi er (using labeled training data Flabeled), and using this classi er to predict the distribution of class labels associated with each friend in Funlabeled.
In our case, there are two possible class labels, and the predicted distribution of class labels is of the form P (allow) = Pallow, P (deny) = Pdeny , where Pallow   [0, 1.0], Pdeny   [0, 1.0], and Pallow + Pdeny = 1.0.
The uncertainty score is computed based on the entropy of the predicted class distribution: Entropy = Pi {allow,deny}  Pi log Pi.
A large entropy value indicates high uncertainty; entropy is minimized when Pallow or Pdeny equals 1, which indicates that the probabilistic classi er is 100% sure about the class prediction.
gest to the user when it would be prudent to stop labeling.
struction phase trains the classi er [pref using the labeled friends Flabeled.
Note that the classi cation algorithms used in the sampling phase and the classi er construction phase need not be the same [25].
We tried a variety of classi ers in our experiments.
From a practical perspective, there may be additional considerations.
If the sampling process is interactive, it is important that the classi er used in that phase be e -ciently updatable; classi ers such as Naive Bayes appear to be a good option for that phase.
In contrast, for typical-size friend lists, we do not expect performance to be much of a concern in the classi er-construction phase.
For this part, user attention, rather than performance is the main bottleneck; in most cases, the classi er can be trained within a few seconds.
As we will see in Section 4, if it is important to communicate the model [pref back to the user, then a human-readable classi er (e.g., decision tree) is attractive for the second phase.
Of course, users are always adding new friends.
Suppose that the user has labeled an initial set of friends, using the active learning wizard described above.
Ideally, we would like to satisfy the following two goals with respect to incremental maintenance:
 which has been learned by the wizard, should make reasonable predictions for the new friends, without any additional input from user.
tinue labeling friends.
The wizard should use these new labels, in combination with the user s original input, without wasting the original labels.
Both of these goals are easily satis ed by the active learning wizard.
Given the original set of friends F with a subset Flabeled of them labeled, when some new set of friends F   is added, the privacy settings for the new friends can be predicted by constructing [pref using Flabeled, and applying it to each friend in F  .
The only part of this process that is tricky is managing features based on community structure.
Recall that community-membership features are extracted from the labeled and unlabeled data.
Thus, when new friends arrive, we will need to reconstruct the communities using F   F  .
However, the labels that the user has assigned to individual friends remain valid.
For example, in Figure 3, after new friends are added, the community structure may change (i.e., we may need to replace features G0, G1, ...).
However, the label allow still applies to the (new feature-vector representation of) friend Alice Adams.
Finally, if new friends are added and the user wishes to devote more e ort to re ning her privacy settings, this is easy.
The wizard simply adds F   to Funlabeled, and continues the sampling process described in the last section.
The active learning wizard interacts with the user by asking her to label speci c friends.
This type of interaction is ideal for nontechnical users, who have di culty reasoning Figure 4: Visualization of Decision Tree Model holistically about their policy con gurations.
On the other hand, the classi er and auto-con guration are essentially a black box, and more advanced users may want to understand the rationale behind the resulting con guration.
For these users, we propose some additional tools that allow the user to visualize and update the classi er learned by the basic wizard.
While the basic wizard can use any classi cation algorithm, if we are going to display the result to the user, then it is important to choose a classi er that is human-readable.
Thus, in the remainder of this section, we will assume that, in the classi er construction phase, the active learning wizard constructs a binary decision tree.
The basic structure of a binary decision tree is easily inter-pretable: Each interior node represents a binary condition (e.g., Hometown = NYC), and each leaf contains a decision (allow or deny).
Each node (either interior or leaf) corresponds to a set of friends that are consistent with the binary conditions from root to the node.
For the privacy-preference model, however, it is necessary to incorporate several additional pieces of information into the basic decision tree.
First, automatically-extracted communities (e.g., G20 in the running example) are meaningless to the user by default.
Thus, in the visualization, we need to produce a meaningful description of each community.
One reasonable option extracts unique keywords from the pro les of friends in each community (e.g., using the TF-IDF score).
Second, we observed that in some cases the resulting decision trees are large, and di cult to view all at once.
To help guide users towards parts of the tree that are likely to require attention, we incorporate two additional pieces of information for each node:   Class Distribution: For each node in the tree, the visualization indicates the class distribution (i.e., proportion labeled allow and deny) of the labeled friends who satisfy the conditions for the (subtree rooted at the) node.
  Representative Rate: the proportion of labeled friends among all friends who satisfy the conditions for a node.
Example 4.
Figure 4 shows a decision tree that was trained using User K s privacy preferences for Date of Birth.
For each node, the class distribution is shown in grayscale, and the representative rate is indicated by node size.
For example, the diagram indicates that friends who are members of be allowed to see Date of Birth.
The representative rate is high, meaning that the user has explicitly labeled most of these friends.
In contrast, notice that there is another node on the left, which describes all friends who are not part of HM Software Corp., and also not part of Alpha University Computer Science.
Few friends in this category have been labeled, as indicated by the small circle.
Further, the class distribution is heterogeneous.
The model visualization may guide the user in determining which friends need further attention.
After visualizing the model, the user may decide to label more friends.
She can do this by choosing a node (often one with low representative rate) and labeling more friends in the node.
We do this as follows: When the user clicks on a node (interior or leaf), the unlabeled friends in the subtree rooted at that node are shown to the user in order of decreasing uncertainty (de ned in Section 3.3).
The user could label some of the displayed friends, and the visualization would change accordingly.
Incremental maintenance of model visualization and mod-i cation is straightforward and does not require additional e ort.
After new friends come, they are added to corresponding nodes in the tree.
Class distribution will remain the same while the representative rate would decrease.
The modi cation process remains the same: unlabeled friends (including the newly added friends) of a node would be displayed to the user when a node is clicked.
The goal of our experiments is to analyze the e ort-accuracy tradeo  achieved by our privacy wizard.
Speci cally, we want to answer the following two questions:   How e ective is the active learning wizard, compared to alternative policy-speci cation tools?
  Which features (e.g., community structure, pro le information, etc.)
are the most useful for predicting privacy preferences?
To answer these questions, we collected raw privacy preference data from a population of real Facebook users.
Our results indicate that the active-learning wizard is more effective than existing alternatives.
The results also indicate that automatically-extracted communities are very e ective features for predicting privacy preferences.
As the basis for our evaluation, we collected detailed privacy preference information from a group of real social network users.
We conducted our study electronically using Facebook.
We selected Facebook in particular because of the availability of an open development platform [1], and we built a Facebook application, which allowed our study subjects (a set of Facebook users) to exhaustively label their privacy preferences for all of their friends.
Our application presented each study subject with two questionnaires.
The  rst questionnaire consisted of a series of coarse-grained questions, which asked, for each pro le data item, whether the user would like to share the data item with all friends, some friends, or no one.
For the purpose of the user study, we selected a representative set of Figure 5: Screenshot of user study application, general questions Figure 6: Screenshot of user study application, detailed questions.
pro le data items: Date of Birth, Home Address, Relationship Status, Photos, Political Views, Religious Views, and Status Updates.
A screenshot of the  rst questionnaire is shown in Figure 5.
The second questionnaire collected more detailed information.
For each pro le data item for which the user selected some friends during the  rst phase, we solicited detailed information during the second phase.
The questionnaire listed the user s friends in a random order, and for each friend f , we asked the user to indicate her preferred access level for the friend: Y ES (interpreted as allow), N O (deny).
The friends were presented in a sequence of pages, with 24 friends per page.
A screenshot of the second questionnaire is shown in Figure 6.
(The names of the user s friends have been hidden for con dentiality.)
In addition to the privacy preference information, the Facebook application allowed us to view the information about each subject s neighborhood described in Section 3.2.
A total of 45 people participated to our user study by labeling preferences.
Of the 45 respondents, 27 of them were male, and 18 of them were female.
The respondents are primarily the authors  colleagues, and they volunteered to participate.
Our respondents had an average of 219 friends.
The maximum number of friends was 826 and the minimum number of friends was 24.
During the  rst phase, 30 of the respondents indicated that at least one pro le data item should be visible to some friends.
In total, there were 64 (user, data item) pairs that required  ne-grained privacy controls; that is, the users speci ed that these data items should be visible to some friends.
Our experimental setup incorporated several open-source packages.
For community nding, we used the implementation of the edge-betweenness in the iGraph library [3].
(We modi ed the algorithm as described in Section 3.2.1 to  nd hierarchical communities.)
For classi cation, we used the tion in our user study.)
As expected, the active-learning approach (DTree-Active) outperforms the random-sampling approach (DecisionTree), and both outperform BruteForce.
The results for DTree-Active are promising from a practical perspective, too; by labeling just 25 friends, users achieve an average setting accuracy of over 90%.
Of course, by averaging across di erent users and data items, Figure 7 does not capture all of the interesting details of the comparison.
To understand the results better, we also developed a scoring approach.
Intuitively, for a particular (user, data item) pair, the score Sstatic is a real number in [0, 1.0] that measures the normalized area beneath the e ort-accuracy curve; higher scores are better.
Definition 1 (Static Score).
For a particular user and data item, the e ectiveness of a policy-speci cation tool can be summarized using a score, where AccuracyF (E = e) is the setting accuracy achieved after applying e ort e on the set of friends F : Sstatic = P
 e=0 AccuracyF (E=e)
 .
Using this scoring mechanism, our results are summarized in Figure 8, which shows the mean Sstatic score, as well as the standard deviation, across all 64 (user, data item) pairs: Tool DTree-Active DecisionTree BruteForce Sstatic mean


 std


 Figure 8: Comparison Summary (Static Case); Di erence between tools is statistically signi cant based on a paired t-test For each (user, data item) pair, we obtained a Sstatic score for each alternative policy-speci cation mechanism.
Observe that, for example, the scores obtained for user Bob s Date of Birth using DTree-Active and DecisionTree can be treated as a dependent pair.
Thus, we can test whether, for example, the Sstatic score for DTree-Active is signi -cantly better than the score for DecisionTree using a paired-sample t-test.
After performing this test, we discovered that, while the mean scores are similar, the di erences between the policy speci cation tools are statistically significant.
(DTree-Active is superior to DecisionTree, which is superior to BruteForce.)
Finally, while the results are omitted for space, we observed that for other classi ers the results are similar (i.e., active learning is superior to learning from a random sample, which is superior to the brute force approach).
The previous experiments focused on policy-speci cation for a static set of friends.
In this section, we continue comparing the three policy-speci cation tools, but this time in the dynamic case, where the user adds new friends over time.
In the following, we will denote the initial set of friends F , and suppose that the user adds a new set of friends F  .
To capture the dynamic case, we extend the scoring approach described in the previous section.
Speci cally, we will use two new scores: Spred and Sdynamic.
The  rst score (Spred) is based on the following scenario.
Using one of the policy-speci cation tools, the user assigns Figure 7: E ort vs. Average Accuracy tradeo  (within limited e ort 100) N aiveBayes, N earestN eighbors, and DecisionT ree operators found in the RapidM iner [31] package.
Our  rst set of experiments compares the active-learning wizard with alternative policy-speci cation tools.
Because our other experiments (Section 5.4) show that community-based features are extremely e ective, we use these features for the experiments in this section.
We include results for the following three approaches:   DTree-Active: This is a speci c implementation of the active learning wizard described in Section 3.
We used a Naive Bayes classi er in the sampling phase, and a decision tree to construct the  nal classifer.
  DecisionTree: To isolate the e ects of the uncertainty sampling, we have also implemented a strawman solution.
Whereas DTree-Active selects samples based on an uncertainty estimate, this algorithm selects samples at random.
Like the previous approach, it uses the labeled examples to train a Decision Tree classi er.
  BruteForce: As a baseline, we evaluated a strawman policy-speci cation tool based on the following process: The user selects a default setting (in our experiments, this is assumed to be the majority class label).
Then, the user can assign labels, one-by-one, to friends.
Any friend left unlabeled is given the default label.
The e ort required by this process is very similar to the e ort required to manually assign friends to lists, as required by the Facebook policy-speci cation tool.
In addition to the three tools described above, we also evaluated some variations of the active-learning and random-sampling wizards.
In particular, we tried using alternative classi ers (Naive Bayes, K-Nearest Neighbors, and Decision Trees) for both sampling and classi er construction.
The results were quite similar, and they are omitted for space.
We begin with the static case, where the user is constructing a policy from scratch for a static set of friends.
As the user applies more e ort (i.e., labels more friends), using each of the policy-speci cation tools, we expect that the user s setting accuracy will increase.
Figure 7 illustrates this e ort-accuracy tradeo  in a very rough way.
The x-axis shows the number of friends labeled (up to 100), and the y-axis shows the average setting accuracy.
(This is the average across all 64 (user, data item) e ort e).
Then, the new set of friends F   arrives, and we measure the setting accuracy for the new friends,4 which we denote AccuracyF   (E = e).
Like before, for a particular user and data item, we will measure this across all values of e, and summarize the result with a single score.
Figure 10 summarizes the results, using the Sstatic score.
In cases where p is low (i.e., users have homogeneous preferences for all friends), the improvement from using the active learning wizard is small.
However, when the p value is larger (e.g., p   (30%, 50%]), the active learning wizard is particularly helpful.
Definition 2 (Prediction Score).
The prediction quality of a policy-speci cation tool can be summarized using the following score.
AccuracyF   (E = e) is the predictive accuracy of the settings, trained using e ort e, and applied to a new set of friends F  : Spred = P
 e=0 AccuracyF   (E=e) .
The second score (Sdynamic) is based on a slightly di erent scenario.
In this case, we assume that the user labels E friends (from the original set F ).
Then, a new set of friends F   is added, and the user labels E  more friends.
We will use the notation AccuracyF  F  (E = e, E  = e ) to denote the resulting setting accuracy for the full friend set F   F  .
In this case, we will measure the accuracy across all values of E and E ; Sdynamic is a real number in [0, 1.0].
Definition 3 (Dynamic Score).
The e ectiveness of a policy-speci cation tool in a dynamic setting can be summarized using the following score: Sdynamic =

 e=0 P
 e =0 AccuracyF  F   (E=e,E =e )
 .
Using both of these scoring mechanisms, our results are summarized in Figure 9.
In order to simulate the case of adding new friends, for each user, we randomly pick 30% of their friends as new friends while the remaining are regarded as the original friends.
Again, based on a paired test, we also observe that DTree-Active is signi cantly better than DecisionTree, which is signi cantly better than BruteForce.
Tool DTree-Active DecisionTree BruteForce Sdynamic Spred mean


 std mean





 std


 Figure 9: Comparison Summary (Dynamic Case); Di erence between tools is statistically signi cant based on a paired t-test
 In our  nal set of comparison experiments, we observe that it is common for di erent users to have di erent distributions of privacy preferences.
For example, user A may allow 90% of his friends to view Date of Birth, while user B may assign only 40% of friends allow permission.
Ideally, we should adopt a policy-speci cation tool that adapts to these di erences.
In order to measure the e ect of skewed class distribution on each of the policy-speci cation tools, we use p to represent the proportion of labels in the minority class (i.e., 0   p   50%), and we partition our experimental data into three groups according to p value: p   (0%, 10%], p   (10%, 30%] and p   (30%, 50%].
new friends are obtained by applying the classifer to F  .
The best BruteForce can do is assign each of the new friends the default label.
Tool DTree-Active DecisionTree BruteForce p   (0%, 10%] mean


 std


 p   (10%, 30%] mean


 std


 p   (30%, 50%] mean


 std


 Figure 10: E ects of class distribution (Sstatic score)
 Our  nal set of experiments compares the e ectiveness of di erent alternative features, which can be used by learning-based wizards.
In preliminary studies, we observed that DTree-Active, which uses a Naive Bayes classi er during the sampling phase, and then constructs a DecisionTree clasi er using the labeled data, resulted in the highest accuracy of all our active learning wizards (by a slight margin).
Thus, in this section, we will present results based on the DTree-Active tool.
We compared  ve di erent combinations of features: (For more details, see Section 3.2.)
  Community These experiments used only features based on extracted communities.
  Pro le These experiments used only pro le-based features such as gender, age, education history (high school and college), work history, relationship status, political views, and religious views.
  Activity These experiments used only features based on online activities such as Facebook groups,  fan  pages, events, and tagged photos.
  None-Comm These experiments used only Pro le and Activity features.
  All These experiments used all of the above.
Figure 11 summarizes our results.
In addition, as described in the last section, we also conducted a paired sample t-test for each of the scores Sstatic, Sdynamic and Spred).
We observed that Community is statistically signi cant better than all other feature combinations.
It s interesting to notice that features as pro les and online activities are not helping much, it may be partially because that these features are usually incomplete and they re also conjecturable from the community features.
The development of usable,  ne-grained tools for protecting personal data is a serious emerging problem in social media [4, 19, 21, 22, 23, 36].
In one study, Acquisti and Sstatic Sdynamic Spred Features Community mean


 None-Comm 0.87
 Pro le Activity All std mean









 std mean









 std




 Figure 11: Comparing features (DTree-Active) (Facebook, MySpace, Friendster, etc.)
expressed high levels of concern about their privacy, the same users often did not implement strict privacy controls over their pro les.
In many cases, this appeared to be due to users  poor understanding of the available privacy controls and the visibility of their pro les [4, 22].
Several recent papers have proposed novel user interfaces for specifying Facebook-style privacy settings, but none has constructed a wizard of the style described in this paper, which models and anticipates a user s preferences based on limited user input.
Most related to our work is a pair of proposals by Adu-Oppong et al. [5] and Danezis [14].
Both propose partitioning a user s friends into lists, based on communities extracted automatically from the network, as a way to simplify the speci cation of privacy policies.
([14] describes this partitioning as a way of inferring a privacy  context. ) While both are related to our work, neither studies real users  privacy preferences to evaluate their proposal.
Also, in both cases, the proposed tools are based on partitioning friends into a  xed set of non-overlapping communities, which does not resolve the challenge of community granularity.
In a mobile location-based application, Ravichandran et al.
[34] studied the problem of predicting a user s privacy preferences (i.e., share her location or not) based on location and time of day; however, this work did not consider taking an underlying social network structure into account when making these decisions.
After a policy is speci ed, many have observed that it is important to provide tools to help users understand the resulting settings.
Lipford et al. proposed and evaluated an  audience view,  which allows a user to view her pro le as it appears to each of her friends [27].
A variation of this interface appears to have been recently adopted by Facebook.
This work is quite complimentary to ours; while the audience view helps a user to understand and evaluate the correctness of an existing policy, it does not assist the user in creating the policy in the  rst place.
In a similar vein, recent work has proposed a methodology for quantifying the risk posed by a user s privacy settings [30, 28]; at a high level, a risk score communicates to a user the extent to which his privacy settings di er from those of other users who are close to him in the social network graph.
Like the audience view, the score provides feedback to the user regarding his existing settings, but it does not help him in creating an initial policy.
Further, the tools only provide a single score, so if a user s privacy settings are out of line, they do not communicate to the user precisely how he should re ne his settings in order to achieve a more acceptable con guration.
Fong et al.
[17] and Carminati et al.
[11, 12] look to formalize the access control model required by social networking sites.
Our work is complementary; the goal is to assist users in expressing their privacy preferences.
In this paper, we have focused on helping users to express simple privacy settings, which is a di cult task on its own.
We have not considered additional problems such as inference [40], or shared data ownership [38].
As a simple example of the former, suppose that a user Alice wishes to hide her political a liation.
The  rst problem, which is the focus of this paper, is to make sure that Alice can even express this preference to the social networking site.
However, even if the site hides Alice s political a liation, it may still be possible for an attacker to infer the hidden information [40].
(For example, if 95% of Alice s friends are liberal, then there is a good chance that Alice is also liberal.)
Interestingly, it is often not possible for Alice to prevent this kind of inference by simply con guring her own privacy settings.
The Pri-vAware system [8] makes an initial step toward quantifying the risk of this type of inference; as a solution, the authors suggest removing certain friend relationships to reduce the inference risk.
Broadly-speaking, social networking websites have led to a number of interesting research questions in information security and privacy.
For example, in 2007, Facebook opened a development API, which allows developers to construct their own applications leveraging user pro le data [1].
This was met with some concern for personal privacy; for example, one study revealed that applications written using this API could often access signi cantly more information than necessary for their core functionality [16].
As an initial solution to this problem, Felt and Evans proposed a proxy-based architecture, which limits the amount of information available to installed applications [16].
Singh et al. propose a trusted third-party mediator called xBook [37].
Lucas and Borisov [29] and Anderson et al. [6] consider an even more restrictive case in which users are reluctant to share their personal information with the Facebook service.
Social networking sites may also enable new forms of classical attacks, including phishing [9] and spam [10].
[15] considers the new risk to anonymous routing that is posed by an attacker who knows users  social network graphs.
Finally, recent work has focused on the privacy risks associated with publishing de-identi ed social network graphs for research.
Even if all pro le information is removed, it is often possible to re-identify individuals in the published data simply based on unique graph topologies [7, 24, 32].
Privacy is an important emerging problem in online social networks.
While these sites are growing rapidly in popularity, existing policy-con guration tools are di cult for average users to understand and use.
This paper presented a template for the design of a privacy wizard, which removes much of the burden from individual users.
At a high level, the wizard solicits a limited amount of input from the user.
Using this input, and other information already visible to the user, the wizard infers a privacy-preference model describing the user s personal privacy preferences.
This model, then, is used to automatically con gure the user s detailed privacy settings.
To illustrate this idea in concrete terms, we have built a sample wizard, which is based on an active learning paradigm.
We have also constructed a visualization tool, which allows advanced users to view and modify the resulting model.
Our experimental evaluation, which is based on detailed privacy-preference information collected from 45 Facebook users, indicates that the wizard is quite e ective in reducing the amount of user e ort, while still producing high-accuracy settings.
The results also indicate that the community structure of a user s social network is a valuable resource when modeling the user s privacy preferences.
In the future, we plan to conduct more user studies to understand how users like the wizard comparing to alternative privacy settings tools, and how much time users are also consider other instances of privacy wizards.
For example, our active learning wizard solicits user input in a very simple form (i.e., asking the user to assign a label to a (friend, data item) pair), which is easy for the user to understand.
Perhaps there are other questions that would yield more information, or require less user e ort.
Also, in this work, we considered three main sources of information in a user s neighborhood when constructing the privacy-preference model: communities, pro le data and online activities.
In the future, other sources of information may be taken into account.
For example, it would be interesting to understand whether ideas such as tie strength [20] are useful in predicting privacy preferences.
This work supported in part by NSF grants IIS-0438909 and CNS-0915782.
The authors would like to thank Lada Adamic for her help in understanding the complex networks literature, and H.V.
Jagadish and Alex Halderman for their comments on earlier versions of the paper.
