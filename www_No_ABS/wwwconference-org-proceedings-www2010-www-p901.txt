Web search engines have completely changed the way people acquire information during the last ten years.
By providing a comprehensive portal between the Internet users and the Web, search engines are able to take a user query and return a ranked list of web pages according to the relevance between queries and the search engine index, which consists a subset of the entire Web.
Recent study indicates that search is still quite di cult, approximately 50% of times search engines fail to return relevant documents.
The reason of failure is that the length of the queries is usually quite short, so that understanding user intents correctly has been a critical yet quite di cult task for search engines.
Among a variety of techniques, query suggestion related techniques [1, 2, 3, 8, 11, 12, 14, 18] have become an e ective way to interact between users and search engines, hence to improve the relevance of search results.
Among all query suggestion techniques, one of the most important and e ective techniques refers to query log analysis [2, 3, 8, 12, 18].
Speci cally, query logs are server-end logs that record user activities in search engines.
A typical query log entry contains timestamp, query, clicked Urls as well as user personal information.
In order to learn a query suggestion model, a commonly used approach is to leverage graph representation which forms query and URL relationship into bipartite graphs.
A query-URL bipartite graph usually consists of two disjoint sets of nodes, corresponding to queries and URLs respectively.
An example of this bipartite representation has been shown in Figure 1(a), where the left-hand set of nodes are queries and the right-hand set are URLs.
The edge between a query q and a URL u indicates user clicks of u when issuing q (for simplicity, the click numbers are omitted from the graph).
The click graph possesses large amount of potential information that can be learnt for query suggestion, query clustering, query reformulation and so on.
As a matter of fact, a myriad of techniques have been proposed.
Among them, random walk technique is one of the most e ective methods [12, 7].
However, leveraging only the click information has a serious drawback.
That is, the models learnt from click graph can only bene t popular queries which possess enough user click feedbacks.
While for rare queries that have only appeared a handful of times in the logs with very few clicks, click graph is unable to capture the underlying relationship between queries.
For example, in Figure 1(a), q1 and q2 do not have commonly clicked URLs, thus a random walk Queries Urls audi parts audi bodywork audi q1 q2 q3 u1 u2 u3 u4 u5 audipartstore.com audiusa.com audi parts q1 audirepair.autorepairlocal.com NWaAudidealers.com audi bodywork en.wikipedia.org/wiki/Audi audi q2 q3 u1 u2 u3 u4 u5 audipartstore.com audiusa.com audirepair.autorepairlocal.com NWaAudidealers.com en.wikipedia.org/wiki/Audi (a) Click Graph (b) Skip Graph Figure 1: An illustrative example of query-URL click graph (a) and skip graph (b).
Query audi parts and audi bodywork are not correlated if only performs random walk on the click graph, but will be highly correlation if random walk is performed on the skip graph.
More details on the text.
model which discovers query relationship according to their common clicks is unable to discover any correlation between q1 and q2.
While it is well known that in search engines, query frequencies follow a power-law distribution where most queries are issued very few times by users, rare queries together constitute a great amount of search tra c which potentially a ects the relevance and revenue of search engines signi -cantly.
Therefore, the lack of e cient and e ective proposals to deal with rare queries needs our immediate attentions.
Figure 1 presents a motivation of our approach.
The left  gure (a) shows the click graph for three queries and  ve URLs that returned as top SERP results.
Ideally, audi parts should be a good suggested query for audi bodywork (and vice versa).
However, after performing a random walk on the click graph, only the query audi can be suggested to audi parts because there is no commonly clicked URLs between audi parts and audi bodywork so that their correlation is zero.
However, if we leverage the top-skipped URLs1 for audi parts and audi bodywork as shown in Figure 1(b), it can be clearly observed that both queries skipped their top-returned two URLs: NwaAudidealers.com and en.wikipedia.org/wiki/Audi.
As a result, a random walk on the skip graph will assign a high correlation score to these two queries.
Our work is inspired by the principle of pseudo-relevance feedback [16, 15, 10, 20, 19] which assumes that the top-k returned documents from search engines are always relevant to the queries, regardless of whether they are clicked or not.
However, for rare queries, many times the top skipped URLs contain di erent levels of information than the clicked URLs.
Because top-returned URLs are more likely to have high static rank scores which are representative of the high-level topic that the query belongs to.
e.g., the URL u5 is a general entry about audi, while queries audi parts and audi bodywork address di erent aspects of user need of the spe-ci c car model.
Although users who issued these two queries clicked on more speci c URLs like audipartstore.com, a general URL o ers a potential topic link between these queries.
To further back up our argument regarding using both clicked and skipped URLs for rare query suggestion, we care-
without being clicked.
So if a user clicked the 3rd-ranked URL, then the 1st and 2nd URLs are said to be skipped.
fully analyzed query logs from a commercial search engine.
Figure 2 shows user session statistics in one of the data sets we use in the experiment which contains 40 million unique queries.
The  gure compares the query frequency (x-axis) against the number of clicked and skipped URLs (y-axis).
It can be observed that when the query frequency is low, more URLs are skipped than clicked during the same user session.
However, with the increase of query popularity, the click patterns become more stable.
Generally, users are tend to click more often on top-returned results for popular queries, while for rare queries, the clicks are more random and thus have higher entropy scores.
We further analyzed the quality of skipped URLs for rare queries.
We selected 6,000 queries which have been issued less than 20 times within a week and asked human judgers to judge the relevance on a 1-5 scale (5 means the best).
Figure 3 demonstrates the comparative ratings between skipped and clicked URLs.
Overall, skipped URLs indicate a little bit less relevance than clicked URLs.
On average, clicked URLs have a rating of 3.78 while skipped URLs have 3.65.
This observation further supports our claim that skipped URLs should be leveraged for rare queries in the context of relevance measurement.
In this paper, we propose a novel graph combination-based rare query suggestion framework.
Our proposal can be sketched into four major steps:
 logs, where the click graph contains query-URL click information and the skip graph contains query-URL skip information, 2. perform random walk on each of the graphs, using the random walk with restart (RWR) technique [17],
 of URLs,
 model to estimate the best parameters of random walk and the combination rate of click and skip graphs.
Finally, combine two query correlation matrices to form the optimal query correlation matrix, which is used for query suggestion.
f o #








 URLs Clicked





 Query Frequency



 s


 f o #








 URLs Skipped





 Query Frequency



 Figure 2: Number of URLs clicked vs. number of URLs skipped in the same user sessions from one week search log.
There are more URLs skipped than clicked for queries with lower frequencies.
Our model speci cally addresses two concerns.
First, how to choose the optimal restarting rate for the random walk?
Second, given two query-URL correlation matrices, how to optimally combine them?
The reason is that the restarting rate directly a ects the transition probability of random walk from nodes to nodes, which a ects the distribution of query relevance scores that is critical for determining the most relevant neighbor nodes.
On the other hand, the combination rate decides the level of contributions from click and skip graphs respectively.
In pseudo-relevance feedback models, this ratio is the same for both clicked and skipped URLs, which is not optimal in practice for rare queries, as we shall see in the empirical analysis.
To the best of our knowledge, we are among the  rst to address the importance of the restarting rate (or jumping rate) of random walk, and optimize the parameter in a principled way.
In other random walk-like models, this rate is either pre- xed (e.g., the original PageRank paper [13] used 0.85 as the jumping rate), or empirically chosen without any support information [7].
The rest of the paper is organized as follows: Section 2 presents the literature in query suggestion, query clustering related research; Section 3 introduces our framework for optimal rare query suggestions; Section 4 provides empirical results on the performance of our model;  nally, Section 5 concludes our proposal with future work.
A variety of research e orts have been devoted to address query suggestion related problems in literature, such as query classi cation, query clustering and query reformulation.
Among them, most of the proposals directly or indirectly make use of query logs that contain query click information.
By representing the relationship between queries and URLs into a click graph, many researchers have investigated in using random walk-related techniques for learning underlying query-document relevance.
In [7], Craswell and Szummer proposed a Markov random walk model on the click graph to rank documents given a user query.
The authors proposed a backward random walk comparing to the traditional forward random walk techniques such as page rank [13].
Speci cally, the backward walk addresses the bias towards documents with more clicks in the forward walk models, by assuming a uniform prior on all documents.
Experimental results indicate that the backward model are more e ective in retrieving relevant documents for images.
Essentially, the backward model can be treated as a nor-URL Skipped URL Clicked









 g n i t a



 e g a r e v







 Query Frequency



 Figure 3: Human judger ratings in terms of relevance for clicked and skipped URLs in query logs.
Break down accordingly to query frequency.
Clicked URLs and skipped URLs have almost the same ratings for rare queries (queries with frequency less than 20).
malization on the document clicks instead of query counts.
Thus the most likely transition from a document to query will not be a ect by the raw account of the queries, which eliminates the click bias.
Similarly, Deng et.
al [9] proposed an entropy-bias framework to represent the edge weights between query and URLs.
Comparing to the traditional raw-click frequency-based count of edge weights, the authors argued that various clicks should be treated di erently based on the importance of the URLs and the queries.
i.e., clicks on more speci c URLs should be weigh more than clicks on general URLs.
An inverse query frequency (IQF) based weighting mechanism was introduced to estimate the click quality.
The authors applied the IQF model on random walk and the experimental results indicated superiority over the traditional count-frequency models.
In [12], Mei et.
al introduced a parameter-free random walk model for query suggestion.
This query-dependent model addressed the e ciency issue in random walk by constructing a subset of nodes in the click graph based on a depth rst search from the target node.
Their model estimated the transition probabilities between two queries via an inner product-based similarity measurement.
Consequently, the model is able to suggest semantically related queries to the original query by iteratively performing random walk and output the highest scored nodes.
Not until recently has the importance of rare query classi- cation/suggestion attracted enough attention from the IR community.
In [6], Broder et.
al leveraged the results from search engines as an external knowledge base for building the word features for rare queries.
The authors trained a classi er on a commercial taxonomy consists of 6,000 nodes for categorization.
Experimental results indicated a significant boost in terms of precision than the baseline query expansion methods.
Lately, Broder et.
al proposed an online expansion of rare queries in [5].
Their framework started by training an o ine model that is able to suggest a ranked list of related queries to the incoming rare query.
The rare query is then expanded by a weighted linear combination of the original query and the related queries according to their suggestion.
The matching precision on the expanded queries demonstrated improvement over the original un-expanded version of queries.
This section introduces our framework for rare query suggestion.
Since our model is inspired by pseudo-relevance feedback, it is valid to assume that search engines do not generate random top results.
Users click the results based on their own perception of relevance so that the a URL may be clicked by one user but skipped by others.
Ideally, all returned URLs should be considered relevant.
However, since we are only con dent about top-ranked URLs, we will only consider the skipped URLs above the last user click.
Next, we discuss how the query-URL graphs are generated.
We construct two bipartite graphs that correspond to explicit user feedback (clicks) and implicit user feedback (skips) from query logs respectively.
The data we use is projected from the search log of a commercial search engine which serves millions of users daily.
Each (simpli ed) record of the log contains (q, uq, Iq), where q corresponds to a user-issued query instance, u is a set of top-k URLs returned by search engine, i.e., uq = {uq k}, and Iq is a vector that contains the corresponding binary variables indicating whether i   {0, 1}.
Note that a URL has been clicked or not, i.e., I q di erent users may issue the same query instance but click on di erent URLs.
Thus, it is quite common that a query q have multiple query instances.
To aggregate the clicks and skips from all query instances for a speci c query q, we de ne a triplet (q, uq, cq, sq), where 1, ..., uq dX j=1 dX j=1 cq i = sq i = I(I q i = 1), i = 1, ..., k, I(I q i = 0), i = 1, ..., k.
(1) Here I is an indicator function that equals 1 when the condition holds and 0 otherwise.
Mathematically, cq i and sq i indicate the number of time a URL ui has been clicked and skipped when users issued query q.
For example, a query q has three query instances {q1, q2, q3}, and the click pattern of the top-5 returned URLs is using eq.
(1), we can get the aggregated clicks and skips: q c s q = {3, 1, 1, 0, 2}, = {0, 2, 1, 2, 0}.
(3) q q 2andu Notice that here tw0 URLs u 3 are both clicked and skipped by di erent query instances.
Next, given a set of m user-issued queries q and the union of n returned URLs u, we represent the relationship between queries and URLs using two squared weight matrices W + and W   , de ned as follows:        
 =




 =



 where C   Rm n, C(i, j) S   Rm n, S(i, j) , (cid:2) = cqi uj (cid:2) = sqi uj .
Since the constructed matrices correspond to the bipartite graphs of a query set and a URL set, there exists no edges between queries (and URLs), as indicated by the big 0 in the diagonal of both W + and W   , which should be learnt from our model.
Table 1 shows several queries and the number of times It can be the top-returned URL being clicked / skipped.
observed that for popular queries like facebook and ebay, the top-ranked URLs are much more likely to be clicked, resulting a low click entropy.
While for queries with lower bowling shoes, the top-ranked URLs, al-frequencies e.g.
though being relevant, do not have a clear advantage over the lower-ranked URLs in terms of clicks.
And in fact, these rare queries have much higher entropies that is more di cult for search engines to determine user intents.
Table 1: Example of URL clicks and skips.
Popular queries have more clicks than skips and thus lower entropies, while rare queries often exhibit much higher entropies.
q1 = {1, 1, 0, 0, 0},
 q2 = {1, 0, 0, 0, 1},
 q3 = {1, 0, 1, 0, 1}.
(2)
 Clicked Skipped Unobserved





 ......
Figure 4: An example of clicked, skipped and unobserved URLs for query instance q3 in eq.
(2).
Figure 4 shows the example of q3 that consists of clicked, skipped and unobserved URLs.
Summarizing eq.
(2) up by Given the weight matrices of query-URL relationships, our objective is to de ne a score that indicates how closely two queries are.
Since the original W matrices contain no such information, we propose to leverage the technique of random walk with restart (RWR) to learn the relevance score between queries [17].
RWR is a technique which speci es a starting node for a walk, then iteratively visits its neighbors with probability proportional to the edge weights.
At each step, the walk has a constant probability of p to jump back to its starting node.
It has been shown that after a certain number of steps, the probability of visiting a node j given the starting node i will become stable.
We can thus de ne e r o c
 e c n a v e e
 l










 Original Query URL weight matrix Weight Matrix with p = 0.1 random walk p = 0.9 p = 0.5 p = 0.1 Weight Matrix with p = 0.5 random walk Weight Matrix with p = 0.95 random walk


 Figure 5: The neighborhood relevance score distribution w.r.t.
di erent restarting rates p of random walks.
the ranking vector for all nodes given i as starting node: Ri = pW Ri + (1   p)Ei, (4) where W is the weight matrix, Ei de nes a starting vector whose ith entry is 1 and the rest 0.
Each entry of Rij de nes the relevance score of node j to the starting node i.
It can be observed that the above equation can be solved iteratively by replacing Ri from the previous iteration.
After convergence, the  nally ranking matrix R = {R1, ..., Rq} for q nodes is a column-normalized matrix that contains the stable relevance scores of all nodes within the graph.
For example, in Figure 1, the most relevant query for q1 (audi parts) is q3 (audi) according to the click graph, since R13 = 0.24 and R12 = 0.
On the other hand, the skip graph suggests that q2 (audi bodywork) has a higher relevance score than q3.
The only parameter in eq.
(4) is the restarting rate p which controls the shape of the probability distribution of neighborhood relevance scores.
Higher p values have more local e ect which assign very higher scores to its nearby nodes and generally ignoring the nodes far apart, while lower p values generate  atter probability distributions so that the start node i are more likely to reach out to distant nodes.
Choosing the right restarting rate is critical for learning the query relevance scores.
As it can be seen from Figure 5, the ranking vector will lose discriminative power when p is too low.
On the other hand, if p is set to be very high, many nodes will end up with no correlations with the starting node i.
Figure 6 further plots the density of weight matrix and shows the impact of p.
Unfortunately, optimizing the restarting rate has generally been ignored in literature.
For example, in the random walk-like pagerank algorithm [13], the restarting (jumping) rate is pre- xed to be 0.85 without optimization.
In some other e orts, researchers empirically chose p in a grid-search way which is however dataset-dependent [7].
In the next two subsections, we propose a gradient optimization framework which leverages URL categorization information from ODP to choose the best parameters.
To get the ground-truth of URL correlation, we acquire the categorization labels of URLs from the Open Directory Project (ODP)2.
ODP is a human-edited repository 2http://www.dmoz.org/ Figure 6: The density of weight matrix with different restarting rates.
p=0.1 gives an over-dense matrix while p=0.95 results in a matrix that is too sparse.
Note that self-correlation has been removed from the graph.
of URLs and categories that contains more than 4 million URLs with over 590,000 categories.
The categories of URLs are organized in a tree-structured taxonomy where more general topics are at higher levels.
In this paper, we leverage the top three levels of the ODP categorization.
For example, the URL {research.microsof t.com} belongs to /Computers/Companies/M icrosof t Corporation/.
An example of taxonomy can be found in Figure 7.
To e ciently generate labels for millions of URLs, we make a simpli ed assumption that all URLs within a domain have the same category.
For URLs that do no belong to the ODP repository, we leverage a content-based hierarchical classi er to generate labels [4], which classi es a URL from top to bottom and re nes the categories by propagating classi cation errors in a bottom-up manner.
However, since in our framework we point out a general guideline of leveraging URL information for query suggestion, the generation of URL labels is beyond the scope of this paper.
In order to determine the correlation between URLs, different weights are assigned to each level of the taxonomy.
Generally, lower levels receive higher weights since the categories are more speci c than top levels.
Algorithm 1 sketches the process to calculate correlation, where the multiplier m controls the bias towards lower levels.
For example, for m = 2, top-three levels get weights of {1, 2, 4} respectively.
Therefore, node 1 and 2 in Figure 7 will have correlation of 3/7, node 3 and 4 correlation of 7/7, and node 1 and 3 of
 It should be noted that under our assumption that URLs having the same category in each domain, the query-URL weight matrix can therefore be compacted into query-domain matrix, which could possibly save much more computational time for random walk.
However, it is critical to understand that the URL correlation is a guideline for optimizing the parameters for random walk as we shall see in the next section, but should not a ect the relevance between queries.
For example, users issue buy printers and buy monitors are very likely to visit both dell.com and hp.com, but apparently these two queries have di erent intents.
Aggregating URLs into domains will possibly rank buy monitors to be more Companies Conferences Dell









 http://www.dell.com http://www.ibm.com http://www.nips.cc http://www.icml2006.org Figure 7: An example of ODP taxonomy for URLs.
We leverage the top three levels of categorization in this paper.
Algorithm 1 URL Correlation Calculation
 multiplier m if l1(i) = l2(i) sim = sim + weight
 3: for each level i in the tree




 9: end for 10: sim =
 end if denominator = denominator + weight weight = weight   multiplier denominator sim relevant to buy printers than other queries such like printer supplies.
In practice, we also notice that the query-URL matrix performs better than query-domain matrix in terms of determining query relevance.
After performing random walk as in eq.
(4), two ranking   matrices R+ and R can be obtained from the click and skip graphs respectively, which can be further decomposed into       +
 =



  
 =  

  



  
     where  Q is the estimated query correlation matrix,  U the estimated URL correlation matrix, and  Q  U the normalized estimated query-URL relationship.
  Since both R+ and R are column-normalized weight matrices, a linear combination is proposed to estimate the ideal correlation matrix, so that the combination will preserve the property of column normalization: + (1    )R  ,     [0, 1], +  R =  R (5) therefore, the estimated URL correlation matrix is also a linear combination  U =  U + + (1    )U  ,     [0, 1].
Along with the restarting rate p of random walk, the combination ratio   is the other parameter in our model.
Since we have the ground-true URL correlations U from ODP data, we can optimize the parameters by minimizing the absolute loss of the estimated  U, (p(cid:2),  (cid:2) ) = arg min p(cid:2), (cid:2) ||  Up,    U||, (6) (7) where  Up,  is the estimated URL correlation given parameters p and  .
Algorithm 2 Parameter Optimization
  }, URL correlation matrix U
 3: do 4: calculate f (p,  ) according to eq.
(8)
      f = = (dfp, df ).
 f  p ,
   f =  f   dfp  p df   p !
.
dfp   df      (cid:2) p (cid:2)         = p     [ 
 f ]  1  f 6: update (p,  ) by the equation

 Since the above equation does not have a close-form solution, we propose to estimate the optimal value using numerical methods.
To be concrete, we specify a function f of p and  , f (p,  ) = {U(i, j)    Up, (i, j)}, (8)

 i j and  (cid:2) and use Newton s method to  nd its  rst and second derivatives so that during each iteration, both p and   are optimized.
The new set of p(cid:2) is then used to perform a new round of random walk as well as the combination, in order to update the estimated URL correlation matrix  Up(cid:2), (cid:2) .
The process continues until the change of f becomes insignificant.
Figure 8 illustrates an example of this optimization.
Each subplot is a density plot of a matrix that shows the absolute di erence between  Up,  and U.
Each dot shows a point-level di erence, where darker color indicates higher di erence and white color means subtle di erence (we used
 iteration = 1, the di erence is signi cant since p and   are randomly initialized.
With the function gradually being optimized with better parameters, the discrepancy starts to vanish.
After the 20th iteration, only less than 5% entries in the matrix are signi cantly di erent.
Typically, the optimization  nishes within 30 iterations.
Finally, the optimal query correlation  Qopt is leveraged for query suggestion.
This section provides empirical results of how the proposed method performs on a large-scale data set, as well as the comparison between di erent random walk models.
We collected a sample of one month query logs between March 16 and April 14 from a large commercial search engine, which contains approximately 40 million unique queries and 110 million query instances.
Since our focus is on rare queries, we  ltered out all popular queries and only kept queries with less than 20 appearances in the log.
We also removed queries that have URL fragments and long queries (more than 10 words).
Overall, we used 3,299,278 unique queries in our experiments.
The data set also contains 8,139,150 user clicks and 13,577,113 skips on a total of 7,784,037 URLs.
can be de ned as: P (j) = # of relevant queries j .
(9) The top N precision is the aggregated precision from all queries in the evaluation set (K is the total number of queries):
 i=1 P (N )

 .
(10) Figure 8: An illustration of the absolute loss (eq.
(7)) of ||  Up,    U|| during di erent iterations with p and   values.
Darker color indicates higher inconsistency (more loss).
For comparison, three algorithms were tested on the same data set.
The baseline approach is a random walk with restart model that only leverages click information from the query log (RWR-Base).
We use the same algorithm as shown in Algorithm 2 to optimize the restarting parameter p, except that in this case the combination rate   is set to be 1.
The second approach is similar to pseudo relevance feedback [15, 19], where all top URLs returned by a search engine are treated as relevant (RWR-Pseudo).
We form edges between a query and top-10 returned URLs.
We then perform a random walk on the click graph that includes all these edges.
Finally, we also implemented the backward random walk [7] using the pseudo relevance model (RW-Back).
We only considered the  101-0.9-backward  model since it performed the best among all models.
Here 101 means 101-step random walk and 0.9 indicates the self-transition probability.
Notice that the  rst and the second methods are supervised random walks which are optimized use ground-truth, while for the third method, the number of random walk steps and the transition probability are  xed but not optimized for the data set.
Since our algorithm is a combination of positive and negative feedbacks, we denote it as RWR-Combo.
We used a similar evaluation process as in [7].
Since it is di cult to judge all the results for this data set with 3 million queries, we resort to sampling methods instead.
We  rst uniformly sampled 500 queries from the set.
The top 5 suggested queries generated from each of the four algo- rithms are evaluated, which results in a total of 2,500 relevance judgments.
Each of the suggested queries are judged by two human judgers.
Each query was judged to be either relevant or irrelevant.
The survey tool was designed in the way that judgers are able to browse the search engine result page (SERP) for the given query when judging the relevance of suggested queries.
The judgers are also allowed to navigate through links in SERP to help better understand the meanings of the query if necessary.
The list of suggested queries from the four algorithms are randomly ordered so that the judgers are not aware of the particular algorithm behind them.
We employ two well-known metrics in information retrieval (IR) community to measure: Precision at rank N (P @N ) and Mean Average Precision (M AP ).
Given a query qi and On the other hand, M AP averages the precision of a given query after each relevant query is retrieved, this metric focuses on both precision and recall so that the earlier relevant documents are retrieved, the higher M AP score will be.
To be speci c, for each query qi,
 j=1(P (j)   I(j)) # of relevant queries AvePi = , (11) where P (j) is the precision at position j as de ned in eq.
(9), I(j) is an indicator function that equals 1 when the j s suggested query is relevant and 0 otherwise.
M AP is the average score over all K queries in evaluation.
Table 2 summarizes the overall performance of the four algorithms in the sample set.
Our algorithm (RWR-Combo) successfully outperforms all other methods in both M AP and P @5.
The random walk using pseudo-relevance (RWR-Pseudo) also has a good performance and beats the backward random walk (RW-Back).
The random walk method leveraging only click information (RWR-Base) shows the worst performance.
These results indicate two facts: (1) using only click information and ignoring the skipped URLs is not e ective in suggesting relevant queries, and (2) treating clicks and skips with equal importance (RWR-Pseudo) is not as e ective as assigning di erent weights to both feed-backs (RWR-Combo).
We also notice that the unsupervised RW-Back method outperforms the baseline RWR-Base a little bit in both metrics.
Next, we break down the performance of these four algorithms into individual queries.
Figure 9 shows P @5 for di erent queries.
While performing the best on most of the queries, our RWR-Combo model also exhibits the lowest variance (0.021).
The baseline RWR-Base shows the highest variance 0.036 among all.
Overall, RWR-Combo outperforms RWR-Pseudo in 19 queries out of the 24 samples.
We also want to observe the quality of query suggestion at di erent positions.
Therefore, we calculate P @1 as well as P @5 as illustrated in Figure 10.
Our algorithm shows 65% of precision at position 1, an improvement of 9% over P @5.
We notice that the baseline approach only has less than 3% of improvement at position 1, which demonstrates that with only click information, even the top-suggested queries are not quite relevant in the case of rare queries.
To illustrate the signi cance of the performance improvement, we conducted rigorous statistical signi cance test on the results of P @5.
Usually, a p-value of less than 0.05 indicates a signi cant improvement.
We performed paired t-test on every pair of the four algorithm.
Table 3 summarizes the results.
Each row shows an algorithm which compares the performance improvement over each column of algorithms.
For example, the entry of the  rst row and  rst column can be interpreted as: RWR-Combo performs RWR-Base RWR-Pseudo RW-Back RWR-Combo









 Table 2: Overall performance comparison of four algorithms in terms of M AP and P @5.
Our algorithm (RWR-Combo) outperforms others in both metrics.
cally signi cant with a p-value = 0.002.
From this table, we also observe that using pseudo relevance show signi cantly better precision than both the backward walk and walk on only click graphs.
On the other hand, although RWR-Back shows some performance improvement over the baseline as indicated in Table 2, the improvement is not signi cantly enough (p-value = 0.11).
To show the parameter sensitivity, we plot the value of f (p, a) as in eq.
(8) in Figure 11.
The optimal result is achieved while f is minimized, when   = 0.765 and p =
 starting node without hitting other nodes) and   = 0 (without using any click information).
It can also be observed from Figure 11 that for any particular value of  , the value of p around 0.6 and 0.85 gives the best results.
Likewise, for any particular value of p,   between 0.65 and 0.8 performs the best.
It is also observable that the loss function possesses a global minimum, so that no matter how parameters are initialized, the best result can always been achieved.
@










 RWR Combo RWR Base RWR Pseudo RW Back








 Query ID Figure 9: Performance break down of precision for each query.
RWR-Combo performs best for most rare queries.
Table 4 shows some example queries and the suggestions by di erent algorithms, where queries with bold font are judged to be relevant by judgers.
Our algorithm returns more relevant queries than any others in all four cases.
The queries valentine one and single ladies are di cult queries which has di erent intents than their literal meanings.
Our algorithm successfully discovers the underlying user intent and makes correct suggestions.
On the other hand, our algorithm also exhibits its capability of diversifying suggestions to queries that have multiple intensions, e.g., dc ups could refer to both the power system and the postal service.
n o i s i c e r





 RWR Combo RWR Pseudo RWR Base RW Back

 Figure 10: Precision at di erent rank of suggested queries.
RWR-Combo achieves the highest precision of 65% among all algorithms at position 1 and 5.
)   , p ( f s s o l d e z i l a m r o n










 p



  


 Figure 11: Normalized loss as in eq.
(8), as a function of p and  .
Smaller values indicate better results.
Best achieved when   = 0.765 and p = 0.837.
Overall, our model is quite straightforward.
We combine query correlations from click and skip graphs and use URL categories as guideline to perform optimal random walk.
So why is the model more successful on rare queries than others, e.g., pseudo-relevance feedback?
The reason is that we somehow smooth the click graph by adding potential relevant edges according to the skip graph.
While the pseudo-relevance feedback model treat all top-returned result as relevant, we perform it di erently in a principled way.
As indicated in Figure 11, the best result is achieved when   = 0.765, suggesting that every click on a URL should be assigned with 0.765 edge weight, while every skip on a top-ranked URL should be treated with 0.235 edge weight.
A rough calculation indicates that edges in click graph should be treated 0.765/0.235   3 times more important as in the skip graph.
Due to the characteristics of high entropy and low click frequency of rare queries, this model is capable of discovering potential edges between queries and skipped URLs, while not over-smoothing the graph like pseudo-relevance feedback which introduces lots of noises.
On the other hand, the optimal restarting rate in our model is 0.837, which is surprisingly coherent with the jumping rate RWR-Pseudo (performs better than) RW-Back (performs better than) RWR-Pseudo 0.06 (p-value = 0.002) (cid:2) (cid:2) RWR-Base 0.22 (p-value< 0.001) 0.16 (p-value < 0.001) (cid:2) RWR-Base 0.18 (p-value < 0.001) 0.12 (p-value = 0.003) 0.04 (p-value = 0.11)* *: insigni cance of the comparison results.
Table 3: Statistical signi cance test on performance improvement of the four algorithms in comparison.
Each entry contains the relative precision increase as well as the p-value.
A p-value of less than 0.05 indicates a signi cance improvement.
Table 4: Examples of query suggestions by four di erent algorithms.
Bold queries are judged as relevant.
Our algorithm RWR-Combo has the most number of relevant suggestions in all four cases.
RWR-Combo is also capable of diversifying the suggestions to multi-intensional queries.
(0.85) as used in the pagerank algorithm.
To summarize, a simpli ed way of leveraging our model to make suggestion for rare queries can be conducted as follows (the parameters are speci ed for the cut-o  value of 20 for query frequency): 1. perform random walk with p around 0.85 on click and skip graphs respectively,
 negative ranking matrix R by 0.25, respectively,    
 linearly to get Ropt and extract the optimal query correlation matrix Qopt.
  values p values








 Query Cut off Frequency








 Query Cut off Frequency In our empirical analysis, when a query set contains more frequent queries, the skip graph becomes less important during the smoothing process.
We ran three tests to obtain the optimal values of   and p on three di erent datasets, with query frequency cut-o  values of 20, 50 and 100 respectively.
Figure 12 shows the bar plots in terms of the best parameter values.
There is an obvious up trend of   values when the query frequency increases, while for the restarting value p, it stabilizes relatively around 0.85.
In this paper, we proposed an optimal solution for rare query suggestions.
Rare queries are those di cult (long-Figure 12: Optimal values of parameters w.r.t.
different query frequency cut-o s.
  value increases with the query frequency, while p is not correlated with the query frequency.
tail) queries in search engines that appeared very few times.
We proposed to tackle this problem by random walk on the query logs.
Speci cally, we leveraged both click and skip information from query log to form an optimal random walk and combination model.
Our model was related to both pseudo-relevance feedback and smoothing technique used in natural language processing.
Our major discovery was that user skipped URLs (observed by users but without clicks) rare queries, but they should be treated with di erent weight comparing to user clicked URLs.
Since our model only relied on the click/skip information without the involvement of URL/query content, we were able to implement the framework on a large-scale data set which contained 40 million unique queries.
The empirical result comparing with other random walk models indicates that our model can generate higher precision scores for rare query suggestion.
Since in this paper we only focused on the observed URLs from users, in the future, it would also be interesting to investigate unobserved URLs below the last user clicks to see if they can bene t our model or bring noises instead.
This way we can break down eq.
(5) into three di erent pieces (clicked, skipped and unobserved URLs) and optimize them jointly.
It would also be useful to investigate other methods for  nding correlations between URLs, e.g., topic models.
And of course, it is worthy of further investigation how our model behaves for rare queries in di erent verticals, e.g., news, sports, commercial-intent and so on.
