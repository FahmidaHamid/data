Search forms an integral part of the Internet, allowing people to navigate on the Web,  nd information on a particular topic, or as a starting point for entertainment.
The keyword-based query formulation mechanism o ered by Web search engines allows users to quickly spin-o  in a particular direction of interest.
It is repeatedly reported in literature that the query length on average is very short, with 90% of the query volume being accounted for by queries with a length l(q)   4 [3, 13].
As a consequence, most queries entered by users leave room for some sort of ambiguity [19] and will lead to a diverse set of search results [1, 18].
In this paper we present MediaFaces, the back-end system that enables the faceted exploration of images in Yahoo! s 1http://images.search.yahoo.com/ Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
image search engine.
Moving towards a  Web-of-objects  experience [6], MediaFaces provides a service that enables faceted exploration of large (media) collections.
The objective of the system is to aggregate the knowledge and high-quality content that is available on and o  the Yahoo!
network, and to support the user in their quest for information by identifying the most relevant aspects of a query.
The user, when presented with the facets, is likely to discover new facets of the query that they were not aware of before.
When clicking on a facet, they will narrow down their search by expanding the original query with the suggested facet.
Faceted exploration of search results is widely used in search interfaces for structured databases such as shopping catalogues2, job listing3, house search4, etc.
Faceted browsing for semi structured sources has been proposed in research literature for some years [20].
But only recently they are also appearing in online search engines such as Yahoo!5, Google6, and Bing7 in the form of search assistants.
These search assistants mostly derive their query suggestions from query log analysis [8].
MediaFaces also uses query log analysis, but only to rank facets from a large pool of candidates, where the facet candidates have been extracted from the trusted sources.
Filtering for known facets allows us to provide conceptual query re nements of high quality.
The application of the system is best demonstrated with an example.
When a user types in a search for a known entity, such as London UK, the system shows the user diverse images of the location but also gives the user the option to explore di erent facets of the entity.
Figure 1 shows the search engine result page when the user queries for London UK.
On the right-hand side the traditional image search results are shown.
It can be clearly seen that the image search results shown are diverse, due to the broad nature of the query.
On the left-hand side there is the list of facets for London UK.
In this case, a list of prominent landmarks in London is displayed.
If the user clicks on one of the facets a new set of photos is shown, displaying only photos that correspond to the clicked facet.
Figure 2 shows the search engine result page when the user has clicked on the London Eye facet.
The left-hand side facet list remains the same but the image results are now focused on the London Eye.
This paper is further organized as follows.
We discuss 2http://shopping.yahoo.com/ 3http://hotjobs.yahoo.com/ 4http://www.realtor.com/ 5http://search.yahoo.com/ 6http://google.com/ 7http://bing.com/ related work in Section 2.
The system architecture is described in Section 3 and Sections 4 to 7 describe the main components of the system: the facet repository, facet extraction, facet ranking, and the facet server.
Finally, we present our conclusions in Section 8.
In this section we will discuss the related work on search assistants, faceted browsing, and media exploration and clustering.
Interactive query re nement   or search assistance   has been studied extensively in the literature.
The re nement terms can be derived either based on the underlying corpus [2, 15], from the set of retrieved documents [2, 14], or from query logs [8, 15].
Anick and Tipirneni suggest a method for generating query re nement terms using lexical dispersion of a word   the number of di erent lexical compounds in which the word occurs [2].
The algorithm takes a list of documents as input and returns the most disperse words as facets and the most frequent lexical compounds as value of the facets.
Joho et al.
investigate interactive query re nement [14].
They compare a hierarchical query term presentation to a linear presentation.
They show that there is little di erence in retrieval performance but the hierarchical presentation results in sig-ni cantly less e ort and is superior in terms of user satisfaction.
The presentation of the MediaFaces facets in Yahoo!
image search uses two layers, as the facets are grouped by category.
This is explained in more detail in Section 7.
Kraft and Zien present a query re nement method using anchor text and median rank aggregation [15].
They evaluate it in a user study and compare performance to re nement methods using document content and queries.
Their evaluation shows that using anchor texts or queries gives similar performance values.
Using document text is however inferior.
Fonseca et al. present a query re nement strategy based on mining association rules from query logs [8].
The re nement terms are clustered into concepts where similar terms appear together.
In an interactive experiment the user is asked to choose the concept that best describes the information need.
When the concept is used for query expansion signi cant improvement in retrieval performance is shown.
The MediaFaces system uses query logs as one of the main sources for ranking facets.
We mine the image search query logs to rank the candidate facets which have been extracted from the trusted sources.
the London Eye facet.
Faceted browsing has been applied for numerous settings, using di erent types of facets.
Burke et al. present faceted browsing for apartment rentals [4].
The user can re ne queries based on facets such as price, size, and neighbour-hood characteristics.
The facets are extracted by applying a parser specialized for parsing classi ed ads.
Yee et al. present an interface for searching and browsing images using faceted meta-data [20].
They apply the system for searching an art catalogue where the meta-data describes di erent facets such as artist names, types of media, dates and textual description of the art item content.
The faceted meta-data is partially provided by the collection itself and partially extracted using WordNet.
Based on our experience with MediaFaces, we can literally have thousands of such facets, while only a few can be presented to the user.
The challenge therefore is to retrieve the most relevant facets from a large set of candidate facets.
Zhang and Marchionini present a faceted browsing interface and apply it to a  lm database [21].
The faceted meta-data consists of  lm names, genres, actors, etc.
Stewart et al. present a faceted browsing interface to search for subject-verb-object patterns in news corpora [16].
Their facets are based on parsing subject-verb-object triples from natural language texts.
The wide availability of social media, and the structured information provided by users participating in the social media o ers an alternative to natural language processing, which we gratefully adopted for MediaFaces.
User evaluation has shown that faceted browsing of search results is particularly useful for exploratory search tasks [20,
 depend on the underlying data and is not a silver bullet that is appropriate for all types of data or all tasks [10, 5].
The best application of facets may depend on a balance between carefully hand crafted facet meta-data and fully automatic facet extraction.
In the MediaFaces system we strike this balance by combining data extracted from high quality data sources with statistical analysis from query logs and photo annotations.
The research on (visual) exploration and clustering of image collections is extensive.
A recent survey by [7] lists a number of the most signi cant contributions to the  eld of image retrieval, and stresses that image retrieval is more than a keyword based search often interactive of nature.
survey by Heesch [11].
Heesch also states that content based image retrieval (CBIR) has traditionally been investigated within a framework that emphasises the explicit formulation of a query: users initiate an automated search for relevant images by submitting an image or draw a sketch that exem-pli es their information need.
Its limitation is clear: There is often little support for exploratory search and scaling to very large collections is problematic.
Moreover, the assumption that users are always able to formulate an appropriate query is questionable.
An e ective, albeit much less studied, method of accessing image collections based on visual content is that of browsing.
One such example where visual exploration is at the core of the approach is described in Heesch et al. [12].
The approach is based on an automatically constructed network of images that can be navigated quickly by following its edges.
The browsing experience is enhanced in a number of ways including multidimensional scaling of the graph neighbour-hood for display purposes, Markov clustering of the image network to provide summaries of its content, and automated annotation of the images to allow users to access the network through text queries.
Alternatively, Hare [9] introduces a faceted model of image semantics which attempts to express the richness of semantic content interpretable within an image.
The interesting aspect of this paper is that it proposes to merge the topical exploration with a visual counterpart to analyse the image content.
In context of the MediaFaces system this is of particular interest when it comes to ensuring that the images retrieved are relevant to the faceted query.
Currently this is outside the scope of the MediaFaces system.
However the notion of visual facets once the topical ambiguity is resolved is certainly high on the agenda [18, 17].
In this section we discuss the system architecture of the MediaFaces system, which is presented in Figure 3.
The system has 5 main components which are described below.
The system interacts with a number of structured sources on and o  the Yahoo!
network, such as GeoPlanetTM, Yahoo!
Movies, Wikipedia, etc.
It uses these sources to extract structured information, e.g., known objects and candidate facets.
On the other hand it uses query log analysis and the annotations provided by Flickr users to rank the facets.
Facet Repository.
The facet repository is responsible for managing the extracted objects and facets - the relationship between a pair of objects.
Section 4 describes the facet repository in detail.
Facet Extractor.
The facet extractor module extracts objects and facets from the trusted sources.
Facet extraction is performed whenever a new data source becomes available or an existing data source is updated.
For example whenever a fresh dump becomes available, or when new items become available through an RSS feed.
The facet extractor processes the input data, extracts objects and passes them onto the facet builder that is responsible for storing the extracted data in the facet repository.
Facet extraction is described in Section 5.
Facet Ranking.
The facet ranking module ranks the candidate facets for a given object.
Facet ranking is performed periodically.
All existing facets are ranked using the latest query logs from image search and the Flickr data.
Section 6 provides a detailed overview of the facet ranking process.
Facet Server.
The facet server is responsible for the interaction with the application.
Given a user query a ranked list of facets and some additional meta-data is returned through the MediaFaces API.
Serving of facets is done on demand when the user enters a query.
The query is mapped to zero or more MediaFaces objects and the top ranked facets are served to the user.
The facet server and the application of MediaFaces as part of the Yahoo!
image search interface is described in Section 7.
Facet Builder.
The facet builder is a communication module between the facet repository and all other components.
When the facet extractor processes a new input source it passes the extracted facets to the facet builder, which is responsible for storing them in the facet repository.
When the facet ranking module is activated it asks the facet builder for a list of facets to rank and then returns the ranked facets back to the facet builder which updates the scores in the facet repository.
When the facet server receives an input query it asks the facet builder for a list of candidate facets to be served.
The facet repository takes care of the back-end data storage of the MediaFaces system.
The facet repository is organized around two main concepts: objects and facets.
Following is a de nition of the two concepts and examples of both can be found in Figure 4.
id name aliases type subtypes details sources
 Bangalore, India Bangalore Bengaluru location city lon=77.5...
lat=12.9...
GeoPlanet Wikipedia id name aliases type subtypes details sources
 George Clooney George T. Clooney person actor director dob=1961-05-06 Y!
Movies
 (a) MediaFaces objects source Bangalore, India target Cubbon Park type subsumes source George Clooney target Ocean s Eleven type played in (b) MediaFaces facets Figure 4: Examples of objects and facets in the Me-diaFaces repository.
Object.
An object is de ned as a real-world object or entity.
Examples of objects can be places such as London, UK, and New York City; celebrities such as Jennifer Anis-ton, and Brad Pitt; movies and tv-shows such as Fight Club and Friends; etc.
Each object has a number of attributes:   id, a unique identi er for the object;   name, the common name under which the object is known;   aliases, a list of alternative names for the object;   type, a high level type for the object;   subtypes, a list of  ne grained types for the object;   details, a attribute-value mapping that can be used to store additional attributes of the object;   sources, a list of sources where the object has been detected.
Facet.
A facet is de ned as a directed mapping from one object to another.
Each facet has a number of attributes:   source object, the object to which the facet belongs;   target object, the object that represents the facet;   type, the type of the facet relation.
Figure 4 shows an example of two MediaFaces objects and two facets.
For the sake of clarity, the examples in this paper identify the source and target objects by their name but in the actual system they are identi ed by their unique identi er.
The facet extraction module of the MediaFaces system is responsible for processing incoming content sources and extracting objects and facets.
The system is general enough to handle any type of data but in the  rst instance of the system we included only sources with geographic and celebrity information.
We carefully selected a set of semi-structured sources where the objects and facets are marked up explicitly.
Most of the sources are maintained internally at Yahoo!
The sources that have been incorporated are:   GeoPlanetTM, a resource for managing all geo-permanent named places on Earth8.
8http://developer.yahoo.com/geo/geoplanet/ Domain Source Geo Object type GeoPlanet Countries, cities, states, lakes Geo Geo Celeb Celeb Celeb mountains, landmarks, etc.
Attractions Y!
Travel Wikipedia Geo-coded Wikipedia pages Y!
Movies Actors, directors, and movies

 Actors, directors, and tv-shows Celebrities Table 1: Objects extracted from the semi-structured sources.
  Yahoo!
Travel, a comprehensive travel guide9.
  Wikipedia, a collaboratively edited encyclopedia10.
  Yahoo!
Movies, a movie information portal11.
  Yahoo!
TV, a TV information portal12.
  Yahoo!
OMG, a celebrity gossip and news site13.
Table 1 shows an overview of the type of objects extracted from the various sources and their domain.
Since objects are marked up explicitly in the sources there was no need of performing entity recognition.
In the case of Wikipedia, each geo-coded article is considered to be an object.
Table 2 shows an overview of the kind of facets extracted from the various sources.
In the case of GeoPlanet we use the builtin object hierarchy to map between places (countries, states, and cities) and points of interest (mountains, lakes, etc.)
For Yahoo!
Travel attractions and geo-coded Wikipedia pages we use the associated longitude-latitude 9http://travel.yahoo.com/ 10http://wikipedia.org/ 11http://movies.yahoo.com 12http://tv.yahoo.com 13http://omg.yahoo.com/ Place    Attraction Source GeoPlanet Place    Point of interest  Y!
Travel Wikipedia Place    Geo-coded page Y!
Movies Person   Movie Y!
Movies Movie   Person Y!
Movies Person   Person



   Where place can be a country, state, or city.
  Where point of interest can be a lake, mountain, landmark, etc.
Type subsumes subsumes subsumes played in has cast co-acted with played in has cast co-acted with appeared with Person   TV show TV show   Person Person   Person Person   Person Table 2: Facets extracted from the semi-structured sources.
coordinate to map the attraction/page to countries, states and cities from the GeoPlanet resource.
For Yahoo!
Movies and Yahoo!
TV the facets are explicitly de ned in the data structure.
In case of OMG!, we add a facet for every pair of celebrities that appear in the same news article.
In the OMG!
feed the celebrities are also explicitly marked-up, thus there is no need for entity extraction.
Having run the extraction process for all the input data sources the facet repository contains millions of objects and tens of millions of facets.
Many of the objects have hundreds of outgoing facets.
It is thus important to be able to rank them in order to be able to serve the most relevant ones to the user.
Ranking of candidate facets is based on the statistical analysis of query terms and query sessions that are derived from the image search logs.
In addition, the tags associated with the public photos in Flickr are used to complement the knowledge derived from the search logs.
After pre-processing the three sources, a common format is derived that is used to perform the statistical analysis.
We have experimented with various metrics, both symmetric and asymmetric, to produce a ranking of facets for a given (source) object of interest.
In this section we ll describe how the sources are processed to derive the data in the form of the common format, we give an overview of the metrics evaluated, and explain how an aggregated ranking is derived based on a linear combination of the three sources.
For the statistical analysis, we need to transform the data from the three di erent sources into the common format:
 ::= EventId <tab> UserId <tab> TimeStamp <tab> EVENTDATA <newline>
 ::= OBJECTENTRY ( <comma> OBJECTENTRY) *
 ( Object | <open_bracket> Object <pipe> Object ( <comma> Object)* <close_bracket> )+ For instance the image search query  Cubbon park in Bangalore India  entered by a user generates the following result based on the query term analysis as will be explained in more detail below: e1001 u01 t1 cubbon+park,{bangalore+india|bangalore,india} EventId The EventId (e1001) is a unique identi er within the de ned event space.
For Flickr, the event space is the collection of public photos, and the photo-id would uniquely identify a photo in this space.
In case of query term analysis this is a page view, and for query session analysis a set of consecutive page-views that take place within a certain time-window.
UserId A UserId (u01) uniquely identi es a particular user.
Typically this can be a browser cookie or a user s (anonymized) account id.
TimeStamp The time stamp (1256395594) registers the start time of the event, and is stored in Unix time format.
The section EVENTDATA describes the objects that have been detected during the event.
(cubbon+park,{bangalore+india|bangalore,india})
 An OBJECTENTRY can be a single object reference such as  cubbon park  , or a composed reference.
This might occur whenever a phrase  Bangalore, India  is detected.
Besides the phrase we have also objects in the repository that refer to the individual terms:  Bangalore  and  India .
Once the data is formatted correctly, the same set of statistical metrics can easily be derived from the di erent sources based on the co-occurrence analysis of objects within a given event.
Our main source for ranking facets is based on the query term analysis.
The queries entered by users in the Yahoo!
image search engine provide us with a massive amount of information.
We have collected a large set of queries spanning a period of several months.
As for Web search the queries posed by users tend to be short.
In their work, Bender-sky and Croft report that 90% of the query volume consists of queries with a length l(q)   4 [3].
For the ranking the candidate facets in the MediaFaces system we are particularly interested in multi-term queries as input for the co-occurrence analysis.
However a straightforward tokeniza-tion of the query based on word-boundaries is insu cient, as the vast majority of the objects in our facet repository consist of phrases, e.g.
person names, movie titles, location names, etc.
We therefore need to derive a more intelligent segmentation of a query.
To that purpose, we  rst tokenize the query based on the word boundaries, and apply an NFD normalization14 of the tokens.
We then use a sliding window over the tokens to  nd
 Unicode_normalization.
Tokenization: Normalization: Segmentation: Object detection: Cubbon park in Bangalore, India Cubbon+park+in+Bangalore+India cubbon+park+in+bangalore+india cubbon+park+in+bangalore+india cubbon+park, {bangalore+india|bangalore,india} src bangalore bangalore+india ...
india trg cubbon+park cubbon+park ...
bangalore sid tid P(trg | src)

 ...
...
...
Table 3: Conditional user probabilities and mapping to objects.
Figure 5: Transformation steps for query term analysis.
the object references in the query and segment the query.
Once the query is segmented, the data can be transformed in the common format.
Figure 5 illustrates how the objects are detected for our example query in four steps.
Once the query is segmented, the event information can be encoded using the common format.
Note that we have detected four object references, and that the term  in  does not match with any object in the database and is therefore omitted.
The query session analysis uses the same query log data as is collected for the query term analysis.
The event space is a query session, which is de ned as a set of consecutive queries issued by the same user within a certain amount of time, for example 15 minutes.
Consider the following scenario, where a user (u01 )  rst searches for  India , then expands his query into  Bangalore, India , and  nally decides to search for  Cubbon park   within a 15 minute time frame.
The following data will be collected for this query session: e9001 u01 t2 india,bangalore+india,cubbon+park For the query session analysis we tokenize and normalize the query as is done for the query term analysis, but there is no further segmentation of the query.
Only whole queries are matched against the objects in the facet repository when doing the object detection.
Due to the exploratory nature of image search, a user is likely to enter several queries during one session.
We observe that the average number of queries entered in a query session exceeds the average number of query terms.
Furthermore, the user is likely to change to several related topics within a session.
We refer to this behaviour as a lateral exploration.
The objective of Medi-aFaces is to support a faceted exploration, rather than a lateral exploration.
We therefore appreciate the outcome of the query session analysis to be inferior to the query term analysis.
The Flickr tag analysis is based on the tags de ned for a large set of 250 million photos that are publicly available on Flickr.
An event is de ned around the tags used to annotate a photo.
Suppose that a user has annotated their photo with the tags: Cubbon park, Bangalore, India.
We can then for each of the three tags simply apply the tokenization and normalization as used for the other two sources.
However, we preserve the tag boundaries as de ned by the user, which leads to the following result: e8008 u01 t3 cubbon+park,bangalore,india In this subsection we explain the procedure followed for computing the ranking of facets per source.
Continuing with the most complex example derived during the query term analysis: e1001 u01 t1 cubbon+park,{bangalore+india|bangalore,india} The  rst step is to compute all possible co-occurring objects for this event: cubbon+park - bangalore+india cubbon+park - bangalore cubbon+park - india bangalore - india We can now directly compute a series of metrics, for example consider the following variant of the conditional probability: P (target|source) = | source T target | | source | , with |source| de ned as the number of users that have used a source object in an event, and | source T target | as the number of users that have used both the source and target object in an event.
Rather than counting the absolute number of times an object, or pair of objects appears, we count the number of distinct users, using that object, or pair of objects.
This makes the metric less prone to the impact a single user can have on the probability score.
Besides the conditional probability, we have experimented with an number of other metrics, and combinations thereof:   atomic metrics: probability, entropy.
  symmetric: joint probability, point-wise mutual information (PMI), cosine similarity.
  asymmetric: (reverse) conditional probability, (reverse) KL divergence.
Based on an empirical evaluation, of which we cannot disclose the details, we have found that the conditional user probability, as described above, performs best across all three sources.
This performance is followed closely by the joint user probability and PMI metrics.
To compute the  nal ranking of facets for a given object of interest, we  rst map all object references to their corresponding object ids.
Continuing our Bangalore example, Table 3 illustrates the consequence of this.
The object references bangalore and bangalore+india refer to the same object (21 ) in the facet repository, but have di erent probabilities.
As we are working with real ent names, and di erent objects are referred to by the same name.
These two problems are unavoidable.
The  rst problem is solved by choosing the maximum probability as the facet score: P (345|21)max = 0.0034.
The second problem most dominantly occurs for locations and is handled by the FacetBuilder.
Finally, when for each facet in the facet repository its conditional user probability is computed per ranking source, we compute an aggregated score per facet using a linear combination.
Most weight is given to the conditional probability score of the query term analysis, followed by the Flickr tag analysis and query session analysis respectively.
The motivation is twofold: First, we want MediaFaces to support a faceted search experience.
Both the query term analysis and the Flickr tag analysis are good at  nding facets of a given object, while the query session analysis supports a more lateral search experience such as celebrities that share certain characteristics, but do not have a direct (faceted) relationship.
Similar one can think of major cities in Europe like: Paris, London, Rome, Barcelona, Amsterdam, which clearly appear to be related according to the query sessions analysis.
Second, we prefer query term analysis over Flickr tag analysis due to the nature of image search, which tends to be broader than Flickr.
For instance, it has a better coverage of the celebrity and entertainment business.
After extracting and ranking the facets we are ready to serve them to the user when appropriate.
The process of online serving of facets is shown in Figure 6.
The user types a query in the search box.
The query is mapped to zero or more query objects in our facet repository.
If no object matches the query, normal image search results are shown.
If one object matches the query, the facets are shown.
If multiple objects match the user is given the option to re ne their query to indicate which object they meant.
The  rst task in the online processing is to map the query to zero or more objects.
We do that using an exact string match on the object name or one of its alias names.
The string match is insensitive to case and punctuation.
As an example, the Bangalore object shown in Figure 4 would be mapped to the queries bangalore; bangalore, india; etc.
Each query string can be mapped to zero or more query objects.
If no object is mapped the normal image search results page is shown.
If one object is mapped the facets are displayed, as shown in Figure 1.
For each facet, we display the name, an automatically selected and generated thumbnail, and the number of corresponding images.
A query string can also be mapped to multiple objects.
As an example the query cambridge is mapped to both Cambridge, England and Cambridge, MA.
In this case the user is given the opportunity to disambiguate the query and choose either one of the objects (see Figure 7).
If the user chooses one of the disambiguation objects the facets for that source object are shown.
When a query object has been uniquely determined the system retrieves a ranked list of facets originating in the query object.
The facet object list is processed in a decreasing relevance order and facets are chosen for displaying if they match the following criteria:   The facet has su cient number of photos.
We can estimate the number of photos returned by composing a query of the concatenation of the names of the source and the target objects of the facet.
If the number of photos fails to  ll a full result screen we do not select the facet.
  The target object string is not a near duplicate of previous target object string.
In some cases when an object is ingested from multiple sources two instances of the object may exist in the facet repository with identical or near identical name.
E.g., one source may refer to the famous New York City as Empire State Building, while another may refers to it simply as Empire State.
In this case we check if the currently processed object name overlaps with a previously processed object name and choose the object with the longest name.
When 10 facets have been chosen the processing terminates and the list is returned to the front-end.
In the geography query example shown in Figure 1 all the target objects of the facets are of the same type   e.g.
location.
In the case of celebrities the system o ers a variety of types.
E.g., for a given celebrity the facet list retrieved may contain other people related to the celebrity or movies the celebrity played in.
This information can be used by the interface to further organize the related facets.
Figure 8 shows the facet lists generated for two geography queries and two celebrity queries.
For the celebrity queries the facet lists are broken up into related people, related movies, and related TV-shows.
The objective of this categorization is to help the user to get a better overview of the facets displayed.
In this paper we presented MediaFaces, a system for serving facets given a query, which is currently used in production by Yahoo!
image search.
The system aids the user in their exploratory search tasks, which are particularly frequent in image search.
MediaFaces enables a faceted search experience by aggregating high-quality content that is available on and o  the Yahoo!
network.
Combined with the analysis of image search query logs and Flickr tagging be-haviour we are able to present the user with conceptual query re nements.
Finally, We have shown how we serve top-k facets as a response to a user query in the Yahoo!
image search setting.
A part of the research leading to these results has received funding from the European Community s Seventh Framework Programme FP7/2007-2013 under grant agreement n 215453 - WeKnowIt.
Ramu Adapala (Yahoo!
), Llu s Garc a Pueyo (Yahoo!
Research), Abhinav Katiyar (Yahoo!
), Kaushal Kurapati (Yahoo!
), Mridul Muralidharan (Yahoo!
Research), Sudar Muthu (Yahoo!
Research), Vanessa Murdock (Yahoo!
Research), Figure 7: Object disambiguation.
