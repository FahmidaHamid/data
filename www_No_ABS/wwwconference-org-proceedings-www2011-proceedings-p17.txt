Click-through logs record user activities on search pages and encode user preferences of search results.
Click-through   crosoft Research Asia.
This work was done when the authors were interns at Mi-Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
logs can be collected at a very low cost, and the analysis of them can help to understand the user s latest preference tendencies.
Naturally, many studies have attempted to discover user preferences from click-through logs to improve the relevance of search results [12, 11, 1].
It is well known that clicks are  informative but biased  [4], and it is a challenging task to estimate unbiased relevance from click-through logs.
One typical bias a ecting user clicks is the so-called position bias: a document appearing in a higher position is more likely to attract user clicks even though it is not as relevant as other documents in lower positions.
Thus, the click-through rate is not a proper measure of relevance.
This bias was  rst noticed by Granka et al.
[7] in their eye-tracking experiment and some followup investigations have been made to alleviate this bias so that the unbiased relevance can be inferred from the clicks.
Richardson et al.
[16] proposed to increase the relevance of the documents in lower positions by using a multiplicative factor.
This idea was later formalized as the examination hypothesis [4], which assumes that the user will click a search result only after examining its search snippet.
In other words, given an examined document, only its relevance determines the user click.
The examination hypothesis decouples document relevance from position bias where the position bias is formulated as the probability that a document is examined by a user.
Recently, many interesting studies have been made to re ne click models using the examination hypothesis.
UBM[6], DBN[3], CCM[8], BBM[13], GCM[19] are typical models which can extend the capabilities of the examination hypothesis.
The examination hypothesis assumes that, if a document has been examined, the click-through rate of the document for a given query is a constant number whose value is determined by the relevance between the query and the document.
We argue that users with di erent search intents, however, may submit the same query to the search engine.
In other words, a single query may not truly re ect user search intent.
Take the query  iPad  as an example.
A user submits this query because she wants to browse general information about iPad, and the results from apple.com or wikipedia.com are attractive to her.
In contrast, another user who submits the same query may look for information such as user reviews or feedback on iPad.
In this situation, search results like technical reviews and discussion forums are more likely to be clicked.
This example indicates that the attractiveness of a search result is not only in uenced by its relevance but also determined by the user s intrinsic search intent behind the query.
Intent Bias Query Click Probability Relevance Document Figure 1: The triangular relationship among intent, query and document.
The edge connecting two entities measures the degree of match between two entities.
We design an experiment to validate that the relevance between a query and a document is not a constant number.
In the experiment, we collect search sessions, and partition them into two groups according to di erent search intents.
We note that after eliminating the position bias effect, most queries (96.6%) have signi cantly di erent click-through rates on two intent groups.
(Please refer to Section
 through rate of an examined document varies greatly across di erent search sessions due to the diversity in search intent.
Figure 1 describes the triangular relationship among intent, query and document, where the edge connecting the two entities measures the degree of match between them.
Each user presumably has an intrinsic search intent before submitting a query.
When a user comes to a search engine, she formulates a query according to her search intent and submits it to the search engine.
The intent bias measures how well the query matches the intent, i.e., the degree of match between the intent and the query.
The search engine receives the query and returns a list of ranked documents, while the relevance measures the degree of match between a query and a document.
The user examines each document and, if a document better satis es her information need, she is more likely to click this document.
The triangular relationship suggests that the user click is determined by both intent bias and relevance.
If a user does not clearly express her information need in the input query, there is a large intent bias.
Thus, the user is unlikely to click the document that does not meet her search intent, even if the document is very relevant to the query.
The examination hypothesis can be considered as a simpli ed case, that it regards the search intent and the input query as equivalent and ignores the intent bias.
Thus, the relevance between a query and a document may be mistakenly estimated when only the examination hypothesis is adopted.
In this paper, we incorporate the concepts of intent and intent bias to propose a novel hypothesis, the intent hypothesis, to explain how user clicks are a ected by intent bias, relevance and position bias.
The intent hypothesis can enhance the analytical power of the examination hypothesis, characterize search intent diversity and interpret user clicks better.
Click models that adopt the intent hypothesis can estimate more accurate and unbiased relevance.
This paper s contributions are fourfold.
First, we empirically demonstrate the limitations of the examination hypothesis and suggest that the position bias is not the only bias a ecting click behavior.
Second, we propose the novel intent hypothesis to enhance the capability of modeling user search behavior.
Third, because the intent hypothesis is general, we apply it to two typical click models, UBM and DBN, and adopt a Bayesian inference method to model the intent hypothesis.
This inference method is capable of learning on very large scale click-though logs.
Finally, the experiment has been conducted on 3.6 million queries and one billion search sessions, and the results illustrate the advantages of adopting the intent hypothesis.
This paper is organized as follows: In Section 2, we brie y review the previous research on click models including their speci cations and hypotheses.
In section 3, we empirically validate that the examination hypothesis can not well interpret real click-through data.
In Section 4, we propose our intent hypothesis and its inference method.
In Section 5, the experiment on real datasets shows the advantages of adopting the proposed hypothesis.
In Section 6, we analyze the intent bias that we estimated from the experiment and discover some insightful results.
We start by introducing de nitions and notations which will be used throughout the paper.
A user submits a query q and the search engine returns a search result page containing M (usually M = 10) documents, denoted by {d i}M i=1, where  i is the index of the document at the i-th position.
The user examines the summary of each search result and clicks some or none of them.
Here the summary includes the search title, snippets and URL.
A search session within the same query is called a search session, denoted by s. Clicks on sponsored ads and other web elements are not considered in one search session.
We regard subsequent query re-submission or reformulation as a new session.
The terms url, document and result have the same meaning, and we use them indiscriminately in the context.
We de ne three binary random variables, Ci, Ei and Ri to model user click, user examination and document relevance events at the i-th position:   Ci: whether the user clicks on the result;   Ei: whether the user examines the result;   Ri: whether the document is relevant where the  rst event is observable from search sessions and the last two events are hidden.
Pr(Ci = 1) is the click-through rate of the i-th document, Pr(Ei = 1) is the probability of examining the i-th document, and Pr(Ri = 1) is the relevance of the i-th document.
We use the parameter r i to represent the document relevance as Pr(Ri = 1) = r i (1) Next, we introduce the examination hypothesis mentioned in Section 1.
The examination hypothesis was originally proposed by Richardson et al.
[16] and later formalized by Craswell et al. [4]: Hypothesis 1 (Examination Hypothesis).
A document is clicked if and only if it is both examined and relevant, which can be formulated as Ei = 1, Ri = 1   Ci = 1 (2) where Ri and Ei are independent of each other.
Equivalently, Formula (2) can be reformulated in a probabilistic way: Pr(Ci = 1|Ei = 1, Ri = 1) = 1 Pr(Ci = 1|Ei = 0) = 0 Pr(Ci = 1|Ri = 0) = 0 (3) (4) (5) as Thus, as [16] explains, the document click-through rate is represented by Pr(Ci = 1) = Pr(Ei = e) Pr(Ci = 1|Ei = e) Pr(Ci = 1|Ei = 1) =r  i Pr(Ci = 1|Ei = 0) = 0 (cid:2) e {0,1} (cid:3) (cid:4)(cid:5) (cid:4)(cid:5) (cid:6) = Pr(Ei = 1) (cid:3) (cid:6) Pr(Ci = 1|Ei = 1) (6) (7) position bias document relevance where the position bias and the document relevance are decomposed.
This hypothesis has been used in most of the state-of-the-art click models to alleviate the position bias problem.
Next, we will brie y review recent research on click models in which DBN and UBM are used to implement the intent hypothesis in the paper.
The cascade hypothesis was originally proposed by Craswell et al. [4] to simulate the user search habit.
Hypothesis 2 (Cascade Hypothesis).
A user examines search results from top to bottom without skips, and the  rst document is always examined: Pr(E1 = 1) = 1 Pr(Ei+1 = 1|Ei = 0) = 0 (8) (9) The cascade model [4] combines the examination hypothesis and the cascade hypothesis, and it further assumes that the user stops the examination after reaching the  rst click and abandons the search session: Pr(Ei+1 = 1|Ei = 1, Ci) = 1   Ci (10) This model is too restrictive and can only deal with the search sessions with at most one click.
The dependent click model (DCM) [9] generalizes the cascade model to sessions with multiple clicks and introduces a set of position-dependent parameters, i.e., Pr(Ei+1 = 1|Ei = 1, Ci = 1) =  i Pr(Ei+1 = 1|Ei = 1, Ci = 0) = 1 (11) (12) where  i represents the probability of examining the next document after a click.
These parameters are globally shared across all search sessions.
In this model, a user is simply assumed to examine all the subsequent documents below the position of the last click.
In fact, if a user is satis ed with the last clicked document, she usually does not continue examining the following results.
The dynamic Bayesian network model (DBN) [3] assumes that document attractiveness determines the user click, and the user satisfaction determines whether the user examines the next document.
Formally speaking, Pr(Ei+1 = 1|Ei = 1, Ci = 1) =  (1   s i ) Pr(Ei+1 = 1|Ei = 1, Ci = 0) = , (13) (14) where the parameter   is the probability the user examines the next document without clicks, and the parameter s i is the user satisfaction.
Experimental comparisons show that DBN outperforms other click models based on the cascade hypothesis.
DBN employs the expectation maximization algorithm to estimate parameters, which may require a great number of iterations for convergence.
Zhu et al. [19] introduced a Bayesian inference method, expectation propagation [14], for DBN.
The user browsing model (UBM) [6] is based on the examination hypothesis but does not follow the cascade hypothesis.
Instead, it assumes that the examination probability Ei depends on the previous clicked position li = max{j   {1,   , i   1} |C j = 1} as well as the distance between the i-th position and the li-th position: Pr(Ei = 1|C1:i 1) =  li,i li (15) If there are no clicks before the position i, li is set to 0.
The likelihood of a search session under UBM can be stated in a quite simple form: i=1 (r i  li,i li )Ci (1   r i  li,i li ) Pr(C1:M ) = (16) where there are M (M +1)/2 { i,j} parameters shared across all search sessions.
The Bayesian browsing model (BBM) [13] follows the same assumptions of UBM but adopts a Bayesian inference algorithm.
M(cid:7)


 As we mentioned above, the examination hypothesis is the basis of most existing click models.
The hypothesis is mainly aimed at modeling the position bias in the click log data.
In particular, it assumes that the probability of a click s occurrence is uniquely determined by the query and the document after the document is examined by the user.
In this section, we use a controlled experiment to demonstrate that the assumptions built into by the examination hypothesis cannot completely interpret the click-through log.
We show that, given a query and an examined document, there is still diversity among click-through rates on this document.
This phenomenon clearly suggests that the position bias is not the only bias that a ects click behaviors.
In order to perform the experiment, we collected click-through logs for one month in which each session contains the top ten returned documents in the search result page.
We selected the search sessions that have at least one click on the documents at positions 2 to 10.
Since it is widely believed that the user browses search results from top to bottom, thus, from the fact that at least one of the documents at the last nine positions is clicked, we can assume that the document at the  rst position is always examined.
The search sessions are further divided into two groups with respect to the number of clicks at the last nine positions: one group includes sessions which have exactly one click at the last nine positions, while another group includes sessions which have at least two clicks at these positions.
For each search query, the click-through rate is calculated on the same document and this document is at the  rst position.
We randomly chose  ve queries and reported the click-through rate values on two groups of sessions in Figure 2.
According to the examination hypothesis, the relevance between a query and a document is a constant number, if
 n o i t i s o p t a t n e m u c o d e h t n o t e a r h g u o r h   k c t i l
 (# clicks at position 2 to 10) = 1 (# clicks at position 2 to 10) > 1






 vitamins sudoku hulu pac man gpa calculator Query Figure 2: The document click-through rate values on two groups of search sessions over  ve randomly picked queries.
One group includes sessions with exactly one click at positions 2 to 10, and another group includes sessions with at least two clicks at positions 2 to 10.
For each query, the click-through rate is calculated on the same document and this document is always at the  rst position.
the document has been examined.
It implies that the click-through rate in the two groups should be equivalent to each other, since the document at the top position is considered always to be examined.
As shown in Figure 2, however, none of the queries presents the same click-through rate value on the two groups.
Instead, it is observed that the click-through rate in the second group is signi cantly higher than that in the  rst group since the P-values of t-test on these two groups is much less than 1%.
In order to investigate the generalization of this analysis, we subtract the click-through rate in the  rst group from that in the second group and plot the distribution of this di erence over all search queries.
Figure 3 illustrates the di erence of the click-through rate values on two groups for all queries.
The resulting distribution matches a Gaussian distribution whose center is at a positive point about 0.2.
Speci cally, we found that the number of queries whose corresponding di erence is located within [ 0.01, 0.01] occupies only 3.34% of all queries, which indicates that the examination hypothesis cannot precisely charaterize the click behaviors for most of the queries.
Since we believe that the users have not read the last nine documents when they are browsing the  rst document, whether the  rst document has a click is an independent event to the click on the last nine documents.
Thus, the only possible explanation for the observed phenomenon is that there is an intrinsic search intent behind the query and that this intent leads to the click diversity in the two groups.
In Section 4, we will characterize this diversity by the concept of search intent and propose the intent hypothesis for click models.
We propose a new hypothesis called the intent hypothesis.
The intent hypothesis preserves the concept of examination proposed by the examination hypothesis.
Moreover, our hy-y t i s n e


 .
.
.
.
.
.
.
 0.5


 Difference of click through rates Figure 3: The distribution of the CTR di erence on two group search sessions.
pothesis assumes that a document is clicked only after it meets the user s search intent, i.e. it is needed by the user.
Since the query partially re ects the user s search intent, it is reasonable to assume that a document is never needed if it is irrelevant to the query.
On the other hand, whether a relevant document is needed is uniquely in uenced by the gap between the user s intent and the query.
From this de -nition, if we are sure that the user always submits the query which exactly re ects her search intent, then the intent hypothesis will be reduced to the examination hypothesis.
Formally, the intent hypothesis includes the following three statements:
 amined and needed by the user.
in uenced by the gap between the user s intent and the query.
Figure 4 compares the graphical models of the examination hypothesis and the intent hypothesis.
We can see in the intent hypothesis a latent event Ni is inserted between Ri and Ci, in order to distinguish the occurrence of being relevant and being clicked.
Hidden: Ei Ri Hidden: Ei Observed: Ci Observed: Ri Ni Ci (a) Examination Hypothesis (b) Intent Hypothesis Figure 4: The graphical models of the examination hypothesis and the intent hypothesis It order to represent the intent hypothesis in a probabilistic way, we  rst introduce some symbols.
Suppose that there are m documents in the session s. The i-th document is denoted by d i and whether it is clicked is denoted by Ci.
Ci is a binary variable.
Ci = 1 represents that the document is clicked and Ci = 0 represents that it is not clicked.
Similarly, whether the document d i is examined, whether resented by the binary variables Ei, Ri and Ni.
Under this de nition, the intent hypothesis can be formulated as: Ei = 1, Ni = 1   Ci = 1 Pr(Ri = 1) =r  i Pr(Ni = 1|Ri = 0) = 0 Pr(Ni = 1|Ri = 1) =  s (17) (18) (19) (20) Here, r i is the relevance of the document d i , and  s is de ned as the intent bias.
Since the intent hypothesis assumes that  s should only be in uenced by the intent and the query,  s is shared across all documents in the same session, which means that it is a global latent variable in session s. However, in di erent sessions, the intent bias is supposed to be di erent.
After we combine (17), (18), (19) and (20), it is not di cult to derive that: Pr(Ci = 1|Ei = 1) =  sr i Pr(Ci = 1|Ei = 0) = 0 (21) (22) Compared to Equation (6) derived from the examination hypothesis, Equation (21) adds a coe cient  s to the original relevance r i .
Intuitively, it can be seen that we take a  s discount o  the relevance.
Especially, if the value of  s is  xed to 1, it means that there will be no intent bias and that our hypothesis will degenerate into the examination hypothesis.
For all previous click models based on the examination hypothesis, the switch from the examination hypothesis to the intent hypothesis is quite simple.
Actually, we only need to replace formula (6) with formula (21) without changing any other speci cations.
Here, the latent intent bias  s is local for each session s. Every session maintains its own intent bias, and the intent biases for di erent sessions are mutually independent.
When the intent hypothesis is adopted to construct or reconstruct a click model M, the resulting click model is referred to as Unbiased-M.
In this paper, we choose two state-of-the-art models, DBN and UBM, to illustrate the impact of the intent hypothesis.
The new models based on DBN and UBM are called Unbiased-DBN and Unbiased-UBM respectively.
As speci ed above, when an unbiased model is constructed, we estimate the value of  s for each session.
After all of the  s are known, then other parameters of the click model (such as relevance) can be learned.
However, since the estimation of  s relies on learning the results of other parameters, the entire inference process has deadlocks.
To avoid this problem, we adopt an iterative inference as shown in Algorithm
 Every iteration consists of two phases.
In Phase A, we learn the click model parameter   based on the estimated values of  s of the last iteration.
In Phase B, we estimate the value of  s for each session based on the parameters   learned in Phase A.
Here, the likelihood function that we Algorithm 1 Iterative inference of unbiased model Require: Input a set S of sessions as training data and an original click model M (Its own parameter set is denoted by  .)
2: repeat
 Phase A: We learn every parameter in   using the original inference method of M while we  x the values of  s according to the latest estimated values of  s.
Phase B: We estimate the value of  s for each session, using maximum-likelihood estimation, under the learning result of parameters   generated in phase A.
5: until all parameters converge want to maximize is the conditional probability that the actual click events of this session occur under the speci cation of the click model, with  s being treated as the condition.
Phase A and Phase B should be executed alternatively and iteratively until all parameters converge.
This general inference framework can be modi ed to be more e cient if the parameters except  s could be learned through online Bayesian inference.
In this case, the inference is still online even after the estimations of  s are included.
Speci cally, when a session is loaded, we use the posterior distributions learned from the previous sessions to give an estimation for  s.
We then use the estimated value of  s to update the distribution of other parameters.
Since the distribution of every parameter changes little before and after the update, we do not need to reestimate the value of  s anymore, so that no iterative steps are needed.
Thus, after all the parameters are updated, we just load in the next session and continue the learning process.
As described in Section 2, both UBM and DBN can employ the Bayesian Paradigm to infer the parameters.
According to the method mentioned above, as a new session is loaded for training, there are three steps to execute:
 rive the likelihood function Pr(C1:m| s).
value of  s.
the Bayesian inference method.
Such online Bayesian inference facilitates the single-pass and incremental computation, which is appealing for very large-scale data processing.
Given a test session, the joint probability distribution of click events in this session can be calculated by the following formula.
(cid:8) 1 Pr(C1:m) =
 Pr(C1:m| s)p( s)d( s) (23) In order to determine p( s), we investigate the distribution of the estimated  s in the training process and draw a density histogram of  s for each query.
Then we use the density histogram as an approximation to p( s).
In our implementation, we evenly divide the range [0, 1] into 100 segments and count the density of  s that fall into each of the segments, and then we treat this density distribution as p( s).
the exact value of the intent bias for future sessions.
This is because the intent bias can only be estimated when the actual user clicks are available, but in the testing data, the user click is hidden and should be unknown to the click model.
Thus, we average the prediction result of future clicks over all intent bias according to the distribution of the intent bias counting from the training set.
This averaging step might lose the advantage of the intent hypothesis.
In an extreme case that a query never occurs in the training data, our model will set the intent bias to be 1, where the intent hypothesis degenerates to the examination hypothesis and gives the same prediction result as the original model.
We take the User Browsing Model (UBM) as an example to demonstrate how to apply the intent hypothesis to a click model.
A Bayesian inference procedure to estimate the parameters is also introduced.
Given a search session s, UBM takes the document rele-vances and transition probabilities as its parameters.
As we mentioned in Section 2, the parameters in a single session can be denoted by   = {r i}M i=1.
In addition, if we want to apply the intent hypothesis to UBM, then a new parameter should be maintained.
This parameter is the intent bias for session s, which we denote by  s.
Under the intent hypothesis, the revised version of the UBM model is formulated by (21), (22) and (15).
likelihood Pr(s| ,  s) for session s as : Pr(s| ,  s) (cid:2) Pr(C1:M| ,  s) M(cid:7) According to the above model speci cation, we derive the i=1  { li,i li}M 1(cid:2) (cid:9) Pr(Ci | Ei = k,  s, r i )  Pr(Ei = k | C1:i 1,  li,i li ) (cid:10) (24) i=1 k=0 = = M(cid:7) i=1 ( sr i  li,i li )Ci (1    sr i  li,i li )
 (25) Here, Ci represents whether the document at position i is clicked.
The overall likelihood for the entire dataset is the product of the likelihood for every single session.
We adopt the Bayesian Paradigm to infer the parameters.
The learning process is incremental: we load and process search sessions one by one, and the data for each session is discarded after it has been processed in the Bayesian inference.
Given a new incoming session s, we update the distribution of each parameter       based on the session data and the click model.
Before the update, each   has a prior distribution p( ).
We compute the likelihood function P (s| ) , multiply it to the prior distribution p( ), and derive the posterior distribution p( |s).
Finally, the distribution of   is updated with respect to its posterior distribution.
Let s examine this updating procedure in more detail.
First, we integrate the likelihood function (25) over   to derive a marginal likelihood function only conditioned on the intent bias: (cid:8) Pr(s| s) = p( ) Pr(s| ,  s)d 
 R| (cid:2)| Since Pr(s| s) is a unimodal function, we can maximize it by the ternary searching procedure on the parameter  s, which is in the range of [0, 1].
The optimal value for  s is   then denoted by   s.
of each parameter       via the Bayes  Rule: Pr(s| ,  s =     s)p(  With  s optimized, we derive the posterior distributions s)   p( ) p( |s,  s =     )d  (cid:8) (cid:4) (cid:4) (cid:4) =  \{ } for short notation.
where   The  nal step is to update p( ) according to p( |s,  s =     s).
To make the whole inference process tractable, it is usually necessary to restrict the mathematical form of p( ) to a speci c distribution family.
Here, we adopt the Probit Bayesian Inference (PBI) proposed by Zhang et al. [18] to implement the  nal update.
PBI connects each   with an auxiliary variable x through the probit link   =  (x), and restricts p(x) always to the Gaussian family.
Thus, in order to update p( ), it is su cient to derive p(x| s =     s) from p( | s =     s ) and approximate it by a Gaussian density.
Then we use the approximation to update p(x) and further update p( ).
For more details, please refer to [18].
Since the learning is incremental, the update procedure is executed once for each session.
In this section, we test the intent hypothesis with two state-of-the-art click models, DBN and UBM, and the original examination hypothesis in DBN and UBM are replaced by the intent hypothesis.
We denote the new click models by Unbiased-UBM and Unbiased-DBN respectively.
In the experiment, we  rstly use the estimated relevance from click models to rank the documents and then evaluate the ranking using the human labeled relevance with respect to the normalized discounted cumulative gains (NDCG) [10].
Secondly, we use log-likelihood to evaluate how accurately the Unbiased-UBM and Unbiased-DBN predict user future clicks over UBM and DBN.
Training and testing datasets: The search sessions used to train and evaluate click models were collected from a commercial search engine in the U.S. market in the English language in January 2010.
A session consists of a input query, a list of returned documents on the search result page and a list of clicked positions.
We collected the session subject to the following constraints: (1) the search session is on the  rst result page returned by the search engine; (2) all clicks in the session are on the search result but neither on sponsored ads nor on other web elements.
In order to prevent the whole dataset from becoming dominated by the extremely frequent queries, we allow each query at most 106 sessions.
We also  lter the search sessions to remove queries with low frequency less than 101.5.
For each query, we sort its search sessions according to the time stamp when the query is sent to the search engine and split them into the training and the testing sets at a ratio of 3:1.
In total, we collect approximately one billion sessions over 3.6 million distinct queries.
The detailed information about the dataset is summarized in Table 1.
Human judgment relevance: The manually labeled data is used as the ground truth for evaluating the relevance estimated from click models.
The human relevance system 101.5 to 102 102 to 102.5 102.5 to 103 103 to 103.5 103.5 to 104 104 to 104.5 104.5 to 105 > 105 Total












































 Table 1: The summary of the data set collected from one month of click logs.
Model

 Unbiased-UBM Improvement

 Unbiased-DBN Improvement






























 Table 2: The experimental results on NDCG (HRS) randomly picks a set of queries and requires editors to label the relevance between these queries and their corresponding search documents.
For each query-document pair, editors give  ve ratings ranging from 0 to 4, corresponding to  ve scales: bad, fair, good, excellent, and perfect.
HRS rating for a query-document pair is derived by averaging the ratings of this pair from several editors.
On average,
 HRS generated 2 million ratings for our data set.
The last two columns in Table 1 show the summarized HRS rating information.
One important ability of the click model is to estimate the document relevance.
The trained click model is able to provide the estimated relevance for each query-document pair.
We can rank all documents under a query according to the estimated relevance and compare this predicted ranking with the human judgment ranking.
We expect the accuracy of the relevance estimation can be improved after eliminating the e ect of the intent bias.
The normalized discounted cumulative gain (NDCG) [10] is a well-known metric for measuring the divergence between the predicted ranking and human judgments.
NDCG is calculated cumulatively from the top of the result list to the bottom with the gain of each result discounted at lower ranks.
Higher NDCG values correspond to a better ranking result.
We report the arithmetic mean of NDCG over multiple queries.
Precisely, given a ranking, the integer sequence {gi} denotes the editorial relevances of the documents ordered by the ranking.
The NDCG at a particular rank threshold K is de ned as:
 2gi   1 log(1 + i) K(cid:2)

 i=1 where Z@K is the normalization to make the ideal ranking (i.e. the ranking obtained by ordering the documents according to their editorial relevance) to have NDCG value of
 metic mean.
We use the relative NDCG improvement to evaluate the model with the intent hypothesis and with the examination hypothesis.
Unbiased DBN upon DBN Unbiased UBM upon UBM NDCG@3: 0.586 upon 0.514 NDCG@3: 0.602 upon 0.532 %

 %

 %

 %

 %

 %
 %

 @



 f o t n e m e v o r p m








 Infinity Query Frequency Figure 5: The relative NDCG improvement over query frequencies We list NDCG evaluation results for the whole dataset in Table 2.
It shows that NDCG@1 has been improved by
 to 0.621 for DBN.
NDCG@10 has been improved 6.25% for UBM and 4.55% for DBN.
We clearly see that the new click models with the intent hypothesis outperform previous models with the examination hypothesis.
The lower rank threshold K is, the higher NDCG@K improvement rate achieved.
We perform the signi cance test for the NDCG improvements at all ten rank threshold K s, and  nd that the P-values of t-test are all less than 0.01%.
Therefore, we conclude that the NDCG improvement after adopting the intent hypothesis is statistically signi cant.
Furthermore, we investigate at which query frequency the intent hypothesis contributes the greatest improvement.
We









 Unbiased DBN upon DBN Unbiased UBM upon UBM NDCG@3: 0.615 upon 0.528 NDCG@3: 0.600 upon 0.52 %

 %

 %

 %

 @



 f o t n e m e v o r p m
 Unbiased DBN upon DBN Unbiased UBM upon UBM %
 %
 %
 %
 d o o h i l i e k
   g o
 f o t n e m e v o r p m
 %
 %










 Percentage of queries ordered by the number of clicks per session Figure 6: The relative NDCG improvement over average number of clicks plot the relative NDCG@3 improvement across di erent query frequencies for UBM and DBN in Figure 5.
We can see the NDCG improvement is very consistent across all query frequencies.
Each of the curves approximately forms an interesting unimodal pattern.
In the beginning, as the query frequency increases, the increase on NDCG improvement is mainly because we can learn the intent bias more accurately with the increase in data.
After reaching the NDCG improvement peak at about 104, the relevance improvement becomes less, since the relevance estimation from the baseline model has become more accurate as more search sessions are used for training.
As we can see, the intent hypothesis helps the baseline model with the examination hypothesis improve the relevance estimation for most queries, especially queries whose frequencies are between 103 to 104.
From the analysis in Section 3, we can see that the number of clicks within a search session is related to the intent bias, and it is interesting to see the relevance improvement on queries with di erent numbers of clicks.
Thus, for each query, we calculate the average number of clicks over all sessions.
We split the query set into 10 equal subsets according to the increasing order of the average number of clicks.
We plot the curves of the improvement rates of NDCG@3 for these 10 subsets in Figure 6.
The ten corresponding quan-tiles of the average number of clicks are aligned along the x-axis above the box.
From the  gure, we clearly see that the curves also have a unimodal form.
As we know, a query with lower average number of clicks tends to be navigational, while a query with higher average number of clicks tends to be informational.
In the beginning, along with the increase of the average number of clicks, the intent hypothesis leads to more signi cant improvement.
Thus, the intent hypothesis makes the click model to more accurately characterize informational queries, which usually have the diversity of search intents.
If the average number of clicks become large enough, the user s intrinsic intents will become too ambiguous to be characterized by the intent bias.
Thus, after a peak point where there is already quite large average number of clicks, the improvement will start to drop with the increase in the average number of clicks.
Infinity Query Frequency Figure 7: The Log-likelihood improvement over query frequencies
 After training the model, the parameters in click model have been estimated and we can use it to predict the joint probabilities Pr(C1:m) for all click con gurations.
We evaluate the click prediction by log-likelihood (LL), which has been widely used to measure the  tness in click models such as UBM [6] and CCM [8].
Its value indicates the logarithm of the joint probability of user click events in testing datasets predicted by the trained click model.
A larger LL indicates better prediction accuracy, and the optimal value is
 as (exp((cid:7)1   (cid:7)2)   1)   100%.
We report average LL over multiple sessions using arithmetic mean.
Figure 7 demonstrates the relative log-likelihood improvements on Unbiased-UBM and Unbiased-DBN over UBM and DBN on di erent query frequencies.
For frequent queries, the baseline model can also accurately predict clicks.
So the improvement curves drop along query frequencies.
The overall improvements in log-likelihood are 2.10% for DBN and
 new models on log-likelihood is close to the baseline model.
As introduced in Section 4.3.2, the prediction results are the average of cases over all intent biases according to the distribution of intent bias computed from the training set.
In this section, we report several interesting  ndings associated with the concept of intent bias.
Our study suggests that the calculation of intent bias is not only helpful in estimating the unbiased document relevance but also allows us to investigate more deeply some other web search mechanisms.
We discovered that the sessions of informational queries and navigational queries have signi cantly di erent intent bias distributions.
This property allows us to design an automatic method for classifying queries into two classes   informational and navigational.
Let us start with two examples.
In Figure 8(a), we report the density distribution of intent bias for the query the density distribution is multi-modal, which means that the search pattern of all users can be clustered into several groups, each with an intent bias.
This observation coincides with our intuition that in an informational query such as  photosynthesis , it is hard to re ect the exact search intent of every user.
However, since a density near 1 is larger than the density at other values, we can conclude that the majority of users tends to click on the documents which are relevant.
In Figure 8(b), we report the density distribution of intent bias for the query  paypal , which is a typical navigational query.
Di erent from the informational query, in this case the sessions with an intent bias near 1 dominate all the sessions.
This result is also intuitive, because we believe that a navigational query is much more likely to precisely re ect the user s intent than an informational query.
y t i s n e
 .
.
.
.
.
.
Navigational Query Informational Query


 y t i s n e








 y t i s n e








 Intent Bias





 Intent Bias

 (a) query  photosynthesis  (b) query  paypal  Figure 8: Density histogram of intent bias on the two example queries In order to numerically characterize the di erence between the distributions of Figure 8(a) and Figure 8(b), we calculate the entropy of the intent bias distribution for each query.
The entropy measures the degree of the diversity of the intent biases behind a single query: a higher entropy value suggests that the distribution of intent biases is more diversi ed, while a lower entropy value suggests that the distribution is more concentrated.
Obviously, the entropy for the query  photosynthesis  (2.4611) is higher than that for  paypal  (0.1452).
To give a more convincing conclusion, we manually chose 200 informational queries and 200 navigational queries, and plotted the distribution of entropies on these two classes of queries in Figure 9.
It is observed that the entropy for navigational queries is mostly located near zero, while the entropy for informational queries are distributed around a positive value far away from zero.
This observation exactly coincides with our intuition that there is a larger degree of diversity in intent biases for informational queries.
The above analysis suggests that search engines can maintain a query classi er based on the entropy of the intent bias.
With such a classi er, the search engine can treat queries with a single intent and with multiple intents di erently so as to satisfy the user s information need behind the query.
Click Patterns According to the intent hypothesis, the intent bias of a search session is deterministically derived from the click events.
Thus, there should be some speci c connections between the intent bias and other click patterns, such as the click positions and the number of clicks.
In Figure 10, we report the




 Entropy of intent bias distribution Figure 9: The distribution of the entropy of the intent bias over the two groups of queries, i.e., the informational queries and the navigational queries.
relation between intent bias and three statistical quantities, including the  rst-click position, the last-click position and the number of clicks in the session.
These quantities are averaged among all the search sessions based on three months of data.
In order to avoid the misapprehension, it is necessary to note that the higher value of  , which is listed along the x-axis, means the lower intent bias.
For example, the rightmost endpoint of x-axis corresponds the case that there is no intent bias.
As illustrated in Figure 10, the  rst-click position decreases as the value of   increases.
This phenomenon is natural, since the lower the intent bias becomes, the more similarity there is between the user s search intent and the query she issues.
Since the search engine arranges the position of documents with respect to their similarities to the query, a higher positioned document is more likely to have a close connection to the query, and a higher probability of being clicked by the user.
On the other hand, Figure 10 shows that the last-click position decreases in the range of [0, 0.4)   (0.85, 1] and increases in the range of [0.4, 0.85].
The reason for its increase may be due to another characteristic of the search intent: with a high intent bias, the user tends to continue browsing the search result page and click more documents.
However, why does the last-click position dramatically decrease in the range of (0.85, 1]?
This phenomenon is caused by the existence of navigational queries.
In fact, users who submit navigational queries usually have their intent biases close to zero, or value of   close to 1.
Most of them would be sat-is ed by the top document and leave.
Thus, the last-click position in sessions with a low intent bias is often equal to the  rst-click position.
The curve of the average number of clicks can also be interpreted in a similar way.
For intent biases in the range of [0, 0.85), most of the queries are informational, so the users click more documents if they have higher intent biases.
However, for intent biases in the range of [0.85, 1], the navigational queries occupy a large proportion, which makes the average number of clicks close to 1.
The interesting connection between the intent bias and other click features makes it a valuable attribute for the e u a























 Intent bias Figure 10: The relation between the intent bias and three click patterns such as the average  rst click position, the average last click position and the average number of clicks.
training of ranking functions.
In addition, it can also be used for the recognition and classi cation of click patterns.
In this paper, we have investigated the relationship between intent, document and query and make a deep exploration of the gap between click-through rate and document relevance.
We have found that the widely adopted concepts of the position bias and the examination hypothesis fail to completely explain the actual bias between click-through rate and relevance because of the gap between user search intent and input query.
In order to characterize the diversity of search intent, we propose the intent hypothesis as a complement to the original examination hypothesis.
The new hypothesis is very general and can be  t into most of the existing click models to improve their capacities for learning unbiased relevance.
Under the concept of intent bias introduced in this paper, we have successfully modeled the actual bias between click-through rate and relevance, whose rationality has been veri ed both theoretically and empirically.
Furthermore, we have demonstrated how to infer the click models with the consideration of the intent hypothesis.
The experiments on large scale click through log show that the models with the intent hypothesis consistently and sig-ni cantly perform better than the original versions of click model under the examination hypothesis.
Besides user clicks, other useful information can be derived from in click through logs, such as the user s history of input queries and visited pages.
This kind of information is related to the user s current search intent and can be used to better identify the search intent behind the query.
Our next step is to include such information into the click model with the intent hypothesis to further improve click model accuracy.
Acknowledgment Botao Hu would like to thank Prof. Roger Olesen of Ts-inghua University for polishing the language.
Botao Hu was supported in part by the National Basic Research Program Average first click position Average last click position Average number of clicks of China Grant 2007CB807900, 2007CB807901, the National Natural Science Foundation of China Grant 60604033, 60553001,
 ment Program of China Grant 2006AA10Z216.
