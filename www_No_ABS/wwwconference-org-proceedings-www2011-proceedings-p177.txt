Cloud Computing has been a dominant IT news topic over the past few years.
It is essentially a way for IT companies to deliver software/hardware on-demand and for costumers to store and access data over the Internet.
Cloud computing applications are generally priced on a subscription model, so end-users may pay a yearly usage fee, for example, rather than the more familiar model of purchasing software to run on desktop.
The Cloud-based services are not only restricted to software applications (Software as a Service   SaaS), but could also be the platform for the development and deployment of cloud applications (Platform as a Service   PaaS) and the hardware infrastructure (Infrastructure as a Service   IaaS).
Many Companies, e.g.
Google and Amazon, are Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
o ering Cloud computing services such as Google s App Engine and Amazon s Elastic Compute Cloud (EC2).
Large data centers provide the infrastructure behind the Cloud and virtualization technology makes Cloud computing resources more e cient and cost-e ective both for providers and customers.
Indeed, end-users obtain the bene ts of the infrastructure without the need to implement and administer it directly adding or removing capacity almost instantaneously on a  pay-as-you-use  basis.
Cloud providers can, on the other hand, maximize the utilization of their physical resources also obtaining economies of scale.
The development of e cient service provisioning policies is among the major issues in Cloud research.
Indeed, modern Clouds live in an open world characterized by continuous changes which occur autonomously and unpredictably.
In this context, game theoretic methods allow to gain a in-depth analytical understanding of the service provisioning problem.
Game Theory has been successfully applied to diverse problems such as Internet pricing,  ow and congestion control, routing, and networking [5].
One of the most widely used  solution concept  in Game Theory is the Nash Equilibrium approach: A set of strategies for the players constitute a Nash Equilibrium if no player can bene t by changing his/her strategy while the other players keep their strategies unchanged or, in other words, every player is playing a best response to the strategy choices of his/her opponents.
In this paper we take the perspective of SaaS providers which host their applications at an IaaS provider.
Each SaaS provider wants to maximize its pro t while complying with QoS requirements, speci ed in Service Level Agreement (SLA) contracts with the end-users, which determine the revenues and penalties on the basis of the achieved performance level.
The pro t of the SaaS is given by the revenues from SLAs minus the cost sustained for using the resources supplied by the IaaS.
However, each SaaS competes with others SaaS and bids for the use of infrastructural resources.
The IaaS, in his turn, wants to maximize the revenues obtained providing the resources.
To capture the behavior of SaaSs and IaaS in this con icting situation in which the best choice for one depends on the choices of the others, we recur to the Generalized Nash game model [13, 15], which is an extension of the classical Nash game.
We then use Game Theory results for developing an e cient algorithm for the run time allocation of IaaS resources to competing SaaSs.
The remainder of the paper is organized as follows.
Section 2 introduces the reference system under study.
In Section 3 we introduce our model based on the concept of Generalized Nash equilibrium and we prove its existence.
In Sec-while a general solution method is proposed in Section 5.
The experimental results discussed in Section 6 demonstrate the e ciency of our method.
Other approaches proposed in the literature are discussed in Section 7.
Conclusions are  nally drawn in Section 8.
We consider SaaS providers using Cloud computing facilities to o er services, according to the IaaS paradigm.
We assume that a SaaS provider o ers multiple transactional Web services (WSs) and each service represents a di erent application.
The hosted WSs can be heterogeneous with respect to resource demands, workload intensities and QoS requirements.
The set of WS applications o ered by the p-th SaaS provider are denoted with Ap.
An SLA contract, associated with each WS application, is established between the SaaS provider and its end-users.
In particular, as in other approaches [9, 10, 31], for each WS application k   Ap, a linear utility function speci es the per request revenue (or penalty) Vk =  k +mk Rk incurred when the end-to-end response time Rk assumes a given value.
The slope of the utility function is mk =  k/Rk < 0 and Rk is the threshold that identi es the revenue/penalty region, that is, if Rk > Rk the SLA is violated and the SaaS incurs in penalties.
Linear utility functions are a  exible mechanism to rank di erent applications (e.g., assigning higher slopes to more important applications), and allow also to implement soft constraints on response times since the SaaS goal is to keep the infrastructure working in a pro tability region, i.e., to provide an average response time lower than Rk looking for the trade-o  between the SLA revenues and infrastructural costs [9].
Applications are hosted in virtual machines (VMs) which are dynamically instantiated by the IaaS provider.
We make the simplifying assumption that each VM hosts a single WS application.
Multiple VMs implementing the same WS application can also run in parallel.
In that case, we further assume that the running VMs are homogeneous in terms of RAM and CPU capacity C and evenly share the workload.
IaaS providers usually charge software providers on an hourly basis [6].
Hence, the SaaS has to face the problem of determining every hour the optimal number of VMs for each WS class in order to maximize the net revenues.
The SaaS performs resource allocation on the basis of a prediction of future WS workloads [10].
The SaaS needs also an estimate of the future performance of each VM in order to determine application average response time.
In the following we model each WS class hosted in a VM as an M/G/1 queue [11], as done in [1, 26] and we assume, as common among Web service containers, that requests are served according to the processor sharing scheduling discipline.
For the IaaS provider we consider a model similar to Amazon EC2 [6] and we assume that the IaaS provider o ers: (i)  at VMs, for which SaaS providers applies for a onetime payment (currently every one or three years) for each instance they want to reserve, (ii) on demand VMs, which allows SaaS to access computing capacity with no long-term commitments, and (iii) on spot VMs, for which SaaS providers bid and compete for unused IaaS resources.
The VM instances are charged with the on spot cost  k for application k, which is set by the IaaS and  uctuates periodically depending on the IaaS provider time of the day energy costs and also on the supply and demand from SaaS for on spot VMs [6, 20].
Indeed, SaaS providers compete among them for the use of on spot VMs and specify the maximum cost  U k for each application k they are willing to pay per instance hour.
The on spot cost  k is  xed by the IaaS provider which can also decide to do not allocate any on spot instance to a SaaS.
On the other hand, each SaaS provider is guaranteed to have access up to f U p  at VMs he reserved by applying to the onetime payment.
The number of on spot VMs available at the IaaS cloud service center is denoted by sU .
For example in the Amazon case on spot costs are available via the EC2 API [6] or by third party sites [29].
On spot costs  uctuate according to the time of the day and on the Cloud site region, and could be less or greater than the time unit cost   for  at VMs.
Finally, we denote with   the cost for on demand instances.
With the current pricing models,   is strictly greater than   and we assume   >  U k for all k.
Indeed, since the IaaS provider can arbitrarily terminate on spot instances from a SaaS resource pool [6], no one is willing to pay for a less reliable resource a time unit cost higher than on demand instances, which provide a higher availability level.
On spot instances have been traditionally adopted to support batch computing intensive workloads [6].
However, since nowadays IaaS providers allow specifying autonomic policies which can dynamically allocate VM instances in few minutes as a reaction to failures, we advocate the use of on spot instances also to support the execution of traditional Web applications.
Hereafter we introduce the Generalized Nash Equilibrium Problem arising in the Cloud computing system under study and we prove the existence of at least an equilibrium.
The goal of SaaS provider p is to determine every hour the number of  at fk, on demand dk and on spot sk VMs to be devoted for the execution of all WS applications k   Ap, in order to maximize its pro ts and, at the same time, so as to satisfy the prediction  k for the arrival rate of the WS application k. Let us denote with  k the maximum service rate for the requests of application k on a VM of capacity one.
If the workload is evenly shared among the VMs, then the average response time for the execution of application , under the k requests is given by E[Rk] =
 C k   k fk +dk +sk assumption that VMs are not saturated, i.e. guaranteeing the equilibrium conditions for the M/G/1 queues C  k (fk + dk + sk)    k > 0.
The average per time unit revenues for application k requests are given by Vk  k = ( k + mk E[Rk])  k.
Considering the infrastructural costs to access  at, on demand, and on spot VM instances the goal of a SaaS provider is to maximize its pro ts given by: (cid:18) (cid:88) k Ap  k  k + mk  k(fk + dk + sk) C  k (fk + dk + sk)    k     fk     dk    k sk With this setting in mind, the problem of the generic SaaS (cid:19) .
Capacity of computational resources Set of applications of the p SaaS provider Set of applications of all the SaaS providers N number of SaaS providers Ap
 f U p Maximum number of  at computational resources IaaS can provide for provider p sU Maximum number of on spot computational resources IaaS can provide for all the SaaS providers
  k Prediction of the arrival rate for application k  k Maximum service rate of a capacity 1 server for executing class k application mk Application k utility function slope      L  U k Minimum time unit cost for on spot VMs used for application k, set by the IaaS provider k Maximum time unit cost for on spot VMs used for application k, set by the SaaS provider Time unit cost for  at VMs Time unit cost for on demand VMs Decision Variables fk dk sk  k xp = (fk, dk, sk)k Ap Strategies vector of SaaS provider p x p = (xi)N Number of  at VMs used for application k Number of on demand VMs used for application k Number of on spot VMs used for application k Time unit cost for on spot VMs used for application k Strategies vector of all SaaS providers di erent from p i=1,i(cid:54)=p, Table 1: Parameters and decision variables.
plications k   Ap and every SaaS provider p, in order to maximize its total revenue: + max  I = (  fk +   dk +  k sk) (cid:88) k A k    k    U  L k   k   A, (5) where A denotes the set of indexes of all WS applications (i.e., A =  pAp, Ap1   Ap2 = (cid:11) if p1 (cid:54)= p2).
Note that, the on spot instance cost lower bound  L k is  xed by the IaaS provider according to the time of the day and includes the energy costs for running a single VM instance for one hour and the amortized cost of the hosting physical machine [20].
For the sake of clarity, the notation adopted in this paper is summarized in Table 1.
k <  L If the maximum time unit costs of an application is lower than the minimum set by the IaaS, i.e.  U k , formally the SaaSs and IaaS problems have no solution.
In that case we can set sk = 0 and consider a simpli ed problem where the capacity allocation problem for application k is limited to determine the number of  at and on demand instances.
k    U Hence in the following we will always assume that  L k for all k. Note that, if the on spot instances are terminated by the IaaS provider, then the SaaS can dynamically start the execution of an equal number of on demand instances.
In this framework, SaaS providers and the IaaS provider are making decisions at the same time, and the decisions of a SaaS depend on those of the others SaaS and the IaaS.
Vice versa, the IaaS objective function depends on SaaS decisions.
In this setting, we can not analyze decision in isolation, but we must ask what a SaaS would do, taking into account the decision of the IaaS and other SaaSs.
To capture the behavior of SaaSs and IaaS in this con icting situation (game) in which what a SaaS or the IaaS (the players of the game) does directly a ects what others do, we consider the Generalized Nash game[13, 15], which is broadly used in Game Theory and other  elds.
We remind the reader that the generalized Nash equilibrium problem (GNEP) di ers from the classical Nash equilibrium problem (NEP) since, not only the objective functions of each player (called payo  functions) depend provider p becomes: max  p = (cid:88)   (cid:88) k Ap k Ap mk  k(fk + dk + sk) C  k (fk + dk + sk)    k   fk   (cid:88) k Ap   dk   (cid:88) (cid:88) fk   f U k Ap p k Ap (cid:88) k A   k   Ap sk   sU   k   Ap.
 k sk (1) (2) (3) (4)  k  k can be dropped in the SaaS fk + dk + sk >  k C  k Note that the terms (cid:80) fk, dk, sk   0 k A objective function since they are independent of the decision variables.
Constraint (1) entails that the  at VMs allocated to applications are less or equal to the one available, while constraint (2) guarantees that resources are not saturated.
Finally constraint (3) guarantees than the on spot VMs allocated to competing SaaS providers are lower than the one available at the IaaS cloud service center sU .
We would like to remark that, in the formulation of the problem, we have not imposed variables fk, dk, sk to be integer, as in reality they are.
In fact, requiring variables to be integer makes the solution much more di cult.
However, preliminary experimental results have shown that if the optimal values of the variables are fractional and they are rounded to the closest integer solution, the gap between the solution of the real integer problem and the relaxed one is very small, justifying the use of a relaxed model.
We therefore decide to deal with continuous variables, actually considering a relaxation of the real problem.
On the other side, the IaaS provider s goal is to determine the time unit cost  k for on spot VM instances for all ap-each player s strategy set may depend on the rival players  strategies.
In our setting the constraint of each problem involving other player s variables (joint constraint) comes from (3).
Following the Nash equilibrium concept, SaaS and IaaS providers adopt a strategy such that none of them can improve its revenue by changing its strategy unilaterally (i.e., while the other players keep their strategies unchanged).
The service provisioning problem results therefore in a GNEP where the players are the SaaS providers and the IaaS provider, the strategy variables of SaaS provider p are fk, dk, and sk, for k   Ap, while the strategy variables of the IaaS are the costs for on spot VMs,  k, for all k   A.
In the following we denote with xp = (fk, dk, sk)k Ap the strategies vector of p=1, x p the vector formed SaaS provider p, with x = (xp)N by the strategies of all SaaS providers di erent from p, and we set   = ( k)k A.
Within this setting, the IaaS s strategy is simple.
In fact, if a SaaS provider decides not to use on spot VMs for application k, that is sk = 0, the value of the IaaS payo  does not depend on the choice for  k, that can be any feasible value.
Whereas, if sk > 0, regardless its value, the best response of the IaaS is to play  k =  U k .
Another important feature of the derived GNEP is that it satis es the Convexity Assumption: the payo  functions of both SaaS providers and IaaS, are concave in its own variables ( p is concave [8] being the sum of linear and concave function, and  I is linear) and the set of strategies are convex.
Moreover, even if the decision of a SaaS depends on the decisions of the other SaaSs and the IaaS, the only constraint of each problem involving other player s variables (coming from (3) in each SaaS problem), is the same for all players: we refer to this special class of GNEP as jointly convex GNEP [15].
Using the model introduced in the previous sections, we now prove that there exists an equilibrium for service provisioning on the Cloud.
The proof is based on the equivalence between generalized Nash equilibria and  xed points of the best-response mapping, and on the Kakutani s  xed point theorem [21].
In the following, we indicate by Xp(x p) the set of strategies for provider p, and XI the set of strategies of the IaaS provider.
Theorem 1 There exists at least one generalized Nash equilibrium for the game.
Proof Let consider any SaaS provider p. For any feasible strategy x p of the other SaaS providers we have that Xp(x p) contains the set: p := {xp   0 : (cid:80)
 fk   f U p , sk = 0   k   Ap k Ap fk + dk >  k/(C  k)   k   Ap}.
(cid:21) .
and  U (cid:88) p (xp) is: (cid:20) mk  k(fk + dk + sk) C  k (fk + dk + sk)    k     fk     dk    L k sk k Ap We remark that if fk + dk + sk    k then  U as well.
p (xp)     and if dk   +  then  U C  k for some k   Ap, p (xp)     If we denote by M p := max xp XL
 p (xp), then the set: (cid:102)Xp := {xp :  U p p (xp)   M p} is nonempty, convex and compact.
Therefore, for any feasible x p and   we obtain that:
 p (xp) = M p max xp Xp(x p)  p(xp,  )   max xp XL  p(xp,  )   max xp XL p p thus: arg max xp Xp(x p)  p(xp,  )   (cid:102)Xp, of the rivals are uniformly bounded by (cid:102)Xp.
(cid:101)X := (cid:102)X1   .
.
.
(cid:103)XN   XI Finally, we consider the convex compact set that is the sets of best responses of player p to the strategies (cid:20) (cid:21)   .
.
.
(cid:48)  I (x,   ).
and the best response set-valued mapping B de ned as follows: (cid:20)   arg B(x,  ) := arg max y1 X1(x 1)  1(y1,  ) max yN  XM (x N )  n(yN ,  )   arg max  (cid:48) XI (cid:21) map B : (cid:101)X   (cid:101)X has nonempty and convex values, and its From the above discussion it follows that the set valued graph is closed by continuity of payo  functions.
Therefore, by Kakutani s theorem there exists a  xed point of B, that is a strategy (x,  )   B(x,  ), which is a generalized Nash equilibrium of the game.
In order to gain insight into the properties of the equilib-ria in our setting, let us focus on the case of a single SaaS provider with a single application class.
In the following we will also assume that the IaaS is over-provisioned and there is no an upper bound sU on the number of on spot VM instances available and, hence, the constraint (3) is relaxed.
Indeed, it is not reasonable that a single SaaS will be able to saturate the on spot instances capacity available in a real system.
In that case, each player s strategy (SaaS and IaaS) belong to a set which is  xed and does not depend on the rival players  strategies: hence the GNEP reduces to a NEP which is much more simple to solve.
The aim of the SaaS provider, given the IaaS strategy  , is to choose f , d, and s that maximize the payo : Moreover, for any feasible strategy   of IaaS provider we have the following relations: p (xp)    p(xp,  )    U
 p (xp), where  L (cid:88) k Ap p (xp) is: (cid:20) mk  k(fk + dk + sk) C  k (fk + dk + sk)    k (cid:21)     fk     dk    U k sk m   (f + d + s)     f     d     s,
 C   (f + d + s)     over the set XS = {(f, d, s)   R3 C   , f   f U}.
The aim of the IaaS provider, given the SaaS strategies (f, d, s), is to choose   that maximizes the payo : + : f + d + s >    I =   f +   d +   s, over the set XI = [ L,  U ].
conditions for the SaaS and the IaaS optimization problems and concatenating them and it is omitted here for space limitation (see [8] for further details).
We can observe that the Nash equilibria depend on the application workload conditions and on the relation between the cost   of the  at VMs and the upper bound  U for on spot instances cost.
The obtained equilibria and the corresponding value of the payo  functions  S and  I are reported in Table 2.
The  rst important remark we get is that, in general, there is no a unique Nash equilibrium (e.g., when   =  U ).
However, if multiple equilibria exist they are equivalent, that is they are characterized by the same values of the payo s.
Furthermore, assuming   >  U k for all k we always have d = 0 (i.e., the SaaS provider always adopt  at or on spot VMs which are always cheaper than on demand instances).
When      U (Table 2,  rst and second rows) then it is more convenient for the SaaS provider to use only on spot instances which number can be obtained by a closed formula under any workload conditions.
Remind that the value of  L is set by the IaaS provider, and SaaS provider can not set the value of  U too low otherwise the IaaS will not provide on spot resources.
Let us now examine the case   <  U and assume initially that f U     C   .
In these hypotheses, the SaaS provider is under heavy load conditions and requests cannot be executed by using only the  at VMs.
The SaaS provider will use all of its  at VMs and will buy on spot VMs at the maximum cost.
Again, the number of on spot VMs can be determined by a closed formula (see Table 2, third row).
Since   <  U , in these conditions the payo   S is greater than the value obtained when      U (Table 2  rst and second rows).
Hence, these conditions are more pro table for the SaaS provider which determines the optimal trade-o  between the cost of the  at and on spot VMs and the revenues which can be achieved by the SLA contract.
With the same arguments we can derive that, vice versa, the payo   I is lower than the value obtained when      U , hence these conditions are less pro table from the IaaS point of view even if on spot instances are sold at the maximum cost.
Let us now examine the case when   <  U and f U >   C   .
The SaaS provider is under light load conditions and, therefore, the incoming requests could be executed by using only the  at VMs.
Under these hypotheses, the equilibria are set according to the marginal value of the payo  function of the SaaS player evaluated in f = f U and s = 0, that is (C   f U  )2 .
This marginal value represents the change in the revenues of SaaS per unit change in s, i.e., the increase in the SaaS provider revenues deriving from SLA contracts obtained providing better performance to end-users by adopting an additional on spot VM.
We identify two cases:  m  2   if   <  U <  m  2 (C   f U  )2 (see Table 2, fourth row), the marginal value is greater than the cost of individual on spot instance sold at the maximum cost (  =  U ), therefore it is convenient for the SaaS provider to buy on spot instances.
Note that under these conditions, the payo   S is greater than the value obtained when      U as in the previous case.
Vice versa, for the IaaS provider these circumstances are less pro table.
(C   f U  )2    U (see Table 2,  fth and  m  2   if   <  U and sixth row), then the marginal value is less or equal to the cost of on spot VMs and hence the SaaS provider has no incentives to buy additional on spot VMs.
Also in these cases, the equilibrium value of the payo  of SaaS provider is greater than the one obtained when      U , while this again does not happen for the IaaS provider.
Finally, it is worth noticing that if (C   f U  )2 <   the SaaS provider adopts a number of VMs lower than f U .
Hence, in that case the costs incurred by using a larger number of  at VMs cannot be counterbalanced by the revenues which can be obtained by improving application performance.
 m  2

 In the previous sections, we showed that the service provisioning problem in a Cloud Computing environment represents a GNEP and more precisely a jointly convex GNEP.
Concerning solution algorithms for general GNEPs, the literature is still very limited.
More interesting results have been obtained for GNEPs with a jointly convex structure as our model is.
In fact, a jointly convex GNEP can be solved introducing a variational inequality (VI) problem1 reformulation: given a jointly convex GNEP whose payo s are continuously di erentiable and convex with respect to each player variables, then every solution of the V I(X, F ), where F =  [( xp  p(x,  )N p=1, I (x,  )] and X := X1 .
.
.
XN  XI is the set of individual and joint constraints, is also a solution of the jointly convex GNEP (see, e.g., [15]).
We remark that the GNEP has usually multiple or even in nitely many solutions and it is not true that any solution of the jointly convex GNEP is also a solution of the VI.
A solution of the jointly convex GNEP which is also a solution of the VI is called a variational equilibrium.
Our approach is to calculate, among all the equilibria, a variational equilibrium which is more socially stable than other equilibria (see [12]) and it is a valuable target for an algorithm.
There are plenty of methods for solving VI problems.
In our setting we have:  
  f1
  d1
  s1     1 
  
 = m1  2
 m1  2
 (C  1 (f1 + d1 + s1)    1)2 +   (C  1 (f1 + d1 + s1)    1)2 +   (C  1 (f1 + d1 + s1)    1)2 +  1 m1  2
      s1          whose Jacobian is: (cid:34)a1 a1 a1 (cid:35) a1 a1 a1 a1 a1 a1
 .
.
.
(cid:34)a|A| a|A| a|A| a|A| a|A| a|A| a|A| a|A| a|A| (cid:35)

 where the generic term ak =   (C  k (fk+dk+sk) k)3 > 0, and B is a matrix of dimension 3|A|   |A|.
Its symmetric part is:
 problem consists in  nding a vector z    X such that (cid:104)F (z ), z   z (cid:105)   0, for all z   X.
k C  k
 f = 0 d = 0 s =   C  
    U +
 C   (  U  U
 (cid:16) (cid:17)  U + (cid:113)  m (cid:16)  m)2 (cid:113)  m (cid:17) d = 0 s   0 (cid:113)  m (cid:16)  m)2 (cid:113)  m (cid:16) (cid:17)   f U  m)2 + f U ( U    ) (cid:17)   f U  m)2 + f U ( U    ) (cid:17) (cid:113)  m  m)2 d = 0 s = 0

  U  U
   C   ( f + s =   C  
 d = 0 s =   C   C   (  U + d = 0 s =   C   C   (  U + f = f U
 f = f U
     (cid:16) f =   C  

     + C   (   IaaS equilibrium and value   =  U
 C   (  m  U +  U )   =  U
 C   (  m  U +  U )   =  U
 C   (  m U +  U ) + f U (     U )   =  U
 C   (  m U +  U ) + f U (     U ) max{ L,  }        U  m   +  )
 C   ( f = f U d = 0 s = 0  S = m   f U C   f U       f U max{ L,  m  2 (C   f U  )2 }        U  I =   f U Table 2: Single application single SaaS equilibria.
(cid:34)a|A| a|A| a|A| a|A| a|A| a|A| a|A| a|A| a|A| (cid:35)  

 Conditions   >  U   =  U   <  U f U     C     <  U f U >   C    U <  m  2   <  U (C   f U  )2 f U >   C    m  2 (C   f U  )2 <     <  U f U >   C        m  2 (C   f U  )2    U (cid:34)a1 a1 a1 (cid:35) a1 a1 a1 a1 a1 a1
 .
.
.
  hyperplane projection method [19], where two projections per iteration are executed.
The method is simple and admits a geometric interpretation.
Given the current point (xt,  t),  rst we compute ProjX ((xt,  t)    t F (xt,  t)) and then we search on the line segment between those points, for (yt,  t) such that the hyperplane {(x,  ) : (cid:104)F (yt,  t), (x,  )   (yt,  t)(cid:105) = 0} strictly separates (xt,  t) from any solution of the problem.
The next iterate (xt+1,  t+1) is computed by projecting (xt,  t) onto the hyperplane and then onto X.
The scheme is formally stated in Figure 1.
We set as initial solution of the algorithm x0 the one obtained by the best reply among SaaS according to the Gauss-Siedel scheme [15] and setting  0 =  U k for all k.
We emphasize that constructing the hyperplane requires a single projection onto the feasible set and employs an Armijo-type line search.
During the line search, moreover, no projection onto X are required, but only function evaluations.
Regarding the choice of the parameters, following [19] we take  t+1 = median(  ,    t  t,  ), where   > 1 but not too large, e.g.
  = 2.
The algorithm for the VI solution can be executed e -ciently by the IaaS, under the assumption that the SaaSs provide to the IaaS also the the incoming workload prediction  k for the next hour.
Indeed, for the problem under analysis the SaaS utility function slopes are advertised to the cloud end-users and hence are known also by the IaaS.
The resource management algorithm proposed has been evaluated for a variety of system and workload con gura-Therefore, in the feasible set X, its nonzero eigenvalues (i.e., 3 a1,   , 3 a|A|) are positive (being mk < 0 and fk + dk + sk >  k ), and hence F results to be monotone2 (not C  k strictly).
Hence, we can calculate a variational equilibrium of the GNEP associated to the service provisioning problem by solving a monotone VI.
Concerning the solution methods for monotone VIs, the projection type methods are among the simplest ones.
These methods found on the well known  xed point reformulation of a VI:     X solves V I(X, F ) i  z   z = ProjX (z       F (z   )) for any   > 0, where ProjX denotes the orthogonal projection onto X.3 The important feature of these methods is that there is not need of using derivative of F and they do not involve any computation besides the function evaluation and the projection onto X.
When the projection is easily computable, as is our case, projection methods are extremely simple and cheap.
Among the projection type methods we consider the
 (cid:104)F (w)   F (z), w   z(cid:105)   0.
and a sequence { t}   [  ,  ].
Let (x0,  0)   X and set t = 0.
STEP 1.
Compute (xt,  t) = (xt,  t)    t F (xt,  t) STEP 2.
If (xt,  t) = ProjX (xt,  t) then STOP STEP 3.
Set j(t) the minimum j   0 :  jProjX (xt,  t) + (1   2  j)(xt,  t))(cid:105) (cid:107)(xt,  t)   ProjX (xt,  t)(cid:107)2.
(cid:104)(xt,  t), F (2      t Let  t = 2 j(t) and (yt,  t) =  t ProjX (xt,  t) + (1    t) (xt,  t),  k = (cid:104)F (yt,  t), (xt,  t)   (yt,  t)(cid:105) (cid:107)F (yt,  t)(cid:107)2 , (xt+1,  t+1) = ProjX ((xt,  t)    t F (yt,  t)) STEP 4.
Set t = t + 1 and go to STEP 1.
Figure 1: Solution algorithm for VI.
tions.
The application performance parameters have been varied as considered in the literature (see e.g.
[25, 1, 9] and references therein).
Cloud providers time unit costs have been varied according to the commercial fees currently adopted [6].
Section 6.1 is devoted to quantitatively anal-yse the single application case study presented in Section
 ties on a medium size system.
Finally, the scalability of the algorithm reported in Figure 1 is discussed in Section 6.3.
For the numerical analysis reported in this Section we set   = 10 req/sec, C = 1,   = 1 req/sec, and m =  1.
Figures
  S an  I where we set  U = 0.09$, and we varied   and f U under the assumption that f U    /(C  ) (i.e., which corresponds to rows 1-3 of Table 2).
Under this hypothesis the SaaS provider is under heavy load conditions since he cannot serve the overall incoming workload by using only his  at resources.
The plots show that under the condition   >  U the payo  functions are constant, while when      U  S ( I ) increases (decreases) linearly with f U .
 m   Figures 4 and 5 plot  S and  I as function of  U (Table
 (  < C   f U ) where we set   = 0.03$ and f U = 50.
In this case the behaviour of the payo  functions changes crossing (C   f U  )2 which with the considered the marginal value setting is equal to 0.0625$: When  U is greater than the marginal value both  S and  I are constant, while increase for lower values of  U .
Indeed, the SaaS provider acquires additional on spot instances to pro tably serve incoming end users requests, while the IaaS obtains higher revenues selling on spot instances.
The aim of this Section is to analyse how the on spot VMs are shared among competing SaaS changing the game parameters.
The analysis results have been obtained by the algorithm described in Section 5.
In particular we consid-Figure 2: SaaS payo  function for f U    /(C  ).
Figure 3: IaaS payo  function for f U    /(C  ).
ered two SaaS o ering  ve heterogeneous applications each.
If not di erently stated we set sU = 40, C = 1,   = 0.1$, p = 20 (p   {1, 2}),  k = 1 req/s,  k = k req/s,   := 0.11$, f U k = 0.09 for all k   {1, 10}.
In mk =  1,  L k = 0.03$, and  U the following we will vary one parameter at the time for the  rst application k = 1, while the parameters of the remaining ones will be held  xed.
Figures 6-9 show how the number of resources devoted to the  rst application (in terms of  at, on demand, and on spot instances) and the overall capacity allocated to the remaining classes change as a function of the varying parameter.
In particular, in Figure 6 the incoming workload  1 varies between 1 and 14 req/s.
As the Figure shows, all of the on spot instances available at the IaaS are always used but, as the workload increases, they are migrated from the other applications to application 1.
In order to pro tably sustain the workload, the number of  at instances used is also increased, but on demand VMs are not used until  1 reaches 11 req/s.
When  1 is further increased the system starts allocating on demand VMs which are more expensive but are needed to serve the incoming requests.
In general the resource allocation trends are linear demand VMs are never used and the trends are linear.
This is very unintuitive, since increasing the maximum time unit cost one is willing to pay for a given application implies that the number of on spot instances devoted to the same application is reduced.
Figure 6: Resource allocation with varying application 1 incoming workload.
Figure 7: Resource allocation with varying application 1 utility function slope.
Figure 8: Resource allocation with varying application 1 maximum service rate.
To evaluate the scalability of our resource allocation algorithm we have considered a very large set of randomly generated instances.
All tests have been performed on VMWare virtual machine based on Ubuntu 9.10 server running on an Intel Nehalem dual socket quad-core system with 32 GB of RAM.
The virtual machine has a physical core dedicated with guaranteed performance and 4 GB of memory reserved.
KNITRO 7.0 has been use as non linear optimization solver.
Figure 4: SaaS payo  function for   < C   f U .
Figure 5: IaaS payo  function for   < C   f U .
with  1, the discontinuities in the plots are due to the fact that the equilibrium is not unique and hence the same performance and revenues can be obtained with multiple values of (fk, dk, sk).
Figure 7 shows the resource sharing at the equilibrium changing the slope of application 1 utility function (which has been varied in the range [ 15, 1]).
As in the previous analysis, the on spot capacity is migrated to application 1 which becomes more sensible to response time variations and hence requires additional capacity.
However, in this case the adoption of on demand instances is never pro table.
Figure 8 analyses how the variational equilibrium changes by varying application 1 maximum service rate (the range [0.05, 1] req/s has been considered).
If the maximum service rate increases the service time required to process each application 1 request decreases and the overall capacity required to process application 1 decreases accordingly.
Hence, in this case on spot instances are migrated from application 1 to the other classes and on demand instances are used only when application 1 requests are very CPU intensive ( 1 < 0.1 req/s).
Finally, Figure 9 shows how the equilibrium changes by varying the maximum time unit cost for application 1 ( U
 has been varied in the range [0.1, 1]$; we set   = 0.03$, while for the remaining classes  L k = 0.02$).
As  U
 application 1 decreases since the IaaS set  1 =  U 1 and the SaaS provider can use in a more cost e cient way the on spot VMs to serve his remaining applications, while application k = 0.01$ and  U tem.
A survey of di erent modelling and solution concepts of networking games, as well as a number of di erent applications in telecommunications and wireless networks, based on Game Theory, can be found in [5].
With respect to telecommunication applications, a rich literature exists which includes solutions for  ow and congestion control [3], network routing [4],  le allocation [24], load balancing [22], resource allocation [17] and quality of service provisioning [14].
In [18] a Markovian queueing network model is used to derive decentralized  ow control mechanisms in computer communication networks with multiple controllers.
In the setting of optimal routing strategies, [23] investigates the existence of Nash equilibria in noncooperative  ow control in a general product-form network shared by multiple end-users introduced in [18].
The goal is to study the existence of Nash equilibria for decentralized control schemes.
This approach is based on directly proving the existence of a  xed point of the best response correspondence of the underlying game.
In [27] the authors examine the problem of communication delays for two main types of heterogeneous systems: (i) systems where all the nodes have the same processing rates and capabilities but the arrival rate of local jobs at nodes may not be the same, and (ii) systems where di erent nodes may process jobs at di erent rates.
In [16] the static load balancing problem in heterogeneous distributed systems is formulated as a noncooperative game among users.
Based on the Nash equilibrium concept, the authors derive a distributed load balancing algorithm, whose performance are compared with that of other existing schemes.
The main advantages of the proposed approach are the distributed structure, low complexity and optimality of allocation for each user.
Finally, authors in [7] analyze the impact of non-cooperative users in a system of multiple parallel non-observable queues by studying the Price of Anarchy (PoA), the worst-case performance loss of the sel sh equilibrium with respect to its centralized counterpart.
Regarding Cloud computing, the use of Game Theory for the resource allocation problem is investigated in [30].
Here, the authors start from a bid proportional auction resource allocation model and propose an incomplete common information model where one bidder does not know how much the others would like to pay for the computing resource.
To this end a Bayesian learning mechanism is introduced.
In [2], the authors consider centralized and decentralized load balancing strategies in a system with multiple and heterogeneous processor sharing servers.
Each server has an associated service capacity and a holding cost per unit time.
The requests arrive as a Poisson process, and the service time of incoming jobs is assumed to be know.
For such system, the load balancing problem is investigated.
In [32] the authors propose a pricing mechanism for allocation capacity in a utility computing system among competing end-users requests.
The  xed available service capacity is allocated among the di erent  ows proportionally to their monetary bids.
The paper studies the resulting equilibrium point, establishes convergence of a best-response algorithm, and bounds the e ciency loss (PoA) of this distributed mechanism.
Di erently from our point of view, in [32] the problem of the capacity allocation is considered for a single virtualized Figure 9: Resource allocation with varying application 1 on spot maximum time unit cost.
The number of SaaS provider has been varied between 10 and 80, the number of applications (evenly shared among SaaSs) between 100 and 800.
The performance parameters of Web applications and infrastructural resources costs have been randomly generated uniformly in the ranges reported in Table 3 as in other literature approaches [1, 9, 25] and according to commercial fees applied by IaaS cloud providers [6].
sU  k mk    L k [100,1000] [1,100] req/s [-10,-1] req/s [0.03,0.24]$ [0.02,0.08]$
  k    U k [1,3] [1,10] req/s [0.08,1.24]$ [0.09,0.30]$ Exe.
Time (s) Exe.
Time (s) Table 3: Performance parameters and time unit cost ranges.
Table 4: VI algorithm average execution time and number of iterations.
Table 4 reports, for problem instances of di erent sizes, the average computational time in seconds for the algorithm reported in Figure 1 starting from the initial best reply solution (the means are computed on ten di erent runs).
The average number of iterations over the whole set of runs is around 5.
Since problems with a size comparable with real systems [28] including thousands of VM instances and hundreds of SaaS providers can be solved in the worst case in less than twenty minutes, our approach can be used to support the run time management of real cloud infrastructures.
The recent development of Cloud systems and the rapid growth of the Internet have led to a remarkable development in the use of the Game Theory tools.
Problems arising in the ICT industry, such as resource or quality of service allocation problems, pricing, and load shedding, can not be handled with classical optimization approaches.
Interaction across di erent players is non-negligible: Each player can be a ected by the actions of all players, not only her own action.
In this setting, a natural modelling framework involves we consider the infrastructure data center at a higher granularity (i.e., VMs).
We proposed a game theory based approach for the run time management of a IaaS provider capacity among multiple competing SaaSs.
The model includes infrastructural costs and revenues deriving form cloud end-users which depend on the achieved level of performance of individual requests.
Future work will validate of our solution by performing experiments in real cloud environments.
Furthermore, a comparison with the heuristic solutions adopted by SaaS and IaaS providers for the run time cloud management will be also performed.
