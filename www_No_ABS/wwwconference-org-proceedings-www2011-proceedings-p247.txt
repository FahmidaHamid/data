With the popularity of low-cost GPS chips and smart phones, geographical records have become prevalent on the Web.
A geographical record is usually denoted by a two Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
dimensional vector, latitude and longitude, representing a unique location on the Earth.
There are several popular ways to obtain geographical records on the Web:
 GPS locations when the photos were taken.
When users upload these photos on the Web, we can get the geographical records from the digital photo  les.
provide interfaces for users to specify a location on the world map.
Such a location can be treated as a geographical record in a reasonable resolution.
in their smart phones.
Popular social networking websites, including Facebook, Twitter, Foursquare and Dopplr, provide services for their users to publish such geographical information.
In the above three scenarios, GPS records are provided together with di erent documents including tags, user posts, etc.
We name those documents with GPS records as GPS-associated documents.
The amount of GPS-associated documents is increasing dramatically.
For example, Flickr hosts more than 100 million photos associated with tags and GPS locations.
The large amount of GPS-associated documents makes it possible to analyze the geographical characteristics of di erent subjects.
For example, by analyzing the geographical distribution of food and festivals, we can compare the cultural di erences around the world.
We can also explore the hot topics regarding the candidates in presidential election in di erent places.
Moreover, we can compare the popularity of speci c products in di erent regions and help make the marketing strategy.
The geographical characteristics of these topics call for e ective approaches to study the GPS-associated documents on the Web.
In recent years, some studies have been conducted on GPS-associated documents including organizing geo-tagged photos [4] and searching large geographical datasets [7].
However, none of them addressed the following two needs in analyzing GPS-associated documents.
  Discovering di erent topics of interests those are coherent in geographical regions.
Administrative divisions such as countries and states can be used as regions to discover topics.
However, we are more interested in di erent region segmentations corresponding to di erent topics.
For example, a city can be grouped into di erent sub-regions in terms of architecture or arated into regions according to landscapes like desert, beach and mountain.
Unfortunately, existing studies either overlook the di erences across geographical regions or employ country/state as the  xed con gura-tion.
  Comparing several topics across di erent geographical locations.
It is often more interesting to compare several topics than to analyze a single topic.
For example, people would like to know which products are more popular in di erent regions, and sociologists may want to know the cultural di erences across di erent areas.
With the help of GPS-associated documents, we can map topics of interests into their geographical distributions.
None of the previous work addressed this problem and we aim to develop an e ective method to compute such comparison.
In this paper, we propose three di erent models for geographical topic discovery and comparison.
First, we introduce a location-driven model, where we cluster GPS-associated documents based on their locations and make each document cluster as one topic.
The location-driven model works if there exist apparent location clusters.
Second, we introduce a text-driven model, which discovers topics based on topic modeling with regularization by spatial information.
The text-driven model can discover geographical topics if the regularizer is carefully selected.
However, it cannot get the topic distribution in di erent locations for topic comparison, since locations are only used for regularization instead of being incorporated into the generative process.
Third, considering the facts that a good geographical con guration bene ts the estimation of topics, and that a good topic model helps identify the meaningful geographical segmentation, we build a uni ed model for both topic discovery and comparison.
We propose a novel location-text joint model called LGTA (Latent Geographical Topic Analysis), which combines geographical clustering and topic modeling into one framework.
Not only can we discover the geographical topics of high quality, but also can estimate the topic distribution in di erent geographical locations for topic comparison.
The rest of the paper is organized as follows.
We formulate the problem of geographical topic discovery and comparison in Section 2.
We introduce the location-driven model in Section 3 and the text-driven model in Section 4.
In Section 5, we propose the Latent Geographical Topic Analysis model.
We compare the performance of di erent methods in Section 6.
We summarize the related work in Section 7 and conclude the paper in Section 8.
In this section, we de ne the problem of geographical topic discovery and comparison.
The notations used in this paper are listed in Table 1.
Definition 1.
A GPS-associated document is a text document associated with a GPS location.
Formally, document d contains a set of words wd, where the words are from vocabulary set V .
ld = (xd, yd) is the location of document d where xd and yd are longitude and latitude respectively.
One example of a GPS-associated document can be a set of tags for a geo-tagged photo in Flickr, where the location Table 1: Notations used in the paper.
Description Vocabulary (word set), w is a word in V Document collection A document d that consists of words and GPS location

 d wd The text of document d ld
   The GPS location of document d The topic set, z is a topic in Z The word distribution set for Z, i.e., { z}z Z is the GPS location where the photo was taken.
Another example can be a tweet in Twitter, where the location is the GPS location from the smart phone.
Definition 2.
A geographical topic is a spatially coherent meaningful theme.
In other words, the words that are often close in space are clustered in a topic.
We give two geographical topic examples as follows.
Example 1.
Given a collection of geo-tagged photos related to festival with tags and locations in Flickr, the desired geographical topics are the festivals in di erent areas, such as Cherry Blossom Festival in Washington DC and South by Southwest Festival in Austin, etc.
Example 2.
Given a collection of geo-tagged photos related to landscape with tags and locations in Flickr, the desired geographical topics are landscape categories that are spatially coherent, such as coast, desert, mountain, etc.
In this paper, we study the problem of geographical topic discovery and comparison.
Given a collection of GPS-associated documents, we would like to discover the geographical topics.
We would also like to compare the topics in di erent geographical locations.
Here we give an example of geographical topic discovery and comparison.
Example 3.
Given a collection of geo-tagged photos related to food with tags and locations in Flickr, we would like to discover the geographical topics, i.e., what people eat in di erent areas.
After we discover the food preferences, we would like to compare the food preference distributions in di erent geographical locations.
To support topic comparison in di erent locations, we de- ne the topic distribution in geographical location as follows.
Definition 3.
A topic distribution in geographical location is the conditional distribution of topics given a (cid:80) speci c location.
Formally, p(z|l) is the probability of topic z given location l = (x, y) where x is longitude and y is z Z p(z|l) = 1.
From p(z|l), we can know latitude, s.t., which topics are popular in location l.
The problem of geographical topic discovery and comparison is formulated as follows.
Given a collection of GPS-associated documents D and the number of topics K, we would like to discover K geographical topics, i.e.,   = (cid:80) { z}z Z where Z is the topic set and a geographical topic z is represented by a word distribution  z = {p(w|z)}w V w V p(w|z) = 1.
Along with the discovered geograph-s.t.
ical topics, we also would like to know the topic distribution in di erent geographical locations for topic comparison, i.e., p(z|l) for all z   Z in location l as in De nition 3.
In the next sections, we will present three di erent models for solving this problem.
(cid:80) In the location-driven model, we simply cluster the documents based on their locations.
Each document cluster corresponds to one topic.
p(z|d) is the probability of topic z given document d from the location clustering result.
We then estimate the word distribution  z for topic z by p(w|z)   d D p(w|d)p(d|z), where p(d|z) is obtained from p(z|d) by Bayes  theorem.
In Festival dataset in Example 1, after we cluster the photos according to their locations, those photos close to each other are merged into the same cluster.
And then we can generate the geographical topics (i.e., festival descriptions for each region) based on tags in each cluster.
To cluster objects in 2-D space, we can use partition-based clustering like KMeans, density-based clustering like Mean-shift [3] and DBScan [5], and mixture model based clustering.
After we get the word distribution  z for topic z   Z based on the clustering result, we would like to know the topic distribution in geographical location p(z|l) for topic comparison.
Therefore, we prefer a generative model for location clustering because we can get the estimation of p(l|z).
p(z|l) can be obtained by Bayes  theorem from p(l|z).
A popular generative model is Gaussian Mixture Model (GMM).
In GMM, we assume that each cluster is mathematically represented by a Gaussian distribution and the entire data set is modeled by a mixture of Gaussian distributions.
Although the location-driven model is straightforward, it is likely to fail if the document locations do not have good cluster patterns.
A geographical topic may be from several di erent areas and these areas may not be close to each other.
For example, in Landscape dataset in Example 2, there are no apparent location clusters; mountains exist in di erent areas and some are distant from each other.
Therefore, the location-driven model fails in Landscape dataset as shown in the experiment in Section 6.2.1.
In the text-driven model, we discover the geographical topics based on topic modeling.
To incorporate location information, we can use the idea of NetPLSA [8] to regularize topic modeling.
PLSA [6] models the probability of each co-occurrence of words and documents as a mixture of conditionally independent multinomial distributions.
NetPLSA regularizes PLSA with a harmonic regularizer based on a graph structure in the data.
In our case, the nodes of the graph are documents and the edge weights are de ned as the closeness in location between two documents.
Therefore, documents that are close in location would be assumed to have similar topic distributions.
The objective function that NetPLSA aims to minimize is as follows.
L(D) =  (1    ) c(w, d) log p(w|z)p(z|d) (cid:88) (cid:88) d D w V (cid:88) (cid:88) z Z (cid:88) z Z +  
 (u,v) E w(u, v) (p(z|du)   p(z|dv))2 (1) where c(w, d) is the count of word w in document d and w(u, v) is the closeness of document du and dv.
p(w|z) is the word distribution of topic z and p(z|d) is the topic distribution of document d.   controls the regularization strength.
With the guidance of text information, the text-driven model may discover geographical topics that are missed by the location-driven model.
However, there are still several Table 2: Notations used in LGTA framework.
Description R The region set, r is a region in R   The topic distribution set for R, i.e., { r}r R   The mean vector set for R, i.e., { r}r R   The covariance matrix set for R, i.e., { r}r R   The region importance weights problems in the text-driven model.
First, we can only get the word distribution of geographical topics  z for z   Z, but we cannot get the topic distribution of geographical locations in De nition 3, which is important for geographical topic In text-driven model we cannot know p(z|l) comparison.
because location is only used for regularization instead of being modeled in the topic generative process.
Second, it is di cult to de ne the document closeness measure used in regularization.
For example, in Food data set in Example 3, some food preferences exist only in some small regions, while some others exist throughout the continent.
It is di cult to choose the closeness measure in this case.
In this section, we propose a novel location-text joint model called LGTA (Latent Geographical Topic Analysis), which combines geographical clustering and topic modeling into one framework.
To discover geographical topics, we need a model to encode the spatial structure of words.
The words that are close in space are likely to be clustered into the same geographical topic.
In order to capture this property, we assume there are a set of regions.
The topics are generated from regions instead of documents.
If two words are close to each other in space, they are more likely to belong to the same region.
If two words are from the same region, they are more likely to be clustered into the same topic.
In Festival dataset in Example 1, the regions can be the areas in di erent cities, so the discovered geographical topics are di erent festivals.
In Landscape data set in Example 2, the regions can be different areas such as the long strips along the coast and the areas in the mountains, so the discovered geographical topics are di erent landscapes.
In Food data set in Example 3, the regions can be di erent areas that people live together, so the discovered geographical topics are di erent food preferences.
We would like to design a model that can identify these regions as well as discover the geographical topics.
In this section, we introduce our LGTA framework for geographical topic discovery and comparison.
The notations used in the framework are listed in Table 2.
We would like to discover K geographical topics.
The word distribution set of all the topics is denoted as  , i.e., { z}z Z .
Let us assume there are N regions and denote the region set as R. We assume that the geographical distribution of each region is Gaussian, parameterized as ( ,  ) = {( r,  r)}r R where  r and  r are the mean vector and co-variance matrix of region r.   is a weight distribution over all the regions.
p(r| ) indicates the weight of region r and p(ld| r,  r) = (cid:112)| r| exp(
 2   (ld    r)T  1 r (ld    r)
 ) p(r|d,  (t)) = (2) where p(wd, ld|r,  (t)) is calculated as follows.
(cid:80) r R p(r| ) = 1.
Since topics are generated from regions, we use   = { r}r R to indicate topic distributions for all the regions.
 r = {p(z|r)}z Z where p(z|r) is the probability of topic z given region r.
(cid:80) z Z p(z|r) = 1 for each r.
In our model, topics are generated from regions instead of documents and the geographical distribution of each region follows a Gaussian distribution.
The words that are close in space are more likely to belong to the same region, so they are more likely to be clustered into the same topic.
The generative procedure of the model is described as follows.
To generate a geographical document d in collection D:
 gion importance  , r   Discrete( ).
(a) Sample a topic z from multinomial  r.
(b) Sample a word w from multinomial  z.
Instead of aligning each topic with a single region, each topic in our model can be related to several regions.
Therefore, our model can handle topics with complex shapes.
Our model identi es the regions considering both location and text information.
Meanwhile, it discovers the geographical topics according to the identi ed geographical regions.
Let us denote all parameters by   = { ,  ,  ,  ,  }.
Given the data collection {(wd, ld)}d D where wd is the text of document d and ld is the location of document d, the log-likelihood of the collection given   is as follows.
L( ; D) = log p(D| ) = log p(wd, ld| ) (3) (cid:89) d D In Section 5.3, we show how to estimate all the parameters using an EM algorithm.
To compare the topics in di erent geographical locations, we need to get p(z|l) in De nition 3 for all topics z   Z given location l = (x, y) where x is longitude and y is latitude.
Given the estimated  , we  rst estimate the density of location l given topic z.
(cid:88) (cid:88) r R r R (cid:88) r R
 In order to estimate parameters   = { ,  ,  ,  ,  } in Equation 3, we use maximum likelihood estimation.
Specifically, we use Expectation Maximization(EM) algorithm to solve the problem, which iteratively computes a local maximum of likelihood.
Let us denote rd as the region of document d. We introduce the hidden variable p(r|d,  ), which is the probability of rd = r given document d and  .
In the E-step, it computes the expectation of the complete likelihood Q( | (t)), where  (t) is the value of   estimated in iteration t. In the M-step, it  nds the estimation  (t+1) that maximizes the expectation of the complete likelihood.
The derivation detail is listed in Appendix A.
In the E-step, p(r|d,  (t)) is updated according to Bayes formulas as in Equation 6.
(cid:80) p(t)(r| )p(wd, ld|r,  (t)) r(cid:48) R p(t)(r(cid:48)| )p(wd, ld|r(cid:48),  (t)) (6) p(wd, ld|r,  (t)) = p(wd|r,  (t))p(ld|r,  (t)) (7) where p(ld|r,  (t)) = p(ld| (t) r ) is de ned as Gaussian distribution in Equation 2 and p(wd|r,  (t)) is multinomial distribution for the words in document d in terms of probability p(w|r,  (t)).
r ,  (t) p(wd|r,  (t))   p(w|r,  (t))c(w,d) (8) (cid:89) w wd where c(d, w) is the count of word w in document d.
We assume that the words in each region are generated from a mixture of a background model and the region-based topic models.
The purpose of using a background model is to make the topics concentrated more on more discriminative words, which leads to more informative models [16].
p(w|r,  (t)) =  Bp(w|B) + (1    B) p(t)(w|z)p(t)(z|r) (cid:88) z Z (9) p(t)(w|z) is from  (t), and p(t)(z|r) is from  (t).
p(w|B) is the background model, which we set as follows.
(cid:80) (cid:80) (cid:80) p(w|B) = d D c(w, d) w V d D c(w, d) In the M-step, we  nd the estimation  (t+1) that maximizes the expectation of the complete likelihood Q( | (t)) using the following updating formulas.
p(t+1)(r| ) = (cid:80) d D p(r|d,  (t)) (cid:80) (cid:80) d D p(r|d,  (t))ld d D p(r|d,  (t)) (cid:80) (cid:80) d D p(r|d,  (t))(ld    (t) d D p(r|d,  (t))  (t+1)
 = r r )(ld    (t) r )T (10) (11) (12) (13) p(l|z,  ) = = (cid:80) p(l|r,  )p(r|z,  ) p(l| r,  r) p(z|r)p(r| ) p(z| ) (4) where p(z| ) = on Equation 2.
r R p(z|r)p(r| ) and p(l| r,  r) is based After we get p(l|z,  ), we can get p(z|l,  ) according to  (t+1) r = Bayes  theorem.
p(z|l,  )   p(l|z,  )p(z| )   p(l| r,  r)p(z|r)p(r| ) (5) In order to get updated  (t+1) and  (t+1) in the M-step, we use another EM algorithm to estimate them.
We de ne the hidden variable  (w, r, z), which corresponds to the events that word w in region r is from topic z.
The relevant EM updating process is as follows.
 (w, r, z)   (cid:80) (cid:80) p(z|r)   p(w|z)   (1    B)p(w|z)p(z|r) r R p(w|z)p(z|r)  Bp(w|B) + (1    B) (cid:80) (cid:80) w V c(w, d)p(r|d,  (t)) (w, r, z) (cid:80) w V c(w, d)p(r|d,  (t)) (w, r, z(cid:48)) (cid:80) d D c(w, d)p(r|d,  (t)) (w, r, z) d D c(w(cid:48), d)p(r|d,  (t)) (w(cid:48), r, z) z(cid:48) Z w(cid:48) V (14) (15) (16)   and   obtained from the above EM steps are considered as  (t+1) and  (t+1).
r r and  (t+1)
 We analyze the complexity of parameter estimation process in Section 5.3.
In the E-step, it needs O(KN|V |) to calculate p(w|r,  (t)) in Equation 9 for all (w, r) pairs, where K is the number of topics, N is the number of regions and |V | is the vocabulary size.
To calculate p(wd|r,  (t)) in Equation 8 for all (d, r) pairs, it needs O(N|W|) where |W| is the total counts of the words in all the documents.
It also needs O(|D|) to calculate p(ld|r,  (t)) for all the documents.
Therefore, the complexity of getting p(r|d,  (t)) for all (r, d) pairs is O(KN|V |+N|W|).
In the M-step, it needs O(N|D|) to get the updated p(t+1)(r| ),  (t+1) as in Equations 11, 12 and 13 for all the regions.
To get updated  (t+1) and  (t+1), it needs O(T2KN|V |) where T2 is the number of iterations for Equations 14, 15 and 16.
Therefore, the complexity of M-step is O(N|D| + T2KN|V |).
The complexity of the whole framework is O(T1(KN|V | + N|W| + N|D| + T2KN|V |)), where T1 is the number of iterations in the EM algorithm.
In our model, we have three parameters, i.e., the mixing weight of the background model  B, the number of topics K and the number of regions N .
A large  B can exclude the common words from the topics.
In this paper  B is  xed as 0.9 following the empirical studies [16, 9].
K is the desired number of geographical topics.
Users can specify the value of K according to their needs.
N is the number of the regions used in our model for generating the topics, which provides the  exility for users to adjust the granularity of regions.
The larger N is, the more  ne-grained the regions are.
For example, in Landscape dataset in Example 2, a large N is preferred, since we would like to use  ne-grained regions to handle complex shapes of di erent landscape categories.
In Festival dataset in Example 1, N is preferred to be close to K, since we would like to discover the topics in di erent areas.
In our experiment, small changes of N yield similar results.
When the parameters are unknown, Schwarz s Bayesian information criterion (BIC) provides an e cient way to select the parameters.
The BIC measure includes two parts: the log-likelihood and the model complexity.
The  rst part characterizes the  tness over the observations, while the second is determined by the number of parameters.
In practice we can train models with di erent parameters, and compare their BIC values.
The model with the lowest value will be selected as the  nal model.
We can add some guidance in the framework to make the discovered geographical topics aligned with our needs for topic comparison.
For example, in Food data set, we would like to compare the geographical distribution of Chinese food and Italian food, we can add some prior knowledge in two topics and guide one topic to be related to Chinese food and the other to be related to Italian food.
Speci cally, we de ne a conjugate prior (i.e., Dirichlet prior) on each multinomial topic distribution.
Let us denote the Dirichlet prior  z for topic z.  z(w) can be interpreted as the corresponding pseudo counts for word w when we estimate the topic distribution p(w|z).
With this conjugate prior, we can use the Maximum a Posteriori (MAP) estimator for parameter estimation, which can be computed using the same EM algorithm except that we would replace Equation 16 with the following formula: (cid:80) (cid:80) d D c(w, d)p(r|d,  (t)) (w, r, z) +  z(w) d D(c(w(cid:48), d)p(r|d,  (t)) (w(cid:48), r, z) +  z(w(cid:48))) w(cid:48) V (cid:80) p(w|z)   (17)
 In [13], Sizov proposed a novel model named GeoFolk to combine the semantics of text feature and spatial knowledge.
Sizov shows that GeoFolk works better than text-only analysis in tag recommendation, content classi cation and clustering.
However, GeoFolk is not suitable for region clustering due to two facts: First, GeoFolk models each region as an isolated topic and thus fails to  nd the common topics in di erent geographical sites.
Second, GeoFolk assumes the geographical distribution of each topic is Gaussian, which makes its results similar to the results of the location-driven model using GMM.
As a result, it would fail to discover the meaningful topics with non-Gaussian geographical distributions.
For example, in the Landscape dataset in Example 2, the coast topic is along the coastline, GeoFolk fails to discover it.
For the mountain topic, GeoFolk cannot discover it because the mountain topic is located in di erent areas.
In contrast, our LGTA model separates the concepts of topics and regions, and the coordinates are generated from regions instead of topics.
Therefore, we can discover the meaningful geographical topics properly.
We evaluate the proposed models on Flickr dataset.
We crawl the images with GPS locations through Flickr API 1.
Flickr API supports search criteria including tag, time, GPS range, etc.. We select several representative topics including Landscape, Activity, Manhattan, National Park, Festival, Car and Food.
The statistics of the datasets are listed in Table 3.
For Landscape dataset, we crawl the images containing tag landscape and keep the images containing tags mountains, mountain, beach, ocean, coast, desert around US.
For Activity data set, we crawl the images containing tags hiking and sur ng around US.
For Manhattan dataset, we crawl the images containing tag manhattan in New York City.
For National Park dataset, we crawl the images containing 1http://www. ickr.com/services/api/ # image # words













 Data set Landscape Activity Manhattan Festival National Park Car Food Time span






 tag nationalpark and keep the images with tags rockymoun-tain, yellowstone, olympic, grandcanyon, everglades, smoky-mountain, yosemite, acadia.
For Festival dataset, we crawl the images containing tag festival in New York, Los Angeles, Chicago, Washington DC, San Francisco and Austin area.
For Car data set, we crawl the images containing tags chevrolet, pontiac, cadillac, gmc, buick, audi, bmw, mer-cedesbenz,  at, peugeot, citroen, renault.
We remove the images with tags autoshow, show, race, racing and only keep car brand names in the dataset.
For Food dataset, we crawl the images containing tags cuisine, food, gourmet, restaurant, restaurants, breakfast, lunch, dinner, appetizer, entree, dessert and keep 278 related food tags including dish names and food style names.
We compare the following methods in the experiment.
  LDM: Location-driven model in Section 3.
  TDM: Text-driven model in Section 4.
We set regularization factor   as 0.5 and add one edge between two documents if their distance is within threshold  .
  varies according to di erent settings in the datasets as shown in Section 6.2.
  GeoFolk: The topic modeling method proposed in [13], which uses both text and spatial information (see Section 5.4.4).
  LGTA: Latent Geographical Topic Analysis framework in Section 5.
In this section, we compare the discovered geographical topics by di erent methods in several representative datasets.
In Landscape dataset, we intend to discover 3 topics, i.e., di erent landscapes.
We set   in TDM as 0.1( 10km), since we assume that two locations within 10km should have similar landscapes.
In LGTA, we set the number of regions N as 30, since we would like to use 10 regions in average to cover each landscape topic.
We list the topics discovered by di erent methods in Table 4, and we also plot the document locations for di erent topics on the map in Figure 1.
Since there are no apparent location clusters for the topics, LDM and GeoFolk fail to discover meaningful geographical topics due to their inappropriate assumption that each topic has a location distribution like Gaussian.
TDM performs better than LDM and GeoFolk.
Topic 1 of TDM is related to coast, but Topic 2 and Topic 3 are not distinguishable.
In LGTA, we assume that the topics are generated from a set of regions, so we can clearly identify three clusters coast, desert and mountain in Table 4.
From the LGTA topics in Figure 1, we can see that Topic 1(coast) is along the coastline, Topic 2(desert) is aligned with the desert areas in US and Topic 3(mountain) maps to the mountain areas in US.
In Activity dataset, we intend to discover 2 topics, i.e., hiking and sur ng.
We set   in TDM as 0.1( 10km), since we assume that two locations within 10km should have similar activities.
In LGTA, we set the number of regions N as 20, since we would like to use 10 regions in average to cover each activity topic.
Similar to Landscape dataset, LDM and GeoFolk fail to discover meaningful geographical topics because there are no apparent location clusters for the topics.
The result of LDM is similar to GeoFolk, while the result of TDM is similar to LGTA.
Both TDM and LGTA can identify two topics, i.e., hiking and sur ng.
We list the topics discovered by GeoFolk and LGTA in Table 5.
Table 5: Topics discovered for Activity dataset.
GeoFolk
 Topic 1 hiking 0.077 mountains 0.037 mountain 0.027 california 0.027 surfing 0.024 beach 0.023 nature 0.020 ocean 0.019 trail 0.015 hike 0.015 *[mtn] is mountain.
[nh] is newhampshire.
Topic 2 hiking 0.095 mountains 0.050 mountain 0.041 surfing 0.032 beach 0.030 [nh] 0.029 white[mtn]s 0.022 trail 0.021 ocean 0.021 nature 0.019 Topic 1(surfing) surfing 0.070 beach 0.065 california 0.059 ocean 0.053 surf 0.031 hiking 0.031 waves 0.028 water 0.025 surfer 0.022 pacific 0.018 Topic 2(hiking) hiking 0.109 mountains 0.059 mountain 0.042 nature 0.027 trail 0.019 hike 0.017 desert 0.017 washington 0.014 lake 0.013 camping 0.013
 In Manhattan dataset, we intend to discover 5 topics, i.e., di erent regions in Manhattan.
We set   in TDM as 0.001( 0.1km), since the photos in Manhattan are very dense.
In LGTA, we make the number of regions close to the number of topics, since we would like to discover large regions in Manhattan.
We set the number of regions N as
 ferent regions in Manhattan because meaningful topics can be obtained by clustering based on location, such as topic lowermanhattan and topic midtown.
Although we have the regularization based on spatial information in TDM, it can only guarantee the smoothness of topics in the neighborhood.
TDM is likely to mix the words from distant areas in the same topic.
For example, TDM mix timessquare 0.060, upperwestside 0.051, chinatown 0.033, greenwichvil- lage 0.031 and unionsquare 0.017 into one topic, and these words are distant from each other.
In Festival dataset, we intend to discover 10 topics, i.e., festivals in di erent cities.
We set   in TDM as 0.01( 1km), since 1km is a reasonable range in cities.
In LGTA, we set the number of regions N as 20.
Similar to Manhattan dataset, LDM, GeoFolk and LGTA can discover meaningful geographical topics, because the cities are distant from each other in space.
TDM is possible to mix the festivals from different areas into the same topic.
We list the topics related to southbysouthwest festival discovered by TDM, GeoFolk and LGTA in Table 6.
The result of LDM is similar to GeoFolk.
From Table 6, we can  nd that GeoFolk and LGTA discover pure topics related to southbysouthwest festival in Austin, but TDM mix southbysouthwest in Austin and atlanticantic streetfair in New York together.
In National Park dataset, we intend to discover 8 top-i.e., di erent national parks.
We set   in TDM as ics, 0.01( 1km), since 1km is a reasonable range in national park Topic 1 california ocean mountains water beach desert mountain sunset coast sea
 Topic 2 mountains desert mountain utah arizona lake snow southwest rock water Topic 3 beach ocean water mountains sea sunset mountain blue seascape lake Topic 1 ocean beach california water sea sunset seascape sand arizona blue
 Topic 2 mountains desert mountain california utah nationalpark snow rock park lake Topic 3 mountains water mountain trees coast lake reflection oregon scenery washington Topic 1 california ocean water beach mountains coast mountain sea sunset pacific GeoFolk Topic 2 desert mountains mountain california water utah arizona sunset rock snow Topic 3 beach ocean water mountains sea sunset mountain blue seascape lake Topic 1 beach ocean water california sea coast sunset seascape pacific sand
 Topic 2 desert california mountains mountain arizona utah rock southwest park sunset Topic 3 mountains mountain lake trees water snow scenery hiking washington reflection LDM(Topic 1) LDM(Topic 2) LDM(Topic 3) TDM(Topic 1) TDM(Topic 2) TDM(Topic 3) GeoFolk(Topic 1) GeoFolk(Topic 2) GeoFolk(Topic 3) LGTA(Topic 1(coast)) LGTA(Topic 2(desert)) LGTA(Topic 3(mountain)) Figure 1: The document locations of di erent topics for Landscape dataset.
Table 6: Topic southbysouthwest for Festival dataset.
sxsw 0.124 brooklyn 0.082 southbysouthwest 0.061 south 0.055 streetfestival 0.050 southwest 0.049 funfunfunfest 0.044 atlanticavenue 0.044 atlanticantic 0.041 streetfair 0.040 GeoFolk sxsw 0.173 austin 0.136 southbysouthwest 0.127 texas 0.125 south 0.121 southwest 0.103 downtown 0.093 musicfestival 0.074 live 0.034 stage 0.010
 sxsw 0.163 austin 0.149 texas 0.142 southbysouthwest 0.085 south 0.070 funfunfunfest 0.061 southwest 0.060 musicfestival 0.057 downtown 0.040 music 0.034 areas.
In LGTA, we set the number of regions N as 20.
We show that even if there are apparent location clusters, LDM and GeoFolk may obtain misleading results.
As shown in Table 7, GeoFolk merges acadia, everglades and greatsmoky-mountain together into topic acadia, because these three national parks have fewer photos than other parks and are all located on the east coast of US.
GeoFolk, similar to LDM, uses one Gaussian distribution to cover all these three parks, so the words from these parks are mixed into a single topic.
In TDM, topic acadia is mixed with rockymountain.
In LGTA, we use the  ne-grained regions to generate the topics, so all the words in LGTA are related to acadia, where mountdesertisland is home to acadia and barharbor is a town on mountdesertisland.
Table 7: Topic acadia for National park dataset.
acadia[npk] 0.088 maine 0.087 acadia 0.087 colorado 0.081 rocky[mtn][npk] 0.071 northrim 0.050 rockymountain 0.036 newengland 0.036 barharbor 0.036 rockymountains 0.034 *[mtn] is mountain.
[npk] is nationalpark.
[isl] is island.
GeoFolk acadia[npk] 0.108 maine 0.107 acadia 0.107 everglades 0.079 florida 0.058 tennessee 0.050 barharbor 0.043 newengland 0.043 greatsmoky[mtn][npk] 0.043 mountdesert[isl] 0.036
 acadia[npk] 0.208 maine 0.205 acadia 0.205 barharbor 0.084 newengland 0.084 mountdesert[isl] 0.070 beach 0.025 outdoor 0.016 flowers 0.015 wood 0.012
 In Car dataset, we intend to discover 3 topics.
We set   in TDM as 0.1( 10km), since 10km is a reasonable range in the world scale.
In LGTA, we would like to use the  ne-grained regions to discover the possible topics, so we set the number of regions N as 50.
In Car dataset, there are no apparent location clusters or good text indications.
As shown in Table 8, LDM, TDM and GeoFolk all fail to discover meaningful topics.
However, LGTA can get the interesting geographical topics.
In LGTA, Topic 1 is about American cars including chevrolet, pontiac, cadillac, gmc and buick.
Topic
 and bmw.
Topic 3 is about those European cars excluding German brands, including  at, peugeot, citroen and renault.
These interesting patterns can be discovered because these car brands in the same topic have similar geographical distributions.
With the experiments on these representative datasets, we can summarize the results as follows.
If there are apparent location cluster patterns such as Manhattan and Festival datasets, LDM and GeoFolk are able to work, so is LGTA.
If there are no apparent location clusters but good text indications in the datasets such as Landscape and Activity datasets, LDM and GeoFolk fail, TDM may work and LGTA works well.
Even if there are location cluster patterns, LDM and GeoFolk may fail, while LGTA is still robust, such as in National Park dataset.
In the di cult datasets such as Car dataset, only LGTA can discover meaningful geographical topics.
Overall, LGTA is the best and most robust method for geographical topic discovery.
In this section, we use some quantitative measures to evaluate the performances of di erent methods.
We use perplexity to evaluate the performance of topic modeling [1].
We keep 80% of the data collection as the train set and use the remaining collection as the held-out test set.
We train the models on the train set and compute the perplexity of the test set to evaluate the models.
A lower perplexity score indicates better generalization performance of the model.
Speci cally, we use text perplexity to measure the topic qualities and use location/text perplexity to measure the performance of geographical topics.
perplexitytext(Dtest) = exp{  d Dtest log p(wd) } perplexitylocation/text(Dtest) = exp{  (cid:80) (cid:80) (cid:80) Nd d Dtest d Dtest (cid:80) log p(wd, ld) } d Dtest Nd

 Topic 2 chevrolet pontiac cadillac buick gmc Topic 3 fiat renault citroen peugeot audi Topic 1 chevrolet gmc cadillac buick pontiac *If the probability of a word in a topic is less than 1e-4, output as  - .
Topic 2 renault peugeot mercedesbenz buick Topic 1 bmw chevrolet fiat citroen buick Topic 3 cadillac audi pontiac gmc buick where Dtest is the test collection and Nd is document length of document d.
We list the results of text perplexity for di erent methods in Table 9 and the results of location/text perplexity for LDM, GeoFolk and LGTA in Table 10.
TDM is not available in Table 10 because we cannot estimate the location probabilities using TDM.
From Table 9 and 10, we can see both text perplexity and location/text perplexity of LGTA are the lowest in all the datasets.
Especially, in Landscape, Activity and Car datasets, neither LDM nor GeoFolk can discover meaningful geographical topics, so the perplexities of LDM and GeoFolk in these data sets are much larger than those of LGTA.
Table 9: Text perplexity in datasets.
Data set Landscape Activity Manhattan National Park Festival Car













 GeoFolk












 Table 10: Location/text perplexity in datasets.
Data set Landscape Activity Manhattan National Park Festival Car













 GeoFolk





 In Table 11, we show the average distance of word distributions of all pairs of topics measured by KL-divergence.
The larger the average KL-divergence is, the more distinct the topics are.
In Landscape and Activity datasets, LDM and GeoFolk fail to discover meaningful topics, so the average KL-divergence of TDM and LGTA is much larger than those of LDM and GeoFolk.
In Manhattan, National Park and Festival datasets, the average KL-divergence of di er-ent methods are similar.
In Car datasets, the average KL-divergence of TDM and LGTA are much larger than LDM and GeoFolk.
Although the words from di erent topics of TDM in Car dataset are distinct, the topics are not meaningful as shown in Section 6.2.6.
Table 11: Average KL-divergence between topics in datasets.
Data set Landscape Activity Manhattan National Park Festival Car
 GeoFolk


























 In this section, we show the results of topic comparison for Car and Food datasets.
Topic 1 fiat renault citroen peugeot mercedesbenz GeoFolk Topic 2 peugeot chevrolet bmw fiat renault Topic 3 chevrolet pontiac cadillac gmc buick Topic 1 fiat renault citroen peugeot -
Topic 2 bmw audi mercedesbenz Topic 3 chevrolet pontiac cadillac gmc buick
 In Figure 2, we plot the topic distribution in di erent locations for Car dataset according to the discovered topics from LGTA in Section 6.2.6.
Compared with European cars, American cars are mainly in North America.
European excluding German cars dominate most of European areas.
German cars, as luxury brands, are popular in Germany and other areas such as East Asia and Australia.
In Food dataset, we set the number of topics K as 10.
To derive the topics that we are interested in, we set the priors according to Equation 17.
We use the words chinese, japanese, italian, french, spanish and mexican as priors for six topics and leave the remaining four topics to other possible food preferences.
We set the number of regions N as 100, since we would like to use more  nd-grained regions to discover the food preferences.
As shown in Table 12, each of the six topics consists of the typical food related to the preferences.
We plot the comparison of the topics on the maps in Figure 3.
From Figure 3, we can  nd that Chinese food is popular in China and Southeast Asia.
In US and West Europe, Chinese food also has certain popularity.
Japanese food is dominant in Japan, and it is welcome on the west coast of US.
Italian food is very popular in Mediterranean area, and it is popular in US too.
French food is popular in France and US.
Spanish food is popular in Spain, US and part of South America.
Mexican food is the main food in Mexico, and it highly in uences the Southwestern area of US.
From all these  gures, we can  nd that each food preference has its main area.
In the metropolitan areas in US, di erent kinds of food coexist.
In this section we discuss some work related to our study, including geo-tagged social media mining, topic modeling and image processing using spatial coherence.
Geo-tagged social media mining With the development of GPS technology, several studies have been done in geo-tagged social media mining.
Rattenbury et al. [11] use Scale-structure Identi cation method to extract place and event semantics for tags based on the GPS metadata of the images in Flickr.
Crandall et al. [4] combine content analysis based on text tags and image data with structural analysis based on geospatial data to estimate the photo locations.
In [7], Kennedy et al. use location, tags and visual features of the images to generate diverse and representative images for the landmarks.
All these studies are related to the interplay between tags and locations in di erent applications, but they do not touch the problem of geographical topics discussed in this paper.
Sizov [13] proposed a framework called GeoFolk to combine text and spatial information together to construct better algorithms for content management, retrieval, and sharing in social media.
To make use of spatial information, GeoFolk assumes that each topic generates latitude and longitude from two topic-speci c Gaussian European(excluding German) Car German Car Figure 2: Topic comparison for Car dataset.
For topic z, we plot p(z|l) for all the locations.
The larger p(z|l) is, the darker the location is.
We only plot the locations with p(l|z) > 1e 4.
Chinese Food chinese 0.552 noodles 0.067 dimsum 0.064 hotpot 0.039 rice 0.038 noodle 0.035 tofu 0.020 dumpling 0.018 duck 0.018 prawn 0.017 Table 12: Topic discovered for Food dataset.
Japanese Food japanese 0.519 ramen 0.104 soba 0.066 noodle 0.065 sashimi 0.039 yakitori 0.030 okonomiyaki 0.026 udon 0.026 tempura 0.020 curry 0.016 Italian Food italian 0.848 cappuccino 0.067 latte 0.048 gelato 0.030 pizza 0.002 pizzeria 0.002 mozzarella 0.001 pasta 0.001 ravioli 0.000 pesto 0.000 French Food french 0.564 bistro 0.070 patisserie 0.056 bakery 0.049 resto 0.044 pastry 0.033 tarte 0.026 croissant 0.021 baguette 0.019 mediterranean 0.018 Spanish Food spanish 0.488 tapas 0.269 paella 0.076 pescado 0.059 olives 0.032 stickyrice 0.017 tortilla 0.013 mediterranean 0.010 mussels 0.008 octopus 0.008 Mexican Food mexican 0.484 tacos 0.069 taco 0.059 salsa 0.036 cajun 0.031 burrito 0.027 crawfish 0.023 guacamole 0.022 margarita 0.020 cocktails 0.020 distributions.
However, geographical topics may not be like Gaussian distributions, such as topics  hiking  and  surfing .
In our model, we distinguish the concepts of topics and regions and provide a more systematic way to discover geographical topics and we also provide geographical topic comparison which is not available in the existing models.
Topic modeling Topic modeling is a classic problem in text mining.
The most representative models include PLSA [6] and LDA [1].
Wang et al. [15] use an LDA-style topic model to capture both the topic structure and the changes over time.
In these studies, they do not consider the location information of the documents, so they do not focus on geographical topics.
In [14], Wang et al. propose a Location Aware Topic Model to explicitly model the relationships between locations and words, where the locations are represented by prede ned location terms in the documents.
Mei et al.[9] proposed a probabilistic approach to model the subtopic themes and spatiotemporal theme patterns simultaneously in weblogs, where the locations need to be prede- ned.
However, in geographical topic discovery, we do not know the locations or regions of interest beforehand.
If we directly use the administrative region partitions, it would be di cult to discover topics whose corresponding regions are not aligned well with the pre-segmented regions.
In [8], Mei et al. proposed a model called NetPLSA to combine PLSA with a graph-based regularizer, where adjacent nodes in document similarity graph should have similar topic distribution.
We use NetPLSA in the text-driven model.
However, NetPLSA cannot provide the geographical distribution of the topics.
As shown in experiment, our LGTA model not only is more robust but also can provide interesting topic comparison results.
Spatial coherence inside images Our work is also partially motivated by the recent work in computer vision [2, 10, 12, 14] which try to simultaneously do object classi cation and segmentation in images.
However, these studies are fundamentally di erent from this paper in three aspects.
First, a spatial coherent segment is part of a image, while our geographical region contains multiple documents.
This fundamental di erence leads to di erent generative models.
Second, segmentations in one image are usually clearly separated by contours and boundaries, which makes it possible to rely on superpixels [2, 12] to merge into an object of interests.
However, there are no contours in geographical distribution.
At last, the computer vision community focus on image classi cation instead of topic comparison, while the latter is important in Web mining.
The emerging trend of GPS-associated document opens up a wide variety of novel applications.
In this paper, we introduce the problem of geographical topic discovery and comparison.
We propose and compare three strategies of modeling geographical topics including location-driven model, text-driven model, and a novel joint model called LGTA (Latent Geographical Topic Analysis) that combines both location and text information.
To test our approaches, we collect several representative datasets from Flickr website including Landscape, Activity, Manhattan, National park, Festival, Car, and Food.
Evaluation results show that the new LGTA model works well for not only  nding regions of interests but also providing e ective comparisons of di erent topics across locations.
Our work opens up several interesting future directions.
First, we can apply our models on other interesting data sources.
For example, we can mine interesting geographical topics from the tweets associated with user locations in Twitter.
Second, other than topic discovery and comparison, we would like to extend our model to other text mining tasks.
For example, we can do geographical sentiment analysis for di erent subjects.
Acknowledgement Research was sponsored in part by the U.S. National Science Foundation under grants CCF-0905014, CNS-0931975, CNS-1027965, and IIS-0713581, by the Army Research Laboratory under Cooperative Agreement Number W911NF-09-
MURI award FA9550-08-1-0265, in part by a Beckman Institute (Illinois) Seed Grant and in part by an NSF Grant IIS 1049332 EAGER.
The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the o cial policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government.
The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.
Japanese Food Italian Food French Food Spanish Food Mexican Food Figure 3: Topic comparison for Food dataset.
For topic z, we plot p(z|l) for all the locations.
The larger p(z|l) is, the darker the location is.
We only plot the locations with p(l|z) > 1e 4.
