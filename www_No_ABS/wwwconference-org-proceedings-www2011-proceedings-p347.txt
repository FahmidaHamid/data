The advancement of Web 2.0 technologies has led to the explosive growth of online opinion data, which is becoming Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
a valuable source for analyzing and understanding people s sentiments toward di erent topics.
At the same time, it also brings the urgent need for automatic sentiment analysis tools.
For this purpose, people have studied many sentiment analysis applications, such as opinion retrieval, opinion question answering, opinion mining, opinion summarization and sentiment classi cation.
Essential to most of these applications is a comprehensive and high quality sentiment lexicon.
Such a lexicon is not only necessary for sentiment analysis when no training data is available (in such a case, supervised learning would be infeasible), but is also useful for improving the e ectiveness of any supervised learning approach to sentiment analysis through providing high quality sentiment features [2].
However, there is not a general-purpose sentiment lexicon that is optimal for all domains, because it is well known that sentiments of words are sensitive to the topic domain [19].
For example,  unpredictable  is negative in the electronics domain while being positive in the movie domain.
Indeed, sentiment lexicons adapted to the particular domain or topic have been shown to improve task performance in a number of applications, including opinion retrieval [15, 9], and expression level sentiment classi cation [2].
Nevertheless, little attention has been paid to the further challenge that even in the same domain the same word may still indicate different polarities with respect to di erent aspects in context.
For example, in laptop domain,  large  is negative for the battery aspect while being positive for the screen aspect.
In this paper, we focus on the problem of constructing a sentiment lexicon that is not only domain speci c but also dependent on the aspect in context.
Here, we use context-aware, context-dependent and aspect-dependent interchangeably, all referring to the expected output of a sentiment score assigned to each aspect and opinion word combination (e.g.
BATTERY:large:-1).
In particular, we are interested in methods generally applicable to any unlabeled opinionated corpus in any topical domain, so we make no assumption of the availability of human judged labels which are usually expensive to obtain in a new domain.
Instead, we identify several sources of easy-to-collect information that are useful for determining the context-dependent sentiment of words.
To solve the challenge that multiple signals come in di erent format and may even cause contradictions, we combine them through appropriate constraints in the objective function of a novel optimization framework, in which we search for optimal assignments of sentiment scores to aspect-opinion pairs that are most consistent with all the constraints.
In this way, the optimization framework pro-struct a domain-speci c aspect-dependent sentiment lexicon by consolidating multiple evidences from di erent sources.
More speci cally, in the objective function, we combine the following four kinds of soft constraints, capturing four di erent sources of knowledge about sentiment, respectively: (1) constraints for sentiment priors which come from general-purpose sentiment lexicons, (2) constraints for overall sentiment ratings which provide the overall sentiments for all the words combined in the reviews, (3) constraints for similar sentiments which can be collected from synonyms in a thesaurus or from parsing the opinion collection with sentiment coherency assumption i.e.  and  rules as in linguistics heuristics, and (4) constraints for opposite sentiments which are from antonyms in a thesaurus or  but  rules in linguistics heuristics.
These constraints cover most of the heuristics that have been exploited in existing work for inferring domain speci c sentiments, and our method is the  rst to combine all those heuristics in a general and uni ed framework.
More importantly, our constructed sentiment lexicon is not only domain speci c but also aspect dependent.
To evaluate the e ectiveness of our proposed framework, we conduct experiments on data sets in two di erent domains: hotel reviews and customer feedback surveys on printers.
The results show that our approach can not only identify new sentiment words speci c to the given domain (e.g.
 private  is positive in hotel reviews;  compatible  is positive about printers) but also determine the di erent polarities of a word depending on the aspect in context (e.g.
 huge room  v.s.
 huge price  for hotels;  cheap ink  v.s.
 cheap appearance  for printers).
To further quantitatively evaluate the lexicon quality, we create a gold standard lexicon through human annotation, and our method is proved to be e ective in constructing a high quality aspect-dependent sentiment lexicon.
The results also demonstrate the advantage of combining multiple evidences over using any single evidence.
Moreover, since the value of sentiment lexicons mostly lies in their usefulness in applications, we also study the performance of an aspect-level sentiment classi cation task by using the automatically constructed lexicon.
The results show that using the context-dependent sentiment lexicon constructed by our optimization framework improves the sentiment classi er, compared with using baselines or a competitive method.
Sentiment analysis has attracted increasing attention recently.
Sentiment lexicon plays an important role in most, if not all, sentiment analysis applications, including opinion retrieval [17], opinion question answering and summariza-tion [3], opinion mining [21, 4] and unsupervised sentiment classi cation [7, 22, 19].
Even though supervised machine learning techniques have been shown to be e ective for sentiment classi cation task (a detailed survey can be found in [18]), authors in [2] demonstrate that including features from sentiment lexicons boosts classi cation performance signi -cantly.
However, manually creating a sentiment lexicon is a label intensive and error prone process; the coverage is also a concern.
Thus, people studied the problem of creating a sentiment lexicon in an unsupervised manner [6, 19, 11, 8,
 ment lexicon that can work well for every domain or topic, because word sentiments are well known to be domain dependent [19].
Indeed, domain adapted sentiment lexicons have been shown to improve task performance in a number of applications, including opinion retrieval [15, 9], and expression level sentiment classi cation [2].
In those automatic methods, it is usually assumed that seed words with known polarity or a general-purpose sentiment lexicon is provided, whose polarity will be propagated to the unknown sentiment polarity of other words.
Di erent heuristics as the propagation strategy have been proposed in existing work.
Some are based on linguistic heuristics in the context [6, 11].
For example, two words linked by  but like conjunctions are most likely to be in opposite polarities, while conjunctions like  and  are evidences for words in the same polarity.
Some works [16, 14] assume polarities of two words are correlated with their morphological relations and/or synonymy relations in thesaurus.
Another popular line of methods, suggested by Turney [19], is to decide the polarity of a word or phrase by comparing whether it has a greater tendency to co-occur with the word  poor  (in a context window) or with the word  excellent  as measured by point-wise mutual information.
Yet another kind of approaches exploit the association between words and expression-level or document-level sentiment [2,
 more than one heuristic (i.e.
linguistic heuristics and syn-onym/antonym rules) [4], but still in an ad-hoc rule-based manner which solves possible con icting polarities by simple majority voting.
To the best of our knowledge, there is no existing method that can combine all kinds of heuristics e ectively in a uni ed framework, which is what we attempt to do in this work.
More importantly, although existing works try to learn word polarity in a speci c domain, few of them consider the problem that even the same word in the same domain may indicate di erent polarities with respect to di erent aspects.
A few studies attempted to generate word sentiment orientation dependent on aspects (or features) often as a side-product of their sentiment analysis problems [1, 12, 20, 10], but they have not directly evaluated the quality of the generated lexicon.
Also, they all rely on a single source of information (document-level sentiment ratings or seed sentiment words), which is not su cient as demonstrated in our experiments.
We  rst de ne a general-purpose sentiment lexicon.
De nition (General-Purpose Sentiment Lexicon) A general-purpose sentiment lexicon L is a dictionary of opinion words where each word w is assigned a score representing the degree of sentiment.
Conventionally, the sentiment score L(w)   [ 1, 1]; and in many cases it is binary, i.e. either +1 (positive) or  1 (negative).
Our goal is to automatically construct a context-dependent sentiment lexicon, which can be used to supplement the general sentiment lexicon and provide more accurate context-dependent sentiment information for di erent applications, such as sentiment classi cation, opinion summarization, opinion retrieval and so on.
To construct a context-dependent sentiment lexicon, we where each aspect is de ned as follows: De nition (Aspect) An aspect Ai is a set of terms characterizing a subtopic or a theme in a given domain, which can be features of products or attributes of services.
For example, words such as  breakfast ,  restaurant , and  pizza  can characterize the aspect about food in hotel reviews.
We denote an aspect by Ai = {a; f (a) = i}, where f (a) is a mapping function from a word a to its aspect index i.
Such aspects can be obtained through domain experts manual e ort, or unsupervised automatic methods (e.g.
[10]), or automatic methods with speci ed user interests as minimal human supervision (e.g.
[13]).
It is not our focus to  nd those aspects.
Instead, assuming the availability of aspects, our problem is to automatically construct a context-dependent sentiment lexicon, de ned as follows: De nition (Context-Dependent Sentiment Lexicon) A context-dependent sentiment lexicon Lc is a dictionary of opinion words conditioned on di erent aspects of the given domain.
Each entry in Lc is a pair of aspect Ai and opinion word w, and it is assigned a score representing the positive or negative sentiment it is expressing.
Lc(Ai, w)   [ 1, 1].
Our general idea of constructing such a lexicon is to leverage many naturally available resources, which we will discuss in detail in the next section.
We do not make any assumption about the availability of human judged labels because they are usually expensive to obtain in a new topic domain.
Nevertheless, we identify several kinds of easy-to-collect information that are helpful signals in determining the context-dependent sentiments of words.
Here we summarize and categorize di erent sources of signals.
  General-purpose sentiment lexicon, which contains words that are almost always positive or negative in any domain, such as  excellent  and  bad .
This lexicon provides high con dence but low coverage sentiments.
  Overall sentiment rating, i.e. sentiment rating/score at the document level.
In many cases, each opinionated text comes with an overall sentiment rating from the user, such as in TripAdvisor1, Epinions2, and Amazon3 reviews.
Such kind of data is abundant on the Web.
For example, there are more than 40 million travel-related reviews on TripAdvisor, and millions of reviews on millions of products from Epinions.
The intuition is that the overall rating conveys some information about the sentiment expressed in the text.
For example, it is very unlikely that a user uses all negative words in the text while giving an overall rating of 5 stars.
  Thesaurus, which contains synonym and antonym information, such as WordNet4.
For example, we may not know whether  large  is positive or negative for the screen aspect 1http://www.tripadvisor.com 2http://www.epinions.com 3http://www.amazon.com 4http://wordnet.princeton.edu Figure 1: Problem Overview in laptop reviews, but we know it should be very similar to  big  and very di erent from  tiny .
Then if we have some other evidences about the polarity of  big  or  tiny , we can better infer the polarity of  large .
  Linguistic heuristics    and  rule: Clauses that are connected with  and like conjunctives usually express the same sentiment polarity.
For example,  battery lasts long and screen size is large  implies that  long  for  battery  and  large  for  screen size  are of the same polarity.
Other terms include: as well as, likewise.
   but  rule: Clauses that are connected with  but like conjunctives usually express the opposite sentiment polarity.
For example,  battery lasts long but screen size is tiny  indicates that  long  for  battery  and  tiny  for  screen size  are of the opposite polarity.
Other terms include: however, nevertheless, though, although, except that, except for, besides, with the exception of, despite, in spite of.
   negation  rule: Negation words such as  no ,  not , and  never  reverse the sentiment of the opinion word in the same clause.
For instance,  not happy  should have opposite sentiment as  happy .
These categories cover most of the heuristics used in existing works of learning domain speci c sentiment lexicon, but no previous work has combined all these sources of signals.
Since the information from any single source can be sparse, it would be helpful if we can combine the signals from multiple sources e ectively.
To this end, we propose to combine all the information from di erent signals and learn a context-dependent sentiment lexicon, as illustrated in Figure 1.
The idea is that when the signal from one source is not available or not con dent enough, we can still refer to other signals to  ll the gap.
In the next section, we propose a novel optimization framework to e ectively combine di erent kinds of signals in a uni ed way.
Due to the fact that the di erent signals come in di erent format, it is not clear how to combine them in a uni ed way.
Moreover, there can be contradictory signals from di erent sources, which we also need to deal with.
We  rst discuss how we generate all the candidate lexicon entries which form OurMthdGeneral(cid:3)Sentiment(cid:3)LexiconGeneral(cid:3)Sentiment(cid:3)Lexiconexcellent,awesome,(cid:3) bad,(cid:3)terrible,(cid:3) Synonym(cid:882)Antonym(cid:3)DictionarySynonym(cid:882)Antonym(cid:3)DictionaryScreen:(cid:3)text Battery:(cid:3)text Overall(cid:3)Rating(cid:3)+Aspect(cid:3)segmented(cid:3)TextDomain(cid:3)IndependentDomain(cid:3)Dependent(cid:3)(e.g.(cid:3)Laptop) 124Methodsmall=(cid:3)tiny(cid:3) (cid:3)big<(cid:882)>small(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3) Language(cid:3)CluesLanguage(cid:3)Clues1.(cid:3) and (cid:3)clue2.(cid:3) but (cid:3)clue3.
(cid:3) negation (cid:3)clueContext(cid:882)dependent(cid:3)Sentiment(cid:3)LexiconContext(cid:882)dependent(cid:3)Sentiment(cid:3)Lexiconbig,(cid:3)greatbig,(cid:3)greattiny,(cid:3)badtiny,(cid:3)badScreen:Screen:small,(cid:3) small,(cid:3) large,(cid:3) large,(cid:3) Battery:Battery:Context(cid:882)dependent(cid:3)Sentiment(cid:3)Lexiconbig,(cid:3)greattiny,(cid:3)badScreen:small,(cid:3) large,(cid:3) Battery: 3WWW 2011   Session: Semantic AnalysisMarch 28 April 1, 2011, Hyderabad, India349the search space for the optimization problem, and then de- ne components in the objective function to capture various constraints.
Finally, we show how we transform the proposed optimization framework into a linear programming problem which has e cient solutions and locally optimal solutions are also guaranteed to be globally optimal.
The goal of this step is to tag the text collection with aspects and extract candidate opinion words to be paired with the aspects.
After that, the pairs serve as entries in the context-dependent sentiment lexicon which are going to be assigned with polarity scores by our optimization method.
It is common to use each sentence as a tagging unit.
But it is often the case, especially in online reviews, that one sentence covers di erent aspects in several subsentences or clauses; in addition, one clause can express sentiment of di erent polarity than other clauses in the same sentence.
Thus, we choose to use clauses as units instead of sentences; this allows us to associate potential opinions words with the aspects more accurately.
We employ the Stanford Parser to do the sentence splitting and to parse sentences into syntactic tree structures.
Then we use the subtrees tagged as  simple declarative clause , as candidate clauses.
We also manually set a few rules to merge fragmental clauses into longer and more meaningful ones.
After that, we can now tag each clause s with the corresponding aspects.
Since we already have a set of de ned aspects A in the form of word clusters, we take the straightforward way that is to tag the clause with the aspects whose word cluster overlaps with the words in the clause.
Now we have the opinionated text segmented into clauses which are tagged with the corresponding aspects.
An example sentence is as follows, where two clauses are in brackets: the  rst clause is tagged with the SERVICE aspect because  check in  appears in the word cluster of SERVICE; similarly, the second clause is tagged with the FOOD aspect.
[The (check in):SERVICE is very smooth] and [the (restaurant):FOOD is the best].
Finally, the other non-aspect and nonstop words in each clause are considered potential opinion words in the context of the tagged aspects.
In the previous example, we will extract the pairs (SERVICE, very) and (SERVICE, smooth) from the  rst clause and (FOOD, best) from the second clause.
If one clause has been tagged with more than one aspect, we will pair the potential opinion words with each aspect.
It is possible to employ other aspect segmentation and tagging techniques to extract the candidate pairs, but we choose a simple and trackable approach here in order to focus on the next step of sentiment learning.
We propose to formulate this as an optimization problem.
Basically, we will be searching for a sentiment score assignment to candidate lexicon entries that optimizes the objective function.
To design the objective function, there will be constraints de ned from di erent sources of information so that the optimal solution to the objective captures the intuitions behind di erent evidences.
opinionated text data (or reviews for short) D = {d1, d2, ..., dm} in a given domain, k de ned aspects and n candidate lexicon entries extracted from the previous step, i.e. n is the Formally, suppose we are provided with a collection of m number of aspect-opinion pairs.
Our goal is to compute S, a n  1 vector, where each Sj   [ 1, 1] indicates the sentiment score of the aspect-opinion pair j in the given domain.
For convenience, let aj denote the aspect of j, wj the opinion word in pair j.
Basically, Sj is a concise representation of an entry in the context-dependent sentiment lexicon as de ned in Section 3, i.e. Sj = Lc(aj, wj).
Constraints for Sentiment Prior: Given an aspect-opinion pair j, if we do not have any clue about the polarity of word wj in the special context of aspect aj , a natural guess is wj s sentiment score in a general-purpose sentiment lexicon (if it is in there), which should give us good prior information.
Provided with a general-purpose sentiment lexicon L, we de ne two n   1 vectors G and I G: for each pair j, we set Gj = L(wj) and I G j = 1 if wj exists in L; otherwise, Gj = 0 and I G is an indicator as whether the word wj has prior sentiment score or not while Gj is the score if there is one available.
Now we introduce the  rst part of our objective function j = 0.
Basically, I G j (cid:40) n(cid:88) (cid:41) minimize j |Sj   Gj|
 (1) j=1 This component in the objective function favors a context-dependent sentiment score assignment of S that is closest to the general-purpose sentiment lexicon, i.e. G.
(cid:41) (cid:40) m(cid:88) Constraints for Overall Sentiment Ratings: Unlike the general-purpose sentiment lexicon that provides the prior sentiment information of words, overall sentiment ratings only represent the sentiment score at the document level.
Nevertheless, it is usually assumed that the overall sentiment rating are positively correlated with the sentiments of the words in the document, which has been validated in some existing work [12, 20].
We de ne O as a m   1 vector, where Oi is the overall sentiment rating of the review text di normalized to [ 1, 1].
Let f (di, S) be a sentiment prediction function that outputs a sentiment score based on the review text di and our context-dependent sentiment lexicon S. Then we want the sentiment score calculated from our lexicon to be close to the overall sentiment rating which is observed, i.e.
minimize |f (di, S)   Oi|
 i (2) i=1 where I O is again an indicator as whether Oi is de ned, i which o ers  exibility in our framework, because not all reviews have overall sentiment rating available.
Here, we choose a simple but commonly-used sentiment prediction function: averaging the sentiment scores of aspect-opinion pairs appearing in the review text based on our context-dependent sentiment lexicon.
Formally, let X bs a m   n co-occurrence matrix, where each Xi is a 1   n vector representing the unigram language model of review di in terms of aspect-opinion pairs.
In other words, Xij is the number of times that the particular pair j occurs in review di divided by the total number of pairs in review di.
We also take into account the  negation  rules here: If there are any negation words in the same clause, we replace the count of this occurrence from 1 to 1 when estimating Xij.
Then, j=1 XijSj in term (2), we have the replacing f (di, S) with(cid:80)n absolute value is implemented as follows: minimize
 i XijSj   Oi (3) minimize
 j + S   j ) (cid:40) m(cid:88) i=1 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) n(cid:88) j=1 (cid:41) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:40) n(cid:88) (cid:41) (5) (6) (7) subject to j=1 Sj = S+ j , S 
 j   S  j   0 j for j = 1       n for j = 1       n j and S Given the equality constraints on (6) (7), term (5) is es  sentially forcing at least one of S+ j to be zero.
For example, if Sj = 0.85 and given no other constraints, the   j = 0 will be favored over S+ assignment of S+ j =     j = 0.15, as the  rst assignment minimizes (S+

 j + S j ).
Now that we can represent the sign and absolute value of each Sj separately, we de ne the fourth part of the objective function as follows: j = 0.85, S (cid:40) n(cid:88) n(cid:88) (cid:0)(cid:12)(cid:12)S+ (cid:12)(cid:12) +(cid:12)(cid:12)S minimize Bjk j   S   k j   S+   k (8) j=1 k=1 Term (8) favors a solution in which if two instances Sj and Sk are connected in the opposite-sentiment matrix B, their sentiment signs are di erent but absolute values of sentiment scores are close.
Combining all the constraints de ned above, we have the following full objective function : (cid:12)(cid:12)(cid:1)(cid:41) (4)
 This term (3) is basically a linear regression formulation where we are looking for a solution for the unknown variables S by minimizing the distance between the observed values of the dependent variable O and the predicted values which are based on the independent variables X. matrix).
Constraints for Similar Sentiments: We can collect evidences about similar sentiments from di erent sources.
Consider any two aspect-opinion pairs j and k on the same aspect (i.e. aj = ak), if wj and wk appear as synonyms in the thesaurus, or if the pairs j and k are often concatenated with conjunctives like  and  in the corpus, we can infer that their sentiments tend to be similar.
To formalize this intuition, we de ne A, a n   n matrix, where Ajk   [0, 1] denotes our con dence about pairs j and k having similar sentiments.
A simple way to construct the matrix A is to set Ajk to 1 if aj = ak and either wj, wk are synonyms in the thesaurus or pairs j, k are conjuncted by  and  linguistic heuristic in the review text for a minimal number of times; while leaving the other elements as zeros.
A more sophisticated way is to use a graded con dence score in A instead of just binary.
Now we de ne the third part in the objective function: (cid:41) (cid:40) n(cid:88) n(cid:88) j=1 k=1 minimize Ajk |Sj   Sk| This term (4) requires that whenever two paris j and k are connected in the matrix A, their sentiment scores Sj and Sk should be close.
Constraints for Opposite Sentiments: Along a similar line as the previous constraints, we de ne B, a n  n matrix, where Bjk   [0, 1] represents our con dence about pairs j and k having opposite sentiments.
The value of Bjk where aj = ak is based on whether wj and wk appear as antonyms in the thesaurus, and whether the pairs j and k are concatenated with conjunctives like  but  multiple times in the corpus.
However, the constraints of opposite sentiments are more complicated than those of similar sentiments, because we want their scores to be at the two extremes, so there is the sign of the sentiment score involved.
Being opposite sentiment scores, the two scores are assumed to be in di erent signs (one positive and the other negative); at the same time, their absolute score values are assumed to be close.
j and S j and S In order to model this intuition, we separate the representation of sign and absolute value for each Sj by introducing   two additional non-negative variables S+ j .
We re  quire S+ j both to be non-negative, but at most one of them is active (i.e. positive), the other being zero.
In this way, (1) which variable being active represents the sign of Sj, i.e. S+ j being active is equivalent to Sj being positive;   j being active is equivalent to Sj being negative; and (2)
   the value of the active variable (S+ j ) represents the absolute value of Sj.
j or S This idea of separating the representation of Sj s sign and XijSj   Oi j=1 n(cid:88) m(cid:88) n(cid:88) n(cid:88) n(cid:88) n(cid:88) k=1 j=1 i=1
 i j=1 k=1 j |Sj   Gj|
 j=1 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) n(cid:88) (cid:0)(cid:12)(cid:12)S+ Bjk Ajk |Sj   Sk| j   S   k (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:12)(cid:12) +(cid:12)(cid:12)S
 j + S   j )  prior
  rating
  sim||A||1  oppo
 n(cid:88)   n j=1 + + + + (9) (10) (11) (cid:12)(cid:12)(cid:1) (12) j   S+   k (13) (14) Now the optimization problem is S = argmin   subject to: j j   S  Sj = S+ j , S  j   0
  1   Sj   1 for j = 1       n for j = 1       n for j = 1       n where  prior,  rating,  sim,  oppo are weighting parameters which should be set to the degree that we trust each source of information, and   can be set to a small value such as
 opposite-sentiment information are of equal importance, we can set  sim =  oppo.
The denominators in the form of ||M||1 represent the 1-norm of the corresponding vector or the sum of all elements absolute values.
matrix M , i.e.
eters so that their impact is comparable.
Note that, it is possible to use other loss functions in the objective function such as mean squared loss, but our speci c choice can be transformed into e cient linear programming.
To solve the optimization problem e ciently, we can transform it into an equivalent linear programing problem.
Basically, for each absolute-value term, we introduce one additional non-negative variable representing the non-negative absolute value.
For example, we introduce x1, x2, ..., xn for the  rst part of objective function in (9) and replace j |Sj   Gj| with (cid:80)n j xj and two sets of addi-(cid:80)n j=1 I G j=1 I G tional constraints: Sj   Gj   xj  Sj + Gj   xj for j = 1  n and I G for j = 1  n and I G j = 1 j = 1 The additional constraints imply that x1, x2, ..., xn are non-negative, so we do not need to explicitly list the non-negative constraints.
Similarly, we can apply similar transformation to all the other terms in the objective function and obtain a linear programming problem where the objective function, equality and inequality constraints are all linear, i.e.
n(cid:88) n(cid:88) j=1 k=1
 i yi +  sim||A||1 Ajkzij n(cid:88) j=1 Bjk(ujk + ukj) +   n
 j + S j ) }   S = argmin   = argmin {
 j xj +  prior
  rating
 m(cid:88) i=1 n(cid:88) n(cid:88) n(cid:88) j=1 j=1 k=1 +  oppo
 subject to n(cid:88)   n(cid:88) j=1 j=1 j j   S  Sj = S+ j , S  j   0
  1   Sj   1 Sj   Gj   xj  Sj + Gj   xj Xij Sj   Oi   yi Xij Sj + Oi   yi Sj   Sk   zjk  Sj + Sk   zjk j   S  k   ujk
 j + S 
 k   ujk for j = 1       n for j = 1       n for j = 1       n for j = 1       n and I G for j = 1       n and I G j = 1 j = 1 for i = 1       m and I O j = 1 for i = 1       m and I O j = 1 for j, k = 1       n and Aj,k > 0 for j, k = 1       n and Aj,k > 0 for j, k = 1       n and Bj,k > 0 for j, k = 1       n and Bj,k > 0 An important and nice theoretic property of linear programming is that the linear constraints de ne the feasible region, which is a convex polyhedron; and a linear objective function is also a convex function, which implies that every local minimum is a global minimum.
By transforming our optimization problem into an equivalent linear programming problem, we can utilize many known methods and toolkits to solve it e ciently.
Since the construction of sentiment lexicon is an o ine task, no real-time response is required.
But still, all the experiments on our data sets  nished within a few seconds.
Domain Speci c Sentiments Printer Data SOFTWARE:compatible + QUALITY:professional + Hotel Data ROOM:private + FOOD:excelent + LOCATION:farthest - ERRMSG:frequently -SUPPORT:eventually -FOOD:tiny -ACTIVITIES:inside -QUALITY:high + FACILITIES:inside + NOISE:high -INK:cheap + APPEARANCE:cheap -INK:fast + SUPPORT:fast Aspect Dependent Sentiments ROOM:huge + PRICE:huge -ACTIVITIES:cool + SERVICE:cool Table 1: Sample Results of OPT

 In this section, we present the experimental evaluation of our techniques.
Our experiments employ two data sets from very di erent domains: one is hotel reviews from Tri-pAdvisor (hotel data); the other is customer feedback survey for printers (printer data).
Following most previous works, we extract adjectives and adverbs as candidate opinion words, although our method is general enough to score candidate opinion words in any part-of-speech.
A WordNet-based lemmatizer is employed to transform each word to its original form (e.g.
 checked  to  check ).
For solving the linear programming problem, we use GAMS/CPLEX, which solves our problems within a few seconds on a machine with 2.80 GHz CPU and 2GB memory.
The default setting used in the proposed optimization framework (OPT) is  prior =  sim =  oppo =  rating.
As comparison, we also consider the following baselines for learning a context-dependent sentiment lexicon:   Random: for each aspect-opinion pair, simply predict its sentiment by random guessing, i.e. 33.33% as positive (+1), 33.33% as negative (1), and 33.33% as neutral (0).
  MPQA: for each aspect-opinion pair j, simply predict its sentiment by looking at the sentiment of the opinion word wj in the general-purpose sentiment lexicon MPQA5.
  INQ: same as the previous method, except that General Inquirer6 is used instead of MPQA.
  Global: the Global Prediction method proposed in [12].
It uses only the overall ratings to generate a context-dependent sentiment lexicon with a Naive Bayes method.
Note that, we are aware of two other methods in addition to the Global method that can output aspect-dependent sentiment scores.
But the idea in [1] is similar to the Global method; and the other method [20] has a strict requirement that each text should come with all k aspects, which is not realistic and does not hold in our data sets.
Thus, we only include the Global method here as a representative of state-of-the-art.
We  rst present some interesting sample results in the context-dependent sentiment lexicon constructed by our optimization framework.
From Table 1, we can see that
 words that are not in any general-purpose sentiment lexicon.
For example,  private  is positive in the ho-5http://www.cs.pitt.edu/mpqa/ 6http://www.wjh.harvard.edu/~inquirer/ domain.
In addition, our method can detect correct sentiment even when the spelling is wrong, e.g.
 exce-lent .
That is because we consolidate di erent statistical evidences to infer its meaning rather just looking at the matching string in the general lexicon.
di erent sentiments for the same word depending on the aspects.
For example, in hotel reviews:  huge room  conveys positive sentiment while  huge price  is not desirable.
It is negative if the activities are  inside , but it is positive if the facilities are  inside  rather than  outside .
Similarly, in the printer data,  high quality  is good but  high noise  is bad.
People are happy if the ink is  cheap , but they are not happy about the  cheap appearance .
The word  fast  has a negative connotation for  ink  (e.g.
 ink runs out fast ), but it is positive if the support service is  fast .
There is no existing data set available to evaluate the quality of a constructed context-dependent sentiment lexicon, which is in the form of a sentiment score assigned to each aspect-opinion pair.
In this section, we describe how we create a gold standard by performing human annotation on a data set of hotel reviews from TripAdvisor.
By comparing against this gold standard, we evaluate the lexicons constructed using di erent methods.
Data Description: We collected 4792 reviews about a well-known hotel brand from TripAdvisor.
Each review has an overall rating (between 1 and 5 stars) of the hotel from the user in addition to the review text.
We manually speci ed
 Facilities, Service, Value and Activities.
For example, the aspect or word cluster  LOCATION  contains words like: downtown, shuttle, metro, airport and etc.
Human Annotation: We randomly sample 750 reviews out of 4792 reviews to be labeled by 5 human judges, and each review is ensured to be labeled by 2 judges.
For each sentence with extracted candidate aspect-opinion pairs (using the method described in Section 5.1), we display the original sentence to the judges followed by the tuples in the format of  aspect:attribute:opinion .
The judges are asked to label each tuple with one of the following tags: +: if positive in the context -: if negative in the context 0: if neutral in the context N: if do not apply X: if attribute-aspect mapping is wrong Below we show an instance that the judge will see.
"within 10 mins , we were checked in and on our way to our room , which was fantastic."
SERVICE:check_in:fantastic ROOM:room:fantastic Note that, there may be ambiguities.
In the above example, judges may have their own opinions about whether  fantastic  applies to  SERVICE  or  ROOM or both.
Considering all occurrences of aspect-opinion pairs which are labeled Method Precision Recall
 Random




 Global






 F-Measure




 Table 2: Lexicon Quality Evaluation on Hotel Data with +, -, or 0, the average agreement among human annotators is 78.18% which is comparable to what had been reported in existing work of sentiment analysis [18].
Gold Standard: After collecting the labels from human judges, we  lter aspect-opinion pair occurrences to keep only the 3730 occurrences agreed by both judges.
Then we aggregate those instances into 1127 unique pairs.
To alleviate the ambiguity problem, we create our gold standard sentiment lexicon by using only the 705 aspect-opinion pairs labeled +1 or 1, which tend to represent high con dence and consistency of the labels.
This gold standard lexicon is domain speci c and aspect-dependent as well; it contains high-quality entries agreed by human annotators.
But the coverage is relatively small because we only include the high-con dent ones in the gold standard in order to be accurate.
Since the gold standard sentiment lexicon contains only binary labels (either +1 or 1 ), we  rst transform our output sentiment lexicon into the same format by only considering the sign of the predicted sentiment value, so that the assigned scores are either +1 or 1.
After that, the output sentiment lexicon can be evaluated by: precision = recall = F-measure = Nagree Nlexicon Nagree Ngold 2   precision   recall precision + recall where Ngold is the number of aspect-opinion pairs in the gold standard lexicon, Nlexicon is the number of aspect-opinion pairs in the automatically constructed sentiment lexicon (i.e. 705), Nagree is the number of pairs that are consistently labeled (either both +1 or both 1) in the gold standard and constructed lexicons.
Note that the human annotation is for evaluation purpose only, and the automatic algorithms do not use any labels.
So we run the algorithms on the whole set of 4792 reviews instead of the subset of 750 reviews labeled by human judges.
After generating candidate lexicon entries, we extract 4627 unique aspect-opinion pairs with at least two occurrences, and score them with di erent algorithms.
However, as there are only 705 pairs in the gold standard, there is some bias in the evaluation by precision.
This is because that there can be some aspect-opinion pairs correctly output by the algorithms but they do not appear in the subset of 750 reviews so human annotators did not label them.
As a result, the precision should be taken with a grain of salt here.
Take an extreme example: a naive method outputting only 100% precision but extremely low recall; but it is not use ful in practice.
Thus, F-measure should be a more reliably measure in order to evaluate the usefulness of a sentiment lexicon, because it captures the balance between precision and recall.
The results of di erent methods on hotel data are shown in Table 2 where the best performance under each measure is highlighted in bold font.
We can see that when directly evaluating the lexicon quality,   Dictionary-based baselines (i.e. MPQA and INQ) which totally ignore the context, provide best precision performance, at the price of low recall.
The recall of MPQA and INQ is signi cantly lower than other methods that take context into consideration (Global and OPT).
This suggests that there are a lot of domain speci c and aspect dependent words that carry sentiments but are totally ignored by dictionary-based baselines.
  In comparison, the Global method, gives a better balance of precision and recall and thus better F-measure.
This method is able to pick up domain speci c and context dependent sentiments by exploiting the association among aspects, words and document-level overall rating.
  Our method OPT further improves the Global method in both precision and recall signi cantly (and thus F-measure too, by almost 15%).
This is because that in addition to the overall rating OPT also incorporates the prior sentiments from dictionaries, the similar/opposite sentiment information and linguistic heuristics, which help the sentiment prediction especially when the signal from the overall ratings is not present or not strong enough to tell the sentiments of some words.
Classi cation Using the Lexicon The value of a sentiment lexicon mostly lies in its use in applications.
Thus, in addition to the evaluation of the lexicon quality, we also conduct experiments to evaluate aspect-level sentiment classi cation performance of using di erent lexicons.
The task is to produce a sentiment score for a given aspect in a piece of text, e.g.
whether a particular hotel review is talking positively or negatively about the LOCATION aspect.
From the manually annotated hotel data described in Section 6.2.1, we use the sentiments at each review-aspect level as the gold standard.
Again, in order to ensure the high con dence of the gold standard, we only consider those aspect-opinion pairs that have labels agreed by two judges.
After that, the gold standard sentiment at each review-aspect level is the averaged sentiment labels of the corresponding aspect-opinion pairs in the review, which is a real value between  1 and +1.
Data Description: For the second data set, we obtain
 survey comes with an overall satisfaction rating (between 1 and 5) and a small piece of text of detailed comments (usually just one or two sentences).
Statistics # of reviews # of possible aspects AVG # of aspects per review AVG # words per review Hotel Data Printer Data







 Table 3: Data Set Statistics for Sentiment Classi cation Task Human Annotation: The company manufacturing the printers hired people to manually label the feedback text so as to get deeper understanding about what people are happy about their printers and what they are upset about.
The human judges are provided with an aspect description  le, in which a set of aspect tags are de ned by a short description.
For example [TRIES]: The number of unsuccessful tries before install success.
[INK]: Ink and print head related issues (Including Install and Removal).
During the labeling process, the judges read each survey, tag it with the matching aspect tags, and assign a sentiment score among { 3, 2, 1, +1, +2, +3} for each aspect tag.
For instance, the review text of  Easy to set up.
digital monitoring is great for ink needs.
  is tagged as  [+3, TRIES]   and  [+3, INK] , because it is talking very positively about both the  TRIES  and the  INK  aspects.
Then we use the top 25 most frequently tagged aspects in our experiments.
Unfortunately, we do not know further details such as how many human judges are involved and what is their agreement, so we cannot report them here.
Both the hotel data and the printer data are manually labeled with di erent sentiment scores for each document-aspect combination.
This enables us to evaluate the aspect-level sentiment classi cation performance of using di erent sentiment lexicons, which represents a real application need.
Actually the classi cation results are essentially what the printer company is interested in.
If we can do accurate clas-si cation automatically, we can save companies e ort to hire people to label the aspect-level sentiment.
Some statistics about the two data sets are summarized in Table 3.
For the task of sentiment classi cation at the document-aspect level, we need to  rst use a sentiment lexicon to predict the sentiment score for each document-aspect combination.
Since we only use an unlabeled corpus, we will continue using unsupervised method for the prediction.
In particular, we adopt the following simple but reasonable baseline approach: for each document-aspect combination (di, aj),we identify all the aspect-opinion pairs on the aspect aj occurring in document di, look up the sentiment score of each pair in the context-dependent sentiment lexicon, and then take the average of sentiment scores as the predicted score for this combination (di, aj).
Now if we only consider the binary sign of the sentiment scores, we can also use precision, recall, and F-measure for evaluation.
But as the gold standard scores are real values (all normalized to [ 1, 1] by min-max normalization) rather than being binary, we also include Mean Squared Error (MSE) as an additional measure, which measures the distance between the predicted sentiment and the gold Hotel Data Random

 Global
 Printer Data Random

 Global
 Prec Recall F-Measure MSE







































 Table 4: Sentiment Classi cation Performance standard sentiment.
MSE is more an accurate measure in the sense that it captures the notion that classifying a positive class into a negative class is worse than classifying it into a neutral one.
Lower MSE means better classi cation accuracy.
We summarize the results on both data sets in Table 4 and highlighted in bold font the best performance under each measure.
In the aspect-level sentiment classi cation task, which is a real application of the constructed context-dependent sentiment lexicon,   dictionary-based baselines (MPQA and INQ) do not necessarily gives best precision.
Moreover, they su er more at recall on the printer data.
(Especially, recall of MPQA is even lower than the random baseline.)
  The Global method still performs well on both precision and recall.
  Our OPT method provides the best balance between precision and recall; it achieves the best F-measure performance on both data sets.
  Furthermore, when we zoom into the performance evaluated at  ner granularity, i.e. as measured by MSE, the performance gain of OPT is even more signi cant.
It has reduced the best MSE in the baselines from 0.4426 to 0.416, from 0.5091 to 0.468 on the two data sets respectively, both improvements are statistically signi cant with p-value less than 10 6 in a paired t-test.
All these observations suggest that a lexicon with higher precision (as shown by dictionary-based baselines in Table 2 where we directly evaluate the lexicon quality) does not necessarily lead to better aspect-level classi cation performance.
The low recall of the dictionary-based baselines would result in many misses of domain-speci c and aspect-dependent polarity words, thus lead to less accurate classi- cation of aspect-level sentiment.
Thus, it is important to achieve a good balance between precision and recall.
In particular, if one is mainly interested in aspect-level classi cation, which is one of the most important applications of sentiment lexicons, OPT is by far the best method.
Such performance advantage demonstrates the e ectiveness of combining multiple useful signals in our optimization framework.
Default Drop one term Weighting important terms  prior








  rating








  sim  oppo F-Measure


























 Table 5: OPT Parameter Tuning: Lexicon Quality on Hotel Data
 We have already shown that OPT in the default parameter setting outperforms all baselines on both lexicon quality evaluation and sentiment classi cation evaluation.
Now we further look into the four parameters  prior,  sim,  oppo,  rating that basically weight the importance of the four components in the objective function.
Our framework is very general, and if we set one parameter to zero it is equivalent to not using the signal as de ned in the corresponding term.
For the purpose of examining the importance of di erent signals, we conduct some analysis experiments where one term is dropped out in each experiment.
Lexicon Quality: The middle rows in Table 5 show the lexicon quality evaluation results of  dropping one term  tested on the hotel data.
Due to the space limit, we only display the F-measure here.
It can be seen that (1) dropping any term in the objective function decreases the lexicon quality, indicating that all the constraints are useful.
(2) when setting  prior or  rating to zero, the performance decreases dramatically (F-measure from 0.7417 to around 0.65), which suggests that these two terms contain more important information.
Then we tried to place more weights on the two important terms.
As shown in the bottom four rows, performance can be further increased, where the best one is highlighted in bold font.
Classi cation Performance: In Table 6, we also show results of parameter tuning on the sentiment classi cation task.
Similar trend is observed too, i.e. classi cation performance is improved if we put more weights on the important signals.
One thing to note is that the importance of signals is di erent in the two data sets: both the prior sentiments and the overall ratings are important in the hotel data while the overall ratings serve as the most important signal in printer data.
This series of experiments demonstrate that our optimization framework is general enough to accommodate di erent weights placed on di erent kinds of signals for constructing a context-dependent sentiment lexicon, which can lead to even better performance than the default setting.
This is especially useful when we have some reliable prior belief of the importance of signals; then we can put more weights on more important signals.
Nevertheless, there is still the challenge of automatically setting the optimal parameters for di erent domains and/or di erent data sets, which we intend to study as future work.
Drop one term Weighting important terms  prior








  rating








 Hotel Data  sim  oppo F-Measure MSE



































  prior








  rating








 Printer Data  sim  oppo F-Measure MSE



































 Table 6: OPT Parameter Tuning: Sentiment Classi cation Performance on Both Data Sets

 In this paper we studied the problem of automatically constructing a context-dependent sentiment lexicon from an unlabeled opinionated text collection.
We studied and summarized several kinds of useful signals, formulated an optimization problem to combine all the signals, and provided a mathematical transformation into linear programming.
We have demonstrated that our method can learn new domain speci c sentiment words and aspect-dependent sentiment.
Further quantitative evaluation against baselines and a state-of-the-art method shows that (1) for a given domain our framework can greatly improve the coverage of a general sentiment lexicon; (2) constructed aspect-level sentiment lexicons are in good quality, achieving a good balance of precision and recall; (3) sentiment classi cation performance can be signi cantly improved with the automatically constructed context-dependent sentiment lexicon; and (4) parameter tuning gives more performance advantage.
The framework we proposed is quite general and applicable for opinionated text collection in any domain.
It is capable of incorporating di erent sources of available information for the automatic construction of a context-aware sentiment lexicon.
As future work, we can exploit other kinds of useful signals such as  pros  and  cons  sections in the reviews and aspect-level ratings.
We also plan to evaluate the e ectiveness of our context-aware sentiment lexicon in other sentiment related applications, such as opinion retrieval and opinion summarization.
Another interesting future work is to study how to tune the weighting parameters automatically for optimal performance.
