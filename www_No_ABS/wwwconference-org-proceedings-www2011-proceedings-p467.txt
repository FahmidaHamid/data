After a period of industry consolidation, there is a resurgence of interest in content delivery networks.
Dozens new CDN companies have emerged and become a critical part of the Web infrastructure: Akamai alone claims to be delivering 20% of all Web tra c [3].
Two main  selling points  of a CDN service are (a) that they supply on-demand capacity to content providers and (b) that they improve performance of accessing the content from user perspective because they deliver the content from a nearby location.
This paper focuses on the second aspect, and considers the performance of the current Akamai   This work is supported by the National Science Foundation under Grant No.
CNS-0721890.
S. Triukose is currently with NICTA (National ICT Australia) and Z. Wen with Microsoft.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
platform and the question of how widely dispersed a CDN platform needs to be to provide proximity bene ts to the users.
Our study of platform distribution is motivated by the ongoing active discussion on the two main approaches in CDN design that have emerged over the years.
One approach, ex-empli ed by Akamai and Digital Island (currently owned by Level 3 Communications), aims at creating relatively limited-capacity points of presence at as many locations as possible.
For example, Akamai platform in 2007 spanned more than 3,000 locations in over 750 cities in over 70 countries, with each location having on average less than ten servers, and their footprint has grown further since then (see http://www.akamai.com/hdwp p.2).
The other approach utilizes massive data centers, comprising thousands of servers, but in many fewer locations.
The examples of providers pursuing this approach include Limelight and AT&T.
Limelight currently lists 20 data centers on its web site [13].
In practice, there may be complex reasons contributing to this design choice.
On one hand, Akamai attempts to obtain free deployment of its cache servers at some ISPs in return for reducing the ISPs  upstream tra c thus reducing the cost of running its platform.
On the other hand, consolidated platforms pursued by Limelight and AT&T can be more manageable and often are deployed in data centers owned rather than rented by the CDN.
Yet a large number of locations is often cited as directly translating to improved client proximity and content delivery performance.
Thus, without passing judgment on the overall merits of the two approaches, we focus on this marketing claim and address the question: how many locations is enough from the client-observed performance perspective?
Or, said differently, when does one hit the diminishing return in terms of improving client proximity by increasing the number of locations?
In fact, by considering performance implications of platform consolidation, our study addresses an important aspect of the two approaches and thus contributes to the debate regarding their overall strengths.
Note that the number of locations is orthogonal to the overall CDN capacity and hence to the CDN s ability to provide capacity-on-demand to content providers.
By provisioning enough network connectivity, power supply, and servers at a given data center, one can assemble a very large aggregate CDN capacity at relatively small number of data centers.
For example, from the statement on Limelight s website that  Each Limelight Networks Delivery Center houses thousands of servers  [13] one can infer that Limelight has at least 20,000 servers across their 20 data centers, ing two orders of magnitude fewer locations.
In terms of network capacity, Limelight had 2.5Tbps aggregate bandwidth in August 2009 [12]; while we could not  nd a similar number for Akamai, this is more than the aggregate peak tra c it has delivered [2].
One would assume that content delivery networks would have done this study themselves long time ago.
This might be true - we will never know.
However, proprietary research is not open to public (and public scrutiny) and is often driven by vested interests.
This paper attempts to answer the above question by examining Akamai performance.
We chose Akamai because it is the dominant CDN provider, both in terms of the market share and size.
Our general approach is to study how performance of Akamai-accelerated content delivery would su er if it were done from fewer data centers.
Considering performance implications of data center consolidation by the same CDN is important because it eliminates a possibility that unrelated issues in di erent CDNs could a ect the results.
An abstract of our preliminary results appeared in [24].
The current paper present the complete study.
Our work contributes insights into the following aspects of content delivery networks:   CDN performance improvement.
CDNs o er capacity on-demand, and hence overload protection, to subscribing content providers.
But do CDNs improve user experience during normal load?
Krishnamurthy et al.
[11] compared the performance of di erent CDNs, but to our knowledge ours is the  rst study that provides an independent direct estimate of the performance improvement of Akamai-accelerated downloads.
In particular, we consider both performance improvement Akamai o ers to content providers and the quality of Akamai server selection when it selects a cache for a download.
  The extent of platform distribution.
We address a question to what extent a large number of points of presence improves CDN performance.
While considering just one aspect   performance   of this issue, this contributes to the debate on the merits of the highly distributed vs. more consolidated approaches to CDN design from the customer perspective.
In addition to the above performance insights, we hope the methodology we develop to obtain them will be useful for others conducting research in this area.
A number of CDNs o er acceleration services today [19,
 decide on their infrastructure investment priorities and for their customers in selecting a CDN provider.
Several papers have studied the performance of CDNs.
Krishnamurthy et al. compared the performance of several CDNs in existence at the time of the study [11].
This study provided the  rst indication that the CDN footprint might not directly translate into performance.
Ours is a direct study of the performance implications of data center consolidation by the same CDN.
Canali et al. [5] study user-perceived performance of CDN delivery, focusing on longitudinal aspects, by monitoring Figure 1: Content Delivery Network the CDN delivery performance from three locations for two years.
Su and Kuzmanovic analyzed Akamai s streaming content delivery from the security perspective [22].
We concentrate on regular Web tra c delivery by Akamai, which is engineered di erently from streaming.
Biliris et al. considered performance implications of accelerating the same content through di erent CDNs for different users [4].
It indicated that no single CDN provided adequate coverage for all Internet users.
Coupled with our current results that Akamai would not su er performance degradation from consolidating their data centers, this would indicate (if these  ndings still hold today) that CDNs may be able to optimize their facility location.
Su et al.
[21] investigated a possibility to leverage Aka-mai s server selection for  nding high-quality overlay routes on the Internet and in the process considered various performance aspects of Akamai.
Poese et al.
[16] observed that CDN server selection could be improved through help from the clients  ISP.
These studies require the discovery of Akamai s servers; our experience in this regard should prove useful for future investigations of this kind.
A CDN is an infrastructure for e cient delivery of Web-related content to Internet users.
A CDN operator (e.g., Akamai) deploys a large number of edge servers throughout the Internet.
The content provider outsources  certain host-names to the CDN s domain name service, so that when a user clicks on an outsourced URL, the content is downloaded through a nearby edge server rather than from the content provider s site.
The basic mechanism is illustrated in Figure 1.
To accomplish the outsourcing of hostname images. rm-x.com,  rm-x s DNS server redirects DNS queries for outsourced host-names to CDN by returning a CNAME (canonical name) type response to the user, e.g.,  images. rm-x.com.CDN-name.net  (step 2 in the  gure).
The user would now have to resolve the canonical name, with a query that will arrive at the DNS system for the CDN-name.net domain, operated by the CDN (step 3).
The latter selects an appropriate edge server (typically close to the client as long as server load and network conditions allow) and responds to the query with the selected server IP address, enacting the content download from the selected server (step 5).
The edge server acts as a cache   it typically provides the content from its local storage (if it has the content from previous requests) or it autonomous system, we conservatively estimate we discovered at least 308 locations.
The real number is likely higher as the discovered edge servers represented 864 distinct /24 pre xes.
Clearly, our discovered portion of Akamai platform represents only a subset of the Akamai s servers and locations; however, as we discuss in Section 6.1, this does not impact our conclusions.
In assessing CDN s performance, our performance metric is the e ective throughput of the page download as reported by the curl tool [6]2.
To measure download performance from a particular edge server rather than the server of Aka-mai s choosing, we need connect to the desired edge server directly using its raw IP address rather than the DNS host-name from the URL.
We found that to trick an arbitrary Akamai s edge server into processing the request, it is suf- cient to simply include the HTTP host header that would have been submitted with a request using the proper DNS hostname.
For example, the following invocation will successfully download the object from a given Akamai edge server (with IP address 206.132.122.75) by supplying the expected host header through the  H  command argument: curl H Host:ak.buy.com \ "http://206.132.122.75/db_assets /large_images/093/207502093.jpg"
 Some of our experiments require forcing the HTTP requests to be ful lled from the origin server and not from the edge server cache.
Normally, requesting a cache to obtain an object from the origin server could be done by using HTTP s Cache-Control header.
However, as we will show shortly, Akamai s edge servers do not honor the Cache-Control header in client requests [23].
To manipulate the edge server to obtain the content from the origin, we exploit the following observation.
On the one hand, modern caches use the entire URL strings, including the search string (the optional portion of a URL after  ? ) as the cache key.
In particular, a request for foo.jpg?randomstring will be forwarded to the origin server because the cache is unlikely to have previously stored an object with this URL.
On the other hand, origin servers ignore unexpected search strings in otherwise valid URLs.
Thus, the above request will return the valid foo.jpg image from the origin server.
To verify this technique, we performed a series of downloads from  planetlab1.iii.u-tokyo.ac.jp  of an Amazon object  http://g-ec2.images-amazon.com/images/G/01/nav2/gam-ma/n2CoreLibs/n2CoreLibs-utilities-12475.js  using edge server
 are close to each other but likely distant from the origin server (both the client and the edge server are in Japan while the origin is likely to be in the US), we hope to be
 mercial version) to obtain server s geographical information.
GeoIP was able to map 98.13% of our discovered edge servers.
persistent accuracy problem with wget on some Planet Lab nodes.
Figure 2: A typical Google map snapshot of active DipZoom measurement points.
obtains the content from the origin site, forwards it to the client, and stores it for future use.
In fact, Akamai employs a two-level DNS system (not shown in the  gure for simplicity): the centralized high-level servers return NS-type responses to queries, redirecting them to nearby low-level DNS servers, and the latter perform the actual hostname-to-IP resolution.
The actual platform architecture involves addressing many other complex issues.
For example, Sherman et al. describe Akamai s sophisticated con guration management system [20].
This section describes the major experimental approaches we used to conduct our study.
Most CDN investigations involve the discovery of the CDN s edge servers [11, 5, 21].
The basic technique for edge server discovery is well established and involves simply identifying and resolving an outsourced hostname.
For example, nslookup on  images.amazon.com  or its canonical name  a1794.l.akamai.net  will usually return at least two IP addresses of edge servers.
The challenge, however, arises when one needs to harvest a large collection of edge servers since this requires host-name lookups resolutions from di erent geographical locations.
To avoid the complexities of gaining access to and communicating with multiple hosts, we utilized DipZoom, a peer-to-peer Internet measurement platform, for this purpose [7, 26].
DipZoom has a large number of measurement points around the world, and it allows global experiments to be implemented as local java applications, without the need to explicitly interact with the individual measurement points.
While the available DipZoom measurement points vary in time, there are typically more then 400 active MPs available, mostly on PlanetLab nodes but also on some academic and residential hosts.
As an indication of geographical coverage, Figure 2 shows a typical Google map snapshot of active DipZoom peers cropped from [7].
In our discovery process, we compiled canonical names outsourced to Akamai by downloading and examining Web page sources of the 95 Akamai customers listed on the Aka-mai s Web site.
We then periodically (twice a week) performed DNS resolution of these names from a large number of network locations over a period of 13 weeks.
As the result, we harvested just under 12, 000 Akamai edge servers, of which 10, 231 servers were pingable at the end of the discov-/foo.js?rand1 /foo.js?rand1 /foo.js?rand1 /foo.js?rand2 /foo.js?rand2 /foo.js?rand2 no-cache, /foo.js?rand2 no-cache, /foo.js?rand2 no-cache, /foo.js?rand3 Throughput

















 Throughput





 ) s /

 ( t u p h g u o r h





 ) s m (





 Trial(s) Table 1: Initial vs. repeat download performance of an object with an appended random search string.
Figure 3: Relation between download throughput and RTT.
able to distinguish download from cache vs. from the origin by the performance di erence.
Table 1 lists the throughput of the download series (the long object URL is replaced with  foo.js  for convenience).
Download 1 is a non-cache download and shows poor performance.
Downloads 2 and 3 are the downloads with the same random string; they exhibit distinctly higher performance, re ecting the fact that these requests are ful lled from the cache, which stored this URL as the result of the  rst download.
The downloads 4-6 con rm this behavior with a di erent random string.
However, downloads 7 and
 produce similarly high performance, indicating they are processed from the cache despite the no-cache directive.
Yet download 9, with the no-cache directive and a new random string, exhibits performance comparable to downloads 1 and
 the No-Cache directive of the HTTP Cache-control header in client requests does not a ect caching by Akamai.
In summary, we can precisely control the caching behavior of Akamai s edge servers by appending search strings to image URLs.
The  rst appearance of a string will cause the download to occur from the origin server while the subsequent downloads of the same string from the same edge server will occur from the edge server cache.
A series of retrievals of the same content with di erent random strings will cause the edge server to obtain the original copy every time.
Most of our experiments below involve comparing download performance from di erent Akamai locations.
A crucial question is a possible bias introduced by transparent caching potentially used by the ISPs through which our measuring points connect to the Internet.
Indeed, a cached download would then be performed from the cache regardless to which Akamai location we ostensibly direct the HTTP request.
To estimate the extent of transparent cache use by the ISPs utilized by DipZoom MPs, we consider how HTTP download performance from a given Akamai edge server depends on its ping round-trip latency.
If transparent caching is widely used, we would see no dependency.
To study these correlations, we perform a set of four curl downloads,  ve pings, and a traceroute from each measuring point to various edge servers.
For HTTP download performance, we average the download throughputs reported by the last three curls (the  rst curl ensures that the object is in the edge server cache); for ping RTT, we average the RTTs from the  ve pings.
We use an outsourced cacheable
 We used 385 measuring points and 20 widely distributed edge servers in this experiment.
To ensure that target edge servers are widely distributed across the world, we clustered all the discovered edge servers into twenty clusters based on the estimated distance between the servers (see Section 6) and selected centers of the clusters as our targets.
Figure 3 plots the values of the ping RTT and curl download throughput in each trial, sorted in the order of the increasing throughput.
(The total number of trials is less than 385   20 because not all measurements were successful.)
The  gure shows clear dependency of the download performance on ping distance.
Quantitatively, the two metrics show Spearman s rank correlation coe cient of  0.8074 indicating a strong dependency and thus no signi cant use of client-side ISP caching.
In fact, we later discovered a direct method to detect a transparent cache.
We deploy our own Web server with a cache-able object and request it twice from every measuring point.
We then examine the server  access log.
If the downloads from a given MP are  ltered through an ISP cache, the log would contain only one request from this MP (the other would be terminated by the ISP cache); otherwise the log would contain both requests.
We tested 527 measurement points (as many as we could assemble) and found only three3 with a single request in our log.
Thus, the overwhelming majority (99.43%) of MPs had no transparent caches between them and the Web servers.
While this test was conducted a few months later than the rest of our study, the two experiments described here give us a high level of con dence that client-side caching does not bias our  ndings.
In Sections 5 and 6.1, we use download performance as the  goodness metric  of a given edge server, and we express it as e ective throughput, which is the object size divided by the download time.
Given that the performance of downloads of di erent-sized objects is predominantly a ected by different network characteristics (bandwidth for large objects and RTT for small objects), we verify our main  ndings on objects of a wide size range (from 10K to 400K).
In addition, Section 6.3 uses round-trip time from the client as the goodness metric of a given server.
12.dynip.nus.edu.sg, (planetlab1.exp-math.uni-essen.de, and 147.126.95.167 (unknown hostname, Chicago).
Singapore), were (nusnet-250-
Essen), Germany,









 cache / non-cache cache / origin
 Ratio










 cache / non-cache cache / origin





 Ratio



 Figure 4: The performance bene ts of Akamai delivery.
Figure 5: The residential client performance bene- ts of Akamai delivery.
This section considers how well the existing Akamai platform ful lls its mission of accelerating content delivery.
First, we study how it a ects the end-user download performance, then consider the quality of its server selection.
In general, a content delivery network can improve Web performance in two ways: by providing overload protection to Web sites and by delivering content to users from nearby locations.
In this study, we are focusing on the latter aspect.
To answer this question precisely, one would need to compare download performance from a CDN with the direct download of the same object from the origin server.
Unfortunately, we found that the origin servers hosting Akamai-delivered content are usually hidden from the Internet users: our attempts to request this content from the origin sites that host the container pages were not successful.
Thus, we resort to two estimates of the download performance from the origin servers.
First, we estimate it by the download time of the Akamai-delivered content when we prevent caching at the edge servers.
This actually measures the Akamai cache miss performance and hence adds the miss penalty to the true value.
But it can indicate the performance of the direct download, assuming Akamai infrastructure is highly optimized.
Second, we estimate the origin server performance by the download performance of a di erent object of similar size, which is not outsourced to CDN delivery, from the same Web site.
Even if the non-outsourced object is served from a di erent server than the one used by Akamai on a miss, the performance of this download indicates the performance that the Web site can achieve without resorting to an external CDN.
We used 377 measuring points for these experiments.
For the CDN-delivered content, we use an outsourced Amazon object with size 50K, and we use the methodology in Section
 we found a non-outsourced static page4 of 55K bytes on the Amazon website.
(We assume the page is static by the fact that multiple downloads from di erent vantage points resulted in the same content.)
Obviously, the results in this subsection are strictly applicable only to Amazon, as another customer may have a di erently provisioned origin site with di erent performance.
However, they o er a speci c data point for a large, and presumably well-provisioned, content provider.
4http://72.21.206.5/gp/help/customer/display.html













 non-cache / origin



 Ratio


 Figure 6: The comparison of no-cache download through Akamai and download from origin server.
Figure 4 plots the cumulative distribution functions of the cache-to-no-cache and cache-to-origin throughput ratios in all the collected measurements.
In both cases, values over
 ery (under the corresponding estimate of the direct delivery performance) and values below 1 indicate the opposite.
The  gure indicates that a CDN promises a signi cant performance improvement under both estimates of the direct delivery performance.
CDN delivery outperforms both no-cache and origin delivery in 98% and 96% of cases respectively.
Furthermore, in 67% and 41% of the cases, the CDN delivery is at least  ve times faster than no-cache and origin delivery respectively.
A possible reason for such dramatic improvement could be because most of our measuring points are well connected to the Internet and do not experience the last mile bottleneck.
Therefore, to see the bene ts for residential clients, we reproduce, in Figure 5, the same results but only for measuring points with maximum download bandwidth less than
 suring points, the performance bene ts drop signi cantly.
CDN delivery is now at least  ve times faster that origin delivery only in 2.3% of the cases.
However, CDN delivery still improves the download performance of residential clients: the CDN delivery outperforms no-cache in 95.5% of cases and origin delivery in 91% of cases.
Finally, the gap between the two curves in both  gures indicates the Akamai global cache miss penalty, i.e., the overhead the edge servers add for a request when the requested object has to be fetched from the origin server.
We quantify this penalty in Figure 6, which plots the CDF of the no-cache-to-origin throughput ratio.
It shows that in 70% of the cases, origin downloads are faster than no-cache down-This indicates that Akamai miss penalty can be signi cant.
A potential limitation of the experiment in this subsection is that it considers performance of a single Web object and not entire page downloads.
Pages typically include multiple embedded objects, which may a ect direct and CDN-accelerated downloads di erently.
Indeed, depending on the setup of the CDN service, the browser can download the initial container HTML object directly from the origin site and the embedded objects from the CDN s edge server.
Thus, the CDN delivery could entail an extra DNS resolution (to resolve host names of embedded URLs) and an extra TCP connection establishment (to establish connections to both the origin and edge server).
However, this should not materially a ect our conclusions because these e ects are amortized over the embedded objects on a page and often over several pages in a session (if the user accesses these pages in short succession so that cached DNS responses and persistent connections remain valid between page accesses).
Aka-mai allows clients to cache DNS responses for 20 seconds (although many use them far longer [15]).
We also probed around 1000 Akamai edge servers for persistent connection support and found they maintain them for unusually long time - 500 seconds after a request (compared to Apache s default of 15s).
This provides ample opportunity for connection reuse.
When a client initiates the download to a content cached by Akamai, the best edge server for this particular client and content is selected dynamically.
This section investigates how good is the Akamai selection algorithm from the client performance perspective.
To answer this question, we selected one customer, Amazon, and measured the download throughput of an Akamai-delivered object of 50K bytes from 391 measuring points.
Out of 10, 231 edge servers we discovered, 430 servers were discovered for Amazon.
At each of the 391 measuring points, 80 edge servers are randomly selected from these 430 servers, and the object is downloaded from the Akamai-selected edge server and from each of the 80 alternative edge servers, using the methodology of Section 4.2 to download from a particular edge.
Because the entire experiment from a given measuring point takes considerable time, we always perform a pair of measurements one right after the other, one for the Akamai-selected server, and one for a given alternative edge server.
Note that the Akamai-selected server may change from one pair to the next.
Finally, we use the techniques of Section 4.3 to ensure that the edge server delivers the object from its cache in each case.
Figure 7 shows, for each measuring point, the percentage of time that the Akamai-selected server performed better than the alternative server, in the increasing order of this metric.
For example, at measuring point number 200, it shows that roughly 80% of the random 80 edge servers were outperformed by the Akamai-selected server.
The server selection was less successful for the 199 measurement points numbered lower and more successful for the the 191 measuring points numbered higher.
Overall, this experiment con rms an early limited study [9] that CDNs rarely select the best edge server but successfully avoid the worst ones.
Indeed, in roughly 75% of the MPs, the Akamai-selected server outperformed half of the alternatives.
s r e v r e
 d e m r o f r e p u
 t f o n o i t c a r














 Measuring Point Number Figure 7: The fraction of servers outperformed by the Akamai-selected server.
) s / e t y

 ( e c n e r e f f i
 t u p h g u o r h



 2 4 6 Average Difference Maximum Gain Minimum Loss


 Measuring Point Number Figure 8: Download throughput di erence between Akamai-selected and an alternative edge server Figure 7 shows how many times Akamai-selected servers perform better or worse than the alternatives but does not say by how much.
To provide this information we plot on Figure 8 the average di erence, the maximum gain, and the maximum loss of throughput of the Akamai-selected server vs. the alternatives.
The average di erence is taken over all 80 alternative servers; negative values indicate the alterna- tive servers performed better on average and positive values correspond to the advantage of the Akamai-selected server.
Maximum gain and maximum loss are the throughput di er-ences of the Akamai-selected server over, resp., the slowest and fastest alternative server.
If positive, the maximum gain shows the advantage of the Akamai-selected server over the worst alternative.
Similarly, if negative, the maximum loss shows the maximum penalty vs. the best alternative.
The  average di erence  curve shows that there are 147 measuring points where Akamai-selected server delivers on average inferior performance, by at most 255 KB/s for measuring point 1.
However, Akamai-selected servers have superior performance in average on 244 measuring points with up to 3.38 MB/s average advantage.
Interestingly, although Akamai-selected servers have superior performance on average, the  maximum loss  curve shows that, in a number of cases, the best alternative servers outperform Akamai-selected servers signi cantly, by up to 6.35 MB/s.
In summary, Akamai usually makes good server selection decisions, but there is a substantial room for further improvements.
Akamai attempts to deliver content to users from nearby servers by placing edge server in a large number of network locations.
The question we pose is: how much would it cost in performance if the number of data centers were reduced signi cantly?
We  rst describe our technique for data center consolidation, then present a study using measurements from Dip-Zoom measurement points, and conclude with a live study involving real Internet users.
Both studies show that a considerable consolidation is possible without a noticeable e ect on performance.
Our methodology for studying a hypothetical consolidated CDN is as follows.
We  rst group edge servers that we believe are close to each other into hypothetical consolidated data centers, which we refer to as big clusters.
We then  place  each big cluster into the location of a central server in the cluster called the representative of the cluster.
To this end, for a given client, we replace the server selected by Akamai, Sakam with the representative of the cluster to which Sakam belongs.
In other words, we assume that all clients that would have been sent to any server in a given big cluster in the existing platform, will be served from the cluster center in the consolidated case.
We then consider performance implications of this replacement by comparing the performance of the downloads from both servers.
We would like to stress again that our study only considers the implication of CDN consolidation on the proximity of clients to data centers: the aggregate CDN capacity, both in terms of network bandwidth and server capacity, is orthogonal to the number of data centers as fewer locations can be compensated by higher processing and connectivity capacity at each data center.
Because our probes impose trivial load on Akamai servers, the performance of our downloads re ect the proximity between servers and clients under normal load.
In fact, any server load di erences in individual server-pair comparisons should work against platform consolidation because Akamai avoids overloaded servers in its server selection while we use cluster centers regardless of their load.
To cluster edge servers, we start by estimating the pairwise network distances between all the servers using a recently proposed dynamic triangles method [25], and then group nearby servers into a prede ned number of big clusters by applying a hierarchical clustering algorithm to the resulting distance matrix.
(We use the so-called hierarchical clustering with complete linkage method, following by the cut-the-tree procedure, both provided by the R software [18] for this computation.)
We could equally use other techniques, such as network-aware clustering [10].
However, our goal is to show that we can consolidate large numbers of servers into fewer locations, and how we select servers for consolidation is immaterial as long as we  nd the performance of the consolidated platform comparable.
In other words, imperfect clustering makes our  nding conservative: Better clustering could lead to a better-constructed consolidated platform with even fewer data centers.
Similarly, a consequence of incomplete discovery of Aka-mai s platform is that we have fewer potential locations for consolidated data centers (indeed, our methodology only



























 Ratio Figure 9: The performance of a consolidated Akamai platform with di erent number of data centers.
chooses between discovered edge servers as potential consolidated locations).
This makes our  nding that signi cant consolidation is possible, again, more conservative.
In other words, the incomplete discovery does not undermine our  ndings regarding the consolidation of the locations that we did discover.
To judge the performance of the hypothetical consolidated Akamai platform, we compare the performance of downloads from the current and consolidated platforms using DipZoom measurement points.
We had 412 measurement points in this experiment.
From each measurement point, we downloaded the object of a given size from the Akamai-selected server and from the center of its cluster in the consolidated platform.
The center is represented by a randomly selected available server from the  ve closest servers to the center of the cluster5.
To avoid the bias from changing network conditions, we perform each pair of downloads in immediate succession.
Further, we pre-request each object from both servers to ensure the server is delivering the object from its cache, thus excluding the possibility of skewing results by the cache-miss penalty.
Having placed the object into the servers  cache, we perform three downloads from either server and take the average as its download performance.
We compare the performance of the existing and consolidated Akamai platforms by the ratio between the download throughput in both platforms.
The performance ratio more than 1 means Akamai s existing con guration yields better download performance than the consolidated con guration and vice versa.
We grouped the 10, 231 edge servers into 150, 100, 60, 40, and 20 data centers, thus considering the varying degree of consolidation.
To check if our conclusions might depend on the size of downloaded objects, we controlled the size of the downloads precisely by  nding a large (over 400K) object6 and specifying an appropriate  Range  header in our HTTP request.
We veri ed that Akamai servers honor range requests.
Figure 9 presents the CDF of the download throughput ratios of the existing-to-consolidated con gurations.
The  gure re ects data points obtained by downloading an out-
the centroid node to reduce an undue e ect of a single server on the entire experiment.
er.
V16565163 .swf



























 Ratio (a) 60 Data Centers























 Ratio (b) 40 Data Centers Figure 10: The performance of a consolidated Akamai platform with di erent target object size.
sourced Amazon object of size 150K, 100K, 50K, and 10K from 412 measurement points worldwide.
The curves re ect 5522 ratios (some downloads were unsuccessful).
As seen in Figure 9, consolidating edge servers into 150, 100, and 60 data centers does not cause noticeable perfor- mance degradation: the consolidated and current platforms show performance advantage over each other with equal probability.
Only when we get down to 40 and 20 data centers, does the original platform start outperforming the consolidated con guration   60% and 70% of the time for
 10 shows, these results are largely independent of the target object size.
The above experiment re ects our mix of measurement points, which are skewed towards well-connected hosts.
Because CDNs are often used by high-volume consumer-oriented sites, where users may have lower capacity connections, we consider the performance of consolidated con gurations separately for measurement points with di erent download bandwidth.
Speci cally, we group the measurement points by the maximum download throughput observed in the course of the experiment of Figure 9.
The results, shown in Figure 11, indicate that the existing Akamai con guration with large number of data centers favors well-connected users.
For measurement points with over 6Mbps bandwidth, the existing con guration outperformed consolidated con gurations once they get down to
 measurement points the less the advantage of the existing con guration.
Given this trend, and because CDNs are often used by high-volume consumer-oriented sites, a pertinent question is how the consolidation may a ect typical residential users.
Thus, we compare, in Figure 12, the performance of existing vs. consolidated con gurations for all measurement points with bandwidth below 1.5Mbps, which is a typical download bandwidth for DSL users.
Figure 12 shows that these clients would not see noticeable performance di erence if the servers were further consolidated into 40 data centers.
Overall, we conclude that one could consolidate our discovered portion of Akamai platform to 60 data centers, and for typical residential users, even to 40 data centers without noticeable performance penalty.
Even compared with our conservative approximation of 308 original data centers, this represents signi cant consolidation.
However, as we mentioned, the real number of Akamai locations represented in our study is likely higher, which makes our  ndings even more signi cant.
The study of the previous subsection measured real downloads but performed them from DipZoom measurement points.
In this section, we perform live measurement from a larger number of vantage points and from real Internet users but measure the latency between the users and the edge servers.
We built a Web page7 with an AJAX application that, when loaded, measures latency to the server that Akamai selects for this browser as well as to a list of other Akamai edge servers, and reports the results to us.
We requested a midsize commercial company to embed our special page into a zero-sized frame, and we also embedded it into our own Web pages.
As clients access these Web sites, we collect our measurement results.
We picked a CNAME (a1694.g.akamai.net, utilized by pc-world.com) which we found is mapped by Akamai to a large number   979   of edge servers.
These servers represent
 estimate them to represent 168 locations.
To compare the current con guration with consolidated con gurations, we partitioned the 979 servers into 10, 50 and 100 clusters using our clustering approach.
We selected 100 servers from the centers of the 100 clusters and measured the latency from clients to these servers from the AJAX application.
To cut down on the number of measurements, we selected representatives of larger clusters among these 100 servers as well (in our clustering, a larger cluster is built as a union of smaller clusters, so we could always  nd an appropriate server this way).
This does not undermine our results because we have a discretion where to place our consolidated data centers.
We could not  nd a way to pass a custom Host header to requests sent from Javascript, which is necessary to obtain a real object from a non-Akamai-selected edge server (Section 4.2.
Thus, we submit a bogus URL that returns  Bad Request  in all cases.
We veri ed with tcpdump that obtaining this response by the client involves two RTTs, allowing us to measure the latency between the client and the edge server involved.
We have collected 24,079 measurements from 2,926 client IP addresses by the time of this writing.
According to the GeoIP database, these vantage points cover a wide area, representing 47 US states and 43 foreign countries, and as
































 > 6.0 Mbps








 Ratio (a) 100 Data Centers




 > 6.0 Mbps








 Ratio (c) 40 Data Centers
































 > 6.0 Mbps








 Ratio (b) 60 Data Centers




 > 6.0 Mbps








 Ratio (d) 20 Data Centers Figure 11: The performance of a consolidated Akamai platform with di erent download speed.
our statistical analysis will show, are su cient to derive a meaningful result.
We consider the di erences between the measured laten-cies from each client to its closest consolidated data center and the Akamai-selected server.
A negative value indicates that the consolidated platform performed better than the existing Akamai platform in the corresponding observation, while a positive value re ects an advantage of the existing Akamai platform.
This assumes that the consolidated con guration performs perfect data center selection and thus should be viewed as an upper bound of the consolidation bene ts.
However, we note that fewer farther-apart locations make server selection easier.
To avoid using correlated measurements in the analysis, we average all the measurements from the same client, so that each client will contribute only one data point to our analysis.
Further, to remove possibly correlated measurements from the same network in the same locale, we use only one randomly selected client from all the clients with the same city and autonomous system according to GeoIP8.
This reduced the number of data points for our analysis from 2,926 to 2,029.
To assess the signi cance of the results, we build con -dence intervals for the reported means.
Because the distribution of the observations is unknown, we use the non-parametric bootstrap method to estimate the population mean and median and to build the con dence interval for the mean.
In particular, we used the bootstrap bias-corrected accelerated (BCa) interval method [16] with 10,000 resam-pling sets and relied on Matlab-provided functions that implement the core of the method.
case because we do not know if in fact these measurements are all correlated.
Table 2 summarizes the results of these measurements, with con dence intervals for the means built for con dence probability 95%.
The results show that with both 100 and 50 consolidated data centers, we could still  nd a closer data center than the Akamai-selected server for a majority of clients, and the average distance to the nearest consolidated data center across all clients is also lower.
In fact, the entire con dence interval for the mean distance di erence is negative, indicating that the above conclusion is statistically sig-ni cant, and even the upper limit of the con dence interval indicates the RTT di erence of over 40ms for 50 data centers and 70ms for 100 data centers.
Only with 10 data centers do we see a mixed result: while the entire con dence interval for the average distance di erence is still negative (indicating the distance from clients to the nearest consolidated data center still smaller on average than to the Akamai-selected server in the current platform), the median di erence indicates an advantage of the current platform, indicating that current Akamai platform would perform better for a majority of clients.
We also note that the median di erence between Akamai and consolidated platforms is much smaller than average in all con gurations.
This says that the average di erence is skewed against Akamai by occasional poor server selections, con rming a  nding from Section 5.2.
Overall, our results show that even with signi cant consolidation, better server selection can more than make up for any performance impact from consolidation.
This paper presents a large-scale performance study of the Akamai CDN.
Using DipZoom measurement platform, we were able to discover a large number of Akamai edge servers for our study, and to utilize hundreds of vantage points for our performance measurements.
To our knowl-Sample Median Sample Mean Bootstrap Median Bootstrap Mean 95% conf.
interval of the mean Best in 10
  15.66
  15.695077 [ 33.816798,  5.129345] Best in 50  5.00  54.43  5.013368  54.313225 [ 72.209521,  43.798741] Best in 100  18.40  81.53  18.260679  81.697586 [ 99.081914,  70.692385] Table 2: The di erence of RTT distance (in milliseconds) from clients to the nearest data center in a given consolidated platform and to the Akamai-selected server in the current platform (live clients).
Ratio Figure 12: The performance of a consolidated Aka-mai platform for residential speed links.
edge, ours is the  rst study to provide an independent direct estimate of the performance improvement of Akamai-accelerated downloads.
We further studied the quality of Akamai server selection at a large scale.
A central to this paper is an evaluation, from the performance perspective, of the possibility of consolidating Akamai s platform into fewer large data centers.
We found that quite signi cant consolidation is possible without appreciably degrading the platform performance.
