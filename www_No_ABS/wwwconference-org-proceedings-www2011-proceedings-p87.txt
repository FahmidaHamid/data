The Semantic Web is an ongoing e ort by the W3C Semantic Web Activity, with the purposes of actualizing data integration and sharing among di erent applications and organizations.
To date, a number of prominent ontologies have emerged for publishing data in speci c domains, such as the Friend of a Friend (FOAF), which de ne common identi ers for classes and properties, in the form of URIs, which have been widely used across data sources.
In the instance level, however, it is still far from achieving agreement among data sources on the use of common URIs to identify a speci c object [11].
In fact, due to the decentralized and dynamic nature of the Semantic Web, it frequently happens that many di erent URIs from a variety of sources, more likely originating from di erent RDF documents, denote one real-world object, i.e., represent the same identity.
Such examples exist in the domains of personal pro les, academic publications, encyclopedic or geographical resources, etc.
Object coreference resolution, also known as object consolidation or identi cation [1], is a task for identifying multiple URIs for the same real-world object, i.e.,  nding coreferent URIs which represent a unique identity.
Object coreference resolution is important for data-centric applications, such as fusing distributed descriptions of equivalent RDF resources in data integration systems.
Driven by the Linking Open Data (LOD) initiative, millions of URIs from independent data sources have been explicitly interlinked with owl:sameAs statements [3].
However, considering billions of object URIs on the current Semantic Web, we observe that there still exist a large amount of URIs which implicitly represent the same objects but have not been connected with owl:sameAs yet.
For example, at least 70 URIs returned by Falcons search engine [2] denote a person  Tim Berners-Lee , the director of W3C, but only  ve of them are linked with owl:sameAs.
In the  eld of Semantic Web, recent studies address this problem mainly from two directions: one is based on utilizing standard OWL semantics, such as owl:sameAs [8] and inverse functional properties (IFPs) [11]; while the other is according to the intuition that two URIs represent the same real-world object if they share some similar property-value pairs [7, 13].
Generally speaking, the semantics-based way can infer explicitly coreferent URIs but probably misses a lot of potential candidates, while the similarity-based way is not always accurate due to heterogenous ways for expressing the same thing.
Hence, a key issue for resolving object coref-classes of techniques for building bridges between coreferent URIs that we already have and potential candidates?
In this paper, we propose a self-training approach to leveraging the semantics-based and similarity-based ways for addressing the problem of object coreference resolution on the Semantic Web.
Self-training is a well-known class of semi-supervised learning algorithms, in which a learner continues labeling unlabeled examples and retraining itself on an extended labeled training set [28].
Self-training is suitable for solving our problem, because there are abundant unresolved object URIs, but the number of existing semantically coref-erent ones is limited.
Speci cally, taking an object URI as input, we  rstly establish a kernel that consists of a set of semantically coref-erent URIs based on owl:sameAs, (inverse) functional properties and (max-)cardinalities, and then iteratively extend the kernel in terms of discriminative property-value pairs in the descriptions of URIs.
The discriminability of a property-value pair is learnt based on a statistical measurement, which not only exploits the key characteristics for representing an object, but also takes into account the matchability between properties from pragmatics.
Furthermore, frequent property combinations are mined to enhance the selection criteria of properties during each iteration, so that the accuracy of the resolution is further improved.
We develop a scalable system and evaluate its performance on a benchmark dataset from OAEI 2010 and a large-scale dataset that is collected by Falcons search engine in 2008.
The experimental results demonstrate that our approach achieves acceptable F-Measure on both datasets, as compared with the performance of six representative competitors.
The remainder of this paper is structured as follows.
The self-training framework of our proposed approach is  rstly outlined in Section 2.
Section 3 introduces a method to  nd semantically coreferent URIs in terms of OWL semantics.
Section 4 describes our self-training algorithm for resolving object coreference with a statistical measurement to calculate the discriminability of a property-value pair.
Section 5 presents a way to mine frequent property combinations for improving the accuracy of the resolution.
Experimental results on the benchmark and large-scale datasets are reported in Section 6.
Section 7 discusses related work and  nally Section 8 concludes this paper with future work.
The architecture of our proposed approach is outlined in Fig. 1, which starts with an object URI u.
After three processing stages, the approach returns a set of coreferent URIs that denote the same object as u.
cally coreferent URIs for u based on the OWL semantics of owl:sameAs, owl:InverseFunctionalProperty (owl:IFP for short), owl:FunctionalProperty (abbr.
owl:FP), owl:cardinality and owl:maxCardinality.
The  ve builtin vocabulary elements in OWL are frequently used to infer the equivalence relation in many systems [19], and combining them together establishes a larger initial labeled training set.
is an iterative process, which  rstly learns discrimina-tive property-value pairs from some labeled coreferent (cid:21) (cid:74) (cid:81) (cid:76) (cid:81) (cid:76) (cid:68) (cid:85) (cid:87) (cid:16) (cid:73) (cid:79) (cid:72) (cid:54) (cid:56)(cid:81)(cid:79)(cid:68)(cid:69)(cid:72)(cid:79)(cid:72)(cid:71)(cid:3)(cid:56)(cid:53)(cid:44)(cid:86) (cid:40)(cid:91)(cid:87)(cid:72)(cid:85)(cid:81)(cid:68)(cid:79)(cid:3)(cid:78)(cid:81)(cid:82)(cid:90)(cid:79)(cid:72)(cid:71)(cid:74)(cid:72) (cid:22) (cid:47)(cid:72)(cid:68)(cid:85)(cid:81)(cid:76)(cid:81)(cid:74)(cid:3)(cid:71)(cid:76)(cid:86)(cid:70)(cid:85)(cid:76)(cid:80)(cid:76)(cid:81)(cid:68)(cid:87)(cid:76)(cid:89)(cid:72)(cid:3) (cid:83)(cid:85)(cid:82)(cid:83)(cid:72)(cid:85)(cid:87)(cid:92)(cid:16)(cid:89)(cid:68)(cid:79)(cid:88)(cid:72)(cid:3)(cid:83)(cid:68)(cid:76)(cid:85)(cid:86) (cid:41)(cid:85)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:87)(cid:3) (cid:83)(cid:85)(cid:82)(cid:83)(cid:72)(cid:85)(cid:87)(cid:92)(cid:3) (cid:70)(cid:82)(cid:80)(cid:69)(cid:76)(cid:81)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86) (cid:47)(cid:68)(cid:69)(cid:72)(cid:79)(cid:72)(cid:71)(cid:3)(cid:56)(cid:53)(cid:44)(cid:86) (cid:11)(cid:38)(cid:82)(cid:85)(cid:72)(cid:73)(cid:72)(cid:85)(cid:72)(cid:81)(cid:87)(cid:3)(cid:56)(cid:53)(cid:44)(cid:86)(cid:12) (cid:20) (cid:37)(cid:88)(cid:76)(cid:79)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:68)(cid:3)(cid:78)(cid:72)(cid:85)(cid:81)(cid:72)(cid:79) (cid:11)(cid:44)(cid:81)(cid:76)(cid:87)(cid:76)(cid:68)(cid:79)(cid:76)(cid:93)(cid:76)(cid:81)(cid:74)(cid:3)(cid:87)(cid:85)(cid:68)(cid:76)(cid:81)(cid:76)(cid:81)(cid:74)(cid:3)(cid:86)(cid:72)(cid:87)(cid:12) (cid:36)(cid:3)(cid:56)(cid:53)(cid:44) Figure 1: Overview of the proposed approach URIs, and then uses the pairs to  nd more coreferent ones.
In accordance with previous works in [10, 13, 17], we assume that coreferent URIs share several common property-value pairs, and certain property-value pairs are more useful for coreference resolution.
For any two URIs, we extract their involved property-
and com-value pairs from the dereference documents, pare these values with a string matching algorithm I-Sub [22].
If the similarity between two values is larger than a threshold, then the related two properties have a kind of commonality.
For a set of coreferent URIs, we select a property pair sharing most matchable values, and assign the most common value to each property in this pair.
These two property-value pairs re ect some discriminative characteristics for their denoted object, and they are used to  nd more coreferent URIs.
ty combinations.
Some properties are more suitable to use together for describing an object, such as longitude and latitude for a coordinate.
If we only choose either of them for identifying coreferent URIs, the results tend to be inaccurate.
Therefore, we apply association rule mining to discover frequent property combinations with heuristic re nement.
For each learning iteration, if any property in a frequent property combination is chosen, the rest property in the combination with its most common value (if existing in the training set) would be complemented.
Consequently, these two properties with associated values are used together for searching new coreferent URIs.
Example 1.
For illustration purposes, let us consider four RDF documents containing candidate URIs for coreference resolution in Fig. 2.
Assuming that dbpedia:Beijing is the input object URI for resolution.
Through searching for owl: sameAs statements, dbpedia:Beijing is semantically coref-erent with geo:1816670.
During training, (rdfs:label,  Beijing ) and (geo:alternateName,  Beijing ) are learnt in the  rst iteration as the most discriminative property-value pairs.
As a result, semweb:Beijing is found.
In the second round, (wgs84_pos:lat,  40 ) is the most discriminative pair, and a wrong coreferent result ex:New_York is discovered.
But considering the frequent property combination {wgs84_pos:lat, wgs84_pos:long}, ex:New_York would not be included any more, because the values of wgs84_pos:long are completely di erent ( 116  for Beijing, while  74  for New York).
The act of retrieving a representation of a resource identi- ed by a URI is referred to as dereferencing that URI [15].
rdfs:label owl:sameAs  Beijing ; geo:1816670.
geo:1816670 semweb:Beijing wgs84_pos:long wgs84_pos:lat geo:alternateName geo:alternateName  116 ;  40 ;  Beijing ;  Peking .
rdfs:label wgs84_pos:lat wgs84_pos:long  Beijing ;  40 ;  116 .
ex:New_York wgs84_pos:long wgs84_pos:lat  74 ;  40 .
Figure 2: An illustrating example

 Let U be a set of URI references (URIrefs), B be a set of blank node IDs and L be a set of literals.
A triple (cid:2)s, p, o(cid:3)   (U   B)  U   (U   B   L) is called anRDF triple .
An RDF graph G is just a set of RDF triples.
The semantics of owl:sameAs indicates that all the URIs linked with this property, in the form of (cid:2)s, owl:sameAs, o(cid:3), have the same identity, implying that the subject and object should be the same resource.
De nition 1.
(The Same-as Relation) Let U be a set of URIs.
The same-as relation, denoted by S, is de ned as the minimal re exive, symmetric relation on U , satisfying that: (1)  s   U , (cid:2)s, s(cid:3)   S; (2) For s, o   U , if there exists a triple (cid:2)s, owl:sameAs, o(cid:3), then(cid:2)s, o(cid:3)   S and (cid:2)o, s(cid:3)  S .
The semantics of an IFP guarantees that a value can only be the value of this property for a single object, that is, two separate objects are indirectly inferred to be identical based on having the same value of that property.
To identify IFPs, we parse ontologies to  nd the properties whose rdf:type is explicitly de ned as owl:IFP.
This is done at the preprocessing time.
Note that IFPs can be inferred in a multitude of ways based on OWL semantics.
For example, the study in [25] did reasoning over pD* that includes rules for handling owl:sameAs, owl:IFP and owl:FP axioms.
But anyone can de ne anything on the Semantic Web, inferring IFPs across di erent sources may cause errors and inconsistency.
As an example, we could infer dc:title as an IFP in the Falcons dataset.
The work in [12] studied the reasoning problem of new ontologies published on the Web rede ning the semantics of existing entities resident in other ontologies (called ontology hijacking), which enlightens us to only use dereferenceable IFPs in our approach for avoiding ontology hijacking.
De nition 2.
(The IFP Relation) Let U be a set of URIs.
The IFP relation, denoted by I, is de ned to be the minimal re exive, symmetric relation on U , which satis es the following conditions: (1)  s   U , (cid:2)s, s(cid:3)  I ; (2) For s1, s2   U , if there are an IFP p and two triples (cid:2)s1, p, o(cid:3), (cid:2)s2, p, o(cid:3), then (cid:2)s1, s2(cid:3)  I and (cid:2)s2, s1(cid:3)   I.
To  nd the IFP relations, we match the values of objects in the RDF triples with same IFPs as the predicates.
If the values are exactly the same by using a trivial string comparison algorithm, we bridge an IFP relation between the subjects of these triples.
This approach has been demonstrated to be feasible in [11, 24].
Besides, the lexical forms of some literals can be empty, e.g., the values of foaf:mbox_sha1sum are blank in a few triples.
We omit these triples for avoiding wrong coreference.
Due to several heterogenous ways for expressing email addresses, we use an ad hoc method to identify identical email addresses for two popular IFPs: foaf:mbox and foaf:mbox_ sha1sum.
Given an email address, we compute its sha1sum value and utilize foaf:mbox_sha1sum to  nd new coreferent URIs.
We bridge the IFP relations between the URIs using the two IFPs.
The way of using functional properties (FPs) to  nd coref-erent URIs is similar to the way for IFPs.
We  rstly obtain the dereferenceable properties whose types are explicitly de- ned as owl:FP, and then use these FPs to construct the FP relations.
De nition 3.
(The FP Relation) Let U be a set of URIs.
The FP relation, denoted by F, is de ned to be the minimal re exive, symmetric relation on U , which satis es: (1)  o   U , (cid:2)o, o(cid:3)   F; (2) For o1, o2   U , if there are a FP p and two triples (cid:2)s, p, o1(cid:3), (cid:2)s, p, o2(cid:3), then (cid:2)o1, o2(cid:3)   F and (cid:2)o2, o1(cid:3)   F.
The cardinality constraint owl:cardinality (or owl:max-Cardinality) is a builtin OWL property which links a restriction class to a data value.
A restriction having an owl: cardinality (or owl:maxCardinality) constraint describes a class of all objects that have exactly (at most) N semantically distinct values for the property concerned, where N is the value of the cardinality constraint.
If N = 1, its semantics is similar to FPs (however, with respect to a particular class) and can be applied to produce coreferent URIs.
De nition 4.
(The Cardinality Relation) Let U be a set of URIs.
The cardinality relation, denoted by C, is de ned as the minimal re exive, symmetric relation on U , which satis- es that: (1)  o   U , (cid:2)o, o(cid:3)   C; (2) For o1, o2   U , if there exist a (max-)cardinality restriction (cid:2)c, owl:onProperty, p(cid:3), (cid:2)c, owl:cardinality,  1 (cid:3) (or (cid:2)c, owl:maxCardinality,  1 (cid:3)), where c, p are the restriction class and property respectively, and three triples (cid:2)s, p, o1(cid:3), (cid:2)s, p, o2(cid:3) and (cid:2)s, rdf:type, c(cid:3), then (cid:2)o1, o2(cid:3)   C and (cid:2)o2, o1(cid:3)   C.
Based on the same-as, IFP, FP and cardinality relations, we de ne the equivalence relation as follows.
De nition 5.
(The Equivalence Relation) Let S, I, F, C be the same-as, IFP, FP and cardinality relations on a set of URIs U , respectively.
K is the transitive closure on S   I  
 It is worth noting that K is an equivalence relation on U , because S, I, F, C are all re exive and symmetric.
De nition 6.
(Kernel) Let U be a set of URIs.
For a URI u   U , the equivalence class [u]K = {v   U | (cid:2)u, v(cid:3)   K}, under the equivalence relation K, is called a kernel of u.
Based on the de nition of the kernel above, it is straightforward to implement a corresponding algorithm for  nding semantically coreferent URIs.
For an RDF graph G, we de ne three operations on G for simplifying our notations: Subj(G) = {s | (cid:2)s, p, o(cid:3)   G}, Pred(G, sk) = {p | (cid:2)sk, p, o(cid:3)  G }, Obj(G, sk, pi) = {o | (cid:2)sk, pi, o(cid:3)   G}.
(1) (2) (3) Our object coreference resolution algorithm is depicted in Algorithm 1, which follows a traditional self-training framework [28].
Inputting a labeled kernel C for an object URI u and a set H of unlabeled URIs, the goal of the algorithm is to iteratively learn the most discriminative property-value pairs for identifying potentially coreferent URIs in H. In the case that there are too many coreferent URIs in C, the algorithm randomly picks up a subset D of C for reducing the computational costs.
We choose |D| = 200 in terms of the computational capability of our personal computers.
The algorithm stops when the iteration times exceeds a maximum number K or all the property pairs have been checked.
Algorithm 1: A coreference resolution algorithm Input: A kernel C for an object URIu in an RDF graph G, and a set H of unlabeled URIs in G.
Output: An extension E, after self-training.
1 begin



 Initialize two empty checked lists P P and P V ; Copy C to E for training; repeat




















 27 end Create a pool D by randomly choosing at most N URIs in E; Select the most matchable property pair (pi, pj) /  P P by Eq.
(4), s.t.
pi   (cid:2) Pred(G, s), pj   (cid:2) t D s D t(cid:3)=s Pred(G, t); if (pi, pj) = N U LL then break; Assign the most common values oi, oj to pi, pj resp.
by Eq.
(6), s.t.
(pi, oi) or (pj, oj) /  P V , oi   (cid:2) Obj(G, t, pj); s D if oi = N U LL and oj = N U LL then Obj(G, s, pi), oj   (cid:2) t D Push (pi, pj) into P P , and go back to Line 6; end if oi (cid:7)= N U LL then Apply (pi, oi) to label a set P of unlabeled URIs, s.t.
P = {s   H | (cid:2)s, pi, oi(cid:3)  G }; if (pi, oi) is discriminative by Eq.
(7) then Add P to E, and remove P from H; end end if oj (cid:7)= N U LL then Apply (pj, oj) to label a set Q of unlabeled URIs, s.t.
Q = {s   H | (cid:2)s, pj, oj(cid:3)   G}; if (pj, oj) is discriminative by Eq.
(7) then Add Q to E, and remove Q from H; end end Push (pi, oi), (pj, oj) into P V ; until iteration times > K; return E; Similar to most self-training algorithms, there exist three key measures/parameters that should be discussed: (1) How to measure the discriminability of a property-value pair?
(2) How to avoid error accumulation during resolution?
and (3) How to determine the maximum iteration times?
We answer these questions in the rest of this section.
We propose a three-step way to measure the discriminabil-ity of each property-value pair.
The intuition behind is that, the more a property-value pair is shared by a set of corefer-ent URIs, the more likely it represents some discriminative characteristics for the denoted real-world object.
However, di erent URIs often use di erent properties to describe the same value.
For example, foaf:name and dc:title are both widely used for describing a person s name.
Given a set of coreferent URIs, ontology matching techniques [6] could be adopted to discover matchable properties from their values (a so-called extensional way), which takes into account the matchability between properties from pragmatics.
The most matchable property pair with associated values can be considered as the most important characteristics supported by the training set to identify coreferent URIs.
To formalize, for an RDF graph G, the matchability between two properties pi, pj in a labeled set D of G is computed by: Match(pi, pj) = |{(o, o(cid:4) ) | o   Obj(G, s, pi), (cid:3) I-Sub(o, o(cid:4) s,t D s(cid:3)=t o(cid:4)   Obj(G, t, pj), I-Sub(o, o(cid:4) ) = Comm(Desc(o), Desc(o(cid:4) ))   Di (Desc(o), Desc(o(cid:4) + Winkler(Desc(o), Desc(o(cid:4) )) ) >  }|, (4) )), (5) where I-Sub is an improved string comparison method [22], whose novelty is that the similarity between two strings is relevant to their commonalities as well as their di erences.
Winkler is a correction coe cient.
When o is a URI, Desc(o) extracts its local name, which is a string after the last hash  #  or slash  /  of the URI; when o is a literal, Desc(o) gets its lexical form.
In addition, pi, pj can be the same property which is used by di erent URIs.
The most matchable properties are the property pair that has the maximum number of matchable values.
Because a property may have di erent values, we assign the most common one to each property in a property pair.
The matchability of values is also considered, because some value for a property is prevalent in the real world but little supported by a speci c training set.
For a matchable property pair (pi, pj) in a labeled set D of G, the most common value pair (oi, oj) for (pi, pj) is computed as follows: (oi, oj) = arg max (o,o(cid:2)) |{(s, s(cid:4) )   D   D | I-Sub(o, o(cid:4) ) >  , (cid:2)s, pi, o(cid:3)  G, (cid:2)s(cid:4), pj, o(cid:4)(cid:3)   G}|.
(6) This equation allows oi, oj to be the same value, and s, s(cid:4) to be the same as well.
The discriminability of a property-value pair is calculated in terms of the number of potentially coreferent URIs that can be found by using such property-value pair.
Speci cally, let (pi, oi) be a property-value pair in G, the discriminability of (pi, oi) is calculated as follows: |{s   D | (cid:2)s, pi, oi(cid:3)   G}| |{s   H | (cid:2)s, pi, oi(cid:3)   G}| , (7) where D, H are labeled and unlabeled sets in G, respectively.
Here, we use a threshold based on our experiments to decide whether a property-value pair is discriminative or not.
Example 2.
Considering Fig. 2, the kernel includes dbpe-dia:Beijing and geo:1816670.
In terms of Eq.
(4), (rdfs: label, geo:alternateName) is the most matchable property pair in the  rst iteration, and  Beijing  is the most common value for them.
(rdfs:label,  Beijing ) and (geo:alterna-teName,  Beijing ) are the two discriminative property-value pairs for identifying coreferent URIs.
To avoid error accumulation, the selection of discrimina-tive property-value pairs reduces the execution of improper extension.
In addition, frequent property combinations are mined for further improvement, which is given in the next section.
Regarding the maximum number of iterations, we observed the average number of property-value pairs associated with an object in a large-scale dataset containing 76 million URIs, and found that in average an object is associated with about eight property-value pairs, so we set K = 10, which is a little larger than this average.
In ontology development, some properties are designed to be used together, e.g., wgs84_pos:long and wgs84_pos:lat; while only use a part of them cannot represent the intended semantics.
To improve the accuracy of our coreference resolution, we mine this kind of property combinations and use them as external knowledge to enhance the selection criteria of properties for constructing property-value pairs.
We propose to tailor association rule mining techniques to obtain binary associations between properties, which means that each property combination is composed of exactly two di erent properties.
We believe that binary associations are more prevalent and easy to understand, although association rule mining is naturally applicable for nary associations.
A binary association rule expresses that the occurrence of a property statistically indicates the presence of another property for the same object URI with certain con dence, which can be transformed into a conditional probability.
We prefer the co-occurrence relation for property combinations, which requires that not only the occurrence of one property implies the other, but vice versa.
The co-occurrence relation could be interpreted as an indicator of interdependency of two properties.
More speci cally, for two properties pi, pj in an RDF graph G, the con dence between pi, pj is computed as follows: Conf(pi, pj) = min{Conf(pi   pj), Conf(pj   pi)}, (8) Conf(pi   pj) = Pr(pj | pi) = Support(pi   pj) Support(pi) |{s   Subj(G) | pi, pj   Pred(G, s)}| |{s   Subj(G) | pi   Pred(G, s)}| = , (9) when Conf(pi, pj) is greater than a prede ned threshold, we say {pi, pj} is a frequent property combination, re ecting its signi cance in statistics.
Di erent from the goal of conventional association rule mining, we select a high threshold in our case (e.g., 0.98 in our experiments), which tends to  nd common combinations in data, rather than some surprising or obscure patterns.
Previous studies demonstrated that standard association rule mining techniques can discover numerous spurious patterns when being applied to random data and to real-world data [27].
From our dataset, we also observed a similar phenomenon.
For example, several social networking sites such as hi5.com and livejournal.com exported a large volume of RDF data for describing users, which led to many spurious frequent property combinations, such as {foaf:name, foaf:mbox}.
These combinations are not tightly co-related in semantics, and using them together can cause over tting in self-training.
Therefore, we propose two heuristic rules to re ne the pre-found combinations.
Firstly, we investigate the data ranges of properties de- ned in their dereference documents, and assume that two properties in a frequent property combination are co-related in semantics if their ranges are compatible.
A data range belongs to one of the six categories: a URI, a  oat, an integer, a string, a date time and a thing, where thing is compatible with the other  ve disjoint categories.
We also remove the frequent property combinations that contain builtin properties in RDF(S), OWL and DC.
Secondly, we perform a statistical analysis for the use of properties and their values.
The intuition behind this analysis is that unrelated properties may exhibit divergence in numbers of assigned values associated with objects.
For an RDF graph G, let pi be a property used as a predicate in G, AV () measures the average number of unique values that pi has, while AC() measures the average cardinality that an object uses pi: s Subj(G) AC(pi) = |{s   Subj(G) | pi   Pred(G, s)}| .
(11) If AC(pi) (cid:9) 1, pi is called a quasi-functional property in [13].
When two properties are semantically co-related, they should have close values of AV s and ACs, e.g., the di erence is less than 0.1 in our experiments.
Example 3.
Considering the example in Fig. 2, the average number of values and the average cardinality for wgs84_ pos#lat are: AV (wgs84_pos#lat) =

 , AC(wgs84_pos#lat) = 1.
The re ned frequent property combinations are stored beforehand.
In self-training, when the most matchable property pair (pi, pj) is selected (see Line 6 in Algorithm 1), we search the frequent property combinations for pi, pj, respectively.
If both of them have counterparts in these frequent property combinations, say (p(cid:4) j), their most common val-i} and {pj, p(cid:4) j} ues (if exists) are extracted.
Therefore, {pi, p(cid:4) with their associated values are used for  nding coreferent URIs.
It usually happens when pi, pj are the same property, and p(cid:4) j are probably also the same.
i, p(cid:4) i, p(cid:4) AV(pi) = (10) | (cid:2) s Subj(G) (cid:4) s Subj(G) Obj(G, s, pi)| |Obj(G, s, pi)| , (cid:4) |Obj(G, s, pi)| Data  le 1 Data  le 2 Ref.
mappings





 Person1 Person2 Restaurants


 Sampling.
It is very di cult, if not impossible, to analyze billions of RDF triples to calculate accurate AV s andAC s for all properties.
As an adaption, we propose a class-based sampling method for dealing with the scalability issue.
For a classc , the objects whose types are explicitly de ned as c are extracted.
If the number of the objects is too small, c is no longer considered because it is insigni cant in statistics; while if the number is too large, a subset of the objects are randomly chosen.
To some extent, this method avoids the skewed sampling, i.e., guarantees the coverage so that a few common classes, such as foaf:Person, do not dominate the sample set.
For our large-scale dataset in the experiments, we  lter the classes with less than 300 objects, and for each class, we extract at most 1,000 objects to form the sample set.
The entire sample set contains 1,199,764 objects, which is used for mining frequent property combinations.
However, note that the discussion on di erent sampling techniques is out of the scope of this paper.
We implemented a scalable system, called ObjectCoref, for our proposed method.
In this section, we report the experimental results on a benchmark dateset (PR) in OAEI 2010 and on a large-scale dataset collected by Falcons until Sept.
The datasets were run on four Xeon Quad 2.4GHz CPUs,
 MySQL 5.0.
The experimental results are downloadable at
 and a part of them about the benchmark test our website, are cited from OAEI 2010 [5].
The PR dataset is a small real dataset, which includes two collections of RDF data  les concerning persons (denoted by Person1 and Person2, respectively) and one collection about restaurants.
OAEI 2010 organizers provided reference mappings for each collection, where each mapping contains two URIs from di erent data  les that denote the same person or restaurant.
The statistics of the PR dataset are listed in Table 1.
The goal of our evaluation on the dataset is twofold.
First, we want to test various values for the parameters in Object-Coref and apply the best ones to the following experiments.
Second, we can compare ObjectCoref with other systems on the same dataset.
The well-known Precision, Recall and F-Measure were used, where F-Measure is a linear combination of Precision and Recall: F-Measure =
 Precision + Recall .
(12) Because all the URIs in the PR dataset are synthetic, no kernel can be established.
Instead, we randomly chose 20 reference mappings from each collection and used them as the
 http://ws.nju.edu.cn/objectcoref/www2011.zip e r u s a e
  












 Person1 Person2 Restaurants

 Iterations

 Figure 3: F-Measures versus number of iterations on the benchmark dataset initial labeled set for training.
To  t the dataset, we slightly modi ed the goal of our self-training algorithm by skipping the assignment of the most common values to properties, since each property only has one value for a URI.
Moreover, all the URIs are described by a set of  xed properties, thus frequent property combinations cannot be mined.
Learning curves.
The learning curves are shown in Fig. 3, where iteration 0 denotes the initial training set.
Based on the  gure, we observed that F-Measures drastically risen up in the  rst one or two iterations, and then dropped sharply.
This demonstrates that one or two properties are accurate enough for identifying a person or a restaurant.
For identifying the same person, soc_sec_id and phone_number were learnt; and for a restaurant, phone_number was discrimina-tive.
If we continued the training, improper properties were chosen, e.g., age for Person1 and Person2, which led to many wrong coreferent URIs.
From the learning, we observed that 0.95 is a good value for I-Sub to determine if two strings are similar enough.
We also observed that 0.125 is a proper threshold for measuring a property-value pair is discriminative or not, which means that using such property-value pair, if the number of potentially coreferent URIs is eight times more than that in the labeled set, this pair would not be considered for resolution.
We used these two thresholds throughout the following experiments.
F-Measure.
We compared the results of ObjectCoref with other four coreference resolution systems, namely ASMOV, CODI, LN2R and RiMOM, which also submitted their results on the PR dataset to OAEI.
ASMOV [16] and CODI [20] employed similarity-based matchers to obtain coreferent URIs and performed logical inference to remove inconsistent results.
LN2R [21] integrated a knowledge-based matcher to  nd semantically coreferent URIs and adopted a similarity propagation algorithm to generate similarities.
RiMOM [18] is a purely similarity-based system, which integrated many matchers to exploit a range of characteristics for both concepts and instances.
All of them can only deal with pairwise instances, which are precisely called instance matching systems.
We discuss their details in Section 7.
RiMOM e r u s a e
  











 Person1 Person2 Restaurants Figure 4: Comparison on F-Measure among Object-Coref, ASMOV, CODI, LN2R and RiMOM on the benchmark dataset The comparison results on F-Measure is depicted in Fig. 4.
From the  gure, we observed that ObjectCoref achieved the best F-Measure in average on the PR dataset.
In particular, the Precision of ObjectCoref is quite good (100% in all the three collections), because we learnt the most discriminative properties for the resolution.
Notice that our F-Measure on the restaurant track in this paper is slightly better than the result published by OAEI [5], as we corrected a parsing bug for addresses in our programs after participating in OAEI.
Furthermore, we took advantage of a small number of reference mappings as the training set and the use of optimal iteration times, which are not against by the OAEI organizers.
If other systems can make use of reference mappings, their performance may be improved as well.
The statistical data of the large-scale dataset is listed in Table 2.
The dataset contains 596,418,935 RDF triples (tr.)
in 11,719,608 RDF documents referring to 76,389,570 URIs, which equals an average of 7.81 RDF triples per URI.
This suggests that each URI is involved in about eight property-value pairs, so we set the maximum iteration times K to
 value is dataset-dependent and no single value would yield similar results on multiple di erent datasets.
We will study how to automatically determine the optimal iteration times in our future work.
By investigating the dataset, 7,880,906 owl:sameAs triples without blank nodes were found, where most of them come from http://bio2rdf.org and http://dbpedia.org.
Considering the purposes of ObjectCoref, blank nodes cannot provide any meaning outside their original scopes.
So we excluded the same-as (and IFP, FP, cardinality) relations having blank nodes in our experiments.
This dataset contains

 were retrieved, where most of them are about foaf:mbox_ sha1sum (11,903) and foaf:mbox (2,981).
It was found that
 garding FPs, we obtained 11,765 dereferenceable FPs from
 Table 2: Statistical Data of Large-Scale Dataset IFP tr.
FP tr.
Cardinality tr.
Same-as tr.
URIs Table 3: Sample URIs










 http://www.w3.org/People/Berners-Lee/card#i http://www.cs.vu.nl/...#Frank+van+Harmelen http://data.semanticweb.org/person/chris-bizer http://dbpedia.org/resource/United_States http://dbpedia.org/resource/New_York_City http://dbpedia.org/resource/Berlin http://dbpedia.org/resource/Semantic_Web http://bio2rdf.org/accession:af048837 http://dbpedia.org/resource/Apple_Inc.
[company] [mammal] http://dbpedia.org/resource/Jaguar [city] out blank nodes, in which 440 triples have the FP relations with others.
Additionally, we discovered 34,635 triples without blank nodes that use 113 dereferenceable properties in cardinalities, where 6,123 ones have the cardinality relations with others.
We collected 364,408 query logs from Falcons and chose 10 popular query URIs, which are listed in Table 3.
These URIs cover a wide range of real world domains (e.g., people, geography), and all of them have semantically coreferent URIs for establishing kernels.
The local names of some URIs have several meanings.
For instance,  apple  can be either a fruit or a computer brand.
We selected each URI having a clear meaning among its polysemic local names, to  nd whether or not ObjectCoref can identify the correct coreferent URIs and how well.
In this test, we evaluated Precision and Relative recall of ObjectCoref for resolving object coreference on the Semantic Web.
Relative recall is the number of coreferent URIs retrieved by one system divided by the total number of unique coreferent ones from all systems, which o ers a practical, if imperfect, solution to the problem that the total number of results is unknown.
This measure has been widely applied to evaluate the quality of large ontology matching [6].
For Precision, we employed three students to take peer reviews on the coreferent URIs returned by each system.
A student judged whether a returned URI is coreferent with the input, in terms of the provided evidences like the equivalence relations, the descriptions in the dereference documents.
Frequent property combinations.
By applying the Apri-ori algorithm to perform association rule mining, we discovered 9,610 frequent property combinations with con dences greater than 0.98.
Then, we used the two heuristic rules to re ne the combinations and retained 349 ones, which were used as external knowledge for improving the accuracy of our resolution.
Some sample frequent property combinations are listed in Table 4, where the average cardinalities are all 1.0, Table 4: Frequent Property Combinations Frequent property combinations {wgs84_pos#long, wgs84_pos#lat} {foaf:surname, foaf:givenname} {foaf:img, foaf:depictioin} {dbpedia:preceded, dbpedia:succeeded} {uniprot:height, uniprot:weight} AV s {.93, .92} {.83, .81} {.52, .52} {.48, .48} {.38, .37} ACs {1.0, 1.0} {1.0, 1.0} {1.0, 1.0} {1.0, 1.0} {1.0, 1.0} ObjectCoref FPC sameas.org sig.ma Table 5: Summary of Average F-Measures
 Benchmark Large-scale n o i s i c e r











 ObjectCoref


 RiMOM sameas.org sig.ma







 The Precision and Relative recall of the four systems are depicted in Fig. 5 and Fig. 6, respectively.
Based on the  g-ures, we observed that ObjectCoref and sameas.org achieved similar Precisions in most cases, while their Relative recalls are quite di erent, because all the systems were run on different datasets, and the returned results only had a part of overlap.
sig.ma did not perform well, because the keyword-based query brought ambiguity, and it limited the number of returned URIs per input no larger than 20.
For the 10 queries, three most matchable properties were rdfs:label, foaf:name and dc:title.
For example, (rdfs:label,  Tim Berners-Lee ) and (foaf:name,  Tim Berners-Lee ) were two discriminative property-value pairs in #1 for extension.
When frequent property combinations were integrated into the system, the Precisions in four cases were further improved, namely #2, #4, #6 and #9.
Notice that the Relative recalls slightly decreased, due to the deletion of some wrong coreferent URIs.
In #2, without frequent property combinations, ObjectCoref only used foaf:firstName and found wrong persons like  Frank Ohrtmann  or  Frank Ley-mann , but after considering frequent property combination {foaf:firstName, foaf:lastName}, such wrong coreferent URIs cannot be found.
But in #10, (rdfs:label,  Jaguar ) was selected as a discriminative property-value pair, which caused wrong resolution.
Furthermore, we did not  nd any frequent property combination for distinguishing the mammal  Jaguar  with the car brand or a chemical package, so the Precision of ObjectCoref-FPC remained the same.
The average number of coreferent URIs found by ObjectCoref-FPC is 68.4, while the average size of the kernels is 10.3.
Average resolution time.
We randomly chose 5,000 sample URIs from our dataset, and repeated the experiment 10 times to measure the average resolution time for Object-Coref.
The total resolution time is about 12 hours, equating to 8.6 seconds per URI.
But the time spent on a few URIs is much longer than this average.
It took several minutes to complete an object URI with tens of potentially coreferent URIs.
This indicates that, although ObjectCoref performs reasonably e cient when starting with a majority of URIs in our dataset, it is still hard to resolve all the URIs on the Semantic Web based on the current state of ObjectCoref.
Summary.
The average F-Measures on the benchmark and large-scale datasets is illustrated in Table 5, depicting that ObjectCoref performed best in both datasets.
As compared with the average performance of the other competitors, our approach achieved 18% and 25% increasing in F-Measure, respectively.
The F-Measure on the large-scale dataset is the linear combination of Precision and Relative recall.
Figure 5: Comparison on Precision among Object-Coref, ObjectCoref-FPC, sameas.org and sig.ma on the large-scale dataset ObjectCoref ObjectCoref FPC sameas.org sig.ma l l a c e r e v i t a l e





















 Figure 6: Comparison on Relative recall among Ob-jectCoref, ObjectCoref-FPC, sameas.org and sig.ma on the large-scale dataset indicating that each property is used once in average for a single object.
For instance, a location usually has only one longitude.
On the contrary, the average number of values for each property is less than 1.0, which re ects that di erent URIs have same property-values.
Precision & Relative recall.
In the experiment, we used three systems for comparison.
ObjectCoref-FPC represents our system performing re nement based on frequent proper-[23] are two ty combinations, while sameas.org online services for object coreference resolution.
sameas.org investigated a number of properties that explicitly de ne the equivalence relation, e.g., owl:sameAs and skos:exactMatch.
sig.ma aimed at data mashup and can only accept keyword queries, so in this experiment we fed it the local names of our sample URIs.
and sig.ma


 http://sameas.org/ http://sig.ma/ Object coreference resolution is an important task for establishing semantic interoperability and realizing data integration.
In the area of Semantic Web, researchers addressed this problem mainly from two directions: one is based upon OWL semantics inference.
Glaser, et al. [8] implemented a coreference resolution service (CRS) mainly by owl:sameAs.
The works in [11, 23] performed large-scale object consolidation in terms of the analysis of IFPs, respectively.
Sa s, et al.
[21] designed a new language RDFS+ for expressing corefer-ence, which integrated FPs, IFPs and owl:disjointWith in OWL as well as SWRL rules in RDFS.
The KnoFuss architecture [19] combined the use of owl:sameAs, IFPs, FPs and owl:differentFrom for resolving coreference.
Additionally, some works analyzed the state of owl:sameAs in the current Semantic Web or Linked Data [3, 10].
The other class of studies is based on the assumption that URIs are denoting the same real-world object if they share some common property-value pairs.
Ferrara, et al. [7] reused an ontology matching tool HMatch to compare the minimal sets of assertions for describing di erent URIs.
Hogan, et al.
[13] proposed a statistical approach for identifying  quasi key properties for object consolidation over Linked Data.
In addition, a number of works called instance matching (e.g., [14, 16, 18, 20, 26]) computed similarities between instances based upon matching their property-values.
Except [13], the rest studies aforementioned assumed that the input is just pairwise instances and their computational costs are usually high, so it is di cult to adapt them to Web-scale.
For architecture, our proposed framework is similar to the work in [9], which dedicated a large-scale clustering to ontology terms.
It used synonyms to set up a kernel, and then extended the kernel with similar terms in labels and identi- ers.
Both of us adopted a bootstrapping running mode, but [9] merely executed the extension one time.
Furthermore, [9] performed extension only based on labels and local names, while our self-training framework is more adaptive for various domains.
In addition, KnoFuss and LN2R [20] searched semantically coreferent URIs and proposed similarity propagation algorithms for re nement.
A key issue in our self-training algorithm is to measure the discriminability for property-value pairs.
Hogan, et al. [13] analyzed the global distribution for properties and their associated values to count the discriminability for a property-value pair.
Di erent from [13], our measurement is not static and further considered the matchability between properties, because a property in di erent domains may have di erent discriminability, while di erent properties could be used for expressing a similar meaning.
In addition, we involved frequent property combinations to improve the accuracy of the resolution, where the analysis on the average cardinalities of properties was inspired by [13].
Besides the Semantic Web community, identifying duplicate entities, which is also under the names of record linkage, duplicate detection, coreference resolution and many others, has been extensively studied in both database and natural language processing areas [1, 4].
These works are in general treated as similarity-based due to a lack of formal semantics to de ne equivalence.
The contributions of this paper are summarized as follows:   We proposed a self-training approach for object coref-erence resolution on the Semantic Web, which  rst constructed a kernel of semantically coreferent URIs for a given object URI based on OWL semantics, and then iteratively extended this kernel in terms of discrimi-native property-value pairs.
For further improving the accuracy of the resolution, frequent property combinations were mined and injected in the learning process.
To the best of our knowledge, our proposed approach is the  rst attempt to adopt self-training for bridging the gap between semantically coreferent URIs and potential candidates, which is important for the maturing Web of Data.
  We introduced a statistical measurement to learn the discriminability of property-value pairs, which not only exploited key characteristics for representing an object, but also considered the matchability between properties from pragmatics.
  We applied association rule mining to discover frequent property combinations, which were further  ltered by comparing the data ranges of properties in each combination and the distribution information on the use of properties as well as their values.
The frequent property combinations avoided error accumulation during the training and improved the accuracy of the resolution.
  We evaluated our proposed approach on both a benchmark dataset in OAEI 2010 and a large-scale dataset that is collected by Falcons search engine in 2008.
The experimental results showed that our approach achieved good F-Measure on the two datasets, as compared with the performance of six representative systems.
In the near future, we will perform more experiments for parameter setting in our self-training approach, such as determining the optimal iteration times.
In the long term, we hope to abstract our object-driven approach to the class level, which will identify discriminative properties for di erent classes in di erent domains.
Furthermore, we would like to design the co-training mechanism to improve the robustness of our coreference resolution algorithm.
In addition, we will use our approach to analyze the coreference phenomenon in Linked Data.
This work is supported in part by the NSFC under Grant
 Research Fund for the Doctoral Program of Higher Education under Grant 20100091120041.
We would like to thank Hang Zhang and Min Liu for the active participation in the experiments.
We also appreciate the helpful comments from three anonymous reviewers.
