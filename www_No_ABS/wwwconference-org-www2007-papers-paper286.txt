Rank aggregation is to combine ranking results of entities from multiple ranking functions in order to generate a better one.
The individual ranking functions are referred to as base rankers, or simply rankers, hereafter.
Rank aggregation can be classified into two categories [2].
In the first category, the entities in individual ranking lists are assigned scores and the rank aggregation function is assumed to use the scores (denoted as score-based aggregation) [11][18][28].
In the second category, only the orders of the entities in individual ranking lists are used by the aggregation function (denoted as *This work was conducted when the first and the third authors were interns at Microsoft Research Asia Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
order-based aggregation).
We focus on order-based aggregation in this paper.
Order-based aggregation is employed at meta-search, for example, in which only order (rank) information from individual search engines is available.
Previously order-based aggregation was mainly addressed with the unsupervised learning approach, in the sense that no training data is utilized; methods like Borda Count [2][7][27], median rank aggregation [9], genetic algorithm [4], fuzzy logic based rank aggregation [1], Markov Chain based rank aggregation [7] and so on were proposed.
One exception is Borda Fuse [2] which also makes use of training data.
However, it is different from the supervised learning method we propose in this paper.
We argue that in order to improve the accuracy of rank aggregation, it is better to employ a supervised learning approach in which we train an order-based aggregation function within an optimization framework using labeled data.
At meta search, for example, labeled data can be documents and their relevancies to given queries.
The key factors, thus, are (a) to assume that only order information from individual rankers is available, (b) to use labeled data, and (c) to train the aggregation function within an optimization framework.
In this paper, we refer to the approach as  Supervised Rank Aggregation .
labeled There are several advantages for taking the supervised learning approach.
First, we can leverage the use of information existing in training data.
Second, we can apply existing optimization techniques to the problem.
Third, it becomes easier to make domain or user adaptation.
Certainly, it also has a disadvantage, that is, labeled data is needed and creating such data can be costly.
This is, however, a shortcoming for any supervised learning method and we can leave it as future research topic.
In this paper, we first give a general framework for conducting Supervised Rank Aggregation.
We show that we can define supervised the existing unsupervised methods, such as Borda Count and Markov Chain based methods by exploiting the framework.
learning methods corresponding to Then we mainly investigate the supervised versions of Markov Chain based methods in this paper, because previous work shows that their unsupervised counterparts are superior [24].
It turns out, however, that the optimization problems for the Markov Chain based methods are hard, because they are not convex optimization problems.
We are able to develop a method for the optimization of one Markov Chain based method, called Supervised MC2.
Specifically, we prove that we can transform the optimization problem into that of Semidefinite Programming.
As a result, we can efficiently solve the issue.
(We plan to apply the same technique to the other Markov Chain methods in the future.)
Experimental results on meta-searches show that Supervised Rank Aggregation (i.e., Supervised MC2) can achieve better performances than existing methods.
introduce related work.
In Section 3, we propose a general framework and for Supervised Rank Aggregation.
In Section 4, we propose an optimization algorithm for the method of Supervised MC2.
Experimental results are reported in Section 5.
Conclusions and future work are given in the last section.
specific methods

 The origin of research on rank aggregation can be traced back to the eighteenth century, when it was studied in social choice theory and applied into political elections [5].
In recent years, rank aggregation gets spotlight again in many new applications, such as genome database construction [26], document filtering [13], database middleware construction [10], spam webpage detection [7], meta-search [2][7][17][24], word association finding [7], multiple search [11], and similarity search [9].
There are two types of rank aggregation: score-based and order-based.
In the former the aggregation function takes score information from the individual base rankers as input, while in the latter it only utilizes order information.
Order-based aggregation fits well with meta-search, as in meta-search only order information from base rankers is available; this is also the main focus of the research in this paper.
Existing methods for order-based aggregation includes, for example, Borda Count [2][7][27], median rank aggregation [9], genetic algorithm [4], fuzzy logic based rank aggregation method [1] and Markov Chain based rank aggregation [7].
Borda Count ranks entities based on their positions in the ranking lists.
For example, the entities are sorted according to the number of entities that are ranked below them in all the ranking lists.
Median rank aggregation sorts the entities based on the medians of their ranks in all the ranking lists.
Markov Chain based rank aggregation assumes that there exists a Markov Chain on the entities and the order relations between entities in the ranking lists represents the transitions in Markov Chain.
The stationary distribution of the Markov Chain is utilized to rank the entities.
Dwork et al [7] proposed four methods (denoted as MC1, MC2, MC3, and MC4) to construct the transition probability matrix of the Markov Chain.
The unsupervised methods described above implicitly conduct majority voting in their final ranking decisions.
That is to say, these methods treat all the ranking lists equally and give high ranks to those entities ranked high by most of the rankers.
This assumption may not hold in practice, however.
For example, in meta-search, ranking lists are generated by different search engines with different capacities and accuracies.
It is not reasonable to treat the results of the search engines equally.
To deal with the problem, Aslam et al [2] proposed Borda Fuse, which can be viewed as weighted Borda Count for meta-search.
Specifically, different rankers are assigned different weights, while the weights are trained separately by using labeled training data.
For example, the weights can be calculated based on the MAP (Mean Average Precision) scores of the base rankers.
Experimental results show that Borda Fuse indeed improves upon Borda Count.
The problem with Borda Fuse is that the weights of the ranking list are calculated independently and by using heuristics.
It is also not clear whether the same idea can be applied to other methods.
We note that order-based rank aggregation in meta-search is similar to relevance ranking in document retrieval, but there are some clear differences.
Therefore, the methods proposed for relevance ranking may not be directly applicable to order-based rank aggregation.
In relevance ranking, a typical approach is to employ a linear combination model of the features to rank documents.
One can also employ a supervised learning method to train the model.
Each feature can be viewed as a ranker and the final ranking model can be viewed as an aggregation function.
However, this final ranking model is more close to that of score-based aggregation, not that of order-based aggregation.
How to apply a score-based method to order-based aggregation is still an open problem, and is out of the scope of this paper.
In this section, we first introduce a general optimization framework for order-based rank aggregation.
We then define Supervised Rank Aggregation methods within the framework.
We first give some definitions and notations.
Given a set of entities S, let V be a subset of S and assume that there is a total order among the entities in V.   is called a ranking list with respect to S, if   is a list of the entities in V maintaining the same total order relation, i.e.,  =  1,   ,   , if  1 >   >   ,  i    ,  = 1,   ,  , where > denotes the relation and m denotes the size of V. If V equals S,   is called a full list, otherwise, it is called a partial list.
A special case of partial list is a top-t list, for which the first tth entities are ordered in the list.
The goal of rank aggregation is to assign a real-valued score to each of the entities by aggregating all the ranking lists given by the base rankers, and then sort the entities according to their scores.
Without loss of generality, hereafter we assume that it is in the descending order.
Let  1,   ,   denote the ranking lists with respect to   and   denotes the number of entities in S. We define the aggregation function as  :  1,   ,       , where   denotes the final score vector of all entities.
That is, if   =    1,   ,   , then all the entities are ranked by the scores in x.
For example in Borda Count,   is called Borda score, which is calculated as,     =    1,   ,   =  =1
  ( ) (3.1.1) ( )  =1, ,  ,   ( ) = #  |  >    , and   >    where  ( )     means that entity i is ranked higher than entity j in ranking list   .
We assume that the aggregation function   is parameterized by a parameter vector   .
In a supervised learning approach to rank aggregation, we try to learn the optimal values of the parameters by using labeled training data.
Typically training data may include ground truth indicating pairwise preferences of which entities should be ranked higher than the others.
In the learning, we actually manage to find the aggregation function that minimizes the disagreements between the ground truth and the output of the aggregation function.
We represent the agreement between the output list of an aggregation function and the ground truth by using an inequality   < 0 where   denotes the output of the function and H denotes a matrix representing the pairwise preference relationship between entities.
For example, suppose that the scores produced by the aggregation function are   =  1,  2,  3,  4   , and the ground truth indicates should be ranked higher than entity 3.
Then, the inequality becomes:   < 0, where   =  1


 By using such a matrix, we can bring any form of ground truth into our framework, and do not need assume a total order existing over all the entities in the training set.
There is no guarantee that there exists a parameter vector   that satisfies all the pairwise constraints in the ground truth.
That is, disagreements may exist.
We introduce  slack variable    to represent the differences (errors),   <  ,     0 To reduce training errors is equivalent to minimize the norm of t.
Thus we can formalize Supervised Rank Aggregation as the following optimization problem.
min , ,     .  .   =    1,   ,  ;           <  ,     0 (3.1.2) where   denotes the parameter vector and C denotes a feasible region for  .
The dimension of matrix H equals the number of pairs indicating pairwise preferences in the training data.
The objective   actually denotes the empirical loss in the training data.
When empirical loss is 0, the aggregation function   satisfies all the pairwise constraints.
With different ways of the aggregation function, we come to different methods for rank aggregation.
instantiating and optimizing
 We show that we can define Supervised Rank Aggregation methods within the framework.
In this paper we only consider the case in which the aggregation function is defined as a linear model of base rankers.
Even the model is simple; it is powerful enough for accomplishing the tasks in this paper.
(1) Borda Fuse Many other rank aggregation methods are based on Markov Chain.
It is advantageous to employ the Markov Chain model in rank aggregation, particularly when the base rankers only output partial lists [8].
Experimental results show that the Markov Chain based methods outperform other methods [24].
That is why we focus on Markov Chain based approach in this paper.
Dwork et al [7] proposed four Markov Chain based models for rank aggregation, referred to as MC1, MC2, MC3, and MC4.
The four models correspond to four different heuristic rules for constructing the transition probability matrix in Markov Chain.
Let us take MC2 as example.
The transitions in Markov Chain are defined as follows.
If the current state is i, then we first select a ranking list   uniformly randomly from the ranking lists  1,   ,   that contain state i, then select state j uniformly randomly from the set of states that are ranked not lower than state i in   , and define j as the next state.
For a full list or top-t list, it is not difficult to verify that the transition matrix is arithmetic mean of transition probability matrices produced from individual ranking lists, referred to as denote the kth base base-transition matrices.
Let       transition matrix produced by ranking list   , in which each element   corresponds to the conditional probability of state j given state i in ranking list   .
The final transition matrix P is defined as ( )    
    =1  
  
 ,   >    or   =     =     0, otherwise (3.2.1) where   = #  |  >    or   =   .
The score vector x can then be computed by solving   =  , with constraints   In Supervised MC2 we assign weighting coefficients to the base matrices Pk:    =1 = 1,   > 0,   = 1,   ,  .
 
  =1     Formally, Supervised MC2 is defined as follows.
Many rank aggregation methods are in fact based on majority voting.
Borda Count [2][7][27] is such a method and the major assumption within it is that all the base rankers are equally important.
As discussed above, it is more reasonable to give different weights to different rankers.
In other words, we can consider using Borda Fuse min ,  ,       .  .   =    =1        =1 = 1,   > 0,   = 1,   ,      =1 = 1,     0,   = 1,   ,      
   <  ,     0 (3.2.2)   =    1,   ,   =    =1    ( ) Note that Borda Fuse contains Borda Count as its special case.
With the optimization framework in (3.1.2), we can define Supervised Borda Fuse.
Specifically we formalize it as the following optimization problem: min , ,       ( )  .  .   =  =1     = 1,     0,   = 1,   ,      =1   <  ,     0 where  ( ) is the same as that in (3.1.1).
Note that the parameter vector is comprised of weights of ranking lists and is to be optimized as well.
(2) Markov Chain based methods Similarly, we can construct the supervised versions of MC1, MC3, and MC4.
The only differences lie in the structures of the transition probability matrices.
a) Supervised MC1: The transition matrix of MC1 can be written as   =  
 ,   ,  1 
     =1  
     =1 where       =
        =1   ,       ( ) with   ( ) =   1,   >    or   =   0, otherwise .
We can derive Supervised MC1 by assigning weighting coefficients to  , and obtain the following optimization problem.
   .  .   =  =1      

     =1 ,   ,
     =1        =1 = 1,   > 0,   = 1,   ,       = 1,     0,   = 1,   ,    =1   <  ,     0  1    b) Supervised MC3: The formulation of MC3 is similar to that of MC2, except the definition of     :   =  
       ,   >      ,   =   0, otherwise , and   = #  |   >    .
Therefore, we can define Supervised MC3 in a similar way as we define Supervised MC2.
c) Supervised MC4: MC4 is similar to MC1, except that the following two facts differ.
(i) The definition of  :       with   ( ) = 1,   >    .
0, otherwise =
        =1   , (ii) The definition of P:       , with     =  
       ,   > 1
   ,   =   0, otherwise , and   = #  |  > 1
 Therefore, we can obtain Supervised MC4, similar to Supervised
 In summary, with the use of the optimization framework, we can introduce new supervised aggregation methods, corresponding to most of the existing unsupervised rank aggregation methods.
The key factor is that weights are assigned to the ranking lists and they are also trained within the optimization framework.
The question next is how to conduct the optimizations.
For some forms of function   in (3.1.2), the optimization is hard to solve, such as those in the Markov chain based methods.
We know of no existing optimization techniques which can be straightforwardly applied, because they are not convex optimization problems.
In our work we are able to find an optimization solution for Supervised MC2 on the basis of Semidefinite Programming (SDP), as will be explained below.
In this section, we describe our solution to the optimization problem for Supervised MC2 as in (3.2.2).
We think that similar techniques can also be applied to other Markov Chain based methods, but leave it as future work.
Our method for Supervised MC2 consists of three steps:
 the feasible region convex.
quadratic optimization problem by employing the bound optimization technique.
into a Semidefinite Programming problem.
Let us elaborate on the three steps in more details.
Theoretical justifications of the transformations are given in a lemma and a proposition.
The first constraint in (3.2.2) represents an eigenvector problem.
One can easily verify that the feasible region of the optimization problem is not convex.
In general such a problem is hard to solve.
We reformulate the original optimization problem by putting the first constraint into the objective function:   min ,  ,    +  =1    
      
    =1 = 1,   > 0,   = 1,   ,      =1  .  .     = 1,     0,   = 1,   ,   (4.1)   <  ,     0 where   1denote the  1-norm of a vector.
Then, the feasible region becomes convex and the objective function becomes one consisting of two parts.
The first part   corresponds second part        =1 corresponds to an approximation of the training errors, and the to
      
 stationary distribution.
The second part of the objective function is not convex.
We try to minimize a differentiable and convex upper bound of it.
Lemma 1 gives the upper bound using the properties of  1-norm.
Lemma 1: Let   =        =1, ,  =  =1    
      , we have   1   2   2 , where   = (1) (1)      11     ( ) ( )      11   .
Proof: See Appendix.
The optimization problem then becomes min ,  ,    + 2   2     .  .    =1 = 1,   > 0,   = 1,   ,        =1 = 1,     0,   = 1,   ,     <  ,     0 (4.2) By defining   = ( 1,   ,  ,  1,   ,   ,  1,   ,   ) , where m is the number of rows in matrix H, and omitting the constant in the objective function which is irrelevant to the optimization, problem (4.2) becomes min   0  (4.3) with  0 =
    ( + +  ) ( + +  )
      +     + +  (4.4)  .  .  1    0  2  =  2  3  < 0







   0


  



  



    2   + + 
       +     + +  where   is identity matrix of size i, and   is vector with size i in which all the elements are one.
The optimization in (4.3) is an optimization problem with quadratic objective function and linear constraints.
The remaining issue is that the Hessian matrix H0 is not positive definite and thus the objective function is not convex.
In this situation, if we employ a method like Gradient Decent, the solution will be optimal.
To cope with it, we further transform the optimization problem into a Semidefinite Programming (SDP), with the theoretical support from Proposition 2.
In our experiment, we used 30 ranking models (features) [22] as base rankers.
These include term frequency, inverse document frequency, document their combinations.
length, BM25 score [25], and  0 +  0 







  2   2 0       0 (4.5) Proposition 2: Optimization problem (4.3) is equivalent to the following Semidefinite Programming problem, max ,     .  .     0 Where   =  1
  3, and   = ( 0,  1


 Proof: See Appendix.
Finally we can solve the optimization problem using the techniques of SDP1, for example, the interior-point method SDPA [30] proposed in [12].
Table 1.
Results of different methods for meta-search with OHSUMED data Supervised





















 Borda-Count Borda Fuse







































 Our Supervised MC2 algorithm can be summarized as follows.
Supervised MC2: Input: ranking lists  1,   ,   Output: weighting parameter   Algorithm: a) Construct base transition matrices  1,   ,   according to equation (3.2.1).
b) Create matrix   as shown in Lemma 1.
c) Create matrices H0, H1, H2, H3 as shown in equation (4.4).
d) Construct matrix U as shown in Proposition 2.
e) Call SDP tool [30] to solve problem (4.5) and get solution  .
f) Compute   by equation (8.2.3).
g) Output the first l elements of   as parameter  .
In this section, we report the experimental results on meta-search using our method based on Supervised Rank Aggregation and existing methods.
Our first experiment was conducted with TREC dataset, and the second was with data from real web search engines.
TREC datasets were used in many previous works on rank aggregation [2][18][19][20][24], in which heuristic models were used as base rankers.
This motivated us to conduct our experiments with TREC dataset as well.
We selected the OHSUMED dataset used in the filtering track of TREC 2000.
The OHSUMED dataset is a collection of 348,566 documents and
 with three levels of relevance judgments:  definitely relevant ,  possibly relevant , and  not relevant  to the query.
Based on these judgments, we can construct pairwise constraints for the training of Supervised MC2.
algorithms have been developed [16][21][23][30].
Table 2.
Results of different methods for meta-search with OHSUMED data Supervised





















 Borda-Count Borda Fuse







































 implemented and Next, we conducted rank aggregation using our method.
For comparison, we also tested other rank aggregation methods, including MC1, MC2, MC3, MC4, Borda Count, and Borda Fuse.
The experiments were performed through
 subsets, used the first two of them for training, the third for validation, and the fourth for testing, and rotated this process four times to create four data sets.
Then we took the average performance over the four trials as the final result for each method.
We used three measures in our experiments for ranking accuracy evaluations: Precision [3], Mean Average Precision (MAP) [3] and Normalized Discount Cumulative Gain (NDCG) [14][15].
When evaluating the performances in terms of precision, we regarded both  definitely relevant  and  possible relevant  as positive, and  not relevant  as negative.
Table 1 shows the results in terms of precision at n (P@n) and MAP, and Table 2 shows the results in terms of DNCG at n (N@n) for all the methods.
From the results, we can see that Supervised MC2 outperforms all the other methods, suggesting that it is better to employ Supervised Rank Aggregation proposed in this paper.
We also tried to apply the rank aggregation methods directly to meta-search on the web.
We randomly sampled 500 queries from the query log of a commercial search engine, as query set.
Table 3 shows some example queries.
Table 3.
Sample queries used in meta-search Queries Altavista, Astronomy Picture of the day, BBC, cadillac, daily nation, delta dental, family guy, fox theater, Google, group health, habitat for humanity, hotmail, Image Entertainment, imdb, jacksonville news, jetblue, kofax, laredo morning times, liberty university, michael Jordan, Microsoft, national zoo, NCAA football, ohio department of education, philips, prime outlets, southern baptist convention, Superbowl, tacoma news tribune, texas department of public safety, Tuesday Morning, ucla, university of Tennessee, venetian, etc.
Table 4.
Results of different methods for meta-search with data from web search engines Supervised





















 Borda-Count Borda Fuse























 Next, we submitted the queries to six commercial web search engines, and collected the top-100 ranking lists of the queries returned by the search engines.
We combined the results together and eliminated the duplicate pages.
On average there were 362 unique pages per query.
The overlap among the ranking lists of the search engines was small: there were on average 4 pages per query occurring in all the ranking lists.
Then we asked human annotators to make relevance judgments on the pages.
The relevance judgments were binary: relevant or irrelevant.
Three annotators made judgments, and majority voting was finally conducted on the results.
We then conducted meta-search on the data through 4-fold cross validation (in the same way as in Section 5.1.
We applied our proposed method, and used MC1, MC2, MC3, MC4, Borda Count, and Borda Fuse as baselines.
Table 4 shows the results in terms of P@n and MAP.
From the results, we can see that our proposed method achieves the best results in terms of both MAP and P@n.
Again this verifies the effectiveness of our proposed method for rank aggregation.
Table 5 shows the experiment results in terms of NDCG@n.
Table 5.
Results of different methods for meta-search with OHSUMED data Supervised



















 Borda-Count Borda Fuse






























































 We (Supervised MC2) outperforms the baseline methods.
investigated why our proposed supervised method Figure 1 shows MAP and the weight to each search engine assigned by our method in the first trial of the cross-validation experiment.
(The results from the other trials have the same tendencies).
Figure 1.
MAP and weights of search engines From Figure 1, we have the following observations.
(a) The weights of search engines are different from each other.
This validates the correctness of our assumption that rankers should have different weights.
(b) The weights of search engines do not necessarily correlate with their MAP values.
Although the fourth search engine achieves the best MAP and obtains the largest weight at the same time, for the other engines, MAP and weight do not correlate.
For example, the first search engine has a higher MAP than the second, but it has much smaller weight than the second.
Our explanation to this is as follows.
The weights of search engines not only depend on their performances, but also depend on the correlations among search engines.
If a search engine highly correlates to the others, its weight (influence) will be reduced within the general optimization framework.
To verify the correctness of this explanation, we calculate the correlation coefficient between each pair of the six engines using the following formula, and present the results in Table 6.
(Note that the correlation is symmetric.)
# query query #  ,   >SE   and  >SE     or (  <SE   and  <SE    ) #   ,    , SE   and ( , SE   ) where SEi denotes the i-th search engine,   >SE     means that document u is ranked higher than v by SEi for a given query, and  ,     SE  means that documents u and v are returned by search engine SEi.
Table 6.
Correlation among search engines


























 From Table 6, we can see that the first search engine highly correlates to the forth and the sixth search engines, and therefore its weight is suppressed by the large weights of the two engines.
In contrast, the second search engine only weakly correlates to the other engines, and thus it retains a large weight.
The observation can also give explanation to other results in the experiments.
From Table 5, one may see an interesting phenomenon.
Borda Fuse, as a supervised method, performs even worse than the unsupervised methods.
As explained, Borda Fuse assumes that the weight of each base ranker only depends on its accuracy, and it neglects the correlation among base rankers.
It seems that this is not appropriate anyway.
Therefore, it appears better to perform rank aggregation using an optimization framework as we do.
In this paper, we have proposed a new approach to rank aggregation: Supervised Rank Aggregation.
Our method is mainly designed for meta-search and is unique in that (a) takes order information from base rankers, (b) it makes use of labeled training data, and (c) it trains the final ranking function within a single optimization framework.
We have set up a general framework for employing the approach.
Specifically, we have formalized the learning problem as that of optimization.
We propose an efficient algorithm to solve the optimization for one of the typical rank aggregation settings, namely the Markov chain based method.
We have compared the performances of our proposed method with those of existing methods on meta-search.
The results show that the proposed method can outperform the existing methods.
The contributions of this paper include 1) proposal on employing the supervised learning approach for rank aggregation;
 formulation of the supervised learning approach as an optimization problem;
 Chain based learning method; and
 empirical verification of the effectiveness of the proposed approach.
As future work, we plan to apply the techniques used in this paper to other supervised learning methods, and to apply the methods to other applications such as similarity search and genome informatics.
The authors would like to thank Wei-Ying Ma at MSRA for his suggestions and comments on this work.
They are also grateful to Shisheng Li at USTC for his helps in the experiments.
The authors would also like to thank the anonymous reviewers for their valuable comments on the paper.
