Geospatial applications on the World Wide Web are quickly growing in popularity.
Web based mapping applications like Google Maps, Yahoo Maps or Microsoft Windows Live Local, as well as 3D geo-browsing applications like Google Earth or NASA World Wind have attracted considerable interest among Web users and developers alike.
Communities in geographically related activities have emerged: By geo-tagging Web pages, RSS feeds or photos on photo sharing sites, users are essentially assigning Web content a location in the real world.
By using open APIs and online mapping toolkits to build map mashups, developers are demonstrating how this geospatial data can be brought to new use for a variety of purposes   from education, to planning of day-to-day activities, to entertainment.
Meanwhile, new types of mobile phones and handheld computing devices are appearing on the market: Combining powerful processors, high resolution displays, wireless LAN or 3G mobile that engage Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
network connectivity with navigation-related features like GPS receivers or digital compasses, these devices promise to drive the adoption of mobile geospatial services and applications in the near future.
In this paper, we discuss the development of mobile geospatial applications in the light of these recent trends.
We remark the discrepancy between mobile applications today, and the unique possibilities offered by new location and orientation-aware devices.
We present an application framework that allows developers to create innovative geospatial user interfaces on high-end devices with advanced navigation features, but at the same time retain interoperability with more conventional devices.
The paper is organized as follows: (cid:131) Section 2 discusses related work, focusing in particular on new types of user interfaces enabled by the combination of location and orientation-awareness.
(cid:131) Section 3 discusses the development of mobile geospatial Web applications using current tools and technologies.
We identify three functional steps of mobile location-based interaction and illustrate them by an example.
Based on the example, we derive requirements for a generic application framework.
(cid:131) Section 4 introduces our application framework, which meets the requirements derived in Section 3.
(cid:131) (cid:131) Section 5 describes the Local Visibility Model, a device independent XML format for local geospatial data, which is the key innovation of our framework.
In Section 6, we apply our framework to the example from Section 3: Due to the Local Visibility Model, the example application can retain its user interface on conventional location-aware devices, while at the same time offer a more compelling user experience on devices with compass and tilt sensors.
(cid:131) Section 7 concludes with a summary and an outlook on future work.
Research on location-aware interaction has been actively pursued for several years.
A number of research projects have experimented with the scenario of attaching digital information to real-world locations like a virtual post-it note or digital graffiti [4], [7], [18].
By using location aware devices, users can discover and access this information, participate in collaborative mapping activities or engage in location-based social interactions [19], [26].
Other efforts have focused on specific sub-domains within the field of mobile geospatial interaction: Extensive research has, anonymity problem associated with the accumulation of user location data [3], [5], [31].
Also, the reliability and accuracy problems of GPS in urban areas, where GPS signal shadowing occurs frequently, have been examined: Alternative positioning methods better suited for urban or indoor environments have been proposed, for example technologies that rely on known locations of wireless LAN and/or GSM cell tower radio beacons [16], [17]; other approaches seek to mitigate the impact of GPS positioning inaccuracy on the user experience by informing the user about it rather than concealing it [37] or, in fact, by exploiting it at as a design resource, for example in the context of multiplayer gaming [2].
We consider all of these activities important prerequisites for our work.
The primary topic addressed in our paper, however, is the interaction between user and geospatial information.
Most mobile geospatial applications today replicate the GUI metaphors of the desktop: Mobile versions of established services like Yahoo!
local search [40] or driving directions [39], as well as mobile versions of Google Maps [11], [21] are merely downsized versions of their large-screen counterparts that shrink the same user interface onto the tiny mobile device.
As empirical research has shown, however, it is inappropriate to apply desktop idioms to mobile user interfaces [15]: mobile users are typically occupied with real-world tasks; interactions are rapid and driven by the external environment [25].
Their intentions are likely to be more immediate and goal-oriented than those of desktop users [35].
User interfaces that demand too much visual attention are therefore problematic, and fact may even be a potential hazard in some situations [37].
As a result, considerable efforts have been made to develop alternative user for mobile geospatial applications: Based on the technology of Geographic Information Systems, Egenhofer [6] predicted Spatial Information Appliances   portable tools for professional users as well as a public audience, interaction metaphors than desktop applications: Smart Compasses that point users into the direction of points of interest, Smart Horizons that allow users to look beyond their real-world field of view or Geo-Wands   intelligent geographic pointers that allow users to identify geographic objects by pointing towards them.
Further related work in this direction includes Wasinger et al [36], who equipped a mobile device with a digital compass to realize Geo-Wand-like pointing functionality, as well as Mitchell et al [20] and Strachan et al [30] who applied similar concepts in the context of a mobile multiplayer game and a handheld audio navigation tool, respectively.
Recent commercial efforts that aim to bring orientation-aware geospatial applications to the market include [10] and [13], as well as the activities of several well-known mobile handset manufacturers who are beginning to introduce a growing number of mobile phone models with suitable hardware features: for example phones with integrated GPS (e.g.
[1], [24] and [28]), with GPS and compass (e.g.
[10]), as well as mobile phones with accelerometer-based tilt sensors [23], [27].
Our work is motivated by the vision that mobile phones will soon serve as generic hard and software-platforms for a variety of fundamentally different interface concepts relying on Spatial Information Appliances.
The necessary advanced navigation features are being integrated into state-of-the-art mobile devices now and can be expected to be even more widespread in the near future.
We argue that, as a next step, an open, standardized application framework that allows developers to experiment with the innovative features offered by these devices: In the same way that open Web APIs and desktop mapping toolkits have fostered the formation of an avid community of map mashup developers on the desktop, such a framework can potentially leverage innovative geospatial Web applications on the mobile platform.
is needed Figure 1.
Wikipedia Finder example application.
In this section, we therefore derive a set of requirements for such a framework.
Using a simple location-based application as an example, we discuss some of the issues that developers need to address when building mobile geospatial Web applications with current tools and APIs.
We thereby want to define the term  mobile Web application  in a slightly broader sense, insofar as we include in this definition all applications that use the Web as communication medium, even if they do not necessarily run in a Web browser.
In that sense, we explicitly include applications that use dedicated client-side software (i.e. software that must be manually installed to the device, unlike e.g.
JavaScript code that is embedded in a Web page).
Figure 1 shows a photo and an emulator screenshot of the application we use as our example: The application was implemented on a GPS-enabled PDA, runs in the device s browser and lists geo-coded Wikipedia articles related to landmarks in the user s vicinity.
Figure 2.
Geospatial application client/server interaction flow.
is rendered on search parameters).
Depending on For the sake of discussion, we subdivide the sequence of a location-based interaction between mobile client and server into three functional steps, as shown in Figure 2: Positioning, i.e. the acquisition of information about the mobile client device s location.
Depending on the positioning method, this step may require actions on the client-side (e.g.
in case of GPS positioning), or on the server-side (e.g.
in the case of network based positioning methods [17]).
Spatial selection of content based on the device s location (and possibly the application, this step may involve querying a spatial database, an online data source over a Web-based geospatial search API, or any other proprietary mechanism to select a subset of geo-referenced content from a larger content base.
Preparation of the content for presentation on the client device.
Depending on the application architecture, this functional step may be performed in either the mobile domain (e.g.
if application-specific XML data is transferred over the wireless link and parsing/formatting is done on the client) or in the server domain (e.g.
if the server transforms the spatial query result into an XHTML page, which the client without modification).
The possibility to determine the user s location is obviously the primary prerequisite for building location-based applications.
Low-cost standalone Bluetooth GPS receivers and recent PDAs and smartphones with integrated GPS make it possible for developers to include location in their applications, without resorting to costly mobile network operator-provided location services [17].
To date, however, it takes considerable effort to integrate GPS with Web-based applications: Dedicated client-side software is required to obtain location coordinates from GPS (or alternative client-side positioning technologies) and communicate them to the server.
We expect that in the future, devices with integrated GPS will most likely feature a JavaScript API for accessing GPS from within the browser.
This way, location-based applications are no longer dependent on proprietary code that must be installed to the device separately.
Meanwhile, however, we worked around this limitation by using a custom ActiveX control.
The control can be embedded in a Web page, where it exposes a proprietary JavaScript interface to the GPS.
The rest of the application is browser based; GPS coordinates are transported to the server in the query string of the HTTP requests.
Discussion.
We note that it is not yet possible to develop mobile geospatial applications that can perform the functional step of positioning without resorting to proprietary client-side code.
This potentially hinders the quick mass-market adoption of mobile geospatial Web applications.
We therefore underline the need for a standardized API to access location from within the browser.
Since client-side operating system and device-hardware-specific aspects are, however, beyond the scope of our work, we do not derive any particular requirements for our framework for the functional step of positioning.
Unlike a traditional Web search query, which is defined by keywords and Boolean expressions, a geospatial search is defined by (or includes) a geographical area expression.
In the case of our example implementation, the Wikipedia search feature of the geonames.org online geographical database is used to select articles related to the vicinity of the mobile user.
The database features a convenient API that allows specifying a radius around the user s location (or, alternatively, a geographical bounding box).
References to articles inside the specified area   together with article-specific meta-data and distance information   are returned in an XML document1.
Discussion.
Spatial queries based on an extrinsic reference frame, such as a bounding box or a radius around a center location, are currently the standard query mechanism supported by spatial databases and Web-based geospatial search APIs.
This query mechanism reflects the interaction metaphor used on the desktop well: e.g.
on a map interface, a user might compose the search query visually, by dragging a rectangle on a graphical map.
We argue, however, that it is not ideal to apply the same metaphor to mobile geospatial search: Unlike a desktop user with a top-down view on a map, the mobile user is physically immersed in the geographical region associated with the search space.
Gardiner and Carswell [9] have found that a deictic reference frame, which is relative to each individual in the search space, can be considered more relevant for mobile-based search.
As a user study conducted by the authors has furthermore confirmed, the concepts of field of view and visibility are indeed relevant criteria for information discovery in a mobile context [8].
Requirements.
We conclude that while geospatial search is becoming available on the Web, current APIs are based on map-and desktop-centric query metaphors such as bounding boxes or circular search areas around a center location.
In accordance with [9], we require that a mobile geospatial application framework must offer geospatial query mechanisms defined by visibility and field of view.
An immediate consequence that arises out of this requirement is the need for three-dimensional map data, as we will discuss in more detail in Section 4.
Following the spatial selection process, the selection result is formatted for presentation on the mobile device.
In our example application, this is performed on the server, by populating a generic XHTML template with the search results retrieved from the geonames database.
Discussion.
In our example, the only device that accesses our service is the test device.
In realistic scenarios, however, the developer s control over the range of client devices is far more limited: The principal dilemma of mobile Web authoring, which is to ensure consistent presentation and optimized user experience across a broad range of client devices that differ substantially in form factor, screen size and supported markup and scripting standards, has been generally acknowledged [29], [33], [34].
The advent of mobile devices equipped with advanced navigation sensors introduces an additional degree of freedom to the user interface design process: Devices may potentially feature an arbitrary combination of sensors   from location-only (e.g.
GPS) to full 3D orientation (e.g.
by combining GPS with compass and tilt sensors).
This further complicates the development process, since the developer may not only need to adapt the visual appearance, but in fact the entire interaction model of the user interface: For example, a user interface based on direction   such 1 http://www.geonames.org/export/wikipedia-webservice.html spatial selection is handled by the framework s visibility query engine that operates on a 2.5-dimensional environment model stored in a PostgreSQL/PostGIS spatial database.
Furthermore, a content interface module connects an arbitrary database, file or remote source of geospatial content to the framework.
The content interface must be provided by the application developer, based on our framework s API.
A traditional spatial search query only operates on the content: i.e.
the geographical search area expression is applied to the dataset, and those data points that lie within the specified area limits are returned as the query result.
In the case of a visibility based query, on the other hand, it is necessary to consider an additional layer of information: The user s field of view must be constructed dynamically, based on the surrounding environment.
Since we generally expect the content dataset to be three-dimensional (i.e. each data point is defined by longitude, latitude and altitude), a three dimensional environment model is needed to compute the query result.
Our framework implementation relies on a 2.5D block model of the environment, i.e. each building in the model is represented by a two-dimensional footprint polygon, which is extruded by a height value.
Until recently, the cost for producing such models (by means of surveying) was prohibitive.
Current technologies, such as automatic or semiautomatic building reconstruction from high-resolution aerial imagery [22] and/or LIDAR (LIght Detection And Ranging) scans [12], however, have greatly three-dimensional simplified environment data, allowing even textured reconstruction of entire cities [14] at comparably reasonable cost.
This has lead to a more widespread use of 3D models for a variety of purposes   from urban development to mobile phone radio network planning.
Two datasets were used in our implementation: First, a small sample dataset was produced manually for testing purposes, based on a traditional two dimensional map and approximated building heights.
The dataset covers an area of roughly 1x1 km around our office premises (an architecturally rather unusual business district in the North of Vienna, Austria) and is shown in the left image in Figure 4.
the gathering of large-scale for detailed as the Smart Compass   is impossible to adapt to a device without integrated compass.
The developer must therefore provide an alternative user interface that may differ substantially from the compass interface, such as a text or map-interface.
Requirements.
In line with the first two principles of the W3C s Mobile Web Best Practices (MWBP) guidelines [35], we derive the following two key requirements for our mobile geospatial Web application framework: (cid:131) The framework must enforce thematic consistency (best practice no.
1 of the MWBP guidelines) by providing a single, unified data output format that is suitable for all mobile devices, regardless of their navigation sensor feature set, and regardless of the interaction model the developer chooses to implement.
(cid:131) The framework must encourage developers to best exploit the capabilities of devices to provide an enhanced user experience (best practice no.
2 of the MWBP guidelines): On the one hand, it must be possible to derive a usable low-fidelity presentation on client devices with limited computational power, graphical output capabilities and navigation features, e.g.
by transforming the output format into meaningful text.
On the other hand, the framework should promote more complex real-time user interfaces on full-featured devices, such as interfaces based on the idea of Spatial Information Appliances.
In this section we describe our framework implementation.
The framework features a geospatial query engine that selects content based on its visibility from the user s location, thus meeting the first requirement stated in Section 3.
The query results are returned in a novel, device and presentation-agnostic XML data exchange format which fulfills the remaining requirements identified in Section 3: to enforce thematic consistency and encourage developers to exploit the capabilities of novel devices.
The framework is implemented as a Java library and is designed so that it can either be included seamlessly into a Java application, or operate as an external service over a Web-based API.
Figure 3.
Framework interaction flow.
Figure 3 shows the sequence of a location-based interaction between mobile client and server using our framework: The sequence corresponds to the original process depicted in Figure 2.
However, it now includes several new components: First, the Figure 4.
Environment model test datasets.
A second, professionally surveyed block model was provided by a project partner.
The dataset has identical properties   i.e. each building is represented by a single polygon and height value   and right image.
The spatial selection process of our framework s query engine consists of two steps: In the first step, the query engine retrieves the 2.5D environment model of the region around the queried location from the database.
In the same step it also retrieves the content that is located within this region.
(As mentioned, it is therefore necessary that the developer provides an interface implementation that translates the framework s bounding box request to the syntax of the application-specific content source.)
In the second step, the query engine performs the actual visibility detection: Per default, only those data points are included in the result data set that have a clear line of sight between query location and content location.
In case a data point is located inside a building, this building is not considered in the visibility detection, i.e. points inside buildings are considered visible, if the building itself is visible from the user s point of view, as shown in Figure 5.
Figure 5.
Spatial selection: line of sight.
The query engine can also be configured to include hidden data points in the result.
In this case, however, the result syntax clearly distinguishes visible from hidden data points (see Section 5.1).
In accordance with the requirements defined in Section 3, we developed a novel XML data exchange format for the query results returned by our query engine.
The format is designed with the idea of the Spatial Information Appliance in mind: It allows developers to embrace the innovative features offered by novel mobile devices as they become available on the market; however without limiting them when developing for more conventional devices that do not feature advanced navigation features.
The XML format can serve as a single, unified model for a multitude of geospatial user interfaces, thus ensuring thematic consistency across presentation types and interaction modes.
In the following section, we present our presentation-agnostic XML query result format: the Local Visibility Model   or LVis in short (pronounced  Elvis ) in detail.
The Local Visibility Model is a simplified, egocentric abstraction of the search result space.
The LVis is novel insofar as it retains the geometrical structure of the search result in three dimensions.
Since it relies on standard units and measurements (i.e. meters and decimal degrees), meaningful textual output can be produced by simply styling it accordingly, e.g.
by using XSLT.
Due to the fact that the LVis uses a polar coordinate notation, direction-based user interfaces that would normally require transformations from Cartesian to polar coordinate space (such as e.g.
the Smart Compass or the Geo-Wand) can be realized with considerably reduced development effort.
In order to keep the barrier of entry low for developers previously not involved in geospatial application development, the LVis uses simple spatial modeling metaphors to describe the geometrical arrangement of the search result space: Points of Interest (POI) and Billboards.
The result of a traditional geospatial search query is normally a set of references to geo-coded content.
The references are typically point-shaped, i.e. they are represented by a single geographical coordinate.
(Therefore, the data points in the search result set can be visualized with graphical markers on a map, along with a list of associated hyperlinks.
This common way of visualizing geospatial search results on the Web is also referred to as the map-and-hyperlink architecture [32].)
Point-shaped geo-coded content of is represented in the LVis as a so-called Point of Interest (POI).
Since the LVis uses a polar coordinate notation, each POI is defined by its distance, heading and elevation relative to the user.
This way, a textual description of the POI (e.g.
 There is a Snack bar located 200 meters to the North ) can be produced without the need for complex computations.
<poi id="poi026" name="Snack Bar" descr="Snack bar near subway station" href="http://www.asnackbar.com/" lng="16.4142" lat="48.23221" alt="178" d="117" hdg="95" elev="5" /> Figure 6.
LVis poi ( Point of Interest ) XML element.
the described type Figure 6 shows an XML code sample for the poi element: The id attribute is a unique identifier for the POI.
The name attribute provides a short, descriptive name that the GUI designer can use to create e.g.
a graphical label.
The descr attribute provides a longer textual description of the POI which can e.g.
be used as help text.
The href attribute contains a URL associated with the
 The lng, lat and alt attributes denote the longitude, latitude and altitude of the POI, i.e. its absolute geographical location.
The attributes d, hdg and elev describe the relative location of the POI with regard to the user: d denotes the distance from the user, expressed in meters.
hdg is the compass heading of the POI, i.e.
the direction the user must turn to face the POI.
The heading is always expressed as an integer value in decimal degrees and lies in the range between 0 and 359.
The elev attribute represents the elevation (or tilt) angle of the POI, i.e. the altitude at which the user must point to aim directly at the POI.
In the example from Figure 6, the user would therefore need face eastward, at a heading of 95 degrees, and point almost horizontally (at a 5 degrees upwards angle) to aim directly at the POI.
As mentioned in Section 4.2, only POI that are directly visible from the user s point of view are included in the LVis per default.
If the query engine is configured to also include hidden POI in the LVis, these POI will be expressed by a different XML element   as the poi element.
Unlike a traditional map-and-hyperlink Web search result, which consists only of points of interest, the LVis also includes the actual geometry of the environment in the query result.
This means that the query does not only return the content in the search space, but in fact it also returns a simplified three-dimensional geometrical representation of the 3D search space itself along with the content.
The motivation for this approach was twofold: (cid:131) First, we argue that local knowledge of the environment geometry on the mobile device is an interesting design feature for some advanced sensor driven interfaces.
(For example, in Figure 15 in Section 6.2, we present a type of user interface that presents the spatial query result in a schematized panorama view of the environment.)
(cid:131) Second, we argue that locally stored geometry is a necessary prerequisite for real-time user interfaces: If the client has information about the three-dimensional structure of the vicinity, it can react to changes from integrated sensors without the need to re-query the server.
For example, the client might be able to recompute distances, headings or the visibility of points of interest locally, as the user moves through the environment.
Traditional vector geometry or geographic data formats like the Geography Markup Language (GML) describe geometry using polygons or geometric primitives in Cartesian 2D or 3D space.
They are therefore not human-readable as such and require complex client-side processing to produce visual output.
Since this conflicts with our design goal of keeping the LVis presentation-agnostic and, in particular, suitable for textual output, we decided to rely on a simpler, abstracted concept to describe geometry: The LVis models the environment using a billboard metaphor.
A billboard approximates a geographic feature, e.g.
a building, by a flat, rectangular wall that faces directly towards the user.
Essentially, the LVis can be thought of as a 360-degrees panoramic  cardboard cutout  version of the search space, much like a movie set where the environment is not made up of solid buildings, but instead of building facades.
Since billboards are   like POI   described in polar coordinates, textual descriptions of nearby buildings (e.g.
 There is an Office Building 150 meters to the South ) can be directly derived from the XML code without the need for arithmetic computations.
Figure 7 shows the principle of how our query engine produces a billboard: The illustration shows a top-down view of a building footprint in the environment model (compare Figure 4).
First, the visible cross section of the building, seen from the query location, is determined.
The billboard is then computed by intersecting the cross section s center line with the building shape and computing a normal to the center line.
Figure 7.
LVis billboard generation principle.
<billboard id="bldg019" name="Tech Gate" descr="Tech Gate Office Building" href="http://www.techgate.at/" lng="16.4094" lat="48.232" alt="183" d="42" hdg="125" elev="28" hwidth="41" vwidth="18" /> Figure 8.
LVis billboard XML element.
Figure 8 shows a code sample for the billboard XML element.
The billboard element has all the attributes of the poi element (id, name, descr, href, lng, lat, alt, d, hdg and elev).
Since the billboard also has a spatial extension, it features two additional attributes, namely the hwidth and vwidth attributes: While d, hdg, and elev denote the distance, heading and elevation of the billboard s center, the hwidth and vwidth attributes provide the horizontal and vertical width of the billboard, respectively.
Like hdg and elev, both attributes are expressed in decimal degrees, with a range of values between 0 and 180 degrees.
hdg
 (lat/long) hwidth




 elev elev vwidth vwidth

 Figure 9.
LVis attributes and geometrical arrangement.
In order to better clarify the relation between the attribute values and the corresponding geometrical arrangement, Figure 9 illustrates a representative example.
The query engine uses a basic scan-line algorithm to determine occlusions among individual billboards (compare [9] for a similar approach).
In order to speed up the billboard occlusion detection process, the algorithm does not compute occlusions among the actual buildings.
Instead, it replaces each building in the scene by its visible cross section in a first step (compare Figure 7).
Each cross section is then checked for full or partial occlusions against every other cross section in the scene.
Since the complexity of this algorithm rises squared with the number of buildings in the scene, a more efficient algorithm based on guided visibility sampling [38] is currently being integrated into the framework implementation.
The result of a complete LVis computation performed by our query engine is shown in Figure 10: The top part of the image shows the computed LVis in a top-down view; the bottom part of the image shows a 360 degrees panoramic visualization of the result.
Visible POI are indicated as small dark rectangular dots, hidden POI are indicated in lighter color.
To make the billboards easier to recognize in the top-down view, a  viewing beam  extends from the query location to each billboard, with beams of lighter color indicating higher billboards.
In the panoramic view, rectangles of lighter color represent more distant billboards.
Figure 12.
Buildings covering >180  field of view.
Based on our application framework, we implemented a modified version of the Wikipedia Finder from Section 3, which fully integrates with the framework: HTTP requests from the client are handled by a Servlet, which queries the framework with the GPS coordinates retrieved from the HTTP request.
The framework computes the LVis from the 2.5D environment model and the content retrieved from the geonames database, and returns it to the Servlet, which forwards it to the client in the body of the HTTP response.
In this section, we demonstrate some of the user interfaces that are possible on devices with different sensor capabilities, due to our framework and the LVis.
On the GPS-enabled PDA, the client-side JavaScript code was modified.
The new script periodically retrieves a new LVis from the server using a background XMLHttpRequest and updates the user interface accordingly.
The appearance of the user interface remains identical, with the only exception being that visible Wikipedia articles are now distinguished from hidden ones by a different background color in the list, as shown in Figure 13.
Figure 10.
LVis computation result.
Although the LVis has so far proven to be a useful data model for realizing different types of geospatial user interfaces (compare Section 6.2), there are two distinct limitations: Arched Buildings.
Our framework currently relies on a 2.5D block model, i.e. every building is modelled as a solid, extruded polygon.
As a particular consequence, neither the framework nor the LVis can describe arched buildings: For example, since the facade of the building shown in Figure 11 is represented in the model by a solid wall, the query algorithm will consider all POI behind that building as hidden, even though the user might actually be able to see them through the passageway in reality.
Figure 11.
Arched Building.
Buildings that cover more than 180 degrees of the user s view.
Per definition, a billboard cannot model buildings that surround the user, i.e. that cover more than 180 degrees of the user s field of view, as shown in Figure 12.
We addressed this inherent limitation of the billboard principle with the following strategy: Every building that covers more than 180 degrees of the users view is always modelled using three equal-width billboards instead of one.
This way, all buildings that cover between 180 and 360 degrees or the user s field of view can be expressed.
Figure 13.
Modified Wikipedia Finder on GPS-enabled PDA.
Due to the novelty of mobile devices that combine integrated GPS and compass, no suitable commercial test device was available to us at the time of writing.
In order to demonstrate how our framework can support alternative types of geospatial user interfaces on such devices nonetheless, we developed an improvised prototype device, as shown in Figure 14.
developers can implement sensor-driven interfaces like Geo-Wands or Smart Compasses without sacrificing interoperability with conventional mobile devices.
We described our implementation of a visibility-based query engine that operates on a 2.5D environment block model, discussed its current limitations, and presented a set of mobile user interface implementations built with our framework.
The focus of our upcoming work lies on prototyping and testing: User trials will not only provide us with a better insight into how GPS and sensor inaccuracy affects the overall system operation, it will also guide the further evolution of the LVis.
Concepts for level-of-detail modeling, as well as the assessment of the billboard metaphor s for modeling non-urban environment, and embedded navigation information are among the topics that will be addressed: Levels of Detail.
A fundamental design goal of the LVis was to keep modeling concepts and syntax as simple and presentation-agnostic as possible.
As a consequence, no true 3D geometry was included.
First feedback to our work has shown, however, that billboards may be a too simplistic modeling metaphor.
We therefore plan to investigate how the LVis can be extended towards including 3D geometry, without compromising its simplicity and compactness, e.g.
by following a level-of-detail approach, where 3D data is included only for nearby buildings, while faraway features are modeled as billboards.
Non-urban terrain.
While the billboard metaphor has so far proven useful for modeling urban environment, it is unclear whether the same metaphor can also be applied to geographic features in rural terrain.
Tests will show whether it is reasonable to model topographical features like mountains or hills using billboards, or whether an alternative model should be applied.
Navigation Primitives.
As further feedback to our work has shown, way-finding turn-by-turn walking directions are considered a desirable feature in many application scenarios.
In order to enable developers to easily include this functionality seamlessly with their applications, we intend to embed this information directly into the LVis, by introducing new XML elements that describe routes or waypoints towards particular (hidden) POI or billboards.
The work presented the this paper Telecommunications Research Center Vienna s P2D   Point to Discover project (http://p2d.ftw.at/).
P2D is funded by mobilkom austria, Siemens Austria and the Kplus competence centre programme.
P2D was further supported by the SUPRA strategic research project.
