At present there is a large gap between Knowledge Management (KM) systems and the natural language materials that form something approaching 80% of corporate data stores [22].
Similarly, Gartner reported in 20021 that for at least the next decade more than 95% of human-to-computer information input will involve textual language.
They also report that by 2012 taxonomic and hierarchical knowledge mapping and indexing will be prevalent in almost all informa-tion-rich applications.
There is a tension here: between the increasingly rich semantic models in KM systems on the one hand, and the continuing prevalence of human language materials on the other.
The process of tying semantic models and natural language together is referred to as semantic annotation.
This process may be characterised as the dynamic creation of interrelationships between ontologies and unstructured and semi-structured documents in a bidirectional manner.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
Information Extraction (IE), a form of natural language analysis, is becoming a central technology for bridging the gap between unstructured text and formal knowledge expressed in ontologies.
Ontology-Based IE (OBIE) is IE which is adapted speci cally for the semantic annotation task.
One of the important di erences between traditional IE and OBIE is in the use of a formal ontology as one of the systems inputs and as the target output.
The main contribution of this paper is in investigating the application of hierarchical classi cation learning to semantic annotation, as part of an ontology-based IE system.
Hierarchical classi cation takes into account the relations between concepts, thus bene ting directly from the ontology.
In particular, this paper studies the large margin hierarchical classi cation learning algorithm Hieron proposed in [8], because it is very e cient during both training and classi cation.
Computational e ciency is of major importance for OBIE, because depending on the size of the ontology, the system may need to train hundreds of classi ers.
However, it should be noted that work presented in this paper is not a simple application of the Hieron algorithm, as proposed in [8].
In fact, OBIE speci cs lead to two important modi cations: introduction of multi-loop learning and a parameter which makes the algorithm applicable on any IE corpus.
Both of these resulted in a quanti able improvement in performance (see Table 6 in Section 5).
In addition, semantic annotation is very di erent from document classi- cation, which is what Hieron was originally developed for.
Consequently, another contribution of this work is in showing how OBIE can be decomposed into several hierarchical classi cation tasks, which can then be approached with an algorithm such as Hieron.
Another important contribution of this work is in the use of the Sekt2 ontology-annotated news corpus for evaluation.
To the best of our knowledge, it is the only corpus suitable for evaluating OBIE, which has a nontrivial number of classes (146 classes) from an independetly created ontology.
The problem with using only the Sekt corpus is that no other systems have been evaluated on it, apart from the SVM and Perceptron ones reported here.
Unfortunately other recent corpora for IE evaluation (e.g., Pascal chal-lenge3, CONLL 034) are either not fully available or use a further information on the Sekt project,
 see http://www.sekt-project.com.
The corpus itself is available on request from the second author.
4http://www.cnts.ua.ac.be/conll2003/ner/ inappropriate for experimenting with semantic annotation on a realistic scale.
The experimental results demonstrate that our hierarchical classi cation algorithm obtains clearly better results than SVM and Perceptron both in terms of conventional precision and recall and also according to an ontology-induced metric.
Additionally, in order to provide some comparison against state-of-the-art learning IE systems, we also evaluate our Hieron-based system on the seminar corpus, where it achieves the best overall performance.
The paper is structured as follows.
Related work on onto-logy-based IE is discussed in Section 2 and our work is placed in that context.
Section 3 introduces the large margin hierarchical classi cation algorithm Hieron, our modi cations to it, the hierarchy-based cost measure, which Hieron requires, and the way in which the OBIE task is formalised as a classi cation problem.
The Sekt ontology-annotated gold-standard is described next (section 4), followed by a comprehensive set of experimental results and their analysis (section 5).
The paper concludes with a discussion and plan for future work.
Previous work can be regarded as being either ontology-oriented or ontology-based.
Ontology-oriented IE systems do not incorporate the target ontology into the IE process, but typically have a mapping between the IE outputs and classes and instances from the ontology.
Ontology-based IE systems go one step further by also using the ontology as one of the inputs to the IE algorithms.
Next we review  rst some ontology-oriented systems.
AeroDAML [16] applies IE techniques to automatically generate DAML annotations from web pages.
AeroDAML uses an ontology which is used to translate the extraction results into a corresponding RDF model.
Amilcare [6] is an IE system which has been integrated in several di erent semantic annotation tools (MnM [21] and SCREAM [14]).
It uses supervised rule learning to adapt to new domains and applications.
It treats the semantic annotations as a  at set of labels, thus ignoring knowledge from the ontology.
One of the problems with these annotation tools is that they do not provide the user with a way to customise the integrated language technology directly.
While many users would not need or want such customisation facilities, users who already have ontologies with rich instance data will ben-e t if they can make this data available to the IE components.
However, this is not possible when  traditional  IE methods like Amilcare are used, because they are not aware of the existence of the users ontology.
The more serious problem however, as discussed in the SCREAM system [14], is that there is often a gap between the IE output annotations and the classes and properties in the users ontology.
The proposed solution is to write some kind of rules, such as logical rules, to resolve this.
For example, an IE system would typically annotate London and UK as locations, but extra rules are needed to specify that there is a containment relationship between the two (for other examples see [14]).
However, rule writing of the proposed kind is too di cult for most users and therefore ontology-based IE is needed, as it annotates directly with the classes and instances from the user s ontology.
In response to these problems, a number of OBIE systems have been developed.
Magpie [10] is a suite of tools which supports semantic annotation of web pages.
It is fully automatic and works by matching the text against instances in the ontology.
The SemTag system [9] is similar in approach to MagPie as it annotates texts by performing lookup against the TAP ontology.
It also has a second, disambiguation phase, where SemTag uses a vector-space model to assign the correct ontological class.
The problem with both systems is that they are not able to discover new instances and are thus restricted in terms of recall.
The C-PANKOW system [5] exploits surface patterns and the redundancy on the Web to categorise automatically named entities with respect to a given ontology.
The advantage is that it is an unsupervised method, which requires little or no training data.
However, this is also its main disadvantage, because the accuracy of its semantic annotation is not yet su ciently close to that of systems such as KIM and ours.
However, it would be interesting to explore in future the possibility of combining our approach with a web-based system such as C-PANKOW OntoSyphon [20] is similar to C-PANKOW and uses the ontology as the starting point and carries out web mining to populate the ontology with instances.
It uses the ontology structure to determine the relevance of the candidate instances.
However, it does not carry out semantic annotation of documents, which is the problem addressed here.
The KIM OBIE system [15] produces annotations linked both to the ontological class and to the exact individual in the instance base.
For new (previously unknown) entities, new instances are added to the semantic repository.
KIM has a rule-based, human-engineered IE system, which uses the ontology structure during pattern matching and instance disambiguation.
The only shortcoming of this approach is that it requires human intervention in order to adapt it to new ontologies.
To summarise, the di erence between our approach and the ontology-oriented systems is that we use the ontology as input to the IE process, not just as an output target.
In comparison to other ontology-based approaches, our system addresses the limitations of earlier work by using machine learning for easy retargeting, exploiting the ontology structure, and carrying out semantic annotation, in addition to ontology population.
Conventional IE uses labels that have no speci c relation among each other, i.e., they are treated as independent the learning algorithms (e.g., Person, Location).
In contrast, as concepts in an ontology are related to each other (at the very least through the subsumption hierarchy), it is bene cial to feed this knowledge into the OBIE algorithms.
This section exploits two aspects of using the ontology structure for OBIE.
First it discusses ontology-induced measures, which are then used by the learning algorithm, in addition to calculating some distance-based metrics.
Secondly, it introduces the Perceptron-based learning algorithm Hieron which has a mechanism to handle e ectively hierarchical classi cation and our adaptations of Hieron for the OBIE requirements.
As concepts in ontologies are related to each other in a subsumption hierarchy, the cost (or loss) for an instance of a concept X being wrongly classi ed as belonging to another concepts (denoted as c(X, Y )).
Given this cost measure, one OBIE requirement is that if the system misclassi es a mention in the text as belonging to class Y, instead of X, the cost of that misclassi cation should be as small as possible, (e.g., classify it as a super-class of the correct class).
IE systems traditionally use evaluation metrics, such as precision, recall and F1, which are computed for each category, independently of all other categories.
An overall performance measure is obtained by averaging the performances for all categories (namely macro-averaged) or by putting together all the results of all classi cations (micro-averaged).
However, this type of measures do not take into account the hierarchical relations between classes in the ontology and their associated misclassi cation costs.
Consequently, another OBIE requirement is to have performance metrics which are sensitive to the structure of the target ontology.
Therefore, next we generalise the commonly used IE metrics, precision, recall and F1 to ontology-based ones.
In order to evaluate an OBIE system on a corpus annotated with a given ontology, we  rst compute the following three numbers on the system-annotated corpus:   n   number of mentions which are instances of concepts in the ontology and have been found by the OBIE system (regardless of whether or not OBIE assigned them to the correct class).
  nmissing   number of entities in the corpus which are instances of concepts in the ontology but are not found by the system.
  nspurious   number of the entities recognised by the system which actually are not an instances of any concept in the ontology.
Then for each pair of concepts X and Y we de ne the cost measure c(X, Y ) as a non-negative number, equal to 0 if
 If we assume that C is the largest cost for a given ontology, then we can de ne a cost based error as ecost(X, Y ) = c(X, Y )/C, satisfying that ecost(X, Y )   [0, 1] and ecost(X, Y ) = 0 if X = Y .
Based on this cost-based error, an overall accuracy for the n entities identi ed by the system is de ned as follows: acost = n Xi=1 (1   ecost(Ai, Bi)) (1) where Ai and Bi are two classes in the ontology and ecost(Ai, Bi) is the cost of misclassifying the ith entity as an instance of class Bi, instead of its correct class Ai (class Bi is the same as Ai if the ith entity is classi ed correctly).
Using the overall accuracy acost we de ne ontology-based precision and recall, respectively, as Po = acost/(acost + nspurious), Ro = acost/(acost + nmissing ) Then, as with conventional f-measure, the ontology-based F1 is de ned as the harmonic mean of ontology-based precision and recall: Fo1 = 2   Po   Ro/(Po + Ro) (2) In other words, ontology-based Fo1 is a generalisation of the standard F1.
In fact, if we de ne the cost c(X, Y ) as the binary function c(X, Y ) =   0 if X = Y 1 otherwise (3) then Fo1 would be reduced to the standard overall F measure.
Recent studies of hierarchical classi cation (see e.g.
[8,
 the two nodes X and Y in the classi cation hierarchy.
In our experiments we used the distance between two classes in the ontology as their misclassi cation cost and henceforth this is referred to as the distance-based metric.
It should be noted that there are some improvements on the distance-based cost metric.
For example, [23] propose a measure based on information content and experimentally showe that the new measure is better than the cost-based one for measuring the similarity of nouns.
[19] present the BDM measure which, besides the shortest distance of the two concepts, takes into account the depth of the most spe-ci c common concept of the two concepts and the size of ontology.
[25] present an overview of cost measures used in hierarchical classi catioin research.
An ongoing work of ours is experimenting with such improved versions of cost-based metrics with Hieron and OBIE.
The Hieron large margin learning algorithm for hierarchical classi cation was de ned by [8], based on the margin Perceptron algorithm.
Hierarchical classi cation refers to a speci c multi-class classi cation problem where the class labels are organised in a hierarchical fashion.
One example is document categorisation where categories belong to a taxonomy.
Here we brie y describe the learning algorithm and discuss our modi cations to the original algorithm and then discuss how to apply it to OBIE.
As de ned, the Hieron algorithm exploits the hierarchical structure of the class labels.
It learns one Perceptron model for each class and meanwhile ensures that the di erence between two models is in proportion to the distance of the two classes in the tree.
The philosophy of the learning algorithm is that, if we have to misclassify one example as class X instead of Y , then that class X should be close to the correct class Y in the hierarchical structure.
Let us suppose a hierarchical classi cation problem which has instance domain X   Rn and label set Y.
The labels in the set Y can be arranged as nodes in a rooted tree T .
For any pair of labels u, v   Y, let  (u, v) denote their distance in the tree, namely the number of edges along the (unique) path from u to v in T .
For every label v in the tree, P(v) is de ned as the set of labels along the path from the root to v, inclusive.
The training set S = {(xi, yi) : i = 1, .
.
.
, m} contains instance-label pairs, where each xi   X and each yi   Y.
The Hieron learning algorithm aims to learn a classi cation function f : X   Y which has a small tree induction error.
The classi er f has the following form: each label v   Y has a matching prototype Wv   Rn, and the classi er f makes its predictions according to the following rule: f (x) = argmaxv Y hWv, xi (4) where h ,  i represents the inner product of two vectors.
Hence, the task of learning f is reduced to learning a set of prototypes {Wv : v   Y}.
However, Hieron does not deal directly with the set of prototypes but rather with the di erence between the prototype of each node and the prototype of its parent.
Formally, we denote A(v) as the parent node of v in the tree and assume that the parent node of a root node is the root itself.
Then Each prototype is now decomposed into the sum Wv = Xu P(v) wu (5) Since the learning algorithm requires that adjacent vertices in the label tree have similar prototypes, by representing each prototype as a sum of vectors from {wv : v   Y}, adjacent prototypes Wv and WA(v) can be kept close by simply keeping the norm of the weight vector wv = Wv   WA(v) small.
The Hieron algorithm assumes that there exists a set of weight vectors {  v : v   Y} such that the following hold: Xv P(yi) h  v, xii   Xu P(r) h  u, xii   p (yi, r), (6)  (xi, yi)   S and  r   Y\{yi} However, note that this assumption can be relaxed if we introduce some regularization parameter into the learning algorithm, as discussed below.
The Hieron learning algorithm is similar to the Perceptron algorithm as it learns one classi er per class.
But, unlike Perceptron where each model is learnt independently of the others, it learns the Perceptrons for all classes in a collective way.
The algorithm initialises each of the Perceptron s weight vectors {wv : v   Y} as a zero vector and updates a weight vector only if a prototype related to it makes a wrong prediction.
By doing so the learning algorithm tries to keep the norm of the weight vector small, which is one of the requirements as discussed above.
The learning algorithm also tries to satisfy the margins requirement for the weight vectors and training set shown in (6).
Formally, for each instance-label pair (xi, yi)   S, the learning algorithm checks if the current weight vectors satisfy the margin requirement for each label y 6= yi by computing the following loss function: L({wv}, xi, yi, y) = Xu P(y) hwu, xii   Xv P(yi) hwv, xii +p (yi, y) (7) The margin requirement for (xi, yi) and y is satis ed if and only if the above function is less than or equal to 0.
If the margin requirement is satis ed for all training examples, then the learning stops and returns the current learnt model.
Otherwise, from all training examples (xi, yi) for which the margin requirement (6) is violated by the current model, it chooses the label  yi that violates the margin requirement the most (namely it has the maximal value of the function (7)), and updates the current weight vectors comprising the two prototypes Wyi and W  yi , respectively, as illustrated in Figure 1.
As shown in Figure 1, when a training example x with label y is predicted mistakenly as label y , only the weight vectors associated with the nodes in the shortest path linking nodes y and y  are updated, except for the node which is the common ancestor of the two nodes considered.
In other words, only the nodes depicted using solid lines are updated, in which the symbol  +  means increasing the corresponding weight vector by the example x and the symbol  -  means decreasing the weight vector by x.
As already discussed above, in order to ensure that adjacent vertices in the label tree have similar prototypes, the Figure 1: Illustration of the Hieron s update.
Hieron algorithm needs to keep the norms of the weight vector w as small as possible.
This is achieved by initialising all weight vectors to zero and only updating them if necessary.
The learning algorithm described above is the original Hi-eron batch learning algorithm presented in [8].
In order to achieve better performance, some modi cations were introduced in our implementation, as follows:
 til no error is made on the training examples, which means that more than one learning loop may be needed on the training set.
In contrast, the original Hieron batch learning allowed only one learning loop.
It will be shown in our experiments below that multi-loop learning has better gen-eralisation performance than single loop learning.
the training set is compatible with the margin conditions described in equation (6), so that the algorithm stops after a  nite number of loops.
This is a problem because in OBIE often it is not known in advance whether or not a training set satis es the margin condition.
Therefore, we introduce a regularization parameter into the algorithm such that the learning would stop after some loops on any training set.
The value of the regularization parameter is a positive num-ber5.
The regularization parameter is similar to that used for Perceptron (see e.g.
[18]).
In more detail, the role of the regularization parameter is to add an extra dimension to the feature vector of each training example and set the component of the dimension as the regularization parameter.
By doing so, the set of training examples with extended feature vectors would become linearly separable regardless of the linear separability of the original training set, meaning that the Hieron algorithm would stop after a  nite number of loops on any training data.
In addition, the original algorithm [8] distinguishes two types of learning models.
One type is weight vectors obtained at the end of learning, namely {wm : v   Y}.
Ant other is the mean of all weight vectors used during training.
Let us assume that we apply the weight vectors m times to training examples during learning and the weight vectors used were {wv i : v   Y, i = 1,       , m}, then for every v   Y
 may be dependent on the data used, in the experiments here, we simply set the regularization parameter to 1.
wv =
 m m Xi=1 wv i (8) It was shown in [8] that the averaged weight vectors had better results than the last weight vectors in most cases.
In our OBIE experiments we also compare the two types of weight vectors (see Section 5).
As already discussed, the goal of OBIE is to identity and classify information entities in text as instances of concepts in an ontology.
On the other hand, Hieron is essentially a learning algorithm which classi es every example into categories organised in a tree structure.
In order to apply Hieron to OBIE, we need to adapt the OBIE task to make it similar to hierarchical classi cation.
First, we convert the OBIE task into two hierarchical clas-si cation problems.
Traditionally, when classi ers are used for information extraction each token in the text is treated as one example and classi ed as belonging to one of the target IE labels or as having no label (see e.g., [12, 17]).
In particular, the annotation task can be viewed as two binary classi cation problems, one is for recognising the start tokens of information entities and the other one is for the end tokens.
Similarly, we transform the OBIE task into two hierarchical classi cation problems.
For each class in the ontology, two hierarchical classi ers are trained   one for recognising the start token of the class instances and one for the end.
Secondly, as there are tokens in the text which do not belong to any class in the ontology, in order to apply Hieron to OBIE, the ontology is extended notionally with a new child node of the root node, that represents the concept of non-relevant token.
However, this added concept is not considered in the evaluation metrics, as it is only required for the proper functioning of the classi cation algorithm.
Thirdly, note that the Hieron algorithm requires that classes are organised in a tree.
However, for some ontologies, the class subsumption hierarchy is not a tree, but a graph where some concepts occur as subclasses of two or more classes.
In other words, some nodes in the ontology may have more than one parent.
The Proton ontology used in our experiments (see below) is one example of this kind of ontology.
For example, the concept SportBuilding is a sub-concept of Building and SportFacility.
Consequently, the Hieron algorithm had to be adapted to deal with graph-like hierarchies, such as the Proton ontology.
The modi cation made to Hieron is simple.
We compute one prototype vector for each path from the root node to the given class using formula (5).
Then, given one example during training or application, the inner products between that example and each prototype vector are compared with each other and the example is assigned the class whose prototype is most relevant.
Finally, we replace the distance  (X, Y ) in the Hieron algorithm with the cost measure c(X, Y ) between two concepts in the ontology.
Therefore, we can learn classi ers which are optimised according to a distance-based cost measure, which encodes structural knowledge from the ontology.
The corpus used in our experiments consists of semantically annotated news articles.
The articles were divided into three subsets according to the article s theme, namely business, international politics and UK politics, which has
 tated manually according to the Proton ontology6 and the experiments below use its psys:Entity branch..
As already discussed above, some concepts in Proton have more than one parent class.
The hierarchical structure of Proton has 10 levels, with maximum path length 14.
The news corpus was annotated with 146 concepts from the Proton ontology.
The concepts span from the 3rd to the 10th level of the class hierarchichy .
As the corpus was created within the Sekt project, hereafter we will refer to the corpus as the Sekt ontology-annotated news corpus.
Table 1: Distribution of concepts with di erent numbers of instances in the Sekt ontology-annotated corpus.
#instances #concepts














 Table 1 presents the distribution of concepts with di erent numbers of instances in the corpus.
We can see that there are 57 concepts each of which has 5 instances or less, thus presenting a data sparseness problem.
In order to examine the e ect of data sparseness on the algorithm s performance, we also created a version of the corpus where all classes were generalised into 7 high-level classes, which are broadly equivalent to labels used in traditional IE systems (e.g., Person, Location, etc).
Table 2 presents the numbers of instance of each of the seven concepts in each part of the corpus.
The corpus is pre-processed with the open-source ANNIE system, which is part of GATE [7].
This enabled us to use a number of linguistic features, in addition to information already present in the document such as words and capitalisation information.
The linguistic features are domain-independent and include token kind (word, number, punctuation), lemma, part-of-speech (POS) tag, gazetteer class, and named entity type according to ANNIE s rule-based name entity recogniser7.
Table 3 shows an example of text with its associated features.
Note that a token may not have values for all features, e.g.
the token  Time  does not have value for the Lookup feature because it does not occur in ANNIE s gazetteer lists.
Our experimental results using SVM (not presented here due to space limitations) showed that the simple features alone such as token form, morphological feature and simple token types can achieve quite good results and using more sophisticated features such as POS tag and name entities from ANNIE or a gazetteer only obtained small improvement (less than 2%).
Since in IE the context of the token is usually as important as the token itself, the learning algorithm takes into account features of the preceding and following tokens, in addition to those of the current token.
In our experiments the same number of left and right tokens was taken as a context window.
The window size was set to 4, which means

 Date, Money, and Address.
#Doc Person Business International






 Loc Org Money Contact Temporal Time

















 Table 3: Example features for the text  Time: 3:30 PM .
The Unknown value for the word  Time  means that ANNIE identi ed the word  Time  as a named entity but could not attribute a more speci c entity type.
Token Time :
 :

 Case Tokenkind Lemma upperInitial word time punctuation number punctuation number word :
 :
 pm allCaps Pos
 :
 :

 Lookup ANNIE Entity Unknown Time Time Time Time time that the algorithm uses features derived from 9 tokens: the
 the use of a context window, the input vector is the combination of the feature vector of the current token and these of its neighboring tokens.
The experiments reported here evaluate our modi ed implementation of the Hieron learning algorithm on the Sekt ontology-annotated news corpus.
As there are no previously reported results on this corpus, we compare Hieron against two state-of-the-art  traditional  learning algorithms for IE: SVM and Perceptron.
Since Hieron exploits the relationships among classes in the ontology, the expectation is that it would perform better on OBIE than SVM and Perceptron which were designed basically for  at classi cation.
In other words, these algorithms ignore the relationships between the classes and treat them as independent of each other.
As already discussed in section 3.2, the Hieron algorithm is very similar to the uneven margins Perceptron except that Hieron takes into account the relationship among classes as well as the misclassi cation cost measure c(X, Y ).
In these experiments, we used the uneven margins SVM and Perceptron with uneven margins (PAUM), instead of the standard algorithms, because the uneven margins algorithms have better performance than the respective standard models for IE (see [17]).
We used the SVM software SV M light (see http://svmlight.joachims.org/), with linear kernel and the parameter C was set to 1.
The default settings of the SV M light were adopted for all other SVM parameters.
Table 4: Comparison of the performance of Hieron, SVM and Perceptron learning on OBIE: micro-averaged F1 (%) and distance induced Fo1(%).
Distance induced Fo1 Micro-averaged F1 PAUM SVM Hieron PAUM SVM Hieron

















 Bu.
Int
 Table 4 presents the results of the three learning algorithms on the Sekt ontology-annotated news corpus, measured both by conventional micro-averaged F1 and the distance-based Fo1 de ned in formula (2).
Recall that the micro-averaged f-measure treats concepts in ontology as independent, whereas the distance-based metric takes into account the relationships in the ontology.
In other words, if a mention in the text is found, but assigned mistakenly the wrong ontology class, then no credit is given with the conventional micro-averaged F1, but some credit (which is inversely proportional to the distance between the two concepts in ontology) will be given by the distance-based measure.
For each algorithm, we run three experiments which use one of the three subsets of the corpus for testing and the other two for training.
Firstly, as shown in Table 4, Hieron outperforms the non-ontology-based IE methods measured by conventional F1.
The 5 to 10% improvement in results demonstrates that the IE algorithm does bene t from taking into account the relationships between classes in the ontology and using this information during the learning process to optimise performance.
In addition, Hieron consistently achieves signi cantly higher performance than SVM and Perceptron according to the distance-based Fo1, which gives partial credit for ontological  near misses .
This increased performance is due to the optimisation mechanism built into Hieron, where the distance between the classi ers for two concepts is proportional to the distance of the two concepts in the ontology.
In contrast, SVM and other traditional IE learning methods are trained to treat each concept independently from the rest.
Consequently, when Hieron misclassi es a mention, it is much more likely than the  at algorithms to assign a close concept if it cannot identify the correct one exactly Consequently, this is the reason for the big di erence in performance between the two metrics.
Table 5 compares the computation times of training and application of the three learning algorithms on the ontology corpus.
The business and international politics parts of the corpus were used for training and the UK politics part for testing.
We ran those experiments on a Linux server with one Pentium 4 CPU (3.0GHz) and 2G RAM.
The results longer than both Perceptron and Hieron.
At the same time, its performance in all experiment is only marginally better than that of Perceptron.
Table 5: Training and test times (in second) of the learning algorithms: Perceptron, SVM, and Hieron.
Training Test PAUM SVM Hieron 3815s 109s 11450s 111s 552s 33s The Hieron algorithm takes longer than Perceptron, but performs substantially better than both traditional IE algorithms.
As the test set consisted of 100 documents, Hieron e ectively took on average 1 second per document.
As already discussed in Section 3.2, we modi ed the Hi-eron algorithm presented in [8] by introducing multiple learning cycles on the training set.
We also introduced a regularization parameter to each weight vector to guarantee that the training would  nish after a  nite number of learning cycles on any data.
Table 6 compares the performance of the original Hieron version against our modi ed algorithm, using the business and international politics subsets for training and the UK politics subset for testing.
Results for the last weight as well as the mean of all obtained weights during learning are reported for all three Hieron variants.
Table 6: Comparisons of the three variants of the Hieron: micro-averaged (MA) F1 (%) and distance induced Fo1 (%).
Training time is shown in second.
Regularization Last Mean



 3815s Single loop Last Mean



 510s 989s Mean


 Dist.
Time Last

 Multi-loop 54173s 97460s 11416s As shown in Table 6, multi-loop learning (300 loops used in the experiment) on its own achieves better results than single loop learning, in particular with respect to the conventional micro-averaged F1, showing that multi-loop learning can exploit better data regularity.
Secondly, when the regularization parameter is added to the multi-loop learning the performance improves even further, while the training time of the former is only about one fourteenth of the time of the latter.
Finally, averaged weights perform slightly better than the last weight in some cases and a bit worse in the other cases.
However, this also requires much higher computation time than the last weights, so there is a trade-o  between performance and training time which means that for practical systems using last weight would probably be more practical.
Last but not least, it should be noted that the di erence in computation times between these variants of the Hieron algorithm a ect only training, whereas application times remain the same.
When IE systems are evaluated, the entities predicted by the system are compared to the entities in the human-annotated gold standard.
In the above experiments we used Hieron to recognise separately the start and end tokens of the instances.
Therefore, if both the start and end boundaries are recognised correctly, we say the entity is recognised correctly or is an exact match to the gold standard.
On the other hand, if only the start or end token match those from the gold standard, then it is referred to as a partial match or a partially correct result.
Few IE systems (e.g.
[6]) are evaluated by using exact match only and partially correct results are discarded.
However, traditional large-scale evaluations of IE systems, e.g., the Message Understanding Conferences (MUC) give also credit to partial matches [4].
Consequently, in the experiments reported above, we took into account both correct and partially correct results and, again following traditional IE scoring methods, partial results are assigned half the score of an exact match.
Table 7 compares the results for exact match against those for correct and partial match combined.
Again we use the business and international politics subsets for training and the UK politics subset for testing.
For exact match Hieron performs worse than SVM with respect to conventional f-measure.
However, if partially correct results are taken into account, Hieron s results are higher, showing that the hierarchical classi er has better capability than the  at  SVM in recognising the presence of instances in the text, even when it is not able to recognise their boundaries exactly.
Table 7: Comparison of the exact match and partial match for the SVM and Hieron: conventional micro-averaged F1 (%) and the distance based Fo1 (%).
Exact Exact and partial
 SVM Hieron



 Distance Fo1 SVM Hieron




 As already discussed above, the Sekt ontology annotated corpus contains documents from three di erent news types, with around 90 documents of each type.
In the experiments discussed above, we used two of these parts for training and the third one for testing, resulting in heterogeneous training and test data.
In addition, we ran an experiment where two third of the documents from each three parts were put together as training data and the remaining documents were used for testing.
Consequently the training and testing data in this case are homogenous.
Using 3-fold cross-validation, the mean results were: conventional F1 = 0.850; distance based F1 = 0.932; Compared to the results of heterogeneous training and testing data listed in Table 4, the homogenous training and testing data helped us achieve better results, but not as much as expected.
We attribute this to the fact that the documents in the corpus are annotated with classes from a general ontology (Proton), which does not contain domain speci c concepts which only occur in one or two of the subsets.
In order to establish the e ect of data sparseness on the system s performance, we carried out experiments to compare the learning curves for the top 7 classes (listed in Table 2) with those for all classes in the Sekt ontology an-in the Proton ontology and have sub-concepts.
For example, Organisation subsumes CommercialOrganisation, Edu-cationOrganisation and PoliticalEntity, etc.
Figure 2 shows the learning curves, using standard IE micro-averaged F1 on, respectively, the top 7 classes and all classes.
Each experiment constituted of ten runs and in each run N documents were selected at random from the Sekt ontology annotated corpus8 as training data and all other documents for testing.
The results for each experiment are the means over the ten runs, with the con dence intervals at the 95% level.
The results show, unsurprisingly, that the more training documents are used, the better the results are.
Secondly, on small training sets (10 or 20 documents), the results for the
 to data sparseness, as each document contains many more examples when the class labels are generalised to the top 7.
The training time for 7 classes is also much less than that for all classes, due to the need for training fewer classi ers.
Hence, if detailed information is not required, then learning fewer high level concepts is better, as it needs less training data and is also much faster.
a good classi er for each class and when the learnt model is applied, it would classify many instance correctly and min-imise the cost on a small number of incorrectly classi ed ones.
This leads to a small di erence between the conventional measure which considers classes separately and the ontology-based measure which takes into account the relations between classes.
In contrast, if using a small training set, Hieron might not be able to learn a good classi er for some individual classes due to data sparsity.
So when this model is applied, it would classify some examples correctly and minimise the cost on many of the misclassi ed instances.
Consequently the ontology-based measure is much higher than the conventional one for small training sets.
Secondly, Hieron has signi cantly better results than SVM on almost every training set.
The ontology-based measures for Hieron are much higher than those for SVM, which in turn outperforms PAUM.
On the other hand, PAUM is much faster for training and testing than both SVM and Hieron.
SVM takes much longer than Hieron, in particular for testing.
Hence, overall we can conclude that Hieron is a good learning algorithm for OBIE, because it balances performance and computational complexity.
Figure 2: Hieron performance on di erent amounts of training data for the top 7 classes and all classes respectively In addition, it is also interesting to compare the di erent performance measures as well as the di erent learning algorithms on small training sets, because in many applications there is often only a small amount of annotated training data.
Figure 3 presents the results of Hieron, SVM and PAUM for all classes on the Sekt ontology annotated corpus, measured both with conventional and distance-based
 Firstly, for Hieron the di erence between the conventional measure and the ontology-induced measure is much larger on small training data.
On the other hand, for SVM (and PAUM) the di erences between the di erent measures changes slowly as the dataset grows.
This re ects the di erent learning mechanisms adopted by Hieron and SVM, respectively.
While the only aim of SVM is to classify every instance correctly, the Hieron classi er at  rst tries to classify an instance as correctly as it possibly can, and if it cannot classify the instance correctly, it then tries to classify it at the lowest possible cost, relative to the correct concept.
Therefore, given a su ciently large training set, Hieron can learn Figure 3: Comparison of Hieron, SVM and PAUM performance on small training sets


 Since there are no existing publically available corpora9, annotated with more than 10 classes, we evaluated our Hieron-based system on the recently created Sekt corpus.
Unfortunately, this makes it di cult to compare our approach
 each of the three parts of the corpus for training.
In other words, the training and test data was homogenous.
has not yet released its human-annorated test data, so cannot be used to compare against other systems.
to other learning algorithms on the seminar corpus: F1 (%) on each slot and macro-averaged F1.
The
 Hieron.
The best results for each slot and for overall performance appear in bold.
speaker location Hieron

 SNoW MaxEnt

 Rapier















 stime







 etime MA F1















 to previous systems, as this corpus is new and no previous evaluations have been reported on it, except those reported here.
On the other hand, there exist several benchmarking corpora on which many IE systems have been evaluated.
In order to make a comparison of our Hieron-based learning algorithm to other state-of-the-art learning systems for IE, we applied our algorithm to the CMU Seminars corpus, which is a standard benchmark for conventional IE.
Since the Seminar corpus has only four types of entity labels with no relations between them, we were unsure whether the Hieron algorithm could outperform SVM, because Hieron depends heavily on the hierarchical relations between the labels.
The Seminars corpus has been used for evaluating many IE systems.
This includes rule learning based system such as Rapier [1], BWI [13], SNoW [24] and (LP )2 [6], as well as statistical learning systems such as HMM [11] and maximum entropy (MaxEnt) [3].
The Seminars corpus contains 485 Seminar announcement posts and is annotated with four types of information entities, namely start time (stime), end time (etime), speaker and location of one seminar.
In order to make a fair comparison with other state-of-the-art learning algorithms for IE, our experiment settings followed the methodology of Rapier and (LP )2.
First, the results are the average over 10 runs and in each run 243 documents are randomly selected from the corpus as training data and the remaining 242 are used for testing.
Secondly, as far as possible, we used the same features as all other systems to enable a more informative comparison.
In particular, the results discussed here, including these of our system, do not use any gazetteer information or named entity recogniser input.
The only features used in this comparison are words, capitalisation information, token types, lemmas, and POS tags.
Finally, we use the exact match for evaluating the results and do not consider partially correct annotations (see Section 5.1), because the results of the other systems were reported in this way.
Since Hieron needs relations among the entity types, in order to apply it to this corpus, we constructed a trivial ontology which consists of one concept Thing as a root node, Entity as the only child of Thing, and the four entity types Stime, Etime, Speaker and Location as the child concepts of Entity.
Table 8 presents the results of our Hieron-based algorithm compared to other IE systems on the Seminars corpus.
The SVM results are from an earlier experiment with an uneven margins SVM [17].
The results of all other systems were obtained from the papers cited at the start of this section.
The results show that on each of the four slots our system s performance is not far from the best per-slot measures which are achieved by di erent systems.
As a result, our Hieron-based system obtained the best overall performance, although its performance is not signi cantly better than the next two systems: (LP )2 and SNoW.
From this, we can conclude that our algorithm is also a very good, state-of-the-art learning algorithm for information extraction.
In our view, the excellent perfomance of our Hieron-based system is due to its exploiting the trivial seminar ontology which we created to meet the algorithm s requirements.
In this ontology, the four classes of interest have the same distance to each other, whereas the distance is larger between each of them and the nonentity concept, which we added to the ontology as a child concept of the top concept Thing.
Consequently, due to Hieron s learning mechanism, the clas-si er for the nonentity class is more di erent than the clas-si ers for these 4 target classes.
This may lead to Hieron making fewer misclassi cations than the other learning algorithms (e.g., SVM), which do not explore the asymmetric similarities between the classes and nonentities in the Seminar corpus.
However, the good performance of Hieron on the Seminar corpus with  at entity labels is worth some further investigation.
This paper investigated the adaptation and evaluation on ontology-based information extraction of a large margin hierarchical classi cation, Perceptron-like algorithm Hieron.
The algorithm takes into account the relations among concepts, thus bene ting directly from the ontology structure.
We made several modi cations to the original Hieron algorithm presented in [8], which, as proven by our evaluation, led to an improved performance.
The algorithm s performance is evaluated on the biggest available semantically annotated corpus, covering 146 concepts from the Proton ontology.
Our system is compared to SVM and Perceptron, which are two state-of-the-art learning algorithms for IE.
The results showed that our hierarchical classi cation algorithm obtained clearly better results than Perceptron and SVM.
The approach was evaluated on the Sekt ontology-annotated news corpus, as it is the only corpus for the OBIE which is annotated with classes from a nontrivial ontology.
However, the problem is that no other systems have been evaluated on it, apart from the SVM and Perceptron comparisons reported here.
Unfortunately other recent corpora for IE evaluation use a  at set of labels, thus making them inappropriate for OBIE.
Nevertheless, in order to enable some comparison of our approach to other work, we also ran Hieron on the Seminar corpus, despite it having a  at set of labels.
The experimental results showed that our system outperformed again other state-of-the-art learning algorithms, proving that Hi-eron is well suited for information extraction tasks.
Our implementation of Hieron for OBIE is based on distance-based cost.
We are currently working on using some improved cost measures instead (see the discussions in Section
 evaluation on related tasks, e.g., opinion mining.
Extraction in Informal Domains.
Machine Learning,
This work is supported by the EU-funded SEKT (IST-
The authors also wish to thank the reviewers for their useful suggestions on improving the paper.
