Phishers launched a record number of attacks in January
 This is part of a very clear trend in which the number of attacks are increasing without showing any signs of slowing.
These attacks often take the form of an email that purports to be from a trusted entity, such as eBay or PayPal.
The email states that the user needs to provide information, such Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
as credit card numbers, identity information, or login credentials, often to correct some alleged problem supposedly found with an account.
Some number of users fall for these attacks by providing the requested information, which can lead to fraudulent charges against credit cards, withdrawals from bank accounts, or other undesirable e ects.
The phishing problem is a hard problem for a number of reasons.
Most di culties stem from the fact that it is very easy for an attacker to create an exact replica of a good site, such as that of a bank, that looks very convincing to users.
Previous work [25] indicates that the ability to create good-looking copies, as well as users  unfamiliarity with browser security indicators, leads to a signi cant percentage of users being unable to recognize a phishing attack.
Unfortunately, the ease with which copies can be made in the digital world also makes it di cult for computers to recognize phishing attacks.
As the phishing websites and phishing emails are often nearly identical to legitimate websites and emails, current  lters have limited success in detecting these attacks, leaving users vulnerable to a growing threat.
Our overall approach,  rst described in [13], centers on extracting information that can be used to detect deception targeted at web users, which is accomplished by looking at features from each incoming email or potential attack vector.
This process involves extracting data directly present in the email, as well as collecting information from external sources.
The combination of internal and external information is then used to create a compact representation called a feature vector, a collection of which are used to train a model.
Based on a given feature vector and the trained model, a decision is made as to whether the instance represents a phishing attack or not.
We present a detailed description of our approach, which  lters approximately 96% of phishing emails before they ever reach the user.
The remainder of this paper is organized in the following manner.
Section 2 discusses previous approaches to  ltering phishing attacks, while Section 3 gives an overview of machine learning and how we apply it to the task of classifying phishing emails, and how it could be used in a browser toolbar.
Section 4 covers the results of empirical evaluation, as well as some challenges presented therein.
Section 5 presents some concluding remarks.
The  rst attempts speci cally designed to  lter phishing attacks have taken the form of browser toolbars, such as in [10], most toolbars are lucky to get 85% accuracy identifying phishing websites.
Accuracy aside, there are both advantages disadvantages to toolbars when compared to email  ltering.
The  rst disadvantage toolbars face when compared to email  ltering is a decreased amount of contextual information.
The email provides the context under which the attack is delivered to the user.
An email  lter can see what words are used to entice the user to take action, which is currently not knowable to a  lter operating in a browser separate from the user s email client.
An email  lter also has access to header information, which contains not only information about who sent the message, but also information about the route the message took to reach the user.
This context is not currently available in the browser with given toolbar implementations.
Future work to more closely integrate a user s email environment with their browser could alleviate these problems, and would actually provide a potentially richer context in which to make a decision.
As discussed later in this paper, there are some pieces of information available in the web browser and website itself that could help to make a more informed decision, especially if this information could be combined with the context from the initial attack vector, such as the email prompting a user to visit a given website.
This is discussed in greater detail in Section 3.3.
The second disadvantage of toolbars is the inability to completely shield the user from the decision making process.
Toolbars usually prompt users with a dialog box, which many users will simply dismiss or misinterpret, or worse yet these warning dialogs can be intercepted by user-space malware [2].
By  ltering out phishing emails before they are ever seen by users, we avoid the risk of these warnings being dismissed by or hidden from the user.
We also prevent the loss of productivity su ered by a user who has to take time to read, process, and delete these attack emails.
Although there are clear advantages to  ltering phishing attacks at the email level, there are at present not many methods speci cally designed to target phishing emails, as opposed to spam emails in general.
The most closely related prior attempt is [7], in which the authors use structural features of emails to determine whether or not they represent phishing attacks.
The features are mostly linguistic, and include things such as the number of words in the email, the  richness  of the vocabulary, the structure of the subject line, and the presence of 18 keywords.
Other examples include the  lter built into Thunderbird 1.5 [21].
However, this  lter is extremely simple, looking for only the presence of any one of three features, namely the presence of IP-based URLs, nonmatching URLs (discussed in Section 3.2.3), and the presence of an HTML  form  element.
The Thunderbird builtin  lter still only presents a warning to the user, and does not avoid the costs of storage and the user s time.
In our implementation and evaluation, we seek to  ll this gap in email-based phishing  lters.
Our approach is gen-eralizable beyond email  ltering, however, and we do note how it could be used and what changes would be required in the context of  ltering web pages as opposed to emails.
Many people have proposed ways in which to eliminate spam emails in general, which would include phishing emails (see, for example, [17, 9, 16, 27, 26, 18]).
A number of early attempts at combating spam emails were based on so-called  na ve  approaches, ranging from  bag-of-words , in which the features of an email are the presence or absence of highly frequent and rare words, to analysis of the entropy of the messages.
While these approaches looking at the text of the email appear to do well for spam, in practice these approaches often fail to stop phishing emails.
This makes sense, as phishing emails are designed to look as close as possible to a real, non-spam email that a legitimate company would (or already has) sent out.
As such, it is our belief that to stop phishing emails, we need to look at features selected speci cally to detect this class of emails.
Looking at class-speci c features is not a new approach in email  ltering.
SpamAssassin [4], for instance, has a number of rules that try to detect features common in spam email that go beyond just the text of the email.
Such tests include things like the ratio of pixels occupied by text to those occupied by images in a rendered version of the mail, presence of certain faked headers, and the like.
Spamato [1] is another extensible  ltering platform that ships with a number of advanced  lters, such as Vipul s Razor [24] (a collaborative algorithm using both URLs and message hashes), that work in tandem to detect spam emails.
Our contribution is a new approach focused on learning to detect phishing, or semantic attacks in general.
We do this by extracting a plurality of features designed to highlight deception, utilizing both sources of information internal to the attack itself, as well as external sources to gain more information about the context of the attack.
Our solution can easily be used in conjunction with existing spam  lters.
The solution signi -cantly reduces the amount of phishing emails with minimal cost in terms of false positives (legitimate emails marked as phishing).
Our approach, PILFER, is a machine-learning based approach to classi cation [20].
In a general sense, we are deciding whether some communication is deceptive, i.e. whether it is designed to trick the user into believing they are communicating with a trusted source, when in reality the communication is from an attacker.
We make this decision based on information from within the email or attack vector itself (an internal source), combined with information from external sources.
This combination of information is then used as the input to a classi er, the result of which is a decision on whether the input contained data designed to deceive the user.
With respect to email classi cation, we have two classes, namely the class of phishing emails, and the class of good ( ham ) emails.
In this paper we present a collection of features that has been identi ed as being particularly successful at detecting phishing, given the current state of attacks.
We expect that over time, as the attacks evolve, new sets of features will have to be identi ed combining information from both internal or external sources.
The features currently used are presented in Section 3.2, with Section 3.3 discussing how these can be adapted for use in detecting phishing web pages.
In Section 4 we present a method for evaluating the e ectiveness of these features, as well as the results of such an evaluation.
Some spam  lters use hundreds of features to detect unwanted emails.
We have tested a number of di erent features, and present in this paper a list of the ten features that are used in PILFER, which are either binary or continuous numeric features.
As the nature of phishing attacks changes, additional features may become more powerful, and PILFER can easily be adapted by providing such new features to the classi er.
At this point, however, we are able to obtain high accuracy with only ten features, which makes the decision boundaries less complex, and therefore both more intuitive and faster to evaluate.
We explain these features in detail below.
While some of these features are already implemented in spam  lters (such as the presence of IP-based URLs), these features are also a useful component of a phishing  lter.
IP-based URLs
 Some phishing attacks are hosted o  of compromised PCs.
These machines may not have DNS entries, and the simplest way to refer to them is by IP address.
Companies rarely link to pages by an IP-address, and so such a link in an email is a potential indication of a phishing attack.
As such, anytime we see a link in an email whose host is an IP-address (such as http://192.168.0.1/paypal.cgi?fix account), we  ag the email as having an IP-based URL.
As phishing attacks are becoming more sophisticated, IP-based links are becoming less prevalent, with attackers purchasing domain names to point to the attack website instead.
However, there are still a signi cant number of IP-based attacks, and therefore this is still a useful feature.
This feature is binary.
Phishers are learning not to give themselves away by using IP-based URLs.
Name-based attacks, in which a phisher will register a similar or otherwise legitimate-sounding domain name (such as playpal.com or paypal-update.com) are increasingly common.
These domains often have a limited life, however.
Phishers may register these domains with fraudulently obtained credit cards (in which case the registrar may cancel the registration), or the domain may be caught by a company hired to monitor registrations that seem suspicious.
(Microsoft, for instance, watches for domain name registrations involving any of their trademarks.)
As such, the phisher has an incentive to use these domain names shortly after registration.
We therefore perform a WHOIS query on each domain name that is linked to, and store the date on which the registrar reports the domain was registered.
If this date is within 60 days of the date the email was sent, the email is  agged with the feature of linking to a  fresh  domain.
This is a binary feature.
Phishers often exploit HTML emails, in which it is possible to display a link that says paypal.com but actually links to badsite.com.
For this feature, all links are checked, and if the text of a link is a URL, and the HREF of the link is to a di erent host than the link in the text, the email is  agged with a  nonmatching URL  feature.
Such a link looks like <a href="badsite.com"> paypal.com</a>.
This is a binary feature.
Phishing emails, often contain text like  Click here to restore your account access .
In many cases, this is the most predominantly displayed link, and is the link the phisher intends the user to click.
Other links are maintained in the email to keep the authentic feel, such as the link to a privacy policy, a link to the user agreement, and others.
We call the domain most frequently linked to the  modal domain  of the email.
If there is a link with the text  link ,  click , or  here  that links to a domain other than this  modal domain , the email is  agged with a  here  link to a non-modal domain feature.
This is a binary feature.
Most emails are sent as either plain text, HTML, or a combination of the two in what is known as a multipart/alternative format.
The email is  agged with the HTML email feature if it contains a section that is denoted with a MIME type of text/html.
(This includes many multipart/alternative emails).
While HTML email is not necessarily indicative of a phishing email, it does make many of the deceptions seen in phishing attacks possible.
For a phisher to launch an attack without using HTML is di cult, because in a plain text email there is virtually no way to disguise the URL to which the user is taken.
Thus, the user still can be deceived by legitimate-sounding domain names, but many of the technical, deceptive attacks are not possible.
This is a binary feature.
The number of links present in an email is a feature.
The number of links is the number of links in the html part(s) of an email, where a link is de ned as being an <a> tag with a href attribute.
This includes mailto: links.
This is a continuous feature.
For all URLs that start with either http:// or https://, we extract the domain name for the purpose of determining whether the email contains a link to a  fresh  domain.
For this feature, we simply take the domain names previously extracted from all of the links, and simply count the number of distinct domains.
We try to only look at the  main  part of a domain, e.g.
what a person actually would pay to register through a domain registrar.
It should be noted that this is not necessarily the combination of the top and second-level domain.
For instance, we consider the  main  part of www.cs.university.edu to be university.edu, but the  main  part of www.company.co.jp would be company.co.jp, as this is what is actually registered with a registrar, even though technically the top-level domain is .jp and the second-level domain is .co.
This feature is simply the number of such  main  domains linked to in the email, and is a continuous feature.
There are a number of ways for attackers to construct legitimate-looking URLs.
One such method uses subdo-mains, like http://www.my-bank.update.data.com.
Another method is such as http://www.google.com/url?q=http://www.badsite.com.
To the user (or a na ve  lter), this may appear to be a site hosted at google.com, but in reality will redirect the browser redirection script, to use a clusion of a URL into an open redirect script or by the use of a number of subdomains, there are a large number of dots in the URL.
Of course, legitimate URLs also can contain a number of dots, and this does not make it a phishing URL, however there is still information conveyed by this feature, as its inclusion increases the accuracy in our empirical evaluations.
This feature is simply the maximum number of dots ( . ) contained in any of the links present in the email, and is a continuous feature.
JavaScript is used for many things, from creating popup windows to changing the status bar of a web browser or email client.
It can appear directly in the body of an email, or it can be embedded in something like a link.
Attackers can use JavaScript to hide information from the user, and potentially launch sophisticated attacks.
An email is  agged with the  contains javascript  feature if the string  javascript  appears in the email, regardless of whether it is actually in a <script> or <a> tag.
This might not be optimal, but it makes parsing much simpler, especially when dealing with attacks that contain malformed HTML.
This is a binary feature.
Spam lter output
 Many mail clients already have a spam  lter in place, and as such it seems natural to leverage the ability of existing solutions in combating the phishing problem.
We therefore include as a feature the class assigned to the email by SpamAssassin - either  ham  or  spam .
This is a binary feature, using the trained version of SpamAssassin with the default rule weights and threshold.
Although we have focused primarily on detecting attacks at the email level, most of the features discussed in Section 3.2 also can be applied towards classi ying a webpage in a browser environment.
A spam  lter cannot generally be run on a webpage, so the last feature is not applicable, but the other features can still be evaluated with slight modi cation.
For instance, the number of dots could be turned into two features - the number of dots in the URL of the current page, and the maximum number of dots in all URLs linked to in the current page.
The same extension could be applied to the evaluation of the domain age feature.
One could likewise split the presence of deceptive links into two features - deceptive links on the current page, and deceptive links on the previous page.
This technique may enable the use of additional context, and would be especially useful if the user is coming to the attack site from a message in their web-based email interface.
Additionally, one might be able to make use of additional context available in the browser and its history in features such as the following.
Site in browser history
 As phishing sites are short-lived and located at a number of di erent URLs, the presence or absence of the current website in the browser s history would provide information for the classi cation process.
A site never previously visited (not in the history) is more likely to be a phishing website than a site already visited for the following simple reason: a user would have no reason to have previously visited that particular spoof of the legitimate site during its short lifetime.
This feature could be used in a binary fashion (present in history or not) if that s all that were available, but if the history included the number of times the page was visited, that would be even more valuable.
A large number of visits would establish some existing relationship with the site, which likely indicates some level of legitimacy.
A site can be reached in a number of di erent ways, including redirection from another site.
When a user goes to a web page, either by clicking a link or typing in a URL, that web page can redirect the browser to a di erent page.
Redirection has many legitimate uses, but one could imagine an attacker using a redirection service such as TinyURL [15] to hide the phishing site s URL in the email (or other attack vector).
The browser is explicitly instructed to redirect to a new page, and as such it would be possible to create a feature out of whether or not the browser was redirected to the present page, or whether the user went to the current page explicitly.
This information would be available in the context of a browser, but might not be available if only analyzing the source email.
 tf-idf , or term frequency-inverse document frequency, is a measure of importance of a term.
One can use tf-idf to attempt to identify key terms of a page, and subsequently determine whether the current page is a copy of a more popular page.
In general, this involves searching for the key terms on a page and checking whether the current page is present in the result.
This method and its accuracy are discussed in more detail in [30].
tf-idf


 In this section, we present the details of our implementation used in evaluation of PILFER (Section 4.2) and in evaluating SpamAssassin (Section 4.3).
The dataset of emails used to perform the evaluation is described in Section 4.4.
Certain challenges are present when trying to do post-hoc analysis of phishing attacks, the speci cs and impact of which are discussed in Section 4.5.
Section 4.6 introduces some terminology, and Section 4.7 shows our results in classifying the dataset.
In order to test our model, we  rst run a set of scripts to extract all the features listed in Section 3.2.
Once the features are extracted, we train and test a classi er using 10-fold cross validation.
(The dataset is divided into ten distinct parts.
Each part is then tested using the other nine parts of the data as the training data.
This ensures that the training data is separate from the test data, and is called  cross-validation .)
For our reference implementation of PILFER, we use a random forest [6] as a classi er.
Random forests create a number of decision trees (in our case, 10), and each decision tree is made by randomly choosing an attribute to split on at each level, and then pruning the tree.
The exact workings of the classi er are beyond the scope of this paper.
We evaluated a number of other classi ers as well, including SVMs [11], rule-based approaches, normal curacies of most of the classi ers were not di erent with statistical signi cance.
Accuracies for some of these other classi ers are shown in appendix A.
For a complete discussion of classi ers and text classi cation in general, the reader is directed to a machine learning text such as [20] or [11].
SpamAssassin is a widely-deployed freely-available spam  lter that is highly accurate in classifying spam emails.
For comparison against PILFER, we classify the exact same dataset using SpamAssassin version 3.1.0, using the default thresholds and rules.
The results reported for  untrained  SpamAssassin are obtained by simply treating the entire dataset as a test set, and not training on any emails.
This represents an out-of-the-box install of SpamAssassin.
(To be sure that SpamAssassin was untrained, we deleted the .spamassassin directory where learned data is stored before testing the emails).
The results reported for the  trained  SpamAssassin are from the same version, except that we now use 10-fold cross validation, where before each fold we clear SpamAssassin s learned data (by deleting v/.spamassassin).
We then train on all the emails in the train part of the fold and test on those in the test part of the fold.
To get realistic results from SpamAssassin, we disable online tests (blacklist lookups, mostly).
Since the dataset we are using is slightly older and publically available, it is probable that the blacklists have much more information about the senders of the emails in the dataset at the time of testing than was available at the time the emails were sent, and so including these tests would arti cally in ate the accuracy.
By disabling these online tests, we hope to more closely approximate the information available at the time the attacks are  rst sent out.
It is not a perfect approximation, but it is the closest we can come.
Two publicly available datasets were used to test our implementation: the ham corpora from the SpamAssassin project [5] (both the 2002 and 2003 ham collections, easy and hard, for a total of approximately 6950 non-phishing non-spam emails), and the publicly available phishingcorpus [22] (approximately 860 email messages).
We use a series of short scripts to programmatically extract the features from Section 3.2, and store these in a database for quick reference.
We label emails as being non-phishing if they come from the SpamAssassin ham corpora, and as phishing if they come from the phishingcorpus.
For these experiments we used the entire dataset and did not relabel any of its contents.
There are a number of challenges posed by doing post-hoc classi cation of phishing emails.
Most of these challenges apply mainly to the phishing emails in the dataset and materialize in the form of missing information, which has the net e ect of increasing the false negative rate.
Without the challenges outlined below, which are mostly artifacts of testing after the fact as opposed to live in a real system, even better accuracy should be possible.
The age of the dataset poses the most problems, which is particularly relevant with the phishing corpus.
Phishing websites are short-lived, often lasting only on the order of
 extracted from older emails, making our tests di cult.
For instance, in one of our features, we are interested in the age of domains linked to.
We perform a WHOIS query to determine the date a domain was registered, and subtract this date from the date the email was sent according to its headers to determine its age.
In many cases of phishing attacks, however, these domains are no longer live at the time of our testing, resulting in missing information.
The disappearance of domain names, combined with di culty in parsing results from a large number of WHOIS servers returning results in non-standardized formats resulted in only being able to pro-grammatically extract registration dates for 505 of a total of 870 distinct domain names referenced in the dataset at the time of writing.
It is not clear whether this dataset is representative of normal people s email inboxes or not, but to date it is the best data we have been able to  nd.
We are currently planning a followup study where we will be having users label every email coming into their inbox as either legitimate, spam, or phishing.
This future work will provide us with a dataset more representative of real users  inboxes.
It is important to note that misclassifying a phishing email may have a di erent impact than misclassifying a good email, so we report separately the rate of false positives and false negatives.
The false positive rate corresponds to the proportion of ham emails classi ed as phishing emails, and false negative rate corresponds to the proportion of phishing emails classi ed as ham.
Let us denote the number of ham emails classi ed as ham (correctly classi ed) as hamham, the number of ham emails classi ed as phishing as hamphish, the number of phishing emails classi ed as ham as phishham, and the number of phishing emails classi ed as phishing as phishphish.
We then de ne f p, the false positive rate, as f p = hamphish hamphish + hamham and f n, the false negatives rate, as f n = phishham phishham + phishphish Given this de nition, f p = 0.1 would correspond to one of every ten good emails being classi ed as phishing, and f n = 0.2 would correspond to two of every ten phishing emails being classi ed as good.
We will use the terms f p and f n in this manner in the evaluations presented in the rest of the paper.
On our dataset, we are able to more accurately classify emails using PILFER than by using a spam  lter alone.
PILFER achieves an overall accuracy of 99.5%.
with a false positive rate f p of approximately 0.0013.
PILFER s false negative rate f n on the dataset is approximately 0.035, which is almost one fourth the false negative rate of the spam  lter by itself.
These results are compared in detail with those of SpamAssassin in Table 1.
As seen in the table, the inclusion of the result of a spam  lter as a feature to PILFER makes for a signi cant reduction in phishing emails that get by.
While PILFER without the spam  lter s input has comparable accuracy to the spam  lter, the accuracy obtained by providing the spam  lter s decision as an input to PILFER, Classi er PILFER, with S.A. feature PILFER, without S.A. feature SpamAssassin (Untrained) SpamAssassin (Trained) False Positive Rate f p False Negative Rate f n







 Table 2: Percentage of emails matching the binary features Non-Phishing Matched Phishing Matched Feature
 Has IP link
 Has  fresh  link Has  nonmatching  URL 0.14%
 Has non-modal here link
 Is HTML email Contains JavaScript

 SpamAssassin Output






 i.e. the combination of the two, improves the accuracy to be much better than either one alone.
This result suggests that the features present in the two are catching di erent subsets of the phishing emails, and shows that a phishing  lter and a spam  lter can work well as complementary parts of an overall solution.
Table 2 shows the exact percentages of emails (by class) matching each of the seven binary features.
All of the binary features are matched more frequently by phishing emails than by nonphishing emails.
For the three non-binary features, their averages and standard deviations per-class are shown in Table 3.
These features have higher mean values for phishing emails.
In summary, PILFER can be either deployed in a standalone con guration without a spam  lter to catch a large percentage of phishing emails with very few false positives, or in conjunction with an existing spam  lter such as Spa-mAssassin for even higher accuracy.
If a  lter like SpamAs-sassin is already deployed, then adding PILFER has the advantage of signi cantly reducing the number of phishing emails making it to the user, while having no signi cant e ect on the number of emails erroneously caught by the  ltering system.
In this paper, we have shown that it is possible to detect phishing emails with high accuracy by using a specialized  lter, using features that are more directly applicable to phishing emails than those employed by general purpose spam  lters.
Although phishing is a subset of spam (after all, who asks to receive emails from a person pretending to be their bank for the purpose of fraud and identity theft?
), it is characterized by certain unique properties that we have identi ed.
One might be inclined to think that phishing emails should be harder to detect than general spam emails.
After all, phishing emails are designed to sound like an email from a legitimate company, often a company with which the attacker hopes the user has a preexisting relationship.
Models based on  na ve  assumptions, such as certain words like  Viagra  being indicative of a class of undesirable emails, no longer hold when the attackers are using the same words and the same overall  feel  to lure the user into a false sense of security.
At the same time, phishing emails present unique opportunities for detection that are not present in general spam emails.
In general spam emails, the sender does not need to misrepresent their identity.
A company o ering to sell  Viagra  over the Internet does not need to convince potential buyers that they are a pharmacy that the user already has a relationship with, such as CVS or RiteAid.
Instead, a spammer can actually set up a (quasi-)legitimate company called Pharmacy1283, and identify themselves as such, with no need to try to convince users that they are receiving a communication from their bank, or some other entity with which they have an established relationship.
It is this misrepresentation of sender identity that is key to the identi cation of phishing emails, and further work in the area should concentrate on features to identify this deceptive behavior.
As the phishing attacks evolve over time to employ alternate deceptive behaviors, so does the information available to combat these attacks.
The approach used is  exible, and new external information sources can be added as they become available.
These sources could take the form of web services, or other tagged resources, to provide additional information to the decision making process.
For instance, many phishing attacks include copies of corporate logos, and if one could map a logo back to its legitimate owner s website, that would be valuable information in determining the authenticity of a website or email displaying that logo.
As image sharing and tagging services such as Flickr [29] are increasing in use, it is not unreasonable to think that some day in the near future, one might actually be able to search with an image and get back a description as a result.
There are a number of emerging technologies that could greatly assist phishing classi cation that we have not considered.
For instance, Sender ID Framework (SIDF) [19] and DomainKeys [28], along with other such sender authentication technologies, should help to both reduce false positives and make detection of spoofed senders much simpler in the time to come.
Looking farther into the future, deeper knowledge-based models of the user and the types of prior Feature Number of links Number of domains Number of dots  phishing


  phishing


  non-phishing


  non-phishing


 relationships she may or may not have with di erent sites or organizations could also help fend o  more sophisticated phishing attacks.
Such techniques would likely build on ongoing research on federated identities and semantic web technologies [14].
In the meantime, however, we believe that using features such as those presented here can signi cantly help with detecting this class of phishing emails.
We are currently in the process of building a live  ltering solution based around PILFER, which we will start making available to users for testing for further validation.
The work reported herein has been supported in part under the NSF Cyber Trust initiative (Grant #0524189) and in part under ARO research grant DAAD19-02-1-0389 ( Perpetually Available and Secure Information Systems ) to Carnegie Mellon University s CyLab.
The authors would also like to thank Lorrie Cranor, Jason Hong, Alessandro Ac-quisti, Julie Downs, Sven Dietrich, Serge Egelman, Mandy Holbrook, Ponnurangam Kumaraguru, and Steve Sheng.
Any opinions,  ndings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily re ect the views of the National Science Foundation.
