Recent work under the banner of  information and communication for development  considers how computing technology can impact socioeconomic development for poor communities [27, 28, 29, 35, 36, 41, 47].
Much of this work is devoted to providing computer applications to support activities in agriculture [41, 47], healthcare [15], or education [27].
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
These communities share characteristics other than economic hardship, even across geographies, because poverty is correlated with other factors such as poor education.
Among these shared traits is illiteracy.
Even conservative estimates of illiteracy suggest that there are over one billion illiterate people in the world [23], and many more are semi-literate   just barely able to write their own names or recognize common words.
Any computing application meant to aid impoverished communities would therefore be more accessible, if provisions were made for illiterate users.
The sheer abundance of text in standard interfaces suggests that there would be significant challenges in developing applications that do not rely on the ability to read text.
Previous work in designing UIs for illiterate and semi-literate populations focuses on broad elements, recommending features such as the use of graphical icons [18, 27, 28, 29, 35, 36, 37], minimal use of text [5, 18, 28], voice annotation [28, 29, 37], easy navigability [5, 18, 29, 28, 35, 36, 37], and the use of numbers for subjects who may be illiterate but not innumerate [29, 35, 36, 37].
All such previous work suggests that information should be provided in graphical, rather than textual, form, with voice annotation on mouse-over as an important component.
On the whole, these are obvious and intuitive features.
What is not so obvious, however, is the optimal representation for illustrating a given concept.
Are photographs better than abstracted hand-drawn graphics?
Are videos or animations better than static imagery?
Does the visual representation matter at all, if there is clear voice annotation?
Etc.
In this paper, we present a body of research that provides initial answers to these and other questions.
In our initial field studies to identify an application domain, we had seen that the health workers were unable to monitor health information effectively.
The ratio of number of paramedical individuals to households was very low.
We also saw that in most government-run hospitals, due to the extremely low doctor-patient ratio, long queues of waiting patients abounded.
Collecting health information was a time consuming process and most doctors/ health workers felt that tremendous amount of their time would be saved if the target community were facilitated to provide their individual records of basic subjective evidence of disease.
We therefore decided to design a text-free health information monitoring form that could be filled out by the patients themselves.
This would be stored and sent to both medical practitioners and the public health care department for effective identification of disease and useful information sharing.
As we were dealing with an illiterate audience, the interface had to use the medium of graphical representation, and the main question that arose was - which medium of graphical representation would be best suited to aid better understanding of decontextual information Our goal was to compare ten different kinds of representations   text, static drawings, static photographs, hand-drawn animations, and video, each with and without voice annotation   to see how comprehensible they were for an illiterate audience.
To this end, we ran a user study with 200 illiterate subjects who were each presented with 13 different health-related concepts to identify, in one of the ten representations mentioned above.
The experiments revealed some unexpected results.
Among the findings, (1) voice annotation generally helps in speed of comprehension, but bimodal audiovisual information can be confusing for some illiterate users; (2) richer information does not appear to be better overall, with hand-drawn cartoons faring better than photorealistic representations; and (3) the relative value of dynamic imagery (video and animation) versus static imagery (photo and drawings) depends on many factors.
More results will be presented in the penultimate section.
In addition to the results of the user study, we also present a methodology we developed to suit our specific target user group, to generate each of the representations tested.
This methodology addresses three of the concerns we had at the beginning of the work: First, what was a meaningful, concrete domain in which to test the abstract representations?
Second, how could we ensure that the visual representations we used for the test were comprehensible to the target community, especially when there were cultural differences between the testers (us) and the subjects?
Third, how could we ensure a  fair  test between the representation types so that no undue bias existed in the content itself?
We based our project in five urban slum communities in Bangalore, India.
We gained access into these communities by working with a nongovernmental organization (NGO) and a government-run hospital, both of which have been working with people from these slum communities for the past 15+ years.
Most of the people in these slums were either semi-illiterate or illiterate.
They were all, however, numerate, and were comfortable reading and writing numbers and performing arithmetic.
The age group of people we worked with was between 25 and 55.
They all belong to the lower income bracket, with a combined family income of between 20 to 50 USD per month [1].
All were comfortable with the local language, Kannada; some additionally spoke Hindi or Tamil.
As potential traits which may have biased our results, we report that the subjects were predominantly women (the men were far less accessible, as they worked outside the slums), and all the subjects volunteered to participate in the design process.
There were a number of challenges we faced in designing the experiment itself.
First, we needed to identify a good domain in which our ten representations could be compared.
It is good to try to compare videos against photographs, but what should the videos be of, that our subjects would respond meaningfully?
Second, we needed to ensure that the visual representations that we used were maximally comprehensible to our test subjects.
We took special care to ensure that the representations were not our own representations for the concepts, as our subjects had cultural biases different from ours.
Third, we did our best to normalize the representations so that the the comparative representation instances of representation.
We describe our approach to solving these methodological issues below.
We first needed to identify a domain that would allow us to test the various representations meaningfully.
In particular, we felt it was important to work in a domain in which concepts would  tests would differentiate between type and not the specific

 on a daily basis,


 job-related the following In addition, we wanted to work in a domain where the immediate results of our experiments could be applied to a practical purpose.
Among the different domains we considered   including education, information, government programs, religious rites and rituals, and so on   healthcare seemed to best fit these criteria.
Specifically, we decided to test representations of common symptoms of illness.
Medical symptoms readily have visual representations and have semantics that can be understood regardless of culture.
They also offer a range of cognitive and visual complexity.
We settled on thirteen commonly occurring health symptoms: headache, vomiting, difficulty in getting up from sitting position, difficulty in breathing on mild exertion, fever, lockjaw, back ache, skin infection, weakness, swelling of feet, stiff neck, sore throat, and bleeding gums.
These symptoms are multimodal in nature, involving elements of color, temperature, and proprioception, while some require motion, spanning some temporal duration, to be clearly illustrated.
Finally, our field studies suggested that efficient medical data-gathering was a pressing need.
Much effort could be saved if there were quicker ways to capture health information than through verbally administered it was appropriate to design a graphical health information collection form which could be installed at primary health-care kiosks so that illiterate patients would be able to enter their own individual health data.
Once we decided to use health symptoms as a test domain, we then needed to ensure that the visual and audio representations we supplied were appropriate for the test group.
To accomplish this, we involved a sample design group of subjects, who were part of the same community from which we interviews.
Thus no overlap between the design group and the test group.)
Using participatory design methods, we involved the design group in generating gestures for the visual representation of the health symptoms.
We asked our design group to help us generate gestures and other visual indicators to represent each symptom.
There were
 performed the exercise in isolation, without interaction with other participants.
Two techniques were used to elicit the appropriate gestures from our subjects:
 The limbs of these dolls could be manipulated.
The participants of the exercise were asked to depict a given symptom using these paper dolls.
Figure 1.
Subjects maneuvering the paper dolls in the participatory design exercise.
The participants were asked to enact the given symptom without using verbal communication.
Figure 2.
Subject enacting the word  weakness .
Participants came in one after another and were asked to go through one of the exercises depending on which they preferred.
The session was photographed extensively so that these gestures could then be captured in the design of the graphical elements by a professional artist.
Reassuringly, we found that most of the participants showed similar gestures for a given symptom.
In both exercises, we additionally asked verbally, how the symptom ought to be depicted.
These questions elicited additional information, such as indications of skin color, etc., that was not immediately captured by the paper-doll or enactment exercises.
All voice annotations were generated by colleagues who spoke the native language of the subjects.
It should be noted that this design step was essential for the experiment.
There were differences the way we, as experimenters, thought certain words and phrases should be depicted, and the way they were actually depicted by design-in group participants.
As an example, to depict the symptom  weakness,  we imagined a man feeling dizzy, holding his head, and possibly fainting.
But, the participatory design exercise revealed a different depiction: across the board, our subjects identified weakness with physical pain in the limbs.
In retrospect, this is consistent with the fact that their daily occupation involved hard physical labor.
Our final concern was whether we could fairly represent health symptoms in each of the different visual representations such that there was no bias toward a given representation.
To arrive at some consistency, we undertook the following process: Video: We began by shooting a full-color video clip of the gestures offered by our design group.
Videos consisted of short recorded clips of a primary actor performing actions that described a given symptom, as indicated by our design group.
The videos also captured secondary information such as skin coloration and background visual context.
Videos were shot to take no more time than needed to illustrate the concept as determined by the design group.
This resulted in videos of average 13.5 seconds duration.
Photograph: Next, we took the video and extracted one key frame that the design group felt best represented the concept, using the key frame as the photographic representation of the symptom.
As with video, textures and colors are captured in this form of visual representation.
Animation: We then asked a professional animator to animate the concept, using the videos as a basis.
In all cases, the animator drew cartoon sketches which traced the outlines of only the visual elements relevant to the symptom.
Thus, the result was dynamic imagery like video but without photorealistic detail.
Color and textural elements were preserved only if relevant in illustrating the symptom.
Static Drawing: Finally, we took the sketch corresponding to the key frame selected for the photograph for the static drawing.
Color and textural elements were preserved only if relevant in illustrating the symptom, but obviously, motion elements were lost.
Text: This version consisted of words of written text in the local language, Kannada.
The written phrase corresponded with the voice annotation used to represent the symptom.
The result of this process is shown in Table 1.
To compare designer intuitions with actual experimental results, we also created a framework to indicate whether we thought a dynamic or static representation would be better suited to capturing each symptom.
For example, the designers felt that a dynamic mode of representation (animation) to depict swollen feet was better because a time-based progression from a normal foot to its extreme swollen state would be far more informative than a static visual.
Another example is that the designers felt a photograph to represent skin pigmentation was better because colour and texture were the primary visual cues for the accurate recognition of these categorizations in detail.
information.
Table 3 shows this their residences,


 Our 200 subjects were illiterate and semi-literate and were drawn from the same community as mentioned in the target community section.
Most of them were never previously exposed to computers.
The tests were conducted in community centers near their homes or at in an environment they were familiar with.
We the combination of the five visual representations (text, drawing, photograph, animation, and video) and two audio representations (no audio, voice annotation).
We randomized the experiment such that each representational type was tested on 10% of the participants (20 subjects for each representation).
The three-step process of testing was as follows:
 and asked to explain the word or phrase that first came to mind, in regards to the symptom that the character in each representation was suffering from.
ten representational types, based on tested all
 the representation had intended to convey.
intended symptom in a manner that they thought was best representative of it.
This step was meant to provide additional insight into the analysis of the data.
Each subject saw only one of the ten representations.
For each symptom, we recorded the time taken to respond, as well as the total number of correct answers.
In addition, all verbal remarks made throughout the exercise were transcribed for later analysis.
Based on the data we collected from user studies, we have the following findings supported by the standard Students t-test of statistical significance.
A summary of the overall accuracy and responsiveness data is given in Figure 1 and Figure 2.
better understood than the representation types without audio.
As had been proposed by earlier work [2, 12, 13, 28, 29] voice annotation was confirmed to be of clear value.
All visual representations with voice annotation were better recognized than the corresponding representations without.
With audio, results show that accuracy is greater in all versions (t=2.461).
Again surprisingly because of the finite time taken to listen to voice annotations, all of the representations allowed for shorter response times   approximately 30% less   with audio than without (t=1.326).
However, we point out that the apparent value of voice annotations should be counterbalanced by the observation that some subjects quickly learned to mimic the voice annotation without thoroughly understanding what was being said or depicted.
annotation representation, some subjects they didn t understand term for  lockjaw  but simply mimicked the voice annotation they heard.
This suggests that good visual representations are still important for certain concepts.
text+voice that the Kannada Particularly revealed the in recognized (t-stat=3.640
 representations accompanied by voice annotation was the most accurately for accuracy).
This advantage was marginal (only 1% more accurate) over animation with voice, which was its nearest contender.
We suspect that one reason why hand-drawn static images and animations fared well was because semi-abstracted drawings in which only the essential information is depicted is better grasped than photorealistic imagery that contains extraneous visual features.
animation was the most accurately identified among the five representations without audio.
It resulted in 7.35 correct identifications out of 13.
Compared to the nearest contender, static drawing identifications), animation leads (t= 2.2782) by a large margin of 23%, for accuracy.
The nearest contender to static is photo, which lags marginally (5.45).
Video and static drawings are second most accurately understood, and photographs were least accurately identified.
Surprisingly, animation+voice, which takes finite time to deliver, also resulted in the quickest response times, though this was a relatively weak, if still statistically significant result (t=0.606).
(which has 5.95 correct the






 ACCURATE RESPONSES (out of 20)














 AVERAGE RESPONSE Without AUDIO AVERAGE RESPONSE With AUDIO Figure 1.
Average number of accurate responses in the tests taken (13 questions per test).
AVERAGE TIME TAKEN (sec)
























 AVERAGE TIME Without AUDIO AVERAGE TIME With AUDIO Figure 2.
Average time taken to complete the tests.
During our tests we made a number of qualitative observations, as well.
These results were not statistically significant, but we present them here as qualitative data and avenues for further investigation.
understood overall: We were interested to test whether our designers  bias [Table 2] was justified by the results.
In certain cases we noticed that richer information was not necessarily better for the audiences  understanding.
For example while depicting the symptom of weakness the designers  bias was with video (dynamic mode of representation) so as to lay the context of intense physical activity before showing the state of inertia caused by weakness.
However static drawing proved to be better as the audience were confused by the additional rich information (of intense physical activity) before the primary action (principal actor feeling weak) and thus drew inaccurate conclusions.
value of static versus dynamic imagery: Although aggregate data is presented above, an interesting question is whether different symptoms are better represented by different representation types.
The answer seems to be a qualified  yes .
Table 2 shows the best-guessed representations by the visual representations without audio assist, was that placing a context-laying activity that was unrelated to the principal action cue caused confusion amongst the subjects.
For example, while describing the symptom of mild fever the video used the context laying activity of an attendant wringing the cloth and then placing it as a cold compress on the fevered forehead of a patient.
The photo representation of the same symptom showed only the action cue of the principal actor (the patient) lying down with a cold compress being placed on forehead.
The latter version was more clearly interpreted by the subjects.
cognition: We had based our project in five urban slum communities.
Within each community, the residents came from similar caste groups and socioeconomic conditions.
We noticed that subjects from the economically better-off slums who typically had more formal education performed better overall throughout the experiment, generally responding more quickly, accurately, and with greater confidence.
was difficult: In the representation types with voice annotation, we saw that some of our subjects were unable to fully process the bimodal stimulus.
They inevitably used a strategy of focusing either on the graphic or the audio, but not both.
If not told, some of them did not understand that the voice annotation was meant to explain the visual graphic presented on the screen at that moment.
This phenomenon was particularly pronounced in subjects from the economically worse slums.
When we tested the text+voice representation with totally illiterate subjects, they listened intently to the audio cue, and ignored the onscreen text completely.
A number of issues came up during the experiments which could have biased the results in one way or another.
We do not feel these were serious enough to invalidate the results, but we record them here, so that our results can be taken with the appropriate caveats.
If the presentation of symptoms was in an order where each of the consecutive symptoms was associated with a complaint of one kind (e.g., some sort of pain or ache), the subject s seemed to become inclined to think only of symptoms of the same category.
For example, if the first three symptoms presented in were headache, backache, sore throat, one after another, then the user was more likely to perceive the next symptom presented as an ache or pain of some sort.
This issue was mitigated by the fact that all representation types suffered from the same issue, as the symptoms were presented in the same order for all subjects and all representation types.
Subjects who had some basic level of schooling exhibited significant nervousness when they were shown the text based version, as they seemed to feel the same pressures they may have faced in school.
We did our best to allay their fears, but the results may nevertheless show a slight bias against the text representations.
There are four areas of related work which are particularly relevant for our research.
The first is the various representational techniques and media in visual communication.
The second is research that explores the use of auditory interfaces for information communication.
The third is the literature that looks at developing a specific kind of representation for a given target audience in the health industry.
The fourth is the literature investigating graphical user interfaces for non-literate users.
To our knowledge, our work occurs at the unexplored intersection of these four streams, with some differences from existing research that distinguish this work.
Representational techniques and media in visual communication: The first stream looks at various representational techniques and media from a visual communication perspective.
This literature is rich and spans decades.
For our purposes this literature can be categorized into two categories: (a) Research that looks at one representational style or technique in-depth and (b) research that looks at multiple representational styles or techniques either categorizing or comparing these styles to establish which enables better communication.
In the first category, most of the work has been done in developing iconography, visual and pictorial symbols.
Among these are works on international graphic symbols [10, 16, 17] handbooks for pictorial symbols [30] icons and symbols for graphical user interfaces [16, 24, 25, 8], design principles and frame of reference for designers to develop new symbols [16].
Very little of the recommendations presented in this body of work, however, is based on rigorous tests with live human subjects, and definitely not with illiterate populations.
In the second category, there is a large body of research works compare two representational styles [4, 6, 20, 22, 32, 31, 34, 38,
 representational styles into a unified progressive framework [9].
in a variety of Most of the work that compares representational styles draws comparison between animation and static imagery [20, 22, 32, 38,
 the benefit of using animation learning environments [22, 32, 38, 45, 48,].
There are other works which have failed in finding benefits of animation [4, 31, 6, 39, 40, 34,
 reasons how bias towards a particular representation style (animation in this case), in terms of content presented and experimentation procedures have led to emergence of results in favor of animation.
This is in agreement with our process of generating representations without bias towards any particular type of representation.
Existing literature also suggests that clever schematization of static diagrams may be just as effective as animation [46].
This particular research work supports our finding that static imagery when carefully designed to consist of distilled information without extraneous details can be accurately understood.
Most of the work in this category of existing literature however does not compare other representational techniques and media and does not address the population we are addressing.
Effectiveness of auditory interfaces for information communication: In this stream there are research papers which have demonstrated the utility of auditory icons in addition to standard graphical feedback in communicating information to users [2, 12, 13, 28,
 annotation generally help users in speed of comprehension.
Existing literature also suggests that auditory icons are an intuitively to provide multidimensional, organized information to users [13].
Developing a representation for a given target audience in the health domain: The third stream of relevant work focuses on developing a specific kind of representation for disseminating and gathering information designed for a given target audience.
Much of this work has been done in the healthcare domain.
In this stream there is a body of work looking separately at the use of iconic graphical language, photographs and illustrations in the health care industry.
One research group has looked at designing an iconic graphical language for an interface of a mobile computing device to be used by health workers in emerging markets with minimal exposure to computing technology [15].
Another group has developed a graphical iconography to help people with limited English proficiency navigate health care facilities [1].
A few researchers look at photography as a tool for imparting health education and collection of data on diabetes [11].
Another group emphasizes preventive healthcare and health education, through illustrations to make difficult information easily accessible [49].
Graphical UIs for illiterates: The fourth stream of relevant work is more recent and it investigates user interfaces for non-literate users.
Early researchers in this area place emphasis on the need for contextual design methods to explore this problem, as non-literate users are very different from the target user imagined by most UI designers [7].
We follow this lead, and have spent literally hundreds of hours in the field, working with non-literate women.
Most previous work with non-literate users suggests the use of graphical information.
In particular, researchers immediately intuited the value of sound accessible way to use through our methodology of imagery in place of text, and extensive use of graphics is advocated by most of this work [15, 18, 28, 29, 35, 36].
Among these, some also investigated on the value of voice annotations and instructions, which are of obvious value to non-literate users [28, 29, 37].
Some authors note the plausible inclusion of number, as non-literate users are often numerate [28, 29, 35, 36, 37].
Others focus on the need for ultra-simplified navigability as a design element [15].
While this previous work suggests excellent UI design elements for the non-literate user, none so far look at investigating the optimal representational mode in graphics imagery based on comparison of various media.
All such previous work suggests that information should be provided in graphical, rather than textual, form.
Following this lead we further look in depth fairly stacking one representational style against the other and investigate the optimal representation for illustrating a given concept for illiterate users.
We have performed a controlled experiment testing a variety of representation types against one another and with some confidence have established that semi-abstracted static imagery accompanied by voice annotation in the best representation for illiterate users on computing devices.
In summary while exploring representational techniques for visual communication and audio icons is not entirely new, our work takes one step further and compares different representational techniques and media using a methodology that fairly stacks one representation style against another and performs rigorous experiments with human subjects to establish which style is the most accurately understood by our target audience.
To our knowledge, the work presented in this paper is novel because (1) it addresses a population that is generally ignored by the computing industry, (2) it performs a controlled experiment testing a variety of representation types against one another, and (3) it confirms with some confidence that voice annotation and semi-abstracted drawings are ideal for illiterate users of computing devices.
In order the optimal audiovisual representation for illustrating concepts to illiterate users, we presented 13 different health-related symptoms to a group of 200 illiterate subjects for them to identify.
Results show that (1) voice annotation generally helps in speed of comprehension, but bimodal audiovisual information can be confusing for the target population; (2) richer information is not necessarily better overall, with hand-drawn cartoons faring better than photorealistic representations; and (3) the relative value of dynamic imagery (video and animation) versus static imagery (photo and drawings) is mixed.
These results were shown with statistical significance, and we believe that these concepts could be applicable to designing UIs for other illiterate user groups in other information domains.
In future work, we are looking at applying these principles which we discovered to the UI design of an application in a relevant domain to illiterate populations.
We would like to take the work presented in this paper, and apply it directly to a health form for effective health-status monitoring of remote rural areas where the number of health practitioners who monitor health information is proportionately very low.
With a better understanding of the best representation to use, we hope that our design will make it easier to collect health data.
