Existing web search engines cannot integrate the information from multiple interrelated pages to answer keyword queries meaningfully.
The next-generation Web search engines require link-awareness, or more generally, the capability of integrating the correlative information that are linked through hyperlinks.
For example, to search for the conferences including the topic of  Information Retrieval  and held in  Beijing 2008 , users issue a keyword query of "Conference 2008 Beijing Information Retrieval" to a search engine like GOOGLE.
As we all know, "WWW 2008" is held in Beijing and  Information Retrieval  is one of its major research topics, but surprisingly, the homepage of "WWW 2008" is not in the top-10 results and not even in the  rst one hundred answers either.
This is because "WWW Copyright is held by the author/owner(s).
2008" splits its information into several pages methodically.
The page of Important Date contains keywords "2008,Con-ference", "Information Retrieval" is contained in the page of Call-For-Paper and "Beijing" is included in the homepage.
Consequently, existing search engines often include a number of false negatives due to the limitation of their models which take only a list of individual pages as the result but neglect the fact that interrelated pages linked by hyperlinks may be more meaningful.
However, this is not an ad hoc problem but ubiquitous over the Internet.
As XML is widely recognized as the data interchange standard over the Internet, the research community has been introducing keyword search capability into XML documents[3,
 be universally applied to Web pages and XML documents.
Therefore, providing both e ective and e cient search ability over such heterogeneous collections within a single search engine remains a big challenge.
This calls for a framework for indexing and querying over large collections of heterogeneous data.
To address these problems, we propose an e ec-tive search engine Sailer based on Structure-Aware Indexing for uni ed retrievaL of hetERogeneous XML and web documents.
As opposed to the traditional search engines, which return a list of individual pages as the results, Sailer extracts a set of relevant pages, which are highly interrelated and related to queries.
We model the Web pages and XML documents as graphs, where the nodes are respectively pages and elements and links are hyperlinks between pages and parent-child relationships (or IDREF) in XML documents.
We can translate the problem of keyword search over the heterogeneous data to the problem of  nding the connected trees with minimal cost over the graphs, which contain all or a part of input keywords, called Steiner trees.
However, it is fairly di cult to extract the Steiner trees in a large graph, which is NP-hard [1].
Alternatively, we devise indices for facilitating keyword-based search over large graphs.
Definition 1.
(Pivotal Node) Given a graph G, a keyword ki, and a node n   G that directly or indirectly contains ki, the node pn(ki,n), which directly contains ki and has the minimal distance with n, is called a pivotal node.
That is, pn(ki,n)=argminnr{ (nr,n)|nr   G}, where nr directly contains ki and  (nr,n) denotes the distance between nr and n.
K={k1, k2,  , km}, and a graph G, consider node n   G, the subtree rooted at n and containing the pivotal paths from n to every pivotal node pn(ki,n) is called a Pivotal Tree.
Pivotal trees are compact connected trees in the graph, which contain all the input keywords, and therefore they can be taken as the answers of keyword queries.
We present how to e ectively rank the pivotal trees.
Given a pivotal tree PT and a keyword query K={k1, k2,  , km}, we present Equation 1 to rank the pivotal tree PT .
Score(root(PT ), ki) Score(K,PT ) = m(cid:88) (1) k=1 where root(PT ) denotes the root of PT .
Score(root(PT , ki)) denotes the score of ki in PT .
Given any node n and a keyword ki, we present how to assign the score of ki in n (i.e., Score(n, ki)) as follows.
If n directly contains ki, we propose Equation 2 to compute Score(n, ki).
Score(n, ki) = ln(1 + tf (ki, n))   ln(idf (ki)) (1   s) + s   ntl(n) (2) where tf (ki,n) denotes the term frequency of ki in n; idf (ki) denotes the inverse document frequency of ki; ntl(n) denotes the normalized term length of n and ntl(n)= , where |n| denotes the number of terms in n and |G| denotes the number of nodes in G; s is a constant and usually set to 0.2.
If n indirectly contains ki, we present Equation 3 to com-n(cid:48) G |n(cid:48)| (cid:80) |n|
 pute Score(n, ki).
Score(n, ki) = Score(pn(ki,n), ki)  (pn(ki,n),n) (3) where   is an attenuation factor.
Obviously, the larger distance between ki and n, the less relevant between them.
We experimentally prove that   is usually set to 0.8.
Note that, Score(pn(ki,n), ki) can be computed based on Equation 2, as pn(ki,n) directly contains ki and  (pn(ki,n), n) can be pre-computed o line.
Accordingly, we can score the nodes that indirectly or directly contain the keywords based on Equation 2 and Equation 3.
We note that Score(n, ki) in Equation 2 and Equation 3 can be pre-computed o line and thus we can materialize such scores into the index.
The entries of the index are the keywords that contained in the graph.
Di erent from inverted indices which only maintain the nodes that directly contain the keyword, each entry of index preserves the nodes that directly or indirectly contain the keyword in the form of a triple <Node, Score, Pivotal Path>, where the Score is the assigned score of the keyword in the Node, and Pivotal Path preserves the path from Node to the corresponding pivotal node.
Accordingly, the index captures the rich structural relationships as each entry preserves the paths from a given node to the corresponding pivotal node.
We have designed and performed a comprehensive set of experiments to evaluate the performance of our approach.
We crawled a huge amount of real data from the Internet.
(a) Search E ciency (b) Search Quality Figure 1: Search E ciency and Quality There are four types of data in our dataset: i) the homepages of top conferences, such as WWW, SIGIR, SIGMOD and so on; ii) the hompages of research groups; iii) the homepages of researchers; iv) XML, PDF, WORD and PPT documents.
There were approximate 100,000,000 documents.
The experiments were conducted on an Intel(R) Pentium(R) 2.4GHz computer with 1GB of RAM.
The algorithms were implemented in Java.
We compared Sailer with state-of-the-art methods, Information Unit [6], and SphereSearch [2].
We selected one hundred queries for the experiments.
We gave the elapsed time of the  rst ten queries and the average precision of all the queries as illustrated in Figure 1.
In this paper, we have investigated the problem of uni ed retrieval over heterogeneous web pages and XML documents.
We modeled the heterogeneous data as graphs and identi ed the pivotal trees to answer keyword queries.
We proposed indexes for facilitating the identi cation of pivotal trees.
We have conducted an extensive performance study to evaluate the search e ciency and quality of our method.
The experimental results show that our approach achieves both high search e ciency and quality, and outperforms the existing approaches signi cantly.
This work is partly supported by the National Natural Science Foundation of China under Grant No.60573094, the National High Technology Development 863 Program of China under Grant No.2007AA01Z152 and 2006AA01A101, the National Grand Fundamental Research 973 Program of China under Grant No.2006CB303103.
