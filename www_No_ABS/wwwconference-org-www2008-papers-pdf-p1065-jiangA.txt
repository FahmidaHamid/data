Web spam is one of the most intractable mischievousness to the search engines.
They exploit many illegal means to bene t from high ranking positions.
Many link-based anti-spamming techniques have been proposed so far[1, 3, 2, 4] for combating them.
In general these approaches are all biased PageRank algorithms.
As mentioned in previous work [1, 4], the seed selection plays an important role in di er-ing good pages from bad ones.
Traditional approaches such as TrustRank[1] and ParentPenalty[3] usually use a manual process to carefully select a small seed set.
However, this process is always time consuming.
It is lumbersome and awkward for periodical refreshing of the seed sets, especially   Corresponding author Copyright is held by the author/owner(s).
when the spamming tricks are adaptive and the web environment is rapidly evolutive.
Besides, when the number of seeds is small, the top ranking results are almost all occupied by seeds or their neighbors due to the re lled value of each seed per iteration in these algorithms.
As far as we know, until recently no previous work has taken these issues into consideration.
In this paper, we demonstrate our preliminary results on these research points.
Among all of the biased PageRank algorithms, propagating rank values via links from a small seed set is a general option.
However, using a small seed set has a big problem: the ranking results have a strong bias towards seeds.
That is, the top ranking results are always occupied by the seeds.
The bias is mainly due to the damping factor.
During the computation, each seed will be re lled with (1    d)   1/Ns after each iteration, where  d is damping factor and Ns is the number of seeds.
Therefore, the side e ect is large when the seed set is small.
So seeds can occupy most of the top positions in the  nal result.
To reduce this result bias, a feasible way is increasing the number of seeds for reducing the re lled value.
Since the number of seeds cannot be guaranteed always enough, we should decide the minimal number.
The point is how many top results are users concerned.
If a user only concerns top 100 results and wishes they are less a ected by result bias, the number of seeds can be small.
Whereas a user concerns a large range of top ranking results, the number of seeds should be large.
In actual fact we can estimate the number of seeds using the assumption as follows: when we concern top N results, we assume that if (1 d) 1/Ns is less than the ( N )th page s score (  is an expansion coe cient), it is less e ected by result bias.
So we can  rst get the ( N )th page s score then calculate the number of seeds.
For example, when N = 100,   = 10 and  d = 0.85, if the 1000th page has a score of
  5, we can get Ns = 3750.
We perform experiments on a partial set of pages crawled by Tianwang search engine (developed by network lab, Peking University) in Nov. 2005.
It contains 13.3 M pages with about 232 M links on 358,245 sites, most of which belong to .cn domain.
With TrustRank[1], we start from 50 seeds and double the number each time.
At each point, we randomly select
 of seeds that top 100 and top 1000 results contain.
The result is shown in Table 1.
It indicates that the top results are nearly all occupied by seeds when the seed set is small.
The number of seeds in top 100 results reaches the nadir at the case of 3200.
Table 1: Result Bias for TrustRank number of seeds in top 1000 results








 number of seeds number of seeds in top 100 results

















 To explore this trend more preciously, we start from 1600 seeds and enlarge the number by 100 each time.
We perform this experiment four times at each point and get the average.
The result is shown in Figure 1.
The x-axis shows the number of seeds while the y-axis represents the corresponding ratio.
We see this ratio runs to stable when the number of seeds is about 4000.
By checking the scores, we  nd the
  5, which is perfectly matched with our estimation in Section 2.
s t l u s e



 p o
 n i s d e e
 f o o i t a









 x 10 3
 Number of Seeds into spam category.
We throw away the nonexistent sites and reselect another one.
(cid:42)(cid:82)(cid:82)(cid:71)(cid:3)(cid:54)(cid:76)(cid:87)(cid:72)(cid:3)(cid:11)(cid:86)(cid:80)(cid:68)(cid:79)(cid:79)(cid:3)(cid:86)(cid:72)(cid:72)(cid:71)(cid:3)(cid:86)(cid:72)(cid:87)(cid:12) (cid:42)(cid:82)(cid:82)(cid:71)(cid:3)(cid:54)(cid:76)(cid:87)(cid:72)(cid:3)(cid:11)(cid:79)(cid:68)(cid:85)(cid:74)(cid:72)(cid:3)(cid:86)(cid:72)(cid:72)(cid:71)(cid:3)(cid:86)(cid:72)(cid:87)(cid:12) (cid:54)(cid:83)(cid:68)(cid:80)(cid:3)(cid:54)(cid:76)(cid:87)(cid:72)(cid:3)(cid:11)(cid:86)(cid:80)(cid:68)(cid:79)(cid:79)(cid:3)(cid:86)(cid:72)(cid:72)(cid:71)(cid:3)(cid:86)(cid:72)(cid:87)(cid:12) (cid:54)(cid:83)(cid:68)(cid:80)(cid:3)(cid:54)(cid:76)(cid:87)(cid:72)(cid:3)(cid:11)(cid:79)(cid:68)(cid:85)(cid:74)(cid:72)(cid:3)(cid:86)(cid:72)(cid:72)(cid:71)(cid:3)(cid:86)(cid:72)(cid:87)(cid:12) (cid:81) (cid:82) (cid:76) (cid:87) (cid:82) (cid:80) (cid:72) (cid:39) (cid:20)(cid:25) (cid:20)(cid:23) (cid:20)(cid:21) (cid:20)(cid:19) (cid:27) (cid:25) (cid:23) (cid:21) (cid:19) (cid:20) (cid:21) (cid:22) (cid:23) (cid:24) (cid:25) (cid:37)(cid:88)(cid:70)(cid:78)(cid:72)(cid:87) (cid:26) (cid:27) (cid:28) (cid:20)(cid:19) Figure 2: The bucket-level demotion of TrustRank scores with di erent seed sets To compare the anti-spamming abilities of di erent seed sets, we select a small seed set X using a method similar to TrustRank [1].
At the same time, we select all the sites in the .gov domain and .edu domain as a large seed set L. Figure 2 shows the bucket-level demotion of TrustRank scores when using X and L. Good sites (reputable and directory) with high rankings have little demotion, i.e. retain high ranking values.
There is no obvious di erence when using these two seed sets.
The average demotion of the good sites is almost less than 4.
However, spam sites have more demotion and using L is much better than using X.
The demotions are always larger than 5.8 with L.
In this paper, we reveal that a large seed set can achieve a better performance than a small seed set on detecting web spam for biased PageRank algorithms.
What is more, instead of carefully selecting a small seed set, we can select a large number of seeds automatically.
For example, we can just select sites in the .gov and .edu domains as seeds.
No doubt that this process is time saving.
So when using a large seed set, we can obtain good result as well as simpli cation of selecting process.
Our future work will explore some unanswered question about seeds selection.
For example, how to exploit large seed sets more e ectively and can we get  useful  bad seeds from good ones?
We will focus on these problems in the future.
