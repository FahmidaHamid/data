Conceptually, a tag is any simple idea describing an object.
A combination of tags describes the object in higher detail.
Today s tagging systems are built around users, tags and resources.
Their tags are implemented as free-form text keywords and the resources may be any web object (URLs, photos, videos, research articles, blogs, etc).
We are interested in URLs tracked by Del.icio.us, whose users bookmark pages that they  nd interesting.
It is  collaborative  tagging because users can see the tags used for the URL by the whole community or by other individuals.
So far tagging systems outpace our understanding of how to best support their socially-driven annotation model for searching the repository.
In terms of search, a single tag acts as a  lter because it selects a subset of all objects (a combination of tags selects fewer).
As Del.icio.us s repository grows, search becomes more di cult due to noise, inaccuracy, spam or lack of navigational functionality.
TagScore can help in each case.
However, we focus this work on currently missing functionality, in particular to  nd similar  pages.
Using a page s tags as  lters to  nd similar pages will not work well: a boolean  and  query will fail for pages with a reasonable number of tags, and  or  queries retrieve too many results.
The user is forced to pick and choose which  lters to apply.
Unfortunately tags do not support intuitive query re nement and such a behavior fails to make use of tags in intelligent ways.
Instead, we apply Copyright is held by the author/owner(s).
TagScore.
It rates the goodness of a tag and helps us decide how much weight to give tags in a multi-tag search.
Given a page, we have a basic synopsis from Del.icio.us: its tags, how often they were used, and the total number of bookmarks.
TagScore enriches this synopsis by also giving each tag a numeric rating (contribution) and giving the page itself an overall  con dence  score.
The overall score is used to prune very large result sets to desired sizes.
The contributions are used for the synopsis similarity measure.
TagScore.
We rate tags with a weighted TFIDF-based approach.
It is simple, fast1, works well for tagging [1, 2] and allows us to score pages independently of each other.
The raw scores are weighted to re ect where in the page tags match and the community s notion of their importance.
We address tagging s common criticisms by lessening the impact of idiosyncratic tags using frequencies and combat-ting word sense ambiguity by also matching related words.
Using pre-built global lookups for cooccurrence and Word-Net, we obtain up to 100 related words for any word in our dataset (DMOZ100k06 [3]).
These are rated the same way as the tags, and their contributions are compounded into a single albeit abstract tag.
Related terms are important for two reasons.
An average page has only 5.0 tags and its tag bag is coarse and not an exhaustive description; the terms signi cantly improve the match rate and overall score (21%).
They also smoothen the distribution by reducing the number of ties.
The  nal contributions of the abstract and user tags are combined (using several normalizations and geometric sums that insist on quality over quantity) to give a single overall  con dence  score in [0,1).
Although we score pages independently, Fig 1(a) shows that TagScore gives a near-uniform score distribution for a randomly-sampled dataset.
The above computations are reasonably fast and scalable.
The bulk (71%) of execution time is in disk IO, which can be cut in half with the lookups in memory.
Synopses.
Tags are a succinct synopsis of a page.
Finding similar pages can be considered a multi-tag search where tag overlap is maximized.
We enrich the basic synopsis by attaching a few extra bytes per tag for its rating.
There is an obvious space vs accuracy trade-o  here, and we use a minimal amount.
A comparison between enriched instead of basic synopses is slower, but only by 4% since the enrichment is a matter of bytes.
The accuracy gains, however, are far larger (Fig 1(b)).
T = P  s meta T = P  s title T = User tags Samples Avg/Median TagScore 0.415 / 0.39 (  = 0.22) 0.555 / 0.59 (  = 0.22) 0.460 / 0.53 (  = 0.24)




 No related terms







 (-8%)
 Table 1: Summary of Fig 1(a).
Also shows TagScore when not using COoccurrences or WordNet.
TagScore distribution for our dataset Correlation with cosine similarity, top-25 results Correlation with cosine similarity, ranking similar pairs from large set


 e g a p i t s n a g a
 s e b a l l r o f e r o c





 T = P s title T = user tags T = P s meta




 Percentile





 n o i t l a e r r o


 E1: +enriched; avg.
of 126 measures E2: +enriched; min.
of 126 measures N1: enriched; max.
of 30 measures N2: enriched; naive (overlap/tag-freq)


 n o i t l a e r r o




 enriched best non-enriched

 TagScore percentile [higher = more low-scoring pages pruned]













 TagScore percentile [higher = more low-scoring pages pruned] (a) TagScore distribution for using the title, tags and meta as page P  s labels.
(b) Kendall   for  given x,  nd similar to x  compared against cosine.
(c) Kendall   for  given a large pool,  nd similar x,y pairs  against cosine.
Fig 1(a) shows the TagScore distribution.
The smoothness indicates few ties.
The linearity indicates a uniform spread.
A summary is in Table 1.
We can see that title is a stronger content descriptor than user tags, and both are better than meta-keywords.
This has long been suspected by web developers.
TagScore captures this sentiment and even quanti es the di erences.
Not matching a page s meta reduces the TagScore mean by
 but does not justify ignoring meta completely because it is inexpensive.
We found that taking the  rst-25 terms is a good shortcut (2% drop in mean,   > 0.9).
Ignoring title gives a similar mean to ignoring meta, suggesting they are interchangeable for being matched against by user tags.
Correlation was very strong (0.76), but title achieves this accuracy with fewer terms and is more ubiquitous, therefore it is the more-useful component of a page.
Taking only the  rst 2.5KB of the body content produced almost identical mean, median and   as using the full body and had a very strong (0.77) correlation against the original list, yet it is on average one fth of the page source.
We  nd that this is a good shortcut in practice.
We performed a one-to-many comparison by taking a random synopsis, comparing against the others and ranking the results.
From 13 values (or combinations of values) obtained from enriched synopses, we trialled 156 di erent similarity measures for producing a ranked list by using the 13 as primary sort criteria and the other 12 to break any ties.
Of these, 126 used the enriched tag contribution variable in some way; the others used data Del.icio.us currently has.
Fig 1(b) shows a summary of the results.
The curve N2 is the naive approach.
The curve N1 plots the best instance among any of the 30 non-enriched measures (averaged over
 the 126 enriched measures.
The average of the enriched measures, E1, was much better.
The result is clear: even the worst of the enriched measures was a closer approximation to cosine.
We also see that   increases with percentile cut-o  as low-scoring pages are prune.
This suggests that under TagScore, low-scoring pages are indeed poorly represented by their tags.
Fig 1(c) shows a many-to-many comparison where we  nd the most similar pairs in a large pool of synopses.
We trialled one of the better enriched measures against the best non-enriched measure.
The result is clear: the ranking produced by the enriched measure is closer to cosine.
Again, we see that   increases with percentile.
and give the page an overall con dence score.
Social tagging systems have large repositories that require new methods for search.
We created a scoring function to rate the goodness of tags and summarized how it was used to  ll a gap in currently missing functionality: to  nd similar  pages in a tagged repository.
We contribute: (cid:129) TagScore, a scoring function to rate the goodness of tags (cid:129) Experiments on real Del.icio.us data to show TagScore s distribution and behavior.
TagScore allows us to quantify various comparisons, such as the author s description of a page (title, meta) compared to users  tags.
We also documented the e ects of matching related terms.
(cid:129) Two experiments on  nding similar pages in a tagged repository.
Our approximation has good correlation with cosine but is 490 times faster.
Our implementation compared about 70,000 synopsis pairs per second.
