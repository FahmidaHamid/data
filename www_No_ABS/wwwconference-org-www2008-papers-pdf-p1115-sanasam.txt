Most of the currently adopted Search Engine s (SE) optimization techniques such as personalization [5], query expansion [2], user s intent [3, 4] try to predict user s interest from past information collected from di erent sources such as user s prede ned interest, user s previously submitted queries and corresponding clicks etc.
But, user s current interest for the same query may be di erent at different times, di erent places.
Considering the famous disambiguation problem for the query jaguar, it is often dif- cult to predict whether user is looking for a car or a cat.
An interesting question that arises is  is it possible to learn user s current interest from the available information of the current query session, learn the user s interest and optimize the results instantly in real time? .
In our study, a query session starts when user submits a new query and it terminates when user changes the query or terminates the search.
If a user clicks on few links related to car (query being jaguar), it clearly indicates that he/she is currently looking for the Copyright is held by the author/owner(s).
jaguar car.
If user further expands the search by extending to next page or reformulates the query, then the SE can instantly optimize the results by selecting only car related results or reformulating the query.
Optimizing the results in real time can provide a unique experience to the users and make the search engine self adaptive.
This is the main motivation of this paper.
The studies on search results clustering [6] have conceptual similarity in which similar results are placed in groups and a user can explore the groups based on his interest.
But, learning user s current interest and user s current search be-haviour in real time has a potential for the search engines to adapt di erently to di erent users in real time.
In this paper, we focus only on learning user s current interest from the clicked information submitted by the user at the time of search.
The model can also merge with the information learnt from the past to enhance the performance, but such a study is beyond the scope of this paper.
We de ne user s interest as a set of terms that can well represent the user s interest.
A term could be an unigram or bigram.
In the above jaguar example, the set of terms such as {car, model} could represent user s interest that user is looking for the jaguar car.
We now formally de ne the problem as follows.
Problem Statement: Let T be the set of results that has been exposed to the user and each result ti in T be a set of terms present in the snippet of the ith result.
We divide the set T into two disjoint subsets Tc and Tc = T   Tc representing the set of clicked and not clicked results respectively.
i ti be the set of terms in T , where n = |T |.
Now Let W =  n the problem is to determine a set of terms     W which can well discriminate Tc and Tc such that terms in   frequently occur in Tc and less frequently occur in Tc.
If Pc(w) and Pc(w) are the probability distribution of w over Tc and Tc respectively, we de ne a weight on each word w as (2   Pc(w)) (2   Pc(w)) d(w) =| Pc(w)   Pc(w) | .
log (1) The values of d(w) ranges from [-1,1].
Larger the value of d(w), higher is the probability of occurring w in Tc.
Large value of | Pc(w)   Pc(w) | in Equation 1 means high frequency of occurrence of the word w in one of the two sets (Tc and Tc) and low frequency of occurrence in the another.
The log part represents the popularity; more positive: terms are more popular in clicked set and more negative: terms are more popular in the not clicked set.
We de ne the set of the
 sions which expand more than 1 pages.
Table 2: It shows the performance of the proposed mechanism in predicting user s interest in next page.
#query ses.
query length % of query sessions which expands beyond page 1






 2 to 3 4 to 5 >6 session with Avg.
Accuracy #Avg.
predicted results query length


 2 to 3 4 to 5
 >6




 words interested to the user as   = {w|w   W, d(w)    } and the set of words not interested to the user as   = {w|w   W, d(w)    } where   and   are the thresholds.
We have considered   = 0.5 and   =  0.5.
The reason for ignoring the words {w|  < d(w) <  } is that they are likely to be noisy.
Given a new result t /  T , the weight of the user s interest on the result t is de ned as follows.
f (t) = d(w) (2)
 w ( ) t If f (t) is positive, then we consider t as interested result to the user.
In this paper, we focus on predicting the user s likely to be interested results.
All the experimental data used for discussion in this section are collected using a tool[1] which were used by a small community of around 12 users.
This tool is a metasearch engine which monitors and records the users behaviour and performs few possible optimizations.
For each new query request, the log contains the query, query session id, time of the request, ip address.
For each click on the results, the log contains the url, rank of the url in the list of the results, time of the click, query, session id, ip address.
It also maintains a cache containing detail information of the results and the clicks for every query session.
It allows the tool to process the request in real time.
Table 1 shows the characteristics of the query sessions.
From the complete log data, we have considered only the query sessions which have expanded at least upto two pages.
We assume that expanding to next page means, user is not satis ed with the results in the  rst page.
The entries in the 2nd row and 3rd column clearly indicate that users are not satis ed with the results in the  rst page (at least) in 19.71% of the total query sessions.
From the third row to sixth row of Table 1, it clearly shows that the query session with very short and very long queries are more likely to be expanded compared to the query sessions of query lengths 2 to 3 words.
We extract the unigrams and bigrams from the snippet of each result and W (see Section 2) is a set of the extracted un-igrams and bigrams.
Therefore, the user s interest is de ned by the set of unigrams and bigrams.
We ignore stopwords.
We predict users interest   from the clicks and not clicks in the  rst page.
Using the unigrams and bigrams thus obtained using Equation 1, we predict the list of the results of users interest using Equation 2.
These predicted lists from the  rst page are then compared with the actually clicked results by the user in the next page of the expansion.
We expect that user should click on the results predicted by the system.
We de ne the accuracy of our prediction of each query session s by the following ratio.
accu(s) = #actually clicked results out of the predicted list Total # of clicks in the expanded page Table 2 shows the performance of our prediction.
For long queries (4th and 5th row of Table 2), almost all the results in the next page are covered by the predicted list.
So, it is obvious that most of the user s clicks (99% in Table 2) are among the predicted list because of its large coverage.
On an average, there is not much signi cance in predicting user s interest for long queries.
But for short queries (2nd and 3rd row of Table 2), the predicted list covers only a small portion of the results in the next page(less than 60% on an average).
Even with such small coverage, it predicts with very high accuracy.
In this paper, we attempt to identify users current interest using click information submitted by the user at the time of search and optimize the results in real time.
From the experimental veri cation, it is found that the proposed mechanism can predict users interest with an accuracy of 96.5% in real time for short queries.
