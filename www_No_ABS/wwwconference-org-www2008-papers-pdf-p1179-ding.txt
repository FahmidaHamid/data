Increasingly semantic web applications are consuming data from different sources.
It is desirable to automatically detect errors and potential issues in semantic web data before using the data.
Semantic web instance data is growing and is dominating the Semantic Web on the web[2].
In this work, we identify a new research problem semantic web instance data evaluation.
The work, while closely related to ontology evaluation, is different in that it focuses on potential and actual compatibility of the instance data with the term de nitions in the corresponding ontologies.
Unlike ontology evaluation which checks logical consistency of the term de nitions, this effort includes issues of representation style in addition to provable errors of syntax and semantics.
We found no existing work dedicated to semantic web instance data evaluation.
Previous related work aimed at general knowledge base environments mainly for ontology evaluation (e.g., [6, 4, 1,
 9]) concentrates on diagnosing semantic consistency issues.
Semantic web instance data evaluation raises two challenges: (i) to identify issues in instance data; and (ii) to develop a customiz-able and extensible approach to meet the diverse evaluation requirements required by different semantic web applications.
Copyright is held by the author/owner(s).
Figure 1 depicts our service-oriented architecture.
The semantic web instance data evaluation process is composed from interactions of independent evaluation services that communicate using a simple data interface.
Each service focuses on one evaluation task and generates the corresponding evaluation report.
An evaluation report entry typically covers the severity, symptom diagnosis, and optional repair instructions.
In order to ful ll the separation requirement, we need to identify the scope of instance data and ontologies.
Our evaluation architecture differentiated three collections of semantic web data: the instance data to be evaluated, the automatically-loaded referenced ontologies that de ne the classes and properties being instantiated in the instance data, and the user-provided optional ontologies that add de nitions and restrictions to the referenced ontologies.
Instance data evaluation considers only the issues introduced by the instance data and ignores the issues that previously existed within the referenced ontologies and/or the optional ontologies.
We identi ed six types of services under the three main categories suggested by previous work on ontology evaluation[7, 9] .
(cid:129) structural (syntactic) issues: RDF syntax parsing and validation for parsing the instance data and the user-provided optional ontologies; referenced ontology resolution for collecting the referenced ontologies from the instance data; and the syntactic aspects of OWL species classi cation.
(cid:129) logical (semantic) issues: RDFS/OWL semantics validation for verifying RDFS and OWL Lite/DL/Full semantics.
(cid:129) user-de ned (style) issues: general style evaluation for issues such as cardinality issues, and domain speci c style evaluation for issues speci c to a certain domain ontology.
URI or text of RDF document evaluation report optional ontologies instance data referenced ontologies RDF parsing and validation referenced ontology resolution OWL species classification RDFS/OWL semantics validation general style evaluation domain specific style evaluation semantic web data evaluation services Figure 1: Evaluation Service Architecture
 and extensible.
The two topmost types of service in Figure 1 must be executed  rst in sequence, and the remaining services, which take the same input, can be executed in any combination and any order.
Moreover, our architecture is extensible, for example, an OWL species classi cation service can be implemented using different OWL reasoners; and new user-de ned services for domain speci c style evaluation can be added as plugins.
In our Inference Web[5] project, we have implemented our architecture in a tool called PmlValidator for evaluating instance data encoded using the Proof Markup Language (PML)[8].
PmlVal-idator implemented and integrated evaluation services at the JAVA API level, and it is available online as a web service at http: //onto.rpi.edu/iw2api/doc_pmlvalidator.
PML instance data is encoded using PML ontologies.
Since the PML ontologies use only OWL DL, we can leverage many existing tools to provide syntax and semantics evaluation services.
RDF parsing and validation is implemented using Jena ( http:// jena.sourceforge.net/), which is also used by W3C RDF Validation Service (http://www.w3.org/RDF/Validator/).
OWL species classi cation and OWL DL semantics validation are implemented using the OWL DL reasoner Pellet (http://pellet.
owldl.com/).
Our current implementation for referenced ontology resolution uses the following heuristics: the referenced ontologies are (i) on-tologies linked by the namespace of classes and properties instantiated in the instance data, and (ii) ontologies recursively imported by the referenced ontologies.
PmlValidator also checks style issues beyond the reach of OWL DL reasoners.
Figure 2 provides several examples to illustrate the following three issues checked by our general style evaluation.
g1 pmlp:DocumentFragment rdf:type ex:docFrag1 o1 pmlp:DocumentFragment rdf:type ex:doc1 pmlp:hasDocument pmlp:hasDocument ex:doc2 g2 ex:docFrag2
 d F g3 rdf:type ex:docFrag3 pmlp:DocumentFragment rdfs:subClassOf owl:Restriction owl:onProperty pmlp:hasDocument owl:cardinality "1"^xsd:nonNegativeInteger pmlp:DocumentFragment p p g o2 pmlp:DocumentFragment pmlp:hasDocument ex:ding rdf:type pmlp:Agent g4 g4 rdf:type ex:docFrag4 pmlp:DocumentFragment pmlp:hasDocument ex:English rdf:type pmlp:Language rdfs:domain pmlp:hasDocument rdfs:range pmlp:Document pmlp:Document owl:disjointWith pmlp:Agent pmlp:Language Figure 2: Example PML instance data with style issues * * g1, g2, g3 and g4 are four independent collections of PML instance data; and o1 and o2 are the corresponding de nitions from PML ontologies.
(i) Issues related to min cardinality restrictions.
OWL DL reasoners, using the open world assumption, will not report any inconsistencies in g1 based on o1 because they assume the expected RDF triples may be found outside g1; but style issues (e.g.
missing expected RDF triples) may be reported when g1 is used by applications using the closed world assumption, e.g.
database applications that require non-null  elds.
(ii) Issues related to max cardinality restrictions.
OWL DL reasoners will not report any inconsistencies in g2 based on o1 because they cannot  nd different from assertion in g2; but style issues (e.g., existence of unwanted RDF triples) may be reported when g2 is used by applications using the unique names assumption, i.e. any two individuals with different names are different from each other unless they have been explicitly asserted to be the same.
(iii) Issues related to multiple class-memberships.
OWL DL reasoners can, for example, infer that ex:docFrag3 is a member of both pmlp:Agent and pmlp:Document in g3 using the rdfs:range statement in o2.
They will only con rm inconsistency in g3 but not in g4 because no relation between pmlp:Language and pmlp:Document has been found in o2.
While it might be unnecessary to exhaust all pairs of classes without any asserted relations such as rdfs:subClassOf and owl:disjointWith, we have found it a useful precaution to check for relationships, particularly those generated from local property value restrictions and global domain and range restrictions.
Pml Validator also adds the following service for domain-speci c style evaluation: (i) existence of PML instance data: whether the instance data contains at least one instantiation of a class or a property de ned in the PML ontologies.
(ii) anonymous URI: instances of some speci c PML classes must not be anonymous.
Semantic web instance data evaluation brings unique and important bene ts to semantic web applications: data publishers may detect and thus  x outstanding issues in the instance data; and data consumers may verify their expectations for incoming semantic web instance data and to customize and extend the domain spe-ci c evaluation services if necessary.
The above style evaluation services have been implemented and tested in PmlValidator.
Future work includes evaluation experiments and performance study of PmlValidator on large scale instance data, implementation extension and improvement to cover more style issues in instance data.
Acknowledgement: This work is supported by NSF #5710001895, DARPA #F30602-00-2-0579, #55-300000680 to-2 R2.
