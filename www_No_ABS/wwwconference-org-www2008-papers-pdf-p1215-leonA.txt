The Internet provides services, such as the online social-related services namely SNS, allowing interaction in huge networks.
One big challenge is developing e cient techniques for identi cation of highly cohesive subgroups, called communities, for large-scale networks.
Clauset, Newman and Moore (CNM) proposed a fast algorithm with O(n log2 n)[1] that could be applied to networks with sizes of less than 500 thousand nodes.
Then, Danon, Diaz and Arenas (DDA)[2] made a modi cation to the CNM to improve the modular-ity while retaining its speed.
Wakita and Tsurumi (WT)[3] proposed some heuristics to improve the speed of CNM, but with compromises in modularity in their fastest heuristics.
All these algorithms are used for undirected networks.
Undirected networks allow representation in symmetric matrices.
There are two implementation frameworks, one  both authors contributed equally to this work Copyright is held by the author/owner(s).
for CNM and another for WT.
Both of them basically use a sparse matrix that stores both symmetric values  Qij and  Qji, and keep them consistent at all times, which impact the performance in both frameworks.
For instance, any update in a pair (i, j) takes O(1) but the update of its symmetric pair (j, i) takes O(log n) because it requires searching column j in row i.
In this paper, we propose a new implementation framework to avoid unnecessary operations to the minimum and a modi cation of the DDA to  t our framework, obtaining improvements in speed and modularity compared to the former algorithms.
The use of triangular matrices avoids or reduces the previously described implementation di culties, accelerating the algorithm, because it stores half of the information required in frameworks of CNM and WT due to symmetry.
Figure 1: A new framework.
We employ two triangular sparse matrices (Figure 1(a)).
The lower triangular matrix stores the values of every  Qij where i < j, and the upper triangular matrix stores the references to their symmetric values in the lower triangular matrix.
The reference matrix allows access over the columns in the lower triangular matrix in O(1).
We use a double-linked sorted list for rows (Figure 1(b)).
The advantage is observed in deletions and updates of  Qij which is done in O(1).
We keep track of the maxj  Qij in row i only for the lower triangular matrix, reducing the search range when obtaining the maximum  Q of the row.
In order to iterate over all the neighbors of the community i, or over the whole row in the symmetric matrix, it is necessary to iterate over the elements in the lower triangular matrix and then switch to elements of the upper triangular reference matrix obtaining the position and access of their DATAREFERENCE3,13,24,37,17,27,37,5471254752133(a)(b)1215WWW 2008 / Poster PaperApril 21-25, 2008   Beijing, ChinaFigure 2: Results from the original CNN and CNM, DDA, DDA2, WT and WT2 under our framework symmetric cells in the lower triangular matrix (Figure 1(b)).
This process is done by the creation of a special iterator to switch the matrix when needed.
When all values of  Qij in the lower triangular matrix are negative for a certain row i, its maximum value is assigned to a constant negative value in order to avoid unnecessary updates in the max heap H.
In the same way, when combining two in-process communities i and j, we keep track of maxk  Qjk for the community j.
In the case that this value is negative after  nish-ing the combination, any further joining of two communities linked to j will still produce negative  Q in the community j.
As a consequence, this in-process community will produce no positive value in any circumstances, therefore, we eliminate these rows, reducing unnecessary operations.
DDA provides better modularity when treating in-process communities of di erent sizes as similar.
DDA normalizes the contribution in modularity by dividing the contribution by the degree of the in-process communities.
The main purpose of this modi cation was to improve the modularity rather than speed as pointed out in [2].
This modi cation makes the matrix asymmetric, which requires the manipulation of the full matrix.
We make a slight modi cation to the algorithm in order to use it in our triangular matrices.
ij =  Qij/ai =   Q     ij =  Qij/min(ai, aj)
 This modi cation will not compromise the result.
Where i and j have di erent degrees and i has the lowest degree, (i, j) will produce a higher value than its symmetric (j, i).
Therefore, in any case the higher value (i, j) is preferable.
We evaluate our improvements with networks of sizes up to 10 million nodes and 50 million edges generated by the CNNR model[4] that produces SNS-like networks.
We implemented the two most representative heuristics of [3], renaming the HE to WT and HE  to WT2.
We created another modi cation of DDA represented by DDA2 that uses our modi ed normalization of DDA only in the max  Q value of each row, which will be inserted in the max heap H. All the algorithms were implemented in our framework using standard C++ and executed on a PC with Xeon 2.8 GHz CPU, 64GB Ram, Red hat linux.
We should note that all programs are single process.
The e ectiveness of our framework is shown in Figure 2(a).
The CNM implemented under our framework is faster than the original CNM, implemented and distributed by Clauset.
Two reference lines obtained by  tting the results show that our framework is 7 times faster.
Subsequent experiments will employ the CNM implemented under our framework.
The e ectiveness and scalability of all the algorithms are shown in Figure 2(b-d).
It should be noted that CNM was applied to networks up to 1 million nodes because of limitations for larger networks.
Figure 2(b) shows the execution time, where all modi cations of CNM are faster than CNM, our DDA being the fastest.
Figure 2(c) presents the modularity obtained by all the algorithms, showing that our DDA and DDA2 are the highest among all the algorithms.
It should be remembered that the original DDA was modi ed to improve modularity, not for acceleration of the CNM[2].
Figure 2(d) details the results obtained by all the algorithms in a network of 1 million nodes and 5 million edges.
Though slower than DDA (still 53 times faster than the former CNM), DDA2 provides the best modular-ity among all the algorithms (13% improvement over the former CNM), and is recommended for networks up to 1 million nodes.
We presented a new implementation and a modi cation of the DDA to speed it up in our framework, obtaining an improvement of 192 times faster than the original CNM.
Large-scale networks up to 10 million nodes and 50 million edges were employed, showing that our modi cations provide better modularity and require less time compared to CNM and its modi cations.
As a result, our improvements make it applicable to large-scale networks.
