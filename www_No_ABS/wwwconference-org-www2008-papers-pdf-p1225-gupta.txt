Graph proximity queries of the form  entities related to a set of keywords  can be answered by searching for answer nodes in the vicinity of nodes matching the keywords.
Such graph conductance queries assume that a keyword-originated prestige starts at the nodes matching the query words and  ows through the graph following edges, and the rank of a node depends on the amount of prestige that reaches it.
There are di erent techniques proposed in literature to compute search rankings; one of which is HubRank [3].
HubRank builds on Personalized Pagerank [4] and Berkhin s [1] Bookmark Coloring Algorithm (BCA).
pr =  Cpr + (1    )r = (1    )(I    C) Consider a graph G = (V, E) where each edge (u, v)   E is associated with a conductance C(v, u): probability of v C(v, u) = 1.
a  random surfer  walking from u to v; Personalized PageRank Vector (PPV) for a teleport vector (r) is then de ned as: (1) where 1     is teleport probability (typically 0.2 0.25).
r is set such that r(u) > 0 only if u is a match node and
 u r(u) = 1.
When r(u) = 1 for a single node u, we call its P P V as P P Vu.
Given a hubset (H) of nodes with precom-puted P P Vh  h   H, we can use Berkhin s [1] asynchronous push to compute pr for a general r as shown in algorithm 1.
 1
 r For ad-hoc search applications, it is adequate to report Copyright is held by the author/owner(s).
the answer nodes with the top-k personalized PageRank values.
At some time during the execution of algorithm 1, let u1, u2,  be the nodes sorted in non-increasing or der of their scores ( pr) then by proposition 1, we can say that u1, u2,  , uk are the best k answer nodes i   pr(uk)    pr(uk+1)+ (cid:5) q (cid:5)1.
This is the basic idea behind early termination of the algorithm while guaranteeing top-k answers.
Proposition 1.
In algorithm 1, at any time,   nodes u,  pr(u)   pr(u)    pr(u)+ (cid:5) q (cid:5)1 In search applications, if the user asked for K = 20 responses, it is typically acceptable if the system returns a few more (say K = 40).
So, we propose that the number of responses be bracketed in [K, K].
This substantially increases the success rate for termination check.
About half the queries terminate through algorithm 2.
Also, the actual rank K at which the termination check succeeds is typically very close to K. Further, we re ne proposition 1 as: Proposition 2.
In algorithm 1, at any time,   nodes u, q(u) +   (cid:5) q (cid:5)1  pr(u)   pr(u)    pr(u) + (1    )  
 Algorithm 1 Basic Push Algorithm 1: q   r,  pr   (cid:2)0 2: while (cid:3)q(cid:3)1 > push








 12: return  pr pick node u with largest q(u) > 0 {delete-max} Node deletion check {Only for Delete-Push; Alg.
3}  q   q(u), q(u)   0 if (u   H)  pr    pr +  q PPVu if (u (cid:5)  H)  pr (u)    pr (u) + (1    ) q for each out-neighbor v of u top-k quit check {For basic topK+DeletePush;Alg.
2} q(v)   q(v) +  C(v, u) q {increase-key} Maximum increase in  pr(u) due to  ow of q(u) that can happen (till push-algorithm termination) is (1    )q(u) +  2q(u).
Similarly, maximum increase in  pr(u) due to  ow of residual from nodes in V other than u is  ((cid:5) q (cid:5)1  q(u)).
Thus,  pr(u) can increase atmost by (1 )q(u)+ 2q(u)+ ((cid:5) q (cid:5)1  q(u)) = (1    )2q(u) +   (cid:5) q (cid:5)1.
However, this better upper bound is dependent on q(u) and so we will need to maintain lower and upper bounds separately as against in proposition 1.
So, we relax the bound as: Proposition 3.
In algorithm 1, at any time,   nodes u,  pr(u)   pr(u)    pr(u) + (1    ) q(u) +   (cid:5) q (cid:5)1 max
 u Algorithm 2 Top-k termination check for Basic Push insert u into M if (|M| < K) else let v   M have the smallest score if (  pr (u) >  pr (v))
 2: for each node u in the score map  pr







 line 11 of algorithm 1 with K 
 12: return cannot yet terminate push loop if (  pr (ub) >  pr (ub+1) + (cid:3)q(cid:3)1) replace v with u
 = b   M such that  pr (u1)            pr (u
 return can terminate push loop from line 2 to Proposition 3 needs less bookkeeping than proposition 2.
These better bounds provide a 6% reduction in query time without any change in accuracy; more queries quit earlier and at lower K   .
Consider the query  nd top-k papers related to XML published in 2008 .
This enforces that the answer nodes returned should be papers, published in 2008.
In this section, we extend basic top-k framework to answer queries with such hard predicates, e ciently.
The target nodes returned as answer nodes, should strictly satisfy the hard predicates.
One of the ways is to modify  basic top-k for soft predicate queries , such that a node is considered to be put in heap M (see algorithm 2) only if it belongs to target set.
We call this as naiveTopk .
We propose a node deletion algorithm which builds on the idea that ranking non-target nodes is not needed in presence of hard predicates.
It can delete nodes without a ecting authority  ow in the remaining graph.
We then use it to delete non-target nodes in the graph while executing push.
Let V contain a special sink node s with self-loop of C(s, s) =  ows to faro  nodes) in the (out)neighborhood of node u and delete a non-target non-hubset node only if its deletion does not blowup number of new edges.
We used a 1994 snapshot of CiteSeer graph which has

 query.
All but the  rst 100K queries were used to train and tune our index.
We  xed [K, K] as [20, 40].
We used samples of typical size 10000 from the  rst 100000 queries as test data and hubset of size 15000 generated using  naive one-shot  hub inclusion policy [3].
For DeletePush expts, we selected slowest 1000 queries from the above sample.
(cid:3) (cid:3) (cid:3) .
, p (cid:3)
 (cid:3) from graph G and adapt the graph structure to create G = (cid:3)|V (cid:8)| 1 over G (cid:3) (cid:3) r(cid:8) (v) =
 pr(v) for all nodes v   V (cid:3) r(cid:8)(v) is computed over and r(v) = 0 for v /  V (v) for v   V (cid:3)
 ) such that for any teleport r (cid:3)   s where p (cid:3) , r(v) = r Let u be a node to be deleted, v be one of the in-neighbors of u and w be one of the out-neighbors of u.
Let q(v) be the residual at node v at some time instant during execution of push algorithm.
Consider the simple case when u does not have a self-loop.
v passes on  q(v)C(u, v) to u then u keeps (1   ) [ q(v)C(u, v)] with itself and passes on   [ q(v)C(u, v)] C(w, u) to w. This can be achieved by increasing C(w, v) by  C(u, v)C(w, u).
To consider the self endorsement by u, (1    ) [ q(v)C(u, v)] is grounded by sending it to sink node by increasing C(s, v) by (1 )C(u, v).
Algorithm 3 considers the case with self-loop at node u.
Algorithm 3 Node Deletion Algorithm
  C(u,v) C(w,u) if (u = v) continue for each out-neighbor w of u
 2: for each in-neighbor v of u






 The algorithm takes O(inDegree(u) outDegree(u)) time if (u = w) continue C(w, v)   C(w, v) + C(w, u)   0 {Delete u   w edge} and can potentially increase #edges by inDegree(u)  outDegree(u)   (inDegree(u) + outDegree(u)).
While performing DeletePush, we  rst pick a node u (step 3 of algorithm 1), delete all the  deletable  non-target entity nodes reachable from u (step 4 of algorithm 1) and then perform push from u.
Deleting a non-target node avoids any further pushes from it; thereby saving some work.
A single node deletion can bloat #edges, so we need to judiciously pick the victim nodes (non-target entities) to be deleted, keeping in mind these observations about social networks.
works, partitions the graph into clusters, ensuring that edges to be added due to a node deletion already exist in the graph.
follow power law [2].
Since large number of nodes have very small indegree or outdegree they can be deleted safely.
As we do not want a large amount of time to be spent in node-deletion, we use a conservative approach where we do a local search (as push may get terminated before authority Figure 1: Push times averaged across queries vs.
fraction of push time allowed in termination checks.
(The top line uses no termination checks.)
As  gure 1 shows, algorithm 2 is fast and e ective.
Quit checks take a very small amount of time and typically give a 4  speed boost.
(To control the fraction of time spent in quit checks, here we timed recent quit checks and invoked them only when enough time has been spent in push loops.)
Also reassuring is that as little as 4% time invested in quit checks result in robust gains.
Now, let us compare DeletePush with NaiveTop-k for hard predicates.
We varied target set size by having di erent hard predicates on publication years.
Note that the time re-NaiveTopK(avgTime=582ms, avgNumPush=4578) DeletePush(avgTime=443ms ,avgNumPush=2580)






 ) s m ( s e m
 y r e u q i

 (5192) Year Predicates (Selectivity) <68 (109) <83(923)

 (10607) <93 (43224) Figure 2: Comparison of top-k algorithms quired by DeletePush does not decrease in proportion with the decrease in number of pushes because of deletion overheads.
Figure 2 shows that DeletePush works better when the target set sizes are not too large.
Thus, by applying a top-k framework over the basic push algorithm, we try to e ciently answer graph conductance queries with hard predicates, achieving better query processing times with low indexing space.
