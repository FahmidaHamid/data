The problem we address in this paper stems from the Blog archiving system we are building at York University.
The system collects and indexes blog postings related to movies as they become available, with individual indexes built for various  elds, such as date of creation, header, body, and links.
Consider the following the query: how many Blog entries in the collection (a) have a body highly similar (with similarity score greater than 0.9) to a given Blog entry, and (b) were created between 01/01/2007 and 02/01/2007?
There are two ways to process this query, depending on whether condition (a) or (b) is evaluated  rst.
Clearly, the most ef cient way is to evaluate the more selective condition of the two, and then the other.
To help planning the query evaluation, it is very important to obtain a quick estimate of the number of Blog entries satisfying each condition.
This becomes more important for complex queries involving multiple data sources or predicates.
The need to obtain a  similarity pro le" of the document collection for a given query also arises from a number of other applications.
For example, in peer-to-peer text retrieval, an essential task is to guide the users to the sources that contain the most relevant documents in a fast and ef cient way.
A naive way to identify those sources is to ask each peer evaluates the query and reports the size of the query result, which are then compared to pick the best sources.
The problem with this approach is that it can be very inef cient, as the document collections at some peers can be huge, and evaluating the query at all peers will therefore be quite expensive.
In such cases, it will be very helpful if we could get a quick Copyright is held by the author/owner(s).
estimate of the  similarity pro le" of the document collection at each peer without fully evaluating the query against the collections.
For instance, the following information can be very important: how many documents are there in the collection whose similarities to the query (assuming a given similarity metric) exceed a given threshold?
This information will allow us to quickly zoom in onto the most promising peers for answering the query, by choosing only the peers with the largest number of relevant documents.
The core problem we address in this paper is to how to ef -ciently and accurately estimate the sizes of similarity queries, i.e., the number of documents whose similarities to the query (under some metric) exceed a user-de ned threshold.
We start with the vanilla sampling-based approach, in which the estimate is obtained based on a sample of the documents.
Our main contribution, however, is the calibration approach which can greatly improve the sampling-based estimation accuracy.
Our work is related to the well-studied problem of database selection ([3, 2, 1]).
However, unlike algorithms such as gGloss [3] and CORI [2] which are speci cally designed for database ranking, our approaches also take into consideration the need arising from query planning (as illustrated in the second example above), and we aim to provide a set of  general purpose" algorithms that can provide more detailed similarity pro les of collections.
Let us denote the set of documents to be queried upon byP , and the number of documents in P by N. For a given query q, denote the set of terms contained in q by Gq = {g1, g2, .
.
.
, gm}.
Let s be the number of documents whose similarities with q are greater than a given threshold  , i.e., s = |{d   P : sim(d, q) >  }|.
Here we assume that the classic vector space model is used, in which every document di is represented by a weight vector wi of index terms.
The weight of the j-th term in document di, denoted by wij, can be calculated using the well-known tf-idf (term frequency-inverse document frequency) measure.
The same weighting scheme applies to the query q.
In this paper, we assume that the cosine similarity is used, where the similarity between the document di and the query q is de ned as sim(di, q) = wi   wq/((cid:3)wi(cid:3)   (cid:3)wq(cid:3)).
Nonetheless, our results can generalize to any similarity measures.
One way to estimate s without examining each document is to employ sampling.
A naive approach is to obtain a uniform random sample S from the whole document collection P .
Note that, however, only those documents that share common terms with the given query can possibly have a similarity score (w.r.t.
the query) higher than the threshold   (assuming   > 0).
It is therefore bene cial to narrow down the sample space (and thereby improve the sampling ef ciency) by restricting our efforts to those  relevant" documents
 that an inverted list Li (of document IDs) is maintained for each term i, PR can be constructed by computing the union all relevant Li s.
For example, suppose the query consists of terms  www",  Beijing", and  2008".
The inverted lists corresponding to those three terms are identi ed, and the union of all document IDs contained in those lists are then computed.
This will be the PR for sampling.
Suppose a sample S of size n is taken from PR in order to estimate the result size of q.
S can be any type of sample, such as a simple random sample (SRS), or a weighted sample.
Let us denote the weight of the sampled document di by vi (di   S), which is the inverse of the inclusion probability of document di in the sample.
Intuitively, vi indicates how many documents that this sampled document di can represent.
For example, in the case of SRS, the inclusion probability of any document in the sample is n/N, so correspondingly the weight of any document in the sample is N/n.
We use xi as an indicator variable to indicate whether di satis es the query q, i.e., xi = 1 if di satis es q, and 0 otherwise.
An estimator of the result size s can be  s = di S xivi.
In the case of SRS, where the inclusion probabilities are all equal to n/N, the estimator simpli es to  s = N n di S xi.
It is a common practice for text retrieval systems to maintain inverted lists for the index terms.
For the purpose of result size estimation, such inverted lists represent valuable auxiliary information that we can utilize to further improve the accuracy of the sampling-based approach.
We propose to adjust the weights of individual documents in a sample, such that the sample conforms better to the known auxiliary information.
Since we maintain an inverted list for each term in the document collection, we can safely assume that we also know the number of distinct document IDs in each inverted list (the length of the inverted list).
Let the number of distinct IDs in the inverted list for term gj(1   j   m) be tj.
Ideally, the number of documents in the sample that contain this term should be exactly proportional to the sample size.
However, due to sample variations, this is rarely the case.
Therefore, we would like to adjust the weights of the sampled documents, such that tj = di S yiwi, where wi is the new weight of document di, and yi is an indicator variable to indicate whether gj appears in di (yi = 1) or not (yi = 0).
As a result, the set of known tj s (1   j   m) essentially present a set of constraints that we would like the new weights wi s to satisfy.
Once the new weights wi s are obtained, we can simply plug them into the estimator described in Section 2.1 to replace the vi s, and compute the new estimate.
When adjusting the weights of sampled documents, we also would like to keep the new weights wi as close to the original weights vi as possible.
This is because we hope to keep certain properties of the original sample design.
For example, if the sample was taken as a SRS, the estimate obtained through the estimator in Section 2.1 is unbiased.
By requiring the new weights to be as close to the original weights as possible, we expect the estimate obtained using the new weights remain nearly unbiased.
As such, calibration can be cast as a constrained optimization problem as follows: Minimize
 (1   j   m), where D(wi/vi) is some distance function that measures the discrepancy between the new weights wi and the original weights vi.
di S viD(wi/vi), subject to di S wiyj = tj
 Various distance measures can be used, as long as they satisfy the following properties: (a) D is positive and strictly convex, (b)
 (cid:3)(1) = 0, and (c) D (cid:3)(cid:3)(1) = 1 .
This optimization problem can be solved using numerical methods (e.g., Newton s method), and for certain distance measures (x   1)2), only one iteration is required, making (e.g., D(x) = 1
 the calibration process very ef cient.
It is worth noting that when many inverted lists are involved in the estimation, the presence of too many constraints (posed by those inverted lists involved) can render the optimization process unstable when the sample size is small.
Therefore, we cap the number of constraints in the equation to a certain limit.
In our implementation, the limit is set at 10% of the sample size.
The constraints used for optimization are randomly chosen from the set of all available constraints.
We evaluated our techniques on a movie data set as well as synthetic data sets.
The movie data set consists of selected Blog entries collected for movies released in the United States during the period from May 1, 2006 to August 8, 2006.
In total, the data set contains
 erating the synthetic data sets, we varied a number of factors such as the number of documents, the sample rate, and the distributions of the documents, to study the behavior of the techniques w.r.t.
to those factors.
Due to space limitation, only selected results on the movie data set are shown here.
Errors of estimation are measured .
All re-by the Absolute Relative Error (ARE), de ned as sults are averages of 30 runs.
SRS is used in the sampling-based approach.
For the calibration approach, the distance function use is (x   1)2.
The query set is generated by randomly se-D(x) = 1
 lecting documents from the date set, and the similarity threshold is set to 0.1.
The Figure below shows the accuracy of two approaches described in Section 2.
| s s| s r o r r e e v i t l a e r l t e u o s b









 Sampling Calibration



 Sample rate (n/N)
 For both approaches, the accuracy improves as the sample rate increases.
It is also evident that the calibration approach improves signi cantly upon the pure sampling-based approach.
We have presented two techniques to reason about the result sizes of similarity queries for text retrieval.
Using the techniques, a text retrieval application can quickly determine the most promising data sources, without running the query against the document collections.
The techniques can also help in query planning, and they can be easily extended to handle the estimation of other parameters of the query results.
Experiments have con rmed the effectiveness of the proposed techniques.
