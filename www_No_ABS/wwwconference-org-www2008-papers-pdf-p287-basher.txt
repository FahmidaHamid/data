In the mid-1990s, a signi cant proportion of Internet traf- c was from applications that used HTTP, the standard protocol for exchanging Web documents.
The distinguishing characteristics of Web-dominated Internet tra c include small-sized  ows, short-lived connections, asymmetric  ow volumes, and well-de ned port usage.
For the past decade, these characteristics have underpinned the tra c models used in network simulation and emulation experiments.
The introduction of Peer-to-Peer (P2P)  le sharing applications, such as Napster in 2000, triggered a paradigm shift in Internet data exchange.
P2P applications typically share large multimedia  les with individual hosts (called peers), Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
which act as both content providers and consumers.
A peer can obtain portions of a  le concurrently from multiple peers and/or obtain portions of the same  le from a single peer using one or more persistent connections.
P2P usage has grown steadily since its inception, and recent empirical studies indicate that Web and P2P together dominate today s Internet tra c [17, 21].
In this paper we use recent packet traces, collected at the gateway of a large university, to extensively characterize and compare tra c generated by Web and P2P applications.
Our focus is on characterizing the behaviors of these applications at the  ow-level and host-level.
The goal of this characterization is to develop  ow-level distributional models that may be used to re ne models of Internet tra c for use in network simulation and emulation experiments, to provide insights into the similarities and di erences between Web and P2P tra c, and to obtain insights into how current P2P applications work.
A distinguishing aspect of our work is the use of recent full-payload packet traces.
Popular P2P applications, including BitTorrent, Gnutella, and eDonkey, are known to use dynamic ports, in addition to well-known ports [6,11,20].
Identi cation of P2P tra c by default port numbers is likely to miss a signi cant portion of this type of tra c.
In fact, our data suggests that as much as 90% of P2P tra c may be on random ports.
In this work, we utilize payload-based signature matching to accurately identify P2P tra c.
Our study highlights the evolving nature of Internet traf- c due to growing P2P tra c.
In addition to studying the aggregate P2P tra c, we also analyze and compare two popular P2P applications: Gnutella and BitTorrent.
This study of individual P2P applications aids in understanding the aggregate P2P tra c trends and also helps in understanding how these two applications work.
We consolidate our understanding of these tra c types by developing distributional models for each type of tra c; these models can help re ne models of Internet tra c.
We present high-level results and key observations from our study in Tables 1 and 2.
Table 1 summarizes the similarities/dissimilarities between Web and P2P tra c, while Table 2 summarizes the similari-ties/dissimilarities between Gnutella and BitTorrent tra c.
The remainder of this paper is structured as follows.
Our trace collection, tra c identi cation, and analysis methodologies are described in Section 2.
Sections 3 and 4 present  ow-level and host-level characterization results, respectively.
Section 5 reviews related work.
Issues related to trace data collection and analysis are discussed in Section 6.
Section 7 summarizes our contributions and lists future work.
Characteristics Flow Size Web Introduces many mice but few elephant  ows.
Model: hybrid Weibull-Pareto distribution.
Flow Inter-arrival time Typically short inter-arrival time.
Distribution is long-tailed.
Model: two-mode Weibull distribution.
Typically short-lived.
Model: two-mode Pareto distribution.
Most hosts maintain more than one concurrent  ow.
Hosts maintain concurrent  ows with a few distinct hosts.
Large transfers are dominated by downstream tra c.
Heavy-hitters account for a large portion of total transfer and their transfers follow a power-law distribution.
Most external hosts are located primarily in the same geographic region.
Introduces many mice and elephant  ows.
Model: hybrid Weibull-Pareto distribution.
Typically long inter-arrival time.
Distribution is heavy-tailed.
Model: hybrid Weibull-Pareto distribution.
Typically long-lived.
Model: hybrid Weibull-Pareto distribution.
Many hosts maintain only one  ow at a time.
Hosts that maintain more than one  ow do so by connecting with many distinct hosts.
Large transfers happen in either upstream or downstream direction.
Heavy-hitters account for a huge portion of total transfer and their transfers follow a power-law distribution.
External peers are globally distributed.
Section





 Flow Duration Flow Concurrency Transfer Volume Geography Characteristics Flow Size Flow Duration Table 2: Key results: Comparing Gnutella and BitTorrent tra c Gnutella Both small and large  ows are observed.
Elephants are relatively more frequent.
Distribution is heavy-tailed.
Model: hybrid Lognormal-Pareto distribution.
Typically short-lived.
Distribution is heavy-tailed.
BitTorrent Small  ows are prevalent.
Elephants are less frequent, but comparatively large.
Distribution is heavy-tailed.
Model: hybrid Lognormal-Pareto distribution.
Typically long-lived.
Distribution is long-tailed.
Peers maintain many concurrent  ows with a large number of distinct hosts.
Transfers are comparatively less asymmetric and more balanced.
Heavy-hitters contribute more traf- c volume.
External peers are from regions with broadband connectivity.
Flow Concurrency Peers mostly connect to a single host at a time.
Transfer Volume Geography Transfers are extremely asymmetric and dominated by single direction tra c.
Heavy hitters account for less volume of tra c.
External peers are mostly concentrated in the same geographic region.
The network tra c traces used in this work were collected from the commercial Internet link1 of the University of Calgary, a large research-intensive university with 28,000 students and 5,000 employees.
We used lindump2 running on a dual processor 1.4 GHz Pentium system with 2 GB memory and 70 GB disk space to capture TCP/IP packets via port mirroring.
Identifying P2P tra c correctly in the traces is a challenge.
One approach, which has been used in some recent P2P characterization studies [17, 21, 24], is to map network tra c to applications using well-known port numbers.
However, many P2P applications including BitTorrent and Gnutella use dynamic port numbers.
This necessitated the use of payload signatures [11, 20] to identify applications.
We used Bro [15], an open source Network Intrusion Detection System, to perform the payload signature matching.
The builtin payload  signature matching engine  in Bro was used to perform the mapping of network  ows to application types.
We used the signatures described by Sen et al. [20] and Karagiannis et al. [11]; details of our payload-based identi cation scheme can be found in [6].
We identify the start of a TCP  ow using connection establishment semantics (i.e., SYN-SYNACK-ACK packet transmissions) or by the  rst packet transmission observed between hosts, and end of a TCP  ow after observing a FIN or RST packet.
By default, Bro considers a  ow terminated if it is idle for more than 900 seconds.
At the time of trace collection, the Internet link was a 100 Mbps full-duplex connection.
http://awgn.antifork.org/codes/lindump.c The payload-based identi cation technique requires traces with relevant application-layer headers.
The signature strings for some P2P applications (e.g., Gnutella) can be buried deep inside a packet [6]; therefore, successful string matching requires full-packet payloads.
This poses another challenge: the huge storage space required for full-packet trace collection from a high-speed Internet connection for an extended interval (e.g., a day or a week).
For our work, we used non-contiguous one-hour traces collected between April 6 and April 30, 2006.
The traces were collected each morning (9-
every week (i.e., eight one-hour traces per-week).
Although discontinuous traces limit the analysis of long-term tra c behavior, we expect the traces to capture morning/evening and weekday/weekend trends.
Our methodology also captured behavioral aspects related to the academic calendar.
The traces contain 1.12 billion IP packets totalling 639.4 Gigabytes (GB) of data.
In this paper, attention is restricted to only TCP/IP packets because these account for 84.4% of the total packets and 92% of the total bytes in the traces.
Furthermore, Web and P2P applications such as Gnutella and BitTorrent use TCP in most cases.
In total, we consider
 GB of data.
Table 3 shows the breakdown by application type.
Web and P2P dominate in terms of bytes.
Although P2P accounts for only 2.8% of the total  ows, it accounts for 33.1% of the total bytes.
The Unknown category includes HTTPS (port 443),  ows without payloads, and  ows unclassi ed by Bro.
The Others category bundles together the remaining tra c; the main contributors (by bytes) are email (5%),  le transfer (3%), and streaming (2%) applications.
Application Web
 Unknown Others Total Flows % Flows Bytes (GB) % Bytes



















 Table 4: Flow and byte count for P2P P2P Systems Gnutella BitTorrent eDonkey Other-P2P Total Flows % Flows Bytes (GB) % Bytes



















 Table 4 categorizes the P2P  ows present in our traces by P2P application type.
There are approximately 646,000 P2P  ows; these account for nearly 195 GB of tra c data.
From the table, we notice that BitTorrent has a lower byte-to- ow ratio than Gnutella.
Table 4 also reveals that although eDonkey accounts for many P2P  ows, the cumulative traf- c volume in bytes was relatively small.
The Other-P2P category consists of P2P applications that each contributed less than 1% of the identi ed P2P  ows.
We consider three  ow-level characterization metrics: Flow Size   the total bytes transferred during a TCP  ow.
Flows can be categorized as mice [25], bu alo [22] and elephants [13].
We label  ows as mice if they transfer less than
 than 5 Megabytes (MB) of data.
The rest are labeled as bu alo.
Flow Duration   the time between the start and the end of a TCP  ow.
Flow Inter-arrival time   the time interval between two consecutive  ow arrivals.
We consider three host-level characterization metrics: Flow Concurrency   the maximum number of TCP  ows a single host uses concurrently to transfer content.
Transfer Volume   the total bytes transferred to and from a host during its activity period.
Upstream transfer volume is measured as the total bytes transmitted from an internal host to the external hosts.
Downstream transfer volume is the total bytes received by an internal host from the hosts external to the network.
Geographic Distribution   the distribution of the shortest distance between individual hosts and our campus along the surface of the Earth.
This distance measure is known as the great-circle3 distance.
We use statistical measurements such as mean, median, standard deviation, inter-quartile range (IQR), and skew-ness to summarize trends of the sample data.
Where necessary, we also use the probability density function (PDF), cumulative distribution function (CDF), and complementary CDF (CCDF) of the sample data to obtain further insights.
] x = <

 [





 -1

 P2P-empirical P2P-model Web-empirical Web-model


 log10 (Flow Size in KB) (a) Web and P2P ] x = <

 [







 BT-empirical BT-model Gnu-empirical Gnu-model -1






 log10 (Flow Size in KB) (b) Gnutella and BitTorrent Figure 1: CDF of  ow sizes References to the  tail  of the CCDF refer to those values in the upper 10% of the empirical distribution; the remaining
 tails are often studied to determine how quickly or slowly they decay.
A distribution where the tail decays more slowly than an exponential distribution is called long-tailed.
A distribution is heavy-tailed if the tail asymptotically follows a hyperbolic shape (i.e., shape parameter 0 <     2).
    )    We present statistical models that capture the salient fea-` tures seen in our data sets.
We use the following distribu-x ) ), Weibull (CDF: 1   tional models: Pareto (CDF: 1   (    ( x ln x  ) where   and   e ), and Lognormal (CDF:   are shape and scale parameters,   and   are mean and standard deviation of the distribution, and   is the Laplace Integral; we also present models that are hybrid of the aforementioned distributions, where the model thresholds were determined manually such that the hybrid distribution passed a goodness-of- t test.
We tested the statistical models for accuracy using the Kolmogorov-Smirnov (KS) goodness-of- t test.
If the statistical model passed the KS test at the 5% signi cance level, we considered it to model our empirical data well.4 Only these models are presented in the paper.
In order to conduct realistic network simulations, models of  ow size, inter-arrival time, and duration are needed.
In this section, we present our  ow-level characterization results and derive distributional models from the characterization results.
Summary statistics for Web and P2P tra c are presented in Table 5.
The corresponding statistics for Gnutella and BitTorrent are shown in Table 6.
Table 5 shows that P2P  ows have a higher mean  ow size and lower median  ow size than Web  ows.
These observations suggest that P2P applications generate many small and many very large-sized  ows compared to Web.
The CDF of Web and P2P  ow sizes in Figure 1(a) corroborates the aforementioned observation.
The preponderance of small-sized P2P  ows is somewhat unexpected as P2P applications are typically used to share large audio and video  les.
There are at least three sources of small-sized  ows: extensive signalling, aborted transfers, and connection attempts with non-responsive peers.
We also  nd some very large-sized P2P  ows.
These few P2P  ows are much larger than the occasional large Web transfer.
Our analysis indicates that P2P applications contribute
 We validated the models using a distribution  tting tool called Easy-
http://en.wikipedia.org/wiki/Great-circle_distance Fit: http://www.mathwave.com/products/easyfit.html.
Characteristic Flow size (KB) Flow Inter-Arrival (sec) Flow duration (sec) Mean Median





 Web Std.
Dev.
IQR Skewness Mean Median












 Std.
Dev.
IQR Skewness





 Characteristic Table 6: Flow-level summary statistics of Gnutella and BitTorrent BitTorrent Std.
Dev.
IQR Skewness Mean Median





 Mean Median


 Gnutella Std.
Dev.
Flow size (KB) Flow Inter-Arrival (sec) Flow duration (sec)








 IQR Skewness





 ) ] x >

 [ (

 g o l
 1 2 3 4 5 6 7 P2P-empirical P2P-model Web-empirical Web-model

 -1




 log10 (Flow Size in KB) (a) Web and P2P ) ] x >

 [ (

 g o l
 1 2 3 4 5 6 BT-empirical BT-model Gnu-empirical Gnu-model -1






 log10 (Flow Size in KB) (b) Gnutella and BitTorrent Figure 2: CCDF of  ow sizes many mice and elephant  ows, and possibly alters the mix of these  ow types in today s IP networks.
We elaborate on this phenomenon in Section 3.1.3.
We examined the tails of the  ow size distributions using CCDF plots.
Figure 2(a) presents the CCDF of  ow sizes for Web and P2P.
In the body of the distribution, P2P  ows are smaller than Web  ows, but in the tail (speci cally, the upper 3.5% of  ows after the  crossover  point) P2P  ows are larger than Web  ows.
Also, the tail of the Web  ow size distribution decays more quickly than the corresponding P2P distribution.
These observations provide further evidence of P2P s large elephant-sized  ows.
Table 6 indicates that Gnutella  ow sizes are larger and more dispersed than BitTorrent  ow sizes.
The empirical CDF for the two P2P variants in Figure 1(b) shows that both applications generate a similar percentage of small-sized  ows (e.g., 5 KB or less).
Many of these smaller  ows are the result of control information exchanged between peers, which is a byproduct of the distributed nature of P2P protocols.
The ratio of large-sized to total  ows for BitTorrent is, however, less than that for Gnutella.
For example, approximately 5% of BitTorrent  ows are larger than
 characteristics of these large-sized  ows are analyzed next.
Figure 2(b) shows the CCDF of  ow sizes of Gnutella and BitTorrent applications.
Gnutella appears to generate more large-sized  ows than BitTorrent.
BitTorrent uses  le segmentation to split an object into multiple equal-sized  pieces  (256 KB each by default), and downloads these pieces from either the same or di erent peers using parallel  ows.
In contrast, Gnutella typically downloads the entire object from a single peer.
As a result, we observe fewer large  ows in BitTorrent than Gnutella.
Table 7: Mice and elephant  ow breakdown Application Mice Elephants % Flows % Bytes % Flows % Bytes Web
 Gnutella BitTorrent















 We observe that both categories of application generate many mice  ows.
Although the mice  ows originating from Web applications are less prevalent than those from P2P applications, Web mice  ows account for a relatively higher proportion of the total Web bytes than P2P mice  ows account for the total P2P bytes.
For example, approximately 9% of total Web bytes are from Web mice  ows, whereas only
 Both applications generate a small proportion of elephant  ows.
Nevertheless, these few elephant  ows contribute a signi cant fraction of the total bytes; the elephant-sized Web  ows contributed about 15% of the total Web-generated bytes, while the elephant-sized P2P  ows contributed as much as 93% of the total P2P bytes.
Network operators may be interested in bandwidth-limiting these long-duration  elephant   ows, or may be interested in assigning these  ows lower priority.
As P2P applications become more popular, we can expect networks to carry increasingly more elephant  ows.
Our results also indicate that P2P elephant  ows are signi cantly larger than Web elephant  ows.
We next analyze mice and elephant  ows generated by Gnutella and BitTorrent.
While both P2P applications have a similar proportion of mice  ows, the BitTorrent mice  ows account for a much higher percentage of byte transfers than Gnutella mice  ows; that is, Gnutella mice  ows are smaller, on average, than BitTorrent mice  ows.
As mentioned earlier, signalling between peers is a major contributor to the pool of P2P mice  ows.
Our data suggests that BitTorrent applications have more intense signaling activities compared to Gnutella, resulting in relatively larger mice  ows.
In our data, Gnutella has a much higher percentage of elephant  ows than BitTorrent, even though both Gnutella and BitTorrent elephant  ows account for a comparable proportion of byte transfers.
Thus, on average, BitTorrent elephant  ows are larger than Gnutella elephant  ows.
We believe that the type of  les exchanged using these P2P systems can provide an explanation for our observation.
A 2005 study by CacheLogic5 showed that a majority of Gnutella users shared mostly audio  les (70%), whereas BitTorrent users shared more video  les (47%).
Video  les are, on av-Table 7 shows the percentage of mice and elephant  ows among the total  ows contributed by di erent applications.
CacheLogic.
Peer-to-Peer File Type Study, http://www.cachelogic.
com/home/pages/research/filetypestudy.php
 x = <

 [





 P2P-empirical P2P-model Web-empirical Web-model


 2 1 -3
 log10 (Flow Inter-arrival in seconds)
 (a) CDF
 1 2 3 4 5 ) ] x >

 [ (

 g o l 3 P2P-empirical P2P-model Web-empirical Web-model
 1 -2


 log10 (Flow Inter-arrival in seconds) (b) CCDF ] x = <

 [





 1 P2P-empirical P2P-model Web-empirical Web-model




 log10 (Flow Duration in seconds) ] x = <

 [





 1 BT-empirical BT-model GN-empirical GN-model




 log10 (Flow Duration in seconds) (a) Web and P2P (b) Gnutella and BitTorrent Figure 3: Web and P2P  ow inter-arrival Figure 4: CDF of  ow duration erage, signi cantly larger than audio  les.
We believe that the extremely large BitTorrent  ows are due to the transfer of multiple pieces of large video  les over a single TCP  ow.
In this section, we present statistical models that describe the body and the tail of  ow size (S) distribution.
These models may be used to generate transfer sizes of TCP  ows in network simulations.
Figures 1 and 2 plot the statistical models in addition to the empirical distributions.
Web  ow sizes are well-modeled by a concatenation of bounded Weibull and Pareto distributions:






 >:1   e ( S





 >:1   e ( S




 FW eb(S) =
 We  nd that the tail of the Web  ow size distribution is a mix of heavy-tailed and long-tailed distributions.
Similarly, we  nd that P2P  ow sizes are well-modeled by a hybrid bounded Weibull and Pareto distributions: From the above-mentioned model, we can conclude that P2P  ow sizes are heavy-tailed.
Both the BitTorrent and Gnutella  ow sizes are well-modeled by combining bounded Lognormal and Pareto distributions:
   ln S 0.03 `






 >>>:
 `


 ln S 0.44



   )0.25
 FGnu(S) =






 We  nd that both BitTorrent and Gnutella  ow size distributions are heavy-tailed; BitTorrent  ow sizes, however, are less heavy-tailed than Gnutella  ows.
Analysis of our data (see Table 5) shows that P2P  ow inter-arrival times (IAT) are much longer and more dispersed than Web  ow IAT.
Figure 3 shows the CDF and CCDF of  ow IAT for Web and P2P.
Web  ow IAT are much shorter than those of P2P  ows.
For example, approximately 97% of Web  ow IAT are less than 0.1 second, whereas only 25% of P2P  ow IAT are this short.
Another way to understand the di erence between the IAT of Web and P2P  ows is to study their corresponding  ow arrival rates.
Web tra c has a higher arrival rate of approximately 80  ows/seconds, compared to P2P tra c, which has arrival rate of only 6  ows/seconds.
Another factor contributing to the lower arrival rate and the longer IAT values for P2P  ows is the persistent nature of their TCP connections.
How these persistent connections are used is discussed in Section 4.1.
We examine the tails of  ow IAT for Web and P2P in Figure 3(b).
Flow IAT from both applications show similar decay throughout the tails.
At the upper tail, we observe sharp decay due to the limited duration of our traces.
Flow IAT from individual P2P applications are found to follow similar patterns, and thus are not shown here.
We  nd that Web  ow IAT can be modeled by a two-mode bounded Weibull distribution:
 1   e FW eb(IAT ) =  (


 : IAT   0.06 sec : IAT > 0.06 sec ( In contrast, P2P  ow IAT are well-modeled by a hybrid Weibull-Pareto distribution:
 >:1   e ( IAT




 : IAT   0.1 sec : 0.1 < IAT   1 sec : IAT > 1 sec
 These distribution models indicate that Web IAT are long-tailed, whereas P2P IAT are heavy-tailed.
Our models provide evidence of the inapplicability of memoryless Poisson models for Web and P2P  ow arrivals [16].
Our statistical analysis (cf.
Table 5) indicates the presence of many short-duration  ows.
Figure 4 shows the CDF of  ow durations.
From Figure 4(a) we observe that approximately 30% of P2P  ows are shorter than 10 seconds in duration.
Some of these short-duration transfers are either failed or aborted  ows, while other short-duration  ows are a byproduct of the P2P applications  signaling behavior.
Note that short-duration  ows typically transfer a small amount of data, but the converse does not always hold.
There are a few long-duration mice  ows; these  ows arose due to repeated unsuccessful connection attempts by peers.
We also
 ] x >

 [ (

 g o l
 1 2 3 4 5 P2P-empirical P2P-model Web-empirical Web-model

 -1


 ) ] x >

 [ (

 g o l
 1 2 3 4 BT-empirical BT-model GN-empirical GN-model

 -1




 ] x = <

 [





 ] x = <

 [







 Web

 BitTorrent Gnutella


 log10 (Flow Duration in seconds) (a) Web and P2P log10 (Flow Duration in seconds) (b) Gnutella and BitTorrent log10 (Maximum # of Concurrent Flows) (a) Web and P2P log10 (Maximum # of Concurrent Flows) (b) Gnutella and BitTorrent Figure 5: CCDF of  ow duration Figure 6: CDF of host  ow concurrency observe that a large proportion, approximately 40%, of P2P  ow durations are between 20 and 200 seconds.
We found that some P2P connections are bandwidth-limited, and thus of long-duration.
Bandwidth limitations re ect the available bandwidth between peers (e.g., peers with asymmetric Internet access have limited uplink capacity) as well as  ow management on our network (cf.
Section 6).
Approximately
 have excellent Internet connectivity in our campus network, and most Web servers are also well-provisioned.
Thus, we expect low response times for Web requests.
The remaining Web  ows that are longer than 1 second are typically responsible for either downloading large objects (e.g., streaming video from youtube.com) or transferring multiple objects from Web pages using persistent HTTP/1.1 connections.
In Figure 5 we analyze the tail of the  ow duration distributions.
Figure 5(a) shows the CCDF of Web and P2P  ow durations.
We  nd that the probability of long-duration  ows is higher for P2P than Web.
Summary statistics in Table 6 show that, on average, BitTorrent  ows last longer than Gnutella  ows; furthermore, the  ow durations are dispersed over a wide range of values.
Figure 4(b) shows the CDF of Gnutella and BitTorrent  ow durations.
This graph rea rms the aforementioned point.
We  nd that these relatively longer  ows of BitTorrent resulted due to its protocol architecture.
BitTorrent utilizes a rarest  rst piece selection policy to exchange data.
At any given time, a  xed number of concurrent uploads/downloads are permitted.
BitTorrent architecture allows persistent connections between peers and controls downloads/uploads using its piece selection policy which results in connections periodically being idle.
Furthermore, concurrent download from a single BitTorrent peer splits the bandwidth available at uploaders for downloading.
In contrast, Gnutella can use a single  ow for downloading an object and thus does not need to share bandwidth.
Occasionally, Gnutella peers may share bandwidth, for example, when the same object is requested by other peers or when di erent objects are requested by the same peer.
Figure 5(b) shows the CCDF of Gnutella and BitTorrent  ow duration.
Two observations can be drawn.
First, before the crossover point, BitTorrent shows a higher percentage of long-duration  ows than Gnutella; however, following the crossover point (upper 2% of  ows), the probability of long-duration  ows in Gnutella is higher than that in BitTorrent.
Second, at the distribution tail, BitTorrent  ow durations decay more quickly than Gnutella  ow durations.
We found earlier that extremely large transfers are not very common in BitTorrent, due to its  le segmentation feature.
We also found a positive correlation (correlation coe cient is 0.69) between BitTorrent  ow size and duration, and therefore, observe a lower proportion of extremely long-duration  ows in BitTorrent.
Other factors such as  le size, swarm population, and availability of pieces in the swarm can also in u-ence the duration of BitTorrent  ows.
These factors result in the BitTorrent tail being long-tailed instead of heavy-tailed.
This section outlines the statistical models of  ow dura-tions (D) (see Figures 4 and 5).
Web  ow duration is well-modeled using two bounded Pareto distributions: : D   60 sec : D > 60 sec

 FW eb(D) =

 ( The preceding model shows that Web  ow durations are heavy-tailed.
A similar analysis shows that P2P  ow dura-tions can be well-modeled by a concatenation of bounded Weibull and heavy-tailed Pareto distribution: : D < 20 sec : 20   D   300 sec : D > 300 sec
 >:1   e ( D





 BitTorrent  ow durations are well-modeled by a hybrid bounded Weibull and Pareto distributions, whereas Gnutella  ow durations are well-modeled by a hybrid bounded Log-normal and Pareto distributions:
 (


 ( `

 ln D 2.1

   : D   300 sec : D > 300 sec : D   10 sec : D > 10 sec
 FGnu(D) = The above-mentioned statistical distributions show that BitTorrent  ow durations are long-tailed (tail  ts a Pareto distribution with   > 2) but not heavy-tailed.
In contrast, Gnutella  ow durations are heavy-tailed.
This section presents a host-level characterization of Web and P2P tra c.
This characterization provides information to network administrators for tasks such as bandwidth management and capacity planning, and also provide insights into the functioning of modern P2P systems.
The results presented here may also be used to develop synthetic workloads and design realistic network simulations.
s

 f o # t c n i t s
 i (

 g o l





 log10 (Maximum # of Concurrent Flows)

 ) s

 f o # t c n i t s
 i (

 g o l





 log10 (Maximum # of Concurrent Flows)

 (a) Web (b) P2P Figure 7: Flow concurrency vs distinct IPs
 Figure 6 shows the CDF of host  ow concurrency for Web, P2P, Gnutella, and BitTorrent.
From Figure 6(a), we observe (surprisingly) that many P2P hosts in our network maintain only a single TCP connection.
We explain the observation later in this section by analyzing  ow concurrency for individual P2P applications.
While analyzing the  ow concurrency for Web hosts, we ignore the Web servers internal to our network.
From the analysis, we  nd that a sig-ni cant proportion of the internal Web hosts maintain more than one concurrent TCP connection.
Web browsers often initiate multiple concurrent connections to transfer content in parallel.
This parallel download feature increases the degree of  ow concurrency in HTTP-based applications.
However, a high-degree of  ow concurrency (e.g., above 30) is not typically observed for general Web clients; rather, Web proxies and content distribution nodes account for this high degree of  ow concurrency.
The CDF of host  ow concurrency for Gnutella and BitTorrent is shown in Figure 6(b).
We observe that most Gnutella hosts connect with only one host at a time.
As discussed earlier, Gnutella applications typically download a whole object from another Gnutella host using a single TCP  ow.
We observed a few Gnutella hosts that maintained more than 10 concurrent TCP connections.
These hosts likely acted as  super peers  in Gnutella s peer hierarchy.
In contrast, most BitTorrent hosts exhibit a high degree of  ow concurrency.
Approximately 24% of the BitTorrent hosts use more than 100 concurrent  ows.
This high degree of concurrency is a natural occurrence in BitTorrent.
BitTorrent clients obtain a peer list from a tracker, and then attempt to connect with these peers.
Once connections are established, BitTorrent uses its rarest  rst piece selection policy and tit-for-tat fairness mechanisms to determine how pieces are shared [3].
Typically, only a small number of these concurrent connections actively transfer  le pieces.
We also study the correlation between the maximum number of concurrent  ows seen at a host and the number of distinct hosts connected at that time.
Figure 7 shows scatter plots of  ow concurrency versus distinct hosts for Web and P2P hosts.
(The plots for Gnutella and BitTorrent are similar to that of P2P, and thus not shown here.)
From Figure 7(a) we observe that most of the points are well-below the diagonal.
In other words, the number of concurrent Web  ows far exceed the number of Web hosts concurrently contacted.
From Figure 7(b), we observe that P2P hosts use concurrent  ows to connect to many distinct hosts as illustrated by the concentration of points along the diagonal.
This behavior is not unexpected, since P2P protocols such as BitTorrent and eDonkey encourage connectivity with multiple hosts to facilitate widespread sharing of data.
] x = <

 [





 Web


 log10 (Volume Transfer in KB) Figure 8: CDF of transfer volume Table 8: Fair-share ratio in P2P systems Downstream (MB) Minimum Fair-share Ratio < 1




 > 100 none






 This section studies the transfer activity of hosts in terms of their transfer volume.
Figure 8 show the CDF of the transfer volume for Web and P2P hosts.
We observe that approximately half of the distinct P2P and Web hosts transfer small amounts of data (e.g., less than 1 MB); these hosts are typically active for less than 100 seconds.
We  nd that these P2P hosts repeatedly yet unsuccessfully attempt to connect with serving peers.
Connection requests are unsuccessful for a variety of reasons including insu cient resources or no useful content at the contacted peers.
In contrast, Web transfers in this region result from Web browsing, widgets that retrieve information from the Web periodically (e.g., weather updates, stock prices), and downloading small  les.
We  nd that approximately 35% of Web hosts and 15% of P2P hosts transfer data ranging from 1 to 10 MB, and are active mostly for 100 to 1000 seconds.
These P2P host transfers are due to sharing small objects, whereas these Web host transfers are due to prolonged Web browsing, downloading software/multimedia  les, and HTTP-based streaming.
The proportion of hosts that transfer large amounts of data (e.g.,
 ni cantly higher in P2P than in Web.
Transfer symmetry is a major concern for P2P system developers, who want to encourage fair sharing among participating peers.
Many content sharing portals require that users maintain a minimum ratio of upstream to downstream transfer volume, which we refer to as the minimum fair-share ratio.
Table 8 shows the minimum ratios of fair-sharing we de ned for di erent levels of downstream tra c.
Note that hosts transferring less than 1 MB of data in total are not sharing any content and thus are excluded from our transfer symmetry calculation.
In most cases, we used equal-sized bins to assign minimum fair-share ratios; however, for above
 of P2P hosts fall in this category.
We divide P2P hosts into three categories (freeloaders, fair-share, and benefactors) according to their transfer ratios (i.e., upstream/downstream ratios) and corresponding minimum fair-share ratios from Table 8.
We de ne freeloaders
 Systems Gnutella BitTorrent Freeloader Fair-share Benefactor










 ] x = <

 [
 -1
 ] x = <

 [





 -1
 Web

 log10 (Ranked Hosts %) (a) Web and P2P BitTorrent Gnutella


 log10 (Ranked Hosts %) (b) Gnutella and BitTorrent Figure 9: CDF of ranked hosts as those hosts who have a transfer ratio less than the minimum fair-share ratio.
Benefactors are hosts that have a transfer ratio of 2 or greater.
The remaining hosts are in the  fair-share  range.
Table 9 shows the percentage of Gnutella and BitTorrent hosts as freeloaders, fair-share hosts, and benefactors.
We  nd that approximately 10% of BitTorrent hosts are acting as freeloaders, whereas 57% of Gnutella hosts are freeloaders.
Benefactors are common in both BitTorrent ( 50%) and Gnutella ( 33%) hosts.
Therefore, Gnutella host behavior appears to be dominated by extreme downstream and upstream transfers.
We  nd that approximately 40% of BitTorrent peers and 10% of Gnutella peers reside in the fair share zone.
BitTorrent introduced a  tit-for-tat  mechanism to encourage fair sharing among the peers [3].
Every peer in the BitTorrent system is encouraged to upload for obtaining the opportunity to download.
Therefore, we observe more freeloaders in Gnutella and better fairness in BitTorrent.
Figure 9 plots the CDF of hosts ranked by transfer volume (the higher the amount of data transferred, the higher the rank).
We  nd that a few hosts account for much of the volume transferred; we call these hosts heavy-hitters.
Figure 9(a) shows that the top 0.1% of Web hosts account for 14% (28 GB) of the total Web transfer.
Similarly, the top 0.1% of P2P hosts transfer 12% (24 GB) of the total P2P data.
Moreover, top 1% of Web and P2P hosts account for 70 GB (34%) and 82 GB (42%) of the total Web and P2P bytes, respectively.
Clearly, heavy-hitters are present in both Web and P2P.
Examination of the upstream to downstream transfer ratio for the P2P heavy-hitters shows that most P2P heavy-hitters are either freeloaders or benefactors.
Figure 10 shows the transfer volume of ranked Web and P2P hosts.
We observe that the total amount of data transferred by the top 10% Web and P2P hosts follows a power-law distribution (with     0.27); we emphasize that the power-law does not apply to the body and the tail of the ranked distribution.
The only di erence seen between the applications is the total transfer volume; top-ranked P2P hosts transfer an order of magnitude more data than top-ranked Web hosts.
Figure 9(b) shows the CDF of ranked transfer volume for Gnutella and BitTorrent hosts.
We  nd that the top 1% of BitTorrent hosts transfer 20 GB (60% of total BitTorrent tra c), whereas the top 1% of Gnutella hosts account for 53 GB (35% of total Gnutella tra c).
Our data suggests that r e f s n a r
 e m u o
 l (

 g o l )

 n i





 1 2 3 4  =0.27
 Web 2 -1


 log10 (Ranked Hosts %) Figure 10: Transfer volume of ranked host North America Other Continents Atlantic




 s t s o
 f o e g a t n e c r e



 Web

 Distance (km) s t s o
 f o e g a t n e c r e







 BitTorrent Gnutella

 Distance (km) (a) Web and P2P (b) Gnutella and BitTorrent Figure 11: Geographic distribution of hosts BitTorrent heavy-hitters account for a much larger fraction of that application s total bytes than Gnutella heavy-hitters do for their total bytes.
We also found that the transfer volume of top-ranked Gnutella and BitTorrent hosts did not follow a power-law distribution.
This section discusses the geographic distribution of hosts external to the campus network.
We calculated the great-circle distance between individual hosts and our campus using a geolocation database6.
This database provides the geographic coordinates, country name, and city name for an IP address range.
Figure 11 shows the geographical distribution of the external hosts.
Note the plateau between 3, 500 and 7, 000 kilometers represents the Atlantic ocean.
Figure 11(a) shows the geographical distribution of the external Web and P2P hosts.
Most of the external Web hosts, approximately 75%, are in North America; Asia and Europe each account for
 surprising.
We know that most of the external Web hosts are Web servers.
O Neill et al. [14] had shown that in 1999 and 2002, 49% and 55% of the public Web sites, respectively, were associated with entities located in the United States.
In addition, we believe that cultural pecularities may also a ect the results.
A majority of our campus Web users are English-speaking, and thus they are more likely to visit Web sites located in predominantly English-speaking countries.
In contrast to the geographic distribution of external Web hosts, we found that approximately 40% of P2P hosts are located in North America, 30% in Europe, 18% in Asia, 6% in Australia, and 5% in South America.
This indicates that connectivity between P2P hosts does not appear to strongly rely on host locality, rather it depends on resource availability during the connection establishment phase.
The non-interactive nature of P2P applications makes latency only a secondary concern; the primary goal is to  nd the requested  le.
In addition, our results suggest that  les being shared using these systems transcend geographic divides.
MaxMind: GeoIP City Database, http://www.maxmind.com/app/city
 It shows that majority of ex-are shown in Figure 11(b).
ternal Gnutella hosts ( 70%) are from North America.
Approximately 18% of the Gnutella hosts are located in Europe and the rest are in Asia (6%), Australia (2.3%), and South America (2.3%).
This suggests that either Gnutella peers prefer to connect with hosts that are in close proximity or that Gnutella clients are widely used in North America for  le-sharing.
In contrast, only 30% of external BitTorrent hosts are located in North America.
Among the rest, approximately 40% of BitTorrent hosts are located in Europe,
 We know BitTorrent hosts connect to peers from a peer-list provided by trackers.
We believe that the list from trackers is created based on host bandwidth availability in a swarm and thus, we see a bias towards regions with high broadband penetration.
We did observe, however, that although BitTorrent peers connect to other distant peers for obtaining content, most of the successful transfers originate from the peers located in the same geographic region.
Web tra c has been extensively characterized.
Many studies concentrate on the user-level behavior such as the size and number of request/response messages, and Web application-speci c properties such as page complexity and [1, 2]).
Flow-level properties of document referencing(e.g., Web tra c have also been studied (e.g., [4, 16]).
One key observation from prior work is that Poisson arrival process may not be appropriate for Web  ows [4,16].
Our data reaf- rms this observation, and also shows that Poisson models may not be appropriate for modeling P2P  ow arrivals.
There are many studies of popular P2P systems in the literature, including Napster [19], KaZaA [8], Gnutella [19,
 studies have focussed on di erent aspects of P2P systems such as query tra c [12], data tra c [8,21],  ow characteristics [17,24], peer behavior [21], system architecture [9,10,18], and system dynamics (e.g., churn) [23, 26].
In this section, we discuss closely related prior work.
Saroiu et al. [19] studied Gnutella and Napster systems using traces collected using crawling techniques.
They observed Gnutella hosts had high-bandwidth, high-latency, and low user-activity periods when compared to Napster hosts.
Sen and Wang [21] studied DirectConnect, Gnutella, and FastTrack traces from a large ISP s network.
They found that the tra c volume, peer connectivity, and mean bandwidth usage distributions are extremely skewed, which is similar to our observations.
Recently, Zhao et al. [26] analyzed tra c from modern Gnutella systems.
They observed a signi cant decrease in free-riders over the past few years.
Our results, however, indicate pronounced free-riding in Gnutella.
We believe free-riding needs to be further studied.
Guo et al. [9] analyzed and modeled BitTorrent systems based on traces collected from a popular tracker site.
They found that swarm popularity decreases exponentially over time, and that the distribution of swarm population is heavily skewed.
Pouwelse et al. [18] studied performance, robustness, and content integrity of BitTorrent systems.
Tutschku [24] and Plissonneau et al. [17] analyzed eDon-key tra c observed on the protocol s standard port.
Tutschku found that eDonkey  ow sizes follow the lognormal distribu-)

 n i i e z
 w o
 ( l

 g o l













 log10 (Flow Duration in seconds) Figure 12: Flow size versus  ow duration tion, that  ow IAT are exponentially distributed, and that eDonkey  ows do not appear to alter the mice-elephant mix of  ows.
Similar to our observations, Plissonneau et al.
found that eDonkey systems generates many short duration  ows, have signi cant unfairness, and do not exploit geographic locality when exchanging data.
Plissonneau et al.
did not present any tra c models in their work.
Our study complements prior work on Web and P2P traf- c analysis.
We used recent traces that re ect the emerging tra c trends in a large edge network, and employed application signature matching to identify Web and P2P traf- c accurately.
We explored the similarities and di erences in  ow-level and host-level characteristics of Web and P2P  ows, and developed models for both types of tra c.
In this section, we discuss two related issues: identi cation of P2P tra c and impact of network tra c management.
Many recent P2P characterization studies (e.g., [17, 21,
 full payload packet traces allow us to apply application signature matching to identify P2P tra c that would otherwise not be identi ed had we only relied on port numbers for tra c identi cation.
We believe that future characterization of P2P tra c should not rely solely on port numbers for identi cation of this tra c.
Because collection of traces with payloads poses unique challenges (e.g., processing cost, longer-term data collection) and are often di cult to obtain, alternative approaches are necessary.
For example, recently proposed machine-learning techniques that use only  ow statistics (see [6, 7] and the references therein) or heuristics-based techniques [5, 11] that leverage characteristic behavior of P2P applications may be suitable candidates for identifying P2P tra c.
A consequence of increased use of P2P applications is the deployment of bandwidth management solutions in edge networks.
Any analysis of network tra c, therefore, needs to be aware of the potential implications of tra c management as some characteristics of interest such as  ow duration and  ow concurrency may be a ected by  ow management.
At the University of Calgary, tra c is managed using a commercial packet shaping device.
The packet shaper (to the best of our knowledge) employs a combination of application signatures and port numbers to identify tra c.
At the time of trace capture, the network policy in place was to group together all identi ed P2P  ows (except those from the student residences) and collectively limit their bandwidth to 56 Kbps.
Figure 12 shows a scatter plot of P2P  ow size and duration for our trace.
The scatter plot includes a straight line that marks the 56 Kbps boundary; P2P  ows (i.e., points) above this line represent an achieved
 that points below this line do not necessarily imply that the  ow s bandwidth was limited by the tra c shaping device.
Flow rates may be below this line for other reasons such as multiplexing of  ows,  ow control, or congestion control mechanisms.
The key observation from the plot is that we do not observe a strong positive correlation between  ow size and duration.
This suggests that some P2P  ows are indeed identi ed and limited by the packet shaping device.
Nevertheless, we do see many points above the 56 Kbps threshold; these P2P  ows clearly escaped detection by the tra c shaper.
The  nal comment we make is regarding the representa-tiveness of our observations and models.
Our study is based on observations from one vantage point, and on a network that employs some form of bandwidth management.
Clearly, there is a need to study tra c from di erent networks to validate the models we propose and also to develop general models for Web and P2P tra c.
Nevertheless, we believe that our results are still useful as they provide a snapshot of Web and P2P tra c characteristics from a large edge network, and thus should be representative of other large edge networks with similar population and network management policies.
In cases where the network di ers signi cantly in design or management policy, our methodology can be applied to develop representative models.
This paper presented an extensive characterization of Web and P2P tra c using full packet traces collected at a large edge network.
We considered three  ow-level metrics, namely  ow size,  ow IAT, and  ow duration, and three host-level metrics, speci cally  ow concurrency, transfer volume, and geographic distance.
We observed a number of contrasting features between Web and P2P tra c.
Typically, Web  ows are short-lived whereas P2P  ows are long-lived.
Both Web and P2P host transfers are asymmetric; however, P2P host transfers are dominated by both upstream and downstream tra c, but not both.
Web hosts maintain a high degree of  ow concurrency, whereas many P2P hosts maintain a single  ow at a time.
Finally, P2P tra c exacerbates the  mice and elephants  phenomenon in Internet tra c.
Flow-level distributional models were developed for Web and P2P tra c; these models can be used in network simulation and emulation experiments.
We believe much work remains.
Tra c from other networks should be studied to facilitate development of general models for Web and P2P tra c.
Similarly, tra c from other non-Web applications, for example P2P streaming applications such as PPLive, P2P VoIP, and other P2P applications, should be examined, and their impact on Web-based applications studied.
The authors thank Je rey Erman, the anonymous WWW reviewers, iCORE, and NSERC.
