Over the last decade, the Web has evolved from its initial days of infancy into an unstructured database that we know of today.
The initial search engines applied the text information retrieval model wherein a Web document was retrieved based on the relevance matching between the user provided query and the words appearing in the document.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
However, with the recent development in the  eld of digital media technology which has resulted in the generation of a huge number of images rapidly, e cient Web image search and browsing have become an important application.
Consequently, Web image clustering has drawn signi cant attention in the research community recently.
For example, properly grouped Web images can provide a very neat bird s eye view of the retrieved images to the user.
Much of the earlier e orts on image clustering were solely based on low-level visual features of images [14, 25].
To cluster images, visual features such as color histogram or wavelet-based [13] texture extracted from images were subjected to traditional data clustering algorithms [17].
The major drawback in this approach is that the state-of-the-art visual features are unable to represent the image content on a semantic level.
As a result, image clustering su ers from the semantic gap between visual features and high-level semantic concepts.
A low-tech and a naive solution adopted by search engines to overcome this problem to a certain extent has been to treat image clustering as a text clustering problem.
Web images are represented using textual features in terms of the surrounding texts and captions.
Images clustered based on these textual features are then retrieved accordingly.
But, since images are not actually text documents, this approach is hardly a solution to the problem at hand.
A better approach is to incorporate both visual and textual features together for e cient Web image clustering.
In [3], a single index vector of an image is formed by combining textual and visual statistics.
Textual statistics are captured in a vector form using latent semantic indexing (LSI) [5] based on text in the containing HTML document, while visual statistics are also stored in a vector form using color and orientation histograms.
A similar approach was adopted in [29] where the textual and visual features were  rst combined into a global vector following which the LSI technique was applied.
In both these works, the two di erent kinds of image representations were simply combined together in a rather rigid way without any theoretical basis.
Cai et al. [2] has used three image representations - viz., visual, textual, and link information, to construct a relationship graph of Web images.
In this work, images were  rst clustered into di erent semantic groups by employing the textual and link features.
This step was then followed by visual feature-based clustering of images in each semantic group.
A problem in this two-step process is that an erroneous  rst step results
 tering.
The use of visual, textual, and link features was also employed in [21].
Here, an iterative algorithm was applied to combine the co-clustering between images and surrounding text and the one-sided clustering of images based on visual features.
The convergence property of this algorithm was not proven and the kind of combination is unsymmetrical according to the status of visual and textual features.
From the above discussion, it is clear that the earlier e orts were along the direction of combining the information from visual and textual features instead of integrating them together synchronously under a sound theoretical framework.
In this paper, we propose the Consistent Isoperimetric High-Order Co-clustering (CIHC) framework for simultaneous integration of visual and textual features for e cient Web image clustering under a graph theoretical approach.
Speci cally, visual features, images and textual features are modelled as the three types of vertices of a tripartite graph.
This tripartite graph is treated as two bipartite graphs of visual features & images and that of images & textual features from the surrounding texts of the image.
Co-clustering is then achieved by simultaneously partitioning these two bipartite graphs together such that the information from both the kinds of features is optimally utilized.
Note that the simultaneous partitioning of the two bipartite graphs is performed in such a way that the local clustering of each graph need not be optimal under the constraint that the fusion of the two results yields optimum image clustering.
Actually, a similar concept was presented by Gao et al.
[11] where the Consistent Bipartite Graph Co-partitioning (CBGC) was proposed under the spectral graph partitioning paradigm.
An iterative algorithm using semi-de nite programming (SDP) [1] is used to partition the tripartite graph which is computationally expensive and does not work well on large data sets.
On the other hand, the proposed methodology requires a simple solution to a sparse system of overde-termined linear equations.
Moreover, the CIHC framework has been derived from the isoperimetric graph partitioning approach which has been shown to achieve superior results than the spectral approach in terms of the quality, e ciency and stability of the partition [15, 16, 26].
Experimental results performed on images extracted from real Websites demonstrate the advantage of CIHC over CBGC in clustering Web images.
In this Section, we introduce some essential background on graph theory and review related work in the literature.
An undirected homogeneous graph G ={V, E} consists of a set of vertices V = {v1, v2, ...., v|V |} and a set of edges E={eij| edge between vi and vj , i, j <= |V |}, where |V | is the number of vertices.
In a weighted graph, each edge eij has a positive weight denoted by w(eij ).
The weight of the edge signi es the level of association between the vertices.
An edge weight of zero denotes the absence of an edge between the two respective vertices.
Given a vertex numbering and the edge weights between the vertices, graphs can be represented by matrices.
We begin with de nitions of a few graph terminologies that play an essential role in the paper.
The adjacency matrix J of the graph is de ned as, (cid:2) Jij = (cid:3) w(eij),
 if eij exists otherwise The degree of a vertex vi denoted by di is de ned as, di = w(eij), eij  eij   E (1) (2) The degree matrix D of the graph is a diagonal matrix having degree of vertices along the diagonal while a degree vector d of a graph is a vector consisting of degree of all the vertices.
The Laplacian matrix L of a graph is a symmetric matrix with one row and column for each vertex such that, Lvi,vj =  w(eij),
 if i = j if eij exists otherwise (3)     di, Suppose we bipartition set V into subsets V1 and V2, then the corresponding graph cut is de ned as, Jij cut(V1, V2) = (4) (cid:3) i V1,j V2 (cid:3) n<  The above de nition can be extended to k partitioning of the graph.
The cut in which case is de ned as, cut(Vn, V ) cut(V1, V2, ....., Vk) = (5) A graph partitioning algorithm assigns a set of values to each vertex in the graph.
We will refer to a vector consisting of the values for each of the vertices as the indicator vector of the graph.
The cutting of the graph is dividing the indicator vector based on the values associated with each vertex using a splitting value.
If u denotes the indicator vector of the graph and s is the splitting value, then the vertices are partitioned into the set of i such that ui > s and the set such that ui   s. Spectral graph theory [4] which is based on performing eigen decomposition on matrices of the graphs, has been one of the most popular and widely applied graph partitioning methods.
In [27], Shi and Malik have applied the spectral method to image segmentation.
The objective function used in this work is, min xT Lx xT Dx , subject to x
 De = 0, x (cid:5)= 0 (6) where e is a unit vector and x is a column vector such that xi = c1 if i   V1 and xi =  c2 if i   V2, where c1 and c2 are constants derived from the degree matrix D. By relaxing xi from discrete to continuous, it can be shown that the solution to Equation (6) is the eigenvector corresponding to the second smallest eigenvalue  2 of the generalized eigenvalue problem [4, 12], Lx =  D x (7) clustering Partitions are then obtained by running a clustering algorithm such as k means [17] on the eigenvector x corresponding to  2.
An undirected bipartite graph G ={M, W, E}, has two sets of vertices, viz., M and W and a set of graph edges E.
Let B be an |W| by |M| graph weight matrix.
An entry Bij in this matrix is the weight of an edge appearing between a vertex wi   W and a vertex mj   M. There are no edges between vertices of the same group.
Then, the adjacency matrix of the bipartite graph is expressed as, (cid:8) (cid:7)




 (8)
 m 2 m 3 m 4 m 5 m 6 w 1 w 2 w 3 w 4 w 5 w 6 w 7 Figure 1: The square and circular vertices (m and w, respectively) denote the two data types in the co-clustering problem that are represented by the bipartite graph.
Partitioning this bipartite graph leads to co-clustering of the two data types.
where the  rst |W| vertices index W and the last |M| index M. The two data types in the co-clustering problem can be represented by the two vertices of the weighted bipartite graph.
Co-clustering of the data is achieved by partitioning the bipartite graph.
In Figure 1, we show the bipartite graph partitioned using dotted lines.
The two partitions obtained are {m1, m2, m3, w1, w2, w3} and {m4, m5, m6, w4, w5, w6, w7}, respectively.
Therefore, the objects in M are clustered into {m1, m2, m3} and {m4, m5, m6}, while those in W are clustered into {w1, w2, w3} and {w4, w5, w6, w7} simultaneously.
In order to compute these partitions using the spectral approach, we also need to solve a generalized eigenvalue problem as in Equation (7).
However, due to the bipartite nature of the problem, the eigenvalue problem reduces to a much e cient Singular Value Decomposition (SVD) [12] problem, and has found application for co-clustering in varied  elds [6, 19, 7].
Recently, Isoperimetric Co-clustering Algorithm (ICA) [26] was proposed to achieve pairwise co-clustering by partitioning a bipartite graph.
ICA bears resemblance to the spectral approach in the sense that it does not require the coordinate information of the vertices of the graphs and allows us to  nd partitions of an optimal cardinality instead of a prede ned cardinality.
It has been shown that ICA outperforms the spectral approach in terms of the quality, e ciency and stability in partitioning a bipartite graph.
co-clustering f1 f2 f3 f4 f5 f6



 m 1 m 2 m 3 m 4 m 5 m 6

 w 1 w 2 w 3 w 4 w 5 w 6 w 7 Figure 2: Tripartite graph of visual features, web images and the words coming from the surrounding text of the images.
The integration of multimodal information for e cient Web image clustering can be represented using a star-structured k-partite graph.
The structure of this weighted graph is such that the central data type (images) is connected to all the other data types (di erent features).
There are no direct edges between the feature vertices.
Images are able to utilize multimodal information by being connected to the di er-ent kinds of feature vertices simultaneously.
In an abstract level, a star-structured k-partite graph can be considered as a generalized version of a tripartite graph.
As a preliminary attempt, in this work, we integrate visual and textual features simultaneously using a tripartite graph, shown in Figure 2.
An undirected tripartite graph G ={F, M, W, E}, has three sets of vertices, viz., F, M and W with E as the set of edges.
If A and B represent the weight matrices for feature-image and image-word bipartite graphs respectively, then the adjacency matrix of the graph is de ned as,  






    
 (9) Every entry in A and B represents the importance of a particular feature and word for that image, respectively.
For B, word frequency in the surrounding text of the images is used.
Partitioning this graph lets us achieve Web image clustering by integrating information from visual and textual features synchronously.
Gao et al. [11] have used a similar tripartite graph model in their Consistent Bipartite Graph Co-partitioning (CBGC) framework.
The tripartite graph is considered to be a fusion of the two bipartite graphs that are partitioned simultaneously using the spectral approach.
Let q = [f m]T and p = [m w]T denote the indicator vectors for the two bipartite graphs and D(f m), D(mw), L(f m) and L(mw) represent the diagonal and Laplacian matrices of the two bipartite graphs.
Then the objective function to minimize for the tripartite graph is expressed as a linear combination of objective functions of the two bipartite graphs as follows, (cid:2) (cid:13) min   qT L(f m)q qT D(f m)q + (1    )
 subject to q

 p
 (f m) (mw) pT L(mw)p pT D(mw)p e = 0, q (cid:5)= 0 e = 0, p (cid:5)= 0 0 <   < 1 (10) where the parameter   speci es the weightage for each bipartite graph in the linear combination.
Illumined by this work and the recent results of ICA for pairwise co-clustering [26], we propose to partition the visual feature-image-word tripartite graph using isoperimetric graph partitioning.
We partition the tripartite graph of features, web images and surrounding text words by extending the ICA framework.
To proceed, we  rst provide a brief overview of ICA to partition a bipartite graph.
ICA has been motivated from the combinatorial formulation of the classic isoperimetric problem [8, 24, 15, 16]: For a  xed area,  nd the shape with minimum perimeter.
It provides polynomial time heuristic for the NP-hard problem of  nding a region with minimum perimeter for a  xed area.
Let V = {M W} be the set of vertices of the bipar-(cid:14) tite graph.
ICA partitions V into sets S and Sc, such that Sc =  .
Like other graph partitioning
 algorithms, ICA achieves optimum partitioning by  nding S and Sc so that isoperimetric ratio of the graph hG de ned Sc = V and S (cid:14) (cid:15)

 V olS hG = (11) m 1 m 2 m 3 m4 m 5 m 6 is minimized.
The numerator and denominator represent the boundary area and the volume of S, respectively.
The boundary of S is de ned as,  S = {eij| edges between a vertex in S and Sc}.
Consequently, w(eij) (12) |(cid:6)S| = (cid:3) eij (cid:3)S The combinatorial volume [8] can be de ned as, V olS = |S|, (13) After a few mathematical deductions, ICA achieves the minimization of Equation (11) by solving a sparse system of linear equations as, (cid:7) (cid:8)
 m w = e (14) where L is the Laplacian matrix of the bipartite graph, [m w]T is the indicator vector to indicate partitioning of the two types of vertices, and e is a vector of ones of size |M| + |W|.
Solving this system of equations results in a real valued [m w]T .
In order to get partitions, this solution needs to be cut using a splitting value (as explained in Section 2).
To partition the visual feature-image-word tripartite graph, intuitively it might seem obvious to perform traditional extension of ICA (abbreviated as TICA) by solving a similar system of linear equations corresponding to the adjacency matrix de ned in Equation (9) as follows,     f m w
     = e (15) (16) where L, the indicator vector [f m w]T and e are similarly de ned for the tripartite graph.
However, by doing so the visual feature-image-word tripartite graph actually ends up being a bipartite graph of image and visual feature & word.
This can be seen by shifting the visual feature vertices on to the side of the word vertices as illustrated in Figure 3.
Due to this, we will be unable to distinguish between cutting a visual feature-image edge and an image-word edge and is thus a conceptual misrepresentation of the basic structure of visual features, images and words as in Figure 2.
An alternative approach is to use a weighting parameter   to prevent the mixing of visual feature and word vertices by de ning the adjacency matrix of the tripartite graph as follows,     0


    

  BT
  B
 However, as demonstrated in Section 3.1 and 5, the numerical weightage is unable to prevent the problem.
Moreover, even if it works on a particular dataset, it is not possible to decide the numerical weight a priori and will not work across other datasets.
To overcome the ill-partitioning of Figure 3, we propose the Consistent Isoperimetric High-order Co-clustering (CIHC) to partition the visual feature-image-word tripartite graph by considering it as two bipartite graphs coupled together.
f1 f2 f3 f4 f5 f6 w 1 w 2 w 3 w 4 w 5 w 6 w 7 Figure 3: Traditional extension of ICA (TICA) for partitioning the feature-image-word tripartite graph ends up actually partitioning a bipartite graph of image and feature & word.
f1 f2 f3 m 1 m 2 m 3 m 4 m 5 m 6 m 7 m 8 w 1 w 2 w 3 w 4 w 5 w 6 Figure 4: Toy problem of 3, 8 and 6 vertices of F, M and W, respectively with uniform weights along all edges.
The dotted line shows the ideal cut for partitioning this graph.
x 10 16







 s e g a m i f l o s e u a v g n d d e b m
 i  2










 Figure 6: CIHC results for partitioning the toy graph.
We are able to get perfect partitioning for each of F, M and W vertices.
It is easy to see that applying ICA separately on the two bipartite graphs will result in two di erent partitioning results on the images.
In order to achieve consistent results, we need to partition the two bipartite graphs simultaneously.
That is, visual feature-image bipartite graph needs to be partitioned under the constraints enforced on images by words while, the partitioning of image-words bipartite graph has to be under the constraints enforced on images by visual features.
In other words, we achieve consistent partitioning of images under the constraints that the partitioning of visual feature-image or image-word need not be optimal.
By doing so, we can consistently integrate the visual and textual features simultaneously for clustering the Web images.
Applying ICA to the visual feature-image bipartite graph, we get, (cid:7) (cid:8) (f m)
 f m (f m) = e (17)
 e g a m l i f o s e u a v g n d d e b m
 i

  2000  4000  6000  8000  10000  12000  14000  16000  18000
 TICA with  =0.01 TICA with  =1 TICA, with  =100 TICA, with  =1000


  1  2  3  4 s e g a m l i f o s e u a v g n d d e b m
 i









  5










 s e g a m l i f o s e u a v g n d d e b m
 i



  0.2  0.4  0.6  0.8




  0.2  0.4  0.6 s e g a m l i f o s e u a v g n d d e b m
 i









  0.8










 Figure 5: TICA results for partitioning the toy problem graph of Figure 4.
Each sub gure shows the results for   = 0.01, 1, 100 and 1000.
Similarly, image-word bipartite graph yields us, (cid:7) (cid:8) (mw)
 m w (mw) = e (18) We combine the above two system of linear equations as, (cid:7) L(f m)

 L(mw)     = (cid:8)    f m w (cid:7) (cid:8) e(f m) e(mw) (19) F r = v where v is a vector of ones of size |F| + 2|M| + |W|.
Note that, F is not a square matrix, i.e. this is an overdetermined system of linear equations where the number of equations is more than the number of variables.
Overdetermined system of linear equations is usually inconsistent and does not have any solution.
However, many least squares methods exist to approximate the solution [20].
We adopted the QR decomposition method due to its simplicity and e ciency to solve Equation (19).
Notice that, any other method can be employed as well.
Amongst the common methods for cutting the indicator vector are the median cut and the ratio cut.
Median cut uses the median of the indicator vector r as the splitting value to produce equally sized partitions while ratio cut chooses one such that the resulting partitions have the lowest isoperimetric ratio of the graph indicating optimal partitioning.
As our goal is not to necessarily produce equally sized clusters, we employ the ratio cut to get a bipartition.
Above, we discussed the need for partitioning the tripartite graph by simultaneously partitioning the two bipartite graphs.
We now illustrate this on a toy problem that TICA does not yield optimum results.
For this, we created a tripartite graph shown in Figure 4 having 3 F, 8 M and 6 W vertices with uniform weights along all the edges.
It is easy to infer the ideal partitioning of this graph shown in the Figure using a dotted line.
We partitioned this graph using TICA with adjacency matrix de ned in Equation (16).
In Figure 5, we show the corresponding results achieved when we varied the value of   from 0.01 to 1000.
The X-axis has the vertices in the order of F, M and W with the dotted line separating each of them.
Embedding value for each vertex in the indicator vector is plotted along the Y-axis.
The two pattern plots (  and (cid:6)) represent the two clusters obtained.
These results clearly show that in spite of increasing edge weights for one of the bipartite graphs drastically over the other, TICA is still unable to distinguish between cutting an FM edge from an MW edge on a simple graph.
On the other hand, Figure 6 shows the results achieved using CIHC.
We can see that, CIHC achieves perfect clustering for all the vertices.
Through this toy problem, we have shown the need to consistently apply isoperimetric co-clustering simultaneously.
More results, on real Web images will be presented in Section 5.
The main steps of CIHC can be summarized as follows:
 partite graph, construct the Laplacian matrix L(f m).
bipartite graph, construct L(mw).
the system of linear equations F r = v.
Both CIHC and CBGC partition the visual feature-image-word tripartite graph by considering it as a fusion of the two bipartite graphs.
However, as we explain below the CIHC framework has a number of advantages over CBGC.
In CBGC, the spectral objective functions of the two bipartite graphs are transformed into single-objective function of Equation (10) by expressing it as a weighted linear combination.
As argued in [9], this is a very ad-hoc approach and not a principled one.
The two objective functions represent two di erent kinds of information.
Hence, instead of converting the original dual-objective problem into a single objective problem, one should use a dual-objective algorithm directly.
Another drawback of CBGC, is that its performance is dependent on three parameters, viz.
 ,  1 and  2.
  is the weighting parameter used in the linear combination of objective functions while  1 and  2 are parameters used to put constraints on the SDP bound controllers.
The problem here is that these three parameters have to be predetermined.
In their work, the authors test the performance of CBGC on few image categories by varying the values of the parameters and choose the best values.
As we show in our results (Section 5), this approach for tuning the CBGC parameters works on only those few categories and performs poorly on the other datasets.
In the real world application for Web image clustering, it is impossible to know what parameter values are to be chosen for clustering the images retrieved.
On the other hand, CIHC is a completely parameter-less
 parameters.
In terms of computational complexity, CIHC is much more e cient compared to CBGC as it only requires a simple solution to a sparse system of linear equations.
Di erentiating this equation with respect to  , q  L(f m)  
 (f m)  q   (f m)
 q  2   +  2q  D(f m)  


 Computational time required by CIHC depends on the solution to Equation (19).
In particular, the time complexity is dependent on the number of nonzero entries in L(f m) and L(mw), which asymptotically is O(|E|) where E is the set of edges in the tripartite graph.
Note that, this only measures the time complexity to compute the indicator vector.
We also need to include the time complexity to employ the ratio cut which is of the order of O(h logh) where h = |F| + |M| + |W|.
Factoring this in, the time complexity of CIHC is O(|E|+h logh).
Empirical results on computational speed are presented in Section 5.3.
In this section, we analyze the sensitivity of CIHC and CBGC with respect to a general parameter  .
+ 2D (f m)  q   (25) Using Rayleigh quotient and the Chain rule, it is possible to calculate  2   .
The Rayleigh quotient is,   = qT L(f m)q qT q Applying Chain rule,  2   =  2  q  q   (26) (27) In the above equation,  2  q can be calculated from equation (26) as,
 (f m)
 q(q q)  1   2q
 (f m)
 q(q
 q)  2 q (28)  2  q From Equation (25), since all the terms are either known or can be calculated analytically, we get a system of linear equations which may be solved for  q   .
If we now consider the second term in Equation (22), and proceed similarly, we get Recall from Equation (19), CIHC requires a solution to a sparse system of linear equations represented by, p  L(mw)  
 (mw)  p   (mw)
 p  2   +  2p  D(mw) F r = v Di erentiating this equation with respect to  ,
  r   =  r  F   +  v   (20) (21) For a given solution to Equation (20), F and r are known and  F   can be determined analytically.
In order to determine the derivative at point r,  r   can be solved for as a system of linear equations.
(cid:2) The CBGC objective function is, + (1    ) min   qT L(f m)q qT D(f m)q pT L(mw)p pT D(mw)p (cid:13) subject to certain constraints (22) If we drop the constant weighting parameter   and consider only the  rst term, we get, (cid:2) (cid:13) min qT L(f m)q qT D(f m)q (23) With reference to the previous discussion on Spectral graph partitioning in Section 2, we know from Equations (6) and (7) that the solution for minimizing this term is the eigen-vector corresponding to second smallest eigenvalue  2 of the generalized eigenvalue problem, (f m)
 q =  2 D (f m) q (24)   (mw)  p   (29) + 2D We can analyze the e ect of a speci c parameter, e.g., edge weight, by substituting for the general parameter  . Equations (21), (25) and (29) show that the derivative of the CIHC solution is never degenerate.
On the other hand, the CBGC solution may be degenerate depending on the value of  2 and the state of its corresponding eigenvector.
For dataset preparation we followed the same approach as in [11].
A web crawler was  rst sent out to crawl some of the Webpages in the Yahoo directory1 to extract images and their surrounding texts.
Images having width-height ratios larger than 5 or less than 1/5 and images having both width and height less than 60 pixels were removed.
After this, the image database consisted of 15, 000 images which were manually assigned to 42 categories.
The surrounding text extracted was  ltered to remove common stop words such as conjunctions, articles, etc.
The words left over after this were considered to be the textual features of the image.
We observed that the quality of the surrounding text varies depending on the source Webpage from where an image was extracted.
Correspondingly, we refer to the textual features for each category to be  poor ,  average  or  good .
For the experiments, we randomly selected 10 of these categories shown in Table I.
To ensure that the image-text bipartite graph is not disconnected when two

 Category Name Category Size Text Quality Owls Flowers Lions Elephants Horses Snow Mountains Flying Eagle Dusk Plants Railways









 Average Average Average Good Average Average Average Poor Poor Good categories are mixed together, we added an extra dummy word to the graph that connects to all the images.
The weights for each of these edges was set to be the reciprocal of the number of images in the graph.
For the visual features, we used the PCA-SIFT2 image descriptors [18].
We  rst demonstrate the need to integrate both the visual and textual features simultaneously.
We present the results for clustering Web images using only textual features and only visual features and then show that the performance can be improved by integrating the two simultaneously using CIHC framework.
We will also compare image clustering results of CIHC with TICA and CBGC.
Image Text Co clustering Image Text Co clustering s e g a m i f o s e u a v l i g n d d e b m









  100
 Elephants and Railways images s e g a m i f o s e u a v l i g n d d e b m

















 Dusk and Plants images


 Image-Text Co-clustering.
Figure 7: (Left) Both Elephants and Railways have  good  textual features leading to perfect clustering.
(Right) Dusk and P lants have  poor  textual features that are not su cient in separating the two categories.
Most of the Web images have noisy surrounding text and is not by itself su cient for clustering.
For Web image clustering using only surrounding text, we selected 4 image categories viz., Elephants, T rains, Dusk and P lants.
We mixed Elephants & T rains that both have  good  textual features and Dusk & P lants that have  poor .
We applied the ICA algorithm to the Image-Text bipartite graph to get the partitions.
For all the experiments, we have used the volume as per Equation (13).
In Figure 7, we show the embedding values of the images and the partitioning obtained.
The dotted line separates the image categories.
As expected in the case of Elephants & T rains, we get perfect clustering results.
However, Dusk & P lants images were extracted from some photo gallery webpages that hardly had any worthwhile text in them.
Images from these two categories had a lot of noisy text such 2http://www.cs.cmu.edu/ yke/pcasift/ as photographer name, photographer address, copyrights, etc.
Consequently, the clustering result on these categories using only surrounding text is very poor.
This experiment shows that if the textual features of the image categories are very good, then those themselves are enough to yield optimum results.
However, that is not always true with the surrounding text around the Web images.
Image Feature Co clustering s e g a m i f l o s e u a v g n d d e b m
 i













 Horses and Snow Mountain images







 Figure 8: Image-Feature Co-clustering.
Most of the images selected from Horses and Snow M ountains are separable using only the visual features.
Images from the Horses category that were misclassi ed were due to their similar backgrounds such as sky or snow.
With regards to Web image clustering by relying only on visual features, we selected 4 categories viz., Horses, SnowM ountains, Owls and F lyingEagle.
For this experiment, we  rst mixed Horses and SnowM ountains by selecting 35 visually dissimilar images from each of them.
In Figure 8, we show sample images from both these categories and the image clustering results achieved by applying ICA to the Image-Feature bipartite graph.
Images from these two categories are mainly dissimilar with few similarities in some images such as the sky or greenery in the background.
Due to this fact, we are able to separate the two categories to a great extent using only the visual features.
On the other hand, although Owls and F lyingEagle belong to two different semantic categories, their images resemble on a number of grounds as shown in Figure 9.
Images from these categories have a birdlike object with similar backgrounds.
Owing to the semantic gap, the visual features are unable to represent the semantics accurately.
Figures 7, 8 and 9 show that integrating the low-level visual feature representation and high-level semantics coming from the textual features together simultaneously may yield better clustering results.
Image Feature Co clustering s e g a m i f l o s e u a v g n d d e b m
 i















 Owls and Eagles images






 Figure 9: Image-Feature Co-clustering.
Owls and Eagles are inseparable using only the visual features due to the semantic gap.
Images from both the categories have similar backgrounds and a birdlike structure at the center of the image.
 0.05  0.1  0.15



 s e g a m i f l o s e u a v g n d d e b m
 i TICA with  =0.01  542.91  542.92  542.93  542.94  542.95  542.96  542.97  542.98  542.99 s e g a m i f l o s e u a v g n d d e b m
 i






 Flowers and Lions images

 TICA with  =1 x 10 3 TICA with  =100



  2  4  6 s e g a m i f l o s e u a v g n d d e b m
 i


 Flowers and Lions images










 Flowers and Lions images

 s e g a m l i f o s e u a v g n d d e b m
 i x 10 4
 TICA with  =500




  2  4  6  8






 Flowers and Lions images



 s e g a m l i f o s e u a v g n d d e b m
 i x 10 4 TICA with  =1000



  2  4  6  8






 Flowers and Lions images







 Figure 10: TICA is unable to separate F lowers and Lions images despite the varying values of   from 0.01 to 1000.
Images from both these categories have  average  textual features and visually dissimilar images.
TICA performs disastrously due to the ill-partitioning of the tripartite graph explained in Figure 3 In Section 3, we had discussed the need for simultaneously partitioning the two bipartite graphs of visual features & images and images & textual features.
We now show experimentally that TICA does not yield optimum results for clustering Web images.
For this, we mixed F lowers and Lions images.
Sample images from these two categories and the results obtained using TICA are shown in Figure 10.
Both these categories have  average  textual features with images having similar backgrounds.
The value of the weighting parameter   was varied from 0.01 to 1, 000.
This experiment demonstrates that TICA actually ends up partitioning the bipartite graph of images and the two features together.
As was the case with the toy problem results (Section 3.1), even the change in the values of   does not help in getting better results.
Figure 11 displays the results we get for partitioning the same dataset using CIHC.
From these results, we can make two key observations.
First of all, we can see the advantages of utilizing the information from both kinds of features simultaneously.
In most of the real-world scenarios, it is unlikely that either of the features would be capable of completely describing the respective categories on their own.
 Average  textual features with tolerable amount of noise along with visual features is good enough to get decent clustering results.
Secondly, the capability of CIHC to achieve the same can be seen.
We have compared CIHC with CBGC in terms of the image clustering results, scalability and computational speed.
s e g a m i f l o s e u a v g n d d e b m
 i x 10 16
  5  6  7  8  9  10  11  12  13






 Flowers and Lions images



 Figure 11: CIHC performs well in grouping F lowers and Lions images by successfully integrating the visual and textual features simultaneously.
As mentioned in Section 3.3, CBGC is a very parameter-dependent framework which relies heavily on the values of  1,  2 and  .
To decide on the values for these 3 parameters, we followed the approach suggested by the authors [11].
We randomly selected two image categories (Elephants and SnowM outains) and varied the values of all the parameters between 0 and 1 for the partitioning.
Values that gave best clustering result were chosen and used for the rest of the categories.
The problem with CBGC is that these values are category speci c and have to be retuned for the other categories.
As an example, in Figure 12, we show the clustering results for Elephants and SnowM ountains using CBGC and CIHC.
Based on the above parameter values, CBGC is able to get perfect clustering results.
On the same dataset, CIHC gets similar results.
In another case involving F lying Eagle and Lions shown in Figure 13, CBGC has misclassi ed a number of Lions images.
CIHC on the other hand was able to generate very good clusters.
The same is true in the case of F lowers and Horses shown in Figure 14 where CBGC produces disastrous results and is completely outperformed by CIHC.
We observed similar results in the clustering of other categories.
To summarize, in CBGC, parameters tuned for partitioning certain categories produce excellent results for those particular categories and may not work well for others.
CIHC framework instead does not require any parameter values to be predetermined.
s e g a m i e h t f o l s e u a v g n d d e b m
 i



  2  4  6 x 10 3
 s e g a m i f o l s e u a v g n d d e b m
 i
 Elephants and Snow Mountains images








 x 10 16

 Elephants and Snow Mountains images Figure 12: In the clustering of Elephants and Snow M outains, CBGC is able to get perfect clustering due to the fact that the values used for the parameters  ,  1 and  2 are suitable for separating these two categories.
CIHC is devoid of any parameters and is able to get comparable results on the same dataset.
To evaluate the image clustering performance of CIHC and CBGC across all the categories, we have used the cross-accuracy metric [11].
If two image categories having n1 and n2 images respectively are mixed, then the ground truth

 Table II: Average clustering performance x 10 3




  1  2  3  4  5 s e g a m i f o s e u a v l i g n d d e b m
  2  3  4  5  6  7  8  9 s e g a m i f o s e u a v l i g n d d e b m
  6






 Eagles and Lions images


  10






 Eagles and Lions images


 Figure 13: Parameters previously set for CBGC are unable to separate F lying Eagles and Lions.
A number of Lions images are misclassi ed.
On the other hand, CIHC performs well.
x 10 3  1
 x 10 16

 s e g a m i f o s e u a v l i g n d d e b m
  1.5  2  2.5  3  3.5  4  4.5  5









 Roses and Horses images s e g a m i f o s e u a v l i g n d d e b m


















 Flowers and Horses images Figure 14: Another example of the e ect of a set of parameter values on other image categories.
The set parameter values of CBGC perform very poorly in separating F lowers and Horses.
Once again, as can be seen CIHC gets decent results.
Boolean vector rt can be written as, rt = (1, 1, ..., 1, 0, 0, ..., 0) (30) i i n1 + n2 n1 + n2 (cid:3) (cid:3) , 1       accuracy = max (rti   rci) where the  rst n1 elements are set to 1 and the rest n2 elements are set to 0.
The image clustering results can be represented as a Boolean vector rc having the same ordering of elements as rt.
Cross-accuracy is de ned as follows, (rti   rci)     (31) where   represents the exclusive-OR operation.
We mixed every image category with the rest of the category and measured the accuracy of the clustering.
In Figure 15, we have plotted the accuracy of CIHC (Y-axis) vs CBGC (X-axis).
Each circle in the plot represents a possible image category pair.
It can be seen that most of the circles fall in the upper part of the diagonal.
This indicates that in the clustering of most of the image category pairs, CIHC outperforms CBGC.
The few circles on the lower part of the diagonal are the category pairs for which CBGC has been properly tuned with the parameter values.
In Table II, we show the mean accuracy between each category and all other categories for both the algorithms.
CIHC has a higher mean accuracy and outperforms CBGC on all the categories.
Owls Lions Flowers Elephants Category Name CBGC CIHC



















 Snow Mountains Dusk Plants Flying Eagle Railways Horses









 f o y c a r u c c


 Clustering performance comparison on all image category pairs





 Accuracy of CBGC Figure 15: Clustering performance of CBGC and CIHC on all image category pairs.
Each circle represents a possible category pair.
Most of the circles fall in the upper part of the diagonal.
s d n o c e s n i e m
 i










 Computational Speed for CIHC and CBGC









 Total number of vertices in the tripartite graph Figure 16: Computational speed comparison of CIHC with CBGC.
The time required by each of the algorithms to compute the indicator vector are displayed for increasing number of vertices in the tripartite graph.
In other words, the sparseness of the two data matrices.
it takes more time to partition a densely connected tripartite graph compared to a sparsely connected one.
For this reason, we considered the worst case scenario of a fully connected tripartite graph (with uniform weights) where every vertex in both the bipartite graphs is connected with all other vertices of the other type.
Since the time required to cut the indicator vector is the same for both algorithms, we compare on the basis of the time required to calculate the indicator vector.
The algorithms were implemented using MATLAB 7.03.
For CBGC implementation, we made use of the SDP library SDPA-M 4 [10].
The experiment was performed on a machine with a 3 GHz Intel Pentium 4 processor with 1 GB RAM.
In Figure 16, we plot the time required by the algorithms as the number of vertices in the fully connected tripartite graph increases.
Time for CIHC gradually We now compare the computational speed of CIHC with CBGC.
The time take by both algorithms is dependent on 3http://www.mathworks.com 4http://grid.r.dendai.ac.jp/sdpa/
 number of vertices we increased to - about almost 4, 000, CIHC required about 98 seconds only.
CBGC on the other hand, was unable to keep up with CIHC.
As can be seen, the time required by CBGC really shoots up for a few hundred vertices in the graph.
Moreover, CBGC is unscalable and is unable to handle larger sized graphs, which was also veri ed by [23, 22].
In our experiment, CBGC was unable to handle graphs with more than 1, 500 vertices.
This experiment clearly demonstrates the computational e ciency of CIHC and the potential for applicability in large-scale real-world applications.
In this paper, we addressed the problem of Web image clustering by simultaneous integration of visual and textual features from a graph partitioning perspective.
In particular, we modelled visual features, images, and words from the surrounding text of the images using a tripartite graph.
This graph is actually considered as a fusion of two bipartite graphs that are partitioned simultaneously by the proposed CIHC framework.
Although a similar approach has been adopted before, the main contribution of this work lies in the computational e ciency, quality in Web image clustering and scalability to large image repositories that CIHC is able to achieve.
We demonstrate this through experimental results performed on real Web images.
In future work, there are a number of directions we are actively pursuing.
Currently, in order to get more than two partitions, we recursively apply CIHC which is a common approach in many other graph partitioning algorithms [11,
 more than two clusters directly.
Another extension of this work is to get  exible clusterings for each of the vertex types in the tripartite graph.
That is, currently we have a hard partitioning framework where there is a one-one association between features, images and words belonging to one cluster.
It would be interesting to discover the association between visual features grouped in one cluster and words or images grouped in another.
We are also working on having di erent number of partitions for each of visual features, images and words, instead of all having the same.
To this end, we have found the recent work on matrix factorization by Long et al.
[23, 22] very interesting and helpful.
