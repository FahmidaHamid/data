In recent years, tagging   the act of adding keywords (tags) to objects   has become a popular means to annotate various web resources, such as web page bookmarks [8], academic publications [6], and multimedia objects [11, 25].
The tags provide meaningful descriptors of the objects, and allow the user to organise and index her content.
This becomes even more important, when dealing with multimedia Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
objects that provide little or no textual context, such as bookmarks, photos and videos.
The availability of rich media annotations is essential for large-scale retrieval systems to work in practice.
The current state-of-the-art in content-based image retrieval is progressing, but has not yet succeeded in bridging the semantic gap between human concepts, e.g., keyword-based queries, and low-level visual features that are extracted from the images [22].
However, the success of Flickr proves that users are willing to provide this semantic context through manual annotations.
Recent user studies on this topic reveal that users do annotate their photos with the motivation to make them better accessible to the general public [4].
Photo annotations provided by the user re ect the personal perspective and context that is important to the photo owner and her audience.
This implies that if the same photo would be annotated by another user it is possible that a different description is produced.
In Flickr, one can  nd many photos on the same subject from many di erent users, which are consequentially described by a wide variety of tags.
For example, a Flickr photo of La Sagrada Familia   a massive Roman Catholic basilica under construction in Barcelona   is described by its owner using the tags Sagrada Familia, and Barcelona.
Using the collective knowledge that resides in Flickr community on this particular topic one can extend the description of the photo with the tags: Gaudi, Spain, Catalunya, architecture, and church.
This extension provides a richer semantical description of the photo and can be used to retrieve the photo for a larger range of keyword queries.
The contribution of this paper is twofold.
First we analyse  how users tag photos  and  what kind of tags they provide , based on a representative snapshot of Flickr consisting of 52 million publicly available photos.
Second, we present four di erent tag recommendation strategies to support to the user when annotating photos by tapping into the collective knowledge of the Flickr community as a whole.
With the incredible amount of photos being tagged by users, we can derive relationships between tags, using global co-occurrence metrics.
Given a user-de ned tag and a photo, tags co-occurring with the user-de ned tag are usually good candidates for recommendation, but their relevance of course depends on the photo.
Likewise, for a given set of user-de ned tags and a photo, tags co-occurring with tags in the set are good candidates.
However, in this case a tag aggregation step is needed to produce the short list of tags that will be recommended.
experimental evaluation, by implementing a blind pooling method to collect candidate tags for a given photo with user-de ned tags.
We repeatedly measure the performance on 200 randomly selected photos with a varying number of user de ned tags per photo.
The number of user-de ned tags per photo range from a single tag for sparsely annotated photos to more than six tags for exhaustively annotated photos.
We measure the e ectiveness of the recommendation strategies using four di erent metrics to gain detailed insight in the performance.
We envision two potential applications for the recommendation strategies.
In one application, the recommendations are presented to the user, who can select the relevant tags and add them to the photo.
Alternatively, the recommended tags are directly used to enrich the index of an image retrieval system.
The remainder of the paper is structured as follows.
We start with discussing the related work in Section 2, followed by the analysis of tag behaviour in Flickr in Section 3, where we focus on tag frequencies and tag semantics.
In Section 4 we present the four tag recommendation strategies for extending photo annotations in Flickr.
The setup of the experimental evaluation is described in Section 5, while the results of the experiment are presented in Section 6.
Finally, in Section 7 we come to the conclusions and explore future directions.
Tagging is a popular means of annotating objects on the web.
A detailed account of di erent types of tagging systems can be found in [13] and [16].
The tags have been shown to be useful to give improved access to photo collections both using temporal information [9] and geographic information [3].
The methods we present in this paper extend the tagging of individual photos making them even more useful for the visualisation applications above.
The usefulness of tagging information depends on the motivation of users.
Ames and Naaman explore the motivations for tagging photographs in mobile and online media [4].
Their investigation focuses on the use of the ZoneTag [2,
 upload and annotate photos to Flickr using their mobile phones.
They  nd that most users are motivated to tag photos for organisation for the general public.
They conclude that the tag-suggestion option included in ZoneTag encourages users to tag their photos.
However, suggesting non-obvious tags may be confusing for users.
Furthermore, users may be inclined to add suggested tags, even if they are not immediately relevant.
Various methods exist to (semi-)automatically annotate photographs.
In the image processing and machine learning communities there is work on learning mappings from visual features to semantic labels [5, 15].
The methods take as input a set of labelled images and try to learn which low level visual features correspond to higher level semantic labels.
The mapping can then be applied to suggest labels for un-labelled images based on visual features alone.
For a more detailed account of content-based analysis for image annotation we refer to a recent overview paper by Datta et al. [7].
The ESP game is a tool for adding meaningful labels to images using a computer game [23].
Users play the game by suggesting tags for photos that appear on their screen and earn points suggesting same tags as another player.
The mobile photo upload tool ZoneTag provides tag suggestion based on personal history, geographic location and time [24].
The di erent approaches work on di erent input data and thus complement each other.
The methods we present here complement the ones above since we use yet a di erent input data, namely, the tags assigned originally by the photo owner.
Our method can be applied on top of any of the tagging methods described above.
Our co-occurrence analysis is related to the construction of term hierarchies and ontologies that have been studied in the information retrieval and semantic web communities [20,
 unlimited, and relations between nodes in the graph have an uncontrolled nature.
Despite these two aspects, we use similar concepts to analyse the tag relations.
There has been some previous work on adding semantic labels to Flickr tags.
Rattenbury et al. describe an approach for extracting event and place semantics of tags [18].
The intuition behind their methods is that event and place-tags  burst  in a speci c segments of time or regions in space, respectively.
Their evaluation is based on a set of geotagged Flickr photographs.
Using the method described above they were able to achieve fairly high precision of classifying tags as either a place or event.
The semantic tag analysis presented in this paper we complement this method using WordNet to add a richer set of semantic tags.
In this section we describe the Flickr photo collection that is used for the evaluation, and we provide insights in the photo tagging behaviour of users.
In particular we are interested in discovering  How do users tag?  and  What are they tagging? .
Besides these two aspects, a third aspect is of importance, when studying tag behaviour in Flickr:  Why do people tag? .
This aspect is studied thoroughly in [23,
 by social incentives.
Flickr is an online photo-sharing service that contains hundreds of millions of photos that are uploaded, tagged and or-ganised by more then 8.5 million registered Web-users.
To get some feeling for the size of the operation, during peak times up to 12,000 photos are being served per second, and the record for number of photos uploaded per day exceeds 2 million photos [12].
For the research described in this paper we have used a random snapshot from Flickr of 52 million publicly available photos with annotations.
The photos were uploaded between February 2004 and June 2007 and each photo has at least one user-de ned tag.
When developing tag recommendation strategies, it is important to analyse why, how, and what users are tagging.
The focus in this section is on how users tag their photos.
The collection we use in this paper consists of over 52 million photos that contain about 188 million tags in total, and about 3.7 million unique tags.
Figure 1 shows the distribution of the tag frequency on a log-log scale.
The x-axis represents the 3.7 million unique tags, ordered by descending tag frequency.
The y-axis refers to the tag frequency.
The distribution can be modeled quite accurately
 Flickr.
by a power law [19, 1], and the probability of a tag having tag frequency x is proportional to x 1.15.
With respect to the tag recommendation task, the head of the power law contains tags that would be too generic to be useful as a tag suggestion.
For example the top 5 most frequent occurring tags are: 2006, 2005, wedding, party, and 2004.
The very tail of the power law contains the infrequent tags that typically can be categorised as incidentally occurring words, such as misspellings, and complex phrases.
For example: ambrose tompkins, ambient vector, and more than 15.7 million other tags that occur only once in this Flickr snapshot.
Due to their infrequent nature, we expect that these highly speci c tags will only be useful recommendations in exceptional cases.
Figure 3: Most frequent WordNet categories for Flickr tags.
ally exhaustively annotated, as there are photos that have more than 50 tags de ned.
Obviously, it will be hard to provide useful recommendations in such a case.
The tail of the power law consists of more than 15 million photos with only a single tag annotated and 17 million photos having only 2 or 3 tags.
Together this already covers 64% of the photos.
Typically, these are the cases where we expect tag recommendation to be useful to extend the annotation of the photo.
To analyse the behaviour of the tag recommendation systems for photos with di erent levels of exhaustiveness of the original annotation, we have de ned four classes, as shown in Table 1.
The classes di erentiate from sparsely annotated to exhaustively annotated photos, and take the distribution of the number of tags per photo into account as is shown in the last column of the table.
In Section 6, we will use this categorisation to analyse the performance for the di erent annotation classes.
Class I Class II Class III Class IV > 6 Tags per photo Photos


   15,500,000   17,500,000   12,000,000   7,000,000 Figure 2: Distribution of the number of tags per photo in Flickr.
Figure 2 shows the distribution of the number of tags per photo also follows a power law distribution.
The x-axis represents the 52 million photos, ordered by the number of tags per photo (descending).
The y-axis refers to the number of tags assigned to the corresponding photo.
The probability of having x tags per photo is proportional to x 0.33.
Again, in context of the tag recommendation task, the head of the power law contains photos that are already exception-Table 1: The de nition of photo-tag classes and the number of photos in each class.
To answer the question  What are users tagging? , we have mapped Flickr tags onto the WordNet broad categories [10].
In a number of cases, multiple WordNet category entries are de ned for a term.
In that case, the tag is bound to the category with the highest ranking.
Consider for example the tag London.
According to WordNet, London belongs to two categories: noun.location, which refers to the city London, and noun.person, referring to the novelist Jack London.
In this case the location category is ranked higher than the person.
Hence, we consider the tag London to refer to the location.
Figure 3 shows the distribution of Flickr tags over the most common WordNet categories.
Following this approach, we can classify 52% of the tags in the collection, leaving 48%
 When focussing on the set of classi ed tags, we  nd that locations are tagged most frequent (28%); followed by artifacts or objects (16%), people or groups (13%), actions or events (9%), and time (7%).
The category other (27%) contains the set of tags that is classi ed by the WordNet broad categories, but does not belong any of the before mentioned categories.
From this information, we can conclude that users do not only tag the visual contents of the photo, but to a large extent provide a broader context in which the photo was taken, such as, location, time, and actions.
In this section we provide a detailed description of the tag recommendation system.
We start with a general overview of the system architecture, followed by an introduction of the tag co-occurrence metrics used.
Finally, we explain the tag aggregation and promotion strategies that are used by the system and evaluated in the experiment.
Figure 4 provides an overview of the tag recommendation process.
Given a photo with user-de ned tags, an ordered list of m candidate tags is derived for each of the user-de ned tags, based on tag co-occurrence.
The lists of candidate tags are then used as input for tag aggregation and ranking, which ultimately produces the ranked list of n recommended tags.
Consider the example given in Figure 4, there are two tags de ned by the user: Sagrada Familia and Barcelona.
For both tags, a list of 6 co-occurring tags is derived.
They have some tags in common, such as Spain, Gaudi, and Catalunya, while the other candidate tags only appear in one.
After aggregation and ranking 5 tags are being recommended: Gaudi, Spain, Catalunya, architecture, and church.
The actual number of tags being recommended should of course depend on the relevancy of the tags, and varies for each di erent application.
Tag co-occurrence is the key to our tag recommendation approach, and only works reliable when a large quantity of supporting data is available.
Obviously, the amount of user-generated content that is created by Flickr users, satis- es this demand and provides the collective knowledge base that is needed to make tag recommendation systems work in practise.
In this subsection we look at various methods to calculate co-occurrence coe cients between of two tags.
We de ne the co-occurrence between two tags to be the number of photos [in our collection] where both tags are used in the same annotation.
Using the raw tag co-occurrence for computing the quality of the relationship between two tags is not very meaningful, as these values do not take the frequency of the individual tags into account.
Therefore it is common to normalise the co-occurrence count with the overall frequency of the tags.
There are essentially two di erent normalisation methods: symmetric and asymmetric.
Symmetric measures.
According to the Jaccard coe cient we can normalise the co-occurrence of two tags ti and tj by calculating: J(ti, tj) := |ti   tj| |ti   tj| (1) The coe cient takes the number of intersections between the two tags, divided by the union of the two tags.
The Jaccard coe cient is know to be useful to measure the similarity between two objects or sets.
In general, we can use symmetric measures, like Jaccard, to induce whether two tags have a similar meaning.
Asymmetric measures.
Alternatively, tag co-occurrence can be normalised using the frequency of one of the tags.
For instance, using the equation: P (tj|ti) := |ti   tj| |ti| (2) It captures how often the tag ti co-occurs with tag tj nor-malised by the total frequency of tag ti.
We can interpret this as the probability of a photo being annotated with tag tj given the it was annotated with tag ti.
Several variations of asymmetric co-occurrence measure have been proposed in literature before to build tag (or term) hierarchies [20, 17,
 To illustrate the di erence between symmetric and asymmetric co-occurrence measures consider the tag Ei el Tower.
For the symmetric measure we  nd that the most co-occurring tags are (in order): Tour Ei el, Ei el, Seine, La Tour Ei el and Paris.
When using the asymmetric measure the most co-occurring tags are (in order): Paris, France, Tour Eiffel, Ei el and Europe.
It shows that the Jaccard symmetric coe cient is good at identifying equivalent tags, like Tour Ei el, Ei el, and La Tour Ei el, or picking up a close by landmark such as the Seine.
Based on this observation, it is more likely that asymmetric tag co-occurrence will provide a more suitable diversity of candidate tags than its symmetric opponent.
When the lists of candidate tags for each of the user-de ned tags are known, a tag aggregation step is needed to merge the lists into a single ranking.
In this section, we de ne two aggregation methods, based on voting and summing that serve this purpose.
Furthermore, we implemented a re-ranking procedure that promotes candidate tags having certain properties.
In the this section we refer to three di erent types of tags:   User-de ned tags U refers to the set of tags that the user assigned to a photo.
  Candidate tags Cu is the ranked list with the top m most co-occurring tags, for a user-de ned tag u   U .
We denote C to refer to the union of all candidate tags for each user-de ned tag u   U .
  Recommended tags R is the ranked list of n most relevant tags produced by the tag recommendation system.
For a given set of candidate tags (C) a tag aggregation step is needed to produce the  nal list of recommended tags (R), whenever there is more than one user-de ned tag.
In this section, we de ne two aggregation strategies.
One strategy is based on voting, and does not take the co-occurrence values of the candidate tags into account, while the summing strategy uses the co-occurrence values to produce the  nal ranking.
In both cases, we apply the strategy to the top m co-occurring tags in the list.
Vote.
The voting strategy computes a score for each candidate tag c   C, where a vote for c is cast, whenever c   Cu.
vote(u, c) = if c   Cu otherwise (3) (cid:26) 1
 (cid:88) u U A list of recommended tags R is obtained by sorting the candidate tags on the number of votes.
A score is therefore computed as: score(c) := vote(u, c), (4) Sum.
The summing strategy also takes the union of all candidate tag lists (C), and sums over the co-occurrence values of the tags, thus the score of a candidate tag c   C as calculated as: score(c) := (P (c|u) , if c   Cu) (5) (cid:88) u U The function P (c|u) calculates the asymmetric co-occurrence value, as de ned in Equation 2.
Note that the score of candidate tag c is obtained by only summing over the tags c   Cu.
We will use these two aggregation strategies as the baseline for our evaluation as is presented in Section 6.
Promotion.
In Section 3 we have made a number of observations with respect to tagging behaviour.
In this section, we translate these observations into a  promotion function  to promote more descriptive tags for recommendation.
From the tag frequency distribution presented in Figure 1, we learnt that both the head and the tail of the power law would probably not contain good tags for recommendation.
Tags in the tail were judged to be unstable descriptors, due to their infrequent nature.
The head on the other hand contained tags that would be too generic to be useful (2006, 2005, wedding, etc.).
  Stability-promotion.
Considered that user-de ned tags with very low collection frequency are less reliable than tags with higher collection frequency, we want to promote those tags for which the statistics are more stable.
This is achieved with the following function: stability(u) := ks ks + abs(ks   log(|u|)) (6) In principle this is a weighting function that weights the impact of the candidate tags for a given user-|u| is the collection frequency of the tag de ned tag.
u and ks is a parameter in this function, which is determined by training.
The function abs(x) returns the absolute value of x.
  Descriptiveness-promotion.
Tags with very high frequency are likely to be too general for individual photos.
We want to promote the descriptiveness by damping the contribution of candidate tags with a very high-frequency: descriptive(c) := kd kd + abs(kd   log(|c|)) (7) This is another weighting function, now only applied to revalue the weight of a candidate tag.
kd is parameter in this function, and is con gured by training.
  Rank-promotion.
The co-occurrence values of tags provide good estimates of the relevance of a candidate tag for a user-de ned tag.
In principle, this is already used by the aggregation strategy for summing, but we observed that the co-occurrence values decline very fast.
The rank promotion does not look at the co-occurrence value, but at the position r of the candidate tag c   Cu for a given user-de ned tag u: rank(u, c) = kr kr + (r   1) (8) Recommended Tags Gaudi Spain Catalunya architecture church Candidate Tags Sagrada Familia: Barcelona Gaudi Spain architecture Catalunya church Barcelona: Spain Gaudi 2006 Catalunya Europe travel User-de ned Tags Sagrada Familia BarcelonaTagCo-occurenceTagAggregation & Ranking331WWW 2008 / Refereed Track: Rich MediaApril 21-25, 2008.
Beijing, ChinaIn the equation above, kr is a damping parameter.
The combined promotion function we apply on a tag pair (u, c) is the following: promotion(u, c) := rank(u, c)   stability(u)   descriptive(c) (9) When applying the promotion function in combination with either the voting or summing aggregation function, the score function is update as presented below for the voting case: (cid:88) u U score(c) := vote(u, c)   promotion(u, c) (10) The tag recommendation system now contains a set of parameters (m, kr, ks, kd) which have to be con gured.
We use a training set, as described in the next section to derive the proper con guration of these parameters.
Furthermore, we will evaluate the performance of the promotion function, with respect to the two aggregation strategies in Section 6.
I.e., we evaluate the four di erent strategies as presented in Table 2.
no-promotion promotion vote vote vote+ sum sum sum+ Table 2: The four tag recommendation strategies explored in this paper.
In the following experiment we compare the four di erent tag recommendation strategies through an empirical evaluation.
In this section we de ne the experimental setup and shortly present the system optimisation results, while the evaluation results are presented in Section 6.
We have de ned the following task: Given a Flickr photo and a set of user-de ned tags the system has to recommend tags that are good descriptors of the photo.
In our evaluation we set this up as a ranking problem, i.e., the system retrieves a list of tags where the tags are ranked by decreasing likelihood of being a good descriptor for the photo.
In an operational setting, such a system is expected to present the recommended tags to the user, such that she can extend the annotation by selecting the relevant tags from the list.
For the evaluation we have selected 331 photos through the Flickr API.
The selected photos are based on a series of high level topics, for example  basketball ,  Iceland , and  sailing , that were chosen by the assessors to ensure that they possessed the necessary expertise to judge the relevancy of the recommended tags in context of the photo.
In addition, we ensured that the photos were evenly distributed over the di erent tag classes as de ned in Table 1 of Section 3, to have variation in the exhaustiveness of the annotations.
Despite these two manipulations, the photo selection process was randomised.
Finally, we have divided the photo pool in a training set and a test set.
For training we used 131 photos and the test set consists of 200 photos.
sum 10 vote
 sum+
 vote+
 m ks --

kd --

kr MRR P@5 .5252 .4626 .5405 .5527 .7779 .6824 .7920 .7995 --

Table 3: Optimal parameter settings and system performance for our tag recommendation strategies.
The ground truth is manually created through a blind review pooling method, where for each of the 331 photos, the top 10 recommendations from each of the four strategies was taken to construct the pool.
The assessors were then asked to assess the descriptiveness of each of the recommended tags in context of the photo.
To help them in their task, the assessors were presented the photo, title, tags, owner name, and the description.
They could access and view the photo directly on Flickr, to  nd additional context when needed.
The assessors were asked to judge the descriptiveness on a four-point scale: very good, good, not good, and don t know.
The distinction between very good and good is de ned, to make the assessment task conceptually easier for the user.
For the evaluation of the results, we will however use a binary judgement, and map both scales to good.
In some cases, we expected that the assessor would not be able to make a good judgement, simply because there is not enough contextual information, or when the expertise of the assessor is not su cient to make a motivated choice.
For this purpose, we added the option don t know.
The assessment pool contains 972 very good judgements, and 984 good judgements.
In 2811 cases the judgement was not good, and in 289 cases it was undecided (don t know ).
For the evaluation of the task, we adopted three metrics, that capture the performance at di erent aspects: Mean Reciprocal Rank (MRR) MRR measures where in the ranking the  rst relevant   i.e., descriptive   tag is returned by the system, averaged over all the photos.
This measure provides insight in the ability of the system to return a relevant tag at the top of the ranking.
Success at rank k (S@k) We report the success at rank k for two values of k: S@1 and S@5.
The success at rank k is de ned as the probability of  nding a good descriptive tag among the top k recommended tags.
Precision at rank k (P@k) We report the precision at rank 5 (P@5).
Precision at rank k is de ned as the proportion of retrieved tags that is relevant, averaged over all photos.
We used the training set of 131 photos to tune the parameters of our system.
Recall from the previous section that our baseline strategies have one parameter m and our promotion strategies have additional three parameters ks, kd, and kr.
We tuned our four strategies by performing a parameter-sweep and maximising system performance both in terms of MRR and P@5.
Table 3 shows the optimal parameter settings and system performance for the four tag

 .7628 .6755 .6550 .4550 .9200 .8750 .4930 .4730 Baseline strategies sum vote Promotion strategies sum+ vote+ Improvement of promotion vote+ vs sum 3.3% 3.1% 2.2% 9.9% .6600 .6750 .7718 .7883 .9450 .9400 .5080 .5420 Table 4: Evaluation results for our four tag recommendation strategies using the test collection.
The improvement of promotion is calculated using our better performing baseline run (sum) and better performing promotion run (vote+).
recommendation strategies.
In the next section we use the same parameter settings when we evaluate the system using the test collection.
The presentation of the evaluation results is organised in four sections.
First we report the results for the two aggregation strategies, and in Section 6.2 we examine the performance of the promotion function.
Section 6.3 discusses the results for the di erent tag classes.
Finally, in Section 6.4, we analyse the type of tags that are recommended and accepted, in comparison to the user-de ned tags based on the WordNet classi cation.
In this section we evaluate the performance of the aggregation strategies sum and vote.
The top section of Table 4 shows the results for the two aggregation methods on the test collection.
First, we inspect the absolute performance of the two strategies.
Based on the metric success at rank 1 (S@1), we observe that for more than 65% of the cases our best performing aggregation strategy   i.e., sum   returns a good descriptive tag at rank 1.
For the success at rank 5 (S@5), we see that this percentage goes up to 92%.
For the precision at rank 5 (P@5), we measure a precision of 0.49 for the sum aggregation strategy, which indicates that on average for this strategy 50% of the tags recommended are considered useful.
We can thus safely argue that the sum aggregation strategy performs very well and would be a useful asset for users who want support when annotating their photos.
When looking at the relative di erence in performance between the two aggregation strategies, vote and sum, we observe that for all metrics the sum strategy outperforms the voting strategy.
This is particularly evident for the very early precision (MRR and S@1) where the voting strategy is clearly inferior.
The intuition behind this behaviour is that the voting strategy does not distinguish between tags that occur at di erent positions in the ranking of the candidate lists.
I.e., it considers the top co-occurring tag just as a good candidate as the tenth.
To the contrary, the sum strategy takes the co-occurrence values into account and thus treats a  rst co-occurring tag as a better candidate than the tenth co-occurring tag.
We will now turn our attention to the performance of our promotion function.
The midsection of Table 4 shows the results of the promotion function in combination with the sum or vote aggregation strategies.
First, we inspect at the absolute performance of our promotion method.
In terms of success at rank 1 (S@1) we see that for more than 67% of the photos the vote+ strategy returns a relevant tag at rank 1.
Expanding to the top 5 recommending tags (S@5) we see the performance goes up to 94%.
In terms of precision at rank 5, P@5, we also observe that the vote+ strategy achieves a precision of 0.54, which says that on average 2.7 of the top 5 recommended tags were accepted as being good descriptors for the photo.
If we compare the relative performance between the two aggregation strategies, sum+ and vote+, we observe that the two strategies behave rather similar, except in terms of precision at 5, where the vote+ strategy outperforms the sum+ method.
This indicates that there is an interaction e ect between the sum strategy and the vote+ strategy, showing that the promotion function has a signi cant positive e ect on the e ectiveness of the recommendation.
As a matter of fact, statistical signi cance tests, based on Manova repeated measurements with a general linear model show that the sum, sum+, and vote+ strategies all perform signi cantly better than the vote strategy (p < 0.05).
And likewise for the vote+ strategy, which is signi cantly performing better than sum, and sum+.
In addition, when comparing the relative improvement, as shown in the bottom section of Table 4 for the best promotion strategy (vote+) compared to the sum strategy.
We  nd that for all metrics there is improvement.
The improvement is marginal for MRR, S@1, and S@5, and as reported before, for the precision at 5, P@5, the improvement is signi cant (9.9%).
We can thus argue that our promotion strategy is good at retrieving useful recommendations in the top 5 of the ranking without negatively a ecting the performance very early in the ranking.
This e ect continues if we look beyond rank 5.
For P@10 we measure that the vote+ strategy continues to improve, showing a 10.1% improvement compared to the sum strategy, although the absolute precision goes down to 0.46.
In this subsection we look at the performance of our system over di erent classes of photos, where we classify the photos, based on the criteria as de ned in Section 3.2 (Table 1).
I.e., we look at classes of photos with 1 tag, photos with 2 3 tags, 4 6 tags, and more than 6 tags, respectively.
Table 5 shows the evaluation results of the sum strategy in comparison to the vote+ strategy.
On the sum strategy the performance is not evenly distributed over the di erent classes.
The performance is better when the photo annotation is sparse (classes I and II) than for the photos with a richer annotation (classes III and IV).
For the vote+ strategy, we  nd that the the performance is more evenly distributed over the di erent classes.
Which is re ected in the bottom section of the table where the relative comparison of the sum and vote+ strategies shows a larger improvement for the classes III and IV.
We observe that promotion has a marginal e ect on the photos with only a few user-de ned tags.
However, for the photos with richer annotations the improvement is signi cant.
Hence we conclude that the pro-

.7000 .6800 .6400 .6000 .7000 .7200 .6800 .6000 .9400 .9000 .9600 .8800 .9600 .9000 .9200 .9800 .5160 .5400 .5160 .4000 .5120 .5640 .5280 .5640 .7937 .7762 .7542 .7272 Baseline (using sum) Class I Class II Class III Class IV Promotion (using vote+) Class I Class II Class III Class IV Improvement Class I Class II Class III Class IV .7932 .8040 .7887 .7673
 -0.1% 0.0%




 Table 5: Performance of our system over di erent classes of topics.
Figure 5: WordNet categories of initially assigned tags, recommended tags, and accepted recommendations.
motion has an overall positive e ect, but mainly increases the performance of our system on photos that have more user-de ned tags.
We  nish the evaluation of the tag recommendation system by analysing what type of tags are being recommended and accepted, to follow up on the tag characterisation presented in Section 3.
We will perform this analysis using our best performing strategy, based on vote aggregation and promotion (vote+).
We turn our attention to the WordNet categories of the tags that are visible to the user in the recommendation application: the user-de ned tags, recommended tags, and accepted tags.
Figure 5 shows the WordNet categories of all the tags that took part in the tag recommendation process.
The  g-ure shows results for the combination of training and testing sets.
The  rst column in each group shows the categories of the tags initially assigned by the Flickr photo owners, the next column shows the categories of the top 5 recommended tags, and the third column shows the categories of the accepted tags (i.e., the tags judged as good or very good).
It can be seen that there exists a gap between user-de ned and accepted tags for those tags which can not be classi ed using WordNet Unclassi ed Location Artifact or Object Person or Group Action or Event Time Other Acceptance ratio






 Table 6: Acceptance ratio of tags of di erent Word-Net categories.
WordNet, but that these two types of tags are well balanced for the other categories.
Table 6 shows the acceptance ratio for di erent Word-Net categories.
From the  gure and the table we see that locations, artifacts, and objects have a relatively high acceptance ratio.
However, people, groups and unclassi ed tags (tags that do not appear in WordNet) have relatively low acceptance ratio.
We conclude that our system is particularly good at recommending additional location, artifact, and object-tags.
We conclude this section by recapitulating the main results of the evaluation results presented in this section.
First, we have shown that the proposed strategies are e ective, i.e., the recommended tags contain useful additions to the user-de ned tags.
For almost 70% of photos we give a good recommendation at the  rst position in the ranking (S@1) and for 94% of the photos we provide a good recommendation among the top 5 ranks.
If 5 tags are recommended for each photo, than on average more than half of our recommendations are good.
Second, we proved that our promotion function has a positive e ect on the performance in general, and in particular on the precision at rank 5.
We found a signi cant increase in the number relevant tags in the top  ve recommended tags.
Third, we have shown that our best strategy (vote+) has a stable performance over different classes of photos.
Fourth, we reported that our system is particularly good at recommending locations, artifacts and objects, both in terms of volume and acceptance ratio.
Annotating photos through tagging is a popular way to index and organise photos.
In this paper we  rst presented a characterisation of tag behaviour in Flickr, which forms the foundation for the tag recommendation system and evaluation presented in the second part of the paper.
Tag behaviour in Flickr.
We have taken a random snapshot of Flickr consisting of 52 million photos to analyse how users tag their photos and what type of tags they are providing.
We found that the tag frequency distribution follows a perfect power law, and we indicated that the mid section of this power law contained the most interesting candidates for tag recommendation.
Looking at the photo-tag distribution, we observed that the majority of the photos is being annotated with only a few tags.
Yet, based on a mapping of tags on the WordNet classi cation scheme, we discovered that the
 tags that span a broad spectrum of the semantic space, i.e., they annotate where their photos are taken, who or what is on the photo, and when the photo was taken.
This motivated us to investigate whether the collective knowledge of the community as a whole could be used to help user extend their annotations of individual photos.
Extending Flickr photo annotations.
Based on our observations, we introduced a novel and generic method for recommending tags, i.e., our approach deploys the collective knowledge that resides in Flickr without introducing tag-class speci c heuristics.
Based on a representative sample of Flickr, we have extracted tag co-occurrence statistics, which in combination with the two tag aggregation strategies, and the promotion function allowed us to build a highly e ective system for tag recommendation.
We have evaluated the four tag recommendation strategies in an empirical experiment using 200 photos which are also available on Flickr.
The evaluation results showed that both tag aggregation strategies are e ective, but that it is essential to take the co-occurrence values of the candidate tags into account when aggregating the intermediate results in a ranked list of recommended tags.
We showed that the promotion function is an e ective way to incorporate the ranking of tags and allows us to focus on the candidate tag set, where we expect to  nd good descriptive tags.
Furthermore, the promotion function further improves the results, and has a highly positive e ect of the precision at rank 5.
The best combination, the vote+ strategy, gives a relevant tag on the  rst position in the ranking in 67% of the cases, and we  nd a relevant tag in 94% of the cases when looking at the top 5.
On average, more than 54% of the recommended tags in the top 5 is accepted as a useful tag in context of the photo.
The vote+ strategy also shows to be a very stable approach for di erent types of tag-classes.
Finally, we have shown that our system is particularly good at recommending locations, artifacts and objects.
Open tagging systems like Flickr have continuously evolving vocabularies.
Our method is based on the statistics of Flickr annotation patterns and our co-occurrence model can be incrementally updated when new annotations become available.
Hence our method can gracefully handle the evolution of the vocabulary.
Future Work.
Our future work includes implementing an online system where users can be aided in extending the annotations of their own photos.
Having such a system allows us to evaluate the tag recommendation task more extensively in an online usability experiment.
Our method is complementary to previously explored approaches using either content-based methods [5, 15] or the spatial, temporal and social context of the user [2, 24].
A combination of di erent complimentary methods is likely to give a more robust performance.
Further research into this is left as future work.
Acknowledgments This research is partially supported by the European Union under contract FP6-045032,  Search Environments for Media   SEMEDIA  (http://www.semedia.org).
