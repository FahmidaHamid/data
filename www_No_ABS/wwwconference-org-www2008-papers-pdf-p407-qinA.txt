Ranking is a central problem for web search, because the goodness of a search system is mainly evaluated by the accuracy of its ranking results.
Traditionally, ranking model is constructed by tuning a few parameters with a small amount of labeled data.
It is only recently machine learning technologies called  learning to rank  have been intensively applied to the task.
In the approach, a large number of features and a large amount of training data are used to create the ranking function and various optimization techniques (loss functions and algorithms) are employed to train the ranking function.
Previous work shows that learning to rank has certain advantages when compared with the traditional approaches.
Many methods have been proposed including Ranking SVM [15, 18], RankBoost [12], RankNet [4], List-Net [6], AdaRank [34], MHR [23], and FRank [31].
Existing technologies on learning to rank are limited to one setting of ranking, namely ranking based on content information.
Speci cally, in web search given a query and a number of retrieved documents containing the query, a ranking function is de ned as a function of query and document.
There are other search applications in which relation information between documents can be or must be exploited.
The relation information can be represented in a graph, or more generally, a matrix.
For example, web pages from the same site form a sitemap hierarchy.
If both a page and its parent page are about the topic of the query, then it would be better to rank higher the parent page for this query.
This is a problem referred to as Topic Distillation at TREC [33].
As another example, similarities between documents are available, and we can leverage the information to enhance relevance ranking.
This is a problem close to Pseudo Relevance Feedback [29] in IR.
Other problems like Subtopic Retrieval [36] also need utilize relation information.
Existing learning to rank methods, however, cannot handle the problems.
In this paper, we propose a new learning framework referred to as learning to rank relational objects (e.g., rank relational documents in web search).
In the ranking task, we make use of both content information and relation information.
In conventional learning to rank, (when applied to
 and document pair.
In contrast, in the new learning task, the ranking function is de ned as that of not only query and document pair, but also relations between documents.
The framework is very general, and in this paper we address two speci c tasks: Pseudo Relevance Feedback and Topic Distillation as examples.
We focus on one setting of learning to rank relational objects, in which the way of using the relationships between objects is prede ned, while the parameters of the ranking function need to be trained by using labeled training data.
We formalize the learning task as an optimization problem.
The optimization problem appears to be a challenging issue, because of the nested structure of the ranking function.
We know of no existing method that can be directly applied.
We then propose a new method to solve the problem, and speci cally an implementation method based on SVM.
Experimental results show that the proposed method outperforms the baseline methods for Pseudo Relevance Feedback and Topic Distillation.
The remaining part of the paper is organized as follows.
In Section 2, we introduce related work.
In Section 3, we give a de nition on the problem  learning to rank relational objects  and in Section 4 we propose one solution to the problem.
An SVM-based algorithm is then presented in Section
 are given in the last section.
Learning to rank is a new area in statistical learning, in parallel with learning for classi cation, regression, etc.
The area is attracting broad interests recently, in part because there are many application issues which can be formalized as ranking, for example, web search, and in part because it is a novel learning task and there are many unknown issues which need to be addressed.
Previously, researchers have tried to transform the problem of ranking into that of classi cation and apply existing classi cation techniques to perform the task.
For example, as classi cation techniques one can employ SVM, Boosting, and Neural Network, and this leads to the methods of Ranking SVM [15], RankBoost [12], and RankNet [4], previously proposed in the literature.
Methods for employing the learning methods in web search have been proposed (e.g., [18]).
Furthermore, methods for making the transformation more appropriate for search have also been studied (e.g., [5, 23,
 More recently, a number of authors have proposed directly de ning a loss function on list of objects and directly optimizing the loss function in learning [6, 34, 35, 26].
This approach formalizes the ranking problem in a more straightforward way and thus tends to be more e ective.
All the learning to rank methods, however, are based on the assumption that there is no relation information between the objects that should be used in ranking.
This is not the case in practice, for example, in search, as we pointed out.
As a result, existing methods cannot be directly applied to such kind of setting.
Simply extending existing methods to the setting would not work well, as will be seen in the experimental results section.
Relation information between documents plays an important role in many web search tasks.
For example, ranking web pages on the basis of importance, improving relevance ranking by using similarity information, diversifying search results.
Relation information has been used for importance ranking [22, 19].
The basic idea is that if a page has many inlinks, then the page is likely to be important, and the importance score can be propagated through the link graph.
PageRank [22] and HITS [19] are well known algorithms for computing importance of web pages.
They rank web pages based on the Markov chain model and authority-hub model respectively; both leverage the use of hyperlink (relation) information on the web.
Similarity between documents is useful information for search ranking as well.
Subtopic Retrieval is an example In the task, given a query, the returned documents [36].
should cover as many subtopics as possible.
If there are documents about the same subtopic, then only one document should be selected and ranked high.
(See also [7].)
In other search tasks, similarity between documents is used to boost relevance, for example, in Pseudo Relevance Feedback [29].
The technique  rst conducts a round of relevance ranking, assumes that the top ranked documents are relevant, and extracts new terms from the relevant documents.
It then formulates a new query and conducts a second round of ranking.
With two rounds of ranking, some relevant documents dropped in the  rst round can be ranked higher.
Topic Distillation is another example of using relation information in web search.
Here, Topic Distillation refers to the search task in which we select a few pages that can best represent a topic by exploiting structure (relation) information on the web.
It is found that propagating the relevance of a document to its neighborhood on the hyperlink graph can improve performance of Topic Distillation [27].
Furthermore, propagating the relevance of a web page to its parent pages can also boost the accuracy of the task [24].
Although relation information between documents has been used in search.
So far there has been no previous work on learning to rank which leverages relation information in ranking.
In this paper, we propose a new learning to rank method which utilizes both content information and relation information.
We take Pseudo Relevance Feedback and Topic Distillation as examples.
There are a number of learning problems in which relation information is used.
Semi-supervised learning on graph data is an example, which is a problem as follows.
Given a graph (either directed or undirected), some of the nodes are labeled, we are to use the graph, i.e., relation information, to label the remaining nodes [38, 37, 3].
Some existing methods perform the task by only using relation information [38, 37], while the others try to use both content and relation information [3].
Cluster on graph data is another example of using relation information in learning [9, 28].
Some existing methods make use of similarity relation [28], while the others make use of co-occurrence relation [9].
The major di erence between our work and these work is that ours is based on supervised learning, while they are based on semi-supervised learning or unsupervised learning.
work entities, such as papers in citation graph [1] and pages in Web graph [32].
In the methods, only relation information is utilized.
There are many application problems in which one wants to learn a model to rank objects by using both content information and relation information.
Let us take web search as example.
The central problem in web search is ranking.
Given a query, we retrieve a number of web pages which contain the query from the index, rank the web pages based on a number of factors such as the relevance of the pages to the query, importance of the pages, diversities of the pages, and then present the top ranked pages (for example, 1000) to the users.
The ranking function (model) is usually created and tuned in advance and o line, using certain amount of labeled data (e.g., relevant, irrelevant).
Relevance mainly depends on the contents of the query and the web pages.
If the query matches well against the content of a web page, for example, the query words occur many times in the page, then the relevance of the pages should be high.
The content information can be and is widely used in search ranking.
Sometimes relation information between the web pages is also available, and we want to make e ective use of it as well.
For instance, similarities between web pages can be calculated, and if two pages are similar with each other and one of the pages is relevant to the query, then it is very likely that the other page is also relevant.
If for some reason the former page is ranked in top position, while the latter is not, then we can use the similarity information to further boost the latter.
This is close to the technique Pseudo Relevance Feedback in IR.
In this paper, for simplicity we also refer to it as Pseudo Relevance Feedback.
As another example, if two pages form a parent-child relation at a website, even both of them are relevant to the query (it is very likely that such phenomenon occurs), we may only want to rank high the parent page.
The parent-child relationship between web pages can be found from the URL hierarchy of a website [25].
This is a task referred to as Topic Distillation at TREC.
The question then becomes how to combine both the content information and relation information in learning and ranking.
We consider a new problem of learning to rank, referred to as learning to rank relational objects.
In the task, we consider the use of both contents of objects and relations between objects.
Let X be an n   d matrix representing d dimensional feature vectors of n objects; each row corresponds to one object and each column corresponds to one feature.
Let R denote an n   n matrix representing relationships between the n objects; each row and each column respectively correspond to one object.
Let y be a vector representing ranking scores of the n objects.
In learning, we are given N training samples: (X1, R1, y1), (X2, R2, y2), .
.
., (XN , RN , yN ), drawn from an unknown joint probability distribution P (X, R, y) where X, R, and y denote feature vectors of objects, relations between objects, and ranking scores of objects respectively.
Here, each sample contains n objects to be ordered1.
Ranking only happens within a sample which consists of a  group of objects .
It does not make sense to make comparison between objects across samples.
Suppose that f is a function, such that y = f (X, R).
The goal of learning is to select the best function (cid:98)f from a using the learned function, i.e., yt = (cid:98)f (Xt, Rt).
yt actually In prediction, given features Xt and relations Rt for n objects drawn from the same joint distribution, we output yt function space F using the training data.
(1) represents the ranking scores of the given n objects having features Xt and relation Rt.
Obviously we make use of both feature (content) information and relation information in the ranking function.
We de ne a loss function and formulate the learning problem as that of minimizing the total loss with respect to the given training data.
(cid:98)f = arg min f F N(cid:88) k=1 L(f (Xk, Rk), yk) where L denotes loss function.
We refer to the above learning problem as  learning to rank relational objects .
It is easy to see that the conventional  learning to rank  problem is a special case of the current problem.
Speci cally, if we ignore the relations R, then we get the same function as that in conventional learning to rank, f (X, R) = f (X).
Many problems in web search can be formalized as learning to rank relational objects.
In this paper, we only consider two examples: Pseudo Relevance Feedback and Topic Distillation.
Given a query, there are n retrieved documents.
X is a matrix representing the feature vectors derived from the query and the documents.
R is a matrix representing the relations between the documents.
y is a vector representing the ranking scores of the documents.
In training, the labeled data about N queries is given.
Each consists of the feature vectors X, the relations R, and the  true  ranking scores y.2 We learn a ranking function f using the training data.
In ranking, given n documents of a new query, we use the trained ranking function to assign scores to the documents and sort them.
In the Pseudo Relevance Feedback de ned in this paper, R is simply a matrix representing the similarities between the documents.
In Topic Distillation, R is a matrix representing the parent-child relationship between web pages in a web site.
same number of objects.
It is easy to generalize to the case in which di erent samples have di erent objects.
the same number of retrieved documents n.
We propose a novel method for learning to rank relational objects.
First, we specify the ranking function (1) in the following way y = f (h(X), R) (2) where X and R denote features and relations respectively, h is a function of X.
That is to say, ranking based on relations is de ned in the outer function f , while ranking based on contents is de ned in the inner function h.
There are three settings for learning the nested ranking function.
Setting 1 : inner function h is prede ned, but outer function f is to be learned Setting 2 : outer function f is prede ned, but inner function h is to be learned Setting 3 : both inner function h and outer function f are to be learned In this paper, we address setting 2.
We leave settings 1 and 3 to future work since they are somewhat complex.
Speci cally, we de ne the ranking function as y = f (h(X;  ), R).
where   is an unknown parameter.
Then, learning becomes the following optimization problem: N(cid:88) k=1 min   L(f (h(Xk;  ), Rk), yk) where L denotes loss function, f (h(X;  ), R) denotes ranking function, and y denotes ground truth.
Again in f (h(X;  ), R), the outer function of f is prede ned, but the inner function of h with parameters   is not.
Now the key question is how to de ne the function f to integrate relation information.
We propose de ning f as a solution of minimizing the linear combination of two objectives.
f (h(X;  ), R) = arg min z {l1(h(X;  ), z) +  l2(R, z)} (3) where z denotes any possible ranking scores, the  rst objective l1(h(X;  ), z) measures the di erence between h and z, and the second objective l2(R, z) measures the inconsistency between elements in z under R. Furthermore,   is a non-negative coe cient, representing the trade-o  between the two objectives.
The  rst objective l1(h(X;  ), z) can simply be l1(h(X;  ), z) = (cid:107)h(X;  )   z(cid:107)2 (4) where (cid:107).
(cid:107) denotes L2 norm.
When   = 0 and h(X;  ) is a linear model, the ranking model Eq.
(3) degenerates to the model: f (X, R;  ) = h(X;  ) = X , (5) and the learning problem in Eq.
(3) becomes that of learning of a linear ranking model such as linear Ranking SVM.
The second objective l2(R, z) may have di erent forms, depending on the types of the relationships between objects.
An intuitive explanation of function f in Eq.
(3) is as follows.
There are n objects.
Each object receives a score from the function h. The objects then propagate the scores with each other on the basis of the relationships given in R (for example, R can be a undirected graph).
The propagation must reach a stable state and the n objects obtain their  nal scores z.
The propagation is de ned as minimization of a total objective function, or an energy function.
The total objective function represents a trade-o  between maintaining local consistence with the output from h and maintaining global consistence with the restraints from R.
Similar techniques have been employed in graph based semi-supervised learning and unsupervised learning.
To the best of our knowledge, this is the  rst time, the technique is used in a supervised learning setting.
This is also the key idea of our method for learning to rank relational objects.
In the following subsections, we give explicit forms of the function f in di erent applications in which di erent relationships are de ned and thus di erent objective functions l2(R, z) are utilized.
We consider a variant of Pseudo Relevance Feedback, in which we make use of both the relevance of documents to the query and the similarities between documents in ranking.
We represent the similarity relationship between documents in an undirected graph, in which the nodes represent objects, and the weights on the edges represent the similarities between objects.
Such kind of graph is widely used in clustering and semi-supervised learning.
It is easy to see that we can use a matrix notation to represent the graph.
The second objective function l2(R, z) can then be de ned as l2(R, z) = 1/2 Ri,j(zi   zj)2 (6) (cid:88) (cid:88) i j where Ri,j is the i-th row j-th column element of matrix R, and represents the similarity between documents i and j. zi is the i-th element of vector z.
The rationale behind is that by minimizing this objective we can guarantee that if two documents are similar, then their  nal ranking scores should also be similar.
Speci cally, the larger the value of Ri,j is, the more similar the objects i, j are, and thus the closer the ranking scores zi and zj are.
With Eq.
(4) and Eq.
(6), the ranking model in Eq.
(3) can be rewritten as f (X, R;  ) = arg min z {(cid:107)h(X;  ) z(cid:107)2+ /2 (cid:88) (cid:88) Ri,j(zi   zj)2} i j (7) Let us denote the total objective in Eq.
(7) as l(z) = (cid:107)h(X;  )   z(cid:107)2 +  
 (cid:88) (cid:88) i j Ri,j(zi   zj)2 (cid:80) Let D be a diagonal matrix with Di,i = can write the total objective as j Ri,j.
Then we l(z) = (cid:107)h(X;  )   z(cid:107)2 +  zT (D   R)z.
Note that D   R is in fact the Laplacian matrix of the relationship graph.
Setting the derivative of l(z) with respect
  l(z)  z = 2(z   h(X;  )) + 2 (D   R)z = 0.
This yields (I +  (D   R))z = h(X;  ) (8) where I denotes an n   n identity matrix.
Since   is non-negative, thus matrix I +  (D   R) is diagonally dominant, and so I +  (D   R) is invertible, according to the Levy-Desplanques theorem.
In this way, we obtain the explicit form of the ranking model for Pseudo Relevance Feedback as follows: f (X, G;  ) = (I +  (D   R))  1h(X;  ) (9) For n objects, the time complexity of straightforwardly computing the ranking model is of order O(n3) and thus is expensive.
The main cost of the computation comes from matrix inversion.
We employ the following technique to quickly carry out the computation.
First, we note that solving the system of linear equation (8) is enough to obtain the ranking model.
Let A = I +  (D   R).
If A is a banded matrix with bandwidth k (cid:191) n, then the score z in Eq.
(8) can be solved with time complexity O(n) [14].
If R is a banded matrix, then A is also a banded matrix, and the bandwidth of A is the same as that of R. In order to make R a banded matrix, we should not compute the similarity between all document pairs, and in fact this is not necessary in practice.
Instead, for each document we only consider the k nearest neighborhoods of it.
As a result, R becomes a sparse matrix, which has at most k nonzero values in each row and each column.
By Gibbs-Poole-Stockmeyer algorithm [20], we can convert a sparse matrix to a banded matrix with linear time.
In this way, the time complexity of creating a relational ranking model becomes of linear order of n and thus is comparable with that of the existing learning to rank methods.
Note that the  Pseudo Relevance Feedback (PRF)  in this paper slightly di ers from the conventional Pseudo Relevance Feedback.
Conventional PRF only considers the similarity between the top ranked documents and the other documents in the second round ranking.
By contrast, our PRF in principle takes into consideration the similarity between all document pairs.
We consider Topic Distillation, in which we make use of both the relevance of web pages to the query and the parent-child relation between the web pages in a web site.
We represent the parent-child relationship between web pages in a matrix R, (cid:40) Ri,j = 1 if object i is the parent of j, 0 other.
(10) Note that the matrix is asymmetric in the sense if i is the parent of j then the converse is not true.
The second objective function l2(R, z) can then be de ned as l2(R, z) = Ri,j exp(zj   zi) (11) (cid:88) (cid:88) Note that each exponential function exp(zj   zi) only contributes when its corresponding Ri,j equals one, which means i j i is the parent of j.
In that case, if i has a larger score than j, then the objective will be low; in contrast, if i has a smaller score than j, then the objective will be high.
The relationship is represented as an exponential function.
This is similar to the use of exponential objective function in supervised learning such as Boosting.
With Eq.
(4) and Eq.
(11), the ranking model in (3) can be written as f (X, R;  ) = arg min z {(cid:107)h(X;  ) z(cid:107)2+  (cid:88) (cid:88) Ri,j exp(zj   zi)} i j (12) (cid:88) (cid:88) Let us denote the total objective in Eq.
(12) as l(z) = (cid:107)h(X;  )   z(cid:107)2 +   Ri,j exp(zj   zi) i j It appears di cult to  nd an analytic solution of minimization of the total objective function.
Here, we choose to make an approximation of the function.
First, we approximate exp(zj   zi) using the Taylor ex-pansion3: exp(zj   zi)   1 + (zj   zi) + (zj   zi)2.
Then, we approximate l(z) as l(z)   (cid:107)h(X;  ) z(cid:107)2+  Ri,j 1 + (zj   zi) + (cid:189) (cid:88) (cid:88) i j (cid:190) .
(zj   zi)2

 We have (cid:80) l(z) = (cid:107)h(X;  )   z(cid:107)2 +  (g0 + gT (cid:80) (cid:80)
 i Ri,k  (cid:80) (cid:80) (cid:80) j Rk,j, k = where g0 =

 i Ri,k + j Rk,j), k = 1, 2, ..., n. Setting the derivative of l(z) with j Ri,j, g1k = i respect to z to 0, we obtain  l(z)  z = 2(z   h(X;  )) +  g1 +  (2D   R   RT )z = 0.
This yields (2I +  (2D   R   RT ))z = 2h(X;  )    g1.
(13) Similarly, matrix 2I + (2D R RT ) is invertible, according to the Levy-Desplanques theorem.
In this way, we obtain the explicit form of the ranking model for Topic Distillation: f (X, R;  ) = (2I + (2D R RT ))  1(2h(X;  ) g1) (14) The time complexity of computing the ranking model is of order O(n3) for a general matrix R. In fact, in sitemap hierarchy, a webpage has at most one parent page, and so matrix R has at most n nonzero elements.
That is, R is naturally very sparse.
Similarly to Pseudo Relevance Feedback, for a sparse matrix R we can compute the ranking model in linear time.
The learning (optimization) task in Eq.
(3) is speci ed, when the ranking function is de ned, for example, as in Eq.
(9) and Eq.(14).
One can use di erent techniques to implement the optimization problem, such as SVM, Boosting and Neural Network.
In this section we consider using
 and so this approximation is reasonable.
Ranking SVM .
For simplicity, we consider the linear function h(X;  ) = X .
We  rst make a review of Ranking SVM.
Ranking SVM is a state of the art method for learning to rank, and its learning task is de ned as the following quadratic programming problem:
 2(cid:107) (cid:107)2 + c min , q,i,j q,i,j  q,i,j s.t.
 T xq,i    T xq,j + 1    q,i,j,  xq,i (cid:194) xq,j,  q,i,j   0 where xq,i (cid:194) xq,j implies that object i is ranked ahead of object j for query q in the training data,  q,i,j denotes slack variable, and (cid:107) (cid:107)2 denotes structural loss.
For ease of explanation, we rewrite the above optimization in a matrix form: (cid:80) (cid:80) (15) (16) min , q

 q 1T q  q s.t.
 q   Q, Cqf (Xq;  )   1q    q, f (Xq;  ) = Xq ,  q   0 where Q is the set of training queries, Cq denotes a constraint matrix for query q, 1q denotes a vector with all the elements being 1, and its dimension is the same as that of  q.
Each row of Cq represents a pairwise constraint: one element is 1, one element is  1, and the other elements are all
 of document 3, and document 2 ahead of document 4, then we have (cid:181) (cid:182) Cq =



 Note that Eq.
(16) can be written in a similar form as Eq.
(3):
 q [1q   Cqf (Xq;  )]+ min , q s.t.
 q   Q, f (Xq;  ) = arg minz (cid:107)Xq    z(cid:107)2
 q 1T (17)

 (cid:80) where [x]+ indicates the positive part of x.
This implies that our formulation of the learning problem in Eq.
(3) is quite general.
We next describe Relational Ranking SVM.
Combining Eq.
(9) with Eq.
(16), we can get the optimization problem of Relational Ranking SVM for Pseudo Relevance Feedback, min , q

 q 1T q  q s.t.
 q   Q, Cqf (Xq, Rq;  )   1q    q,  q   0 f (Xq, Rq;  ) = (I +  (Dq   Rq)) 1Xq  (18) This is a Linear Constrained Quadratic Programming problem, and can be solved by employing existing optimization techniques.
Similarly, for Relational Ranking SVM in Topic Distillation, we have an optimization problem as follows: min , q

 q 1T q  q s.t.
 q   Q, Cqf (Xq, Rq;  )   1q    q,  q   0 f (Xq, Rq;  ) = (2I +  (2Dq   Rq   RT q )) 1(2Xq     gq,1) where gq,1 is the vector g1 in Eq.
(13) for query q.
This problem can also be solved by employing existing optimization techniques.
(19) (cid:80) (cid:80)

 We applied Relational Ranking SVM to the tasks of Pseudo Relevance Feedback and Topic Distillation.
We used LETOR [21] in our experiments, which is a dataset created for learning to rank research4.
We used OHSUMED in LETOR for Pseudo Relevance Feedback and TREC in LETOR for Topic Distillation.
As evaluation measure, we utilized NDCG@n (Normalized Discounted Cumulative Gain) [17].
We compared the performances of Relational Ranking SVM and several baseline methods in Pseudo Relevance Feedback using the OHSUMED data set in LETOR.
The OHSUMED data set in LETOR has been derived from the OHSUMED benchmark data [16] for information retrieval research.
The document collection is a subset of MEDLINE, a database on medical publications.
The collection consists of 348,566 records (out of over 7 million) from 270 medical journals during the period of 1987-1991.
The  elds of a record include title, abstract, MeSH indexing terms, author, source, and publication type.
There are 106 queries in OHSUMED data set, each with a number of associated documents.
The relevance degrees of documents with respect to the queries are judged by humans, on three levels: de nitely relevant, partially relevant, or not relevant.
There are in total 16,140 query-document pairs with relevance judgments.
Each query-document pair is represented by a 25 dimension feature vector.
For the details of the features, please refer to [21].
Similarity between documents is provided as relation information.
The similarity between two documents is calculated in the following way.
First stop words are removed from the documents.
Each document is represented by a term vector in the vector space model [2].
The similarity Ri,j between two documents i and j is de ned as cosine between the term vectors of the two documents.
Note that a term vector di ers from a feature vector in learning; the former is a function of document, while the latter a function of query document pair.
As baseline, we adopted Ranking SVM and Ranking SVM plus relation [10].
For reference purposes, we also tested BM25 and Pseudo Relevance Feedback based on BM25.
For BM25 and Pseudo Relevance Feedback, we used the tools provided in Lemur toolkit5.
In Ranking SVM, we only use content information.
In comparison with this baseline, we can see whether Relational Ranking SVM can e ectively leverage relation information to perform better ranking.
Actually, the results of Ranking SVM are already provided in LETOR.
In Ranking SVM plus relation, we make use of both content information and relation information.
Following the proposal in [10], we conduct regularization on the scores output by Ranking SVM, using similarities between documents .
In comparison with this baseline, we can verify whether it is better to integrate relation information into learning process, as in Relational Ranking SVM.
http://research.microsoft.com/users/LETOR/.
5http://www.lemurproject.org/ downloaded from data can set be
 Figure 2: Comparison with Non-Learning Methods We conducted 5 fold cross validation experiments, using the partitions provided in LETOR.
For all the SVM models in the experiments, we employed Linear SVM, because the result of Ranking SVM in the LETOR data set is based on Linear Ranking SVM.
There is a parameter   in the ranking model Eq.(3).
In the experiments, we heuristically set   as 0.1, 0.2, 0.3, and conducted experiments with the values for Relational Ranking SVM and Ranking SVM plus relation.
Figure 1 show the average performances of Ranking SVM, Ranking SVM plus relation, and Relational Ranking SVM over 5 folds.
Here  RSVM  stands for Ranking SVM,  RSVM+R  stands for Ranking SVM plus relation and  RRSVM  stands for Relational Ranking SVM.
For all the   values, RRSVM performs much better than RSVM and RSVM+R in terms of NDCG at all positions.
Particularly for NDCG@1, RRSVM works signi cantly better than RSVM, with more than 10% relative improvement.
Furthermore, RRSVM also works better than RSVM+R.
Figure 2 show the results of BM25 and Pseudo Relevance Feedback (PRF) based on BM25.
We can see that PRF is better than BM25.
RRSVM signi cantly outperforms BM25 and PRF, which veri es the correctness of the claim that learning methods using relation works better than non-learning methods using relation.
In summary, RRSVM can really outperform the baseline methods.
Table 1 and 2 show the top 10 results of RSVM and RRSVM for query  FIBROMYALGIA/FIBROSITIS, DIAGNOSIS AND TREATMENT  separately.
The documents in red are  de nitely relevant , documents in blue are  partially relevant , and documents in black are  not relevant .
It is easy to  nd that RRSVM is better than RSVM for this query.
Document 114913 is a  de nitely relevant  document.
RSVM is only able to rank it to position 5.
This document is in fact very similar to document 142171 which is ranked at position 1.
Using the similarity information between them, RRSVM can e ectively boost it to top 3.
This example shows why we can improve the performance of relevance by using similarity information.
Figure 3: RRSVM with Di erent   Values The coe cient   represents a trade-o  between the uses of content information and relation information.
Figure 3 shows the performance curve of RRSVM with di erent   values.
Note that when   = 0 RRSVM degenerates to RSVM.
RRSVM achieves the highest NDCG@1 value when   = 0.1.
When   gets larger, RRSVM s performance begins to deteriorate.
That is, we need to select relatively small   for this task.
We compared the performances of Relational Ranking SVM and several baseline methods in Topic Distillation using the TREC2004 data set in LETOR.
In TREC 2004, there was a special track for web search.
The goal of this track was to investigate the behaviors of search methods when the document collection is from the web.
The track used the .gov data as document collection, which is from a crawl of the .gov domain on January,

 relevance judgments on documents.
The TREC dataset in LETOR has been derived from the .gov collection.
There are 75 queries, each associated with about 1,000 documents.
The relevance degrees of documents with respect to the queries are o ered by TREC, on two levels: relevant or not relevant.
There are 44 features de ned as functions over a query-document pair [21].
Table 2: Top 10 Results of RRSVM Doc ID Title

 Current pharmacologic therapy of arthritis.
Incidence of transient nephrotic syndrome during pregnancy in diabetic women with and without preexisting microalbuminuria Molecular relationships between the class II HLA antigens and susceptibility to rheumatoid arthritis Impaired carbohydrate metabolism of poly-morphonuclear leukocytes in glycogen storage disease Ib.
Current pharmacologic management of narcolepsy.
Reiter s syndrome precipitated by a typhoid vaccination Neuropeptides in synovium of patients with rheumatoid arthritis and osteoarthritis.
Electromyographic abnormalities in neuro-logic injury associated with pelvic fracture: case reports and literature review.
Synthesis and release of phospholipase A2 by unstimulated human articular chondrocytes.
Role of the general practitioner in managing patients with myocardial infarction







 Doc ID Title

 Current pharmacologic therapy of arthritis.
Incidence of transient nephrotic syndrome during pregnancy in diabetic women with and without preexisting microalbuminuria Current pharmacologic management of narcolepsy.
Electromyographic abnormalities in neuro-logic injury associated with pelvic fracture: case reports and literature review.
Impaired carbohydrate metabolism of poly-morphonuclear leukocytes in glycogen storage disease Ib.
Synthesis and release of phospholipase A2 by unstimulated human articular chondrocytes.
Molecular relationships between the class II HLA antigens and susceptibility to rheumatoid arthritis Cardiopulmonary consequences of obstructive sleep apnea.
Neuropeptides in synovium of patients with rheumatoid arthritis and osteoarthritis.
Defective CD2 pathway T cell activation in systemic lupus erythematosus







 Relation between web pages in a web site is given as a matrix R. The element Ri,j equals 1 if page i is parent of page j, and equals 0 for other cases.
As baseline methods, we used Ranking SVM (RSVM).
We also tested existing non-learning method of sitemap based relevance propagation [24].
The basic idea of sitemap based relevance propagation is to use the relevance of a child page to enhance the relevance of its parent page.
This method makes use of the parent-child relationship.
There are two variants of the method: sitemap based term propagation ( ST  for short) and sitemap based score propagation ( SS  for short).
Considering the fact that Ranking SVM does not use relation information, we tested another method, Ranking SVM plus relation (RSVM+R).
In this method, we use the ranking score of a child page output by RSVM to enhance the ranking score of its parent also output by RSVM.
The idea is similar to that of sitemap based relevance propagation [24].
We conduced 5-fold cross validation experiments, using the partitions in LETOR.
For Ranking SVM, we can make use of the results of it provided in LETOR.
For all the SVM models in the experiment, we employed Linear SVM.
This is because the LETOR data set o ers results of Linear Ranking
 In the experiments, we heuristically set   as 0.1, 0.2, 0.3, and applied them to Relational Ranking SVM.
Figure 4 show the average performances of RRSVM, RSVM, and RSVM+R in 5-fold cross validation.
RRSVM outperforms RSVM and RSVM+R, in all settings of  , especially when   = 0.1.
Although RSVM+R boosts NDCG@1 score higher than RSVM, its NDCG@3 and NDCG@10 scores are not as good as those of RSVM.
The results indicate that learning relation information can indeed boost the performance of Topic Distillation.
Moveover, Figure 5 show the average performances of RRSVM, ST and SS in 5-fold cross validation.
We can see that RRSVM work much better than ST and SS in terms of NDCG.
For example, The NDCG values of RRSVM are 10 points higher than the relevance propagation methods, which represents 30% relative improvements.
The results show that the learning based method can achieve better accuracy than non-learning methods.
Figure 4: Comparison with Learning Methods
 We investigated the reason that RRSVM can achieve better results than RSVM and concluded that it is because RRSVM can successfully leverage the relation information.
Doc ID URL









 http://www.nasa.gov/ http://lifto .msfc.nasa.gov/ http://www.hq.nasa.gov/osf/ http://www.hq.nasa.gov/osf/heds/ http://spacelink.nasa.gov/nasa.../.index.html http://www.lanl.gov/csse/ http://sse.jpl.nasa.gov/ http://technologyplan.nasa.gov/default.cfm?id=8.0 http://www.pnl.gov/microcats/apps/space/ http://www.jpl.nasa.gov/forum/ Figure 5: Comparison with Non-Learning Methods Table 3: Top 10 Results of RSVM Doc ID URL









 http://www.nasa.gov/ http://lifto .msfc.nasa.gov/ http://www.hq.nasa.gov/osf/heds/ http://www.hq.nasa.gov/osf/ http://spacelink.nasa.gov/nasa.../.index.html http://core.nasa.gov/cu.html http://www.hq.nasa.gov/osf/heds/hedsplan.html http://sse.jpl.nasa.gov/ http://www.lanl.gov/csse/ http://www.pnl.gov/microcats/apps/space/ Table 3 and 4 show the case of query  space exploration .
There are ten results returned by each of the methods RRSVM and RSVM.
The answer pages for this query are red colored.
In Table 3, the answer page (id 20325) is ranked below its child page (id 22352) by RSVM, because its content feature is not so strong as that of its child page.
In Table 4, the answer page (id 20325) is ranked higher than its child page (id
 relation information to boost the position of it.
The coe cient   represents a trade-o  between the uses of content information and relation information.
Figure
   values.
Note that with   = 0 RRSVM degenerates to RSVM.
Again, RRSVM achieves the highest NDCG@1 score at   = 0.1.
When   gets larger, RRSVM  performance begins to deteriorate.
That is, we need to select relatively small   for this task.
In this paper, we have proposed a new and general problem referred to as learning to rank relational objects, in which the ranking model is de ned as a function of both content information and relation information of objects.
Learning to rank relational objects can be applied to a large variety of problems in web search, such as Pseudo Relevance Feedback and Topic Distillation.
We have focused on one setting of the learning task and proposed a new learning method for it on the basis of optimization.
We have applied the method to the above two web search tasks by de ning Figure 6: RRSVM with Di erent   Values suitable ranking models.
Furthermore, we have developed SVM techniques for solving the optimization problem.
Experimental results on two public data sets show that the proposed method performs signi cantly better than the baseline methods.
There are still many issues which need further investigations.
(1) We have assumed that all the training queries and documents are labeled.
It is interesting to study how to perform learning to rank relational objects when some of the queries and documents are unlabeled.
(2) We have looked at one setting of the problem (setting 2 in Section 4.1), it is interesting to know how to address the learning problems in the other settings (setting 1 and 3).
(3) We have formalized the learning task as an optimization problem with a nested ranking function.
It is worth to see whether there are any other approaches.
(4) We have proposed one learning method to solve the optimization issue.
The generalization ability of the method is not known.
(5) We have applied the SVM techniques to the problem.
It is also interesting to see how to apply other techniques such as Boosting and Neural Network here.
(6) We have studied two applications: Pseudo Relevance Feedback and Topic Distillation.
We also need to look at other web search tasks.
We would like to thank Eric P. Xing and John D. La erty for their valuable comments and suggestions on the work.
We would also like to thank Xiu-Bo Geng, Yu-Ting Liu, Cong-Kai Sun, Fen Xia, Zhen Liao, and Yin He for their proofreading of the paper.
