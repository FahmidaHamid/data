Email spam has been around for more than a decade, with many covert companies o ering mass emailing services for product advertisements.
It has become usual for people to receive more spam email than relevant email.
The design of the SMTP protocol is one main reason for email spam: it is possible to send millions of fake email messages via computer software without any authentication.
Lately, authentication policies have been adopted by various web servers, where webmasters can maintain a list of blocked web domains.
However, spammers keep registering millions of domain names at a pace far greater than what system administrators can cope up with.
The biggest step in the  ght against spam has been the successful design of spam  ltering software.
Such software typically trains classi ers to identify spam and ham.
For the past decade, much progress has been made in designing accurate classi ers for text emails.
These classi ers are trained to use two kinds of rules: (a), rules based on connection and relay properties of the email, and (b), rules exploiting the features extracted from the content of emails.
The former category of rules utilize publicly shared blacklists of servers which have been known to transmit spam emails.
This information is frequently updated, requiring spammers to change domain names and servers frequently.
The second type of rules use features extracted from spam text (e.g.
keywords, frequent words etc) which are compared with corresponding features from ham text (normal emails) and classi ers are learnt [6].
Such classi ers have proven to be very useful and highly accurate, even though spammers continue to devise novel ways of fooling them.
Image based spam is a breakthrough from the spammers  view point; it is a simple and e ective way of deceiving spam  lters since they can process only text.
An image spam email is formatted in HTML, which usually has only non-suspicious text with an embedded image (sent either as an attachment or via the use of self referencing HTML with image data in its payload).
The embedded image carries the target message and most email clients display the message
 to make images resemble web pages.
in their entirety.
Since many ham emails also have similar properties (using HTML, carrying embedded images, with normal text) as image-based emails, existing spam  lters can no longer distinguish between image-based spam and image ham.
A whitepaper released in November 2006 [12] shows the rise of image spam from 10% in April to 27% of all email spam in October 2006 totaling 48 billion emails everyday.
It is thus imperative to devise new approaches for identifying image-based spam in email tra c which are both fast and accurate.
Clearly, identi cation of image-based email spam (referred as I-spam here onwards) requires content analysis Since images are a large and of the attached image.
heterogeneous data format, it is essential to understand characteristic properties of I-spam in order to identify them successfully.
I-spam has been studied very recently by some researchers and it is possible to identify some common traits of currently visible spam images; exploiting these properties forms the basis of our solution to detection of I-spam.
  I-spam contains text messages: Almost all images in spam emails contain text messages conveying the intent of the spammer.
This text is usually an advertisement and often contains text which has been blacklisted by spam  lters (e.g.
Cialis pills, drug store, stock tip, etc).
  I-spam is usually noisy and di erent from one another: It takes signi cant e ort to design a spam image; however spammers reduce the involved e ort by generating spam images using algorithms which ensure each generating image is distinct.
To achieve this, techniques used include rearranging the items in spam emails, adding random noise, changing background or font colors, using di erent fonts and sizes, using random patterns like lines or circles, adding borders and so on.
While such changes might go unnoticed by a human at the  rst glance, they cause signi cant changes in the properties of resulting in statistically di erent data.
This obfuscation of original data makes trivial content analysis unsuitable; in fact, even sophisticated techniques like Optical Character Recognition (OCR) can fail to recognize text in images, a fact that is often used in designing CAPTCHAs.
This line of spam generation renders early i-spam detection techniques [6] ine ective.
  I-spam messages use HTML e ectively: I-spam uses images, MIME to transport attached image data along with HTML formatting and non-suspicious text.
However, the text contained in I-spam images and the text contained in the HTML body usually have no correlation, a property which can be exploited to classify i-spam.
Regular text is usually taken from books or standard documents used to fool text-based email classi ers.
Thus, the HTML text o ers almost no help to test classi ers, unless appearing too harmless can be exploited as a feature.
  I-spam messages di er from natural images: Natural images tend to have smoother distribution in RGB/LAB color-space than I-spam.
This property leads to better approximation of natural images by arti cial distributions (e.g.
Gaussian) than i-spam which often includes clear and sharp objects.
This property is di cult to exploit in practice; nevertheless it is a signi cant property since ham emails with attached images contain very often natural images (e.g.
photographs).
  I-spam messages are template based: A large number of I-spam are near-duplicates, i.e. a base pattern is permuted to form large number of similar looking but distinct I-spam images.
Spammers exploit an existing pattern for a certain time period before investing in a new I-spam pattern.
Such patterns are common in the world of text email spam, and are normally tackled by collaborative feedback from the user community.
We envision the application of similar methods for new kinds audiovisual spam in systems like YouTube.
Available  gures for 2006 suggest more than 30% of all spam emails are image based, and most of these emails reach email inboxes undetected.
Humans are easily able to distinguish spam images from normal spam; moreover, they can abstract from various versions of the same base image, even though these images may have very di erent properties like background, fonts, or di erent arrangement of sub-images.
Current feature based approaches have had some success in identifying image spam [5]; extracted features include  le type and size, average color, color saturation, edge detection, and random pixel test.
However these features do not seem to provide good generalization, since spammers can easily modify these features; thus further
 In particular, we observe that computer-generated images do not have the same texture as natural images; natural images like photographs would likely be classi ed as ham.
We therefore postulate that low-level features which capture how an image is perceived are likely to be better discriminants between spam and ham.
This is the  rst part of our detection strategy: to  nd features which capture how humans perceive spam images vs. ham images.
While some extracted features may provide good generalization, a spammer can clearly realize this and mutate spam images by using more natural/photographic content in spam images.
However, creating completely di erent image spam each time is a costly activity; thus any spam image is likely to have thousands of similar (though not same) images, each generated from the same template image, but modi ed using the usual spam tricks.
Even though image spam may evolve to defeat obvious giveaway features (like text), there are likely to be many near duplicates.
This forms the second part of our spam detection strategy: to detect near-duplicates of spam images which have been labeled as spam.
As noted earlier, recent work has used feature-based [5] have classi cation to detect I-spam.
Dredze et al.
investigated the use of high-level features in classifying I-spam.
Table 1 lists the features used by the authors in this work; the core idea is that high level features of the image, for example  le format, can be extracted much quicker than lower level features like edges; thus there is an intrinsic ordering of features we want to consider in order to build fast classi ers.
The approach is general and our work can easily be extended to this framework.
Other researchers (cf.
[16]) have discussed yet another important aspect which we capture in our methodology: they have investigated common obfuscation methods like rotation, scaling, partial translation, font change etc.
They correctly identify the procedure used by spammers to generate image spam; they postulate that the two steps involved are template generation and the randomization of template.
This procedure makes images sent to di erent users di erent in nature, hence defeating simple techniques for checking exact duplicates (e.g.
hashing).
However, their method is limited in the features used, achieving an accuracy below
 using a simple and novel mechanism of dealing with various obfuscation techniques.
Table 2 lists obfuscation techniques that the survey in [16] has identi ed.
Early methods for I-spam exploited the heavy use of text in I-spam, a feature that is still present.
However, spammers hit back by exploiting the de ciencies of Optical Character Recognition and modifying I-spam accordingly.
Shortcomings of OCR have been aptly demonstrated in the design of CAPTCHAs1 which remain an e ective mechanism of telling humans and computer agents apart.
To demonstrate the ine ectiveness of OCR for (current) I-spam  ltering, we have compared our algorithm with OCR.
1www.captcha.net Feature Type Average Color Color Saturation Edge Detection File Format File Size Image Metadata Image Size Prevalent Color Coverage Random Pixel Test No.
Of Features








 Table 1: Features used for I-spam classi cation by Dredze et al. [5] Method Description wave animate deform rotate shift crop size dots bars frame font line color shape metadata url using wavy text to fool OCR using animated frame deforming text using irregular fonts rotate text to defeat OCR move template image cropping template image randomly same image on di erent canvas size adding random pixels adding random lines in the image add a frame to the use di erent font or size adding lines of random color use random shapes in background randomize metadata use di erent urls in image Table 2: Randomization Methods used for I-spam generation by Wang et al. [16]


 While technology may not be advanced enough for recognizing spam from random images without any explicit instructions or rules, recent research in machine learning has lead to e cient and accurate pattern recognition algorithms.
Our near duplicate detection algorithm is based on the intuition that we can recognize a lot of images similar to an identi ed spam image; since I-spam is usually generated from a template (see Sec.
2), near duplicates should be easy to detect.
Given enough training data, we should be able to detect large volumes of I-spam, while being open to further training.
We should additionally provide better generalization performance than pure similarity search and abstract from observer positive and negative samples.
Near-duplicate detection for images is an extreme form of similarity search [7] which is a well studied topic.
Recent work in probabilistic image clustering has focused on similar issues but from a di erent perspective, where a query image is used to search for similar images in a large database.
Probabilistic image modeling is particularly suited to the task at hand since we want to classify a family of images as spam, while having observed only a few samples from the family.
We have chosen Gaussian Mixture Models (GMM) as the starting point for our approach.
Gaussian Mixture Models model an image as coherent features are extracted regions in feature space.
First,
 feature space.
For each pixel, we extract a seven tuple feature vector: two parameters for pixel coordinates (x, y) (to include spatial information), three for color attributes in the color space and two for texture attributes (anisotropy and contrast [3]).
We chose the (L , a , b  ) color space (henceforth called as Lab) since it models most closely how humans perceive colors.
The Lab color space is perceptually linear, meaning that a change of the same amount in a color value produces a change of about the same visual importance.
For texture, anisotropy and contrast are extracted from the second moment matrix de ned as follows: M  = G (x, y)   ( I)( I)T , (1) where G (x, y) is a separable binomial approximation to a Gaussian smoothing kernel with variance  2, and ( I) is the gradient of the L channel in the Lab color-space.
At every pixel, M  is a 2   2 matrix, and can be eigen-decomposed very simply.
Considering a  xed scale  , we compute the eigenvalues { 1,  2} for M  at (x, y).
Anisotropy are consequent de ned as A = 1    2/ 1 and contrast c =  
  1 +  2.
Given this transformation, we now represent an image as a set of 7-tuples: I = {p1, p2,    , pn}, pi = (xi, yi, Li, ai, bi, Ai, Ci) , (2) where n is the number of pixel in the image.
Given this representation with parameters , we model the probability distribution of I with a mixture model with K gaussians, f (p| ) =
 j=0  j fj(p| j ), s.t.
kX j=0  j = 1 (3) where p is a feature vector, representing each point of an Image, and   = ( 1,  ,  K ,  1,  ,  K ), and each fj is a multivariate Gaussian density function parameterized by  j i.e., ( j and  j ).
The probability distribution function fj (p| j) can then be written as 1q (2 )d| j| exp{  1 fj (p| j) =  1(p    j )T} (p    j ) k
 Additional constraints on the parameters of the above model include  j > 0, and diagonal covariance  j ; this simpli es the model and avoids inversions of the covariance matrix.
We are now interested in  nding the maximum likelihood estimate (MLE) of the model parameters  , such that:  M L = argmax
 f (p1, p2,  , pn|    ) (4) Since no closed form solutions exist for the above maximization, Expectation Maximization [4] is used to  nd the MLE.
The EM procedure alternates between E-steps and M-steps where the parameters are updated in the direction of maximum gain in log-likelihood.
The EM equations for GMM are presented below: E-step: wij =
  jf (pi| j ,  j )  lf (pi| l,  l) k l=1 (5) M-step: wij nX  j   1 n


  j    j   i=1 n i=1 n i=1 n i=1 wij pi wij wij (pi    j)(pi    j )T
 n i=1 wij (6) (7) (8) The GMM framework allows us to learn probabilistic models of images, but a hidden assumption is that the images are similar in size.
While this is not true for our data, it o ers an opportunity as well: at lower resolutions, many obfuscation techniques are ine ective.
Using this key assumption, we scale every image to a resolution of 100 100.
The computational advantage of this method is obvious.
This scale has been selected empirically and strikes a balance between loss of information and gain in performance.
We explore the e ect of scale when extracting visual image features in Section 4.1.
In order to ensure faster GMM  tting, we optimized model  tting procedure; the EM model was parameterized using K-means clustering.
For all experiments, the number of mixtures was  xed at K = 4.
A smaller value of K would have resulted in omission of important components of an image, while a larger value would have taken into consideration also the insigni cant portions of an image.
After su cient experimentation, the value of K was  xed at 4 to ensure that noise was  ltered out of the model.
After all the GMMs have been learnt (one for every image), we need to cluster similar images together.
Clustering requires a similarity measure, and our task requires modeling distance between two probability distributions.
A commonly used distance measure is Kullback-Leiber (KL) Divergence de ned as follows:
 P (i) log P (i) Q(i) (9)
 i Even though it gives a measure of closeness of two distributions to each other, this measure is not symmetric.
We therefore choose Jensen-Shannon divergence as the distance measure.
The distance measure between clusters c1 and c2 takes into account both the dissimilarity between the probability distributions and the size of the two clusters as shown by the equation



 (10)
 where M = 1 clustering (Labeled Agglomerative Clustering); the idea is to  nd images which are similar enough in the training set, and to replace them with one signature.
New images from the test set can now be compared to the already identi ed signatures and if there is a close match, then a positive identi cation can be made.
In [8], the authors have described an agglomerative clustering algorithm, where clusters are learnt from observed data in an unsupervised fashion, i.e. the number of clusters is initially unknown.
To aid in clustering, the Information Bottleneck principle is used.
The information bottleneck
 between the objects and the features extracted should be minimized by the desired clustering among all possible clusterings.
Using the IB principle, clustering of the object space X is done by preserving the relevant information about another space Y .
We assume, as part of the IB approach, that  X   X   Y is a Markov chain, i.e. given X the clustering  X is independent of the feature space Y .
Consider the following distortion function: d(x,  x) = DKL(p(y|X = x)||p(y|  X =  x)) (11)
 Note that p(y| x) = where DKL is as de ned above in (10).
p(x| x)p(y|x) is a function of p( x|x).
Hence, d(x| x) is not predetermined, but depends on the clustering.
Therefore, as we search for the best clustering, we also search for the most suitable distance measure.
x Since the number of clusters may not be known apriori, we use the agglomerative clustering.
The Agglomerative Information Bottleneck (AIB) algorithm for clustering is a greedy algorithm based on a bottom-up merging procedure [13] which exploits the IB principle.
The algorithm starts with the trivial clustering where each cluster consists of a single point.
Since we want to minimize the overall information loss caused by the clustering, in every greedy step we merge the two classes such that the loss in the mutual information caused by merging them is minimized.
Note however, that we are still operating in the classi- cation domain, i.e. the data available to us has a label (ham/spam).
The original AIB approach does not consider data labels as input; therefore, we extend it here for handling label data.
We can use label information to restrict the clustering to a similar data, thus speeding up the cluster formation by distance comparison with data of the same label.
Since the base AIB algorithm is quadratic, this information can result in a speedup of up to 4 times (assuming labels are equally likely to be positive and negative).
Further optimizations are possible to make the unsupervised clustering faster (e.g.
merging more than two clusters in an iteration or merging below a threshold); this is a placeholder for replacement with better Labeled AIB algorithms.
Our presented algorithm consists of the two phases GMM training and Labeled AIB clustering which are summarized in Algorithms 1 and 2.
Algorithm 1 TrainGMM (Ii, i = {1..N}, k) Require: Images Ii, i = {1..N}, No of Mixtures k Resize Ii to 100   100 pixels.
Extract (x,y,L,a,b,A,c) features for each pixel.
Perform K-means clustering on Ii.
Choose  j randomly, s.t on Initialize  j to center of cluster j.
Initialize  j to 1.
11: end for Ensure:   = ( j ,  j ,  j ) Repeat E-steps and M-steps (Eq.
(5)-(8)) end while  j = 1.
k j f (p|ci) = { i} {Each image in its own cluster} Algorithm 2 LabeledAIB ( i, Li) Require: GMMs  i, i = {1..N}, Label Li for each image


 4: end for

 7: end for


 Find {m, n} = argmin |Distance(i, j)| repeat m,n until Lm == Ln, else  nd next minimum if Distance(m, n)   T hreshold then Break end if






 18: end for Ensure: f (p|cl), cl, l   No.
Of Clusters f ( c) = |cm cn| f (cm) + Update Distance(i, j) |cm| |cn| |cm cn| f (cn)
 New images, whose label have to be predicted, are  tted to a GMM, and compared to the labeled signatures already known from the trained cluster model.
The closest cluster to a new image, is found using the JS divergence distance, and the label of the new image is the label of the cluster.
As a result, images similar to the signatures corresponding to spam label will be marked as spam and images similar to ham labeled signatures will be marked as ham.
An optimization of this algorithm is to introduce a new label called unidenti ed.
Images that are not similar to any of the existing signatures (i.e.
the JS divergence with the closest cluster is larger than a particular threshold) can be labeled as unidenti ed and may require user intervention to be labeled appropriately into either of ham or spam data sets.
This way more accurate results are obtained while also ensuring that the training phase continues even in the testing phase.
Near-Duplication is likely to perform well in abstracting base templates, when given enough examples of various spam templates in use.
However, the generalization ability of this method will be limited, since we are not exploiting global features of images; there are many likely giveaway features as previous work has shown.
We feel however that the explored feature set does not identify a key aspect: i-spam is arti cially generated.
In this section, we explore visual features like texture, shape and color and learn classi ers using these selected features.
Notice that we extract global features, i.e.
each feature represents a property of the entire spam image.
Color models are used to classify colors and to qualify them according to such attributes as hue, saturation, lightness, or brightness.
The Red-Blue-Green chroma,
 It is also the basic color model for onscreen display.
Using this color model, we chose the following features   Average RGB : Average RGB represents the average values in R, G and B channel of each pixels in an image.
The range of RGB is normalized to (0, 1).
  Color Histogram: For a given image, the color histogram HI is a compact summary of the image.
A color histogram H is a vector (h1, h2,  , hn), in which each bucket hj contains the number of pixels of color j in the image.
Typically images are represented in the RGB color-space, and a few of the most signi cant bits are used from each color channel.
We chose a 6-bit color space leading to 64 feature vectors.
  Color Moment: The use of color moments is based on the assumption that the distribution of color in an image can be interpreted as a probability distribution.
Probability distributions are characterized by a number of unique moments; [14] uses three central moments of a image s color distribution; they are mean, standard deviation and skewness.
Using RGB channels and 3 moments for each channel, we get 9 feature vectors.
  Color Coherence Vector : An image s color coherence is the degree to which pixels of that color are members of large similarly-colored regions.
We refer to these signi cant regions as coherent regions and aim to classify pixels as coherent or incoherent.
We  rst blur the image slightly by replacing pixel values with the average value in a small local neighborhood (currently including the 8 adjacent pixels).
This eliminates small variations between neighboring pixels.
We then discretize the color space, such that there are only n distinct colors in the image.
The next step is to classify the pixels within a given color bucket as either coherent or incoherent.
A coherent pixel is part of a large group of pixels of the same color, while an incoherent pixel is not.
We determine the pixel groups by computing connected components.
Note that we only compute connected components within a given discretized color bucket.
This e ectively segments the image based on the discretized color-space.
We classify pixels as either coherent or incoherent depending on the size in pixels of its connected component(C).
A pixel is coherent if the size of its connected component exceeds a  xed value T (e.g.
1% of number of pixels); otherwise, the pixel is incoherent.
128 feature vectors are chosen in this manner.
Image texture, de ned as a function of the spatial variation in pixel intensities (gray values), is useful in a variety of applications and has been a subject of intense study by many researchers (cf.
[15]).
The intuition behind choosing texture features for classi cation is that natural images have a di erent quality of texture as compared to textures in computer generated images.
We extract the following features from the images in our data set:   Autocorrelation: Autocorrelation measures the coarseness of an image by evaluating the linear spatial relationships between texture primitives.
Large primitives Figure 2: Examples of Ham images chosen by us for training the classi er.
Note that we chose some ham images with text as well, other categories of ham images used company logos, cartoons and wall papers.
give rise to coarse texture (e.g.
rock surface) and small primitives give rise to  ne texture (e.g.
silk surface).
If the primitives are large, the autocorrelation function decreases slowly with increasing distance whereas it decreases rapidly if texture consists of small primitives.
If the primitives are periodic, the autocorrelation function increases and decreases periodically with distance.
  Edge Frequency: A number of edge detectors can be used to yield an edge image from an original image.
We can compute an edge dependent texture description function E as follows: E =|f (i, j)   f (i, j + d)| + |f (i, j)   f (i, j   d)| +|f (i, j)   f (i + d, j)| + |f (i, j)   f (i   d, j)| This function is inversely related to the autocorrela-tion function.
Texture features can be evaluated by choosing speci ed distances d and averaging over the entire image.
We vary the distance d parameter from 1 to 25 giving us a total of 25 features.
  Primitive Length (Run Length): A primitive is a continuous set of maximum number of pixels in the same direction that have the same gray level.
Each primitive is de ned by its gray level, length and direction.
Primitive length (run length) uses lengths of texture primitives in di erent directions as texture description.
Coarse textures contain more long texture primitives, and  ne textures contain more short texture primitives.
  Co-occurrence Matrices: Whether considering the intensity or gray-scale values of the image or various dimensions of color, the co-occurrence matrix can
 Because co-occurrence matrices are typically large and sparse, often various metrics of the matrix are taken to get a more useful set of features.
Features generated using this technique are usually called Haralick features [9].
Co-occurrence Matrices are based on repeated occurrence of some gray-level con guration in the texture; this con guration varies rapidly in  ne textures, though more slowly in coarse textures.
  Geometric Moment: Image moments are certain weighted averages (moments) of the image pixels  intensities, or functions of those moments, usually chosen to have some attractive property or interpretation.
When normalized, they can be considered as a probability distribution.
If f (x, y) is a digital image, the central moment is de ned as follows:

  pq = (x    x)p(y    y)qf (x, y) (12) x y The central moment is useful orientation of the image content.
in representing the   Eccentricity: An approximate measure of eccentricity or elongation of an object is given by ( 20    02)2 + 4 11 11 ( 20 +  02)2 e = (13) Where  ij is the i, jth moment as de ned in Eq.
(12).
  Legendre and Zernike Momemts: Global moments are employed as the invariant global features of an image in pattern recognition due to their ability to recognize shapes.
The use of non-geometric moments has been advocated in image reconstruction due to their better resistance to noise and more accurate reconstruction.
Legendre moments use Legendre polynomials while Zernike moments use Zernike polynomials.
sual Features Many approaches exist to train classi ers using extracted features; however, Support Vector Machines(SVM) [2] have been established as the best performing technique.
In particular, the use of the kernel trick allows SVM to explore nonlinear combinations of features by considering dot products in a high dimensional Hilbert space.
The SVM classi cation is formalized as follows: We consider data points of the form: {(x1, c1), (x2, c2), .
.
.
, (xn, cn)} (14) where ci   { 1, 1} and denotes the class that xi belongs to (e.g.
spam/ham).We can view this as training data, which denotes the correct classi cation which we would like the SVM to distinguish, by means of the dividing (or separating) hyperplane, which takes the form w.x   b = 1, |w| = 1 (15) The kernel trick is used in the dual form of quadratic problem solving the above optimization.
The SVMlight package [10] o ers an e cient implementation of SVMs









 y c a r u c c
 n o i t c d e r
 i Classification accuracy of SVM using Visual features.
Images downscaled to 50x50 Images downscaled to 100x100 Images downscaled to 400x400





 Fraction of Training data



 Figure 3: Classi cation Accuracy of Visual Features based-SVM compared at di erent resolutions.
Notice how higher resolutions provide better results, but at much higher costs, since most texture and shape features have non linear extraction time.
with many supported kernels.
Since data might not be separable, soft margin classi cation may be required.
We have used the radial basis function as a kernel function since the corresponding Hilbert space is of in nite dimension.
Algorithm 3 summarizes the overall approach.
Algorithm 3 SVM-classify (Ii, Li) Require: Images Ii, Label Li, i = {1..N}, i i i Fcolor Fshape Ftexture Fi = Fcolor = ExtractColorF eatures(Ii) = ExtractShapeF eatures(Ii)




 6: end for
 = ExtractT extureF eatures(Ii)   Ftexture   Fshape i i i Ensure: Classi er C
 Optical Character Recognition (OCR) was the  rst proposed solution to I-spam; there are various commercial and open source solutions (e.g.
SpamAssasin s FuzzyOCR plugin) using OCR libraries.
We chose to use the well known Tesseract OCR suite developed by HP labs, recently open sourced by Google2.
The OCR based algorithm we use is a simple one: we classify an image as spam if the OCR module can  nd more than 2 characters in the image.
This has low accuracy of around 80%; increasing the threshold to 5 characters leads to accuracies below 65%.
To evaluate our algorithms, we have chosen three recent public datasets; the  rst is due to [6] who collected over
 tesseract-ocr/ is available at http://code.google.com/p/







 Classification accuracy of SVM using Visual features.
reported by Dredze et al Personal Spam vs Ham Spam Archive vs Ham Spam Archive vs Ham* (Dredze et al) All Spam vs Ham* (Dredze et al) Personal Spam Archive vs Ham* (Dredze et al) OCR on SpamArchive Comparision of Classification accuracy of SVM, AIB and OCR





 y c a r u c c
 n o i t c d e r
 i OCR based recognition Visual features based SVM GMM based Labeled AIB linear y c a r u c c
 n o i t c d e r
 i





 Fraction of Training data












 Fraction of Training data Figure 4: Classi cation Accuracy of Visual Features based-SVM compared with previous results.
Notice a signi cant improvement over other approaches and good generalization results at training sizes as low as 10%.
second was created by Dredze et al. [5] (who also used the SpamArchive dataset for evaluation) from their personal emails.
This is called the Personal Spam dataset by the authors; they have also created a Personal Ham dataset from their personal emails, representing true ham emails.
This is an important collection since most other researchers have used general images and photos from the web (examples of ham images are shown in Fig. 3.2.1).
Both these datasets are now publicly distributed at http://www.seas.upenn.
edu/~mdredze/datasets/image_spam/.
The SpamArchive Collection consists of 13621  les, out of which only 10623 are in image format.
The other  les are unreadable by image processors; this is due to deliberate manipulation by spammers to use other alternatives of image for email spam.
The Personal spam collection consists of 3300 images.
In addition, we have also used the Princeton Image Spam Benchmark4 which contains 1071 images with category information.
The utility of this dataset is that each category contains permutations of the same base I-spam template (See Fig. 6).
Baseline: For the sake of comparison, we use the same datasets used previously by other researchers.
In particular, we use the approach for testing as used by Dredze et al. since their results are the best reported so far in comparison to other work.
The above presented algorithms are compared in identical conditions as in the experiments in [5].
OCR results using Open Source Tesseract are also provided for comparison.
We  rst discuss the more general approach of binary classi cation using visual features.
We use our homegrown ham data set consisting of logos, wallpapers, emoticons and similar items used in real world images, photographs,
 org/.
4http://www.cs.princeton.edu/cass/spam/spam_bench/ Figure 5: Comparison of Classi cation Accuracy of Visual Features based-SVM along with GMM based AIB and OCR (Princeton Dataset).
GMM Based AIB # Original Clusters # Clusters Found # Total Images # Images Correctly classi ed # Images Misclassi ed # % Error





 Table 3: Clustering Accuracy of GMM based Labeled AIB on the Princeton Spam Benchmark email exchanges.
In all, this amounts to 5373 ham images created from collected images including a large chunk of Dredze et al. s personal ham (which has not been released in its entirety due to privacy reasons).
We  rst resize the images to 100   100 pixels; this simple mechanism makes our method robust to random pixels, simple translation and scaling.
It also helps greatly with computational requirements as texture and shape extraction are time consuming nonlinear routines.
We then extract features from all the images from the positive and negative test set.
A fraction   of the images are used for training the classi er based on SVMlight while the tests are then carried out on the remaining (1 ) fraction of images.
Fig. 4 reports the prediction accuracy over the positive and negative set as function of  .
We observe that visual features are highly indicative of spam images; our method reports a prediction accuracy of over 95% in all cases.
Even with large sets of over 15, 000 emails with only 10% data used for training, the prediction accuracy is higher than best numbers reported by [5, 6].
At a comparable fraction of training/test set as used by Dredze et al., we achieved almost 98% accuracy, an improvement of over 6%.
With the Personal spam dataset, we achieve comparable results as [5].
We also investigated the impact of resolution on our approach; in particular we are interested to know if lower resolutions can provide similar results at a cheaper computationally cost.
Fig. 3 shows the results of this evaluation; we notice small losses at lower resolutions and small gains at higher resolutions.
At 400   400, the approach is near
 b) a) c) a) c) b) c) Figure 6: Examples of two I-spam images from the same category in the Princeton dataset.
In the  gure on top, (b) is the 100X100 image, and (c) is the reproduced image.
In the  gure below, the small  gures are GMM reconstructions of 100X100 thumbnails.
Notice how close the reproduction of the low-res image is to the actual low-res image.
Even though the spam images are di erent in resolution and content (see the  gure below), the low res reproduction are almost identical to the GMM approximation.
perfect achieving more than 99.6%.
Higher accuracies will be practically impossible due to human errors in labeling data.
It is important to point out that our results are nearly completely comparable with the previous papers; all researchers have used their own ham datasets, including us.
The choice of ham can have a big impact on the outcome of prediction.
However, the important issue is labeling spam correctly over a large heterogeneous spam set.
We are currently procuring more spam by creating honeypots with an aim of collecting over 100,000 spam emails.
We are also working on the creation of a SpamAssassin 5 Plugin using our framework.
Results from GMM based AIB The Labeled AIB approach is unlikely to reach the same generalization performance; the approach is designed to identify permutations of a base template.
Since positive images do not necessary follow this pattern and are potentially in nite, Labeled AIB is expected to be clueless about images previously unseen.
Early experiments in settings as above lead to weak results.
However, the idea is still powerful; collaborative approaches to spam  ltering like Spamato [1] encourage users to share manually-classi ed email spam, which can be used to train 5www.spamassasin.org the spam  lters of other users in the community.
Our approach  ts very well into this framework, since AIB based on GMMs can identify the base template.
This makes our approach also well suited to server deployment as an identi ed pattern can be protected against for a large user population before spam reaches individual inboxes.
The goal is to detect a new pattern in a manner similar to viruses and make the pattern available to all subscribed email servers.
Further investigation of this idea is in progress.
To explore how e ective the GMM approach is in identifying patterns pre-classi ed as spam, we  nd the Princeton dataset very helpful.
This dataset has various categories of I-spam images clustered according to the base template; descriptions of di erent strategies used by spammers are also provided.
Fig. 6 demonstrates that two spam images produced by the same template are indeed modeled very similarly to each other.
Notice how well our chosen features can model the low resolution thumbnails with a simple parametric model.
This provides the perfect opportunity to raise the question: Can AIB Clustering based on GMM identify the clusters correctly and demonstrate that it recognizes the base templates?
We performed a run with our algorithm to test this hypothesis.
The Princeton dataset contains images in 178 categories,
 clusters can be merged and manual clustering resulted in fewer than 150 clusters.
Our approach found 140 clusters; clearly some misclassi cation was also found.
However, the performance is better than indicated by the numbers; clusters that were wrongly merged were classi ed as wrong, though they are similar when manually observed.
When constrained to  nd exactly 178 clusters, the misclassi cation rate falls to below 16%.
This indicates that the predictive performance for spam detection should still be high.
Fig. 5 proves this empirically.
GMM based Labeled AIB has high accuracy when predicting spam in comparable conditions.
OCR does much worse, while the trained SVM has a marginally better performance.
In this paper, we have presented two novel approaches to  ght the menace of image-based email spam by exploiting visual features and the template-based nature of I-spam.
Experimental results heavily support our hypothesis that low-level feature analysis can provide a more accurate detection mechanism than previously known.
Our work complements earlier work, and it should be very easy features extracted by us into the to incorporate visual framework of [5].
The gain is likely to be better accuracy, with a much improved running time by using the JIT feature extraction suggested by them.
Since research in I-spam is recent, with less than one year since the emergence of the problem, more work is likely to happen in the future.
In particular, spammers will notice the anti-spam measures taken and innovate to produce new attacks.
The emergence of PDF based spam is one such innovation from spammers; clearly, spammers try to exploit all popular document formats to get their messages through.
Till more principled shifts in email (e.g.
postage for email c.a.
[11]) or improvements in the underlying protocols happen, anti-spam research will remain a  re ghting operation.
