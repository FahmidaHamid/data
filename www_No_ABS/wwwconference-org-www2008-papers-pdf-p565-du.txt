Nowadays OWL [22] has been established as a core standard in the Semantic Web.
It comes in three layers in ascending expressivity, i.e., OWL Lite, OWL DL and OWL Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
Full, where the former two coincide semantically with certain description logics (DLs) [1].
A DL-based ontology consists of an intensional part and an extensional part.
The intensional part consists of a TBox and an RBox, and contains knowledge about concepts and relations (called roles) between the elements of the domain.
The extensional part consists of an ABox, and contains knowledge about individuals and how they relate to the concepts and roles from the intensional part.
In this paper, the knowledge in intensional parts is called axioms, whilst the knowledge in extensional parts is called ABox assertions or simply assertions.
A crucial question in the vision of Semantic Web is how to support and ease the process of creating and maintaining DL-based ontologies.
An important task within this process is ontology population, which adds instances of concepts and relations to the ontology.
In recent years, there has been a great surge of interest in methods for populating ontolo-gies from textual resources.
To name a few, Text2Onto [3] and KITE [30] are frameworks that integrate algorithms for populating ontologies from textual data.
The algorithms include information extraction algorithms that assign annotations carrying some semantics to regions of the data, and co-reference algorithms that identify annotated individuals in multiple places.
As for populating DL-based ontologies, the information extraction process behaves as adding con-cept/role assertions, whilst the co-reference process behaves as adding equality/inequality assertions.
The populated ontology, however, may become inconsistent because the information extraction/co-reference process is imprecise or the populated data possibly con ict with the original data.
In order to repair the populated ontology, we propose to delete a subset of assertions in which the sum of removal costs is minimum, based on the following considerations.
First, the intensional part should not be changed, because in general it is well prepared and coherent (i.e., having no unsatis able concepts) before the population.
Second, for changing the extensional part, only the deletion of assertions is considered because there is generally no criteria for revising assertions.
Third, for deleting assertions, some minimal criteria on removable assertions (e.g., the cost of losing information) should be considered.
Fourth, the certainty information on an assertion, given by the information extraction/co-reference process, can be used as the cost of losing information (called the removal cost), because deleting a more certain assertion generally loses more information.
Fifth, the
 imated by the sum of removal costs in the set.
Therefore, we in this paper address computing a minimum cost diagnosis for an inconsistent ontology KB, i.e. a subset of removable assertions whose removal turns KB consistent and in which the sum of removal costs is minimum.
We show that, unless P=NP, the problem of  nding a minimum cost diagnosis for a DL-Lite ontology is insolvable in polynomial time (PTIME) w.r.t.
data complexity, i.e. the complexity measured in the size of the ABox only.
Note that DL-Lite is a fairly inexpressive DL language such that the consistency checking problem for DL-Lite ontologies is in PTIME in the size of the ontology [2].
This complexity result implies that the problem of  nding minimum cost diagnoses is in general intractable.
In spite of that, we develop a feasible computational method for more general (i.e. SHIQ) ontologies.
It transforms a SHIQ ontology to a set of disjoint propositional programs by applying an existing transformation method (from SHIQ to disjunctive datalog) [12,
 our method reduces the problem of  nding a minimum cost diagnosis into a set of independent subproblems.
Each such subproblem computes an optimal model and is solvable in O(log2 n) calls to a satis ability (SAT) solver, by assuming that removal costs have been scaled to positive integers polynomial in n the number of removable assertions.
We implement our method and experiment on several originally consistent, real/benchmark ontologies.
Each test ontology has over thousands of assertions.
We implement a tool to inject con icts into a consistent ontology, where a con ict, caused by several inserted assertions, violates a functional restriction or a disjointness constraint.
Experimental results show that, even when all assertions are assumed removable, our method can handle all the test ontolo-gies with injected con icts.
Especially, our method scales well on the extended benchmark ontologies with increasing number (from 1000) of con icts.
There are some works that address repairing DL-based ontologies.
Kalyanpur et al. [13] extended Reiter s Hitting Set Tree (HST) algorithm [24] to compute a minimum-rank hitting set, which is a subset of axioms that need to be re-moved/ xed to correct an unsatis able concept, such that the sum of axiom ranks in the subset is minimum.
The notion of minimum-rank hitting set is similar to that of minimum cost diagnosis, except that the former is on axioms while the latter is on assertions.
Schlobach [26] applied Re-iter s HST algorithm to compute a minimal subset of axioms that need to be removed/ xed to correct an unsatis able concept or an incoherent TBox.
The above methods require all minimal con ict sets be computed beforehand, where a minimal con ict set is a minimal subset of axioms responsible for the unwanted consequence.
Though the above methods can work with ABoxes as well (by viewing assertions as axioms), it is impractical to adapt them to computing minimum cost diagnoses.
First, the problem of  nding a minimum hitting set from minimal con ict sets is intrinsically intractable [15].
Second, though there exist e cient methods for computing a minimal con ict set (e.g., [27, 14, 20]), computing all minimal con ict sets is still hard because the number of minimal con ict sets can be exponential in the number of assertions, as shown in the following example.
Example 1.
Let the intensional part consist of two axioms A (cid:2)  P. A(cid:4) Q. A and  A (cid:2)  P.A(cid:4) Q.A, and the ABox be {A(a1), P (an, a1), Q(an, a1)}   {P (ai, ai+1), Q(ai, ai+1) |
 ontology is inconsistent, because  A(a1) is one of its consequences but con icts with A(a1).
The minimal con ict sets over the ABox are of the form {A(a1), U1(a1, a2), .
.
.
, Un 1(an 1, an), Un(an, a1)}, where Ui is either P or Q.
So the number of minimal con ict sets is 2n.
Hence, a method that computes minimum cost diagnoses from minimal con ict sets may work in exponential time and exponential space w.r.t.
data complexity (e.g., when it handles an ontology that is the union of the ontology in the above example and the ontology given in the proof of Theorem 2).
In contrast, our method works in exponential time (more precisely, in logarithmic calls to an NP oracle) and polynomial space w.r.t.
data complexity.
There exist some heuristics-based methods for repairing DL-based ontologies.
Schlobach [25] proposed an approximate approach to computing a subset of axioms whose removal corrects an unsatis able concept or an incoherent TBox.
Dolby et al. [4] exploited summarization and re ne-ment techniques to compute a subset of assertions whose removal turns an inconsistent ontology consistent.
Their proposed methods, however, cannot guarantee minimality for the set of removed axioms/assertions.
There also exist some methods for revising problematic axioms (e.g., [19, 13, 16, 23]).
But they cannot be adapted to revising assertions, because assertions are assumed atomic in our work.
We only consider the deletion of assertions.
As for dealing with inconsistency in DL-based ontologies, there is another approach that simply avoids/tolerates the inconsistency and applies a nonstandard reasoning method to obtain meaningful answers (e.g., [11, 17]).
We can also adapt our method to this approach, by de ning a consistent consequence of an inconsistent ontology as a consequence invariant under all minimum cost diagnoses.
This is out of the scope of this paper and is not discussed here.
  The SHIQ description logic [10] is a syntactic variant of OWL DL [22] without nominals and concrete domain spec-i cations, but allowing quali ed number restrictions.
A SHIQ RBox KBR is a  nite set of transitivity axioms T rans(R) and role inclusion axioms R (cid:2) S, where R and S be the re exive transitive closure of {R (cid:2) are roles.
Let (cid:2)  S, Inv(R) (cid:2) Inv(S) | R (cid:2) S   KBR}, where Inv(R) = R   and Inv(R ) = R for a role R. A role S is simple if there is S and either T rans(R)   KBR or no role R such that R (cid:2)  T rans(Inv(R))   KBR.
The set of SHIQ concepts is the smallest set containing (cid:8),  , A,  C, C (cid:4) D, C (cid:10) D,  R.C,  R.C,  n S.C and  n S.C, where A is a concept name (i.e.
an atomic concept), C and D SHIQ concepts, R a role, S a simple role, and n a positive integer.
A SHIQ TBox KBT is a  nite set of concept inclusion axioms C (cid:2) D, where C and D are SHIQ concepts.
A SHIQ ABox KBA is a set of concept assertions C(a), role assertions R(a, b), equality assertions a   b and inequality assertions a (cid:14)  b, where C is a SHIQ concept, R a role, and a and b individuals.
A SHIQ ontology KB is a triple (KBR, KBT , KBA), where
 KBR is an RBox, KBT a TBox, and KBA an ABox.
In this paper, by KB we simply denote (KBR, KBT , KBA) if there is no confusion.
DL-Lite [2] is a sub-language of SHIQ.
The set of DL-
Lite concepts is the smallest set containing A,  R,  R and C1 (cid:4) C2, where A is a concept name, R a role name, B a basic concept (i.e. a concept of the form A,  R or  R   ), and C1 and C2 DL-Lite concepts.
 R is actually an un-quali ed existential restriction  R.(cid:8).
A DL-Lite ontology KB = (KBT , KBA) consists of a TBox KBT and an ABox KBA.
KBT is a  nite set of inclusion axioms B (cid:2) C and functionality axioms (func R) and (func R ), where B is a basic concept, C a DL-Lite concept and R a role.
KBA is a set of concept assertions B(a) and role assertions R(a, b), where B is a basic concept, R a role, and a and b individuals.
The semantics of a SHIQ ontology KB is given by a mapping   that translates KB into  rst-order logic.
Due to space limitation, we refer readers to [12] for the de nition of  . KB is said to be consistent/satis able if there exists a  rst-order model of  (KB).
The semantics of a DL-Lite ontology KB can still be given by the same mapping  , because a functionality axiom (func R) is a syntactic variant of (cid:8) (cid:2) 1 R.(cid:8).
Note that the unique name assumption (UNA) [1] on individuals is applied in DL-Lite but not in SHIQ.
UNA can be explicitly axiomatized by appending to the ABox all inequality assertions a (cid:14)  b for any two individuals a and b that have di erent URIs.
  In our work we assume that all concept assertions are attached to atomic concepts only, due to the following reasons.
First, the representation of non-atomic concept assertions is not supported by the RDF/XML syntax of OWL (cf.
http://www.w3.org/TR/owl-ref), which is the main syntax for representing DL-based ontologies nowadays.
Second, a non-atomic concept assertion C(a) can be reduced to an atomic one by replacing C(a) with Q(a) and appending C   Q to the TBox, where Q is a new atomic concept.
A disjunctive datalog program with equality [6] P is a  nite set of rules without function symbols of the form A1   .
.
.
  An   B1, .
.
.
, Bm (where Ai and Bi are atoms).
Each rule must be safe, i.e., each variable occurring in a head atom Ai must occur in some body atom Bj.
For a rule r, the set of head atoms is denoted by head(r), whereas the set of body atoms is denoted by body(r).
A rule r is called a constraint if |head(r)| = 0; a fact if |body(r)| = 0.
An atom is called negated if it leads with negation-as-failure.
Typical de nitions of a disjunctive datalog program, such as [6], allow negated atoms in the body.
In our work, negated atoms cannot occur in a transformed program that we consider, so we omit negation-as-failure from the de nitions.
Disjunctive datalog programs without negation-as-failure are often called positive programs.
The set of all ground instances of rules in P is denoted by ground(P ).
An interpretation M of P is a subset of ground atoms in the Herbrand base of P .
An interpretation M is called a model of P if (i) body(r)   M implies head(r)   M (cid:14)=   for each rule r   ground(P ), and (ii) all atoms from M with the equality predicate   yield a congruence relation, i.e. a relation that is re exive, symmetric, transitive, and T (a1, .
.
.
, ai, .
.
.
, an)   M and ai   bi   M imply T (a1, .
.
.
, bi, .
.
.
, an)   M for each predicate symbol T in P .
P is said to be satis able if it has a model.
Since SHIQ is a subset of  rst-order logic, SHIQ axioms can  rst be translated into logical formulas, then into clausal form.
The resulting clauses can be represented as disjunctive rules without negation-as-failure.
However, due to possible skolemization steps in the clausal form translation, the resulting rules may contain function symbols.
Standard logic program engines, however, may not terminate in the presence of function symbols.
To cope with this problem, Hustadt et al.
[12, 21] developed the KAON2 transformation method to get rid of function symbols without losing ABox consequences.
The method reduces a SHIQ ontology KB to a positive disjunctive datalog program DD(KB) =  (KBR, KBT )    (KBA)    (KB).
 (KBR, KBT ) is a set of disjunctive datalog rules computed from the intensional part of KB by translating SHIQ axioms into clauses, adding logical consequences, and translating clauses into disjunctive datalog rules.
 (KBA) is a set of facts translated from KBA, where each inequality assertion (of the form a (cid:14)  b) is translated into a ground constraint (of the from   a   b), and other assertions are directly translated into ground facts.
 (KB) is a set of facts of the form HU (a), HU (af ) and Sf (a, af ), which are introduced to remove function symbols and instantiated for each individual a occurring in KB and each function symbol f .
Theorem 1 ([21]).
For KB a SHIQ ontology, KB is unsatis able if and only if DD(KB) is unsatis able.
Given a possibly inconsistent SHIQ ontology KB in which some assertions are removable and assigned removal costs, our goal is to  nd a subset of removable assertions whose removal turns KB consistent and in which the sum of removal costs is minimum.
Such subset is called a minimum cost diagnosis, formally de ned below.
De nition 1.
Let KB be a possibly inconsistent SHIQ ontology and RKB   KBA a set of removable assertions such that each assertion     RKB is given a removal cost c( ) > 0.
Then, a subset of assertions R   RKB is called a diagnosis for KB w.r.t.
RKB if (KBR, KBT , KBA \ R) is consistent.
A diagnosis R is called a minimum cost diagnosis for KB w.r.t.
RKB if there is no diagnosis R for KB w.r.t.
 R c( ).
R is simply called RKB such that a diagnosis/minimum cost diagnosis if KB and RKB are clear from the context.
 R(cid:2) c( ) < (cid:2) (cid:2) (cid:3) We consider the time complexity for  nding a minimum cost diagnosis.
Complexity results in this paper refer to data complexity, i.e. the complexity measured as a function of the number of assertions in the ontology.
Theorem 2 shows that, unless P=NP, there is no polynomial time algorithm for  nding a minimum cost diagnosis for a DL-Lite ontology KB w.r.t.
KBA.
It implies that the problem of  nding minimum cost diagnoses for SHIQ ontologies is in general intractable.
Theorem 2.
Given a positive integer k and a possibly inconsistent DL-Lite ontology KB = (KBT , KBA) where each assertion     KBA is given a removal cost c( ) = 1, deciding if there is a diagnosis R for KB w.r.t.
KBA such that  R c( )   k is NP-hard w.r.t.
data complexity.
(cid:2)
   Proof.
Given an arbitrary instance I of the SAT problem, we transform it into an instance I of the given decision problem.
Let I be the formula f = C1   .
.
.
  Cm with m (cid:3) clauses and n boolean variables x1, .
.
.
, xn.
We construct I as follows.
(1) KBT consists of the following axioms:   (func S  T (cid:2)  S,  T   (cid:2)  S (func T (2) For each boolean variable xi in f , KBA contains a corresponding constant ai.
(3) For each clause Cj containing nj literals lj,1, .
.
.
, lj,nj whose corresponding constants in KBA, introduced in (2), are aj,1, .
.
.
, aj,nj respectively, KBA contains a corresponding constant cj for Cj and nj assertions U (aj,1, cj), .
.
.
, U (aj,nj , cj ), where U (aj,k, cj ) is T (aj,k, cj) if lj,k is positive, or S(aj,k, cj ) otherwise.
(4) Let k = j=1(nj   1).
(cid:2)m   ), , ).
Now we prove that f is satis able if and only if there is a diagnosis R for KB = (KBT , KBA) w.r.t.
KBA such that (cid:2) a R c(a)   k, i.e., |R|   k. ( ) Since f is satis able, for each clause Cj there is a literal lj,k assigned true.
We append to R all assertions in KBA of the form U (aj,p, cj ) (p (cid:14)= k), where U (aj,p, cj) is T (aj,p, cj ) if lj,p is positive, or S(aj,p, cj ) otherwise.
Clearly, R is a diagnosis for KB w.r.t.
KBA such that |R|   k. ( ) Suppose R is a diagnosis for KB w.r.t.
KBA such that |R|   k.
It is not hard to see that any set of assertions of the form U (aj,k, cj ) (U is either T or S) must have exactly nj   1 assertions in R and one in KBA \ R. To see that f is satis able, for each U (aj,k, cj)   KBA \ R (j = 1, .
.
.
, m), if U is T , we assign xj,k (i.e. the corresponding variable of aj,k in f ) true; otherwise we assign xj,k false.
The above (partial) assignment on {x1, .
.
.
, xn} is consistent and ensures lj,k = true for all j = 1, .
.
.
, m. Thus f is satis able.
Since the construction of KB is accomplished in PTIME and the SAT problem is NP-complete, and since KBT has a  xed size, this theorem follows.
As analyzed in related work, a method that computes minimum cost diagnoses based on minimal con ict sets is impractical, because it may require both exponential time and exponential space.
We thus consider methods that need not compute minimal con ict sets.
A na ve method is the black-box method, which searches minimum cost diagnoses over all subsets of removal assertions by applying a DL reasoner to check diagnoses.
However, the black-box method cannot compute a minimum cost diagnosis for a DL-Lite ontology in polynomial calls to a DL reasoner, otherwise a minimum cost diagnosis can be computed in PTIME w.r.t.
data complexity, contradicting Theorem 2.
In order to  nd a practical computational method, we consider transforming the input ontology KB into a positive program   such that for any subset S of RKB the set of removable assertions, ) = 1 | KB \ S is consistent if and only if     {assign(    ) = 0 |     RKB \ S} is satis able,     S}   {assign(    where   is a fresh ground atom corresponding to ground atom   in  , and assign( ) denotes the 0-1 truth value of  .
Then, a minimum cost diagnosis corresponds to a valuation of X such that ) is minimum and   is satis able, where X = {   X c( )   assign(      |     RKB}.
(cid:2)   To  nd such a valuation of X, we need to handle pseudo-i cixi   d boolean constraints (PB-constraints) of the form with constants ci, d   Z and variables xi   {0, 1}, or a linear (cid:2) (cid:2) i cixi with optimization function of the form minimize constants ci   Z and variables xi   {0, 1}, where Z denotes the integer domain.
The SAT problems with PB-constraints and linear optimization functions are well studied in the SAT community (cf.
http://www.cril.univ-artois.fr/PB07/).
A SAT problem with linear optimization functions can be translated into a set of SAT problems with PB-constraints.
A SAT problem with PB-constraints can be either solved by standard SAT solvers after translating PB-constraints to SAT clauses [5], or solved by extended SAT solvers that support PB-constraints natively (e.g., PUEBLO [28]).
Now, the remaining problems are how to transform a SHIQ ontology to the intended positive program and how to e ciently compute minimum cost diagnoses.
We address these problems in the following subsections.
Given a possibly inconsistent SHIQ ontology KB, we  rst employ the KAON2 transformation method [12, 21], described in Preliminaries, to reduce KB to a disjunctive datalog program DD(KB) =  (KBR, KBT )    (KBA)    (KB), but introduce a special treatment.
The original KAON2 transformation method allows equality atoms (of the form X   Y or a   b, where X, Y denote variables and a, b denote constants) to occur in rule bodies in DD(KB) while disallows inequality atoms (of the form X (cid:14)  Y or a (cid:14)  b) to occur in DD(KB).
To handle inequality assertions in a similar way as other assertions, we  rst move equality atoms (X   Y or a   b) in any rule body in DD(KB) to the corresponding rule head and replace them with inequality atoms (X (cid:14)  Y or a (cid:14)  b), then append to DD(KB) a constraint   X   Y, X (cid:14)  Y (written R(cid:5) ), so that  (KBA) is simpli ed to a direct translation from assertions in KBA to ground facts in DD(KB).
Having such treatment we simply denote  (KBA) as KBA.
The modi ed rules in DD(KB) are still safe due to the restricted form of the original rules that have equality atoms in the body.
In essence, our treatment views an inequality atom as an ordinary one and does not impact the satis ability of DD(KB).
Then, we convert DD(KB) to a repair program R(KB) de ned below.
Intuitively, the decision atom   is introduced to weaken KB, so that   = false) implies that   is re-= true (resp.
  moved from (resp.
kept in) KB.
Note that decision atoms in R(KB) are treated as nullary ground atoms.
      De nition 2.
For KB a possibly inconsistent SHIQ ontology and RKB   KBA a set of removable assertions such that each assertion     RKB is given a removal cost c( ) >
 a disjunctive datalog program converted from DD(KB) as follows: for each assertion     RKB, we introduce a corresponding decision atom   ) = c( ), then replace the ground fact   in DD(KB) with     .
We simply call R(KB) a repair program if RKB is clear from the context.
and give it a cost c(      Example 2.
Let A, E, H, P , S, T , me and pa abbreviate Artif icer, Engineer, Human, P rof essor, Student, T eacher, mentor and parent respectively.
Given a SHIQ ontology KB = ( , KBT , KBA), where KBT = {S (cid:2) 1 me (cid:4)  me.P (cid:4) H, H (cid:2)  pa.H, P (cid:2) E,  me.E (cid:2)  A, E (cid:2)  T} and KBA = {S(s1), S(s2), me(s1, t1), me(s1, t2), A(s2), T (t1), T (t2), T (p1), E(p2), pa(s1, p1), pa(s2, p1), t1 (cid:14)  t2, p1   p2}, and a set of removable assertions RKB =
 that c( ) = 1 for each assertion     RKB, we construct the repair program R(KB) as follows.
Y1   Y2   S(X), me(X, Y1), me(X, Y2).
P (Xf )   S(X), Sf (X, Xf ).
First, by applying the KAON2 transformation method with our special treatment, we reduce KB to DD(KB) =  (KBR, KBT )   {R(cid:5) }   KBA    (KB), where  (KB) = {Sf (s1, s1f ), Sf (s2, s2f ), Sf (t1, t1f ), Sf (t2, t2f ), Sf (p1, p1f )} and  (KBR, KBT ) = {R1, .
.
.
, R9} as given below.
R3: me(X, Xf )   S(X), Sf (X, Xf ).
R5: H(Y )   H(X), pa(X, Y ).
R7:   A(X), me(X, Y ), E(Y ).
Then, by introducing decision atoms and converting ground facts in DD(KB), we obtain R(KB) = {R1, .
.
.
, R9, R(cid:5) }   (KB)   {S(s1), me(s1, t1), me(s1, t2), T (p1), pa(s1, p1), pa(s2, p1), S(s2)   S(s2) , T (t1)   T (t1)   , T (t2)   T (t2) , (t1 (cid:14)  t2)   (t1 (cid:14)  t2)   ,  }.
(p1   p2)   (p1   p2) , E(p2)   E(p2) , A(s2)   A(s2)         There exists a correspondence between minimum cost diagnoses for KB w.r.t.
RKB and X-MC models of R(KB),   |     RKB} (see Theorem 3).
A model where X = {  M of a positive program P is called an X-MC model of P  M(cid:2) X c( ) < if there is no model M (cid:2)  M X c( ), where X is a set of ground atoms and c is a of P such that (cid:2) (cid:3) prede ned cost function over X.
  |     RKB}.
Theorem 3.
Let KB be a SHIQ ontology, RKB   KBA a set of removable assertions such that each assertion     RKB is given a removal cost c( ) > 0, R(KB) a repair program of KB w.r.t.
RKB , and X = {  (Soundness) For each X-MC model M of R(KB), {  |     M} is a minimum cost diagnosis for KB w.r.t.
RKB;   (Completeness) For each minimum cost diagnosis R for KB w.r.t.
RKB, there exists an X-MC model M of R(KB) such that R = {  |   Proof sketch.
(Soundness) Let M be an X-MC model  |    R}.
    M} and M of R(KB), R = {  |   is a model of DD(KB)\R.
By The-(cid:3) It can be shown that M orem 1, R is diagnosis of KB w.r.t.
RKB .
Further, R must be a minimum cost diagnoses, otherwise it can be shown that ) < there exists a model M (cid:2) of R(KB) s.t.
= M \ { 
  M(cid:2)(cid:2) X c(   M X c(  (Completeness) Let R be a minimum cost diagnosis for KB w.r.t.
RKB.
By Theorem 1, DD(KB) \ R is satis able (cid:3) and thus has a model, say M .
It can be shown that M = M   {    |     R} is a model of R(KB).
Further, M (cid:3) must be an X-MC model of R(KB), otherwise it can be for KB w.r.t.
RKB shown that there exists a diagnosis R s.t.
 R(cid:2) c( ) <  R c( ).
(cid:2) (cid:2) (cid:2)     ).
(cid:3) (cid:3) (cid:3)(cid:3) By Theorem 3, the problem of  nding minimum cost diagnoses for KB w.r.t.
RKB is reduced to the problem of computing X-MC models of R(KB), which can be realized by applying SAT solvers.
However, SAT solvers take a positive propositional program as input and do not distinguish equality atoms from other atoms.
To treat the equality predicate  , which is interpreted as a congruence relation, as an ordinary predicate, we use a well-known transformation from [8].
For a disjunctive datalog program P , let P  denote the program consisting of the rules stating that the equality predicate is re exive, symmetric and transitive, and the replacement rules given below, instantiated for each predicate T in P (excluding  ) and each position i.
Note that the re exive rule is not safe and is instead represented as a set of ground facts of the form a   a, instantiated for each constant a in P .
Then, appending P  to P allows to treat   as an ordinary predicate.
T (X1, .
.
.
, Yi, .
.
.
, Xn)   Xi   Yi, T (X1, .
.
.
, Xi, .
.
.
, Xn).
For the input issue, we need to ground R(KB) before applying SAT solvers.
A well-known grounding technique is intelligent grounding (IG) [7], which only applies to equality-free disjunctive datalog programs.
That is, if the equality predicate   is present in a disjunctive datalog program P , we must append P  to P before grounding P using the IG technique.
The IG technique has been implemented in a disjunctive datalog engine DLV [18], but the current implementation cannot handle large disjunctive datalog programs due to memory limitation1, especially when the equality predicate is present.
On the other hand, current implementations of SAT solvers lack scalability for large propositional programs.
To address these problems, we develop two disk-based algorithms for grounding R(KB) to  (KB) and for partitioning  (KB) to disjoint subprograms respectively, so that the computation of minimum cost diagnoses can be separately performed over each subprogram.
Algorithm 1 is our algorithm for grounding a repair program P .
By Mdef we denote the unique minimal model of the de nite fragment of P , i.e. {R   P | |head(R)| = 1}.
C is actually the set of congruence classes {C1, .
.
.
, Cm} occurring in P , where Ci = {b | a   b   Mdef} for an arbitrary constant a occurring in some equality atom in Mdef that is not of the form a   a. fc(a,C) denotes the congruence class in C that contains constant a. minc(C) denotes the constant a   C having the smallest value in {occ(a) | a   C}, where occ(a) is the occurrence order of a in P .
Ddef is actually a set of non-equality atoms in Mdef such that for each non-equality atom T (a1, .
.
.
, ak)   Mdef , there exists a unique ground atom T (b1, .
.
.
, bk)   Ddef such that for each i = 1, .
.
.
, k, ai and bi are either the same or together in some C   C. D is the set of ground atoms occurring in the grounded program  .
Let S and S be two sets of ground atoms.
S  denotes the subset of S consisting of all equality atoms in S; S\  denotes S \ S .
For a rule R, the function GetSubstitutes(R, S, (cid:3)
 ) returns the set of all ground substitutes   such that body(R )   S, head(R )\    S =   and head(R )  does not contain equality atoms of the form a   a.
The function Rewrite(S, C) rewrites all constants a in S such that fc(a,C) exists to minc(fc(a,C)), and returns the modi ed S.
(cid:3) (cid:3) The algorithm consists of three steps.
Step 1 (lines 1 13) computes Mdef in a standard iterative manner, but represents Mdef as Ddef and C. Step 2 (lines 14 16) rewrites the constants occurring in disjunctive ground facts (of the form         ) in P , because some constants occurring in  
 (http://www.mat.unical.it/terracina/dlvdb/), does not work with DBs if the input program has disjunctions.
step 1 and step 2, all constants in a congruence class are replaced with a same constant, so as to reduce the number of instantiated rules in step 3.
Step 3 (lines 17 26) grounds P +, i.e. P   P  excluding the de nite ground facts, in a standard iterative manner based on Mdef .
Each instantiated rule r such that head(r)   Mdef (cid:14)=   is ignored (line
 a (cid:14)  b   Ddef , the equality atom a   b in an instantiated rule head is not appended to D (line 24), because it cannot occur in any model of P .
The ground atoms in Mdef are removed from the body of any instantiated rule (lines 25 
 function GetSubstitutes can be realized by applying a SQL engine and its results can be stored in disk, so the algorithm In what follows, by  (KB) we denote the is disk-based.
grounded repair program returned by Ground(R(KB)).
Algorithm 1.
Ground(P ) Input: A repair program P .
Output: A set C of sets of constants and a positive propositional def def do program  .
C :=  ; Ddef :=  ; D(cid:3) def := { }; // to enforce Ddef (cid:4)= D(cid:3) that are not together in some C   C then

 def := Ddef ; D(cid:3)
 for each rule R   P s.t.
|head(R)| = 1 do
   := GetSubstitutes(R, Ddef , Ddef );
 for each   sequentially retrieved from   do


 Ddef := Rewrite(Ddef , C); // executed once for   Ddef := Ddef   head(R )\ ; if head(R )  = {a   b} for some constants a and b if fc(a, C) does not exist then Set fc(a, C) as {a}; if fc(b, C) does not exist then Set fc(b, C) as {b}; C := fc(a, C)   fc(b, C); C := (C \ {fc(a, C), fc(b, C)})   {C};




 14. for each disjunctive ground fact         ) s.t.
fc(a, C) exists do
 ) to minc(fc(a, C));









   := GetSubstitutes(R, D, Ddef ); for each   sequentially retrieved from   do D(cid:3) for each rule R   P + do D := D   head(R )\    {a   b   head(R )  | a (cid:4)  B := body(R ) \ (Ddef   {a   a | a occurs in R });   :=     {(cid:3) head(R )   (cid:4) for each constant a in   (or   Rewrite a in   (or   b (cid:4)  Ddef}; in P do :=  ;
    


 Example 3.
Continue with Example 2.
We now demonstrate how Ground(R(KB)) works.
In step 1, we compute the unique minimal model Mdef of R(KB)def in an iterative manner, obtaining C = {{t1, t2, s1f}} and Ddef = {S(s1), me(s1, t1), T (p1), pa(s1, p1), pa(s2, p1), Sf (s1, t1), P (t1), H(s1), H(p1), E(t1), Sf (s2, s2f ), Sf (t1, t1f ), Sf (t1, t2f ), Sf (p1, p1f )}.
In step 2, according to C, we replace the set of disjunctive ground facts in R(KB) with {S(s2)   S(s2)   , A(s2)   A(s2) , T (t1)   T (t1) , (t1 (cid:14)    t1)   (t1 (cid:14)  t1) , (p1   p2)   (p1   p2)   In step 3, we ground R(KB)   R(KB)  (excluding the de nite ground , E(p2)   E(p2)  }.
    .
  facts) in an iterative manner, obtaining a propositional program  (KB) = {r1, .
.
.
, r22}, where r14 is instantiated from   X   Y, X (cid:14)  Y (i.e. R(cid:5) ), r15, .
.
.
, r20 are instantiated from R(KB) .
Note that for instantiating a rule that contains X   Y in the body, we only consider all ground substitutes   such that occ(X )   occ(Y  ), where occ(a) is the occurrence order of constant a in R(KB).
r1 : S(s2)   S(s2) r3 : (t1 (cid:14)  t1)   (t1 (cid:14)  t1)   .
r5 : (p1   p2)   (P1 (cid:14)  p2)   r7 : P (s2f )   S(s2).
r9 : H(s2)   S(s2).
r11 :  A(s2), me(s2, s2f ), E(s2f ).
r13 :  A(s2), S(s2).
r15 : p2   p1   p1   p2.
r17 : E(p2)   p1   p2, E(p1).
r19 : E(p1)   p1   p2, E(p2).
r21 :  E(p1).
r2 : A(s2)   A(s2)   .
r4 : T (t1)   T (t1)   .
r6 : E(p2)   E(p2)   r8 : me(s2, s2f )   S(s2).
r10 : E(s2f )   P (s2f ).
r12 :  T (t1).
r14 :  t1 (cid:14)  t1.
r16 : T (p2)   p1   p2.
r18 : pa(s1, p2)   p1   p2.
r20 : pa(s2, p2)   p1   p2.
r22 :  T (p2), E(p2).
.
.
Algorithm 2.
Partition( , X) Input: A positive propositional program   and a set X of ground atoms occurring in  .
Set map( ) as 0 for all ground atoms   occurring in  ; Output: A set of disjoint subprograms of  .
merged := false; for each rule r sequentially retrieved from   s.t.
head(r) =   or map( ) > 0 for all     head(r) \ X do repeat for each     head(r)   body(r) s.t.
map( ) = 0 do if |map(r)| > 1 then k := k + 1; map( ) := k; merged := true; minid := min(map(r)); for each     head(r)   body(r) do map( ) := minid;




 11. until not merged; 12. for i = 1, .
.
.
, k do

  i := {r     |     head(r)   body(r) : map( ) = i}; Algorithm 2 is our algorithm for partitioning a positive propositional program   based on a set X of ground atoms occurring in  .
The basic idea is to  lter out rules that have no impact on M   X when constructing an X-MC model M of   and put together remaining rules that have common ground atoms to form disjoint subprograms.
In the algorithm, each ground atom   occurring in   is mapped to a partition identi er map( ).
For a rule r, we use map(r) to denote {map( ) |     head(r)   body(r)}.
To simplify explanation, we call a rule r     ready if head(r) =   or map( ) > 0 for all     head(r) \ X.
Before a ground atom is detected in some ready rule, it is mapped to 0 (line 1).
To process ready rules as early as possible, constraints (which are ready rules) are moved in front of other rules in   (line
 tive manner until {map(r) | r    } reaches a  xpoint (lines
 initially mapped to a unique partition identifer (lines 6 7).
All ground atoms in a ready rule r are mapped to the same partition identi er (lines 8 10).
After the loop is  nished, all ready rules in   mapped to the same partition identi er are put together, yielding a set of nonempty subprograms { i}1 i n (lines 12 13).
is at most | |, because the mapping adjustment (lines 9 10) ensures that in each iteration, a ready rule rm having the smallest value of min(map(r)) among {r     | r is ready and |map(r)| > 1} must reach a state that |map(rm)| = 1 and that map(rm) is unchanged in subsequent iterations.
Furthermore,  0 =  \(cid:5)n i=1  i is the intended set of  ltered rules (see Lemma 1);  i and  j contain no common ground atoms for all 1   i < j   n. Since   is sequentially accessed in each iteration, the algorithm is also disk-based.
(cid:3) r 0 (cid:5) P, M = M   (cid:5) (cid:3)   X.
Proof.
Let M0 = Lemma 1.
Let P be the set of subprograms returned by Partition( , X) and  0 =   \ (cid:5) P. For any X-MC {    head(r) |   (cid:14)  model M of X, map( ) = 0} is an X-MC model of   such that M   X =
 {    head(r) |   (cid:14)  X, map( ) =

 satis es every rule in  0.
Moreover, since map( ) > 0 for (cid:5) P, M0   M =   and every ground atom   occurring in (cid:5) P as M .
It follows that thus M still satis es every rule in is an X-MC
 model of   such that M   X = M (cid:3)   X.
is a model of  .
Since M0   X =  , M r 0 (cid:5) (cid:3) (cid:3) (cid:3) (cid:3)    
 Example 4.
Continue with Example 3.
Let X (cid:4) be the set in  (KB).
We now demon-of ground atoms of the form   strate how Partition( (KB), X (cid:4)) works.
We  rst move r11, .
.
.
, r14, r21, r22 in front of other rules in  (KB), then map each ground atom in   to a partition identi er.
In the  rst iteration for processing rules r    , map(r) is set as follows (for every ground atom  ,  j:k denotes map( ) = j before processing r at line 8 in Algorithm 2, and map( ) = k after the  rst iteration).
r11 :  A(s2)1:1, me(s2, s2f )2:1, E(s2f )3:1.
r12 :  T (t1)4:4.
r14 :  (t1 (cid:14)  t1)6:6.
r13 :  A(s2)1:1, S(s2)5:1.
r22 :  T (p2)8:7, E(p2)9:7.
r21 :  E(p1)7:7.
r2 : A(s2)1:1   A(s2) r1 : S(s2)1:1   S(s2)  
 r3 : (t1 (cid:14)  t1)6:6   (t1 (cid:14)  t1) r4 : T (t1)4:4   T (t1)    


 r5 : (p1   p2)14:7   (p1   p2)    
 r7 : P (s2f )0:1   S(s2)1:1.
r8 : me(s2, s2f )1:1   S(s2)1:1.
r9 : H(s2)0:0   S(s2)1:1.
r10 : E(s2f )1:1   P (s2f )17:1.
r15 : (p2   p1)0:0   (p1   p2)14:7.
r16 : T (p2)8:7   (p1   p2)14:7.
r17 : E(p2)8:7   (p1   p2)8:7, E(p1)7:7.
r18 : pa(s1, p2)0:0   (p1   p2)7:7.
r19 : E(p1)7:7   (p1   p2)7:7, E(p2)7:7.
r20 : pa(s2, p2)0:0   (p1   p2)7:7.
In the second iteration, it is detected that |map(r)| = 1 for all ready rules r    , so the loop is  nished.
Finally we obtain four disjoint subprograms from the resulting mapping:  1 = {r11, r13, r1, r2, r7, r8, r10},  2 = {r12, r4},  3 = {r14, r3} and  4 = {r21, r22, r5, r6, r16, r17, r19}.
  In what follows, we call a ground atom of the form   a translated decision atom.
Let C be the set of congruence classes returned by Ground(R(KB)), and { i}1 i n the set of subprograms returned by Partition( (KB), X (cid:4)), where X (cid:4) is the set of translated decision atoms occurring in  (KB).
We intend to compute X-MC models of R(KB) over each of { i}1 i n, where X is the set of decision atoms occurring in R(KB).
However, some decision atoms are re-i=1  i, because all constants in placed with other atoms in a congruence class in C are replaced with a same constant.
(cid:5)n (cid:3) (cid:3) (cid:3)     (cid:2) ) = Let X (cid:5)n i=1  i.
X ), where bi
 (T (a1, .
.
.
, ak) T (b1,...,bk) X,b1 .=C a1,...,bk be the set of translated decision atoms occurring in is said to be soundly converted from X w.r.t.
C if each ground atom T (a1, .
.
.
, ak) has been given a (cid:3) .=C ak cost c .
=C ai means that constants bi c(T (b1, .
.
.
, bk) and ai are the same or together in some C   C. Such conver-  sion is reasonable because all decision atoms T (b1, .
.
.
, bk)   X such that b1   .
=C ak for some T (a1, .
.
.
, ak)
 must be present or absent together in every model of R(KB).
Moreover, given a subset S of X , we de ne a decoding of S w.r.t.
X and C, written d(S, X,C), as {T (b1, .
.
.
, bk)     X | T (a1, .
.
.
, ak) =C ak}.
Then, .
a minimum cost diagnosis of KB corresponds to a disjoint union of models in each subprogram (see Theorem 4).
.
=C a1, .
.
.
, bk .
=C a1, .
.
.
, bk     S, b1 (cid:3) (cid:3) (cid:3) (cid:3)             (cid:5)4 (T (t1) , A(s2) Example 5.
Continue with Example 4.
Let X be the set of decision atoms in R(KB).
In i=1  i, the set of ground atoms soundly converted from X w.r.t.
C = {{t1, t2, s1f}} = {S(s2) , (t1 (cid:14)  t1) , (p1   p2)     is X , T (t1) ,  }, where each ground atom  
 (cid:3) E(p2) is given a cost (cid:3)   (cid:3) c ) = 2.
Let Xi (i = 1, .
.
.
, 4) ) = 1 except that c (  be the subsets of X that occur in  i.
It is easy to see that  1 has two X1-MC models M1,1 = {S(s2) , A(s2)} and , P (s2f ), me(s2, s2f ), E(s2f )};  2 M1,2 = {S(s2), A(s2)  };  3 has a unique has a unique X2-MC model M2 = {T (t1) X3-MC model M3 = {(t1 (cid:14)  t1)  };  4 has two X4-MC models M4,1 = {(p1   p2) , E(p2)} and M4,2 = {E(p2)   , p1   p2, T (p2)}.
Hence, d(M1,1   X1, X,C) = {S(s2)  };  }; d(M2   X2, X, C) = {T (t1) d(M1,2   X1, X, C) = {A(s2)    }; d(M4,1 X4, X,C) T (t2) = {(p1   p2)  }.
By Theorem 4, we obtain four minimum cost diagnoses for KB w.r.t.
RKB : {S(s2), T (t1), T (t2), t1 (cid:14)  t2, p1   p2}, {A(s2), T (t1), T (t2), t1 (cid:14)  t2, p1   p2}, {S(s2), T (t1), T (t2), t1 (cid:14)  t2, E(p2)} and {A(s2), T (t1), T (t2), t1 (cid:14)  t2, E(p2)}.
 }; d(M4,2   X4, X, C) = {E(p2)  }; d(M3 X3, X,C) = {(t1 (cid:14)  t2)   (cid:3) (cid:3) (cid:5)n that occur in  1, .
.
.
,  n respectively.
i=1 d(Mi   Xi, X,C)} is a minimum cost diag-Theorem 4.
For KB a SHIQ ontology and RKB   KBA a set of removable assertions such that each assertion     RKB is given a removal cost c( ) > 0, suppose Ground(R(KB)) returns (C,  (KB)) and Partition( (KB), X (cid:4)) returns { i}1 i n, where X (cid:4) is the set of translated decision atoms occurring in  (KB).
Let X be the set of trans-i=1  i which is soundly lated decision atoms occurring in   |     RKB}, and X1, .
.
.
, Xn be converted from X = {  the subsets of X (Soundness) For each Xi-MC model Mi of  i (i = 1, .
.
.
, n),     (cid:5)n {  |   nosis for KB w.r.t.
RKB; (Completeness) For each minimum cost diagnosis R for KB w.r.t.
RKB, there exists an Xi-MC model Mi of  i (i = i=1 d(Mi   Xi, X,C)}.
Proof sketch.
(Soundness) For i = 1, .
.
.
, n, let Bi be the set of ground atoms occurring in  i and Mi an Xi-MC model of  i.
Let  0 =  (KB) \ (cid:5)n i=1  i and M = {    head(r) |   (cid:14)  X (cid:4)   (cid:5)n (cid:5) i=1(Mi   Bi).
r 0 (cid:3) Let M be the set of ground atoms derived by applying all rules in R(KB)  over M   {a   b | a and b are together in some C   C}, and M + = M   M .
It can be seen that (cid:5)n i=1 d(Mi   Xi, X,C) = M +   X.
It can further be shown that M + is an X-MC model of R(KB).
By Theorem 3,     M +} is a mini{ |  mum cost diagnosis for KB w.r.t.
RKB.
i=1 d(Mi   Xi, X, C)} = { |  i=1 Bi}   (cid:5)n     (cid:5)n     (cid:5)n (cid:3)
 KB w.r.t.
RKB .
By Theorem 3, there exists an X-MC     M}.
Let M model M of R(KB) s.t.
R = { |  be a set of ground atoms converted from M by rewriting each constant a in M s.t.
fc(a,C) exists to minc(fc(a,C)).
It (cid:3)   Bi is an Xi-MC model of  i can be shown that Mi = M     (cid:5)n (i = 1, .
.
.
, n) s.t.
R = {  |   i=1 d(Mi Xi, X,C)}.
(cid:3) By Theorem 4, the problem of  nding minimum cost diagnoses for KB w.r.t.
RKB is reduced to n subproblems, each of which computes Xi-MC models of  i (i = 1, .
.
.
, n).
We consider computing Xi-MC models of  i by applying SAT solvers that support PB-constraints.
We assume that the cost of each atom in Xi has been scaled to a positive integer polynomial in |X| the total number of removable assertions.
Then, the  rst Xi-MC model of  i can be computed by a bi-(cid:2) (cid:3)  Xi c nary search (within range [0, ( )]) for the minimum value vmin such that  i   {(cid:2) ( )   assign( )   vmin} (cid:3)  Xi c (cid:2) ( )) = O(log2 |X|) calls (cid:3)  Xi c is satis able, taking O(log2 to a SAT solver.
Let M = {M   Xi | M is a previously computed Xi-MC model of  i}.
Then a next Xi-MC model M of  i, such that M   Xi (cid:14)= S for every S   M, can be computed as a model of  i   {(cid:2) ( )   assign( )   vmin} {  (cid:4)  S   | S   M}, by calling a SAT solver once.
(cid:3)  Xi c Consider the time complexity for computing minimum cost diagnoses.
Under the data complexity assumption, the number of non-ground rules in R(KB) and the number of di erent variables in each rule in R(KB) are bounded by constants.
Thus the number of rules in  (KB) is polynomial in |KBA|.
It follows that Ground(R(KB)) is executed in PTIME.
Let X (cid:4) be the set of translated decision atoms occurring in  (KB).
Partition( (KB), X (cid:4)) commits at most | (KB)| iterations over  (KB), so it is executed in PTIME too.
Let n be the number of removable assertions in KB and { i}1 i m be the set of propositional programs returned by Partition( (KB), X (cid:4)).
Note that the SAT problem with a PB-constraint is NP-complete.
Since  i and  j have no common ground atoms for all 1   i < j   m, m calls to a SAT solver over  1, .
.
.
,  m respectively amount to one call to an NP oracle over i=1  i.
Under the assumption that each removal cost has been scaled to a positive integer polynomial in n, it follows from Theorem 4 that, the  rst minimum cost diagnosis is computed in O(log2 n) calls to an NP oracle, and a next one, in one more call.
(cid:5)m

 We implemented the proposed method for computing minimum cost diagnoses in GNU C++.
In the implementation, MySQL is used as the back-end SQL engine; ABox assertions and new ground atoms derived in the grounding process are maintained in a SQL database; All ground substitutes of rules, retrieved via SQL statements, are maintained in disk  les; The SAT solver MiniSat+ [5], which supports PB-constraints and linear optimization functions by internally translating them into SAT clauses, is applied to compute X-MC models.
All the experiments were conducted on a 3.2GHz Pentium 4 CPU 2GB RAM PC running Windows XP and Cygwin.
Semintec2 is an ontology about  nancial services, created
 http://www.cs.put.poznan.pl/alawrynowicz/ Table 1: The complexity of test ontologies

















 NA Nr Features











   Note: S stands for Semintec.
H stands for HumanCyc
 stands for LUBM1+.
L10 stands for LUBM10+.
NC is the number of concept names.
NR is the number of role names.
NI is the number of individuals.
NA is the number of ABox assertions stored in MySQL databases.
Nr is the number of rules transformed from the intensional part.
The features show how many special transformed rules: EQn means there are n equality rules (i.e. rules containing equality atoms); DSn means there are n disjunctive rules.
in the SEMINTEC project at the University of Poznan.
Its intensional part contains functional roles and disjointness constraints.
HumanCyc3 is an ontology on human metabolic pathways and human genome, created by the SRI International corporation.
Since its intensional part contains nomimals and concrete domain speci cations (e.g., a role range is of some datatype, a concrete role is functional, etc.)
that cannot be handled by our method, we converted nominals to new atomic concepts and deleted concrete domain speci cations.
The weakened intensional part still contains disjunctions, functional roles/restrictions and disjointness constraints.
LUBM4 is a benchmark ontology developed at the Lehigh University [9].
Since its intensional part has no functional roles, number restrictions or disjointness constraints, which implies that it cannot be inconsistent, we extended it by adding a functional role headOf and an inverse functional role isTaughtBy, where headOf (resp.
isTaughtBy) is also de ned as an inverse role of isHeadOf (resp.
teacherOf), and adding disjointness constraints X (cid:2)  N onX for each existing concept name X, where N onX is a new concept name.
LUBM comes with an ABox generator.
Let LUBMn denote the ontology obtained from the generator by setting the number of universities to n.
Before testing the proposed method, the intensional parts of the above ontologies were o ine transformed to datalog programs using the KAON2 DL reasoner5.
Each transformation was performed in less than one second.
Moreover, ABox assertions of the above ontologies were stored into MySQL databases, where duplicated ABox assertions were removed.
Table 1 summarizes the complexity of the test on-tologies and the datalog programs transformed from their denotes the weakened intensional parts, where HumanCyc HumanCyc, and LUBMn+ denotes the extended LUBMn.
We developed a tool, called Injector, to inject a given number of con icts into an ontology.
Given a consistent ontology KB and a number ncnf of con icts to be injected, Injector  rst deduces into KB all atomic concept assertions that are consequences of KB, then injects ncnf con icts one by one.
Let SF R denote the set of functional/inverse func-  semintec.htm


 http://humancyc.org/ http://swat.cse.lehigh.edu/projects/lubm/ http://kaon2.semanticweb.org/
 disjoint concepts.
To inject a con ict, Injector randomly selects an entity in SF R SDC.
In case an functional role R is selected, if there exist role assertions over R in KB, Injector randomly selects one, say R(a, b), and appends R(a, c) and b (cid:14)  c to KB, where c is a new individual; otherwise, Injector appends R(a, b), R(a, c) and b (cid:14)  c to KB, where a, b, c are new individuals.
In case an inverse functional role R is selected, Injector treats it as R .
In case an atomic concept C is selected, if there exist concept assertions over C in KB, Injector randomly selects one, say C(a), and appends D(a) to KB for a randomly selected disjoint concept D of C; otherwise, Injector appends C(a) and D(a) to KB, where a is a new individual and D a randomly selected disjoint concept of C. Injector was implemented in JAVA, using the Pellet [29] API to deduce all atomic concept assertions that are consequences of a consistent ontology.
 
 We injected di erent number of con icts to the four test ontologies using Injector, obtaining a set of inconsistent ontologies.
We consider the hardest case where all assertions in an obtained ontology are assumed removable.
We assume that each assertion is given a removal cost 1.
In order to make the implemented system terminate in an acceptable time, we set a time limit of 20 minutes for one call to MiniSat+.
The test results are reported in Table 2.
In each block, the  rst row lists ncnf , i.e. the number of injected con icts; the second row lists the total execution time for computing the  rst minimum cost diagnosis, starting from transform, the ing the input ontology.
For Semintec and HumanCyc implemented system cannot handle more injected con icts in our test environment, because when ncnf = 140 for Sem-), some call to MiniSat+ intec (or ncnf = 60 for HumanCyc exceeds the time limit.
In contrast, the implemented system scales well on LUBM1+/LUBM10+ ontologies with increasing number (from 1000) of con icts.
    We also collected runtime statistics on the partitioning process.
Let KB be an inconsistent ontology reported in Table 2.
As can be seen, the number of rules in each grounded repair program  (KB) is up to millions.
In addition, the number of decision atoms in  (KB) is at least in thousands.
We experimentally veri ed that any  (KB), without being partitioned, cannot be handled by MiniSat+ because the execution exceeds the time or memory limit.
This shows the importance of the partitioning process.
Other statistics show the e ectiveness of the partition-| (KB)| , is at ing process.
The percentage of  ltered rules, least 11% for all reported ontologies (esp., at least 57% for LUBM10+ ontologies).
The number of disjoint subprograms of  (KB) (i.e. the number of partitions), #{ i}, increases when the number of con icts increases.
This shows that the partitioning process improves the scalability.
Table 2 also reports the maximum number of ground rules in each partition, max(|{ i}|), and the maximum number of translated decision atoms in each partition, max(|{Xi}|).
It can be seen that the total execution time is roughly dominated by max(|{ i}|) and max(|{Xi}|).
For Semintec and , since max(|{Xi}|) is up to tens of thousands, HumanCyc the execution of MiniSat+ over the largest partition quickly exceeds the time limit when the number of con icts increases (as max(|{ i}|) increases too).
In contrast, for LUBM1+   Table 2: Test results against di erent number of con icts ncnf Semintec ncnf Time (sec)


 #{ i} max({| i|}) max({|Xi|}) ncnf Time (sec)


 #{ i} max({| i|}) max({|Xi|}) ncnf Time (sec)


 #{ i} max({| i|}) max({|Xi|})








































   HumanCyc






















































































 ncnf Time (sec)


 #{ i}





 max({| i|})

 max({|Xi|})
 Note: | (KB)| is the number of rules in the grounded repair | (KB)| is the percentage of rules  ltered program  (KB).
out in our partitioning algorithm.
#{ i} is the number of partitions.
max({| i|}) is the maximum number of ground rules in each partition.
max({|Xi|}) is the maximum number of translated decision atoms in each partition.
and LUBM10+, since max(|{ i}|) or max(|{Xi}|) is stable around a relatively small value, the total execution time increases smoothly when the number of con icts increases.
We can conclude that the performance of our method depends on the e ectiveness of the partitioning process.
As for what in uences such e ectiveness when the number of assertions and the number of con icts are  xed, we can see from Table 1 and Table 2 that, equality rules have a stronger impact than normal rules; further, disjunctive rules have a stronger impact than equality rules.
Hence, we believe that our method can handle any real (populated) ontology that has up to millions of assertions together with a moderately complex intensional part, which can be transformed to up to hundreds of datalog rules with a few disjunctive rules and equality rules.
A DL-based ontology may become inconsistent after it is populated.
In this paper, we proposed a solution to repair the populated ontology by deleting assertions in a minimum cost diagnosis.
We  rst showed the intractability of  nding a minimum cost diagnosis, then presented an exact method for computing minimum cost diagnoses for SHIQ ontolo-gies.
The method transforms a SHIQ ontology to a set of disjoint propositional programs in PTIME w.r.t.
data complexity, thus reducing the original problem into a set of independent subproblems.
Each such subproblem computes an X-MC model and is solvable by applying SAT solvers.
We experimentally showed that the method can handle moderately complex ontologies with over thousands of assertions, where all assertions can be assumed removable.
Especially, the method scales well on the extended LUBM ontologies with increasing number (from 1000) of con icts.
For future work, we plan to enhance our method to cope with concrete domain speci cations, seek feasible approaches to handling nomimals, and work on tractable approximate methods for computing minimum cost diagnoses.
