XML is an important standard format for data storage and exchange over the Internet.
As a result, how to e -ciently process queries over XML databases attracts lots of research interests [15].
Existing works on XML query processing mainly focus on how to e ciently match the query pattern to XML document, which is considered as a core operation to process queries in most standard XML query languages (e.g.
XPath [2] and XQuery [5]).
As more and more business data are represented in XML format, analytical queries involving grouping and aggregate operations have become more popular.
To process an analytical query Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
with grouping, existing pattern matching techniques are no longer e ective.
A new technique is required to handle the grouping operation in queries.
Similar to relational databases, most analytical queries over XML documents contain a main operator group-by and a set of aggregate functions such as max( ), min( ), sum( ), count( ), avg( ), etc.
In most XML query languages, aggregate functions are syntactically supported; however, the shortcoming is the lack of explicit support for grouping.
E.g.
XQuery 1.0 is a widely adopted version by most XQuery engines, however, grouping in XQuery 1.0 can only be expressed implicitly using nesting.
This nested expression for grouping can be neither well understood by users, nor easily detected by query optimizer, as pointed out by [4].
There are many e orts [6, 3, 18] on extending the expressive power for XQuery to support grouping, until W3C publishes the latest version of XQuery, XQuery 1.1 [11], to introduce a new construct to explicitly express grouping in FLWOR expression.
For example, consider the bookstore document shown in Fig. 1, and a query to  nd the average book price for each publisher in each year.
This query can be expressed in XQuery 1.1 as follows: FOR $p IN distinct-values(doc( bookstore.xml )//book/publisher), $y IN distinct-values(doc( bookstore.xml )//book/year), LET $pr := doc( bookstore.xml )//book[publisher=$p and year=$y]/price GROUP BY $p, $y ORDER BY $p, $y
 <book publisher= {$p}  year= {$y} > <average price>{avg($pr)}</average price> </book> Although the work of XQuery 1.1 has just started, it re ects the importance of grouping operations in XML queries.
As a result, how to e ciently process XML queries with grouping becomes a new research direction.
Since RDBMS is the dominant model for structured data, in the early stage there are many works [29, 28, 25] on storing and querying XML data using RDBMS.
In these relational approaches, they normally shred XML documents into tables and convert XML queries into SQL to query the database.
This sort of approaches can handle grouping in XML queries with the group-by function in SQL.
However, SQL has di culty supporting multilevel (nested) grouping, which often appears in analytical XML queries.
Also the primeval drawbacks of relational approaches in query structural search, such as the ine ciency to answer  // axis queries over XML document recent work [14] proposed an algorithm to compute group-by queries natively over XML document.
They scan the document for each query and prune out irrelevant nodes.
For the relevant nodes, they merge and count the analytical attributes for each group so that aggregate function can be easily performed.The major problem is that their approach is only suitable for queries with simple predicate.
They  nd the relevant nodes in documents by scanning the document for each query.
However, if a query contains complex predicates as selection conditions and the document schema is complex (e.g.
 // axis query and documents with recursively appearing tags),  le scan is neither e cient, nor effective to return correct answers.
That also explains why many twig pattern matching techniques, e.g.
TwigStack [7], attract lots of research attention.
To solve the problem in structural search in existing work for XML query processing with grouping, we extend our previous algorithm VERT [26], to e ciently compute group-by operators in XML queries with complex predicates.
Given a group-by query, we match the query pattern to the document based on query predicates using VERT.
VERT can handle both structural search and content search in an XML query e ciently, thus it is suitable for queries with complex predicates.
After that, we use the table indices to get the values of relevant properties and compute the aggregate functions in di erent levels of nested grouping by scanning the resulting tuples.
The contribution of this paper is summarized as follows:   We propose an extended algorithm V ERT G based on our previous algorithm, VERT, to process group-by queries over XML document e ciently.
V ERT G inherits all the advantages of VERT, including the e -ciency in matching complex query pattern.
  We propose two optimizations based on semantic information like object and property, which can further enhance the query performance.
  We conduct experiments to compare the e ciency of our approach to existing works, to validate the bene t of our approach.
Some background, as well as related work is presented in Section 2.
In Section 3 and 4 we describe a format of queries with grouping and aggregation, which is used in our system, and design the algorithm V ERT G to e ciently process queries.
In Section 5, we optimize our algorithm with semantics of object and property.
We present experimental results in Section 6 and conclude this paper in Section 7.
XML documents are normally modeled as ordered trees without considering ID/IDREF, in which nodes represent elements, attributes or values in document, and edges represent the relationships between element, attribute and value.
The predicate in a query are the constraint to  lter the query results.
It is similar to the where clause in SQL to specify the selection condition.
An XML query with predicate can be represented by a tree structure, which is called a twig pattern.
Finding all occurrences of a twig pattern query in the tree structure of the XML document is the core operation for XML query processing.
Aggregate function is used to perform analytical computation and summarization.
Some common aggregate operators include max( ), min( ), sum( ), count( ), avg( ), etc.
Since usually we need to apply the aggregate functions to each of a number of groups, another operator group-by is commonly used.
Furthermore, an optional operator having normally comes with group-by to specify the quali cations over groups.
Grouping and aggregation are well supported by SQL in relational databases.
There are also research works [16, 19] to generalize or optimize such analytical operations in RDBMS.
Since XQuery 1.0 lacks functions to explicitly support grouping, processing queries with grouping in XML is addressed by researchers in recent years.
Intuitively, the relational approaches [29, 28, 25] to store and query XML data can support grouping and aggregation because those approaches shred XML data into relational tables and convert queries involving grouping operation into SQL to query the database.
These sort of approaches have limitations such as the ine ciency to answer  // axis queries over the document with recursively appearing tags [7].
Also [29] proves that the relational approaches are not e cient as native approaches for most cases.
The research in XML grouping in native XML databases mainly focuses on three directions.
The  rst direction is on how to support grouping by either providing logical grouping operators [13, 9, 22], or detecting grouping in nested queries and rewriting queries [10, 12, 20, 23, 24].
Particularly, in [13] they provide algebraic operators for grouping, and achieve e cient construction of XML elements using their algebra.
[9, 22] focus on designing a graphical query language supporting grouping, and eventually the query will be translated to XQuery expression to process.
The works [10, 12, 20, 23, 24] detect the potential grouping from nested queries and using di erent rewriting rules to transform the queries into a new structure with explicit group-by operator.
However, this approach has a bottleneck, which is the di -culty of detecting grouping in nested queries.
Sometimes it is even not possible to detect such potential grouping [3].
Due to the limitation of detecting grouping in nested queries, some researchers focus on a second direction, which is extending XQuery 1.0 to explicitly support grouping in queries.
In [6, 3, 18] they de ned extra operator to complement FLWOR expression in XQuery for grouping.
In this case, the query optimizer does not need to detect potential grouping in an XQuery expression.
Based on these research e orts, W3C published the new version of XQuery, XQuery 1.1, in which a grouping construct is introduced as a core requirement, though the work has just started.
Since none of the works mentioned above focuses on physically computing group-by and aggregate function over XML documents, a new research direction works on algorithmic support for processing grouping and aggregation.
[14] proposes an algorithm to directly compute group-bys.
However their method did not consider the case that an XML query may contain complex predicate and the document may also have a complex schema such as containing recursively ap-(3:4,3) book (5:18,3) bookstore (1:1000,1) subject (2:63,2) book (19:34,3) subject (64:321,2)  ...
book (35:48,3) book (49:62,3) computer publisher (6:7,4) title (8:9.4) author (10:11,4) year (12:13,4) price (14:15,4) quantity (16:17,4) publisher (20:21,4) title (22:23.4) author (24:25,4) author (26:27,4) year (28:29,4) price (30:31,4) quantity (32:33,4) publisher (36:37,4) title (38:39.4) author (40:41,4) year price (42:43,4) (44:45,4) quantity (46:47,4) publisher (50:51,4) title (52:53.4) author (54:55,4) year (56:57,4) price (58:59,4) quantity (60:61,4) HillmanNetwork Green
 Elco Database Systems Smith Cole


 Elco
 Smith


 Elco Data Replication Wang


 Figure 1: An example document bookstore.xml pearing elements.
For such documents and queries, the  le scan to select relevant nodes in [14] may fail to work, and this motivates many pattern matching techniques ([15]).
There are also works ([21]) to eliminate duplicates during grouping computation so that better performance can be retrieved.
In this section, we describe the general form of XML queries with grouping, which is used in our V ERT G algorithm.
The general query form is shown in Fig. 2 below.
Expr ::=  PATTERN:  XPath_expression Group(cid:882)by* Group(cid:882)by ::=  GROUP BY:  group(cid:882)by_attribute+ ( ORDER BY:  group(cid:882)by_attribute+)?
( HAVING:  condition+ )?
 RETURN: {  aggregate_function+ Group(cid:882)by*  }  Occurrence Indicator: + 1 or more * 0 or more ?
0 or 1 Figure 2: Query form used by V ERT G Pattern: The grouping operation and aggregation function are built on twig pattern queries as mentioned in Section
 The nodes in a twig pattern should include all the predicate nodes, group-by nodes and output nodes in the given query.
Grouping: Grouping is explicitly expressed using the keyword group by.
Group by indicates the query nodes by which the results are grouped, and an optional order by clause indicates the order to output each group.
Without indicating the grouping order, we will output the result based on the ascending order of the group-by nodes by default.
Grouping often comes with optional having, which is used to specify the aggregate conditions.
Grouping can be parallel, which means the results are grouped in multiple ways by di erent properties.
Grouping can also be nested, which means the results within each return clause can be further grouped.
Return: The return clause speci es the aggregate functions in each group.
As mentioned above, grouping can recursively appear in a query, so the output information following the return clause can be the value of an aggregate function, or a nested grouping operation with another return clause.
Example 1.
Consider a query to  nd  rst all the computer books grouped by publisher to output the total number of books of each publisher whose average book price is greater than 40, and then group all books under each of these publishers by year and price separately to  nd the total quantity of books in each subgroup.
This query can be expressed as Q1 in Fig. 3.
Note that the pattern in Q1 is an XPath expression in which all relevant nodes to the query are included.
Q1: PATTERN: subject[name= computer ]/book[publisher][year][price][quantity] GROUP BY: publisher ORDER BY: publisher HAVING: avg(price)>40 RETURN: { count(book), GROUP BY: year RETURN: { sum(quantity) } GROUP BY: price RETURN: { sum(quantity) } } Figure 3: Example query Q1

 In this section, we introduce the algorithm V ERT G to perform grouping as well as aggregate function in XML queries with complex predicate.
Our algorithm contains two phases.
In the  rst phase, we perform pattern matching to  nd all the relevant nodes that satisfy the query predicates in XML document.
In our implementation we use our previously proposed algorithm VERT to match query pattern because: (1) VERT solves content problems existing in many other algorithms, such as the ine ciency of content management, content search and content extraction.
(2) VERT makes use of relational tables to index values, which is more compatible with the algorithm proposed in this paper, and (3) VERT is a very e cient algorithm to process twig pattern queries.
After that, in the second phase we use the table indices on values, together with the result from pattern matching, to perform grouping and compute aggregate functions.
Multilevel grouping can be e ciently supported in V ERT G. First of all, we brie y review VERT with table indices.
Traditional twig pattern matching techniques su er from problems dealing with contents, such as di culty in data content management and ine ciency in performing content search.
We proposed VERT, to solve these content problems, by introducing relational tables to index values.
Most XML query processing algorithms assign labels to each document node so that the parent-child relationship or ancestor-descendant relationship between two nodes can be easily In VERT, we use tables to identi ed using node labels.
store labels of properties and their values.
The term property used in this paper refers to the property of each object, irrespective of whether it appears as an element type or an attribute type in an XML document.
When we parse an XML document, we label only elements and attributes, and put the labels into corresponding streams.
A stream for each element or attribute is used to store labels for that element or attribute in document order.
Values in documents are not labeled; instead we put them into relational tables together of each table is: Rproperty(Label, Value) In this schema, the subscript property in the table name indicates for which type of property this table is used.
The two  elds  Label  and  Value  store the label of the property node and its child value.
There are di erent labeling schemes for static or dynamic1 XML documents.
Suppose we adopt containment labeling scheme [29] in our implementation, the labels assigned to each document node is shown in Fig. 1 and the example tables for property  title  and  author  in the the same document is shown in Fig. 4.
Value Network Rtitle Label (8:9,4) (22:23,4) Database(cid:3)Systems
 ( (52:53,4) Data(cid:3)Replication , ) Rauthor Label Value (10:11,4) Green , ) ( (24:25,4) Smith (26:27,4) Cole (40 41 4) S ith (40:41,4) Smith (54:55,4) Wang Figure 4: Table indices for  title  and  author  To process a twig pattern query with value comparison in the predicate, VERT performs content search  rst on the value comparisons, and then rewrites the query by removing those value comparisons and performs structural search on the new query pattern using any e cient structural join algorithm, e.g.
TwigStack.
For example, to process the query shown in Fig. 5(a), VERT  rst refers to the title table to get the labels for property title whose value is  XML .
It constructs a new title stream for this query using the selected title labels.
Now we just need to process the rewritten query in Fig. 5(b), ignoring the value comparison and using the new stream for title.
The reason why we can simplify the original query like this is that the value of the property title for all the labels in the new title stream is  XML  and actually we have already handled the predicate based on title.
Comparing VERT using a relational table to handle values with the pure structural matching algorithms, we can see VERT signi cantly reduces the size of the stream for title, and reduces the number of structural joins by 1.
We also propose optimizations for VERT.
Details can be found in [26].
book book title author titleXML author
 (a) Original query (b) Rewritten query Figure 5: Example query in VERT processing
 We de ne the query format in Section 3.
In this section, we discuss how we store the query information into relevant data structures, which will be used during query processing with V ERT G. Since we adopt VERT to process pattern matching for queries, we need to maintain the index tables for each type of property, as mentioned in last section.
The tables are also used to extract actual values for each property when we perform grouping and aggregation.
whereas, dynamic document is frequently updated.
Besides the table indices, we also need two tree structures in V ERT G. One is a query structure tree, named QT, and the other one is a grouping structure tree, named GT.
QT is used to represent the XPath expression in a query, and it is also named as twig pattern.
V ERT G matches QT to the document.
This pattern matching process can be considered as a selection based on predicates.
In GT, each node stands for a grouping operation.
Thus within a GT node we record the group-by property2, the order-by property, the grouping constraint and the output aggregate function.
Each GT node has two pointers: child and next sibling.
The child points to a nested grouping operation, and the next sibling points to a parallel grouping operation in the same grouping level as the current node.
Example 2.
Consider Q1 in Fig. 3.
The structures QT and GT for Q1 are shown in Fig. 6.
In GT, the four entries in each node stand for group-by property, order-by property, grouping constraint and output aggregate function in order.
The child pointer re ects the nested relationship between the two levels of grouping, and the next sibling pointer re ects the parallel relationship between the two grouping operations in the same level.
subject name book  computer  publisher year price quantity publisher publisher avg(price)>40 count(book) child year year nil next sibling price price nil sum(quantity) sum(quantity) Figure 6: Structures for Q1 The format of the output results can be easily generated by analyzing the query.
The result format for Q1 is shown in Fig. 7.
Due to the space limitation, the details of generating QT, GT and output format from the query are omitted.
Result Publisher_group Publisher_group   publisher no_of_book Year_group Year_group   Price_group    Elco 
 year total_quantity price total_quantity  2005 
  32 
 Figure 7: Output format for Q1
 To process a query with grouping using V ERT G, we  rst perform a pattern matching for the query to the XML document.
After that in the second phase we perform grouping and aggregation based on the matching results.
Pattern matching: As mentioned previously, we adopt VERT for pattern matching.
The output of this pattern matching phase is tuples of labels for relevant nodes, which is considered as intermediate result set, named as RSintermediate.
The relevant nodes means the nodes which are searched by
 by property in each grouping operation.
The data structures can be easily extended to support multiple group-by properties.
The same assumption is made for grouping constraint and output aggregate function.
gregate functions.
For example, to process Q1, we match the path expression following PATTERN to the document.
Since nodes  book ,  publisher ,  year ,  price  and  quantity  appear in GROUP BY, HAVING and RETURN clauses, VERT will output the labels for these nodes in each matched segment.
The intermediate result set for Q1 is shown in Fig.
8, where each tuple contains the node labels in each twig pat tern occurrence in document.
RSintermediate book (5:18,3) (19:34,3) (35:48,3) (49:62 3) (49:62,3) publisher (6:7,4) (20:21,4) (36:37,4) (50:51 4) (50:51,4) year (12:13,4) (28:29,4) (42:43,4) (56:57 4) (56:57,4) price (14:15,4) (30:31,4) (44:45,4) (58:59 4) (58:59,4) quantity (16:17,4) (32:33,4) (46:47,4) (60:61 4) (60:61,4) Figure 8: Pattern matching result for Q1 Performing grouping: In the second phase, we perform grouping, as well as aggregate functions.
We  rst construct RSf inal by extracting actual values for the properties in the intermediate result set RSintermediate using table indices for each property.
After that we traverse the GT for the query according to a child rst fashion.
The recursive method for GT traverse is shown in Algorithm 1.
We start with traverse (GT.root) and the global variable level, which indicates the grouping level that we start performing grouping with, is initialized to be 1.
When we visit a node, we attach the group-by property, order-by property, grouping constraint and aggregate function in that node to the end of the corresponding global lists GL, OL, CL and AL.
If a node does not have a child, we begin to perform grouping in RSf inal with current GL, OL, CL, AL and level.
We also consider the parallel grouping within the same level by checking the next sibling of each GT node.
The level value is set to be the level of the node which has a next sibling.
Algorithm 1: traverse (node) attach the group-by property, order-by property, grouping constraint and aggregate function in node to the end of the lists GL, OL, CL and AL separately if node.getChild == null then perform (RSf inal, GL, OL, CL, AL, level) delete the last entry of GL, OL, CL and AL.
else traverse (node.getChild) if node.getNextSibling != null then level=node.getLevel traverse (node.getNextSibling)








 To process the query Q1, we traverse the GT in Fig. 6.
By Algorithm 1, we perform grouping twice for Q1: one is for properties  publisher  and  year  with level =1, and the other one is for  publisher  and  price  with level =2.
Now we move to the algorithm to perform grouping, which is shown in Algorithm 2.
Note that although the RSf inal is in relational table format, we cannot use SQL to compute all the group-by clauses, because SQL cannot support nested grouping due to the  at format of relational table.
We partition RSf inal in line 1.
The function partition(RSf inal, GL, OL) sorts the table RSf inal based on all the properties in GL, following the order by which the properties appear in OL if it is di erent from that in GL.
Sorting by multiple properties works in the way that the system sorts tuples by the  rst property, and if two or more tuples have the same value on the  rst property, then it sorts them by the second property, and so forth.
Now the tuples can be partitioned into di erent groups for di erent levels.
Algorithm 2: perform (RSf inal, GL, OL, CL, AL, level)






















 partition(RSf inal, GL, OL) let n = GL.length foreach i = level to n do initialize cv [i] = RSf inal[GL[i]] initialize lists count[i][ ], sum[i][ ], max[i][ ], min[i][ ] for relevant properties in RSf inal, which are used to compute aggregate functions foreach tuple t in RSf inal do foreach i = level to n do if t[GL[i]] != cv[i] then foreach j = i to n do check the constraints in CL[j] if CL[j] holds then compute aggregate functions in AL[j] put cv [j] and the aggregate results into the appropriate position in result tree cv [j] = t[GL[i]] reset count[j][ ], sum[j][ ], max[j][ ], min[j][ ] break else update count[j][ ], sum[j][ ], max[j][ ], min[j][ ] foreach i = level to n do check the constraints in CL[i] if CL[i] holds then compute aggregate functions in AL[i] put cv [i] and the aggregate results into the appropriate position in result tree Example 3.
Consider Q1 in Fig. 3 with the intermediate result set shown in Fig. 8.
Using the index tables Rpublisher, Ryear, Rprice and Rquantity we can get the exact values for each  eld.
When the perform function is  rst called in Algorithm 1, we partition the RSf inal based on properties  publisher  and  year .
The result is shown in Fig. 9.
The bold lines in the RSf inal show the partition.
Level(cid:3)1 partition Level(cid:3)2 partition
 RSfinal publisher Elco Elco Elco Hillman year



 book (19:34,3) (35:48,3) (49:62,3) (5:18,3) ( ) price



 quantity



 Figure 9: Example RSf inal with partition for Q1 In lines 2-5, we initialize the lists used in this algorithm.
Particularly, cv[i] stores the current value of the group-by property in the ith level group, while statistic lists count[i][ ], sum[i][ ], max[i][ ] and min[i][ ] store the corresponding current statistic values for the ith level group.
In lines 6-
each tuple in RSf inal to see whether any new partition in the di erent levels begins at this tuple.
This is done by checking whether the value of the group-by property in each level is changed in line 8.
If any new partition begins in a certain grouping level, for every lower level a new partition also begins.
Then we check the HAVING constraint in these levels and compute the aggregate functions using the corresponding statistic lists, as shown in lines 10-13.
After that we reset the current group-by property value and the statistic lists for each of these levels, in lines 14-15.
If in a tuple, some grouping level does not end, we simply update to maintain all the statistic lists as the query may be only interested in some of them.
To simplify the presentation, we use all the statistic lists in the pseudo-code.
Lines 19-23  nalize the query processing by outputting the result for the last group in each grouping level.
Example 4.
When the perform function is  rst called during GT traverse for Q1, the RSf inal with partition is shown in Fig. 9.
We start with level=1, and initialize the current value and the necessary statistic lists for each grouping level, as shown in Fig. 10.
The list cv[ ] contains two entries since there are two levels of grouping.
The statistical list, saying count[1][ ], stores the total number of each target property in the  rst level, e.g.
count[1][2] is the count of the second property  price  in level 1 grouping.
Nil in some entries of each list means the corresponding statistic value is not asked by the query and we do not need to maintain it.
publisher cv[ ] year
 price quantity Elco book
 nil nil count[1][ ] sum[1][ ] sum[2][ ] Note: In count[i][j] and sum[i][j], i is the grouping level and j is the position in the list.
nil nil nil
 Figure 10: Example initial lists for Q1 When the system reads the third tuple in RSf inal, the value in cv[1] is the same as the  publisher  value in the third tuple.
That means the current level 1 group does not end at this tuple.
Thus it updates the lists count[1][ ] and sum[1][ ].
However, the value  2005  in cv[2] is di erent from the  year  value  2006  in the third tuple, which means current level 2 group ends.
It then follows lines 10-13 in Algorithm 2 to compute the aggregate function in level 2 grouping based on current statistic list for this level, e.g.
sum[2][ ], and puts the value  2005  for the group-by property  year  and the result  30  for aggregate function sum(quantity) into appropriate position in the result tree as shown in Fig. 7.
After that the system resets cv[2] and the statistic list sum[2][ ] for level 2 grouping and continues reading the next tuple.
The relevant lists before and after reading the third tuple is shown in Fig. 11.
publisher cv[ ] count[1][ ] sum[1][ ] sum[2][ ] Elco book
 nil nil year
 price

 nil publisher cv[ ] count[1][ ] sum[1][ ] sum[2][ ] Elco book
 nil nil year
 price

 nil quantity nil nil
 quantity nil nil
 (a) Before the third tuple (b) After the third tuple Figure 11: Example lists before and after reading the third tuple in RSf inal for Q1 processing
 Anti-monotonic constraint is de ned as the constraint which will never be true once it becomes false.
Some aggregate constraints that appear in HAVING clauses, such as count( )   num, max( )   num, min( )   num or sum( )   num (num is a numeric value), are anti-monotonic constraints.
E.g.
for the constrain max(price)   100, once we get a price greater than 100 in a group, we can never turn the constraint to be true, no matter how many more prices are checked in the same group.
Motivated by anti-monotonic constraints, some early pruning can be done to enhance the query performance.
When we read tuples in RSf inal, we can check the anti-monotonic constraint  rst, rather than checking all constraints after meeting the end tuple of the group.
If any anti-monotonic constraint is violated by a certain tuple, all other tuples in the same group can be skipped.
The query form and query processing algorithms presented in Section 3 and Section 4.2 are built on basic aggregation.
Sometimes the user may issue queries involving keyword constraints distinct, or some other aggregate functions, or even moving windows following the group-by properties.
In this section, we explain brie y how our algorithm is  exible to be extended to support these advanced features.
Distinct: Some aggregate function aims to  nd aggregate results on distinct values in the group.
In this case, we need to introduce keyword distinct.
There are two types of parameters that can be used by distinct constraint.
The  rst type is property.
E.g.
count(distinct name) counts the number of di erent names distinguished by name values.
To support this type of distinct, we can maintain a sorted list to store di erent values for the corresponding properties.
When a value comes, we can know whether it is a distinct value or not by check the sorted list.
The second type of parameter following distinct constraint is object, e.g.
count(distinct book).
This function is not easy to compute as  book  is an object class rather than property, and there is no child value for  book  to explicitly distinguish each  book  object.
One way to distinguish objects under the same class is to discover more semantics on object ID [8].
As long as the ID of an object class is clear, we can easily perform aggregate functions on distinct objects by introducing ID to RSf inal for the relevant object.
Other aggregate functions: We discuss four more aggregate functions that are frequently asked, namely, maxN( ), minN( ), median( ) and mode( ).
The function maxN( ) and minN( ) are top N functions to  nd the N maximum or minimum values.
Median( ) returns the value that separates the higher half of a set of values from the lower half, and mode( ) is used to  nd the value that occurs most often In the discussion about distinct keyword above, in a set.
we mentioned that we can maintain an additional sorted list to store di erent values for particular property.
To compute maxN( ), minN( ), median( ) and mode( ), we not only need the sorted list for the distinct values for relevant properties, but also need a frequency list in which each entry stores the number of occurrences of the value in the corresponding entry in the sorted list.
Using these two lists, these aggregate functions can be easily computed.
Moving windows: Moving windows are used to group answers by ranges of values on a certain property.
E.g.
a query needs to  nd the total quantity of books group by range of 5 years with a moving step of 3 years, beginning at 2008.
In this query, we need to put books with year in [2008, 2012] together, with year in [2011, 2015] together and so on.
The general approach to handle moving windows is, we  rst do grouping and aggregation as usual for each distinct value, and after that we perform a post-aggregation that aggregates the results from the previous step based on First we get the sum(quantity) for each year, and then in the post-aggregation step, we just sum up the quantity for years from 2008 to 2012, and from 2011 to 2015, etc.
If there are nested grouping operations inside each window group, the post-aggregation is also e ective.
For example, continuing with the above query, suppose for each year window, we need to  nd the number of books grouped by publisher.
In the  rst step, we group books by each di erent year, and then in each group, we do a secondary grouping on publisher and count the books in each subgroup.
The post-aggregation will integrate all subgroups in the  ve groups with year value from 2008 to 2012, from 2011 to 2015, etc, by summing up the results under the same publishers.
In Q1, we group  book  by its descendant properties.
Actually our algorithm also supports grouping by the properties appearing in other places in document, rather than descendants of an object.
Example 5.
Consider the query Q2 to  nd the average price of books published in 2005, group by publisher  rst and then group by subject name.
In this query, subject name appears as a property of the parent node of  book .
To answer this query, we just match the twig pattern shown in Fig. 12(a) to the document tree, and extract values for each property using table index to form RSf inal.
Then grouping operation and aggregate function can be done normally in RSf inal.
The result structure is shown in Fig. 12(b).
Result subject name book publisher year price  2005  (a) Twig pattern Publisher_group Publisher_group   pubisher Subject_group Subject_group    Elco  name avg_price name avg_price  computer 
  biology  (b) Result tree
 Figure 12: Query Q2 and result tree By investigating analytical queries, we  nd many of them group objects by their own properties.
E.g.
in Q1, we group books by publisher and then by year and price.
Publisher, year and price are all the properties of book.
With the semantic information on grouped object, and the relationship between grouped object and group-by properties, we can optimize tables to further improve the query performance.
Recall the table index we used in V ERT G (e.g.
the example tables shown in Fig. 4), we can see the  Label   eld in each table stores the label of the corresponding property, while the  Value   eld stores the value of the property.
If we have knowledge on the object to which each property belongs, e.g.
the object for properties  title  and  author  is  book , we can optimize the table to be object/property table, instead of the previous property table.
The schema of the object/property table is: Robject/property(Label, Value) In the object/property table, the table name indicates which object and property the table is for.
The  Label   eld stores the label for the object, instead of the property, and the  Value   eld stores the corresponding property value.
Example 6.
For the bookstore document in Fig. 1, we can optimize the index property table to be object/property table.
The table for object  book  and property  title  is shown in Fig. 13(a).
Comparing the  book/title  table in Fig. 13(a) to the table for  title  shown in Fig. 4, we can  nd that the stored information in  Label   eld is changed from  title  labels to  book  labels, whereas the  Value   eld is not changed.
Now when we process Q1 using the new table indices, we can simplify the twig pattern as shown in Fig. 13(b), by reducing quite a number of structure nodes and structure joins.
After getting the labels for  book  during twig pattern matching, we can use the corresponding object/property tables to get values for  publisher ,  year ,  price  and  quantity , to form RSf inal.
Value Network Rbook/title Label (5:18,3) (19:34,3) Database(cid:3)Systems
 ( (49:62,3) Data(cid:3)Replication , ) subject name book computer (a) Object/property table for  book/title  (b) Twig pattern for Q1 with new table indices Figure 13: Example for Optimization 1
 In Optimization 1, for each object we maintain di erent table indices for di erent properties.
E.g.
for the object  book  in the bookstore document in Fig. 1, we have tables Rbook/title, Rbook/author, etc.
Processing a group-by query involving di erent properties on the same object requires accessing multiple table indices.
Those tables have the same  Label  value as there are for the same object.
If we merge all object/property tables for the same object and single-valued properties to get object table, we can save the cost on the access and the search in multiple tables for the same object.
Motivated by this, we have the second optimization.
The schema for object table used in Optimization 2 is: Robject(Label, Property*) The table name indicates for which object the table is, the  eld  Label  stores the labels of each object and the rest  elds store the names of each belonging single-valued property and the corresponding values.
For multi-valued properties, we cannot merge them with other properties, so we keep the object/property table for multi-valued properties.
Publisher Title Hillman Rbook Label (5:18,3) (19:34,3) Elco (35:48,3) Elco ( (49:62,3) Elco , ) Price Quantity Year
 Network Database(cid:3)Systems 2005 32

 Data(cid:3)Replication




 Rbook/author Value Label Green (5:18,3) ( , ) Smith (19:34,3) (19:34,3) Cole (35 48 3) S ith (35:48,3) Smith (49:62,3) Wang Figure 14: Example object table in Optimization 2 Example 7.
Consider the bookstore document shown in Fig. 1.
The index tables for  book  under Optimization 2 are shown in Fig. 14.
We merge all the single-valued properties for  book  to Rbook, and for the multi-valued property  author  we keep the object/property table.
With the new optimization, for Q1 we only need to join RSintermediate in Fig. 8 with Rbook once to get all the property values.
while the parent node of each property can be considered as the corresponding object, but it is not always correct.
E.g.
in an XML document,  person  has property  name , and  name  is a composite property having two children  rst-Name  and  lastName .
In this case,  rstName  and  last-Name  should be the properties of object  person , though they are not the children of  person .
Normally the semantics of object can be inferred from domain knowledge.
Without such semantics, we can still process queries using Optimization 2, in which the parent node of each property is simply considered as an object, e.g.
in the above example, we consider  name  as an object with two properties  rstName  and  lastName .
Once we have more semantic information, we can include it to the table index and further improve the query performance.
E.g.
in a query to  nd the person whose  rstName  is  John .
When we consider  name  as an object of property  rstName , we need to  nd the  name  whose property  rstName  has value of  John , and then join it with each  person .
If we know the actual object for  rstName  is  person , we can directly  nd the  person  whose property  rstName  has value of  John .
In this section we present experimental results.
First we conduct experiments to compare the query performance using V ERT G without optimization, with Optimization 1 and with Optimization 2.
Then we use V ERT G Optimization 2 to compare with other approaches including relational approach, XQuery engine, and a recently proposed algorithm N-GB [14] on group-by query processing.
We implemented all algorithms in Java.
The experiments were performed on a dual-core 2.33GHz processor with 4G RAM.
We used real-world data sets DBLP (91MB) and NASA (23MB), and a well known synthetic data set XMark [27] in our experiments.
Note that DBLP data has a simple schema, while NASA data has a complex schema.
The characteristics of queries used is shown in Fig. 15.
Query


 X1,(cid:3)N1,(cid:3)D1,(cid:3)XM1,(cid:3)NM1
 X2,(cid:3)N2, D2,(cid:3)XM2,(cid:3)NM2
 X3,(cid:3)N3,(cid:3)D3,(cid:3)XM3,(cid:3)NM3 X4,(cid:3)N4,(cid:3)D4,(cid:3)XM4,(cid:3)NM4 X5,(cid:3)N5, D5, XM5,(cid:3)NM5 X6,(cid:3)N6,(cid:3)D6,(cid:3)XM6,(cid:3)NM6
 X7,(cid:3)N7,(cid:3)D7,(cid:3)XM7,(cid:3)NM7 X8,(cid:3)N8,(cid:3)D8,(cid:3)XM8,(cid:3)NM8 SX,(cid:3)SN,(cid:3)SD i
 Grouping(cid:3) levels








 1(cid:882)6 i
 Grouping(cid:3) properties








 1(cid:882)6
 Query
 XNR1,(cid:3)XNS1 XNR2,(cid:3)XNS2
 XNR3,(cid:3)XNS3 XNR4,(cid:3)XNS4 XNR5,(cid:3)XNS5 XNR6,(cid:3)XNS6
 DN1,(cid:3)DN2,(cid:3)DN3 DN4,(cid:3)DN5,(cid:3)DN6 DN7,(cid:3)DN8,(cid:3)DN9 i
 Grouping(cid:3) levels









 i
 Grouping(cid:3) properties






 1(cid:882)2
 2(cid:882)4 3(cid:882)6 Figure 15: Experimental queries with No.
of grouping levels and No.
of grouping properties
 with optimizations
 We process 8 queries in each document to compare the query performance between original V ERT G algorithm and the two optimizations (named as V ERT G-op1 and V ERT G-op2).
Queries X1-X8 are issued to Xmark document, N1-N8 to NASA document and D1-D8 to DBLP document.
The experimental results on execution time are shown in Fig. 16.
1(cid:882)level
 ) s ibute m



 ( (cid:3) e m
 i t (cid:3) n o o i t u c e x




 2(cid:882)level 3(cid:882)level 4(cid:882)level 5(cid:882)level 6(cid:882)level Number(cid:3)of(cid:3)grouping(cid:3)levels








 Queries





 1(cid:882)level
 ) s ibute m ( (cid:3) e m
 i t (cid:3) n o o i t u c e x





 2(cid:882)level 3(cid:882)level 4(cid:882)level 5(cid:882)level 6(cid:882)level Number(cid:3)of(cid:3)grouping(cid:3)levels








 Queries




 VERTG-op1 VERTG-op2


 (a) XMark data set VERTG (cid:3)VERTG-op1 VERTG-op2





 (b) NASA data set

 ) s ibute m

 1(cid:882)level








 ( (cid:3) e m
 i t (cid:3) n o o i t u c e x




 2(cid:882)level 3(cid:882)level 4(cid:882)level 5(cid:882)level 6(cid:882)level Number(cid:3)of(cid:3)grouping(cid:3)levels








 Queries


 VERTG VERTG-op1 VERTG-op2




 (c) DBLP data set Figure 16: Query performance comparison for V ERT G, V ERT G-op1 and V ERT G-op2 We can see that for all the queries V ERT G-op2 outperforms V ERT G-op1, and V ERT G-op1 outperforms V ERT G without optimization.
This validates the analysis in Section
 further simplify the query to improve the performance, and V ERT G-op2 combine object/property tables to object tables, so that the table accesses and the tuple searches are reduced and the performance is further improved.
It is natural that the user issues a query with nested grouping.
In this section we measure the time trend of our algorithm V ERT G and its optimizations when the grouping levels increase.
For each document, we select one type of query with predicates  xed and grouping levels varied.
The result on the scalability is shown in Fig. 17.
From the result we can see that running time for V ERT G increases as the number of grouping levels increases.
The reason is, if we group a set of objects by a new property, we have to include that property for pattern matching, which is time consuming.
However, if we adopt V ERT G with either V ERT G-op1 or V ERT G-op2, we only match the relevant objects, instead of each property node.
As a result, the execution time increases slowly when more grouping levels are involved.
V ERT G-op2 is better than V ERT G-op1 because we access less table indices in V ERT G-op2.
In this section, we compare our approach with other approaches including relational approaches, XQuery engine, and N-GB.
We use V ERT G-op2 in our approach for the comparison.
As mentioned in Section 1, relational approaches shred XML into relational tables and translate XML queries into SQL to query the database, and they support grouping in ) s ) s
 i t (cid:3) n o o i t u c e x
 m




 m m
 ( (cid:3) ( e (cid:3)
 e m m




 i t (cid:3) n o i t u c e x
 i t (cid:3) n o i t c e x


















 Queries


 vels ) s ) s
 i t (cid:3) n o o i t u c e x
 m





 m m
 (
 (cid:3) ( e (cid:3) e m m






 i t (cid:3) n o i t u c e x
 i t (cid:3) n o i t c e x

















 Queries



 VGroup

 VGroup(cid:3)opt1

 VGroup(cid:3)opt2

 5(cid:882)level 2(cid:882)level 4(cid:882)level 1(cid:882)level 1(cid:882)level 2(cid:882)level 3(cid:882)level 4(cid:882)level 5(cid:882)level 6(cid:882)level 6(cid:882)level
 VGroup

 VGroup(cid:3)opt1

 VGroup(cid:3)opt2

 5(cid:882)level 4(cid:882)level 2(cid:882)level 1(cid:882)level 1(cid:882)level 5(cid:882)level 4(cid:882)level 2(cid:882)level 3(cid:882)level 6(cid:882)level 6(cid:882)level 3(cid:882)level Queries Number(cid:3)of(cid:3)grouping(cid:3)levels Number(cid:3)of(cid:3)grouping(cid:3)levels N(cid:882)GB
 VERTG-op1 VG(cid:882)opt

 VERTG-op2


 3(cid:882)level Queries Number(cid:3)of(cid:3)grouping(cid:3)levels Number(cid:3)of(cid:3)grouping(cid:3)levels N(cid:882)GB
 VERTG-op1 VG(cid:882)opt

 VERTG-op2


 joins, the performance of MonetDB is a ected.
In XMark data set, the CPU time for MonetDB increases fast on XM3-XM8.
In NASA data set, though the CPU time on NM3-NM4 is still relatively low, when we increase the number of grouping levels in NM5-NM8, the e ciency of MonetDB is signi cantly a ected.
Our approach, V ERT G-op2, outperforms MonetDB for those queries with multilevel groupings.
(a) XMark data with SX (b) NASA data with SN
 vels ) s ) s i t (cid:3) n o o i t u c e x







 m






 m m

 ( (cid:3) ( e (cid:3) e m

 m










 5(cid:882)level
 Queries

 VGroup(cid:3)opt1 4(cid:882)level 4(cid:882)level i t (cid:3) n o i t u c e x
 2(cid:882)level 2(cid:882)level 1(cid:882)level 1(cid:882)level i t (cid:3) n o i t c e x

 VGroup 5(cid:882)level










 VGroup(cid:3)opt2 6(cid:882)level 6(cid:882)level 3(cid:882)level 3(cid:882)level Queries Number(cid:3)of(cid:3)grouping(cid:3)levels Number(cid:3)of(cid:3)grouping(cid:3)levels N(cid:882)GB
 VERTG-op1 VG(cid:882)opt

 VERTG-op2


 (c) DBLP data with SD Figure 17: Scalability for V ERT G, V ERT G-op1 and V ERT G-op2 queries.
In [14] they conducted experiments to show the bad performance using shredding method proposed in [25].
We tried another shredding method [17] in our experiments.
We issued a query with 1-level grouping to an XMark document of 11MB.
The relational database system takes around 10 minutes to return the answer, whereas in our approach such query only needs several seconds.
When more query nodes are introduced, the processing time of the relational approach increases exponentially.
Besides, we take MonetDB [1], which is a well known ef- cient memory-based XQuery engine, for comparison.
We used two data sets, XMark (11MB) and NASA (23MB), and conducted experiments on 8 queries in each data set (XM1-XM8 and NM1-NM8).
All the queries contain grouping operation, and the group-by properties may not necessarily be the children or descendants of the object to be grouped.
E.g.
in NM8 for NASA data we group journals by subject, which is the ancestor node of  journal  in document.
The experimental results are shown in Fig. 18 (Y-axis is in logarithmic scale).
e(cid:3)attribute
 e(cid:3)attribute


















 Queries MonetDB Queries VERTG-op2 Queries Queires MonetDB MonetDB Queries VERTG-op2 Vp (cid:3) (a) XMark data set (b) NASA data set Figure 18: CPU time comparison between MonetDB and V ERT G-op2 For both data sets, we can see that for 1-level grouping with one property, MonetDB performs well.
However, when the number of group-by properties and the number of grouping levels increases, since XQuery needs to express such queries using nesting with multiple document retrievals and l l ) ) e e a a c c s s g g o o
 l l (cid:3) (cid:3) , , s s
 m m ( ( (cid:3) (cid:3) e e m m
 i i t t (cid:3) (cid:3)









 l ) e a c s g o
 l (cid:3) , s
 m ( (cid:3) e m
 i t (cid:3)






 We also compare our work with a recently proposed algorithm N-GB ([14]) to process queries with grouping and aggregation.
We take two data sets, XMark (111MB) and DBLP (91MB) for the comparison.
For XMark data, we perform two sets of queries.
The  rst set contains queries in which group-by properties appear in any positional relationship with the object to be grouped.
E.g.
we group journals by either its child property  year  or its ancestor property  subject .
For this set of queries, our optimization can reduce the complexity during query processing, but we still need pattern matching to get query node occurrences in document.
The second set of queries have group-by properties, output nodes and aggregate properties under the same object.
In this case, we do not need to perform pattern matching, and the e ciency will be enhanced.
For each query set, we have 6 queries with grouping levels varying among 1, 2 and 3.
Fig. 19 shows the experimental results for XMark data.
one(cid:3)attribute

 s els
 m one(cid:3)attribute

 s els
 m m ) ) e e a a c c s s g g o o ) ) e e a a c c s s g g o o





 ) s ) ) s s l l l l








 l l (cid:3) (cid:3) , , s s ( (cid:3) e e

 m m m ( ( (cid:3) (cid:3) e e m m

 i i t t (cid:3) (cid:3)







 i t (cid:3) n o i t u c e x















 l l (cid:3) (cid:3) , , s s ( ( (cid:3) (cid:3) e e e e


 m m m m ( ( (cid:3) (cid:3) e e m m


 i i t t (cid:3) (cid:3)








 i i t t (cid:3) (cid:3) n n o o i i t t u u c c e e x x




























 Queries
 Queries Queries

 Queries Queires MonetDB MonetDB N(cid:882)GB N(cid:882)GB Queries VERTG(cid:882)op2 VERTG(cid:882)op2 VERTG(cid:882)op2 VERTG(cid:882)op2
 Queries Queires MonetDB MonetDB N(cid:882)GB Queries VERTG(cid:882)op2 VERTG(cid:882)op2 VERTG(cid:882)op2 (a) Group-by properties random position in (b) Group-by properties the same object as outputs in Figure 19: Execution time comparison between N-GB and V ERT G-op2 for XMark data From the  gure above we can see V ERT G-op2 always outperforms N-GB.
For the  rst set of queries (Fig. 19(a)), V ERT G-op2 saves 30%-51% running time, and for the second query set (Fig. 19(b), this saving becomes 86%-93%.
We also used the real-world data DBLP to compare our approach and N-GB.
We used 9 queries for DBLP data, which are DN1-DN9.
Since N-GB assumes the answer tree can  t in memory, we allocated 1GB memory for JVM during experiments.
The results are shown in Fig. 20.
We can see from the  gure, V ERT G-op2 outperforms N-GB for all kinds of queries.
This result shows that our approach is ef- cient not only for complex documents (e.g.
XMark), but also for  at documents (e.g.
DBLP).
In this paper we analyzed the drawbacks of di erent existing approaches to process XML queries with grouping and aggregation, and proposed a novel algorithm, V ERT G, which can perform grouping operation and compute aggregate functions in XML queries with complex predicate.
The main technique of V ERT G is to introduce table index during XML query processing.
After processing XML queries
 ) s m ( (cid:3) e m i t (cid:3) n o i t u c e x







 Queries N(cid:882)GB VERTG-op2 Figure 20: Execution time comparison between N-GB and V ERT G-op2 for DBLP data over documents natively using any pattern matching algorithm, e.g.
VERT, V ERT G extracts actual values for relevant nodes with table indices and performs grouping and aggregation.
Furthermore, we proposed two semantic optimizations to table index, which can signi cantly enhance the query processing performance.
We conducted experiments to compare our approach with a relational approach, a well known XQuery engine and a recently proposed algorithm, to show the advantages of our approach.
In future work, we plan to investigate real-life queries and further optimize the table index so that the relationship between relevant objects can be e ciently discovered using index, instead of searching the document.
Also we will extend our approach to handle queries with ID references, and queries across multiple XML documents.
