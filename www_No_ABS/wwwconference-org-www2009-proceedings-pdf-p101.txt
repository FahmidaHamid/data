The World Wide Web has been growing rapidly as a huge information repository, which contains various kinds of valuable semantic information about real-world entities, such as people, organizations, and locations.
We have been working on object-level search engines, which automatically extract and integrate the semantic information about entities and return a list of ranked entities instead of webpages to answer user queries [18].
In object-level search engines, it is particularly important to mine entity relations from the Web to automatically build an entity relationship graph to link all the extracted information together.
With the entity relationship graph, users will be able to easily navigate through their interested entities just like the way they navigate through hyperlinked webpages.
This paper focuses on entity relation mining from the Web.
We have deployed an entity relationship search engine in Chinese search market called Renlifang1.
Renlifang is a different kind of search engine we have been building, one that explores relationships between entities.
In Renlifang, users can query the system about people, locations, and organizations and explore their relationships.
Currently Renlifang only serves in the Chinese language domain.
These entities and their relationships are automatically mined from billions of crawled Chinese webpages.
For each crawled webpage in Renlifang, the system extracts entity information and detects relationships, covering a spectrum of everyday individuals and well-known people, locations, or organizations.
Below we list the key features of Renlifang: Entity Relationship Mining and Navigation.
Renli-fang enables users to explore highly relevant information during searches to discover interesting relationships about entities associated with their queries.
Finding Expertise.
Renlifang can return a ranked list of people known for dancing or any other topic.
Web-Prominence Ranking.
Renlifang detects the popularity of an entity and enables users to browse entities in di erent categories ranked by their prominence on the Web during a given time period.
1http://renlifang.msra.cn to make sure the system will not be drifted by errors.
Although the bootstrapping architecture is promising, Snowball has at least two obvious limitations, which make it unsuitable for the Web-scale relation extraction as motivated by Renlifang.
First, since the target of Snowball is to extract a speci c type of relation (e.g., companies and their headquarters) the extraction patterns in Snowball are mainly based on strict keyword-matching.
Although these patterns can identify highly accurate results, the recall will be limited.
Second, Snowball does not have an elegant evaluation measure, such as the probability/likelihood of a probabilistic model, to evaluate generated patterns.
The carefully crafted measures and pattern selection criteria are not directly adaptable to general patterns (e.g., POS tag sequences), which can signi cantly improve the recall as shown in our empirical studies.
This is because many tuples extracted by a general pattern are more likely not to be the target relations of Snowball, although they can be other types of relations.
In this case, the con dence scores will be very small, and it is inappropriate to use the criteria as used in Snowball to select these patterns.
In this paper, we address these issues as su ered by Snowball to improve the recall while keeping a high precision.
We present a system called Statistical Snowball (StatSnowball).
StatSnowball adopts the bootstrapping architecture and applies the recently developed feature selection method using  1-norm [25, 11] to select extraction patterns both keyword matching and general patterns.
Starting with a handful set of initial seeds, it iteratively generates new extraction patterns; performs an  1-norm regularized maximum likelihood estimation (MLE) to select good patterns; and extracts new relation tuples.
StatSnowball is a general framework and the statistical model can be any probabilistic model.
StatSnow-ball uses the general discriminative Markov logic networks (MLN) [21], which subsume logistic regression (LR) and conditional random  elds (CRF) [15].
Discriminative models can incorporate arbitrary useful features without strong independence assumptions as made in generative models, like na ve Bayes (NB) and Hidden Markov Models (HMM).
By incorporating general patterns, StatSnowball can perform both traditional relation extraction like Snowball to extract pre-speci ed relations and open information extraction (Open IE) [3] to identify general types of relations.
Open IE is a novel domain-independent extraction paradigm, which has been studied in both the natural language document corpus [22] and the Web environment [3].
Although the existing Open IE systems are self-supervised, they require a set of human-selected features in order to learn a good extractor.
In contrast, StatSnowball automatically generates and selects the extraction patterns.
Moreover, the Open IE systems require expensive deep linguistic parsing techniques to correctly label training samples, while StatSnwoball only uses cheaper and more robust shallow parsing techniques to generate its patterns.
Finally, by using the MLN model, StatSnowball can perform joint inference, while the O-CRFs [4] treat sentences independently.
Our empirical studies demonstrate the promise of using joint inference.
To the best of our knowledge, StatSnwoball is the  rst working system that takes a bootstrapping architecture and applies the well-developed  1-norm regularized MLE to incrementally identify entity relations.
Speci cally, we make the following contributions: Figure 1: An entity relationship graph for the query  Bill Gates  generated by EntityCube (i.e. the English version of Renlifang).
People Bio Ranking.
Renlifang ranks text blocks from webpages by the likelihood of their being biography blocks.
Renlifang has been well received by Chinese Internet users and mainstream media in China (including CCTV and Phoenix TV) with positive comments and millions of daily page-views during the peak days.
The English version of Renlifang is called EntityCube, and it is currently under development2.
In Figure 1, we show an automatically generated entity relationship graph using our English Renlifang prototype.
Based on the overwhelming response from Chinese Internet users of the Renlifang entity relationship search, we found that automatically extracting a large number of highly accurate entity relations is important to improve performance.
However, existing work on entity relation extraction in the literature could not meet the requirements of a Web-scale entity relationship search engine.
Relation extraction has been promoted by the Message Understanding Conference (MUCs) and Automatic Content Extraction (ACE) program.
The task has been traditionally studied so as to extract prede ned semantic relations between pairs of entities in text, e.g., in supervised learning methods [27, 8, 9, 26] and bootstrapping systems [5, 1].
Supervised methods require a set of relation-speci c human tagged examples to learn an extractor.
Labeling training examples is tedious and labor intensive, thus, it makes supervised methods di cult to apply to Web-scale applications like Renlifang.
Bootstrapping methods [5, 1, 7] signi cantly reduce the number of training examples by iteratively discovering extraction patterns and identifying entity relations with a small number of seeds, either target relation tuples [1] or general extraction templates [7].
Take the well-known Snowball [1], which serves as the basis of our proposed approach, as an example.
Snowball takes a small set of seed tuples as inputs, and employs the pattern-entity duality [5] to iteratively generate extraction patterns and identify new relation tuples.
From the generated patterns and identi ed tuples, some con dence measures are carefully crafted to select good ones and add them to Snowball as new knowledge.
Evaluating patterns and tuples is one key component, since 2www.entitycube.com using  1-regularized feature selection to incrementally discover extraction patterns and identify relation tuples.
Compared to the closely related Snowball, StatSnowball contains the following advantages: i StatSnowball can perform both traditional relation extraction as in Snowball and Open IE.
ii The probabilistic foundation provides StatSnowball a principled approach to evaluating and selecting patterns.
In Snowball, however, the con dence measures lack an elegant interpretation and they are dif- cult to be applied to general patterns.
iii StatSnowball automatically learns the weights of generated patterns, which are represented as formulae in MLN, while Snowball applies some heuristic rules to assign the weights.
iv StatSnowball can be easily extended.
In current implementation, StatSnowball takes the same strategy as Snowball to separately identify named entities and entity relations.
StatSnowball can easily integrate these two tasks into one probabilistic model and thus can achieve a higher performance by exploring their mutual enhancements.
The promise of integrated extraction has been shown in di erent applications [20, 28].
But the heuristic-based Snowball is hard to be coherently integrated with the state-of-the-art statistical named entity extraction systems.
(b) We extensively evaluate StatSnowball and empirically show that StatSnowball can achieve a signi cantly higher precision and recall on large scale Web data.
(c) StatSnowball is e cient and we have developed a working Entity Relation Search Engine based on it.
The rest of the paper is structured as follows.
Section 2 brie y overviews the StatSnowball system.
Section 3 presents the statistical model (i.e., Markov logic networks), including some speeding up techniques.
Section 4 presents how to generate and select good patterns in StatSnowball.
Section
 related work, and Section 7 concludes this paper, with some future work discussed.
In this section, we brie y overview the framework of Stat-Snowball.
Di erent components will be explained in incoming sections.
The task of StatSnowball is to identify relation tuples.
Each relation tuple can be among several entities.
Here, we only focus on the binary relationship, and an extraction is a tuple (ei, ej, key) i 6= j, where ei and ej are two entities and key is a set of keywords that indicate the relationship.
Like many other relation extraction systems [1, 8, 9], we assume that the entities are given and focus on how to detect (i.e., decide whether a relationship exists between two entities) and categorize (i.e., assign relation keywords to a detected relationship) the relationships.
Figure 2 shows the architecture of StatSnowball.
Generally, StatSnowball has three parts.
The  rst part P1 is the input, which contains a set of seeds and an initial model.
The seeds are not required to contain relation keywords that Initial Model

 (e1, e2, key) (e3, e4, ? )
...
augment seeds (online) learn model select patterns (online) inference/extraction generate patterns
 relation clustering (e5, e6, key1) (e3, e4, key2) ...
Figure 2: The framework of StatSnowball, with three parts   P1 (input), P2 (statistical extraction model), and P3 (output).
indicate the relationship.
Thus, we have two types of seeds, i.e., seeds with relation keywords like (e1, e2, key) or seeds without relation keywords like (e3, e4, ?).
If the initial model is empty, we will  rst use the seeds to generate extraction patterns in order to start the process.
The second part P2 is the statistical extraction model.
To start the iterative extraction process, StatSnowball takes the input seeds and the initial model (can be empty) in P1 to learn an extractor.
We apply the  2-norm regularized maximum likelihood estimation (MLE) at this step.
Online learning is an alternative if batch learning is expensive.
Then, StatSnowball uses the learned model to extract new relation tuples on the data corpus.
The third step in P2 is to generate extraction patterns with the newly identi ed relation tuples.
These patterns are used to compose formu-lae of MLN.
Finally, it selects good formulae to add to the probabilistic model and retrain the model.
In this step, we  rst do  1-norm regularized MLE, which will set some formulae s weights to zeros.
Then, we remove these zero-weighted formulae and send the resultant model to the next step for retraining.
StatSnowball iteratively performs these four steps until no new extraction tuples are identi ed or no new patterns are generated.
In this part, an optional component is the augmenting seeds, which can be used to  nd more seeds to start the process.
In order to get high quality training seeds, this component applies strict keyword matching rules.
We do not use it in the current system.
The third part P3 is the output, which is necessary only when StatSnowball is con gured to do Open IE [3].
When StatSnowball performs Open IE, the extraction results in P2 are general relation tuples.
To make the results more readable, we can apply clustering methods to group the relation tuples and assign relation keywords to them.
The missing keywords of the seeds can be  lled in this part.
Currently, we treat it as a post-processing step.
Recent work on relational clustering with MLN in [14] suggests that we can more later.
Before going into the full exposition of the system, let s end this section with a strict mathematical formulation of StatSnowball.
Formally, StatSnowball iteratively solves an  1-norm regularized optimization problem:
 w   = arg min w LL(D, R, w) +  kwk1.
where LL(D, R, w) is the loss de ned on the corpus D given a set of patterns (which are represented as formulae in the probabilistic model as we shall see) R and the model weights w; and k.k1 is the  1-norm.
The data corpus D and the pattern set R are updated at each iteration.
For D, by changing, we mean that new relation tuples are identi ed.
For R, the change is in the sense that new patterns are added.
In the problem P, the loss can be the log-loss as used in probabilistic models or the hinge loss as used in support vector machines [6].
In this paper, we focus on the log-loss.
This  1-norm regularized MLE problem yields a sparse estimate by setting some components of w to exact zeros [24, 11] and has e cient solvers, such as the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN) method [2].
In this section, we de ne the task of entity relationship identi cation and present the probabilistic models we applied in StatSnowball, including the training and inference (extraction) parts in P2.
The task of StatSnowball is to identify related entity pairs and detect the keywords that indicate the relationships.
Like many other relation extraction systems [1, 8, 9], we assume that entities are given.
In probabilistic models, the task of relation extraction is to predict whether two entities ei and ej have a relation R based on the probability p(R(ei, ej )|O).
For relation keyword detection, the task is to predict whether a token is a relation keyword.
In StatSnow-ball, we de ne three  elds (labels) that a token can belong to, namely, REL-S: the start of a relation; REL-C: a continuation of a relation; and NULL: not a relation keyword.
We assume that each token can belong to one  eld.
Then, relation keyword detection is to predict in which  eld (label) f the token t is most likely to be based on the probability p(InF ield(t, f )|O), where f   {REL-S, RES-C, NULL}, and O denotes the observations that are available to make the prediction.
In discriminative models, O can be arbitrary features of the inputs, e.g., the text content of a token or its neighboring tokens.
Based on the power of available probabilistic models, we can de ne the task at three di erent levels: a. Entity-Level: this is the simplest extraction model with a strong independence assumption that whether two entities have some relationship is independent of other entities and is also independent of relation keyword detection.
Logistic regression (LR) model is for this task.
b. Sentence-Level: since in human languages, the words in a sentence are not independent of each other to express a speci c meaning, the independence assumption of the Entity-Level model is too strong.
A Sentence-Level model relaxes this assumption and treats a sentence as a whole input and jointly detects whether a pair of entities (if any) in that sentence have some relationship and whether the tokens around the entities indicate the relation type.
One example is presented in [4], where entities are assumed to be at the ends of a sentence and the tokens in-between are classi ed to be relation keywords or not by a linear-chain
 c. Page-Level or Corpus-Level: since the sentences in a webpage or a text document are not completely independent, it may be desirable to jointly extract these related sentences.
Joint inference has been shown to be e ective to get globally consistent extraction results, such as [17,
 to jointly model correlated data.
We provide this alternative and will empirically demonstrate the advantages of joint inference in StatSnowball.
As we have stated, we can use any probabilistic model in StatSnowball.
In order to accommodate the above three levels of relationship extraction, StatSnowball adopts the most general MLN model, which can be con gured to do the LR-based Entity-Level and the CRF-based Sentence-Level relation extraction, as we shall see.
A  rst-order knowledge base contains a set of formulae, which are constructed using constants, variables, functions, and predicates.
Constants are the objects (e.g., entities and tokens) in the interested domain and variables range over the objects.
For example,  Bob  and  Jim  are two people entities, and  killed  is a token.
e and t are variables which denote an entity and a token, respectively.
A function is a mapping from a set of objects to objects (e.g., MotherOf(ei)) and a predicate represents a relation among objects (e.g., HasRelation(ei, ej) or some attributes (e.g., IsPeople(ei)).
An atom is a predicate applied to a set of arguments, which are constants or variables.
If an atom s arguments are all constants, it is a ground atom.
A world is an assignment of truth values to all possible ground atoms.
If a world violates one formula, it is impossible.
Thus, the formulae in a  rst-order logic can be viewed as a set of hard constraints on the possible worlds.
Markov logic is a probabilistic extension and softens the hard constraints by assigning a weight to each formula.
The weight indicates how strong the corresponding formula is.
When a world violates some formulae it is less impossible, but not impossible.
For the task of entity relation extraction, we know the query predicates and the evidence predicates a prior.
Thus, we partition the ground atoms into two sets the set of evidence atoms X and the set of query atoms Q, and de- ne a discriminative MLN [23].
Discriminative models have shown great promise as compared to generative models in many applications [15, 23].
In StatSnowball, X can be all the possible features we can extract from the inputs, and Q can be all the relationship queries R(ei, ej),  i 6= j and keyword detection queries InF ield(t, f )  t, f .
Given an input x (e.g., a sentence and its features), the discriminative MLN de nes a conditional distribution p(q|x) as follows: wigj(q, x)(cid:17), exp(cid:16) X p(q|x) =
 (1)
 Z(w, x) i FQ j Gi where FQ is the set of formulae with at least one grounding involving a query atom, Gi is the set of ground formulae of factor, also known as partition function in physics.
gj(q, x) is a binary function and equals to 1 if the jth ground formula is true and 0 otherwise.
Markov Logic Networks have the power of  rst-order logic to model complex relational databases.
In the experiments, we will show examples of using MLN to do joint inference in StatSnowball.
In StatSnowball, we apply the discriminative learning algorithm [23, 10] to learn the model weights with a sphere Gaussian prior, or equivalently the  2-norm penalized MLE, to avoid over tting.
As we have stated, logistic regression (LR) is the simplest Entity-Level extraction model.
It makes a strong independence assumption that entity pairs are independent of each other to have some relationship.
Also, the existence of a relationship is independent of relation keyword detection.
By restricting all the formulae in MLN to be the ones in which the query predicates can appear ONLY ONCE, the resultant MLN reduces to an LR model, and the distribution in Eq.
(1) has the factorized form: p(q|x) = Qij p(R(ei, ej )|xij)Qt p(InF ield(t, ft)|xt), of which each component is an exponential family distribution.
For example, p(R(ei, ej )|xij) has the exponential form: p(R(ei, ej)|xij )   exp(cid:0) Pi FR Pj Gi wigj(R(ei, ej ), xij)(cid:1), where FR are the formulas in which the query predicate R appears.
The observations are the inputs xij related to the entities ei and ej .
For relation keyword detection, p(InF ield(t, f )|xt) has the similar distribution form.
In a Sentence-Level extraction model, entities and the tokens in the same sentence are not independent.
Without context tokens, we cannot decide whether two entities in a sentence have some relationship.
On the other hand, whether a token is a relation keyword is dependent on its surrounding tokens.
For example, for the sentence  Google forced to buy YouTube. , which contains the entities  Google  and  YouTube , the verb  buy  indicates an acquirement relationship between the two entities and the verb  forced  is not a relation keyword because the following  buy  is more likely to be.
The LR model cannot consider this mutual dependence information.
Instead, for Sentence-Level extraction, we need to apply the linear-chain conditional random  elds (CRFs) [15].
The MLN reduces to a linear-chain CRF by de ning the following  rst-order formulae: InField(ti, REL-S)   Verb(ti+1) => InField(ti+1, REL-C), which means when a token is the start of a relation (REL-S), then the following verb is more likely to be a continuation of the relation (REL-C).
One application of CRFs to identify relation keywords is presented in [4].
The second step of the part P2 is to extract new relation tuples, which is an inference problem in probabilistic models.
Suppose the current MLN model is M. For each pair of entities (ei, ej), we use M to predict whether a relationship exists between ei and ej with the probability p(R(ei, ej )|xij, M).
For each token t, we use M to predict whether t is a relation keyword.
Here, the query R(ei, ej) is a binary predicate and equals to 1 if a relationship exists between ei and ej and 0 otherwise.
Thus, it is natural to use the probability p(R(ei, ej )|xij, M) as a con -dence measure of the identi ed new tuple.
We can choose a threshold c and keep the candidate extraction (ei, ej) only if p(R(ei, ej)|xij, M) > c. The higher the c, the stricter the decision rule is.
If a high c is chosen during the iterations of StatSnowball, only high-quality relation tuples are selected and passed to the next step for generating patterns.
For relation keyword detection, the query InF ield(t, f ) is ternary.
We predict each token t to the label f which has the highest probability, that is, f   = arg maxf p(InField(t, f )|xt, M).
Similar to the use of p(R(ei, ej)|M), we can use the probability as a con dence measure of the extraction.
For the probabilistic models we are using in StatSnow-ball, the computational cost of both training and inference mainly depends on two factors the number of queries and the complexity of the model.
Since the number of relation keyword detection queries is linear to the number of tokens, we only consider the relation query R. For logistic regression, the model is very simple and the cost depends on how many relation queries are formulated.
For the linear-chain structured CRF [15], it is also very e cient to do inference and learning by using dynamic programming methods.
Moreover, as a Sentence-Level extraction model, the number of relation queries in CRFs is linear to the number of sentences.
For the general MLN, its complexity depends on the number of formulae and their formulations.
As we shall see, StatSnowball only generates very simple formulae.
Thus, the cost mainly depends on the number of relation queries.
Na vely formulating all possible relation queries for every combination of two entities, as in the current Alchemy3, the whole number of queries is quadratic to the number of entities in a corpus for both LR and MLN.
In our application of relation extraction, only when the entities appear within a short range, they could have enough evidence to indicate some relation between them.
For two isolated entities, even human readers could have di culty in deciding whether they have a relationship.
Thus, we make some gentle assumptions in StatSnowball.
For example, in Page-Level extraction models, we can assume that only the entities appearing in the same webpage/document are likely to have some relationship.
When formulating the relation queries, entities in di erent pages/documents are not considered as a candidate.
Similarly, for Sentence-Level extraction models, we can assume that only entities appearing in the same sentences are likely to have relations; otherwise, they do not.
These assumptions can signi cantly reduce the number of queries.
For example, suppose we have 200 entities in a corpus of 20 webpages and uniformly each page has 10 entities.
Without any assumptions, the number of possible queries will be 200   200 (4   104) for all the combinations of two entities.
If we make the assumption that only the entities in the same page are possible to be related, then only 20   10   10 (2   103 or 5 percent) queries are possible to be relation tuples.
All the other queries are discarded and consume no resources.
With the above independence assumption, an online learning method can be used for the learning of MLN.
We implemented this technique for the learning of MLN too.
3http://alchemy.cs.washington.edu.
In this section, we present how to generate and select good extraction patterns in StatSnowball.
Generating new extraction patterns, which are used to compose the formulae of MLNs, is a key component of Stat-Snowball.
A good pattern should achieve a good balance between two competitive criteria speci city and coverage.
Speci city means the pattern is able to identify high-quality relation tuples; while coverage means the pattern can identify a statistically nontrivial number of good relation tuples.
In Snowball, the generated patterns are mainly based on keyword matching.
These strict patterns can have very high precision, but the coverage (i.e., recall) is very low.
As we have stated, there are two reasons why Snowball cannot e ectively incorporate general patterns, which can signi -cantly improve the recall as we shall see.
First, Snowball was originally proposed to extract a speci c type of relationship, for example, companies and their headquarters [1].
In this case, general patterns can yield many invalid extractions, although these extractions could be other types of valid relation tuples.
Second, Snowball de nes some measures and criteria which are not applicable to general patterns.
For pattern evaluation, Snowball de nes a con dence measure as the ratio of positive extractions of that pattern.
For general patterns, the con dence scores could be very small, and it is di cult to select these patterns by using a threshold.
Instead of de ning some heuristic measurements, Stat-Snowball applies probabilistic models and renders the pattern selection as the  1-norm regularized optimization problem P. Under this framework, we can treat strict keyword matching patterns and general patterns identically.
Also, by using general patterns, StatSnowball can be con gured to perform open information extraction, as we have stated.
In our experiments, we evaluate both the Open IE and Snowball-like extraction with StatSnowball.
In our system, the keywords are from two parts.
The  rst part is from the initial seeds.
As shown in Figure 2, users can provide seeds with some keywords to indicate the relationships.
We take these keywords to de ne candidate patterns, e.g., a candidate pattern should contain at least one of these keywords.
The second parts of the keywords are those that are automatically discovered during the Stat-Snowball extraction process.
To make the patterns more informative, we only consider three types of keywords as in Table 1 according to the part-of-speech (POS) tags, where MIN OCCUR is pre-speci ed number, e.g., 20.
Here, we use the same naming system as the Penn Treebank Project 4.
Our general extraction patterns are all based on a shallow natural language processing (NLP) technique part-of-speech tagging (POS).
Much work has been done to investigate the usability of shallow or deep linguistic structures for various application tasks such as named entity extraction [7], and relationship identi cation [9, 8].
In contrast to deep natural language processing, shallow NLP techniques
 nn treebank pos.html are more robust and more e cient.
This is a very important factor for Web-scale relation extraction as in Renlifang.
Thus, StatSnowball only uses the part-of-speech tagging results.
All the sentences in our data sets are parsed using a part-of-speech tagger.
Our general patterns are the POS-tag sequences appearing between entities.
Note that the above two types of patterns are not necessarily independent of each other.
For example, the general pattern  POS+NP/NN  can be seen as a keyword matching pattern too because only one token is tagged as POS (i.e., possessive ending), that is,  s .
Selecting patterns is a feature induction problem of Markov random  elds or Markov networks [19, 16].
In MLN, the problem is called structure learning [12].
Alchemy uses a generative approach to learning the structure of MLN by using beam search to generate candidate formulae and selecting good candidates according to the gain in (weighted) pseudo-likelihood.
In StatSnowball, we apply the  1-norm regularized MLE as de ned in the problem P and do dis-criminative structure learning [10].
As we have stated, the  1-norm penalty encourages a sparse estimate [25].
Speci cally, we  rst use the generated patterns to formulate a set of candidate formulae of MLN.
Then, we apply the algorithm [2] to optimize the  1-norm penalized conditional likelihood function as in the problem P, which yields a sparse model by setting some formulae s weights to zeros.
The zero-weighted formulae are discarded and the resultant model is passed to the next step for retraining.
Our method can be viewed as a simpli ed variant of the discriminative structure learning [10].
Since our patterns (i.e., predicates) have been generated, we can generate the candidate formulae easily instead of applying an ILP system such as Aleph to do this from scratch.
Here, we generate the formulae with the N nary (e.g., binary or ternary) combination of the patterns.
As in [10], we restrict the formulae to be non-recursive de nite clauses, in which query predicates only appear once.
Under this constraint, the model is equivalent to a logistic regression model with a set of automatically generated features (i.e., extraction patterns).
For complex formulae, which contain multiple query predicates and can be used for joint inference in MLN, we do not automatically generate them because these formulae are very general and the number of these patterns is very small, as we shall see in the experiments.
We manually design these formulae and add them to the model in each iteration of StatSnowball.
To compare with, we also use a heuristic-based method in our experiments to select patterns.
Speci cally, we use the generated patterns and formulate a set of candidate formulas.
Then, we apply some heuristic rules to select these formulas and learn the resultant model s weights.
For example, a formula will be selected if the number of its covered instances is above a certain threshold (e.g., 10).
In this section, we report some empirical results of Stat-Snowball with di erent con gurations.
We compare Stat-Snowball with O-CRFs [4] for Open IE and show the advantages of joint inference by using MLN in StatSnowball.
We also compare StatSnowball with Snowball on a large Web data corpus for traditional relation extraction.
We show that Types Requirements


 not stop word and occur more than MIN OCCUR times if the token appear more than MIN OCCUR times and the previous token is a noun phrase the following token is a noun phrase Example (e1, killed, e2) (e1, mother of, e2) (e1,  s mother, e2) by elegantly incorporating general patterns, StatSnowball achieves signi cantly higher precision and recall.
Finally, StatSnowball is e cient and has been applied to Renlifang.
Our experiments are performed on two data sets.
The  rst one is the published corpus [4] and will be referred to as Sent500.
This data set contains 500 sentences and each sentence has one pair of entities (noun phrases).
In [4], CRFs are used to do sequence labeling and identify the words that represent a relationship between the two entities.
The second corpus is built from the MSN news crawler.
To remove noise, such as page heads, navigation bars, etc., we  rst partition the crawled webpages into blocks using a visual parser [28].
The blocks in the center of a webpage are selected to compose our data set.
All the text sentences in the blocks are parsed using a part-of-speech tagger to get the POS tagging results.
We collect 1 million such blocks and will refer to this data set as Web1M.
We report the experiments and results on two data sets separately as follows.
On Sent500, we perform two types of experiments.
The  rst experiment is to demonstrate the advantages of MLNs over CRFs.
In [4], CRFs are used to label the words between two entities (noun phrases) as a sequence labeling problem.
In this experiment, we apply the MLN to do the similar sequence labeling task but with joint inference and show its advantages.
The second experiment is to use StatSnowball to do Open IE and identify the unknown entity relationships.
We compare StatSnowball with O-CRFs [4].
We also compare two StatSnowball systems with di erent pattern selection methods, i.e., the  1-norm regularized pattern selection and heuristic-based pattern selection.
We will refer to these two StatSnowball systems as  1StatSnowball and heS-tatSnowball, respectively.
As in [4], we evaluate on four categories of relations, that is, Verb, Noun+Prep, Verb+Prep, and In nitive.
On Web1M, we con gure StatSnowball to do the traditional relation extraction and compare it with Snowball.
We compare MLNs and CRFs on Sent500 to do sequence labeling on sentences and label tokens to be REL-B, REL-C, or NULL.
The set of features used in this experiment are similar to the features as used in O-CRFs [4], including POS tags, token relative position and context features.
In CRFs, sentences are labeled independently.
To do joint inference in MLN, we  rst group the sentences according to the similarity between their tokens.
In total, 76 groups are identi ed in Sent500.
For similar tokens (i.e., tokens in the same group), we de ne the following formula to do collective labeling: SimiToken(t1, t2)   F1(t1)   F2(t2)   InField(t1, +f )   InField(t2, +f ), Table 2: Evaluation results of MLNs with joint inference and the basic CRFs on the Sent500 data set Categories







 verb noun+prep verb+prep in nitive overall























 where the predicate SimiT oken(ti, tj) is true if ti is similar to tj, false otherwise.
Basically, this formula says that similar tokens (grouped together) should have the same label if they also have some token-level features Fi.
We will refer to the above two methods as CRF and MLN respectively.
Table 2 shows the average results over 10 runs.
In each run of the basic CRF, we randomly select 50 percent of the sentences as training and test on the rest (di erent from the experiments in [4]).
For the joint MLN, we randomly select a half of the groups as training data and test on the rest.
From the results, we can see that the joint inference in MLN performs much better, almost on all the four categories, than the CRF model, which treats the sentences independently.
The performance of MLN on Verb is slightly worse than that of CRF.
As we have stated, StatSnowball can be con gured to do Open IE.
Here, we compare StatSnowball on the Sent500 with the state-of-the-art Open IE system, that is, O-CRFs [4].
All the patterns used in StatSnowball are the general POS tag sequences, except that we use the preposition keywords (like  in  and  of ) to distinguish the tokens that are tagged as  IN  by the POS tagger.
We randomly select 30 sentences as initial seeds for the two StatSnowball systems that use di erent pattern selection methods (i.e.,  1-norm regularized and heuristic based methods).
The results are shown in Table 3, where the results of O-CRFs are from the original paper [4], and the results of StatSnowball systems are the average results over 10 runs.
For the  1StatSnowball, using di erent regularization constants (i.e.,  ) during the iterations could improve the performance.
In all the experiments, we do not tune the parameter but set   at 0.5.
From the results, we can see that the O-CRFs generally achieve higher precisions, especially on  Verb+Prep  and  In nitive .
In contrast, StatSnowball systems achieve a better balance between recall and precision.
Thus, the overall F1 of both StatSnowball systems are signi cantly better than that of the O-CRFs.
Also, we can see that the heuristic-based pattern selection method works much worse than the  1-norm regularized pattern selection method in StatSnowball.
Figure 3 shows the performance of the two StatSnowball systems with respect to the number of iterations.
The results are from one run.
We do not take the average over 10 Categories O-CRFs [4]
 Recall Precision 0.939

 Precision 0.956

 Precision 0.929


 Verb Noun+Prep Verb+Prep In nitive Overall




































 heStatSnowball Recall  1StatSnowball Recall i i n o s c e r










 l l a c e

























 L1 norm Heuristic

 Iteration L1 norm Heuristic

 Iteration L1 norm Heuristic

 Iteration Figure 3: The performance (precision, recall, and F1) of the two StatSnowball systems with di erent pattern selection methods during the iteration.
runs because di erent runs can have various iteration numbers, e.g., from 4 to 10.
We can see that during the iteration, both systems can  nd more relation tuples.
Moreover, the precision of heStatSnowball decreases a lot, while the precision of  1StatSnowball does not change much, although with a slight decrease.
Overall, the F1 curve of  1StatSnowball is consistently above that of heStatSnowball.
Also, the former is increasing and the latter decreases a little.
Similar to the  rst experiment using MLN to do joint inference, we incorporate the joint inference to StatSnow-ball.
We do not automatically generate these joint inference formulae.
This is because the joint inference formulae are general and the number is very small (only 1 as shown in Section 5.2.1).
Thus, it would be much harder to automatically generate these formulae and also it may cause di culty in selecting them.
Instead, we apply a simple strategy here.
We manually de ne these joint formulae as in Section 5.2.1.
During the iterations of StatSnowball, we automatically generate and select the simpler formulae, each of which contain only one query predicate, and add the joint formula to the resultant model to learn an MLN for joint inference.
For the joint StatSnowball, the sentences in Sent500 are grouped as in Section 5.2.1.
We randomly select 10, 15, and 25 groups as starting seeds, and take the average over 10 runs as the  nal results.
Table 4 shows the overall performance of the  1StatSnowball with joint inference, the heStatSnowball with joint inference, and the  1StatSnowball without joint inference.
From the results, we can see that the  1StatSnowball with joint inference always performs the best compared to the other two systems.
Also, for all the three systems, the performance consistently gets better when more seeds are provided.
Similar to Figure 3, Figure 4 shows the performance of the two StatSnowball systems with joint inference with Table 4: Overall performance of di erent systems with di erent number of initial seeds.
# groups


  1StatSnowball

 (no joint inference) F1 0.681 0.758 0.779
 heStatSnowball
 (joint inference) F1 0.728 0.739 0.786

  1StatSnowball (joint inference) F1 0.796 0.800 0.837









 l l a c e

























 L1 norm Heuristic

 Iteration L1 norm Heuristic

 Iteration L1 norm Heuristic

 Iteration i i n o s c e r
 Figure 4: The performance (precision, recall, and F1) of the two StatSnowball systems with joint inference during the iteration.
respect to the number of iterations, and the results are from one of the ten runs.
We can see that the  1-norm regularized pattern selection method consistently outperforms the heuristic-based method, especially on recall and F1.
Since for the large data corpus Web1M, labeling all the relations is impractical, it is di cult to quantitatively evaluate the Open IE as in [4].
To give a quantitative analysis of StatSnwoball, we con gure it to extract prede ned relations, as in the traditional use of Snowball.
Here, we focus on the  Wife  and  Husband  relationships.
We want to identify all the entity pairs (ei, ej), where ei is the wife or husband of ej.
Similar to the previous evaluations, the relation extraction is a sequence labeling problem.
But in this task, we predict the tokens between each entity pair as either REL-R (i.e., a relation keyword) or NULL.
Our extraction patterns are based on both the general POS tags and the strict keyword matching.
For example, we use the POS tag sequence between the entity pairs as a candidate extraction pattern.
we only generate the patterns that contain at least one of the relation keywords provided with the initial seeds.
As we have stated, the MLN model in StatSnowball has the great  exibility to do joint inference.
Here, we provide another example of using StatSnowball to perform joint relation extraction.
In this experiment, the two types of relationships we are concerned with are strongly correlated.
For example, if e1 is the husband of e2, then e2 is more likely to be the wife of e1 if we ignore the issue that multiple entities can have the same name.
We incorporate this prior knowledge of dependency into the MLN model in StatSnowball by de ning the following formula: IsHusband(e1, e2)   IsWife(e2, e1).
Using this formula, the MLN can jointly extract the two types of relations.
We refer to this system as StatSnowball (Joint) and refer to the StatSnowball without the above formula as StatSnowball (Basic).
Similar to the previous use of StatSnowball for joint inference (see Section 5.2.3), we only generate formulae that contain only one query predicate and manually add the above formula during the iterations.
The original Snowball system [1] uses strict keyword matching patterns.
To see how the performance changes with general patterns, we con gure another Snowball system with additional general patterns based on POS tags.
We refer to this Snowball system as PosSnowball.
The evaluation criteria of patterns and extraction tuples in PosSnowball are the same as those in the original Snowball.
To start the iteration process, StatSnowball (Joint) uses
 systems perform the extraction of  Wife  and  Husband  separately with the corresponding seeds.
All the extracted tuples are sent to human readers to judge whether they are correct extractions.
Figure 5 shows the number of correct tuples and the precision of the identi ed tuples with respect to the number of iterations.
From the results, we can see that StatSnwoball systems identify much more correct relation tuples with a signi cantly higher precision on all the identi ed tuples than the Snowball systems, especially the Snowball using only keyword-matching patterns.
It is interesting to note that by using the simple joint inference formula as de ned above in StatSnowball, we can  nd more accurate tuples, but with a slightly lower precision compared to the StatSnowball without this formula.
The results of PosSnowball show that using general POS tag-based patterns can signi cantly improve the recall.
Finally, during the iterations, although the number of correct tuples grows in Snowball systems, the precision decreases very quickly.
In StatSnowball, however, we can get more correct tuples without sacri cing the high precision.
The StatSnowball is e cient.
It takes about 50 minutes to  nish the experiments on Web1M with a standard single-core desktop computer.
That means 1 billion Web blocks can be processed by StatSnowball within 1 day by using
 relation search engine, as shown in the introduction, which indexes the entities (people, locations, and organizations) and their relationships extracted from 10M Web blocks.
Relation extraction has been promoted by the Message Understanding Conference and Automatic Content Extrac-l s e p u
 d o o
 #









 Snowball PosSnowball StatSnowball (Basic) StatSnowball (Joint)




 Iteration

 i i n o s c e r












 Snowball PosSnowball StatSnowball (Basic) StatSnowball (Joint)




 Iteration Figure 5: The number of correct relation tuples (left plot) and the precision of the extracted results by di erent methods.
tion program.
The task has been traditionally studied as to extract prede ned semantic relations between pairs of entities in text.
The supervised methods [27, 8, 9, 26] require a set of human-tagged examples of the prede ned relations.
Bootstrapping methods [5, 1, 7] signi cantly reduce the number of training examples by iteratively discovering new extraction patterns and identifying entity relations with a small set of seeds, either target relation tuples [1] or general extraction templates [7].
However, the system [1] only generates patterns that are mainly based on keyword matching and its evaluation criteria are also speci c to these strict high-precision but low-recall patterns.
Another bootstrapping system KnowItAll [7] requires large numbers of search engine queries and webpage downloads.
Open information extraction (Open IE) [3] is a domain independent extraction paradigm and has been studied in both the natural language document corpus [22] and the Web environment [3] to extract relation tuples.
Open IE can extract unknown relations from heterogeneous corpora.
As we have stated, StatSnowball di ers from the Open IE methods in several aspects.
For example, Open IE systems require human-selected features to learn a good extractor, while StatSnowball automatically generates and selects the extraction patterns; Open IE systems require the use of deep linguistic parsing techniques to correctly label training samples, while StatSnwoball only uses cheaper and more robust shallow parsing techniques to generate its patterns; and the start-of-the-art Open IE system O-CRFs [3] use CRFs to label each sentences independently, but StatSnowball can perform joint inference, which can yield better extraction results.
Pattern selection in StatSnowball is the problem of structure learning in Markov logic networks [12] or the problem of feature induction in Markov random  elds [19, 16].
Similar to the feature induction of MRFs, where features are assumed to be composed from basic features, structure learning [12] is studied under the assumption that candidate formulas can be constructed from predicates via some operators like addition and  ipping.
Statistic predicate invention in Markov logic networks, also known as hidden variable discovery in statistical learning, is studied in [13], which can generate and select new predicates that are expressed in terms of existing ones via iterative clustering.
Both structure learning and statistical predicate invention can be too expensive to be applied to a large data set.
The discrimina-tive structure learning of MLN [10] applies  1-norm regularized MLE to select candidate formulas generated by a  rst-the candidate formulas iteratively from extracted relation tuples.
[8] C. Giuliano, A. Lavelli, and L. Romano.
Exploiting shallow linguistic information for relation extraction from biomedical literature.
In EACL, 2006.
This paper presents a statistical entity relation extraction system called StatSnowball.
By adopting a bootstrapping architecture, StatSnowball signi cantly reduces the number of human-tagged examples.
By elegantly incorporating general extraction patterns, StatSnowball can signi cantly improve the recall and can be con gured to perform open information extraction (Open IE).
StatSnowball uses the general relational model Markov logic networks (MLNs), which can be con gured to perform di erent levels of relation extraction and can perform joint inference.
Our empirical studies show that by using joint inference in MLN and StatSnow-ball, performance can be improved.
Finally, by applying the  1-norm regularized maximum likelihood estimation, which enjoys well-founded theories and e cient solvers, StatSnow-ball is e cient and can perform well on large scale Web data.
We have built an entity relationship search engine called Renlifang based on it.
The statistical StatSnowball opens broad ways for future improvements and extensions.
Currently, we apply a named entity extraction method to process the data sets to get the entities.
It is interesting to integrate StatSnowball with named entity extraction methods and build a self-contained extraction system.
This tightly integrated approach allows information  ow between two tasks and can obtain better performance by using joint inference [28, 17, 20].
Similarly, the optional P3 part in StatSnowball can be integrated into P2 as suggested by the relational clustering methods [14].
The authors Jun and Bo are supported by Chinese Nature Science Foundation Grant 60621062 and 60605003; National Key Foundation R&D Projects 2003CB317007, 2004CB318108 and 2007CB311003; and Basic Research Foundation of Ts-inghua National Lab for Info Sci & Tech.
Jun is also supported by a Microsoft Fellowship.
