Users who pose a query to a web search engine often have specific information needs in mind, such as finding the address of a business, an article about a historic event, a company s home page, and so on.
Users select pages by clicking on links on a search engine result page that deem to be closely relevant to their intended information needs.
Considering collective filtering, it is reasonable to assume a frequently clicked set of pages for a query reflects the kinds of information that the users intend to find by posing the query.
Further, it is observed that users of similar information needs click on a similar set of pages, even though the queries they pose may vary, thus forming a cluster of queries and clicked pages that are more strongly connected to each other than with the rest of queries and clicked pages.
Based on the observations, we hypothesize queries within such a cluster express highly similar information needs and intention and group such queries into a cluster.
We have designed a query clustering method that takes into account the query and clicked page relationship, not considering syntactic or semantic features on the query, such as keywords.
It is known that approaches based on keywords are not very suitable for query clustering because of the short lengths of queries [5].
We represent the query and click-through page relationships by a directed bipartite graph that consists of a set of queries, a set of Copyright is held by the author/owner(s).
connecting nodes in V1 and V2.
To generate maximal bicliques, G is transformed to a general graph G =(V1 V2, E ), where E =E  (V1 V1) (V2 V2).
Then the maximal clique generation algorithm for a general graph, such as the one in [4], can be applied on G .
This algorithm, however, requires an increased amount of the main memory space proportional to the entire expanded graph.
We deal with a very large click-through graph that would hardly fit into main memory.
We instead modified the bipartite core generation algorithm in [2] to generate maximal bicliques.
One of the major advantages of the algorithm is that it does not require to store the entire graph in memory.
Instead it applies various pruning techniques on sorted lists of nodes; one for queries, and another for pages for click-through graph.
The algorithm can be further optimized to sort only once, and build only a small index in main memory.
Since we are looking for query clusters larger than certain size, queries and pages of which in and out-degrees do not meet the minimum size requirement can be eliminated.
To compute a biclique of size (i,j), query nodes with out-degree smaller than i and their outgoing edges are pruned.
Similarly, any page node with in-degree smaller than j and its associated edges are pruned.
This pruning step is iteratively applied until there exists no more such nodes.
At each step of the biclique generation algorithm we either generate a biclique, or exclude a node and the associated edges from the graph.
After generating a biclique, the subgraph corresponding to the biclique is removed from the click-through graph.
Starting from the maximum out-degree size, we repeat the following steps iteratively for each decreasing value of i:
 degree i, and list the neighbors of each qk, P(qk).
Q(pl), of each page, pl  P(qk).
(An index on the page URLs is used for better performance.)
, and E .
(m   be a set of all edges between
 and P(qk).
j), generate a biclique of size (i,m),   P(qk), E).
After generating a biclique, ( remove all query and page nodes, and edges in the biclique from the click-through graph (unless the node is a part of another cluster).
that do not connect to a query node in the intersection .
(This removes edges between the bicliques, the edges that cross the cut lined on Figure 1.)
After removing all edges, apply the iterative pruning before continuing with the next iteration with out-degree size i-1.
The generated bicliques are maximal.
For each biclique generated, the query set, an equivalence set that becomes a query cluster.
forms

 After preprocessing with  =2, there remain ~1.15M and ~2M query and page nodes, and ~68M edges in the sample graph, reduced from ~16M and ~10M nodes and ~ 92M edges, respectively.
Figure 2: Number of query clusters if they slightly violate Figure 2 plots the number of query clusters extracted by our algorithm.
As expected, the numbers of maximal bicliques drop significantly as the size of the cliques grow.
The number may be interpreted as lower bound of query clusters, as our method considers only maximal bicliques.
As we relax the equivalence condition and consider strongly connected, but not necessarily completely connected bipartite subgraphs as the candidates, it may further reveal interesting quasi-equivalence sets of queries.
Due to the strict requirement of complete connectedness of the clusters by the current algorithm, many potentially interesting query clusters are excluded the requirements.
We have studied a problem of discovering query clusters and proposed an algorithm that utilizes click-through data from search engine query logs.
The proposed method identifies all bicliques and all queries in a biclique are equivalent in terms of user information needs.
In the future, we plan to extend the algorithm to consider quasi-bicliques as candidates of query clusters.
This is expected to be a more robust algorithm under the presence of slightly irregular click patterns, if the threshold is properly set.
We plan to apply a frequency weight of each edge between a query and a clicked page to distinguish noisy clicks.
