Suggesting high quality bidterms to advertisers received signi cant attention in recent years, since relevant and profitable bidterms lead to improved ad clickability and increased conversion rates.
Bidterm suggestion is similar to query expansion in mainstream IR [3] and in ad retrieval [9].
Existing approaches to bidterm suggestion rely on three main data sources: search engine results [1, 2, 6, 8], search engine logs [2] and advertiser bidding patterns [2, 5].
We describe a large-scale bidterm suggestion system that seeks to model the user s intent implicitly targeted by an ad, and  nds new bidterms consistent with that intent.
Ad intents are derived from a large collection of bidterm sets explicitly enumerated by advertisers (obtained from Yahoo s ad database), rendering our system close in spirit to [2] and [5].
In contrast to previous work that uses advertiser bidding patterns, our methods use second order co-bidding information and run on an industrial size database rather than on small test sets.
We also demonstrate that the system increases the coverage of Yahoo s state of the art production system while maintaining the same precision.
The intent (or information need) of a search engine user is expressed as short textual queries [7].
A typical ad consists of a set of bidterms (search terms purchased by the advertiser) whose underlying intents are likely to cause a user to  The research described herein was conducted while the  rst author was a summer intern at Yahoo!
Copyright is held by the author/owner(s).
be interested in the advertised product or service.
Given a very large collection of such ads, we can begin to learn mappings between bidterms and the hidden intents.
We hypothesize that most ads try to capture a small set of intents (e.g., the purchase of a speci c product or service), and therefore the set of bidterms in an ad is likely to be associated with the same hidden intent.
Given a bidterm b, we model its set of hidden intents by the set of all other bidterms co-bidded with b (i.e., other bidterms occurring in the same ad as b).
Some co-bidded terms are more discrimi-native than others so we weigh them by the strength of their association with b as follows.
Let P M I(b) = (pmib1 , pmib2 , .
.
.
, pmibm ) denote a point-wise mutual information feature vector, constructed for each bidterm b, where pmibf is the pointwise mutual information between bidterm b and co-bidded term f : pmibf = log (cid:80)n (cid:80)n cbf
   i=1 cif
 j=1 cbj
 (1) where cbf is the number of times b and f are co-bidded, n is the number of unique bidterms, and N is the total bidterm occurrences.
By our hypothesis, two bidterms that capture the same intents will have more similar feature vectors than two bidterms that capture di erent intents.
In this paper, we de ne the similarity between two bidterms bi and bj using the cosine similarity metric between their PMI feature vectors, sim(bi, bj) = cosine(P M I(bi), P M I(bj)).
Bidterm suggestion algorithm (IDBS) Given an ad consisting of k bidterms, {b1, b2, .
.
.
, bk}, we rank each bidterm b ever seen in our ad network by summing sim(b, bi) for i = [1..k].
We call this system Intent-Driven Bidterm Suggestion (IDBS).
The calculation of the similarity between all pairs of bid-terms is computationally intensive.
A brute force implementation is O(n2f ), where n is the number of bidterms and f is the size of the feature space (f = n in our system).
For a large real-life collection of bidterms, optimizations and par-allelization are necessary.
Our optimization strategy follows a generalized sparse-matrix multiplication approach [10], which is based on the observation that a scalar product of two vectors depends only on the coordinates for which both vectors have nonzero values.
Similarly, cosine similarity is determined solely by the features shared by both vectors.
Since most of our feature vectors are very sparse (i.e., most bidterms never co-occur with any particular bidterm), the computation can be greatly sped up.
Determining which vectors share a non-zero
 Table 2: Added value vs. Yahoo s production system Ad Bidterms 22 sail boat 23 sail boat 24 sail boat 25 sail boat capri catalina catalina capri catalina sail boat IDBS Suggestions sail boat sales old sail boat boat for sale by owner used boat for sale used yacht sailing boat used power boat for sale sail boat for sale by owner Precision
 Added Coverage Baseline
  0%
 IDBS Combined
  5%

  5%
 (cid:80) i N 2 feature can easily be achieved by  rst building an inverted index for the features.
The computational cost of IDBS is i , where Ni is the number of vectors that have a nonzero ith coordinate; this cost can be further reduced by thresholding low PMI values.
On our datasets, we observed near linear average running time in the corpus size.
Our MapReduce implementation is an extension of the approach of Elsayed et al. [4].
We randomly sampled 200 ads from Yahoo s sponsored search ad database, such that each ad had fewer than 50 bidterms.
We scraped the Yahoo production bidterm suggestion system, a variant of [2], which generates up to 11 suggestions for each ad.
We also generated up to 11 suggestions using IDBS and a baseline system, which was a simpli cation of IDBS where a bidterm is represented by a vector of ids of the ads to which it belongs ( rst order co-occurrence), similar to [2] and [5].
We extracted statistics to build our baseline and IDBS using Yahoo s ad network.
We experimentally set the cosine thresholds for the baseline to 0.1 and for IDBS to 0.4.
Table 1 shows sample IDBS output.
Each bidterm suggestion from each of the three systems was manually judged by two editors.
The editorial guidelines asked the judges to mark a suggestion as correct if any reasonable intent that would generate the suggestion as a search term matches any reasonable intent captured by the ad bidterms1.
Our intent-based judgments yielded high inter-annotator agreement: the kappa score is 0.86 on the 2,045 judged suggestions.
Using the editorial judgments, we assess system performance using macro-averaged precision and coverage statistics.
Coverage is de ned as the ratio between the number of suggestions produced by a system and the maximum number of allowed suggestions (11 per ad in our setup, to match the Yahoo production system).
Our hypothesis is that the Yahoo production system would generate much higher coverage than IDBS since it has access to many more features such as session logs and click data [2].
We show below, however, that IDBS adds value by making accurate suggestions when Yahoo s production system fails to do so.
Yahoo s overall precision was 0.87  0.02 (95% con dence) with a coverage of 43%.
IDBS achieved half the coverage for the same precision, however Table 2 shows that our system adds 13% coverage to the Yahoo system with little loss in Figure 1: Interpolated precision vs. added coverage precision.
Table 2 also lists the added value of our baseline and that of Combined, a fourth system that combines the baseline system with our intent-driven system by interlacing the suggestions.
Combined achieves the same precision as Yahoo s production system and increases its coverage by
 added coverage relative to the Yahoo production system.
This paper presents a large-scale bidterm suggestion system that models an advertiser s intent and  nds new bidterms consistent with that intent.
Preliminary experiments show that our system increases the coverage of Yahoo s production system by 13% while maintaining comparable precision.
