Billions of queries are submitted to search engines on the Important attributes of these search ac-web every day.
tivities are automatically logged as implicit user feedbacks.
These attributes include, for each query session, the query string, the time-stamp, the list of web documents shown in the search result and whether each document is clicked or not.
Web search click logs are probably the most extensive, albeit indirect, surveys on user experience, which can be   summer internship with Microsoft Research.
Part of this work was done when the  rst author was on a Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
aggregated over weeks, months and even years.
Extracting key statistics or patterns from these terabyte logs is of much interest to both search engine providers, who could obtain objective measures of user experience and useful features to improve their services, and to world wide web researchers, who could better understand user behavior and calibrate their hypotheses and models.
For example, the topic of utilizing click data to optimize search ranker has been well explored and evaluated by quite a few academic and industrial researchers since the beginning of this century (e.g.
, [2, 8,
 A number of studies have been conducted previously on analyzing user behavior in web search and their relationship to click data.
Joachims et al. [9, 10] carried out eye-tracking experiments to study participants  decision process as they scan through search results, and further compared implicit click feedback against explicit relevance judgments.
They found that clicks are accurate enough as relative judgement to indicate user s preferences for certain pairs of documents, but they are not reliable as absolute relevance judgement, i.e. , clicks are informative but biased .
A particular example is that users tend to click more on web documents in higher positions even if the ranking is reversed [10].
Richardson et al. [16] proposed the examination hypothesis to explain the position-bias of clicks.
Under this hypothesis, a web document must be examined before being clicked, and user-perceived document relevance is de ned as the conditional probability of being clicked after being examined.
Top ranked documents may have more chance to be examined than those ranked below, regardless of their relevance.
Craswell et al. [4] further proposed the cascade model for describing mathematically how the  rst click arises when users linearly scan through search results.
However, the cascade model assumes that users abandon the query session after the  rst click and hence does not provide a complete picture of how multiple clicks arise in a query session and how to estimate document relevance from such data.
Click models provide a principled way of integrating knowledge of user search behaviors to infer user-perceived relevance of web documents, which can be leveraged in a number of search-related applications, including:   Automated ranking alterations: The top-part of ranking can be adjusted based on the inferred relevance so that they are aligned with users  preference.
  Search quality metrics: The inferred relevance and user examination probabilities can be used to compose isfaction [6].
  Adaptive search: When the meaning of a query changes over time, so do user click patterns.
Based on the inferred relevance that shifts with click data, the search engine can be adaptive.
  Judge of the judges: The inferred  rst-party relevance judgement could be contrasted/reconciled with well-trained human judges for improved quality.
  Online advertising: The user interaction model can be adapted to a number of sponsored search applications such as ad auctions [1, 11].
idr i(cid:79) Examine(cid:3)Next(cid:3) Document Click(cid:3) Through?
Yes See(cid:3)More(cid:3) Results?
No Done No Yes No Reach(cid:3)the(cid:3) End?
Yes Done An ideal model of clicks should, in addition to enabling reliable relevance inference, have two other important properties - scalability and incremental computation; Scalability enables processing of large amounts (typically, terabytes) of clicklogs data and the incremental computation enables updating the model as new data are recorded.
Two click models are recently proposed which are based on the same examination hypothesis but with di erent assumptions about user behaviors.
The user browsing model (UBM) proposed by Dupret and Piwowarski [5] is demonstrated to outperform the cascade model in predicting click probabilities.
However, the iterative nature of the inference algorithm of UBM requires multiple scans of the data, which not only increases the computation cost but renders incremental update obscure as well.
The dependent click model (DCM) which appears in our previous work [7] is naturally incremental, and is an order of magnitude more e cient than UBM, but its performance on tail queries could be further improved.
In this paper, we propose the click chain model (CCM), that has the following desirable properties:   Foundation: It is based on a solid, Bayesian framework.
A closed-form representation of the relevance posterior can be derived from the proposed approximation inference scheme.
  Scalability: It is fast and nimble, with excellent scala-bility with respect to both time and space; it can also work in an incremental fashion.
  E ectiveness: It performs well in practice.
CCM consistently shows performance improvements over two of the state-of-the-art competitors in a number of evaluation metrics such as log-likelihood, click perplexity and click prediction robustness.
The rest of this paper is organized as follows.
We  rst survey existing click models in Section 2, and then present CCM in Section 3.
Algorithms for relevance inference, parameter estimation and incremental computation are detailed in Section 4.
Section 5 is devoted to experimental studies.
The paper is concluded in Section 6.
We  rst introduce de nitions and notations that will be used throughout the paper.
A web search user initializes a query session by submitting a query to the search engine.
We regard re-submissions and reformulations of the same query as distinct query sessions.
We use document impression to refer to the web documents (or URLs) presented in the  rst result page, and discard other page elements such as sponsored ads and related search.
The document impression Figure 1: The user model of DCM, in which rdi is the relevance for document di at position i, and  i is the conditional probability of examining the next position after a click at position i.
can be represented as D = {d1, .
.
.
, dM} (usually M = 10), where di is an index into a set of documents for the query.
A document is in a higher position (or rank) if it appears before those in lower positions.
Examination and clicks are treated as probabilistic events.
In particular, for a given query session, we use binary random variables Ei and Ci to represent the examination and click events of the document at position i,respectively.
The corresponding, examination and click probabilities for position i are denoted by P (Ei = 1) and P (Ci = 1), respectively.
The examination hypothesis [16] can be summarized as follows: for i = 1, .
.
.
, M , P (Ci = 1|Ei = 0) = 0, P (Ci = 1|Ei = 1) = rdi , where rdi , de ned as the document relevance, is the conditional probability of click after examination.
Given Ei, Ci is conditionally independent of previous examine/click events E1:i 1, C1:i 1.
It helps to disentangle clickthroughs of various documents as being caused by position and relevance.
Click models based on the examination hypothesis share this de nition but di er in the speci cation of P (Ei).
The cascade hypothesis in [4] states that users always start the examination at the  rst document.
The examination is strictly linear to the position, and a document is examined only if all documents in higher positions are examined:
 P (Ei+1 = 1|Ei = 0) = 0.
Given Ei, Ei+1 is conditionally independent of all exam-ine/click events above i, but may depend on the click Ci.
The cascade model [4] puts together previous two hypotheses and further constrain that P (Ei+1 = 1|Ei = 1, Ci) = 1   Ci, (1) which implies that a user keeps examining the next document until reaching the  rst click, after which the user simply stops the examination and abandons the query session.
We  rst introduce the dependent click model (DCM) [7].
Its user model is illustrated in Figure 1.
It generalizes the cascade model to multiple clicks by putting position-dependent parameters as conditional probabilities of examining the next P (Ei+1 = 1|Ei = 1, Ci = 1) =  i P (Ei+1 = 1|Ei = 1, Ci = 0) = 1, (2) (3) where { i|1   i   M   1} are the user behavior parameters in the model and are shared across query sessions.
The probability of a query session is therefore
 (rdi  i) Ci (1   rdi )1 Ci (cid:6)   l(cid:4) (cid:5) i=1 (cid:5) M(cid:4) (cid:6) , (4) 1    l +  l (1   rdj ) M(cid:4) j=l+1 where l = arg max1 i M{Ci = 1} is the last clicked position in the query session.
If there is no click, l is set to 0 in the equation above.
This suggests that the user would scan the entire list of search results, which is a major limitation in the modeling assumption of DCM.
The user browsing model (UBM) [5] is also based on the examination hypothesis, but does not follow the cascade hypothesis.
Instead, it assumes that the examination probability Ei depends only on the previous clicked position li = arg maxl<i{Cl = 1} as well as the distance i   li: P (Ei = 1|C1:i 1) =  li,i li .
(5) Given click observations C1:i 1, Ei is conditionally independent of all previous examination events E1:i 1.
If there is no click before i, li is set to 0.
Since 0   li < i   M , there are a total of M (M + 1)/2 user behavior parameters  , which are again shared among all query sessions.
The probability of a query session under UBM is
 (rdi  li,i li ) Ci (1   rdi  li,i li )1 Ci .
(6) i=1 Maximium likelihood (ML) learning of UBM is an order of magnitude more expensive than DCM in terms of time and space cost.
Under DCM, we could keep 3 su cient statistics, or counts, for each query-document pair, and an additional 3(M   1) counts for global parameter estimation [6].
However, for UBM with a more complicated user behavior assumption, we should keep at least (1+M (M +1)/2) counts for each query-document pair and an additional (1+M (M +
 under our implementation (detailed in Appendix A), the algorithm usually takes dozens of iterations until convergence.
A most recent related work is a DBN click model proposed by Chapelle and Zhang [3], which appears as another paper in this proceeding.
The model still satis es the examination and cascade hypotheses as DCM does.
The di erence is the speci cation of examine-next probability P (Ei+1 = 1|Ei = 1, Ci).
Under this DBN model, (1) the only user behavior parameter in the model is denoted by  , and P (Ei+1 = 1|Ei = 1, Ci = 0) =  ; (2) two values are associated with each query-document pair.
For one of them, denoted by sdi , P (Ei+1 = 1|Ei = 1, Ci = 1) =  (1   sdi ), whereas the other one, denoted by adi is equivalent to document relevance under the examination hypothesis: P (Ci =
 proximate ML learning algorithms.
Details about the modeling assumption and algorithmic design are available in [3].
Examine(cid:3)Next(cid:3) Document Click(cid:3) Through?
Yes iR See(cid:3)More(cid:3) Results?
No Done No Yes 1(cid:68) See(cid:3)More(cid:3) Results?
No Done Yes
 i (cid:68)
 (cid:11)
 (cid:16) (cid:12) (cid:14) (cid:68)

 i Figure 2: The user model of CCM, in which Ri is the relevance variable of di at position i, and  s form the set of user behavior parameters.
      Figure 3: The graphical model representation of CCM.
Shaded nodes are observed click variables.
The CCM model is based on generative process for the users interaction with the search engine results, illustrated as a  ow chart in Figure 2, and as a generative model in Figure 3.
User starts the examination of the search result from the top ranked document.
At each position i, the user can choose to click or skip the document di according to the perceived relevance.
Either way, the user can choose to continue the examination or abandon the current query session.
The probability of continuing to examine di+1 depends on her action at the current position i. Speci cally, if the user skips di, this probability is  1; on the other hand, if the user clicks di, the probability to examine di+1 depends on the relevance Ri of di and range between  3 and  2.
CCM shares the following assumptions with the cascade model and DCM: (1) users are homogeneous: their information needs are similar given the same query; (2) decoupled examination and click events: click probability is solely determined by the examination probability and the document relevance at a given position; (3) cascade examination: examination is in strictly sequential order with no breaks.
CCM distinguishes itself from other click models by doing a proper Bayesian inference to infer the posterior distribution of the document relevance.
In CCM, document relevance Ri is a random variable between 0 and 1.
Model training of CCM therefore includes inferring the posterior distribution of Ri and estimating user-behavior parameters  s.
The posterior distribution may be particularly helpful for applications such as automated ranking alterations because it is possible to derive con dence measures and other useful features using standard statistical techniques.
In the graphical model of CCM shown in Figure 3, there and Ci denote binary examination and click events as usual, where Ri is the user-perceived relevance of di.
The click layer is fully observed from the click log.
CCM is named after the chain structure of variables representing the sequential examination and clicks through each position in the search result.
The following conditional probabilities are de ned in Figure 3 according to the model assumption: P (Ci = 1|Ei = 0) = 0 (7) P (C1 = 1|Ei = 1, Ri) = Ri (8) P (Ei+1 = 1|Ei = 0) = 0 (9) P (Ei+1 = 1|Ei = 1, Ci = 0) =  1 (10) P (Ei+1 = 1|Ei = 1, Ci = 1, Ri) =  2(1   Ri) +  3Ri (11) To complete the model speci cation we let P (E1 = 1) = 1 and document relevances Ri s are iid and uniformly distributed within [0, 1], i.e. , p(Ri) = 1 for 0   Ri   1.
Note that in the model speci cation, we did not put a limit on the length of the chain structure.
Instead we allow the chain to go to in nite, with the examination probability diminishing exponentially.
We will discuss, in the next section, that this choice simpli es the inference algorithm and o ers more scalability.
An alternative is to truncate the click chain to a  nite length of M .
The inference and learning algorithms could be adapted to this truncated CCM, with an order of magnitude higher space, but it still needs only one pass through the click data.
Its performance of improvement over CCM would depend on the tail of the distribution of last clicked position.
Details are to be presented in an extended version of this paper.
This section describes algorithms for the CCM.
We start with the algorithm for computing the posterior distribution over the relevance of each document.
Then we describe how to estimate the   parameters.
Finally, we discuss how to incrementally update the relevance posteriors and   parameters with more data.
Given the click data C 1:U from U query sessions for a query, we want to compute the posterior distribution for the relevance of a document i, i.e. P (Ri|C 1:U ).
For a single query session, this posterior is simple to compute and store due to the chain structure of the graphical model ( gure 3).
However, for multiple query sessions, the graph may have loops due to sharing of relevance variables between query sessions.
For example, if documents i and j both appear in two sessions, then the graph including both sessions will have a loop.
This signi cantly complicates the posterior.
One possibility is to use an iterative algorithm such as expectation propagation [13] that traverses and approximates the loops.
However, for this application we propose a faster method that simply cuts the loops.
The approximation is that, when computing the posterior for Ri, we do not link the relevance variables for other documents across sessions.
In other words, we approximate clicks in query sessions as conditionally independent random variables given Ri: p(Ri|C 1:U )   (constant)   p(Ri) P (C u|Ri).
(12) U(cid:4) u=1 Case(cid:3)1 Case(cid:3)2 Case(cid:3)3 Case(cid:3)4



  

 Case(cid:3)5




  
 Case




 Conditions i < l, Ci = 0 i < l, Ci = 1 i = l i > l No Click Results
 (cid:5) (cid:6) Ri(1   (1    3/ 2)Ri) Ri 1 +  2 3 2 1 2 Ri


 6 3 1 2 2 3 (1 1)( 2+2 3) (2/ 1)


 (i l) 1 Ri Figure 4: Di erent cases for computing P (C|Ri) up to a constant where l is the last clicked position.
Darker nodes in the  gure above indicate clicks.
Since the prior p(Ri) is already known, we only need to  gure out P ( C u| Ri) for each session u.
Once P ( C u| Ri) is calculated up to a constant w.r.t.
Ri, Eq.
12 immediately gives an un-normalized version of the posterior.
Section 4.1 will elaborate on the computation of P ( C u| Ri), and the superscript u is discarded in the following as we focus on a single query session.
Before diving into the details of deriving P (C|Ri), we  rst highlight the following three properties of CCM, which will greatly simplify the variable elimination procedure as we take sum or integration over all hidden variables other than Ri:


  1)1 Ei+1 does not depend on Ri.
(1  Property (1) states that every document before the last click position is examined, so for these documents, we only need take care of di erent values of random variables within its Markov blanket in Figure 3, which is Ci, Ei and Ei+1.
Property (2) comes from the cascade hypothesis, and it reduces the cost of eliminating E variables from exponential time to linear time using branch-and-conquer techniques.
Property (3) is a corollary from Eq.
11, and it enables rearrangement of the sum operation over E and R variables to minimize computational e ort.
Calculating P (C|Ri) requires summing over all the hidden variables other than Ri in Figure 3, which is generally intractable.
But with the above three properties, closed-form solutions can be derived.
Speci cally, from property 1, we know that the last clicked position l = arg maxj{Cj = 1} plays an important role.
Figure 4 lists the complete results separated to two categories, depending on whether the last click position l exists or not.
cases 1 3.
The derivation of case 3 is illuminating to the other two cases.
Case 1: i < l, Ci = 0 By property 1 and 3, Ei = 1, Ei+1 = 1 and P (Ei+1 =
 Since any constant w.r.t.
Ri can be ignored, we have P (C|Ri)   P (Ci = 0|Ei = 1, Ri) = 1   Ri (13) Case 2: i < l, Ci = 1 By property 1, Ei = 1, Ei+1 = 1, the Markov blanket of Ri consists of Ci, Ei and Ei+1.
P (C|Ri)   P (Ci = 1|Ei = 1, Ri)P (Ei+1 = 1|Ei = 1, Ci = 1, Ri)   Ri(1   (1    3/ 2)Ri) (14) Case 3: i = l By property 1, the Markov blanket of Ri does not contain any variable before position i, and we also know that Ci = 1, Ei = 1 and  j > i, Cj = 0.
We need to take sum/integration over all the E>i, R>i variables and it can be performed as follows: P (C|Ri)   P (Ci = 1|Ei = 1, Ri)   (cid:5) (cid:8) (cid:7) (cid:4) Ej>i Rj>i j>i (cid:6) (cid:9) P (Ej|Ej 1, Cj 1, Rj 1)   p(Rj )   P (Cj|Ej, Rj )

 = Ri   P (Ei+1 = 0|Ei = 1, Ci = 1, Ri)   1 (cid:10)(cid:8) + P (Ei+1 = 1|Ei = 1, Ci = 1, Ri)  p(Ri+1) P (Ci+1 = 0|Ei+1 = 1, Ri+1)dRi+1 (cid:12) P (Ei+2 = 0|Ei+1 = 1, Ci+1 = 0)   1 (cid:10)(cid:8) + P (Ei+2 = 1|Ei+1 = 1, Ci+1 = 0)  (cid:13) p(Ri+2) P (Ci+2 = 0|Ei+2 = 1, Ri+2)dRi+2 (cid:14)(cid:15)(cid:16) (cid:11)  

 .
.
.
(cid:10) (1    2(1   Ri)    3Ri) + ( 2(1   Ri) +  3Ri)  (cid:5) (1    1) +  1   1 (cid:10)
  2    3 2    1    2 (cid:18)(cid:6)(cid:11)  (cid:17) (cid:11) (15)
 .
.
.
Ri = Ri  

   Ri (cid:11)   Both case 4 and case 5 need to take sum over the hidden variables after the current position i.
The result of case 4 and 5 depend on the distance from the last clicked position.
Therefore the total number of distinct results for computing P (C|Ri) in these 5 cases when 1   i   M are 1 + 1 + 1 + (M   1) + M = 2M + 2.
If we impose a  nite chain length M on CCM and let P (EM +1) = 0 in Figure 3, then the Table 1: The algorithm for computing a factorized representation of relevance posterior.
Alg.
1: Computing the Un-normalized Posterior Input: Click Data C (M   U matrix); Cm,u = 1 if user u clicks the mth page abstract Impression Data I (M   U matrix); Im,u is the document index shown to user u at position m which ranges between 1 and D Parameters   Output: Coe cients   ((2M + 2)-dim vector) Exponents P (D   (2M + 2) matrix) Compute   using the results in Figure 4.
Initialize P by setting all the elements to 0.
for 1   u   U Identify the linear factors using the click data C u, obtain a M dim vector b, such that  bm is the corresponding coe cient for position m.
for 1   m   M PImu,bm = PImu,bm + 1 Time Complexity: O(M U ).
Space Complexity: O(M D + M U ).
(Usually U > D >> M = 10.)
number of distinct results would be M (M + 3)/2 + 2, which is an order of magnitude higher than the current design, and further increases the cost of subsequent step of inference and parameter estimation.
All the conditional probabilities in Figure 4 for a single i (1    jRi) query session can be written in the form of RCi where  j is a case-dependent coe cient dependent on the user behavior parameters  s.
Let M be the number of web documents in the  rst result page and it usually equals 10.
There are at most 2M + 3 such   coe cients from the 5 cases as discussed above.
From Eq.
12, we know that the un-normalized posterior of any web page is a polynomial, which consists of at most (2M + 2) + 1 distinct linear factors of Ri (including Ri itself) and (2M + 2) independent exponents as su cient statistics.
The detailed algorithm for parsing through the data and updating the counting statistics is listed in Table 1.
Given the output exponents P as well as coe cients   from Alg.
1, the un-normalized relevance posterior of a document d is  pRd (r)   rPd,2+Pd,3 (1    mr) Pd,m (16) m=1
 Standard polynomial integration of  p(r) is straightforward but is subject to the dimensional curse: the rounding error will dominate as the order of the polynomial goes up to
 procedure for computing posterior moments in Table 2 using the midpoint rule with B equal-size bins.The jth moment for document d is therefore
 rj  p(r)dr   1
 rPd,2+Pd,3+j b (1 +  mrb) Pd,m for j   1 divided by the normalizing constant c. Although the number of bins can be adaptively set, usually we  nd
 m=1 B(cid:7) b=1 (cid:8)

 log(rb) +

 m=1 Pd,m log(1 +  mrb) .
Eqs.
18 and 19 leave a degree of freedom in choosing the value  2 and  3 introduced by applying the iid uniform priors over all documents.
We can assign a value to  2/ 3 according to the context of the model application (more on this in experiments).
Parameter values do not depend on N4 when the chain length is in nite.
When new click data are available, we can run Alg.
1 (Table 1) to update exponents stored in P by increasing the counts.
The computational time is thus O(M U(cid:3) ), where U(cid:3) is the number of users in the new data.
Extra storage other than input is needed only when there are previously unseen web document of interest.
If necessary, we can update the posterior relevancy estimates using Alg.
2 (Table 2).
We can also update   using the same counts.
In this section, we report on the experimental evaluation and comparison based on a data set with 8.8 million query sessions that are uniformly sampled from a commercial search engine.
We measure the performance of three click models with a number of evaluation metrics, and the experimental results show that CCM consistently outperforms UBM and DCM: over 9.7% better log-likelihood (Section 5.2), over 6.2% improvement in click perplexity (Section 5.3) and much more robust (up to 30%) click statistics prediction (Section 5.4) As these widely used metrics measure the model quality from di erent aspects, the consistently better results indicate that CCM robustly captures the clicks in a number of contexts.
Finally, in Section 5.5, we present the empirical examine and click distribution curves, which help illustrate the di erences in modeling assumptions.
The experiment data set is uniformly sampled from a commercial search engine in July 2008.
Only query sessions with at least one click are kept for performance evaluation, because those discarded sessions tend to correlate with clicks on other search elements, e.g.
, ads and query suggestions.
For each query, we sort all of its query sessions in ascending order of the time stamps, and split them evenly into the training set and the test set.
The number of query sessions in the training set is 4,804,633.
Moreover, in order to prevent evaluations from being biased by highly frequent queries for which even the simplest model could do well, 178 (0.16%) queries with more than 103.5 sessions are excluded from the test set.
Performances of di erent click models on these top queries are consistent with less frequent queries but with a much smaller margin.
The  nal test set consists of 110,630 distinct queries and 4,028,209 query sessions.
In order to investigate the performance variations across di erent query frequencies, queries in the test set are categorized according to the query frequency into the 6 groups as listed in Table 3.
For each query, we compute document relevance and position relevance based on each of the three models, respectively.
Position relevance is computed by treating each position as a pseudo-document.
The position relevance can substitute the document relevance estimates for documents that appear zero or very few times in the training set but do appear in the test set.
This essentially smooths the predictive model and improves the performance on the test set.
Table 2: The algorithm for computing posterior moments using numerical integration.
Alg.
2: Numerical Integration for Posteriors Input: Exponents P (D   (2M + 2) matrix) Coe cients   ((2M + 2)-dim vector) Number of bins B Output: Normalizing Constants c (D-dim vector) Posterior Mean   (D-dim vector) Posterior Second Moment   (D-dim vector) Create a D   3 matrix T for intermediate results.
Create a B-dimensional vector r to keep the center of each bin: rb = (b   0.5)/B for 1   b   B for 0   j   2 (cid:19)B for 1   d   D (cid:6) b=1 exp (  log(B) + (Pd,2 + Pd,3 + j)  Md,j = (cid:19) cd = Md,0,  d = Md,1/Md,0,  d = Md,2/Md,0 Time Complexity: O(M DB).
Space Complexity: O(M D + DB + M B).
that B = 100 is su cient.
To avoid numerical problems in implementation, we usually take sum of log values for the linear factors instead of multiplying them directly.
In general, for posterior point estimates Ep(r)[f (r)], we can simply replace the term rj b in the pervious equation by f (rb) and divide the result by the normalization constant c.
To estimate the model parameters   from the data, we employ approximate maximum likelihood estimation.
Ideally, we want to maximize the likelihood p(C 1:U| ), in which the relevance variables Ri are integrated out.
However, as discussed earlier in section 4, the graph of relevance variables has loops, preventing exact integration.
Therefore we approximate the integral by cutting all edges between query sessions.
In other words, the clicks are approximated as con-p(C u| ).
For a single query session, the likelihood p(C| ) is computed by integrating out the Ri (with uniform priors) and the examination variables Ei.
The exact derivation is similar to (15) and is omitted.
Summing over query sessions, the resulting approximate log-likelihood function is ditionally independent given  : p(C 1:U| )  (cid:20)U u=1 (cid:7)( ) = N1 log  1 + N2 log  4 + N3 log(6   3 1    4) + N5 log(1    1)   (N3 + N5) log(2    1)   N1 log 2   (N2 + N3) log 6 (17) where  4 (cid:2)  2 + 2 3 is an auxiliary variable and Ni is the total number of times documents fall into case i in Figure 4 in the click data.
By maximizing this approximate log-likelihood w.r.t.
 s, we have



  1 = and  4 =

 (18) (19) # Sessions Avg # Clk Query Freq # Queries











 The cuto  is set adaptively as (cid:9)2 log10(Query Frequency)(cid:10).
For CCM, the number of bins B is set to 100 which provides adequate level of accuracy.
To account for heterogeneous browsing patterns for di er-ent queries, we  t di erent models for navigational queries and informational queries and learn two sets of parameters for each model according to the median of click distribution over positions [6, 12].
In particular, CCM sets the ratio  2/ 3 equal to 2.5 for navigational queries and 1.5 for informational queries, because a larger ratio implies a smaller examination probability after a click.
The value of  1 equals 1 as a result of discarding query sessions with no clicks (N5 = 0 in Eq.
18).
For navigational queries,  2 = 0.10 and  3 = 0.04; for informational queries,  2 = 0.40 and  3 = 0.27.
Parameter estimation results for DCM and UBM will be available at the author s web site.
For performance evaluation on test data, we compute the log-likelihood and other statistics needed for each query session using the document relevance and user behavior parameter estimates learned/inferred from training data.
In particular, by assuming independent document relevance priors in CCM, all the necessary statistics can be derived in close form, which is summarized in Appendix B.
Finally, to avoid in nite values in log-likelihood, a lower bound of 0.01 and a upper bound of 0.99 are applied to document relevance estimates for DCM and UBM.
All of the experiments were carried out with MATLAB R2008b on a 64-bit server with 32GB RAM and eight 2.8GHz cores.
The total time of model training for UBM, DCM and CCM is 333 minutes, 5.4 minutes and 9.8 minutes, respectively.
For CCM, obtaining su cient statistics (Alg.
1), parameter estimation, and posterior computation (Alg.
2) accounted for 54%, 2.0% and 44% of the total time, respectively.
For UBM, the algorithm converged in 34 iterations.
Log-likelihood (LL) is widely used to measure model  t-ness.
Given the document impression for each query session in the test data, LL is de ned as the log probability of observed click events computed under the trained model.
A larger LL indicates better performance, and the optimal value is 0.
The improvement of LL value (cid:7)1 over (cid:7)2 is computed as (exp((cid:7)1   (cid:7)2)   1)   100%.
We report average LL over multiple query sessions using arithmetic mean.
Figure 5 presents LL curves for the three models over different frequencies.
The average LL over all query sessions is -1.171 for CCM, which means that with 31% chance, CCM predicts the correct user clicks out of the 210 possibilities on the top 10 results for a query session in the test data.
The average LL is -1.264 for UBM and -1.302 for DCM, with improvement ratios to be 9.7% and 14% respectively.
Thanks to the Bayesian modeling of the relevance, CCM outperforms the other models more signi cantly on less-frequent


  0.5  1  1.5  2  2.5  3  3.5 d o o h i l i e k
   g o
  4






 Query Frequency Figure 5: Log-likelihood per query session on the test data for di erent query frequencies.
The overall average for CCM is -1.171, 9.7% better than UBM (-1.264) and 14% better than DCM (-1.302).
queries than on frequent ones, as indicated in Figure 5.
Fitting di erent models for navigational and informational queries leads to 2.5% better LL for DCM compared with a previous implementation in [7] on the same data set (average

 Click perplexity was used as the evaluation metric in [5].
It is computed for binary click events at each position in a query session independently rather than the whole click sequence as in the log-likelihood computation.
For a set of query sessions indexed by n = 1, .
.
.
, N , if we use qn i to denote the probability of click derived from the click model on position i and C n i to denote the corresponding binary click event, then the click perplexity i +(1 Cn i ) log2(1 qn i log2 qn n=1(Cn (cid:19) N   1 pi = 2
 i )).
(20) A smaller perplexity value indicates higher prediction quality, and the optimal value is 1.
The improvement of perplexity value p1 over p2 is given by (p2   p1)/(p2   1)   100%.
The average click perplexity over all query sessions and positions is 1.1479 for CCM, which is a 6.2% improvement per position over UBM (1.1577) and a 7.0% improvement over DCM (1.1590).
Again, CCM outperforms the other two models more signi cantly on less frequent queries than on more frequent queries.
As shown in Figure 6(a), the improvement ratio is over 26% when compared with DCM and UBM for the least frequent query category.
Figure 6(b) demonstrates that click prediction quality of CCM is the best of the three models for every position, whereas DCM and UBM are almost comparable.
Perplexity value for CCM on position 1 and 10 is comparable to the perplexity of predicting the outcome of throwing a biased coin of with known p(Head) = 0.099 and p(Head) = 0.0117 respectively.
Root-mean-square (RMS) error on click statistics prediction was used as an evaluation metric in [7].
It is calculated











 l y t i x e p r e








 Query Frequency (a) l y t i x e p r e

















 Position (b)



 Figure 6: Perplexity results on the test data for (a) for di erent query frequencies or (b) di erent positions.
Average click perplexity over all positions for CCM is 1.1479, 6.2% improvement over UBM (1.1577) and
 by comparing the observation statistics such as the  rst click position or the last clicked position in a query session with the model predicted position.
Predicting the last click position is particularly challenging for click models while predicting the  rst click position is a relatively easy task.
We evaluate the performance of these predictions on the test data under two settings.
First, given the impression data, we compute the distribution of the  rst/last clicked position in closed form, and compare the expected value with the observed statistics to compute the RMS error.
The optimal RMS value under this setting is approximately the standard deviation of  rst/last clicked positions over all query sessions for a given query, and it is included in Figure 7 as the  optimal-exp  curve.
We expect that a model that gives consistently good  t of click data would have a small margin with respect to the optimal error.
The improvement of RMS error e1 over e2 w.r.t.
)   100%.
the optimal value e  We report average error by taking the RMS mean over all query sessions.
is given by (e2   e1)/(e2   e  The optimal RMS error under this setting for  rst clicked position is 1.198, whereas the error of CCM is 1.264.
Compared with the RMS value of 1.271 for DCM and 1.278 for UBM, the improvement ratios are 10% and 18%, respectively.
The optimal RMS error under this setting for last clicked position is 1.443, whereas the error of CCM is
 slightly better than UBM (0.2%).
Under the second setting, we simulate query session clicks from the model, collect those samples with clicks, compare the  rst/last clicked position against the ground truth in the test data and compute the RMS error, in the same way as [7].
The number of samples in the simulation is set to
 but it is much more di cult to achieve than in the  rst setting, because errors from simulations re ect both biases and variances of the prediction.
So we report the RMS error margin for the same model between the two settings.
And


 y t i l i b a b o r
 k c i l i
 / e n m a x
 UBM Examine DCM Examine CCM Examine UBM Click DCM Click CCM Click Empirical Click





 Position



 Figure 8: Examination and click probability distributions over the top 10 positions.
we believe that a more robust click model should have a smaller margin.
This margin on  rst click prediction is 0.366 for CCM, compared with 0.384 for DCM (4.8% larger) and
 last click position, the margin is 0.460 for CCM, compared with 0.566 for DCM (23% larger) and 0.599 for UBM (30% larger).
In summary, CCM is the best of the three model in this experiment, to predict the  rst and the last click position e ectively and robustly.
Model click distribution over positions are the averaged click probabilities derived from click models based on the document impression in the test data.
It re ects the position-bias implied by the click model and can be compared with






 r o r r
 n o i i t c d e r
 k c i l
 t s r i











 r o r r
 n o i i t c d e r
 k c i l
 t s a





















 Query Frequency


 Query Frequency (a) (b) Figure 7: Root-mean-square (RMS) errors for predicting (a)  rst clicked position and (b) last clicked position.
Prediction is based on the SIMulation for solid curves and EXPectation for dashed curves.
the objective ground truth the empirical click distribution over the test set.
Any deviation of model click distribution from the ground truth would suggest the existing modeling bias in clicks.
Note that on the other side, a close match does not necessarily indicate excellent click prediction, for example, prediction of clicks {00, 11} as {01, 10} would still have a perfect empirical distribution.
Model examination distribution over positions can be computed in a similar way to the click distribution.
But there is no ground truth to be contrasted with.
Under the examination hypothesis, the gap between examination and click curves of the same model re ects the average document relevance.
Figure 8 illustrates the model examination and click distribution derived from CCM, DCM and UBM as well as the empirical click distribution on the test data.
All three models underestimate the click probabilities in the last few positions.
CCM has a larger bias due to the approximation of in nite-length in inference and estimation.
This approximation is immaterial as CCM gives the best results in the above experiments.
A truncated version of CCM could be applied here for improved quality, but the time and space cost would be an order of magnitude higher, based on some ongoing experiments not reported here.
Therefore, we believe that this bias is acceptable unless certain applications require very accurate modeling of the last few positions.
The examination curves of CCM and DCM decrease with a similar exponential rate.
Both models are based on the cascade assumption, under which examination is a linear traverse through the rank.
The examination probability derived by UBM is much larger, and this suggests that the absolute value of document relevance derived from UBM is not directly comparable to that from DCM and CCM.
Relevance judgments from click models is still a relative measure.
In this paper, we propose the click chain model (CCM), which includes Bayesian modeling and inference of user-perceived relevance.
Using an approximate closed-form representation of the relevance posterior, CCM is both scal-able and incremental, perfectly meeting the challenges posed by real world practice.
We carry out a set of extensive experiments with various evaluation metrics, and the results clearly evidence the advancement of the state-of-the-art.
Similar Bayesian techniques could also be applied to models such as DCM and UBM.
We would like to thank Ethan Tu and Li-Wei He for their help and e ort, and anonymous reviewers for their constructive comments on this paper.
Fan Guo and Christos Falout-sos are supported in part by the National Science Foundation under Grant No.
DBI-0640543.
Any opinions,  ndings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily re ect the views of the National Science Foundation.
