When the load o ered to a system exceeds its maximum processing capacity, the system is said to be overloaded.
Typical symptoms of an uncontrolled overload situation are increased delays, thrashing, saturated resources and backlogged queues.
There have been many proposed approaches to overload control of Web applications [1 4].
Most mechanisms use a combination of online measurements of performance metrics, overload detection mechanisms, and tuning  This research was supported by the Philips Fellowship.
 This research was supported by the 2007 IBM Faculty Award.
Copyright is held by the author/owner(s).
of controllable parameters to protect the system from adverse e ects of overload.
Some solutions additionally call for architectural changes, such as adding  work queues , to the Web server.
This gives rise to the question of where such overload control mechanisms are implemented.
Modifying the Web server code requires having access to the code, and the resulting implementation is speci c to the particular Web server.
An alternative approach is to use a proxy server introduced in to the request  ow path between clients and servers [4].
The proxy can act as an admission controller, preventing the upstream servers from going into an overloaded state by managing the load sent upstream.
A proxy based approach is easily portable to any Web servers.
Existing Free and Open Source Software (FOSS) HTTP proxy projects like Mu n (http://muffin.doit.org/) and Squid (http://squid-cache.org/) have shortcomings such as lack of multi-class support or work queue architecture.
Also, most are focused on acting as gateways for tra c outbound from a private network while our usage is akin to the reverse proxy scenario for inbound tra c.
Given our need for measurement infrastructure and architectural elements discussed below, we chose to develop an extensible proxy-based platform, for performance management of Web applications, from the ground up.
The main design goal of our proxy-based solution (called MASTH  Multi-class Admission-controlled Self-Tuning Http Proxy) presented here, is to provide an easily extensible platform for development and deployment of Web application performance management mechanisms.
Using this platform, one should be able to quickly prototype any control method by concentrating on the core logic, rather than on implementing measurement instrumentation or tun-able parameters.
The proxy provides the following features:
 incorporates classi cation of incoming requests into a con gurable number of classes according to any HTTP header  eld.
A separate queue of received HTTP requests is maintained for each class.
Round Robin Database (RRD4J 2.0.5, http://rrd4j.dev.
java.net/) that maintains histories of measurements at various granularities in an e cient manner.
We can query the database for any measured metric in any speci ed measure-c e s / s t s e u q e r ( t u p d o o







 Goodput: No Proxy Goodput: Proxy + Fixed Rate Response Time: No Proxy Response Time: Proxy + Fixed Rate 1e+06







 Number of Emulated Browsers

 ) c e s m i ( e m
 e s n o p s e
 Figure 1: Results from TPC-W Benchmark ment interval at various resolutions.
e.g.
5 second averages for past 10 minutes, 2 minute averages for past hour, etc.
Measurements include arrival rate, waiting time, response time, goodput (usable throughput), client timeouts, queue length, and resource utilizations.
The set of measurements is stored on a per-class as well as aggregate basis.
rate of admitted requests, bu er size, rate of upstream request dispatch, maximum number of pending upstream requests, queue priorities, queuing disciplines (FIFO, LIFO), and multi-queue scheduling policies (round robin, priority) are provided for use by overload control mechanisms.
Admission control in the proxy is implemented by placing token-bucket regulators at the ingress and egress points of each queue.
This allows  exible tra c-shaping of the incoming load on a per-class basis.
modular multistage event-driven architecture with separate specialized threads/ thread-pools for request parsing, classi- cation, queue management, upstream dispatch, recording and querying of measurements, parameter tuning etc.
This makes the design  exible, and it is quite straight forward to extend the functionality of the proxy on two fronts.
First to implement new features, such as adding an aggregate rate control over and above the per-class token-bucket regulators, adding new queue scheduling policies, etc.
without doing major code restructuring.
Secondly, implementing new control loops/ feedback methods becomes straight forward.
This can be done in two ways.
First is to extend the Tun-ingThread base class and implement the core logic of the method being developed.
Interfaces to measurements, tun-able parameters are directly available.
The other way is to use the proxy s Web API to remotely control the tunable parameters from an external implementation of the control method.
In this case the proxy acts as a measurement and management subsystem.
To test the e cacy of our proxy, we carry out load-testing experiments on a test-bed of one server (Dual Intel Xeon, 8GB), and three clients (Intel P4, 1GB).
We use a Java+Tomcat+MySQL implementation of the TPC-W benchmark (http://www.ece.wisc.edu/~pharm/tpcw.
shtml.
Note that we have modi ed the TPC-W load generator to add request timeouts and think time between successive retries of a blocked request.
We varied the load from
 WebAPI call: HEAD http://proxy:port/API/ratelimit/35/1 (a) Fixed rate control: Class1 set to 35 req/s class ThrottleHomeOnOverload extends TuningThread { void doTuning() { if (Measurement.isOverloaded()) { AppQueues.setTokenBucketRate(TPCW_Home, 0.6 * Measurement.getGoodputMax(OneDay,TPCW_Home)); AppQueues.enableIngressThrottling(); } else AppQueues.disableIngressThrottling(); }} (b) Limit to 60% of peak goodput only if overloaded Figure 2: Rate control of TPCW_Home (Class1) In Fig. 1, the graph of aggregate goodput shows that the peak without proxy is at 200 req/s.
However, as the number of EBs increases, the goodput drops to less than 20 req/s.
We can use MASTH proxy with a request admission rate control mechanism to manage such an overload.
For instance, setting a  xed rate limit of 35 req/s on the TPCW_Home class using the WebAPI call in Fig. 2(a) prevents the degradation of goodput after overload the goodput settles at
 response time charts in Fig. 1 show that the  xed rate limit successfully keeps response times low.
Fig. 2(b) shows how this static scheme may be extended, with a few lines of code, to apply a rate limit only if an overload is detected, and to set it based on past measurements.
MASTH Proxy is an easily extensible platform for performance management of Web applications with features such as a detailed performance monitoring, multi-class support, work queues and pre-built control points for rate control and online tuning of system parameters.
The proxy has been coded in Java 6 for portability, and supports HTTP 1.1 with persistent connections.
The code has been released as a FOSS project (at http://sourceforge.net/projects/masthproxy), and can be used by anybody to test their overload control mechanisms.
