In an ideal world, the search results seen by a user are based on the entire content available on the Web at the time of the query.
In practice, a search engine has a crawler which continually crawls and re-crawls the web, fetching and storing web pages in a local repository.
Due to limited resources, not all of the local copies are up-to-date.
In addition, it takes time for the crawled content to be indexed and stored into searchable indexes.
When a query comes in, documents in these partially stale indexes are retrieved and ranked by the runtime system, and a small subset of those documents are displayed to the user.
Copyright is held by the author/owner(s).
Since the freshness of the search indexes does impact the quality of search results as seen by users, it is important for a production search engine to measure and monitor its freshness from a user perspective.
Not only would such a metric capture the e ectiveness of the synchronization policy, but it would also detect any system issues or bugs along the rest of the search engine pipeline.
Most previous measures of freshness were devised in the context of developing a better synchronization policy in the crawler.
Thus, they have focused on the freshness of documents as they exist in the crawler.
Two common metrics are freshness and age [1].
The freshness of a crawler is simply the fraction of documents that are fresh, i.e., have not changed since last time they were crawled.
The age of a document quanti es how stale the local copy is; the age of a crawler is the average of the ages of its documents.
The article [3] does bring in the user perspective in its  top-k freshness  metric, which looks only at documents that appear in the  rst page of search results.
This metric is de ned for a result set, however, rather than for an entire search engine.
Another article [2] introduces the concept of a weighted freshness metric, whereby documents contribute unequally to the overall freshness depending on their  importance .
They point out that importance can be related to the frequency at which a document is associated with a query, although without elaborating how to quantify it.
In this article, we propose a new way of measuring freshness from a user perspective.
Our contribution is in devising metrics that: (1) expand on the idea of limiting the documents to ones that users actually see, hence, user-centric; (2) build on the concept of a weighted metric by using the number of clicks or views as weights; and (3) account for the latency involved in indexing a document after it has been crawled.
We also describe a practical implementation of these metrics that were used successfully in a leading web search engine.
Fig. 1 illustrates our user-centric metrics.
A local page was crawled (or sync ed) at time 1, indexed at time 2, and clicked by a user at time 6.
Its age re ects the fact that the local copy has been stale for 3 days, ever since the web copy was  rst modi ed after the last sync.
If the web copy had not been modi ed, the local page would have been fresh, with an age of zero, even though the local copy has been sitting in the index for 4 days at the view time.
Hence, our metrics measure the staleness of a page with respect to if and when it is clicked by users.
In the following de nitions, assume the repository S (of size |S|) refers to the set of crawled pages and Sc to the set of clicked pages.
The de nitions for viewed pages or pages of any other category, e.g., news pages, are analogous.
The weighted metrics consider the fact that pages are clicked in the search results with varying frequency.
As such, a stale page clicked on by many users can have a bigger impact on the perception of freshness of a search engine index than many pages that rarely show up in user search results.
The unweighted metrics ignore the frequency impact.
The metrics are de ned in an average sense but can easily be converted into histograms.
De nition 1.
The freshness of a local page p at time t is de ned as F (p, t) = 1 if p is up-to-date at time t (i.e., not modi ed since its last sync), 0 otherwise.
The age of a local page p at time t is A(p, t) = 0 if p is up-to-date at time t, t  tmod otherwise, where tmod is the time of the  rst modi cation after the last sync of p.
De nition 2.
The (basic) freshness of S at time t is de- ned as F (S, t) = 1|S| p S F (p, t).
Similarly, the (basic) age of S at time t is de ned as A(S, t) = 1|S| p S A(p, t).
These de nitions respectively refer to the unweighted freshness Fu and unweighted age Au when S is replaced by Sc.
De nition 3.
Let nclicks(p, t) be the number of times users have clicked page p since it was  rst modi ed after the last sync.
The weighted freshness of Sc at time t is Fw(Sc, t) = p Sc F (p, t)   nclicks(p, t) p Sc nclicks(p, t)



 and the weighted age of Sc at time t is Aw(Sc, t) = p Sc A(p, t)   nclicks(p, t) p Sc nclicks(p, t) , .
(1) (2)

 We implemented the user-centric freshness metrics described above to monitor a production search engine.
The metrics were updated periodically.
Due the search index size, it was impractical to measure all documents.
Instead we sampled documents from the search engine s query logs.
To take into account the variation in queries over time, we took a new sample periodically from query logs, and tracked those documents over multiple periods.
After being tracked for a predetermined number of periods, documents were removed from the sample.
The freshness and age metrics require knowledge about when a document is modi ed on the web.
In order to collect Figure 2: Comparison of freshness metrics.
this information, we have set up a separate crawler that synchronizes sampled documents periodically at a  xed rate.
Thus, we knew modi cation times of these documents up to the resolution of the refresh period.
We obtained daily click and view statistics from the search engine s query logs.
The freshness metrics were recalculated periodically for the local copies of the sample residing in the search indexes.
Due to the con dential nature of the data, we will not show the actual data collected.
Instead, Fig. 2 shows a representative example to illustrate the value of the user-centric In this example, the fact that  user unweighted  metrics.
is consistently higher than the  basic  metric implies that the search engine is fresher for documents that are actually viewed or clicked by users.
The fact that  user weighted  is even higher implies that the search engine is even fresher on a per-click or per-view basis.
In addition, the sudden drop in freshness on day 6 alerts us of a possible problem in the search engine pipeline.
One limitation of the methodology is the time resolution limit due to the refresh rate of the separate crawler and the sample rate from query logs.
However, this limitation can be overcome by simply increasing those rates of data collection.
We proposed metrics for measuring freshness from a user s perspective.
These metrics account for the latency added by the full search engine pipeline, and capture the variation in user click and view frequency among di erent documents.
We described a practical implementation geared at measuring and monitoring freshness in a production search engine.
