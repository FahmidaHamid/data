Anomaly intrusion detection is a widely studied topic in computer networks because of its capability of detecting  The author has moved to Q2S Center of Excellence, NTNU, Norway.
Copyright is held by the author/owner(s).
novel attacks.
Anomaly detection normally builds a pro le of a subject s normal activities and attempts to identify any unacceptable deviation as possibly the result of an attack.
Many existing anomaly IDSs (Intrusion Detection System) have some di culties for practical use.
First, a large amount of precisely labeled data is very di cult to obtain in practice.
In contrast, many existing anomaly detection approaches need precisely labeled data to train the detection model.
Second, data for intrusion detection is typically steaming and the detection models should be frequently updated with new incoming labeled data.
However, many existing anomaly detection methods involve o line learning.
Quickly and manually labeling the data is di cult and thus it is quite expensive to frequently retrain the IDS with new clean labeled data.
Third, many current anomaly detection approaches assume that the data distribution is stationary and the model is static accordingly.
In practice, however, data involved in current network environments always evolves.
An e ective anomaly detection method, therefore, should have adaptive capability to deal with the  concept drift  problem.
That is, the model should be automatically updated to adapt to normal behaviors when there is a change detected.
Our framework has a assumption that normal data is very large while abnormal data is rare in practical detection environments.
During the clustering process, we use the size as well as looseness of each cluster to identify the anomalies.
Our framework adaptively detects attacks with the following three steps (the pseudo code is described in Fig. 1).
  Step 1.
Building the initial model with some online clustering algorithms.
The  rst bunch of data is clustered and the exemplars (or cluster centers) as well as their associated items are thus obtained.
Some outliers are identi ed, marked as suspicious and then put into a reservoir.
  Step 2.
Identifying outliers and updating the model in the data streaming environment.
As the audit data to the exemplars.
If too far from the nearest exemplar, the item is identi ed as an outlier, marked as suspicious and then put into the reservoir.
Otherwise the item is regarded as normal and the model is updated accordingly with the normal item.
  Step 3.
Rebuilding the model and identifying attacks.
The model rebuilding criterion is triggered if the number of incoming outliers exceeds a threshold or if a time period is up to another threshold.
The detection model is rebuilt with the current exemplars and with the outliers in the reservoir, using the clustering algorithm again.
An attack is identi ed if an outlier in the reservoir is marked as suspicious once again after the model rebuilding.
Audit data stream x1, .
.
.
xt, .
.
.
;  t threshold N,   Clustering (x1, .
.
.
, xT ) with some clustering algorithms ei is the exemplar (clustering center) of one cluster ni is the number of items in exemplar ei  i is the mean sum of the distances between each exemplar ei and its corresponding items Reservoir = {} if ni   N or  i     then Reservoir   all items xj in ei end if for t > T do  nd ei which is the nearest exemplar to item xt if d(ei, xt) <   then Update model else Reservoir   xt end if if change detected then Rebuild the model (Re-clustering) Consider all the exemplars ej in Reservoir if ej appears at least twice in Reservoir and (nj   N or  j    ) then all the items in ej are attacks else Update the model end if end if end for Fig.1.
Pseudo code of the framework


 The detection models can be based on any online clustering algorithms.
We extend DBSCAN [1] to Str-DBSCAN that is suitable for clustering streaming data.
The Str-DBSCAN as well as a newly invented StrAP [3] are both used to build the detection models based on the framework, because these two clustering algorithms have no need to de- ne the number of clusters beforehand.
DBSCAN is a density based clustering algorithm.
After the initial clustering, each cluster is represented by an exemplar that is closest to its center.
In data streaming environments, upon a  concept change  has been detected, Str-DBSCAN clusters all the current exemplars as well as the outliers that are the points far from the exemplars.
During the clustering, we continually update the exemplars with some weights, so that some exemplars will be forgotten if they seldom appear in a period while some exemplars will be strengthened if they appear very frequently.
A nity Propagation (AP) is a recently developed clustering algorithm and Zhang et al. extended it to StrAP in data steaming environments.
AP clusters an initial data set and  nds some exemplars to represent each cluster.
In streaming environments, similarly StrAP continually updates the clusters and deal with  concept drift  in the data streams.
In the experiments, we collected a very large data set of HTTP logs on the main Apache server of our institute for web attack detection.
We also used another 35 di erent types of attack (http://www.i-pi.com/HTTP-attacks-JoCN-
comparison, we also used k-NN to build a static model for attack detection.
We set k=1 and compute the closest Euclidean distance between an incoming test vector X and each vector in the training data set.
X is classi ed as anomalous if its closest distance is above a pre-de ned threshold.
) % ( e t a
 n o i t c e t e





 StrAP kNN Str DBSCAN

 False Positive Rate (%)
 Fig.2.
ROC curves with Str-DBSCAN, StrAP and k-NN ROC curves (Detection Rates against False Positive Rates) are presented in Fig. 1 to show the testing results.
It is seen that adaptive anomaly detection methods, Str-DBSCAN as well as StrAP, are more e ective than static detection method, k-NN, because adaptive methods adopt to the behavioral changes while the static method does not.
The adaptive methods are also e ecient than static method because adaptive methods summarize the historical data into some simple concepts (e.g., exemplars) while the static method does not.
Web attack detection is becoming important as Web-based vulnerabilities represent a substantial portion of the security exposures of computer networks.
Our framework is e ective to detect attacks in an online and adaptive fashion without a priori knowledge (e.g., data distribution as well as labeled information).
