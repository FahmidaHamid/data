Social networks are platforms that allow people to publish details about themselves and to connect to other members of the network through friendship links.
Recently, the popularity of such online social networks is increasing signi cantly.
For example, Facebook now claims to have more than 110 million active users.1 The existence of online social networks that can be easily mined for various reasons creates both interesting opportunities and challenges.
For example, social network data could be used for marketing products to the right customers.
At the same time, privacy concerns can prevent such e orts in practice [1].
Therefore, for future social network applications, privacy emerges as an important concern.
In this paper, we focus on the problem of individual private information leakage due to being part of an online social network.
More speci cally, we explore how the online 1http://www.facebook.com/press/info.php?statistics Copyright is held by the author/owner(s).
social network data could be used to predict some individual private trait that a user is not willing to disclose (e.g., political or religious a liation) and explore the e ect of possible data sanitization alternatives on preventing such private information leakage.
To our knowledge this is the  rst comprehensive paper that discusses the problem of inferring private traits using real-life social network data and possible sanitization approaches to prevent such inference.
First, we present a modi cation of Na ve Bayes classi cation that is suitable for classifying large amount of social network data.
Our mod-i ed Na ve Bayes algorithm predicts privacy sensitive trait information using both node traits and link structure.
We compare the accuracy of our learning method based on link structure against the accuracy of our learning method based on node traits.
Please see extended version of this paper [3] for further details of our modi ed Naive Bayes classi er.
In order to protect privacy, we sanitize both trait (e.g., deleting some information from a user s online pro le) and link details (e.g., deleting links between friends) and explore the e ect they have on combating possible inference attacks.
Our initial results indicate that just sanitizing trait information or link information may not be enough to prevent inference attacks and comprehensive sanitization techniques that involve both aspects are needed in practice.
Similar to our paper, in [2], authors consider ways to infer private information via friendship links by creating a Bayesian Network from the links inside a social network.
A similar privacy problem for online social networks is discussed in [4].
Compared to [2] and [4], we provide techniques that help in choosing the most e ective traits or links that need to be removed for protecting privacy.
We wrote a program to crawl the Facebook network to gather data for our research.
Because of the size of Facebook s social network, we limited crawling to pro les inside the Dallas/Forth Worth (DFW) network.
This means that if two people share a common friend that is outside the DFW network, this is not re ected inside the database.
Also, some people have enabled privacy restrictions on their pro le and prevented the crawler from seeing their pro le details.
Our total crawl resulted in over 167,000 pro les, almost 4.5 million pro le details, and over 3 million friendship links.
All but 22 of the people crawled were inside one, large component of diameter 16.
pro le information revealed to others inside their network.
Na ve Bayes Details Only Links Only Average 0t, 0l



 0t, 10l



 10t, 0l



 10t, 10l



 Table 1: Comparison of local classi cation methods For our experiments, we consider only the subset of the graph for which we know the expressed political a liation as either  Conservative  or  Liberal .
This reduces our overall set size from approximately 160,000 to approximately 35,000 nodes.
To compare our methods to a traditional Na ve Bayes clas-si er, we implemented our own version of a traditional Na ve Bayes classi er.
Then, we use the ideas discussed in [3] to create a list of the most representative traits in the graph, which we use to remove the 10 most predictive traits from the graph.
That is, when we say that we remove K traits, we calculate which K traits are globally the most likely to reveal your true political a liation and then remove those traits from every node that originally had them.
Similarly, we use the ideas discussed in [3] to remove the 10 most telling links from every node in the graph.
Unlike removing traits, which is done globally, removal of links is done locally.
Finally, we combine the two methods and generate test sets with both 10 traits and 10 links removed from the graph.
We refer to these sets as 0t, 0l; 10t, 0l; 0t, 10l; 10t, 10l removed, respectively.
Following this, we randomly divide our nodes to form sets of 50% of the nodes in the training and 50% in the test sets.
We repeated the previous process  ve times, and run each experiment independently.
We then take the average of each of these  ve runs as the overall accuracy.
Our results, as shown in Table 1, indicate that the Average algorithm substantially outperformed traditional Na ve Bayes and the Links algorithm.
Additionally, the Average algorithm generally performed better than the Details Only algorithm with the exception of the (0 traits, 10 links) experiments.
An examination of the Links results for that experiment shows that the drop in Average accuracy can be accounted for by the exceptionally low performance of the Links classi er and the consistent Details Only performance for that point.
Also, as a veri cation of expected results, the Details clas-si cation accuracy only decreased when we removed traits from nodes, and the (0t, *) accuracies are approximately equivalent.
Similarly, the Links accuracies were mostly affected by the removal of links between nodes, and the (*, 0l) points of interest are approximately equal.
The di erence of in accuracy between (0t, 0l) and (10t, 0l) can be accounted for by the weighting portion of the Links calculations, that depend on the similarity between two nodes.
Next, we examine the speci c a ects of removing traits.
We  rst test the local classi cation accuracies after removing K traits, where K   [0, 10].
After removing the K traits, we randomize our collection of nodes and create a test set of
 the accuracy of the local classi er on this test set.
We repeat 5 times and average the results for the overall accuracy for K, at each classi er.
The results of this are shown in Figure
 classi cation accuracy immediately decreases signi cantly.
Average Details Only Links Only









 ) % ( y c a r u c c





 Number of Traits Removed

 Figure 1: Local Classi cation accuracy by number of traits removed After removing an additional trait, the classi cation returns to its prior accuracy, and for each subsequent trait removed we see a slight downward trend in classi cation accuracies.
The sudden downward spike can be easily explained by looking at the trait removal lists.
The highest-ranked trait is evidence for the trait value of  Liberal .
Removing this trait makes the probability of being  Conservative  outweigh the probability of a trait being  Liberal .
This is why the Details accuracy is approximately the same as merely guessing the majority class for each node.
However, when we remove the second trait, which is representative of being  Conservative  the probabilities again balance.
None of the remaining traits are as highly indicative as the initial two, so we instead see a gradual decrease in the accuracy over the tested parameters.
Unsurprisingly, the Links Only classi er is only slightly a ected by the removal of traits.
In [3], we report additional experimental results that show the impact of link removal, collective inference and varying labeled vs unlabeled nodes ratios.
We addressed various issues related to private information leakage in social networks.
Especially, we explored the e ect of removing traits and links in preventing sensitive information leakage.
Our results indicate that removing trait details and friendship links together is the best way to reduce clas-si er accuracy, but this is probably infeasible in maintaining the use of social networks.
However, we also show that by removing only traits, we greatly reduce the accuracy of local classi ers, which is the maximum accuracy that we were able to achieve through any combination of methods.
