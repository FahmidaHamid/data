Nowadays the World Wide Web s content is increasing in a scale never seen before.
Especially the upcoming of social web applications (e.g.
blogs and wikis) that make it easy for people to create User Generated Content has substantially contributed to the huge amount of available information in the Web.
Their increasing popularity has given rise to search and analysis engines focusing on the social web, e.g.
Google s blog search.
A key requirement of such systems is to identify the genre of the respective web pages as they crawl the Web.
The genre of a web page   as opposed to the topic of its content   comprises its functionality, purpose and conventions of usage, content creation, authorship and reception, thus de nes a typical appearance and way of providing content with similar web pages.
For example, web pages enable displaying a product (e.g.
the web genre e shop), representing a person in a social or organizational context (personal or academic homepage) or allowing to follow and take part in discussions in a forum.
In a user study, Meyer zu Eissen et al. [2] show the importance of web genres for the expectations of users.
They, as well as Santini [4], employ di erent machine learning algorithms in order to automatically detect web pages  genres between di erent genre classes like discussion, personal homepages, etc.
.
Both apply di erent feature types like linguistic Copyright is held by the author/owner(s).
features (e.g.
part-of-speech tagging and document terms), structural features (e.g.
HTML tag frequencies, use of facets used to enable functionalities like form input elements) and simple text statistics (e.g.
frequencies of punctuation).
However, a fact often neglected by related work is that the absolute dominance of the English language on the web is decreasing.
Thus, it is important to develop a way of recognizing web genres independently of the language used on the respective web page.
As many genres exhibit a certain structural and visual layout, this property enables to ignore linguistic features altogether.
In this research we restrict ourselves to the challenge of recognizing the web genres wiki, forum and blog, as they are content-creation backbones of online communities, widely adopted and used, and support di erent paradigms of content creation and collaboration in di erent languages.
Therefore, use of language in our scenario is not a discerning feature and should be neglected in favour of a truly language agnostic approach.
Instead, we apply conventional features that are language-independent and are commonly used by related approaches: HTML tag frequencies, layout, functional and typographical facets as described in [4], content word count, punctuation frequencies, URL properties, text / markup ratios and CSS rule counts.
Further, we propose some novel features that base on the logical structure of a web genre.
Speci c genres often exhibit typical content structures (e.g.
a blog basically consists of blog posts and any number of comments to each of this blog posts).
As can be easily perceived by a human, this structure is mirrored in the visual layout of the content blocks   and in the markup structure rendered by the application s underlying template engine.
For example, all comments on a blog post page share a common structure, only the user generated content (i.e. the text entered by a user) contained in this structure varies (e.g.
multiple paragraphs, additional links or images etc.
).
Thus, some similar markup is repeated.
We call this repeated markup structure a structural pattern.
Based on these structural patterns, we compute features that represent properties of a web resource that relate to the number, size, hierarchy, structure, in-page location and content ratio of identi ed patterns.
The pattern extraction method is based on [3], a computationally a ordable approach to measure (sub)-tree similarity.
It recursively walks the HTML Document Object Model, abstracting each node count the sub-tree structure by ignoring textual content.
Elements that are less likely to be a structural part of a pattern are ignored (like inline elements) or contracted (like paragraphs).
The structure representations that share a common parent node are compared with each other, and if their similarity exceeds a certain threshold, they are considered to be pattern candidates.
Finally, all pattern candidates that do not ful l requirements like e.g.
a certain level of complexity are discarded.
The remaining patterns are taken as a basis for computation of the pattern features mentioned above.
In [1], the pattern extraction algorithm and the features are explained in more detail.
After a preliminary analysis of our focused web genres, we saw the need to split the blog and the forum genre corpora into sub-genres in order to re ect the structural diversity within the di erent web page types in the web genres themselves.
For example, the respective start pages that serve to give an overview of all contained blog posts or forum threads di er structurally from the pages that present the content (in this case the blog post pages and the forum thread pages).
There is no corpus with our genre and multi-language requirements available, so we compiled a corpus containing example instances for machine learning by classi ed examples and to validate the selected features.
From this corpus we randomly selected 200 sample instances per (sub-)genre, getting a corpus containing 1000 multilingual instances (of which 65% are English, 7% German, 7% French and the rest in about twenty di erent European and Asian languages) in  ve di erent genres or sub-genres.
Further, we took great care to include di erent applications per genre, e.g.
for wikis we sampled pages from wiki engines like MediaWiki, Moin-Moin and many others.
For our evaluation, we applied Support Vector Machines with Sequential Minimal Optimization (SMO) for classi cation.
All classi cation results were subjected to tenfold cross validation.
Table 1: Confusion Matrix for classi cation using all features with SMO a







 b







 c







 d







 e   classi ed as a = Blog Page
 b = Blog Post
 c = Wiki Page
 d = Forum Start

 e = Forum Thread



 Using all features, we achieved 90.8% accuracy (i.e. correctly classi ed instances) in our results.
From the result s confusion matrix (see Table 1), one can see that a major source of incorrect classi cation is the distinction between blog start pages (here labeled as class Blog_Page) and blog post pages (Blog_Post).
As these are a liated with the same superordinate genre blog (same with Forum_Start and Forum_Thread), we may integrate these results if we are not interested in detecting the exact sub-genre, getting an overall accuracy of 95.1%.
Ranking all features by information gain shows that among the 20 most important features are HTML tag frequencies, syntactic URL analysis, link analysis, HTML facets and two of the pattern ratio features.
This means that the ratio of how much content of a web resource is contained in recurring patterns is signi cant to the web genre of this resource.
In conclusion, it is possible to achieve a good accuracy for detection of a web genre like blog, wiki and forum and their respecting sub-genres taking into account traditional features and pattern features.
The latter base on the reoccurring HTML markup structures and do not demand knowledge of the language of the HTML s content.
Thus our approach is fully language independent.
Further, it works with di erent systems and applications.
We obtained reasonable results with only a small set of
 ing use of linguistic analysis   often have several thousand features.
Thus the limited number of features in our approach reduces the computational complexity of the actual classi cation task.
Further research will include the   in other web genre detection research often neglected   issue of classifying outliers as well, i.e. detecting if a web page belongs to one of our genres or not.
This is vital for a real world application of this genre detection approach, as we rarely know in advance that our analyzed web resources will only consist of the web genres mentioned here.
Preliminary results show that the accuracy with an included outlier-class performs still well with
 here, we will apply the results gained in our evaluations to the  eld of Community Mining.
The content presented in this paper is a result of the project  Web 2.0 Resources and Artifacts , which was funded by SAP Research.
The authors take responsibility for the content.
