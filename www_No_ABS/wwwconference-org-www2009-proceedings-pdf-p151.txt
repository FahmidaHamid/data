Tasks relying on recognizing entities have recently received signi cant attention in the literature [10, 12, 2, 14, 11, 9].
Many solutions to these tasks assume the existence of extensive reference entity tables.
For instance, extracting named entities such as products and locations from a reference entity table is important for several applications.
A typical application is the business analytics and reporting system which analyzes user sentiment of products.
The system periodically obtains a few review articles (e.g., feeds from review website and online forums), and aggregates user reviews for a reference list of products (e.g., products from certain manufacturers, or products in certain categories).
Such a reporting application requires us to e ectively identify mentions of those reference products in the review articles.
Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
Consider another application.
The entity matching task identi es entity pairs, one from a reference entity table and the other from an external entity list, matching with each other.
An example application is the o er matching system which consolidates o ers (e.g., listed price for products) from multiple retailers.
This application needs to accurately match product names from various sources to those in the system s reference table, and to provide a uni ed view for each product.
At the core of the above two applications, the task is to check whether or not a candidate string (a sub-string from a review article or an entry from an o er list) matches with a member of a reference table.
This problem is challenge because users often like to use phrases, which are not member of the reference table, to refer to some entities.
These phrases can be an individual s preferred description of an entity, and the description is di erent from the entity s conventional name included in a reference table.
For instance, consider a product entity  Lenovo ThinkPad X61 Notebook .
In many reviews, users may just refer to  Lenovo ThinkPad X61 Notebook  by writing  Lenovo X61 , or simply  X61 .
Exact match techniques, which insist that sub-strings in review articles match exactly with entity names in the reference table, drastically limit their applicability in our scenarios.
To characterize whether or not a candidate string matches with a reference entity string, an alternative approach is to compute the string similarity score between the candidate and the reference strings [10, 6].
For example, the (unweighted) Jaccard similarity1 function comparing a candidate string  X61  and the entity  Lenovo ThinkPad X61 Notebook  would observe that one out of four distinct tokens (using a typical white space delimited tokenizer) are common between the two strings and thus measures similarity to be quite low at 1
  Lenovo ThinkPad Notebook  has three tokens which are shared with  Lenovo ThinkPad X61 Notebook , and thus the Jaccard similarity between them is 3
 the common knowledge, we all know that  X61  does refer to  Lenovo ThinkPad X61 Notebook , and  Lenovo ThinkPad Notebook  does not because there are many models in the ThinkPad series.
We observe a similar problem with other similarity functions as well.
Therefore, the string-based similarity does not often re ect the  common knowledge  that users generally have for the candidate string in question.
weights, which may in turn depend on token frequencies in a corpus or a reference table.
serve that the  common knowledge  is often incorporated in documents within which a candidate string is mentioned.
For instance, the candidate string  X61  is very highly correlated with the tokens in the entity  Lenovo ThinkPad X61 Notebook .
And, many documents which contain the tokens  X61  also mention within its vicinity the remaining tokens in the entity.
This provides a stronger evidence that  X61  matches with  Lenovo ThinkPad X61 Notebook .
In this paper, we observe that such  correlation  between a candidate string   and an entity e is seen across multiple documents and exploit it.
We propose new document-based similarity measures to quantify the similarity in the context of multiple documents containing   .
However, the challenge is that it is quite hard to obtain a large number of documents containing a string   unless a large portion of the web is crawled and indexed as done by search engines.
Most of us do not have access to such crawled document collections from the web.
Therefore, we exploit a web search engine and identify a small set of very relevant documents (or even just their snippets returned by a web search engine) containing the given candidate string   .
We rely on these small set of highly relevant documents to measure the correlation between   and the target entity e.
Note that our criteria matching   and e needs the web search results for   to obtain a highly relevant set of documents or snippets containing   .
Hence, evaluating the similarity between a candidate string with entities in a reference table in general may not be applicable.
Our approach here is to  rst identify a set of  synonyms  for each entity in the reference table.
Once such synonyms are identi ed, our task of approximately matching a candidate string with a reference entity is now reduced to match exactly with synonym or original entity names, i.e., the (sub)set of tokens in the candidate string is equal to the token set of either a synonym or of an original entity name.
Methods which only support exact match between candidate strings and entities in a reference table are signi cantly faster (e.g., [3]).
In this paper, we focus on a class of synonyms where each synonym for an entity e is an identifying set of tokens, which when mentioned contiguously (or within a small window) refer to e with high probability.
We refer to these identifying token sets as IDTokenSets.
We only consider IDTokenSets for an entity e which consist of a subset of the tokens in e for two reasons.
First, the reference entity tables are often provided by authoritative sources; hence, each entity name generally does contain the most important tokens required to identify an entity exactly but may also contain redundant tokens which are not required for identifying the entity.
Therefore, it is su cient to isolate the identifying subset of tokens for each entity as an IDTokenSet.
The IDTokenSets of an entity can be considered as keys that uniquely refer to the original entity.
Second, our target applications are mainly entity extraction from documents.
These documents are mainly drawn from the web such as blogs, forums, reviews, queries, etc, where it is often observed that users like to represent a possibly long entity name by a subset of identifying tokens (e.g., 1-3 keywords).
The main technical challenge in identifying IDTokenSets for an entity e is that the number of all token subsets of e could be fairly large.
For example, the entity  Canon EOS Digital Rebel XTI SLR Camera  has 127 subsets.
Directly evaluating whether or not each subset  e of e matches with In other words, if  e    (cid:48) e would require a web search query to be issued.
Therefore, the main challenge is to reduce the number of web search queries issued to identify IDTokenSets for an entity.
Our main insight in addressing this challenge is that for most entities, if the set  e   e of tokens identify an entity e then e where  e    (cid:48) e   e also identi es e (i.e., subset-a set  (cid:48) e   e, superset monotonicity).
then  (cid:48) e is more correlated to e. This is reminiscent of the  apriori  property in the frequent itemset mining [1, 13], where a superset is frequent only if its subsets are frequent.
We assume that the subset-superset monotonicity is true in general and develop techniques which signi cantly reduce the number of web search queries issued.
For example, suppose  Canon XTI  identi es  Canon EOS Digital Rebel XTI SLR Camera  uniquely.
Hence we assume that any superset say  Canon EOS XTI  also identi es e1 uniquely.
Therefore, if we e ciently determine the  border  of IDTokenSets whose supersets are all IDTokenSets and whose subsets are not, then we can often signi cantly reduce the number of web search queries per entity.
In this paper, we develop ef- cient techniques to determine the border e ciently.
We further extend these techniques for multiple entities by taking advantage of entities which are structurally similar.
In summary, our contributions in this paper are as follows.
tween candidate strings and reference entities.
These similarity functions are more accurate than previous string-based similarity functions because they aggregate evidence from multiple documents, and exploit web search engines in order to measure similarity.
kenSets of entities in a reference table.
and demonstrate their accuracy and e ciency.
The remainder of the paper is organized as follows.
We de ne problem in Section 2.
We develop several e cient algorithms for generating IDTokenSets in Section 3, and discuss some extensions in Section 4.
We present a case study that uses IDTokenSets for entity extraction in Section 5.
In Section 6, we discuss the experimental results.
In Section 7, we review the related work.
Finally, we conclude in Section


 We  rst de ne the notation used in the paper.
Let E denote the set of entities in a reference table.
For each e   E, let T ok(e) denote the set of tokens in e. For simplicity, we use e to denote T ok(e).
We use the notation  e to denote a subset of tokens of e. That is,  e   e.
Recall that we focus on identifying token sets which are subsets of the token set of the entity.
That is, an IDTokenSet of an entity e consists of a subset  e of tokens in e.
In the following, we formally de ne IDTokenSets.
As discussed earlier in Section 1, to characterize an IDTokenSet, we rely on a set of documents and analyze correlations between the candidate subset  e and the target entity e.
If a subset  e identi es e, then a large fraction, say  , of documents mentioning  e is likely to contain the remaining tokens in e    e.
We  rst de ne the notion of a document mentioning a token subset.
tokens.
We say that d mentions  e if there exists a sub-string s of d such that T ok(s) =  e.
We are now ready to de ne the aggregated correlation between  e and e with respect to a document set W ( e).
Informally, the aggregated correlation is the aggregated evidence that  e refers to e from all documents mentioning  e.
ID Document d1 The All-New, 2009 Ford F150 takes on ...
d2 Sony Vaio F150 is...business notebook...
d3 An overview of the Ford F150 Pickup...
Table 1: A set of documents corr( e, e, W ( e)) = Example 1.
For instance, the document d2 in Table 1 mentions the subset {V aio, F 150}, and the documents d1 and d3 mention the subset {F ord, F 150} For each document that mentions a subset  e, we check whether the document also contains the remaining tokens in e   e.
In the ideal case, a large fraction of these documents mention tokens in e   e next to the mention of  e.
However, this may be too constraining.
Hence, we relax this notion in two ways.
First, we want to parameterize the context window size p within which we expect to observe all tokens in e e.
Second, it may be good enough to  nd a signi cant fraction of tokens in e   e within the context window of the mention of  e; the size of the fraction quanti es the evidence that  e refers to e.
Definition 2.
(p-window context) Let M = {m} be a set of mentions of  e in a document d = t1, .
.
.
, tn.
For each mention m, let c(m, p) be the sequence of tokens by including (at most) p tokens before and after m. The p-window context of  e in d is C( e, d, p) = (cid:83) m M c(m, p).
Example 2.
For example, the 1-window context of  F150  in document d2 of Table 1 is {Vaio, F150, is} and that in d1 and d3 are {Ford, F150, takes} and {F ord, F 150, P ickup}, respectively.
We now de ne the measure to quantify the evidence that  e refers to e in a document d. We  rst de ne the stricter notion of evidence g1, where all tokens in e   e are required to be present in the p-window context of  e.
(cid:189) g1( e, e, d) = if e   C( e, d, p) otherwise

 We now de ne a relaxed notion of evidence g2 of a document referring to an entity e, which is quanti ed by the fraction of tokens in e   e that are present in the p-window context of  e.
(cid:80) (cid:80) g2( e, e, d) = t C( e,d,p) e w(t) t e w(t) (2) where w(t) is the weight (e.g., IDF weight [5]) of the token t.
The IDTokenSets problem is to generate for a given entity e all its IDTokenSets with respect to a document collection D. In the ideal case, this set corresponds to a large collection of documents on the web which requires us to have access to a crawled repository of the web.
Since this is hard to have access to in the scenarios we focus on, we exploit the web search engines to provide us a small set W ( e) of very relevant document snippets which are highly relevant for  e.
Definition 3.
(Correlation) Given e,  e, a search engine W , we de ne the aggregated correlation corr( e, e, W ( e)) as follows.
(cid:80) g( e, e, d) d W ( e),d mentions  e |{d|d   W ( e), d mentions  e}| Given a correlation threshold  , we say that  e is an ID-TokenSet of e if corr( e, e, W ( e))    .
Example 3.
Let e = Sony Vaio F150 Laptop  be the target entity, and  e = {F 150} be the candidate subset.
Suppose documents in Table 1 are obtained snippets from W ( e).
Each document mentions {F 150}.
In order to validate whether  e = {F 150} is an IDTokenSet of e, we compute: g1( e, e, d1) = 0, g1( e, e, d2) = 1, g1( e, e, d3) = 0.
Thus, corr( e, e, W ( e)) = 1 Suppose the token weights of {Sony, V aio, F 150, Laptop} are {6.8, 9.5, 10.5, 6.5}.
Using g2, we have: g2( e, e, d1) = 0.29, g2( e, e, d2) = 0.80, g2( e, e, d3) = 0.29.
Thus, corr( e, e, W ( e)) = 1.38

 Definition 4.
(IDTokenSets Problem) Given an entity e, a search engine W , and the correlation threshold  , the IDTokenSets problem is to identify the set Se of all subsets such that for each  e   Se, corr( e, e, W ( e))    .
Using the above similarity function, adapting techniques which measure similarity between candidate strings and entities from reference tables directly is an expensive approach.
Therefore, we pre-process the reference entity table and expand the original entities with their IDTokenSets.
By generating accurate IDTokenSets o line, we transform the approximate match against the reference entity table problem to an exact match over the set of IDTokenSets, thus signi -cantly improving the e ciency and accuracy of the approximate lookup task.
(1)

 We now describe our techniques for e ciently generating IDTokenSets of a given set of entities.
We  rst discuss the optimization criterion and the complexity of the optimal solution for generating IDTokenSets of a single entity.
We then outline an algorithmic framework, under which, we develop two algorithms.
We then extend these techniques to generate IDTokenSets for a set of entities, and take advantage of entities which are structurally similar.
We show that one of the discussed algorithms is within a factor of the optimal solution.
The input to our system is a set E of entities, and a search interface W .
For each entity e, all subsets of e consist of the candidate space.
For each subset  e of entity e, we want to validate whether  e is an IDTokenSet of e, using the measure in De nition 3.
Speci cally, the general framework to process an entity e is to validate each of its subsets  e, which consists of the following two steps: (title, URL and snippets) as the relevant documents;
 kenSet if corr( e, e, W ( e))    ; We consider the whole process to validate  e as an atomic operator, and notate it as validate( e).
Furthermore, we assume the cost of validate( e) for di erent  e is roughly same since the most expensive part of validate( e) is sending  e to W .
Thus, in order to e ciently generate all IDTokenSets of an entity e, we need to reduce the number of web search queries we issued.
The optimization is mainly based on the intuition that removing some tokens from a subset  e weakens the correlation between  e and e. On the other hand, adding more tokens (belong to e) to  e enhances the correlation between  e and e. This is formally characterized as the subset-superset monotonicity in De nition 5.
Definition 5.
(subset-superset monotonicity) Given e be two subsets of e, and  e    (cid:48) e.
e is also an IDTokenSet an entity e, let  e and  (cid:48) If  e is an IDTokenSet of e, then  (cid:48) of e.
e ( e    (cid:48) e ( (cid:48) Based on the subset-superset monotonicity, if  e is an ID-e   e) are IDTokenSets TokenSet of e, all subsets  (cid:48) of e, and thus can be pruned for validation.
If  e is not e    e) are not IDTo-an IDTokenSet of e, all subsets  (cid:48) kenSets of e, and thus can be pruned for validation.
Therefore, by appropriately schedule the order in which subsets  e are submitted for validation, we can reduce the number of web search queries.
Before we present the detailed algorithms, we  rst discuss the optimal solution.
In order to exploit the subset-superset monotonicity, we use the lattice structure to model the partial order between all subsets.
An example of subset-lattice of entity  Sony Vaio F150 Laptop  is shown in Figure 1.
Figure 1: Subset-lattice of  Sony Vaio F150 Laptop  The optimal algorithm is built upon the notion of minimal positive subset and maximal negative subset, as de ned below.
Definition 6.
Given an entity e, a subset  e is a minimal positive subset if validate( e) = true and for all subsets e    e, validate( (cid:48)  (cid:48) e) = f alse.
Similarly, a subset  e is a maximal negative subset if validate( e) = f alse and for all subsets  (cid:48) e such that  e    (cid:48) e   e, validate( (cid:48) e) = true.
We use the notation Cut(e) to denote the set of all minimal positive and maximal negative subsets.
We now illustrate it with an example.
Example 4.
Given the entity  Sony Vaio F150 Laptop , e = {sony, vaio, laptop} is not an IDTokenSet the subset   1 since there are models other than F150 in the vaio series.
Consequently, all subsets of {sony, vaio, laptop} are not ID-TokenSets.
Because F150 is a popular ford truck,   2 e = {F 150} is not an IDTokenSet either.
However,   3 e = {sony, e = {F 150, laptop} are all F 150},   4 IDTokenSets.
These  ve subsets constitute the cut.
One can easily verify that all other subsets are either supersets of   3 e ,   4 e = {vaio, F 150} and   5 e or subsets of   1 e ,   2 e .
e ,   5 Consider a special case where all subsets with |e| 2 tokens (suppose |e| is even) are not IDTokenSets and all subsets |e| with
 |e|
 that all subsets with and |Cut(e)| is exponential to |e|.
For a given entity, a scheduling algorithm is optimal if it validates the minimal number of subsets.
One can easily verify that any subset in the cut can not be pruned by other subsets, and thus has to be validated.
The following lemma shows the connection between optimal solution and Cut(e).
|e| 2 or Lemma 1.
Given an entity e, the optimal scheduling algorithm validates and only validates subsets in Cut(e).
In the worst case, the number of subsets in Cut(e) is exponential to |e|.
As shown in the previous subsection, given an entity e, it is su cient to validate those subsets that are in Cut(e).
However, both the maximal negative and minimal positive subsets are not known beforehand.
In this paper, we use a greedy algorithmic framework that iteratively probes a subset, validates it and prunes other subsets (if applicable).
The algorithm stops when no subset is left undetermined.
The framework is outlined in Algorithm 1.
Let Pe be the set of all subsets of e. Our task is to determine for all subsets in Pe, whether they are IDTokenSets of e. The algorithm maintains a set of candidate subsets in Le.
Initially, Le = Pe.
As soon as a subset  e   Le is validated or pruned,  e is removed from Le.
The algorithm repeats the following two steps until Le =  .
If  e is an IDTokenSet, all  e s supersets subset  e.
are determined to be IDTokenSets, and will be pruned from Le for further validation.
If  e is not an IDTo-kenSet, all  e s subsets are determined to be not ID-TokenSets, and will be pruned from Le as well.
next.
We discuss various strategies for implementing getnext in this section.
We now describe two strategies to implement getnext.
The depth rst scheduling starts with the maximal (or minimal) subset, and schedules subsets for validation by following the edges on the lattice structure.
The max-bene t scheduling considers all subsets simultaneously: for each remaining subset, it computes the potential bene t for each subset, and picks the one with the maximal bene t.
                                        WWW 2009 MADRID!Track: Data Mining / Session: Web Mining154Algorithm 1 Generating IDTokenSets for an Entity Input: An entity: e, Search interface: W the size of the context window: p, number of top documents: k, threshold for IDTokenSet:  








 10: return  e = getnext(Le); Submit  e to W , and retrieve W ( e); if (corr( e, e, W ( e))    ) //  e is an IDTokenSet Report  e and all its supersets as IDTokenSets; Remove  e and all its supersets from Le; Remove  e and its subsets from Le; else// e is not an IDTokenSet
 Given an entity e, all its subsets constitute a lattice (see Figure 1).
The main idea of depth rst strategy is to start with a top root node (it can start at the bottom node as well) and recursively traverse the lattice structure.
Suppose the algorithm reaches a node corresponding to a subset  e at some stage.
The getnext step determines which subset to validate next.
It consists of three steps:
 e be a child of  e.
If  (cid:48) e could be   c e (note  (cid:48)   c scheduling.
That is, there is a descendent  (cid:48) status is unknown; e itself),   c e   Le such that  (cid:48) e   e is a candidate for e whose
 e   Le such that  (cid:48) the algorithm looks for the siblings of  e.
Let   s sibling of  e.
If  (cid:48) e ,   s candidate for scheduling; e for scheduling, e be a e     s e is a
 e , and ing, the algorithm goes back to  e s parent   p restarts the step 1 on   p e .
When multiple subsets (such as multiple children of  e or multiple siblings of  e) are available for scheduling, we rely on the intuition that the higher string similarity between the subset and e, the higher the possibility that this subset is an IDTokenSet.
Since the depth rst scheduling starts from e, we expect to quickly  nd a subset that is not an IDTokenSet in order to prune all its descendent subsets.
Therefore, we pick the candidate subset with the lowest string similarity (e.g., the Jaccard similarity as de ned in Section 2).
Similarly, if the traversal starts from the bottom node, we will pick the candidate subset with the highest string similarity.
Theorem 1 gives a performance guarantee by the depth rst scheduling algorithm.
The main insight is that using the depth rst scheduling, we will validate at most |e|   1 subsets before we hit a subset belonging to the cut.
We omit the detailed proof here.
Theorem 1.
Given an entity e, let DF S(e) be the number of validations (e.g., web search queries) performed by the depth rst scheduling, and let OP T (e) be the number of validation performed by the optimal scheduling.
We have DF S(e)   |e|OP T (e).
Di erent from the depth rst scheduling, the max-bene t scheduling does not con ne to the lattice structure.
Instead, at any stage, all subsets in Le are under consideration, and the one with the maximum estimated bene t will be picked.
The getnext step in the max-bene t scheduling works as follows.
For each subset  e   Le, we can bene t in two ways from validating  e: pos benef it( e) if validate( e) = true or neg benef it( e) if validate( e) = f alse.
The bene t is simply computed by the number of subsets in Le that are expected to be pruned.
If validate( e) = true, the bene t of validating  e is de ned as follows.
pos benef it( e) = |{  e| e     (cid:48) e   e and   (cid:48) e   Le}| (cid:48) (3) If validate( e) = f alse, the bene t of validating  e is de ned as follows.
neg benef it( e) = |{  e|  (cid:48) e    e and   (cid:48) e   Le}| (cid:48) (4) We consider three aggregate bene t formulation: max, min and avg, as de ned as follows.
max( e) = max{pos benef it( e), neg benef it( e)} min( e) = min{pos benef it( e), neg benef it( e)} avg( e) = 1 2 (pos benef it( e) + neg benef it( e)) Intuitively, max is an aggressive aggregate which always aims for the best; min is a conservative aggregate which guarantees for the worst scenario; and avg is in between the above two.
For each of the aggregate option, the getnext step picks a  e with the maximum aggregated bene t.
In this subsection, we discuss the techniques for scheduling subset validation when the input consists of multiple entities, and our goal is to generate IDTokenSets for all entities.
We  rst note that our techniques in this section improve the e ciency and the results are still correct.
That is, the result would be the same as that of processing each entity independently, and taking the union of the results.
The intuition is as follows.
Often, names of entities follow an implicit structure.
The IDTokenSets of such structurally similar entities are also likely to follow the implicit structure.
By exploring such structured information across entities, our scheduling strategy can be more e cient.
Suppose there is a group of entities e1, e2, .
.
.
, en, which are structurally similar to each other.
After the  rst i entities are processed, we may have a better idea on which subsets of ei+1 are IDTokenSets and which are not.
For instance, both  lenovo thinkpad T41  and  lenovo thinkpad T60  belong to the thinkpad series from Lenovo.
After processing  lenovo thinkpad T41 , one may identify that {T 41} is an IDTokenSet of  lenovo thinkpad T41 , and {T 41} belongs to the cut.
By observing the structural similarity across entities, we may  rst validate {T 60} in its lattice structure.
Depending on the outcome of validation, the scheduling algorithm may terminate early or proceed further.
In order to build the connection across multiple entities, we  rst group together entities that are structurally similar.
For each group, we create a group pro le, which aggregates statistics from entities in the group processed so far.
Our new bene t estimation function for any subset exploits the the statistics on the group pro le.
We continue to apply that leverages the group pro le statistics.
Observe that our single entity scheduling algorithms operate on the subset lattice structure obtained by tokenizing an input entity.
In order to share statistics for improved scheduling across entities, the statistics also have to be on the same subset lattice structure.
Otherwise, it would be much harder to exploit them.
Therefore, the main constraint on grouping multiple entities together for statistics collection is that we should be able to easily aggregate statistics across entity lattices.
In this paper, we take an approach of normalizing entity names based on  token level  regular expressions.
That is, each of these normalization rules takes as input a single token and maps it to a more general class, all of which are accepted by the regular expression.
The outcome is that entities which share the same normal form (characterized by a sequence of token level regular expressions) may all be grouped together.
More importantly, they would share the same subset lattice structure.
We further denote the normalized form shared by all entities in the group as group pro le.
Some example token level regular expressions are as follows.
  Regular expressions: [0   9]+   P U RE N U M BER,
   Synonyms: {red, green, blue, white, .
.
.}
  COLOR, {standard, prof essional, enterprise}   V ERSION Formally, we de ne the group and its pro le as follows.
An example is given in Example 5.
Definition 7.
Let e1, e2, .
.
.
, en be n entities.
Let N = {rule1, rule2, .
.
.
, ruler} be a set of single token normalization rules.
We denote ei as the normalized form of ei after applying rules in N .
A set {e1, e2, .
.
.
, en} form a group if e1 = e2 = .
.
.
= en.
The group pro le is the normalized entity ei (i = 1, .
.
.
, n).
Example 5.
Suppose the normalization rule is [A Z][0 
 thinkpad T41  and e2= lenovo thinkpad T60 , their normalized forms are both e1 = e2= lenovo thinkpad CHAR NUMBER .
Therefore, e1 and e2 form a group, and the group pro le is  lenovo thinkpad CHAR NUMBER .
Based on the normalized rules, all input entities are partitioned into disjoint groups.
Note that the normalized form of some entities may be the same as the original entity.
This occurs when no normalization rules apply on the entity.
Each entity where no normalization rules apply forms its own group and the multi-entity scheduling reduces to single-entity scheduling strategy.
After grouping entities into multiple partitions, we process entities one group at a time.
In each group, we process entities one by one.
Let e1, e2, .
.
.
, en be entities in a group, and let ep be the group pro le.
For any subset  ei from ei, there is a corresponding subset  ep from ep.
Assume the entities are processed in the order of e1, .
.
.
, en.
In the beginning, there are no statistics on ep.
We will use the single-entity scheduling algorithm (as shown in the previous subsection) to process e1.
Suppose the  rst i entities have been processed, and the next entity is ei+1.
The algorithm  rst updates the statistics on ep using the validation results of ei.
For each subset  ep in ep, we keep two counters:  ep .positive and  ep .negative.
For each subset  ei in ei, if  ei is an IDTokenSet of ei, we increment  ep .positive by 1.
Otherwise, we increment  ep .negative by 1.
After ep has accumulated statistics over a number of entities (e.g., i > 1), we use the pro le information to process ei+1.
Similar to the max-bene t search, among all remaining subsets  ei+1 in Lei+1 , we will pick the one with the maximum bene t.
The idea is that if a subset  ei+1 has higher probability to be an IDTokenSet of ei+1, that is,  ep .positive >  ep .negative, we estimate its bene t using pos benef it( ei+1 ) (e.g., Equation 3).
If  ei+1 has higher probability to be invalid, we estimate its bene t using neg benef it( ei+1 ) (e.g., Equation 4).
If there is a tie between positive count and negative count, we do not consider  ei+1 .
If all subsets tie on the positive and negative counts, we switch to the single entity scheduling algorithm as we did for the  rst entity e1.
The bene t of a subset  ei+1 is formally de ned as follows.
  benef it( ei+1 ) = pos benef it( ei+1 ) if  ep .postive >  ep .negative neg benef it( ei+1 ) if  ep .postive <  ep .negative
 Observe that if for any entity ei+1, where (i > 0), if the pro le ep correctly accumulates the statistics such that for any  ei+1 ,  ei+1 is an IDTokenSet of ei+1 i   ep .positive >  ep .negative, then the pro le-based scheduling algorithm for ei+1 is optimal.
That is, we directly validate the subsets on the Cut(ei+1), thus mimicking the optimal algorithm would.
In our experiments, we observe that the simple bene t function as de ned above works well.
Our algorithmic framework is able to take other bene t functions, and we intend to further explore them in the future.
In this section, we discuss two extensions to our approach.
In the  rst extension, we show how to incorporate additional constraints to prune candidate subsets for generating IDTo-kenSet.
Such constraints are especially meaningful for entities with a large number of tokens.
In the second extension, we relax the de nition of mention (De nition 1) to further enrich the applicability of our techniques.
In the above section, we assume all subsets are candidates for generating IDTokenSet.
In some scenarios, users may have additional constraints that can be applied to prune some subset candidates.
It is especially bene cial if the constraint can be evaluated before the subset is validated.
Thus, we can save the cost of validation.
To incorporate constraints into Algorithm 1, we simply replace Le (the candidate space) by the set of candidates which satisfy the constraints.
The rest of the algorithm remains the same.
In Example 3, {Sony, F 150} is an IDTokenSet of  Sony Vaio F150 Laptop .
However, a document may mention we require that all tokens in a mention be contiguous within a document.
Therefore, we would not identify the mention  Sony PCG F150 .
We now relax the de nition of document mentioning a candidate by relaxing the requirement that a document sub-string consist of a contiguous set of tokens in a document.
Instead, we may consider all sets of tokens which are  close  to each other within a window.
Informally, we consider w-gap token sets from the document where the maximum gap (i.e., number of intervening tokens) between neighboring tokens in the subset is no more than w. A w-gap token set that exactly matches with an IDTokenSet is called w-gap mention.
w controls the proximity of the tokens, w = 0 means that the token set is a contiguous token set in the document d, w =   means any subsets of tokens in d may be a valid mention.
Typically, one may set w = 0 for longer documents such as web pages, and set w =   for short documents such as queries, titles or snippets.
Here we describe a case study that uses IDTokenSets to facilitate fast and accurate entity extraction.
We assume the extraction task is based on a reference entity table, as demonstrated by the example applications in Section 1.
The system architecture, which is outlined in Figure 2, consists of two phases: the o ine phase and the online phase.
Figure 2: System Framework for Entity Extraction The o ine phase generates the IDTokenSets for each reference entity and constructs an exact lookup structure over the IDTokenSets.
The online phase extracts sub-strings as candidates from query documents and checks them against the lookup structure for exact match.
We observe that users often use di erent token order in mentioning an entity.
For instance, both  sony F150 notebook  and  sony notebook F150  refer to the same entity.
Therefore, we apply the set-based exact match criterion (or, the Jaccard similarity with threshold 1) between candidates from query documents and IDTokenSets.
In doing this, we reorder tokens in each ID-TokenSet according to a global order (say, lexicographic).
The tokens in the candidates are also reordered according to the same order.
In order to e ciently extract candidates from query documents, we apply the optimization techniques used in [6].
First, we create a token table which keeps all distinct tokens appearing in the generated IDTokenSets.
Given a query document, we  rst check each token against the token table, and only keep those hit-tokens (i.e., tokens appearing in the table).
We denote a set of contiguous hit-tokens as hit-sequence.
Suppose we derive h hit-sequences from a query document.
The second optimization exploits the concept of strong-token.
From each IDTokenSet, we identify the token with the least frequency over the corpus.
For instance, from the IDTokenSet {sony, F 150, notebook}, one may extract F 150 as the strong-token.
Since we enforce exact match, a strong-token has to be matched between any candidate and its matched IDTokenSet.
We put strong-tokens from all ID-TokenSets into a strong-token table.
For each hit-sequence derived from the  rst step, we check whether it contains a strong token.
A hit-sequence is pruned immediately if it does not contain a strong-token.
For all the remaining hit-sequences, we will enumerate sub-strings with length up to L (suppose the longest IDTokenSet has L tokens), while ensuring that each of which contains at least one strong-token.
We then lookup each of these sub-strings against the lookup structure.
We now present the results of an extensive empirical study to evaluate the techniques described in this paper.
We use real data sets for the experiments.
The reference entity table is a collection of 200k product names (e.g., consumer and electronics, bicycles, shoes, etc).
The number of tokens in the product names varies from 2 to 10, with 3.6 tokens on average.
The major  ndings of our study can be summarized as follows:
 the document-based measure performs signi cantly better than the traditional string-based similarity measure in determining IDTokenSets;
 we generated is within reasonable size (i.e., generally 2-4 times of the original entity number);
 able to prune more than 80% of the web queries in generating IDTokenSet;
 traction shows that using IDTokenSets, our system is able to process 200 documents per second, where each document contains 3, 689 tokens on average; In the remaining of this section, we show the experimental results in terms of quality of IDTokenSets, cost of materializing IDTokenSets and the number of IDTokenSets.
We also report the performance of the entity extraction application.
We use Live Search API 2 to retrieve web documents.
To examine the quality of the IDTokenSets, we compare our proposed document-based measures with the traditional string-based similarity measure (e.g., weighted Jaccard similarity).
We use Live Search to retrieve top-10 results.
Since we only consider title, url and snippets, which are succinct in general, we set w =   in determining w-gap mentions (Section 4.2), and p =   in determining p-window context (Definition 2).
We notate Corr1 for the document-based measure with g1 (Equation 1), Corr2 for the document-based 2http://dev.live.com/livesearch/      Pre-Compute !
"#$	%	  &Exact Set-based MatchPre-ComputeIDTokenSetsOnline Lookup'((()& &&(')*& *)'((()& &DocumentsEntity Mentions&&WWW 2009 MADRID!Track: Data Mining / Session: Web Mining157Figure 3: Precision-Recall on Bicycle Synonyms Figure 4: Precision-Recall on Laptop Synonyms Figure 5: Precision-Recall on Shoe Synonyms Figure 6: Generating IDTokenSet for
 Figure 7: Generating IDTokenSet for
 Figure 8: Number of Web Queries w.r.t.
Entity Number measure with g2 (Equation 2), and Jaccard for the string-based weighted Jaccard Similarity.
The experiments are conducted on three di erence categories: bicycles, shoes and laptops.
In each category, we sample 100 product names, and manually label all subsets which are IDTokenSets.
By varying the threshold in (0.3, 0.5, 0.7, 0.9) for Corr1, (0.6,
 recall curves in Figures 3-5.
We observe that in all three categories, the document-based measures are signi cantly better than the string-based measure.
Among two variants of document-based measures, Corr1 performs better than Corr2.
We notice that Corr1 is a fairly strict measure since it requires all tokens (in the original entity) to be presenting in at least 50% of the documents (assuming threshold is 0.5).
When the threshold is 0.5, it achieves 80% recall and more than 97% precision.
The recall drops when we increase the threshold.
This is expected since not all documents mention all tokens in the context.
To improve the recall, we found it is important to recognize token-synonyms in matching tokens.
For instance, the token in the product title may be  bicycle , and in the document, users may write  bike .
Given the prior knowledge that we are processing bicycle names,  bike  can be matched to  bicycle .
In this experiment, we only use the exact token matching, and the preliminary results is already very promising.
We leave the robust token matching as future work.
Here we compare the computational performance using various strategies for generating IDTokenSets, as discussed in Section 3.
The computation time is roughly proportional to the number of web queries.
Since the time needed for a web query relies on network tra c condition and server loading status, we compare the number of web queries instead.
We use Corr1 as the measure, and  x the threshold to
 consumer product names.
Figure 6 shows the number of web queries used by the following methods: dfs-topdown (DT), the depth rst scheduling starting from e for all entities e in the reference table; dfs-bottomup (DB), the depth rst scheduling starting from   for all e; max-max (MAX), the max-bene t scheduling using max bene t function; max-min (MIN): the max-bene t scheduling using min bene t function; max-avg (AVG), the max-bene t scheduling using avg bene t function; multi-entity (ME): the multiple entity scheduling algorithm; upper-bound (UB), the total number of subsets; and lower-bound (LB), the total number of subsets in the cut (de ned in Section 3.2).
We observe that multi-entity performs the best.
It is close to the optimal scheduling in that the number of web queries is only 1.34 times of that in the lower bound.
Comparing to the upper bound, it prunes more than 80% of web queries.
Within the single entity scheduling, the depth rst
 w.r.t.
Entity Size Figure 10: Number of IDTokenSet w.r.t.
Entity Number Figure 11: Query Performance scheduling performs better than the max-bene t scheduling.
Within the depth rst scheduling, the top-down scheduling strategy is better than the bottom-up scheduling strategy.
This matches the intuition that IDTokenSets generally share more tokens with the original entities.
We also impose an additional constraint that each subset has to appear as a contiguous substring in some documents (as we discussed in Section 4.1).
In order to evaluate the constraint, we still leverage the web search engine to retrieve the relevant documents.
However, sending each subset to the web search engine is equally expensive as validating the subset.
Instead, we using the following heuristic to evaluate the constraint.
For each entity e, we will  rst send e as a query to the web search engine, and retrieve top-K documents (i.e., title, url and snippets), where K could be a large number.
We then evaluate the constraint by checking whether a subsets of e appears contiguously in at least one of these documents.
Figure 7 shows the performance by di erent methods, which is similar to that in the complete lattice case.
Notice that di erent from the complete lattice case where we can compute the lower-bound of the web API calls, we are not able to obtain the lower-bound in the constrained case where candidate subsets form a partial lattice structure.
This is because the optimal solution may pick any subsets in the complete lattice in order to prune subsets in the partial lattice.
The optimal solution is essentially a set covering problem, which is NP-hard.
The last experiment in this subsection is to show the scal-ability of the algorithms.
We  x a mixed strategy such that for all entities with no more than 5 tokens, we apply the complete lattice model; and for entities with more than 5 tokens, we enforce the same constraint in Figure 7.
Figure 8 shows the number of web queries by multi-entity and dfs- topdown, with respect to di erent number of input entities.
We observe that both methods are linearly scalable to the number of input entities.
The performance gain of multi-entity is not signi cant in our experiment.
This is because our entity database is rather diversi ed.
However, it shows a clear trend that multi-entity bene ts more by increasing the entity number.
By increasing the number of entities, the grouping method is able to identify more entities which have similar structure to each other.
Hence, the multi-entity has better chance to locate subsets in the Cut in scheduling.
We pre-compute the IDTokenSet to support e cient approximate match on-the- y.
It is important to show that the IDTokenSets are within the manageable size.
Figure 9 reports the average number of IDTokenSets per entity with respect to di erent entity size (e.g., number of tokens in the entity).
In each size group, we compute the number of IDTo-kenSets for both the complete lattice case and partial lattice case (using the same constraint in Figure 7).
We observe that the constraint is quite e ective in reducing the number of IDTokenSets.
Actually, the constraint is also meaningful since not all IDTokenSets are conventionally used by users.
Figure 10 shows the number of IDTokenSets by increasing the number of entities, using the same experimental con g-uration in Figure 8.
In general, the number of IDTokenSets is about 2-4 times of the entity number.
In the last experiment, we brie y show the performance on entity extraction, using the generated IDTokenSets.
The input string is a collection of 10, 000 documents.
On average, each document contains 3, 689 tokens.
The reference entity table includes 200k entities, from which, we generate 592k IDTokenSets.
We extract all substrings from documents with length up to 10, and apply set based exact match (using a hash-table) over the IDTokenSets.
We use the  lter ideas discussed in Section 5 to prune non-interested sub-strings.
The experiments are conducted on a 2.4GHz Intel Core 2 Duo PC with 4GB RAM, and the execution time is reported in Figure 11.
Our system is fairly e cient in that it is able to process around 200 documents per second.
A number of techniques have been proposed for using dictionary information in entity extraction.
Cohen and Sarawagi [10] exploited external dictionaries to improve the accuracy of named entity recognition.
Agrawal et al. [2] introduced the  ad-hoc  entity extraction task where entities of interest are constrained to be from a list of entities that is speci c to the task, and have also considered approximate match based on similarity functions.
Approximate-match based dictionary lookup was studied under the context of string similarity search in application scenarios such as data cleaning and entity extraction
 tions which only use information from the input string and the target entity it is supposed to match.
In contrast, we develop a new similarity scheme which exploits evidence from a collection of documents.
Our work is related to synonym detection, which is the problem of identifying when di erent references (i.e., sets of attribute values) in a dataset correspond to the same real entity.
Synonym detection has received signi cant attention in the literature [14].
Most previous literature assumed references having a fair number of attributes.
While additional attributes or linkage structures may help provide extra evidence, in this paper, we assume we are only given the list of entity names which is usually the case.
An alternative approach for generating IDTokenSets could be to segment the original entities into attributes.
Consider the entity  Lenovo ThinkPad X61 Notebook , where the tokens can be tagged as follows: Lenovo (Brand Name), ThinkPad (Product Line), X61 (Product Model) and Notebook (Product Type).
A rule based approach then may suggest that Product Model is speci c enough to refer to a product, and hence  X61  is a valid IDTokenSet.
This rule based approach has two limitations.
First, not all entities have a clear schema for segmentation.
For instance, one may not be able to segment a movie name.
Second, even for some entities that can be segmented, the rule based approach is not robust.
Consider another product entity  Sony Vaio F150 Laptop , F150 will be tagged as product model.
Hence the rule based approach may conclude that  F150  is an IDTo-kenSet of  Sony Vaio F150 Laptop .
While actually, from the common knowledge,  F150  is better known as a Ford vehicle.
In contrast, our techniques do not assume that each entity is segmentable into attribute values, and we do not assume the availability of a robust segmentation technique.
Turney [15] introduced a simple unsupervised learning algorithm that exploits web documents for recognizing synonyms.
Given a problem word and a set of alternative words, the task is to choose the member from the set of alternative words that is most similar in meaning to the problem word.
In this paper, we focus on e ciently generating IDTokenSets for a large collection of entities.
The search space is significantly larger than that in [15], and we focus on methods that minimize the generation cost.
The subset-superset monotonicity exploited in this paper is related to the  apriori  property used in many frequent itemset mining algorithms [1, 13].
The di erence is that the subset-superset monotonicity prunes computation in two directions.
That is, if   is a valid IDTokenSet, all    s supersets are pruned for validation; if   is not a valid IDTokenSet, all    s subsets are pruned for validation.
While in frequent itemset mining, the  apriori  property only prunes computation in one direction (e.g., if an itemset   is not frequent, only its supersets are pruned).
In order to support fast and accurate approximate entity match, we propose a new solution by exploiting IDTokenSet.
Our approach di ers from many previous methods in two folders:  rst, we pre-compute a list of IDTokenSets for each entity.
Speci cally, we use the document-based similarity measure to validate IDTokenSets, and leverage web search to retrieve related documents; and Second, we apply exact set-based match over the IDTokenSets at matching phase.
This paper mainly focuses on the quality of the IDTokenSets, as well as e cient algorithms in generating IDTokenSets.
We show the document-based measure is signi cantly better than the traditional string-based similarity measure.
Several algorithms are proposed to e ciently generate IDTokenSets by pruning majority number of web queries.
We plan to explore several directions in future work.
First, we studied a document-based similarity measure in this paper.
One extension is to build a classi er with features derived from multiple documents.
Second, we will consider an alternative computation model where the evidence documents are available for direct access (e.g., scan all documents).
Speci cally, we will exploit batched processing by simultaneously generating IDTokenSets for all entities.
