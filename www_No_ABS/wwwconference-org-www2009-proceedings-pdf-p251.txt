A bidding agent is an entity that implements an online advertising campaign by bidding in ad auctions on behalf of an advertiser.
A recent development in Web advertising is the emergence of an auction-based marketplace for display ads, where advertisers can bid on individual display advertising opportunities in real time auctions, as in sponsored search.
Such a marketplace allows advertisers greater  exibility in the design and implementation of their display advertising campaigns, which were previously restricted to contracts with publishers at pre-negotiated prices.
In this paper, we study the design of bidding agents for display advertising, which implement an ad campaign by bidding in such an auction-based marketplace.
The bidding agent in question could either be an advertiser herself, or an intermediary acting on behalf of the advertiser.
Since display advertising is usually sold on a per impression (CPM) basis, a campaign for display advertising has di erent goals and metrics than one for sponsored search [2].
A CPM-based campaign typically has a target quantity of impressions that need to be acquired over a certain duration with certain targeting characteristics (the targeting can include information both about the webpage on which the ad will appear, as well as the user viewing the page).
In addition to the target quantity, a typical constraint in a CPM campaign is a budget constraint on the total spend, since payment is made on a CPM rather than a per click (CPC) basis.
We will assume that the bidding agent wants to exhaust, rather than simply stay within, the allocated budget, for the following reason.
Di erent advertisers often have different pieces of information regarding how valuable a particular user might be, and often a high bid for an impression re ects this information; thus a high price might indicate high value1.
This also agrees with anecdotal observations that advertisers prefer to exhaust their budgets.
Consider a bidding agent that needs to win d impressions and has a total budget T .
We assume that the bidding agent knows the total supply n of impressions satisfying the tar-
on behalf of an advertiser would also like to deliver high-value impressions subject to the chosen budget.
Since our algorithms target supply over budget when they are not simultaneously feasible, the intermediary can deliver the cheapest impressions if desired by choosing a small enough budget.
a lower bound on the supply can be used instead).
De ne f = d/n to be the fraction of the supply that the agent needs to win, and de ne t = T /d to be target spend per impression won.
We suppose that the highest bids from other bidders are drawn i.i.d.2 from a distribution with CDF P, and that each impression is sold using a second price auction.
In general, a given target quantity and spend need not be simultaneously feasible for the distribution P if this happens, we always choose in favor of quantity (our algorithms can be modi ed to make the opposite choice).
If the distribution P is known to the bidding agent, then the problem is simple (under weak conditions described in Section 2).
Let z(cid:63) = P 1(f ) be the bid that would win fraction f of the supply.
De ne p(cid:63) such that EP [X | X   p(cid:63) ] = t, that is, p(cid:63) is the bid that achieves the target spend t in If z(cid:63)   p(cid:63) then bidding p(cid:63) with probability expectation.
A = f /P(p(cid:63)) independently on each available impression achieves both the supply and spend targets in expectation.
Otherwise, prioritizing supply, we bid z(cid:63) achieving the desired fraction of supply in expectation.
In practice, of course, the distribution P is not known to the bidding agent.
Our problem is therefore one of learning the unknown distribution P in order to meet the target quantity and spend constraints.
However, learning incurs a penalty, leading to an explore-exploit tradeo .
The nature of the penalty depends on the assumptions made about the extent of information available to the bidding agent.
We consider two settings:   Fully Observable Exchange.
Here, the winning bid in each auction is announced publicly, so that the bidding agent can learn without placing any bids and therefore expending any budget.
The only tradeo  here is between accuracy and length of exploration, which could a ect feasibility during exploitation.
  Partially Observable Exchange.
A harder problem is when the winning bid is not announced publicly  only the winner receives information about the price and therefore the distribution (a realistic setting in online advertising).
Thus the bidding agent can infer information about P only by bidding high enough to win, i.e., it must pay for every sample it observes from the distribution.
We begin in Section 2 with algorithm Learn-Then-Bid for the fully observable case, and provide performance guarantees using non-asymptotic uniform convergence results for empirical processes.
While the algorithm is simple it observes and then bids according to the empirical distribution, the analysis is a useful  rst step for the partially observable case.
A natural improvement is to continue to learn while exploiting; this algorithm indeed outperforms Learn-Then-Bid as shown experimentally in Section 4.
In Section 3 we move on to the partially observable case, which is harder since a cost must be paid for every bid that is observed from the distribution.
We give an algorithm Guess-Double-Panic that explores the distribution gradually based on a guess-then-double pattern, in order to control the spend in the learning phase.
A simple guess-then-double algorithm does not su ce since the distribution may have mass concentrated right above a guess, leading to severe
 overspending upon doubling.
We introduce a panic phase to the algorithm to deal with this problem, which limits the overspending and admits performance guarantees.
In Section 4 we experimentally evaluate these algorithms, as well as some additional heuristics, on realistic data derived from the Right Media Exchange.
Both Learn-Then-Bid (and its improved version Learn-While-Bid ) and Guess-Double-Panic perform very well for a wide range of target fractions and spends.
The experiments also demonstrate that natural heuristics for the partially observable case are indeed inadequate, and are well outperformed by Guess-Double-Panic.
Most interestingly, the lack of full information is not a severe handicap: Guess-Double-Panic does nearly as well as Learn-Then-Bid despite access to only partial information.
Related work: Although there are many commercial ventures that optimize campaigns on behalf of advertisers, the design and analysis of bidding agents for online advertising has not received much attention in the research literature.
The focus has largely been on bidding agents for sponsored search keyword auctions for instance, Cary et al. [2] propose and analyze a pragmatic bidding agent for sponsored search.
Unlike display advertising, the goal there is to choose the optimal (utility maximizing) slot to bid on for each keyword; the authors show that there is a greedy bidding strategy that leads to convergence to equilibrium when all advertisers use the same strategy.
In this paper, we consider approaches inspired by online learning (cf.
[3] for a survey).
In particular, our results are similar to those on the multi-armed bandit algorithm UCB1 [1] where there is an unknown stationary distribution over events from round to round; we do almost as well asymptotically as we would had the distribution been known in advance.
However, although this work has been extended to uncountably in nite action spaces [5], it di ers in two major factors: we try to get the correct average behavior (i.e., to behave correctly on average).
Regret is inappropriate for this setting: bids going over budget result in a payo  of  .
Second, the expected price obtained on a given round as a function of the bid (roughly analogous to cost in [6]) is not only non-convex, but there is also no predetermined Lips-chitz constant K, making discretization of the action space unboundedly ine cient as a method of approximation.
As an alternative, we focus on the speci c properties of the problem to more e ciently explore and exploit.
We  rst consider a fully observable exchange where the winning bid is revealed after every auction.
After describing the algorithm we use the DKW inequality to bound the error on our estimates and the suboptimality of our performance.
Learn-Then-Bid takes as input a target fraction f , spend t, supply n and exploration length m. It explores for m steps by bidding 0, that is, simply waiting and forms the empirical CDF Pm from the observations Ei   P. It then computes bid value3 P (cid:63) m that would achieve the target spend t, and Z (cid:63) m that would achieve the necessary fraction, and bids P (cid:63) m with probability Am if is feasible to achieve both targets on Pm, else it bids Z (cid:63) m.
We prove that the expected future fraction of impressions won and amount spent per impression by Learn-Then-Bid
 Algorithm Learn-Then-Bid (f, t, n, m)
 m   inf {p : EPm [X | X   p ]   t} i=1 1 [Ei   x]; (cid:111) f n (n m)Pm(P (cid:63) m) (cid:110)





 9: else
 11: end if m   inf m   Z (cid:63) for opportunities i   {m + 1, .
.
.
, n} do z : Pm(z)   f n n m m then Bid P (cid:63) m with probability Am, and 0 otherwise.
for opportunities i   {m + 1, .
.
.
, n} do Bid Z (cid:63) m.
converge in probability with rates exponential in the learning phase length.
We assume that the distribution P is continuous, strictly monotonic, has support on [a, b] where 0   a < b <   and P(a) = 0.
This implies that g(y) = EP [X | X   y ] is well-de ned, continuous and strictly increasing over [a, b], and so P 1 and g 1 are well-de ned also.
Many of the results we obtain depend upon the problem being feasible after exploration.
In Section 4 we show experimentally that m can be chosen small enough so that the problem remains feasible for most f and t. Moreover in normal scenarios, one needs a small number of impressions and has a small budget, and the total number of impressions tends to be large.
Definition 1.
De ne   = f n n m .
If t   EP [X], de ne p(cid:63) = g 1(t).
A problem is feasible after exploration if t   EP [X] and P(p(cid:63))    .
Note that this also implies     1.
We will refer to   and p(cid:63) throughout this section as de ned above.
The performance of the algorithm depends primarily upon the accuracy of the exploration phase measurements.
Definition 2.
For a given  > 0, the algorithm has -accurate observations if for all x   [a, b]: |P(x)   Pm(x)|    .
(1) The following is a restatement of the DKW inequality [4].
For the remainder of the analysis, we will condition our results on the observations being -accurate.
Corollary 3.
For  > 0, the probability of the algorithm having -accurate observations is greater than or equal to 1   2 exp(cid:0) 2m2(cid:1).
We next link -accuracy to the expected fraction of supply won when bidding Z (cid:63) m.
Lemma 4.
Given  > 0, if the problem is feasible after exploration, and the Learn-Then-Bid algorithm has -accurate observations then m)    |    .
Proof.
We  rst consider bidding Z (cid:63) |P(Z (cid:63) m on each round of the bidding phase; our goal is to prove that the expected fraction won P(Z (cid:63) m) is close to the target fraction   w.h.p.
If (2)     , then P(Z (cid:63) m)   0       .
If   > , then (0,     ] (cid:54)=  , and for any (cid:48)   (0,     ], de ne z(cid:63)  = P 1(       (cid:48)).
Because the algorithm has -accurate observations: (cid:0)z(cid:63) (cid:1)   P(cid:0)z(cid:63) (cid:1) +  =      Pm (cid:48) <     Pm (Z (cid:63) m) , and so z(cid:63)  < Z (cid:63) for all (cid:48)   (0,     ], P(Z (cid:63) P(Z (cid:63) m by the monotonicity4 of Pm.
Therefore, m) > P(z(cid:63) ) =       (cid:48), implying m)       .
By a similar argument, P(Z (cid:63) m)     + .
Our  rst main result states that Learn-Then-Bid wins close to f n opportunities, if the algorithm has -accurate observations and the problem is feasible after exploration.
The following lemma is a consequence of a positive partial derivative.
Lemma 5.
For  ,  > 0, x (x+) 1 is strictly increasing, and x (x   ) 1 is strictly decreasing.
Theorem 6.
Given  > 0, and j > m, let Bj be the jth bid of the Learn-Then-Bid algorithm.
If the problem is feasible after exploration and the algorithm has -accurate observations, then: m and therefore Bj = Z (cid:63)        E[P(Bj)|E1 .
.
.
Em]            2   .
(3) Proof.
From Lemma 4, we know that |P(Z (cid:63) m)    |   .
m   P (cid:63) m, then        P(Bj)   If Z (cid:63)   +       2  .
Therefore for the remainder of the proof we assume that P(P (cid:63) m with probability Am, and zero otherwise (P(0) = 0).
The conditional probability of winning bid j given the outcome of the exploration phase is P(P (cid:63) it is this value we wish to show is close to the target  : P(P (cid:63) In this case, Bj = P (cid:63)          m)   P(Z (cid:63) m)       .
m)Am:   .
m) m)Am =     P(P (cid:63) P(P (cid:63) P(P (cid:63) m) Pm(P (cid:63) m) m) +    The  rst equality follows by de nition of Am, the  rst inequality follows due to the -accurate observations, and the  nal inequality is a consequence of Lemma 5 and the inequality P(P (cid:63) m)       .
We upper-bound the expected fraction won in a similar fashion: m)   P(Z (cid:63) P(P (cid:63) m) Pm(P (cid:63) m)     P(P (cid:63) P(P (cid:63) m) m)                 2   .
Our second theorem establishes that Learn-Then-Bid spends close to budget if the observations are -accurate and the problem is feasible after exploration.
To prove this, we  rst convert DKW-type uniform closeness of true and empirical CDFs to uniform closeness of expected spend.
This  uniformity  is gained by focusing only on the area of interest, bids that obtain at least      impressions.
( )( 2) + (b a)  2 , For a given    (0,  /2), de ne   = b  ( ) + (b a)   and + = b
 m) because Pm is weakly monotonic, thus the need for (cid:48) > 0.
.
de ne the function gm(y) = EPm [X | X   y ].
If the algorithm has -accurate observations , then if Y   z(cid:63) : gm(Y )        g(Y )   gm(Y ) + + .
Proof.
Because the algorithm has -accurate observations, both of the following relations hold5 for all y   [a, b]: (cid:12)(cid:12)(cid:12)(cid:12)(cid:90) y a (1   P(x)) dx   (cid:90) y a |P(y)   Pm(y)|    (1   Pm(x)) dx (cid:12)(cid:12)(cid:12)(cid:12)   (b   a) .
Lower-bounding gm(Y ) with the above relations, identity c+ = d c(c+) , and P(Y )   P(z(cid:63) ) =     : c   d d gm(Y ) = a (1   Pm(x)) dx Pm(Y ) a +(cid:82) Y   a +(cid:82) Y = g(Y )   (a +(cid:82) Y a (1   P(x)) dx
   (b   a)
 a (1   P(x)) dx)
   (b   a) b .
 (    )     g(Y )     (b   a)
 (4) Upper-bounding gm(Y ) proceeds by the same arguments and identity d c  = d c + d c(c ) .
Theorem 8.
Given the problem is feasible and    (0,  /2), if the algorithm has -accurate observations, j > m and Bj is the jth bid and Bj > 0, then: t       g(Bj)   t + +.
Proof.
t        g(max(Z (cid:63) m, P (cid:63) m))   t + + .
(5) m, P (cid:63) Note that if j > m and Bj > 0 then Bj = g(max(Z (cid:63) m)).
As with Lemma 4, we need to analyze values that bracket the value of interest.
In particular, the  rst value of interest is z(cid:63)  = P 1(    ).
If g(z(cid:63) )   t    , then by Lemma 4, m   z(cid:63) , and by the monotonicity of max(Z (cid:63) m, P (cid:63) m))   g(z(cid:63) )   t    .
Therefore, we can g, g(max(Z (cid:63) assume that g(z(cid:63) ) < t   .
Since t > t    > g(z(cid:63) )   a, t     is in the range of g and g 1(t    )   z(cid:63) .
For (cid:48)   (0, t       a], de ne p(cid:63)  = g 1(t       (cid:48)).
m)   Z (cid:63) m, P (cid:63) gm(p(cid:63)  )    = t    (cid:48) )   g(p(cid:63)  < t   gm(P (cid:63) m) , m, P (cid:63) so p(cid:63)    P (cid:63) creasing, for any (cid:48) > 0, t       (cid:48)   g(P (cid:63) t       g(P (cid:63) t + +   g(P (cid:63) From Corollary 3 the algorithm has -accurate observations m. Therefore, because g is monotonically in-m), implying m)   g(max(Z (cid:63) m)).
By a similar argument, m).
with probability 1   2 exp(cid:0) 2n2(cid:1).
Combining this with ration.
If    (0,  /2): With probability 1   2 exp(cid:0) 2n2(cid:1): Theorems 6 and 8 proves that Learn-Then-Bid  s performance converges to the targets in probability with fast rates: Theorem 9.
Given a problem that is feasible after explo-t        g(Bj)   t + + if Bj > 0 (6)        E[P(Bj)|e1 .
.
.
em]            2 (7)
 bounded, monotonic functions.
  .
We now move on to the partially observable case, where information is revealed only to an auction s winner.
This problem is more di cult because the bidder must pay a cost in order to obtain information; speci cally, we cannot simply learn about the auction by bidding zero for a while.
The most brute force approach is to bid   for an exploration period, but that can cause overspending by almost b/t when the target fraction is small.
In this section, we will try to be approximately optimal.
If b/t is small then we can bid b: however, we also want to handle the case where b/t is large.
Consider a simple algorithm that works rather well: bid 2t blindly until the correct number of impressions are obtained.
Observe that since the minimum bid to get f n impressions is less than the bid that gets an expected price of t, then the expected price paid when a bid is made which obtains f n is less than or equal to t. Therefore, by Markov s inequality, the number of the lowest f n impressions below 2t is f n/2.
Moreover, the most that one can spend is 2tf n, and since the budget is tf n, this is only twice the budget.
Therefore, this algorithm will not dramatically overspend and it will obtain half the required impressions.
Instead of either of these extremes (bidding 2t blindly or aggressively exploring with b), we will apply the guess-then-double pattern.
This approach is used in a variety of domains.
For instance, if we want to create an array of items but do not know how many elements it will contain, we make a guess, and if we need more space, we double the size of the array.
Thus, the number of new allocations is logarithmic in the number of elements entered, and the number of copies is linear, and the size may be o  by no more than a factor of two.
Of course, doubling is only one possibility: in the case of the array, multiplying by a factor   smaller than 2 will result in more copies but greater e ciency in space.
In the Guess-Double-Panic algorithm, we apply a modi- cation of this technique to bids in the exploration phase.
We will refer to a bid being used during exploration as an exploration bid.
A  safe  bid6 is t, the target spend, since there is no danger of going over budget.
From this point, we exponentially increase our exploration bid, exploring enough with each new bid to learn the distribution below this bid.
At some point we notice our exploration bid exceeds p(cid:63).
A na ve approach is to simply test for this condition at each iteration, and then react to our experience at the end of each phase of the exploration (i.e., remove lines 8-9).
However, this can result in a large amount of overspending, as the following example shows.7 The target price is 10 cents and we need to obtain 10% of the 1000 impressions.
Therefore, we are searching for 100 impressions for $10.00 total.
The distribution of bids is: 9.9% are at 1 cent.
0.1% are at $9.01.
Finally, the remaining 90% of the bids are at $10.00.
An ideal bid is $9.01.
However, it is di cult to say whether this one bid will be observed.
Unless there is a very slow exploration, the bids will likely exceed $10.00 during exploration.
Thus, there will be a high penalty where the algorithm will most likely pay 10 times its budget.
Instead, if we start overspending during the exploration phase, we go to the Panic() subroutine, where we move into
 happen if we get many opportunities while we are bidding too low.
However, this is not a problem so long as the exploration period is su ciently short with respect to  n.
overspending, then we momentarily ignore the budget, and target solely the number of impressions obtained.
As before, we continue to increase the bids, but if we realize that we can get enough impressions in the exploitation phase, we immediately move on to the exploitation phase.
The algorithm continues to explore (or panic) until it  nds a price Bi(cid:63) where it estimates its budget can be exhausted and it can win enough impressions (or it has explored at b or above).
As with the observable case, we have a good approximation of the outcome of bidding any price below Bi(cid:63) as we leave the exploration phase.
In particular, there are now three modes of operation.
The  rst mode is exploration: the algorithm explores until it either gets enough information or the budget becomes tight.
The second (optional) mode is panic: the budget is tight, but the algorithm does not have enough information to obtain the right number of impressions, so it aggressively grabs impressions until it reaches a more stable scenario.
The third stage is exploitation.
In the exploitation stage, if there is su cient budget to obtain the right number of impressions, then the algorithm tries to exhaust the budget.
Otherwise, it is thrifty and tries to get the right number of impressions at a discount price.
For the following algorithm, all variables are global.
Algorithm Guess-Double-Panic(f, t, n, m,  )


 Bi < b do i   i + 1.
Si     to be a multiset.
for k = 1 to m do
















 end if end for if Si (cid:54)=   then Ti   1|Si| Pi   |Si|
 m .
22: end while 23: i(cid:63)   i.
 return Panic() if (gremain   1)Ti 1 + Bi 1 > budget then j   j + 1.
if gremain = 0 then Terminate.
Bid Bi.
if Bid wins then De ne pj   price won.
gremain   gremain   1.
budget   budget   pj.
Add pj to Si.
(cid:80) p else Ti   0.
p Si The  rst danger of using any exploration technique is that the problem may be unsolvable if one spends too much time exploring.
Note that there will be no more than r = (cid:100)log (b/t)(cid:101) + 1 rounds of exploration, because then the bid will be above b.
In each round, there are m bids, so mr is the maximum number of steps of exploration.
Definition 10.
De ne   = f n n mr .
If t   EP [X], de ne p(cid:63) = g 1(t).
A problem is feasible after exploration if t   EP [X] and P(p(cid:63))    .
(Again, this implies     1.)
if gremain < Pi 1(n   j) then De ne pj   price won.
gremain   gremain   1.
budget   budget   pj.
Add pj to Si.
end if j   j + 1.
Bid Bi.
if Bid wins then Subroutine Panic
 26: while k   m do
 i(cid:63)   i   1.
return Exploit().
end if k   k + 1.
end while k   1.
if Si (cid:54)=   then Ti   1|Si| Pi   |Si| m .
i   i + 1.
Si     to be a multiset.
47: end while 48: i(cid:63)   i   1.
(cid:80) p Si p else Ti   0.
Let us consider the period that generated Si.
De ne S(cid:63) i to be the multiset of all prices (observed and unobserved) during this period (clearly not an observed set).
As in the observed case, there are several observations we could make about this distribution (although in this case only theoretically).
Formally, de ne: P i m(x) = m  1|{y   S(cid:63) i |y   x}| .
(8) Moreover, we can look at these independently from the algorithm itself.
Definition 11.
The algorithm has -accurate observa-m(x) P(x)|   tions if for each i   {1 .
.
.
r}, argmaxx [a,b] |P i .
servations is at most 2((cid:100)log (b/t)(cid:101) + 1) exp(cid:0) 2m2(cid:1).
Lemma 12.
The probability of not having -accurate ob-The probability of -accurate observations can be determined by applying the DKW inequality to each round of exploration/panicking, and then applying a union bound.
De ne Cexplore, Cpanic and Cexploit to be the spend during exploration, panic and exploitation, respectively.
De ne nexplore, npanic and nexploit to be the number of impressions won during exploration, panic and exploitation phases, respectively.
De ne m(cid:48) to be the number of opportunities during the exploration and panic phases combined.
De- ne n(cid:63) exploit to be the target number of impressions that remain after the exploration and panic phases.
Note that this is equal to gremain at the beginning of the exploitation phase.
Instead of targeting   as we did before, we are tar-exploit   f n geting  (cid:48) = and m(cid:48)   mr, implying that  (cid:48)   1.
Because the number of impressions obtained is a priority, the proof that this is achieved is fairly straightforward.
The spend we will bound is C = Cexplore + Cpanic + E[Cexploit|E1 .
.
.
Em(cid:48) ].
, where  (cid:48)     because n(cid:63) n(cid:63) exploit n m(cid:48)


 Pi(cid:63) (n j) .
Sort p   Si(cid:63) : de ne qk to be the kth smallest p in Si(cid:63) .
ks  (cid:108) gremain (cid:109) n j m (cid:80)k .
k gremain i=1 qi.
for k = 1 to |Si(cid:63)| do gk   1 t(cid:63)   budget kp   mink:gk t(cid:63) k.
k(cid:63)   max(ks, kp).
m .
A(n j) .
63: end if


 67: end while Bid B nal with probability A, 0 otherwise.
If Bid won then gremain   gremain   1.
Theorem 13.
If the problem is feasible after exploration, and the algorithm has -accurate observations, then: f n   nexplore + npanic + (n   m where B nal and A are as in Line 65.
)P(B nal)A   f n    , (cid:48) m, and qkp is analogous to P (cid:63) Proof.
The upper bound is true because there is always a check that gremain > 0 before any bid is made.
The proof of the lower bound has the same rough outline as Theorem 6.
qks is analogous to Z (cid:63) m. Now the target fraction of impressions to win during exploitation may be lower than  , due to some being won during the exploration and panic.
However, it is still easy to prove that |P(qks )    (cid:48)|    using techniques similar to Lemma 4, because the proof does not depend upon the target.
The most serious issue is when kp   ks (analogous to P (cid:63) m), there is no implicit lower bound on P(qkp ) outside of  (cid:48).
This makes the upper bounds that we obtained in Theorem 6 impossible to obtain, and why we explicitly bound the number of impressions obtained from above.
However, the lower bounds on AP(qkp ) work out just as in Theorem 6.
m   Z (cid:63) We prove an upper bound on the spend of the algorithm.
Theorem 14.
If the algorithm has -accurate observations and the problem is feasible after exploration, then C    tf n + (1/3 + 2/3)nb.
Proof.
With Lemmas 15-21, we cover overspending based upon every outcome of exploration and panic, as well as the relationship between ks and kp.
In particular:
 Lemma 15 applies if kp   ks, and Lemma 21 applies if kp < ks.
Lemma 16 applies.
Lemma 17 applies if no panic bids are made, Lemma 18 applies if a panic bid of Bi(cid:63)+1 is made, Lemma 20 applies if the largest panic bid is Bi(cid:63) and kp   ks, and Lemma 19 applies if kp > ks.
Lemma 15.
If the algorithm exits the exploration phase at Line 24, the algorithm has -accurate observations, the problem is feasible after exploration, and kp   ks, then the amount overspent is less than C   tf n + (1/3 + 2/3)bn.
Proof.
As before, if a large fraction of the impressions remains, then the estimates will be accurate.
On the other hand, if many of the impressions are already gone, the impact of making a mistake is less.
We choose a point,  (cid:63) = 1/3+, as a threshold: if  (cid:48) >  (cid:63), we can bound the spend normally.
If  (cid:48)    (cid:63), then the most we can spend is  (cid:63)b.
As we consider the bound proven in Lemma 7, if we replace   with  (cid:63) in Equation 4, then we get: gm(Y )   g(Y )   b  (cid:63)( (cid:63)   ) b   (b   a)  (cid:63)   (b   a) 1/3 ( + 1/3)(1/3) = g(Y )     g(Y )   1/3b   2/3(b   a)   g(Y )   1/3b   2/3b .
(9) (10) (11) (12) Equation 12 follows because decreasing the denominator (replacing +1/3 with ) makes the term larger, but making a negative term larger makes the overall expression smaller.
Also, since    1, 2/3   , implying  (cid:48)b   1/3b + 2/3b.
Lemma 16.
If exploration exits due to Line 11, then C    tf n .
Proof.
De ne B(cid:63) to be equal to budget at the last time Line 8 was visited.
This is the ideal amount to bid on the last bid such that the budget is exactly met.
The maximum amount that could be bid would be Bi.
Before the last bid was made, gremain = 1 and (due to Line 8), Bi 1   B(cid:63).
Therefore, Bi    B(cid:63).
The maximum amount overspent would be Bi   B(cid:63)   (    1).
Since B(cid:63)   tf n, the result follows.
Lemma 17.
If exploration exits on Line 9, and no panic bids (Line 32) are made, then C    tf n + (1/3 + 2/3)nb.
Proof.
During the middle of an exploration phase, an impression is won (which we will call the overpriced impression) and Line 8 is true.
De ne pop to be the price of this bid.
At the time when the expression in Line 8 is true: tf n   budget = Cexplore + Cpanic gremain = n(cid:63) exploit .
(13) (14) Consider the last time that Line 8 is false, i.e.when one less impression was won and pop less was spent.
tf n   budget = Cexplore + Cpanic   pop (15) gremain   1 = n(cid:63) (16) exploit (gremain   1)Ti 1 + Bi 1   budget (n(cid:63) exploit)Ti 1 + Bi 1 (17)   tf n + pop   (Cexplore + Cpanic) .
(18) In this case, since we go through panic, at this time i 1 = i(cid:63), we can reframe this as a bound on the  spend : Cexplore + Cpanic + (n(cid:63) exploit)Ti(cid:63)   tf n + pop   Bi(cid:63) .
Because pop   Bi(cid:63)   (    1)Bi(cid:63)   (    1)tf n: Cexplore + Cpanic + (n(cid:63) exploit)Ti(cid:63)    tf n .
(19) (even though Ti(cid:63) is an estimate of g(Bi(cid:63) )).
The remainder is similar to Lemma 15.
There are two scenarios: either Pi(cid:63) is small, and therefore few impressions are left to obtain, or Pi(cid:63) is large and Ti(cid:63) is accurate.
Formally, consider  (cid:63) = +1/3.
If Pi(cid:63)    (cid:63), then because the expression in Line 27 is true, exploit   n (cid:63).
If Pi(cid:63)    (cid:63), then P(Bi(cid:63) )    (cid:63)   , then n(cid:63) substituting  (cid:63) for   in Lemma 7: g(Bi(cid:63) )   Ti(cid:63) + (b   a)  (cid:63) + b  (cid:63)( (cid:63)   ) b (b   a)  + 1/3 (1/3 + )(1/3) = Ti(cid:63) + +   Ti(cid:63) + 1/3b + 2/3(b   a)   Ti(cid:63) + 1/3b + 2/3b .
(20) (21) (22) (23) Summarizing: exploit)   max( (cid:63)nb, (Ti(cid:63) + 1/3b + 2/3b)f n) g(Bi(cid:63) )(n(cid:63) Cexplore + Cpanic + n(cid:63) exploitg(Bi(cid:63) )    tf n + max( (cid:63)nb, (1/3b + 2/3b)f n) .
Because  (cid:63) =  + 1/3, and f   1, the result follows.
Lemma 18.
If, during the Panic() algorithm, a bid of Bi(cid:63)+1 is the highest bid that is actually made, the problem is feasible after exploration, and the algorithm has -accurate observations, then C   f n(t  + b).
Proof.
During exploitation, the algorithm bids no more than Bi(cid:63) , so the expected price per impression is at most g(Bi(cid:63) ).
This is the easy part; the hard part is bounding the spend during exploration and panic.
De ne b(cid:63) = min(Bi(cid:63)+1, b), the largest e ective bid during panicking.
How many impressions need to obtained before the algorithm realizes it can bid Bi(cid:63) for the remainder?
Formally: max #big bids won = f n   (P(Bi(cid:63) )   )(n   mr) = f n = f n = f n Cpanic + Cexploit   f n (cid:19) f n (cid:18)
 (cid:18)
 (cid:18)     (P(Bi(cid:63) )   ) (cid:18)     (P(Bi(cid:63) )   ) (cid:19) (cid:19) (cid:19)     b(cid:63) .
  In other words, the maximum fraction of bids won during exploration and panic is ( +     P(Bi(cid:63) ))  1.
Note that if the algorithm were to bid P 1( )   p(cid:63), then in expectation (    P(Bi(cid:63) ))  1 bids would be Bi(cid:63) or above.
Therefore, if the problem is feasible after exploration: t = g(p(cid:63))   g(P 1( ))       P(Bi(cid:63) )   Bi(cid:63) + P(Bi(cid:63) )   g(Bi(cid:63) )   t        P(Bi(cid:63) )       P(Bi(cid:63) ) t  + b(cid:63)       P(Bi(cid:63) )   P(Bi(cid:63) ) Bi(cid:63)   + g(Bi(cid:63) )   P(Bi(cid:63) ) b(cid:63) +   g(Bi(cid:63) ) P(Bi(cid:63) )   P(Bi(cid:63) )   g(Bi(cid:63) ) b(cid:63) + b(cid:63) + g(Bi(cid:63) )    +     P(Bi(cid:63) ) b(cid:63) +     f n(t  + b)   Cexplore + Cpanic + E[Cexploit|E1 .
.
.
Em(cid:48) ]] .
The last line is due to the fact that b(cid:63) is a bound on the price during exploration and panic, g(Bi(cid:63) ) is a bound on the expected price during exploitation, and the worst-case scenario is to have the maximum number of bids during the exploration and panic phases.
Lemma 19.
If the largest panic bid is Bi(cid:63) , during exploitation ks < kp (such that the bid during exploitation is based upon the target spend t), the problem is feasible after exploration, and the algorithm has -accurate observations, then C   tf n + (1/3 + 2/3)bn.
Proof Sketch.
This scenario is rare, in that it implies that the algorithm panicked, but then somehow the budget recovered.
One possibility is that a very high but unlikely bid was obtained, followed by small but unlikely bids.
Since the last round is -accurate, the argument is similar to Lemma 15.
Lemma 20.
If the largest panic bid is Bi(cid:63) , during exploitation ks   kp (such that the bid during exploitation is based upon the target number of impressions), the problem is feasible after exploration, and the algorithm has -accurate observations, then C    tf n + nb.
In this case, we know that P(Bi(cid:63) 1)   Proof Sketch.
  + , and for however long we are exploring and panicking, we know that Bi(cid:63) 1 is not expected to give us enough impressions, just as with Bi(cid:63) in Lemma 18.
If the exploitation bid B was less than or equal to Bi(cid:63) 1 (e.g., due to a change in the estimation from Si(cid:63) 1 to Si(cid:63) ), then the analysis from Lemma 18 holds, with i(cid:63)   1 replacing i(cid:63).
If B > Bi(cid:63) 1, we know that all the bids we obtained during exploration and panicking were not enough, and during exploitation, we choose a bid such that we get just enough impressions above Bi(cid:63) 1.
Thus, these impressions above Bi(cid:63) 1 during exploitation and the impressions during exploration and panicking are almost exactly enough such that bidding Bi(cid:63) 1 during exploitation would have won the remainder.
Therefore, Lemma 18 s argument completes the result.
Lemma 21.
If the algorithm exits the exploration phase at Line 24, the algorithm has -accurate observations, the problem is feasible after exploration, and kp < ks, then C    tf n + (1/3 + 2/3)nb.
Proof.
This is similar to Lemma 17, in that the algorithm does not have more than one impression that is overpriced (note that the last impression won during exploration may be overpriced).
Therefore, with the exception that i(cid:63) = i, a variant of Equation 19 holds here.
Cexplore + Cpanic + (n(cid:63) (24) If B nal   Bi(cid:63) 1, then the argument from Lemma 17 holds, in that the algorithm might has well of panicked.
exploit)Ti(cid:63) 1    tf n .
panicked: the key condition (that it needs more impressions that it believes will be obtained by Bi(cid:63) 1) is satis ed at the end of the exploration phase, which is loosely what is required in Lemma 20.
Note that the bound in Lemma 17 is looser than the bound in Lemma 20.
Unfortunately, there are cases where the algorithm can underspend.
For instance, suppose that the objective is to obtain a very small number of impressions at a very high price.
For instance, 10% of the impressions are at $11.00, and 90% are at $1.00, and the target spend is $2.00, and the algorithm wants 1% of the impressions.
Therefore, bidding $11.00 is ideal.
However, if the algorithm starts by bidding $2.00, it is possible that before exploration is over, the algorithm obtains enough impressions, but has only spent half the budget.
Of course, in this case, the algorithm which starts by bidding b to explore is doing just the right thing.
Figure 1: The observed and modeled distribution of the winning bid on the Right Media Exchange.
In this section we evaluate our algorithms on synthetically derived data drawn from a log-normal distribution, which  ts data observed from the Right Media Exchange.
Algorithms for the fully observable case are evaluated in Section 4.2, and the partially observable case in Section 4.3.
To evaluate our algorithms, we collected winning bids from live auctions run on the Right Media Exchange, which has over 50,000 buyers and sellers and processes over 6 billion impressions daily.
The bids we collected represent a 1% uniform sample across a variety of individual publish ers.
Focusing on a single publisher, we plot the CDF of the empirical distribution of the bids in Figure 1.
While it is di cult to predict the winning bid on any particular impression, for a  xed publisher the data can be  tted with a log-normal distribution with the appropriate mean and variance.
In Figure 1 we provide such a  t for a single publisher (350,000 auctions total).
While the exact variance changes from publisher to publisher, on all instances the data can be  tted well with a log-normal distribution.
Based on the above  t, we sample i.i.d.
from a log-normal distribution with mean and variance one.8 While very large prices are never observed on the exchange, the log-normal distribution supports arbitrarily large prices.
We deal with this by discarding samples larger than an upper-limit b, chosen to be the 99.7th percentile.
That is, we sample from the log-normal distribution conditioned on {X   b}.
We set the supply to be n = 10, 000 impressions.
To evaluate each algorithm we choose 16 evenly spaced values of target f and target t from the interval (0, 1), and measure the actual fraction and spend against the targets (we include only 4 data points each for clarity).
For each of the 256 parameter settings, we run each algorithm on 500 i.i.d.
samples to average out e ects of sampling.
m, Am and Z (cid:63) The Learn-Then-Bid algorithm waits for a signi cant exploration period before bidding.
An obvious improvement is the Learn-While-Bid algorithm which continues to learn during exploitation: Pm, P (cid:63) m are updated after each bid, as in Learn-Then-Bid lines 2 5 but with adaptive targets.
Although harder to analyze, this has the advantage of a possibly shorter exploration phase without compromising estimation accuracy.
We compare the performance of these two algorithms experimentally: on average both algorithms perform very close to ideal.
However, Learn-While-Bid spending is more tightly concentrated around the ideal than Learn-Then-Bid for the same exploration-only phase.
Figures 2 and 3 show the spending of Learn-Then-Bid and Learn-While-Bid respectively.
The dotted lines depict the minimum spending necessary to achieve the target fraction of supply as given by max{E [X | X   z(cid:63)] , t}: when the fraction and spend goals cannot simultaneously be satis ed, both algorithms prioritize the former while minimizing over spending.
The distribution of each algorithm s spending, for each (f, t) pair, is summarized by a box-and-whisker plot: each box depicts the 25%, 50% (the median) and 75% quan-tiles representing the spread of spending.
As is evident in the  gures, more runs of Learn-While-Bid have spend close to the ideal.
To achieve comparable concentration with Learn-Then-Bid, m must be increased.
However this can lead to infeasibility for high f (e.g.
for m = 1, 000 and f = 0.94 the problem becomes infeasible leading to underdelivery).
Figure 4 plots the performance of the algorithms with respect to supply.
Both algorithms win close to the target fraction of supply for a wide range of target spending goals.
Figure 5 compares theory and practice, depicting our bounds on the concentration of the fraction of supply won and the spending per impression won, with respect to increasing exploration length.
As exploration increases, the bounds become tighter but at the same time the problem becomes harder to satisfy until it becomes infeasible (occurring at the maximum m shown).
Also shown are empirical results for running Learn-Then-Bid.
In particular for each m value (exploration phase length), Learn-Then-Bid was run 1, 000 times.
For each run the fraction won during exploitation, and the spend per impression won, were calculated and the
 this case the distribution-free theory matches the empirical results well, particularly for concentration of fraction won.
distribution does not a ect our algorithms  behavior; they deliver the same supply and actually overspend less (since there is a larger fraction of lower-priced impressions).
by Learn-Then-Bid with m = 100 for 4 values of f .
Figure 3: Actual & ideal spend per impression won by Learn-While-Bid with m = 100 for 4 values of f .
Figure 4: Fraction of supply won by Learn-Then-Bid and Learn-While-Bid with m = 100 for 4 values of t.
Figure 5: Learn-Then-Bid supply and spend 95% con dence bands given by: the concentration bounds, and 1,000-sample empirical quantiles.
In this section we evaluate algorithms for bidding in a partially observable exchange.
The Guess-Double-Panic algorithm outperforms the strawman bidders in terms of target spend for a wide range of target supply fractions.
More interestingly, the lack of full information does not handicap the Guess-Double-Panic algorithm: the accuracy of supply and spend are very close to those for full information.
Figures 6 and 7 plot the supply and spend for Guess-Double-Panic as well as two strawman algorithms, Max-Then-Bid and Bid-Two-t.
Given that Learn-Then-Bid performs well even for very short exploration phases, it is natural to apply the same idea in the partially observable setting: Max-Then-Bid bids b in the length m exploration phase and then exploits based on the empirical distribution.9 While Max-Then-Bid performs well on supply it is an inferior strategy for target spend, since the spending during exploration can be very high: speci cally when f and t are both small the algorithm must acquire the right number of
 impressions acquired despite partial information: Max-Then-Bid wins every impression during exploration in contrast to Learn-Then-Bid which wins zero.
Also, if the problem is feasible after Learn-Then-Bid  s exploration then it will be feasible for Max-Then-Bid.
Then-Bid and Guess-Double-Panic with m = 100 for 4 values of t. Figure 7: Spend per impression won by Bid-Two-t, Max-Then-Bid and Guess-Double-Panic with m = 100 for 4 values of f .
impressions at a low price, and Max-Then-Bid is very likely to overspend.
Guess-Double-Panic will perform well precisely in this setting due to its more cautious exploration starting with a bid of t as opposed to b.
This comparison is borne out in Figure 7 where Max-Then-Bid overspends most dramatically relative to Guess-Double-Panic for the lowest target fraction f = 0.059; overspending is evident for higher values up to f = 0.59.
The Bid-Two-t strawman algorithm does not perform much better than expected from theory, which predicts supply and spend within only a loose multiplicative factor of the targets.
We study the problem of acquiring a given number of impressions with a given budget constraint by bidding against an unknown distribution.
Our approach consists of learning the distribution in an exploration phase, and then bidding according to the empirical distribution of observations from exploration.
We consider both the fully observable and the harder partially observable case, and present algorithms with theoretical performance guarantees that also perform very well in experimental evaluations against realistic data.
The experiments indicate that in addition to performing well with respect to both constraints, our algorithm for partial information does nearly as well as algorithms in the full information setting despite the fact that a cost must be paid for every sample during exploration.
The performance of the algorithms improves as the supply increases, and is asymptotically optimal since a longer exploration phase can be used for higher accuracy; also, the actual number of impressions won and the total spend are more tightly concentrated around their means as n increases.
The most interesting direction for further research is removing the i.i.d.
assumption, and considering a game theoretic perspective: we assume that every other bidder in each individual auction has unit demand and therefore bids his value; one can instead consider best response and equilibrium analysis when a number of bidding agents compete in such a marketplace.
We gratefully acknowledge the support of the NSF through grant DMS-0707060.
