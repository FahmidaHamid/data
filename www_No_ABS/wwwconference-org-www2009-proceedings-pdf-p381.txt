In the current search model, the user expresses her information need with the use of a few query terms.
In such a  Work done while author was an intern at Microsoft Search Labs Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
scenario, the small number of terms often specify the intent implicitly.
In the absence of explicit information representing user intent, the search engine needs to  guess  the results that are most likely to satisfy di erent intents.
In particular, for an ambiguous query such as eclipse, the search engine could either take the probability ranking principle approach of taking the  best guess  intent and showing the results, or it could choose to present search results that maximize the probability of a user with a random intent  nding at least one relevant document on the results page.
This problem of the user not  nding any any relevant document in her scanned set of documents is de ned as query abandonment.
Result diversi cation lends itself as an e ective solution to minimizing query abandonment [1, 9, 18].
Intuitively, diversi cation implies a trade-o  between having more relevant results of the  correct  intent and having diverse results in the top positions for a given query [6, 8].
Hence the twin objectives of being diverse and being relevant compete with each other, and any diversi cation system must  gure out how to trade-o  these objectives appropriately.
This often results in the diversi cation problem being characterized as a bi-criteria optimization problem.
Diver-si cation can be viewed as combining both ranking (presenting more relevant results in the higher positions) and clustering (grouping documents satisfying similar intents) and therefore addresses a loosely de ned goal of picking a set of most relevant but novel documents.
This has resulted in the development of a set of very di erent objective functions and algorithms ranging from combinatorial optimizations [6, 18, 1] to those based on probabilistic language models [8, 22].
The underlying principles supporting these techniques are often di erent and therefore admit di erent trade-o  criteria.
Given the importance of the problem there has been relatively little work aimed at understanding result diversi cation independent of the objective functions or the algorithms used to solve the problem.
In this work, we initiate an axiomatic study of result di-versi cation.
We propose a set of simple properties that any diversi cation system ought to satisfy and these properties help serve as a basis for the space of objective functions for result diversi cation.
Generally, a diversi cation function can be thought of as taking two application speci c inputs viz, a relevance function that speci es the relevance of document for a given query, and a distance function that captures the pairwise similarity between any pair of documents in the set of relevant results for a given query.
In the context of web search, one can use the search engine s ranking the distance function is not that clear.
In fact, designing the right distance function is key for having e ective result diversi cation.
For example, by restricting the distance function to be a metric by imposing the triangle inequality d(u, w)   d(u, v) + d(v, w) for all u, v, w   U , we can exploit e cient approximation algorithms to solve certain class of diversi cation objectives (see Section 3).
In this work, we propose a set of natural axioms for result diversi cation that aid in the choice of an objective function and therefore help in constraining the resulting solution.
Our work is similar in spirit to recent work on axiomatiza-tion of ranking and clustering systems [2, 12].
We study the functions that arise out of the requirement of satisfying a set of simple properties and show an impossibility result which states that there exists no diversi cation function f that satis es all the properties.
We state the properties in Section 2.
Although we do not aim to completely map the space of objective functions in this study, we show that some di-versi cation objectives reduce to di erent versions of the well-studied facility dispersion problem.
Speci cally, we pick three functions that satisfy di erent subsets of the properties and characterize the solutions obtained by well-known approximation algorithms for each of these functions.
We also characterize some of the objective functions de ned in earlier works [1, 18, 8] using the axioms.
Finally, we do a preliminary characterization of the choice of an objective (and its underlying properties) using the natural measures of relevance and novelty.
We posit that di erent subsets of axioms will exhibit di erent trade-o s between these measures.
Towards this end, we provide an evaluation methodology that computes the measures based on the disambiguation pages in Wikipedia2, which is the largest public-domain evaluation data set used for testing a diversi cation system (see Section 5).
Further, we consider two distance functions - a semantic distance function and a categorical distance function (see Section 4) - to test the effectiveness of the objectives under two di erent application contexts.
The early work of Carbonell and Goldstein [6] described the trade-o  between relevance and novelty via the choice of a parametrized objective function.
Subsequent work on query abandonment by Chen and Karger [8] is based on the idea that documents should be selected sequentially according to the probability of the document being relevant conditioned on the documents that come before.
Das Sarma et.
al. [18], solved a similar problem by using bypass rates of a document to measure the overall likelihood of a user bypassing all documents in a given set.
Thus, the objective in their setting was to produce a set that minimized likelihood of completely getting bypassed.
Agrawal et.
al., [1] propose a diversi cation objective that tries to maximize the likelihood of  nding a relevant document in the top-k positions given the categorical information of the queries and documents.
Other works on topical diver-si cation include [23].
Zhai and La erty [22, 20] propose a
 2http://en.wikipedia.org risk minimization framework for information retrieval that allows a user to de ne an arbitrary loss function over the set of returned documents.
Vee et.
al., [19] proposed a method for diversifying query results in online shopping applications wherein the query is presented in a structure form using online forms.
Our work is based on axiomatizations of ranking and clustering systems [3, 12, 2].
Kleinberg [12] proposed a set of three natural axioms for clustering functions and showed that no clustering function satis es all three axioms.
Altman and Tennenholtz [2] study ranking functions that combine individual votes of agents into a social ranking of the agents and compare them to social choice welfare functions which were  rst proposed in the classical work on social choice theory by Kenneth Arrow [3].
One of the contributions of our work is the mapping of di-versi cation functions to those used in facility dispersion [15,
 on facility dispersion in [16, 7].
This section introduces the axiomatic framework and  xes the notation to be used in the remainder of the paper.
We are given a set U = {u1, u2, .
.
.
, un} of n   2 of documents, and a set (we ll assume this to be  nite for now) of queries Q.
Now, given a query q   Q and an integer k, we want to output a subset Sk   U of documents3 that is simultaneously both relevant and diverse.
The relevance of each document is speci ed by a function w : U   Q   R+, where a higher value implies that the document is more relevant to a particular query.
The diversi cation objective is intuitively thought of as giving preference to dissimilar documents.
To formalize this, we de ne a distance function d : U   U   R+ between the documents, where smaller the distance, the more similar the two documents are.
We also require the distance function to be discriminative, i.e.
for any two documents u, v   U , we have d(u, v) = 0 if and only if u = v, and symmetric, i.e d(u, v) = d(v, u).
Note that the distance function need not be a metric.
We restrict attention to the set selection problem instead of the search problem of selecting a ranked list as this is clearly a simpler problem.
In particular, the approach we will take is to  nd the best set and then rank it in order of relevance.
Formally, the set selection function f : 2U   Q   w   d   R can be thought of as assigning scores to all possible subsets of U , given a query q   Q, a weight function w( ), a distance function d( , ).
Fixing q, w( ), d( , ) and a given integer k   Z+ (k   2), the objective is to select a set Sk   U of documents such that the value of the function f is maximized, i.e. the objective is to  nd
   k = argmax Sk U |Sk|=k f (Sk, q, w( ), d( , )) where all arguments other than the set Sk are  xed inputs to the function.
An important observation is that the diversi cation framework is underspeci ed and even if one assumes that the relevance and distance functions are provided, there are many possible choices for the objective function f .
These functions could trade-o  relevance and similarity in di erent ways, and
 |Sk| = k tions.
A natural mathematical approach in such a situation is to provide axioms that any diversi cation system should be expected to satisfy and therefore provide some basis of comparison between di erent objective functions.
We propose that f is such that it satisfy the set of axioms given below, each of which seems intuitive for the setting of diversi cation.
In addition, we show that any proper subset of these axioms is maximal, i.e. no diversi cation function can satisfy all these axioms.
This provides a natural method of selecting between various objective functions, as one can choose the essential properties for any particular diversi cation system.
In section 3, we will illustrate the use of the axioms in choosing between di erent diversi cation objectives.
Before we state the axioms, we state the following notation.
Fix any q, w( ), d( , ), k and f , such that f is maximized by S  k = argmaxSk U f (Sk, q, w( ), d( , )).
k, i.e., S 
 Informally, this property states that the set selection function should be insensitive to the scaling of the input functions.
Consider the set optimal set S  k. Now, we require f to be such that we k = argmaxSk U f (Sk, q,     w( ),     d( , )) for have S  any  xed positive constant     R,   > 0, i.e. S  k still maximizes f even if all relevance and distance values are scaled by some constant.
put documents more relevant and more diverse, and making other documents less relevant and less diverse should not change the output of the ranking.
Now, given any two functions   : U   R+ and   : U   U   R+, we modify the relevance and weight functions as follows: w(u) = w(u) +  (u) w(u)    (u) , u   S  , otherwise k ( ( d(u, v) = d(u, v) +  (u, v) d(u, v)    (u, v) , u, v   S  k , otherwise The ranking function f must be such that it is still maximized by S  k.
states that we should be able to achieve any possible set as the output, given the right choice of relevance and distance function.
Formally, there exists some w( ) and d( , ) such that for any k   2, there is a unique
 k which maximizes f .
the output set does not change arbitrarily with the output size, i.e., the function f should be de ned such that S  k   S  k+1.
  d(u, v) for all u, v /  S.
addition of any document does not decrease the score of the set.
Fix any w( ), d( , ), f and S   U .
Now, for any x /  S, we must have f (S   {x})   f (S)
 no function f ignores the relevance function.
Formally, we  x some w( ), d( , ), f and S. Now, the following properties should hold for any x   S: (a) There exist some real numbers  0 > 0 and a0 > 0, such that the condition stated below is satis ed after the following modi cation: obtain a new relevance function w(cid:48)( ) from w( ), where w(cid:48)( ) is identical to w( ) except that w(cid:48)(x) = a0 > w(x).
The remaining relevance and distance values could decrease arbitrarily.
Now, we must have f (S, w (cid:48) ( ), d( , ), k) = f (S, w( ), d( , ), k) +  0 (b) If f (S \ {x}) < f (S), then there exist some real numbers  1 > 0 and a1 > 0 such that the following condition holds: modify the relevance function w( ) to get a new relevance function w(cid:48)( ) which is identical to w( ) except that w(cid:48)(x) = a1 < w(x).
Now, we must have f (S, w (cid:48) ( ), d( , ), k) = f (S, w( ), d( , ), k)    1
 no function f ignores the similarity function.
Formally, we  x some w( ), d( , ), f and S. Now, the following properties should hold for any x   S: (a) There exist some real numbers  0 > 0 and b0 > 0, such that the condition stated below is satis ed after the following modi cation: obtain a new distance function d(cid:48)( , ) from d( , ), where we increase d(x, u) for the required u   S to ensure that minu S d(x, u) = b0.
The remaining relevance and distance values could decrease arbitrarily.
Now, we must have f (S, w( ), d (cid:48) ( , ), k) = f (S, w( ), d( , ), k) +  0 (b) If f (S \ {x}) < f (S), then there exist some real numbers  1 > 0 and b1 > 0 such that the following condition holds: modify the distance function d( , ) by decreasing d(x, u) to ensure that maxu S d(x, u) = b1.
Call this modi ed distance function d(cid:48)( , ).
Now, we must have f (S, w( ), d (cid:48) ( , ), k) = f (S, w( ), d( , ), k)    1
 iom states that the score of a set is not a ected by most attributes of documents outside the set.
Specifically, given a set S, we require the function f to be such that f (S) is independent of values of:   w(u) for all u /  S.
Given these axioms, a natural question is to characterize the set of functions f that satisfy these axioms.
A somewhat surprising observation here is that it is impossible to satisfy all of these axioms simultaneously (proof is in appendix): Theorem 1.
No function f satis es all 8 axioms stated above.
maximal.
This result allows us to naturally characterize the set of diversi cation functions, and selection of a particular function reduces to deciding upon the subset of axioms (or properties) that the function is desired to satisfy.
The following sections explore this idea further and show that the axiomatic framework could be a powerful tool in choosing between diversi cation function.
Another advantage of the framework is that it allows a theoretical characterization of the function which is independent of the speci cs of the di-versi cation system such as the distance and the relevance function.
In light of the impossibility result shown in Theorem 1, we can only hope for diversi cation functions that satisfy a subset of the axioms.
We note that the list of such functions is possibly quite large, and indeed several such functions have been previously explored in the literature (see [8,18,1], for instance).
Further, proposing a diversi cation objective may not be useful in itself unless one can actually  nd algorithms to optimize the objective.
In this section, we aim to address both of the above issues: we demonstrate the power of the axiomatic framework in choosing objectives, and also propose reductions from a number of natural diver-si cation objectives to the well-studied combinatorial optimization problem of facility dispersion [16].
In particular, we propose three diversi cation objectives in the following sections, and provide algorithms that optimize those objectives.
We also present a brief characterization of the objective functions studied in earlier works [1, 18, 8].
We will use the same notation as in the previous section and have the f (Sk, q, w( ), d( , )), where objective as S  f would vary from one function to another.
Also, we assume w( ), d( , ) and k to be  xed here and hence use the shorthand f (S) for the function.
k = argmax Sk U |Sk|=k A natural bi-criteria objective is to maximize the sum of the relevance and dissimilarity of the selected set.
This objective can be encoded in terms of our formulation in terms of the function f (S), which is de ned as follows: f (S) = (k   1) w(u) + 2  d(u, v) (1)
 u,v S
 u S where |S| = k, and   > 0 is a parameter specifying the trade-o  between relevance and similarity.
Observe that we need to scale up the  rst sum to balance out the fact that there are k(k 1) numbers in the similarity sum, as opposed to k numbers in the relevance sum.
We  rst characterize the objective in terms of the axioms.
Remark 1.
The objective function given in equation 1 sat-is es all the axioms, except stability.
This objective can be recast in terms of a facility dispersion objective, known as the MAXSUMDISPERSION problem.
The MAXSUMDISPERSION problem is a facility dispersion problem having the objective maximizing the sum of all pairwise distances between points in the set S which we show to be equivalent to equation 1.
To this end, we de ne a new distance function d(cid:48)(u, v) as follows: (cid:48) d (u, v) = w(u) + w(v) + 2 d(u, v) (2) Input : Universe U , k Output: Set S (|S| = k) that maximizes f (S) Initialize the set S =   2(cid:99) do for i   1 to (cid:98) k Find (u, v) = argmaxx,y U d(x, y) Set S = S   {u, v} Delete all edges from E that are incident to u or v end If k is odd, add an arbitrary document to S Algorithm 1: Algorithm for MAXSUMDISPERSION It is not hard to see the following claim (proof skipped): Claim 1. d(cid:48)( , ) is a metric if the distance d( , ) constitutes a metric.
Further, note that for some S   U (|S| = k), we have: (cid:48) (u, v) = (k   1) d w(u) + 2  d(u, v)
 u,v S
 u,v S
 u S
 u,v S using the de nition of d(cid:48)(u, v) and the fact that each w(u) is counted exactly k   1 times in the sum (as we consider the complete graph on S).
Hence, from equation 1 we have that f (S) = (cid:48) d (u, v) But this is also the objective of the MAXSUMDISPERSION problem described above where the distance metric is given by d(cid:48)( , ).
Given this reduction, we can map known results about MAXSUMDISPERSION to the diversi cation objective.
First of all, we observe that maximizing the objective in equation 1 is NP-hard, but there are known approximation algorithms for the problem.
In particular, there is a 2-approx-imation algorithm for the MAXSUMDISPERSION problem [13,
 we can use algorithm 1, for the max-sum objective stated in equation 1.
The second bi-criteria objective we propose, maximizes the minimum relevance and dissimilarity of the selected set.
This objective can be encoded in terms of our formulation in terms of the function f (S), which is de ned as follows: f (S) = min u S w(u) +   min u,v S (3) where |S| = k, and   > 0 is a parameter specifying the trade-o  between relevance and similarity.
Here is the characterization of the objective in terms of the axioms: d(u, v) Remark 2.
The diversi cation objective given in equation 3 satis es all the axioms except consistency and stability.
We proceed as before to link this objective to facility dispersion, and the dispersion objective that is relevant in this case is MAXMINDISPERSION.
The objective for the MAX-MINDISPERSION problem is: g(P ) = minvi,vj P d(vi, vj), which we now show to be equivalent to equation 3.
As before, we combine the objective in equation 1 in terms of a single metric, with which we can then solve the MAXMIN-DISPERSION problem.
To this end, we de ne a new distance Output: Set S (|S| = k) that maximizes f (S) Initialize the set S =  ; Find (u, v) = argmaxx,y U d(x, y) and set S = {u, v}; For any x   U \ S, de ne d(x, S) = minu S d(x, u); while |S| < k do Find x   U \ S such that x = argmaxx U\S d(x, S); Set S = S   {x}; end Algorithm 2: Algorithm for MAXMINDISPERSION function d(cid:48)(u, v) as follows: Now, we show how to use this algorithm for the bi-criteria objective given in equation 3.
In order to do this, we again need to combine our objective function in terms of a single metric, with which we can then solve the MAXMINDISPERSION problem.
Hence, we de ne a new distance function d(cid:48)(u, v) as follows: (cid:48) d (u, v) =

 (w(u) + w(v)) +  d(u, v) (4) It is not hard to see the following claim (proof skipped): Claim 2.
The distance d(cid:48)( , ) forms a metric if the distance d( , ) forms a metric.
Further, note that for some S   U (|S| = k), we have: d(u, v) = f (S) d (cid:48) (u, v) = min u S w(u) +   min u,v S min u,v S from equation 3.
This is also the objective from the MAX-MINDISPERSION problem where the distance metric is given by d(cid:48)( , ).
Hence, we can use algorithm 2 to approximately maximize the objective stated in equation 3.
Again, we can map known results about the MAXMIN-DISPERSION problem to equation 3, such as NP-hardness.
We describe a 2-approximation algorithm in algorithm 2 that was proposed in [15], and refer the reader to [15] for further results.
The third and  nal objective we will explore does not relate to facility dispersion as it combines the relevance and the similarity values into a single value for each document (as opposed to each edge for the previous two objectives).
The objective can be stated in the notation of our framework in terms of the function f (S), which is de ned as follows: f (S) = (cid:48) w (u) (5)
 u S where the new relevance value w(cid:48)( ) for each document u   U is computed as follows: (cid:48) w (u) = w(u) +  
 d(u, v)
 v U for some parameter   > 0 specifying the trade-o  between relevance and similarity.
Intuitively, the value w(cid:48)(u) computes the  global  importance (i.e. not with respect to any particular set S) of each document u.
The axiomatic characterization of this objective is as follows: Also observe that it is possible to exactly optimize objective 5 by computing the value w(cid:48)(u) for all u   U and then picking the documents with the top k values of u for the set S of size k.
We note that the link to the facility dispersion problem explored above is particularly rich as many dispersion objectives have been studied in the literature (see [16,7]).
We only explore two objectives here in order to illustrate the use of the framework, and also because other objectives share common algorithms.
For instance, the MAXMSTDISPERSION problem seeks to maximize the weight of the minimum spanning tree of the selected set.
It turns out that algorithm 2 is the best known approximation algorithm for this objective as well, although the approximation factor is 4.
The axiomatic framework can also be used to characterize diversi cation objectives that have been proposed previously (we note that the characterization might be nontrivial to obtain as one needs to cast the objectives in our setting).
In particular, we point out that the DIVERSIFY objective function in [1] as well as the MINQQUERYABANDONMENT formulations proposed in [18] violate the stability and the independence of irrelevant attributes axioms.
The diversi cation algorithm only partially speci es the framework, and to complete the speci cation, we also need to specify the distance and the relevance functions.
We describe the relevance function later in the experiments, and focus on the distance function here as it depends on the content of the data set being used, and might be of independent interest.
Speci cally, we describe the distance function for web pages and product hierarchies.
Semantic distance is based on content similarity between two pages.
Instead of using the whole of a page in the similarity computation, we use simple sketching algorithms based on the well known min-hashing scheme [5, 10] to compute the sketch of a document and then apply Jaccard similarity between sketches to compute the pairwise semantic distance between the documents.
We state this more formally.
Fix a hash function h that maps elements from the universe U to a real number uniformly at random in [0, 1].
Then the min-hash of a set of elements A is de ned as M Hh(A) = argminx{h(x)|x   A}.
Therefore, M Hh(A) is the element in A whose hash value corresponds to the minimum value among all values hashed into the range [0, 1].
This computation can be easily extended to multi-sets wherein the min-hash of a bag A is computed as M H(A) = argmin x {h(x, i)|x   A, 1   i   cx}, where cx is the frequency of element x in A.
Thus, given k hash functions h1,  , hk, the sketch of a document d is S(d) = {M Hh1 (d), M Hh2 (d), .
.
.
, M Hhk (d)}.
We can now compute the similarity between two documents as sim(u, v) = |S(u)   S(v)| |S(u)   S(v)| Remark 3.
The objective in equation 5 satis es all the axioms except consistency.
We note that Jaccard similarity is known to be a metric.
However, one issue that makes such a computation of sim(u, v) simple approach to handle such random documents, would be to discard documents that have a small sketch size.
Thus, one characterization of the semantic distance between two documents u and v could be d(u, v) = 1   sim(u, v)
 (6) The semantic distance is not applicable in all contexts.
One scenario is when two  intuitively  similar documents like http://www.apache.org/ and http://www.apache.org/docs actually might have very di erent sketches.
However, these documents are  close  to each other with respect to the distance in the underlying web graph.
However, computing the pairwise distance of two web pages based on their web graph connectivity can be very expensive.
Taxonomies o er a succinct encoding of distances between pages wherein the category of the page can be viewed as its sketch.
Therefore, the distance between the same pages on similar topics in the taxonomy is likely to be small.
In this context, we use a weighted tree distance [4] as a measure of similarity between two categories in the taxonomy.
Distance between two nodes u and v in the tree is computed as l(u)X i=1 l(v)X i=1 d(u, v) =
 2e(i 1) +
 2e(i 1) (7)
 where e   0 and l( ) is the depth of the given node in the taxonomy.
This de nition of a weighted tree distance reduces to the well-known tree distance (measured in path length through the least common ancestor   lca(u, v)) when e is set to zero and to the notion of hierarchically separated trees (due to Bartal [4]) for greater values of e. Thus, nodes corresponding to more general categories (e.g.,/Top/Health and /Top/Finance) are more separated than speci c categories (e.g., /Top/Health/Geriatrics/Osteoporosis and /Top/Health/Geriatrics/Mental Health).
We can extend this notion of distance to the case where a document belongs to multiple categories (with di erent con dences), one cannot equate the categorical distance to the distance between nodes in the taxonomy.
Given two documents x and y and their category information Cx and Cy respectively, we de ne their categorical distance as dc(x, y) = u Cx,v Cy min(Cx(u),Cy(v)) argmin d(u, v) (8) v where Cx(u) denotes the con dence (or probability) of document x belonging to category u.
Recall that we used the axiomatic framework to characterize di erences between diversi cation objectives in section 3.
We now switch gears to investigate the other method of distinguishing between various objectives, namely through their experimental behavior.
In this section, we characterize the choice of the objective function and its underlying axioms using two well-known measures relevance and novelty.
We demonstrate the usefulness of the diversi cation framework by conducting two sets of experiments.
In the  rst set of experiments, which we call semantic disambiguation, we compare the performance of the three diversi cation algorithms using the set of Wikipedia disambiguation pages,4 as the ground truth.
For instance, the Wikipedia disambiguation page for jaguar5 lists several different meanings for the word, including jaguar the cat and jaguar cars, along with links to their Wikipedia pages.
The titles of the disambiguation pages in Wikipedia (for instance, jaguar in the above example) serve as the query set for our evaluation.
This is a natural set of queries as they have been  labeled  by human editors as being ambiguous and the search engine would want to cover their di erent meanings in the search results.
The data set also has the advantage of being large scale (about 2.5 million documents) and representative of the words that naturally occur on the Web and in web search (Wikipedia is one of the primary results surfaced for many informational queries).
In addition, unlike query data for search engines, the Wikipedia data is in public domain.
In the second set of experiments, which we call product disambiguation, we demonstrate the e cacy of our algorithms in diversifying product searches using the the categorical distance function in Section 4.2.
We use a product catalog of about 41, 799, 440 products and 6808 product categories.
We use a logistic regression classi er6 to classify the queries into the product taxonomy.
We will refer to the queries drawn from the title of Wikipedia disambiguation pages as ambiguous queries.
Let us denote the set of these titles by Q and the set of meanings or topics (i.e. the di erent Wikipedia pages) associated with each disambiguation title q by Sq.
Now, we posit that an ideal set of diverse search results for query q would represent a large selection of the topics in Sq (and not necessarily the Wikipedia pages) within its top set of results.
To associate any search result page with a Wikipedia topic, we compute the semantic distance between the web page and the Wikipedia topic page using the distance function described in Section 4.1.
Thus, for a given query q, we compute the topical distribution of a result page by computing its distance to all pages in Sq.
Let us denote the probability (distance normalized by the sum) of a document d representing a particular topic s   Sq by pq(x, s).
We will use this idea of coverage of a give topic to use the Wikipedia data set for evaluating the e ectiveness of the diversi cation algorithm.
Recall from the framework that we view diversi cation as a re-ranking process for the search results, and we use the search results for baseline comparison here.
Thus, given an ambiguous query q   Q, we  rst retrieve its top n results R(q) using a commercial search engine.
Then we run our diversi cation algorithm to choose the top k diversi ed results (the ordered list of diversi ed results is denote by D(q)) from the set of n results and compare the set of top k results, D(q) and Rk(q), in terms of relevance and novelty.
The details of the performance measurement for each of the two measures are described next.
The idea behind the evaluation of novelty for a list is to compute the number of categories represented in the list


 http://en.wikipedia.org/wiki/Disambiguation_page http://en.wikipedia.org/wiki/Jaguar_(disambiguation) http://www.csie.ntu.edu.tw/~cjlin/liblinear/ Noveltyq(L).
We note that this measure is same as the S-recall measure proposed in [21].
The list of topics for the query q is given by the set Sq of Wikipedia disambiguation pages for q.
in L, i.e. P We compute the probability distribution over Sq for all documents in the list L. To compute the representation or coverage of a topic s   Sq in the list L of search results, we aggregate the con dence on the topic over all the results x L pq(x, s).
If this sum is above a threshold     R we conclude that the topic s is covered by the S. The fraction of covered topics gives us a measure of novelty of the set S: !
Noveltyq(L) =
 |Sq|
 pq(x, s) >  
 s Sq
 x L where I ( ) is the indicator function for an expression, evaluating to 1 if the expression is true, and 0 otherwise.
Since we are only interested in the di erence in this value between the two lists D(q) and Rk(q), we de ne fractional novelty: Noveltyq(D(q))   Noveltyq(Rk(q)) max`Noveltyq(D(q)), Noveltyq(Rk(q))  FNq = We note that the value FNq could also be negative, though we would expect it to be positive for a diversi ed set of results.
The relevance of a given document is often measured by the likelihood of the document satisfying the information need of the user expressed in terms of the search query.
Therefore, it could be viewed as a measure of how close a document is to the query in the high-dimensional embedding.
To compute the overall e ectiveness of an ordering S, we compute its relevance based on its relative distance to the ideal ordering S as (cid:48)   1 rs
 (cid:48) s S     1 (cid:48) r s R(S, q) = (9) (cid:48) s is the where rs is the rank of the document s in S and r rank of s in S (cid:48) 7 The aim of this evaluation is to compare the relevance of the diversi ed list D(q) with the original list Rk(q).
To be able to compare these lists, we need to know the relative importance of each topic s   Sq.
For the list Rk(q) (or L), we achieve this by using the search engine to perform a site restricted search using only Wikipedia sites.
From this search, we produce a relevance ordering O on Sq by noting the position of each s   Sq.
In the case of the diversi ed list D(q), we compute the relevance of a topic s   Sq as
 Rel(s, q) =
 pq(d, s), d D(q) pos(d) where pos(d) is the 1-based rank of d in the list D(q).
We compute a relevance ordering O(cid:48) for D(q) and use the func-
re-ranking problem, we assume that both S and S contain the same documents albeit in a di erent order.
One simple characterization of relevance could set the rank of each document to its position in the ordered set of results.
(cid:48) Figure 1: [Best viewed in color] The e ect of varying the value of the trade-o  parameter  , and the threshold for measuring novelty on the output of the search results from MAXSUMDISPERSION.
tion in Equation 9 to compute the relevance distance between the two lists.
The value computed from applying Equation 9 to these lists is the relevance score Relevanceq(L).
As before, we can compute the fractional di erence in the relevance score: FRq = Relevanceq(D(q))   Relevanceq(Rk(q)) max (Relevanceq(D(q)), Relevanceq(Rk(q)))
 The parameters used for the experiments in this work as: n = 30, k = 10.
We choose n = 30 as relevance decreases rapidly beyond these results.
The other parameters for the experiments are   and  , and the e ect of these parameters is shown in Figure 1.
Each point in this plot represents the average fractional di erence in novelty given a value of   and  .
The average is computed over a 100 queries drawn randomly from the set of the Wikipedia disambiguation pages.
First of all, note that the fractional di erence is always positive indicating that the diversi cation algorithm does succeed in increasing the novelty of the search results.
Further, observe that increasing the con dence threshold   has the e ect of increasing the fractional di erence between the search results.
This indicates that the diversi ed search results have a higher con dence on the coverage of each category, and consequently the upward trend is a further vindication of increase in novelty of the diversi ed search results.
Recall that the   value governs the trade-o  between relevance and diversity, and hence one would expect the novelty to increase with  .
This trend is observed in the plot, although the increase is marginal above a certain value of   when the trade-o  is already heavily biased towards novelty.
Figure 2(a) plots the histogram of the fractional di erence in novelty as obtained over a 1000 queries drawn randomly from the set of Wikipedia disambiguation pages.
It is worth noting that from the de nition of fractional novelty that a fractional di erence value of 0.1, with 10 covered categories, implies that the diversi ed search results covered one more category than the vanilla search results.
Hence, on an average, the diversi ed search results cover as many as 4 more categories out of every 10 as compared to the original set of search results.
In fact, we can say about 75% of the queries
 note that on the overall, MAXMINDISPERSION outperforms the other two objectives.
(a) Novelty (b) Relevance Figure 2: [Best viewed in color] The histogram of fractional di erence in novelty (a) and relevance (b) plotted over a 1000 ambiguous queries.
Figure 2(b) plots the histogram of the fractional di er-ence in relevance as obtained over the same sample of 1000 queries.
We note that the diversi ed set of search results does as well as the search engine ranking in the majority of the queries.
Thus, the diversi cation algorithm does not su er much in terms of relevance, while gaining a lot in novelty.
Within the three algorithms, MONOOBJECTIVE does quite well on relevance on some queries, which is expected due to the importance given to relevance in the objective.
In another set of experiments, we study the positional variation of both relevance and novelty for all the three objective functions, i.e. we study the relevance and diversity values by restricting the output ranking to top m ranks, where m = {1, 2,  , k}.
We set   = 1.0 and   = 0.5 for this experiment.
Figure 3(a) plots the diversity at each position for the three objective functions and the search engine results.
We note that the number of topics covered increases with position, and the results D(q) produced by all three algorithms cover a larger number of categories even at the high ranked positions (low m) compared to the search engine.
Although the di erence in novelty between the search engine results and the diverse results is noticeable, the three diversi cation objectives perform quite comparably to each other.
A similar plot for relevance is shown in Figure 3(b), which plots the positional variation in the value of relevance.
We observe that all the orderings are equally relevant in the higher positions (lower m) while di erences appear in lower positions.
We note on the overall, the MONOOBJECTIVE formulation does the best in terms of relevance as it has the smallest distance to the ground truth.
The MAXSUM-DISPERSION algorithm comparatively produces the least relevant result sets among the three diversi cation objectives as it is more likely to add a more diverse result with respect to S than the other algorithms.
In this set of experiments, we evaluate the performance of the three objective functions using di erent notions of distance and relevance.
Speci cally, we use the distance function described in Section 4.2 and the relevance score based on the popularity of a product.
We note that the categorical distance can be tuned using the parameter e to
 results had no overlap with the Wikipedia topics.
(a) Novelty (b) Relevance Figure 3: [Best viewed in color] The positional variation in the novelty (a) and relevance (b) of the result set.
e ectively distinguish between various features of a product.
For example, we would two di erent CD players produced by the same company to be closer to each other than to a CD player from a di erent company in a product taxonomy.
Our data set (obtained from a commercial product search engine) consists of a set of 100 product queries and the top 50 results ranked according to popularity.
There is one drawback when we rank products based on their popularity.
In the case where the popularity is skewed toward one or a few brands, the results can be dominated by products belonging to that brand with (sometimes) slight variations in the product descriptions.
To observe the e ec-tiveness of our formulation and the distance function, we diversi ed the results for 100 queries using the MAXSUM-DISPERSION algorithm and compared the ordering with the results produced by a commercial product search engine.
The parameters in this experiment were as follows: n = 30, k = 10, and   = 1.0.
Table 1 illustrates the di erence between the orderings for the query cd player.
Even though the search engine results for cd player o ers some dominant brands, it does not include the other popular brands that the diversi ed results capture.
Note that we do not alter the relative positions of the popular brands in the di-versi ed results.
Similar to novelty evaluation for semantic disambiguation, we compute the number of categories represented in the list L of top-k results for a given query q which we denote by Noveltyq(L).
To compute the representation of a category in the result set, we require that the category is not the descendant of any other category in the result set.
The fraction of covered topics gives us a measure of novelty of the set S:
 u,v L Noveltyq(L) =

 I (lca(u, v) /  {u, v})
 Sony SCD CE595-SACD changer Sony CDP CE375-CD changer Sony CDP CX355-CD changer Teac SR-L50- CD player/radio Bose Wave Music System Multi-CD Changer Sony RCD-W500C-CD changer/CD recorder Sony CD Walkman D-EJ011-CD player Sony S2 Sports ATRAC3/MP3 CD Walkman D-NS505 Diversi ed Results Sony SCD CE595-SACD changer Sony CDP CE375-CD changer Teac SR-L50-CD player/radio Bose Wave Music System Multi-CD Changer Sony S2 Sports ATRAC3/MP3 CD Walkman D-NS505 COBY CX CD109-CD player JVC XL PG3-CD player Pioneer PD M426-CD changer Sony Atrac3/MP3 CD Walkman D-NF430 Sony SCD XA9000ES-SACD player COBY CX CD109-CD player Yamaha CDR HD1500-CD recorder/HDD recorder Table 1: The di erence in the top 10 results for the query cd player from a commercial product search engine and the diversi ed results produced by running MAXSUMDISPERSION with n = 30 and k = 10 represent the nodes in the taxonomy as well.
Figure 4(b) shows the positional variation in relevance for the product search engine and the diverse results produced by MAXMIN-DISPERSION.
Surprisingly, the relevance of MONOOBJECTIVE decreases relative to the other objectives.
This work presents an approach to characterizing diversi- cation systems using a set of natural axioms and an empirical analysis that qualitatively compares the choice of axioms, relevance and distance functions using the well-known measures of novelty and relevance.
The choice of axioms presents a clean way of characterizing objectives independent of the algorithms used for the objective, and the speci c forms of the distance and relevance functions.
Speci cally, we illustrate the use of the axiomatic framework by studying three objectives satisfying di erent subsets of axioms.
The empirical analysis on the other hand, while being dependent on these parameters, has the advantage of being able to quantify the trade-o s between novelty and relevance in the diversi cation objective.
In this regard, we explore two applications of web search and product search, each with di erent notions of relevance and distance.
In each application, we compare the performance of the three objectives by measuring the trade-o  in novelty and relevance.
There are several open questions that present themselves in light of these results.
In terms of the axiomatic framework, it would be interesting to determine if the impossibility proof still holds if the distance function is a metric.
Relaxations of the axioms (for instance, weakening the stability axiom) are also an avenue for future research.
Another direction of future research could be to explore the facility dispersion link, and identify optimal objective functions for settings of interest (such as web search, product search etc).
Acknowledgments We would like to thank Kunal Talwar for helpful discussions, and Panayiotis Tsaparas for providing data and helping us with the classi cation of product queries.
