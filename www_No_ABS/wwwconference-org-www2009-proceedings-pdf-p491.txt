Web advertising has become a major industry: according to a recent study by the Interactive Advertising Bureau and PricewaterhouseCoopers International, online advertising spending in 2007 reached over 21 billion US dollars, an increase of 26% from the previous year [12].
This is the  rst time that online advertising spending was larger than each of the traditional advertising media: radio, cable and broadcast TV.
A signi cant part of this market consists of textual ads, the ubiquitous short text messages usually marked as  sponsored links  or similar.
The main advertising channels used to distribute textual ads are:
 consists in placing ads on the result pages from a web search engine, with ads driven by the originating query.
All major current web search engines (Google, Yahoo!, Microsoft, etc.)
support such ads and act simultaneously as a search engine and an ad agency.
refers to the placement of commercial ads within the content of a generic web page.
In contextual advertising, usually there is a commercial intermediary, called an ad-network, in charge of optimizing the ad selection with the twin goal of increasing revenue (shared between publisher and ad-network) and improving user experience.
Again, all major current web search engines provide such ad-networking services but there are also many smaller players.
The prevalent pricing model for textual ads is that the advertisers pay a certain amount for every click on the advertisement (pay-per-click or PPC).
There are also other models: pay-per-impression where the advertisers pay for the number of exposures of an ad, and pay-per-action where the advertisers pay only if the ad leads to a sale or similar transaction.
For simplicity, in this paper, we consider only an advertiser (and hence the revenue of the search engine or ad-network) is related to the total number of exposures of the ad (impressions) and the click-through-rate (CTR) which can be viewed as the probability that an end-user would click on the ad when shown.
Both impressions and CTR are di cult to estimate due to various factors such as tra c  uctuation and sparsity, but they are orthogonal.
An ad with a high CTR might not be shown enough to generate revenue, and on the other hand, ads with low CTRs could get tons of impressions and waste expensive tra c.
However any of them individually can still be very informative and extremely useful in planning and budgeting advertising campaigns.
We focus on impression forecasting in this paper.
In the SS market, textual ads are characterized by bid phrases representing those queries where the advertisers would like to have their ads displayed.
The amount paid by the advertiser for each ad click is determined by an auction process [7].
Very simpli ed, in this process each advertiser enters a bid for the phrase of interest; the search engines choose among the ads competing on that phrase those ads that have high bids and high CTRs, thus attempting to maximize the search engines  total revenue.
Of course CTR is not known a priori; however it can be determined, e.g., by historical observation, or approximately estimated .
The situation is more complicated in contextual advertising.
Here the bid phrase has no direct bearing on the ad placement: the ad network has to  nd ads that will have high CTRs for the given context.
Given a page, rather than placing generic ads, it seems preferable to have ads related to the content to match the user interest and thus to increase the probability of clicks.
This intuition is supported by the analogy to conventional publishing where there are very successful magazines (e.g., Vogue) where a majority of the content is topical advertising (fashion in the case of Vogue) and by user studies that have con rmed that higher relevance increases the number of clicks [6, 18].
The majority of the approaches proposed so far for estimating the relevance of a given ad to a given content, and thus indirectly CTR, are based on the co-occurrence of words or phrases within ads and pages [13, 16, 20] or on a combination of semantic and syntactic factors [4].
At the core, most of these approaches can be viewed as computing a similarity score Sima,p between a vector of features characterizing the ad a and a vector of features characterizing the page p. For the ad a such features could include the bid phrase, the title words (usually displayed in a bold font in the presentation), synonyms of these words, the displayed abstract, the target URL, the target web site, the semantic category, etc.
Similarly, for the page p such features might include words on page, words in title, URL, category, synonyms, etc.
In this paper, for simplicity, we assume that given a page p and a set of available ads {a1, a2, }, the ad network places the ads that maximize the product Scorea,p def= Sima,p   Bida, (1) where Bida is the bid amount of ad a in the PPC model.
As we discussed, note that Sima,p can be regarded roughly as an unnormalized approximation of CTR [6, 18].
In other words, ad placement discussed here indeed takes CTR indirectly into consideration.
Given the model above, advertisers eager to reach as many customers as possible, have two possibilities: they can either craft their ads to better match more opportunities or they can increase their bids.
In either case, the advertisers are probably interested to know what is the e ect of these changes.
A simple approach is to try a test ad and/or a test bid in real tra c and analyze the e ect after a number of days.
This is of course very expensive, ine cient, and has a very long turnaround and a huge variance.
The need for forecasting is actually well recognized: existing SS systems provide such facilities,1 but none of the available CA systems provides forecasting, to the best of our knowledge.
Such a forecasting system has obvious applications for ad selection, campaign budgeting, and advertising strategy.
The main goal of this paper is to propose a method to forecast the future performance of new and modi ed ads accurately, in a real-time manner, based on replaying past impression data.
The past data is composed of actual page views with the associated ads (there are multiple ads shown on the page).
To estimate the impression count, given an ad a and a bid Bida, we consider all content match opportunities over, say, the last four weeks, and check how often the ad a would have been shown if it were in the system with the given bid.
That is, how often Scorea,p would have exceeded the score of the lowest scoring ad actually shown on the page p. The impression rate is then used in an obvious manner to predict the impression volume over, say, the next week.
At  rst blush this task seems daunting: for a real system we would need to check billions of past CA opportunities.
To address this problem the e ciency of our algorithm depends only on the number of distinct pages, which is a relatively small number when compared to the total number of im-presssions.
Secondly, our search procedure greatly reduces the number of pages that need to be considered for full evaluation.
We veri ed our approach using a set of 700M actual CA opportunities over around 375K distinct pages obtained from a certain random set of hosts participating in Yahoo!
ad network.
The ad database used for our experiments consisted of about 10M actual ads and their bids.
The ranking function is given by Formula (1), and the similarity score by a formula related to the approach presented in [4].
With this data, and using a standard PC with 2GB memory, the time required to forecast the volume of impressions for a  xed ad and a single bid is around 10 milliseconds; plotting a curve forecasting the ad volume for 100 di erent bid levels takes less than 400 milliseconds.
While it can be argued that a real system needs to be hundreds of times larger, our system is trivially parallelizable, and its performance depends only on the number of distinct pages in the historical data.
Furthermore, as long as the page index  ts in memory, the forecasting time increases very slowly our index is less than 10MB and thus we estimate that a single 8GB box can handle 25 million distinct pages in 15 milliseconds.
Last but not least, infrequent pages can be ignored.
In this paper we focus on ad selection based on similarity score.
Real-world matching systems involve many ad selection mechanisms such as business rules, behavioral targeting (di erent users might get di erent ads), advertiser budgets, pricing based on a generalized second price auction, tra c quality discounts, positional e ects (same ad exhibits di er-ent CTRs in di erent positions), anti-fraud measures, and so on.
Some of these could be easily included in our model 1e.g., http://searchmarketing.yahoo.com/srch/features.php training data (e.g., anti-fraud measures).
The approach of replaying ads can in principle accomodate any ad selection technique as long as we can e ciently invert the selection process from selecting ads for a given page, to counting the pages where the ad would have been shown if it were present in the system.
Given a new ad a and a bid Bida, we consider all impressions over some training period, and check how often the ad a would have been shown if it were present in the system with the bid.
In other words we count how often Scorea,p exceeds the score of the lowest scoring ad that the system would assign to page p absent ad a.
This minimum score is denoted as minScorep and is discussed further below.
The abstract problem that we need to solve is as follows: given a feature vector u, and a stream of events {Xi} each having an associated feature vector vi and a threshold ti, In our case, u represents the features associated with the test ad a, vi represents the features of the page pi, the threshold ti is minScorepi , and (u, vi) is Scorea,pi .
we want to computeP (u,vi)>ti
 In contextual advertising, the number of ads shown on a page typically varies between 1 and 20.
For a page pi, the ad ranking system chooses the top ki ranking ads according to Formula (1).
The score of the lowest ranking ad among these ki ads shown on pi de nes minScorepi .
If the test ad a would have been available when pi was displayed, then a would have been shown if and only if Scorea,pi > minScorepi .2 Naively, we can go over every page in the training set and we can calculate how many times the test ad would have been shown.
Since the ad database might include hundreds of millions of ads, and the training set possibly include billions of impressions, linear scanning is completely impractical.
To reduce the size of the problem, we assume that Scorea,p is constant over all occurrences of the page p. However minScorep might vary from occurrence to occurrence because ads are continuously added and deleted from the system and bids change as well.
Assume that the page was shown n times.
There are several possible approaches to circumventing the multiple minima problem:
 scores, that is, we keep a list of minima m1   m2       mr and of weights 0 < w1   w2       wr = Impp, where Impp is the number of impressions of page p .
The interpretation is that there were a total of w1 occurrences of p with minScorep = m1, there were a total of w2 occurrences of p with minScorep = m1 or m2, etc.
Thus if Scorea,p falls between mj and mj+1, the ad a would have been shown wj times.
ad scores for the page impressions.
considering only the currently available ads and their bids.
This has the advantage that it captures the most recent picture of the marketplace but it does not re ect the historical bid variation.
assume the test ad would not have been shown.
Figure 1: The system architecture for forecasting ad impressions.
The part inside the dotted line runs o ine and prepares the data for the online forecasting.
The output can be the number of forecasted impressions or an impression vs. bid curve.
Preliminary experiments show that there is no signi cant di erence between di erent approaches.
In our experiments, we used the last approach, but the algorithms can be easily modi ed to use approach 1 or 2.
By collapsing all occurrences of one page to one record we achieve a huge improvement (by a factor of about 2000 in our experiments); nevertheless, even a linear scan of all distinct pages is prohibitively time consuming.
For further improvement, we reduce this scanning process to a two-level search process over the collection of distinct web pages.
At the  rst level, an inexpensive approximate evaluation is conducted to identify the set of pages on which the ad could have been shown.
The pages in this set are called candidates.
At the second level, a full evaluation is performed for each candidate page by comparing the score of the ad being considered against minScorep of the candidate p. If the score is larger, then the forecast counter is increased accordingly.
Our system architecture is presented in Figure 1.
The upper part of the picture depicts o ine processing that consists Feature ExtractionInput AdFeature ExtractionIndexing EngineInverted Index of AdsInverted Index of PagesHistorical Impression DataImpp1, minScorep1p1Impp2, minScorep2p2ImppN, minScorepNPage Statistics CollectorpNOffline stepsbid valuenumber of impressionsDesign adBest Prices on DVD ...Specify bid amount OKCancelAd Impression ForecastingQueriesAdsWWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion493of analyzing the pages, building a page inverted index, and creating a page statistics  le.
The page analysis module extracts, for each page p, the features needed to compute Sima,p.
Since we are using the approach 3 above, these features are used to obtain the top k ads from the ads currently active in the system and thus compute minScorep.
The inverted index is a mapping from features to the pages that contain these features (a description of inverted indexes is given in Section 3.1).
The page statistics  le contains, for each page p, the number of its impressions in the training set and minScorep.
In the online component of the system we use the inverted page index and the page statistics  le to forecast the number of impressions of a given ad.
When an advertiser submits a new ad, we extract features from this ad and use these features to query the page index via the two-level search process described above.
Advertisers can either provide a bid value for the ad being tested and get back the number of expected impressions for this speci c ad/bid combination, or they can ask for an impression vs. bid curve, as illustrated in Figure 1.
An advertiser can also use this interface to change the wording of its ad and then check the expected number of impressions with a di erent ad description.
To reduce the cost of the search over the past impressions we use a document-at-a-time (DAAT) strategy [17] and a two-level evaluation approach.
Here, we  rst go over all the web pages and identify candidates by inexpensive approximate evaluation.
Full evaluation is performed only over the candidates by checking if the given test ad would have been shown if it were present in the ad database.
The check calculates the score that the test ad would have had if it were present in the ad database at the time of the page impression.
Then the score is compared to the minimal score of the ads actually shown on the candidate page minScorep.
We have adapted the WAND [3] procedure to avoid examining every page in the data set.
For reference, Table 1 summarizes all the notation used in this paper.
Here we brie y review some basic concepts in information retrieval (IR) and terminology used in this paper.
Inverted Index.
Most information retrieval (IR) systems use inverted indexes as the main data structure for full-text indexing [19].
There is a considerable body of literature on e cient ways of building inverted indexes (e.g., [1, 2, 9, 11, 15, 19]) and using them to evaluate full-text queries (e.g., [3,
 In this paper, we use an inverted index structure where each occurrence of a feature f within a web page p is represented by a posting of a form hPID, wf,pi.
PID is the page identi er which in this paper we assume that ranges from 1 to the number of unique pages N .
wf,p is called weight and is used to store arbitrary information about the occurrence of f within p. The postings associated with the same feature are grouped into a posting list.
Each posting list is sorted in increasing order of PID.
Often, skip lists or B-trees [10] are used to index the posting lists [9, 15] to allow for quick  nding of postings given a PID.
Table 1: Notation used in this paper

 pi fj wf,p Impp Sima,p Bida Scorea,p maxWeightf minScorep
 the total number of distinct web pages the ith web page the jth feature, such as a unigram term the weight of feature f in page or ad p the number of impressions of web page p the similarity between ad a and page p the bid amount of ad a the ranking score for ad a on page p the largest weight of feature f in any page the lowest ranking score of previously shown ads on page p Joining Posting Lists Typically, to evaluate the query, we need to perform a join over the presorted posting lists.
One of the common approaches to performing this join is to use a document-at-the-time (DAAT) evaluation.
Most of the DAAT algorithms in the literature are merge-joins with improved e ciency [10].
To evaluate a free-text query using a DAAT algorithm, a cursor Cf is created for each feature f in the query, and is used to access f  s posting list.
During the join, the cursors are moved in a coordinated fashion forward over the posting lists.
Almost all posting list join algorithms are based on the Cf .beyond(PID p) primitive that advances the Cf cursor to the  rst posting such that PID is greater than or equal to p, returning the PID of the new position.
If p is beyond the end of the posting list, beyond() returns a special posting element with an identi er LastID which is the smallest integer (N + 1) larger than all existing PIDs in the index.
Scoring.
The join algorithm evaluates the query over a subset of candidate pages by calculating the scores between the query and the pages.
The match between the query and the page is mostly quanti ed by a query dependent or dynamic score.
Usually, there is also a query-independent component which is based on the static rank of the web page.
In most IR systems, the query-dependent component of the score follows an additive scoring model for each feature, whereas the static component can be based on the connectivity of web pages, as in PageRank [2], or on other factors such as source, length, creation date, etc.
In this work, we do not use static scores for pages.
The similarity score between page p and ad a, Sima,p is decided by summing contributions over all common features of a and p as follows:
 f a p Sima,p def= wf,a   wf,p, (2) where the weights wf,p and wf,a measure the importance of the feature f on the ad and the page side correspondingly.
The features used in our implementation include tf idf weighting for unigrams, compounds based on a dictionary (e.g.,  New York Times ) and class labels corresponding to ad and page classi cation in a commercial taxonomy of about 6000 nodes, as described in [4].
Many di erent approaches have been proposed in the literature to speed up the search process [3, 8, 5], and we adopt a two-level procedure similar to [3] here.
could be shown on the given page by comparing an upper bound of the ad score with minScorep: wf,a   maxWeightf > minScorep.
(3) Bida   X f a p In this formula, maxWeightf represents the maximum weight of the feature f in any page.
The value of maxWeightf is pre-calculated during index building for each feature f and stored in the meta-data section of the posting list.
Using the maximal weights, the sum expression in Formula 3 is an upper bound of Sima,p.
Thus, following from the score de nition in Formula 1, the left-hand side of Formula 3 is an upper bound of Scorea,p.
Using a single value for the page-side weights allows us to avoid accessing the posting lists to obtain the actual weight, as described in the following sections.
The tightness of the bound depends on the variance of the weights and impacts the  ltering rate at the  rst level of the search process.
The  rst phase  ltering does not alter the  nal results we would obtain exactly the same results even if this phase is not applied.
The pages that satisfy the  rst level  ltering are further evaluated at the second level.
Here a full evaluation is performed where instead of using maxWeightf for the page feature weights, the actual page weights are retrieved from the index: we check if Scorea,p > minScorep, and we increase the number of forecasted impressions for ad a if the inequality holds.
In this work we implement the two-level search process using a variation of the WAND operator [3].
WAND, standing for Weak AND, or Weighted AND, has been proposed to e ciently implement the two-level search process over large document collections.
The algorithm takes as arguments a list of Boolean indicator variables X1, X2,  , Xk, a list of associated positive weights, w1, w2,  , wk, and a threshold h. By de nition, WAND(X1, w1,  , Xk, wk, h) is true i 
 1 i k Xiwi   h.
h does not change at all no matter how the cursors move.
A new WAND iterator needs to be devised to accommodate this particularity of our application.
To take advantage of the di erence among lowest ranking scores of di erent pages, we index the pages in increasing order of minScorep (i.e., pages with smaller PIDs have lower minScorep) so that it becomes more di cult to have the test ad shown when the posting list cursors move to larger PIDs, i.e., more pages that do not qualify Formula (3) are skipped, as demonstrated in our experimental results (Table 4).
Figure 2 describes our implementation of the new WAND iterator, showing the basic procedure to calculate the expected number of impressions for a test ad.
The two methods in Figure 2, initializeCursors() and nextCandidate(), are described in detail in Figure 3 and Figure 4, respectively.
nImpressions   0 initializeCursors() (see Figure 3)








 nImpressions   nImpressions + Impp Calculate Sima,p by Formula (2) if (Scorea,p > minScorep) end while return nImpressions Figure 2: Main function that forecasts the number of impressions for test ad a.
The ad features are used as a query to the inverted index of pages.
The new WAND iterator is initialized by calling the method initializeCursors() depicted in the pseudo-code shown in Figure 3.
The method receives as input the array of features extracted for the query ad.
It sets the current web page to be considered (currentPage) to zero and for each query feature, f , it initializes its current posting cursor to be the  rst posting element in its posting list.
currentPage   0 for each f   features Cf .beyond(0) Given this setup, our preliminary evaluation in Formula (3) consists of evaluating for each web page p WAND(Xf1 , wf1,a   maxWeightf1 , Xf2 , wf2,a   maxWeightf2 ,   , Xf|a| , wf|a|,a   maxWeightf|a| , minScorep Bida ), where Xfi is an indicator variable for the presence of query feature fi in web page p and |a| is the number of features for ad a.
If WAND evaluates to be true, then the web page p undergoes a full evaluation.
The original WAND iterator [3] is used to obtain a ranked list of documents relevant to a query.
To do ordinary web search using WAND, the threshold is set dynamically to the minimum score of the top results found so far as the cursors of the posting lists advance.
In addition, the threshold is  xed for pages between two consecutive full evaluations.
However, in ad impression forecasting, the threshold h is page dependent since the lowest ranking score of shown ads, minScorep, is di erent for each page and, for a given page, Figure 3: The initializeCursors() method of the WAND iterator Similar to the original WAND iterator, our implementation also maintains two invariants during its execution:
 been considered as candidates.
PID < Cf .PID, has already been considered as a candidate.
Note that initializeCursors() establishes these invariants.
After calling initializeCursors(), the algorithm repeatedly calls nextCandidate() to get the next candidate for full evaluation.
The nextCandidate() method returns the next web page whose approximate score satis es Formula (3).
Web pages whose approximate scores do not satisfy Formula (3) are skipped.
Figure 4 contains the pseudo-code for nextCan-didate(), which repeatedly advances the individual feature cursors until it  nds a candidate web page to return.
end repeat else sort(features) pivotFeature    ndPivotFeature(features) if (pivotFeature = null) return (LastID) pivotPID   CpivotF eature.PID if (pivotPID = LastID) return (LastID) if (pivotPID = currentPage) //pivotPID tested?
f   pickFeature(features[1,       , pivotFeature]) Cf .beyond(pivotPID + 1) if (C0.PID= pivotPID) //Formula (3) satis ed?
currentPage   pivotPID return (currentPage) f   pickFeature(features[1,       , pivotFeature]) Cf .beyond(pivotPID) else Figure 5: A (counter) example of randomly indexed web pages ( minScorep1 minScorep2 > wf1,a maxWeightf1 > ).
The nextCandidate() method in Figure Bida 4 would miss p2 as a valid candidate web page.
Bida Figure 4: The nextCandidate() method of the WAND iterator The nextCandidate() method invokes three helper methods, sort(),  ndPivotFeature() and pickFeature().
The  rst helper, sort(), sorts the features in non-decreasing order of their current PIDs.
And,  ndPivotFeature() returns pivotFeature the  rst feature in the sorted order for which the accumulated (weighted by wf,a) upper bounds of all features preceding it, including it, exceed the corresponding threshold, minScorep/Bida.
The last helper, pickFeature(), receives as input a set of features and selects the feature whose cursor is to be advanced.
The nextCandidate() method  rst sorts the query features in non-decreasing order of the PID s of their current postings using sort().
Next, calling  ndPivotFeature(), it computes the pivotFeature.
If there is no such feature (meaning the sum of all features  (weighted by wf,a) upper bounds is less than the threshold), the iterator stops and returns the constant LastID.
Then the pivotPID variable is set to the PID corresponding to the current posting of pivotFeature.
If pivotPID is equal to the PID of the last web page considered (current-Page), WAND picks a feature preceding the pivot term and advances its iterator past currentPage by calling pickFea-ture() (Lines 8-10), the reason being that all web pages preceding currentPage have already been considered (by Invariant 1) and therefore the system should next consider a web page with a larger PID.
Note that this move preserves Invariant 2.
We need to check whether indeed the sum of approximated contributions to pivotPID is greater than its threshold.
There are two cases: if the current posting PID of all features preceding pivotFeature is equal to pivotPID, then pivotPID contains a set of query features with an accumulated (weighted by wf,a) upper bound larger than the threshold and hence nextCandidate() sets currentPage to pivotPID, and returns this web page as a candidate for full evaluation (Lines 12-14).
Otherwise, pivotPID might or might not contain all the preceding features, that is, it might or might not have enough contributions, hence WAND picks one of these features and advances its cursor to a location   pivotPID (Lines 15-17).
The nextCandidate() method also maintains Invariant 1.
Because we index web pages in increasing order of minScorep, it is not possible for another web page whose PID is smaller than pivotPID to be a valid candidate since pivotFeature by de nition is the  rst feature in the PID order for which the accumulated (weighted by wf,a) upper bound exceeds the corresponding threshold.
Hence, all web pages with a smaller PID than pivotPID can only contain features which precede pivotFeature, and the upper bound (weighted by wf,a) on their scores are strictly less than the corresponding threshold (otherwise we would have a di erent pivotFea-ture).
It follows that nextCandidate() maintains the invariant since currentPage is only advanced to pivotPID in the cases of success, i.e.,  nding a new valid candidate who is the  rst in the order.
Note that if we indexed the web pages not in increasing order of minScorep, the threshold for a page with a larger PID could be actually smaller than the one for a page with a smaller PID and Invariant 1 would not be held any more.
An example of randomly indexed web pages is illustrated in Figure 5, where minScorep1 minScorep2 pivotFeature as a feature other than f1 since minScorep1 wf1,a  maxWeightf1 , and then miss p2 as a valid candidate.
> wf1,a   maxWeightf1 > .
The nextCandidate() method would discover Bida Bida Bida > In this section, we discuss the experiments we conducted to validate our approach.
We collected two weeks of actual impression events from a certain random set of hosts participating in Yahoo! s ad network, for a total of about 1.3 billion impressions.
Our evaluation uses a set of 10 million textual ads, again chosen at random from Yahoo! s database of ads.
For each distinct page p in the set of impressions, we counted its total number of occurrences and determined minScorep by selecting the best matching ads as discussed in Section 2.
After feature extraction, all the pages were indexed in an inverted  le of features each feature being associated with a posting list of pages where it appears.
We split the collected data set into a training set of 614 million impressions involving 318,317 distinct web pages, obtained from August 12 18, 2007, and a testing set of 699 million impressions involving 375,507 distinct web pages, obtained from August 19 25, 2007.
Thus, in our experiments we forecast one week worth of impressions based on the previous week.
Naturally, many pages appear both in the training set and in the test set.
However, due to the Posting list of f1Posting list of f2p1p2p3Cf1Cf2PagesWWW 2009 MADRID!Track: Search / Session: Ads and Query Expansion496Table 2: Average absolute relative error of fore-casted impressions of a week at di erent impression levels, with the corresponding 90% con dence interval.
Table 3: Average absolute relative error of fore-casted impressions of two days at di erent impression levels, with the corresponding 90% con dence interval.
#Impressions









 #Ads









 Error
 26364.2% [-100%,1e5%]








 #Impressions









 #Ads









 Error










 dynamic nature of the Web and to tra c variations, the sets are not identical and they di er both with respect to composition and to impression counts.
We evaluated our system by randomly picking approximately 6000 sample test ads.
To evaluate the system on both new ads and existing ads we picked half of the sample from the 10 million set used in the training stage and the other half from another, disjoint set of ads.
Note that estimating volumes for ads not previously seen is not more di cult than estimating existing ads.
Preliminary results on new and existing ads separately do not show any signi cant di erence, and we report the results on the mixed ads.
To demonstrate the e ectiveness of our approach, we compare the forecasted impressions based on the training set with the actual impressions from the test set.
We split the test ads according to the forecasted impression level and report the number of sample ads at that level, the average absolute relative error and the corresponding 90% con dence interval in Table 2.
The relative error is de ned as #Actual   #Forecasted Relative Error = #Forecasted , and the 90% interval is a range such that 90% of the test ads have a relative error in that range.
(We remark in passing, that, not unexpectedly, the distribution of impressions at various levels seems to follow roughly a power law.)
The average absolute relative error becomes smaller when the number of impressions becomes larger, and the con dence interval becomes tighter.
At the  rst glance, the errors in Table 2 seem big.
However,  rst of all, when the tra c in the training set is identical to the test set, our method gives correct forecasting without any error.
The errors come from tra c  uctuation.
We conjecture that with larger periods, better forecasting could be obtained, due to less tra c  uctuation.
Second, producing this forecast, even within large margins of error (which is acceptable in campaign budgeting and advertising strategy), is extremely challenging, and there is no previously published work reporting results close to ours, to the best of our knowledge.
Third, one might argue that our method is only accurate for a small fraction of ads, the ones with highest volume which could be accurately estimated o line and cached.
But this is only true when the bids of those ads are  xed.
When the bids change signi cantly, their volume would change dramatically as well.
It is very common and vitally important for advertisers to optimize their investment by exploring the most cost-e ective bids via methods like ours.
There is a general belief that it is easier to forecast long-term tra c rather than short-term tra c.
For comparison, we show the similar results for a two day forecast in Table
 forecasting.
As we discussed earlier, our approach is also able to present advertisers with an impression volume vs. bid curve to help them make the most cost-e ective decision on bids.
To this end, note that we do not need to evaluate the same test ad repeatedly with di erent bid levels   instead we can evaluate the test ad once as follows: for each page, we get the minimum bid that would ensure that the test ad will be shown.
We then compare these minimum bids against di erent bid levels to collect the forecasted impressions in a more e cient way.
Several randomly selected examples of such curves (with comparison to the actual impression curves) are shown in Figure 6.
Note that, as expected, the number of impressions increases monotonically as advertisers bid higher.
In Figure 6, the top row curves demonstrate that our approach can forecast impressions accurately for di erent shapes of curves.
The curves at the bottom do not match the actual impression curves very well due to page tra c  uctu-ation, but share roughly the same trend or shape with the actual curves.
Therefore, these curves are still very valuable in assisting advertisers to make cost-e ective decisions, e.g., one advertiser might prefer to invest in an ad with a smooth bid curve, while another advertiser might prefer to bid above a  cli  that would keep the competition away.
When all the advertisers make reasonable cost-e ective decisions, the tra c in ad servers could be better utilized and lead to more revenue at the end.
In order to  ne-tune their bids and check the impact of wording changes, advertisers need real-time feedback.
In our experiments, our approach is demonstrated to respond in sub-seconds.
On an Intel Xeon 3GHz PC with 2GB RAM, with the inverted page index and the page statistics  le kept in memory, the average evaluation time for a (test ad, bid) pair is 10.1 milliseconds and we require 377.1 milliseconds for curve plotting with 100 di erent bid levels.
impression curves (dashed).
These curves are randomly selected from our test ads and arranged into two rows.
The top row curves demonstrate that our approach can forecast impressions accurately.
The curves at the bottom do not match the actual impressions very well due to page tra c  uctuation, but share roughly the same trend or shape with the actual impression curves.
Thus, these curves are still very valuable to assist advertisers to make cost-e ective decisions on bids.
In Section 3, we claimed that our search skips more and more web pages as the posting list cursors advance, due to our storing of pages in increasing order of minScorep.
We numerically evaluate the skipping behavior here.
The skipping distance is de ned as the di erence of PIDs of two web pages that are consecutively fully evaluated, or the di erence between LastID and the PID of the last fully evaluated web page.
For each test ad, we calculate average relative skipping distance with respect to the average skipping distance in the  rst decile of the web page index we have built.
We report the mean of these statistics over all test ads for di erent deciles in Table 4, in which the skips are signi cantly larger as the cursors move towards larger PIDs.
In other words, we process the last 10% of the index at rate 3000 faster than the  rst 10%, which means that, as long as the page index  ts in memory, the forecasting time increases very slowly our index is less than 10MB and thus we estimate that a single

 The usage of the upper bounds of page-to-ad scores guarantees that the proposed algorithm will  nd the precise count of pages p such that minScorep < Scorea,p.
In our applications, due to tra c variations, precise counts are not practically usable.
In this section we explore if we can trade count precision for better evaluation performance.
The performance of the two-level process depends on the tightness of the upper-bounds in the page-to-ad score es-Table 4: Mean average normalized skipping distance with respect to the average skipping distance in the  rst decile of the web page inverted index.
Skips Decile


















 timation.
This in turn depends on how well maxWeightf bounds the weight of an index posting during the scoring.
Since maxWeightf is the maximum weight in the posting list, in a case of a skewed weight distribution, few postings with relatively higher weights can result in loose bounds and many unnecessary candidates passing the  lter of the  rst phase.
To shrink the subset of web pages that are passed to full evaluation, we can enforce a stricter  rst level  ltering at the price of allowing a few true candidates to be  ltered out.
This would be acceptable in our application as long as crease (with respect to   = 1) in number of full evaluations vs.  , with unit standard deviation bars.
The number of full evaluations decreases quickly as the value of   increases.
Figure 8: (Accuracy) The average percentage decrease (with respect to   = 1) in number of fore-casted impressions vs.
 , with unit standard deviation bars.
The forecasted impressions decrease quickly as the value of   increases.
the overall forecasting quality does not decrease signi cantly.
One way to achieve this e ect is to introduce an adjusting factor     1 to o set the overestimation of maxWeightf , and update Formula (3) as wf,a   maxWeightf >     minScorep, (4) Bida   X f a p The term   is related to how much increase in the forecasting error we can tolerate.
When   = 1, Formula (4) becomes Formula (3).
If we increase the value of  , we get a smaller candidate pool in the second phase.
Simultaneously we may miss more web pages on which the test ad could actually have been shown.
In other words, stricter  ltering (larger  ) leads to less accurate estimation but faster response.
Therefore, the selection of the value of   is indeed a tradeo  between accuracy and e ciency, as demonstrated in Figure 7 and Figure 8.
As   increases, the number of full evaluations decreases, so does the forecasted impressions.
A relatively smooth curve could be  t for both Figure 7 and Figure 8.
Note that even with this lossy estimation, our system is still capable to suggest bids since it captures the general trends over bid value reasonably well.
To further demonstrate how our system can be used as a tool for advertisers to design and manage new ads, we manually created several ads with subtle di erences3, shown in Table 5 with their corresponding forecasted impressions.
The other attributes of all the ads in Table 5 are identical, for example, they use the same description and have the same landing page (same URLs) and same bid amount.
As we can see, although most of the attributes are identical, the subtle di erences make a big impact in number of impressions.
It is interesting to see that the usage of terms like  cheap  and  free  reduces the number of forecasted impressions: the underlying system correctly predicts that
 privacy and copyright issues, we would not have been able to show the ad contents and their di erences.
such ads have lower CTRs and hence their score is adjusted downward, that is Sima,p becomes lower for all pages.
Current ad networks do have certain forecasting functionalities, however, unfortunately, they are not publicly accessible.
One simple approach to estimating ad impressions is to run real systems with the test ads for a while to get the estimate of their performance.
However, the running cost in ad servers is prohibitive, and running free test ads for a long time to alleviate sparseness is  nancially infeasible.
Furthermore, in this naive way, advertisers have to wait a long while to get performance report of their test ads.
Another alternative to the replaying approach presented in the paper is to estimate the impressions of a new ad based on the impressions of the ads currently in the system.
A machine learning framework can be built that extracts features from the ads and predicts the impressions based on ads that are similar to the test ad.
While we have found no prior work on impression forecasting using this method, we believe the search based method presented in this paper has two main advantages.
First, in the method proposed in this paper we use an ad-to-page matching that is the same as with the ad selection.
The complexity of the ad selection mechanism can be di cult to capture by a machine learning model over the ad features.
Second, an ad-to-ad comparison introduces an indirection in the data use, as the ad selection is performed between ads and pages.
This additional step might introduce noise in the prediction, e.g., considering the extreme case: when the tra c in the future is identical to the past, search-based methods will give exact number of impressions without any error, and learning-based methods will highly possibly give noisy predictions.
We presented a search-based method for ad impression forecasting of new ads (or old ads with new bids) in contextual advertising.
The salient feature of our approach is that it replays the ad selection process over a log of past page not shown below are the same for all four ads), but the impressions of the ads di er a lot.
Ads Titles Bid Phrases # of Impressions
 cheap DVDs


 free DVDs




 Buy cheap DVDs Buy great DVDs at low price DVD Free DVDs DVDs for less impressions and counts how many times the new ad would have been shown if it were present in the system.
In this way, during forecasting, we can employ exactly the same page-to-ad scoring as during ad serving.
Ad selection is usually done based on complicated, highly tuned formulae.
The proposed approach enables us to factor the scoring into the forecasting process as a black-box.
To make the search feasible, we  rst reduce the search over the past page impressions into a search over the unique web pages in those impressions.
Then we search the space of web pages using a two-level search process: at the  rst level an inexpensive approximate evaluation is performed to identify candidate web pages on which a test ad could possibly have been shown; at the second level the candidates are fully evaluated and their contributions are counted.
Experimentally, we demonstrate that our approach can accurately forecast impressions of ads in the higher range of views per day.
As such, it can be used by midsize and large advertisers that run campaigns with millions of ad views per day.
Besides forecasting impression counts, the approach proposed in this paper can also be used for bid suggestion, and ad evaluation.
In our current work, we are exploring how to improve our estimates by combining machine learning-based methods.
