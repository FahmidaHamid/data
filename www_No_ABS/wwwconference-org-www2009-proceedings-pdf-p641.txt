We are transitioning from the  Web 1.0,  where information consumers and providers are clearly distinct, to the so-called  Web 2.0  in which anyone can easily annotate objects (sites, pages, media, and so on) that someone else authored.
These annotations take many  Corresponding author.
Email: bmarkine@cs.indiana.edu Copyright is held by the International World Wide Web Conference Committee (IW3C2).
Distribution of these papers is limited to classroom use, and personal use by others.
forms such as classi cation, voting, editing, and rating.
Social bookmarking systems [17] are increasingly popular among  Social Web  applications.
Their emergent information organizations, based on free-form tag annotations, have become known as folksonomies.
From the perspective of critical Web applications such as search engines, we see this as the second major transition in the brief history of the Web.
The  rst one occurred when researchers went beyond the textual analysis of content by taking into account the hyperlinks created by authors as implicit endorsements between pages, leading to effective ranking and clustering algorithms such as PageRank [6].
Now folksonomies grant us access to a more explicit and semantically richer source of social annotation.
They allow us to extend the assessment of what a page is about from content analysis algorithms to the collective  wisdom of the crowd.  If many people agree that a page is about programming then with high probability it is about programming even if its content does not include the word  programming.  This bottom-up approach of collaborative content structuring is able to counteract some core de ciencies of knowledge management applications, such as the knowledge acquisition bottleneck.
The usage of folksonomy induced information and the combination with Semantic Web technology is seen as the next transition towards the  Web 3.0.  The fact that collaborative tagging leverages large-scale human annotation of Web resources makes it a perfect candidate for bootstrapping Semantic Web applications.
Hereby, the notion of similarity plays a crucial role.
For example, keyword (tag) similarity supports navigation, keyword clustering, query expansion, tag recommendation and ontology learning; and resource (page/site) similarity supports result clustering, similarity search, ontology population and again page recommendation and navigation.
Figure 1 illustrates three applications thereof.
Measures of semantic similarity between objects are naturally based upon a precise understanding of how the object space is structured.
The inherent tripartite data structure of folksonomies (consisting of users, tags and resources) differs fundamentally from well-studied schemes like ontologies or the Web s link graph.
Hence, a key question is how to extend and adapt traditional content and link analysis algorithms to folksonomies.
In this work, we focus on de ning and analyzing semantic similarity relationships obtained from mining socially annotated data.
As a large-scale evaluation of semantic relationships is a dif cult task, we perform a two-step experimentation: First, we compare the ability of various tag similarity measures to predict user-created tag relations from the social bookmarking system BibSonomy.org, and second we provide an external grounding to reliable measures validated by user studies on large and open reference data sets.
Our insights inform the choice of an appropriate measure, e.g.
in a given application context.
The similarity notions that we wish to derive from folksonomies represent bottom-up, emergent, social semantic relationships obtained by aggregating the opinions of many users who are likely to have inconsistent knowledge and semantic representations.
There are many ways to pursue such a goal and many open questions.
For example, should a relationship be stronger if many people agree that two objects are related than if only few people do?
Which weighting schemes regulate best the in uence of an individual?
How does the sparsity of annotations affect the accuracy of these measures?
Are the same measures most effective for both resource and tag similarity?
Which aggregation schemes retain the most reliable semantic information?
Which lend themselves to incremental computation?
We address all of the above questions here by describing an evaluation framework to compare various general folksonomy-based similarity measures.
The main contributions of this paper are:   A general and extensive foundation for the formulation of similarity measures in folksonomies, spanning critical design dimensions such as the symmetry between users, resources, and tags; aggregation schemes; exploitation of collaborative  lter-ing; and information-theoretic issues.
Some of the measures considered have been introduced and investigated before (cf.
[10]), but no systematic study including all dimensions of a folksonomy and all measures exists to date about their application to social similarity.
(  3)   An experimental assessment of the effectiveness of several similarity measures for both tags and resources.
For the former, we establish a comparison with user-created tag relations to measure effectiveness.
For both tags and resources, as a second step we gauge the similarity measures against reliable grounding measures validated by user studies on large and open reference data sets.
This evaluation addresses several key limitations of traditional user based assessments.
(  4)   An analysis of the empirical evaluation results in the context of their scalability, in particular their viability for practical implementations in existing social bookmarking systems.
A clear trade-off between effectiveness and ef ciency is demonstrated and discussed.
(  5)

 Social bookmarking is a way to manage bookmarks online, for easy access from multiple locations, and also to share them with a community.
There are many social bookmarking sites including popular ones such as Del.icio.us, StumbleUpon.com, CiteULike.org, BibSonomy.org, and too many others to list.
A number of early social bookmarking tools and their functionalities were reviewed by Hammond et al. [17, 29].
While bookmarking and tagging may share several incentives [34], they are separate processes; many people bookmark without tagging [38].
The tagging approach has several limitations including lack of structure [3], lack of global coherence [38], polysemy, and word semantics [15].
Synonymy, the use of different languages, and spelling mistakes may force users to search through numerous tags.
Navigation can be enhanced by suggesting tag relations grounded in content-based features [1].
Collaborative tagging is often contrasted with more traditional knowledge management approaches.
Voss [46] provides evidence that the difference between controlled and free indexing blurs with suf cient feedback mechanisms.
The weaknesses and strengths of these by In prior work, we have contrasted peer-to-peer Christiaens [11].
knowledge management with tagging approaches [41].
different metadata mechanisms compared are Figure 1: Three applications utilizing relationships between objects induced by social media.
Top: Given a tag, the social bookmarking system BibSonomy.org suggests semantically similar tags.
Middle: GiveALink.org leverages a similarity network of resources to visualize search results [13].
Bottom: The online tool at netr.it visualizes tag relationships generated from a user s Flickr pro le.
Measuring the relationships among tags or tagged resources is an active research area.
Mika provides a model of semantic-social networks for extracting lightweight ontologies from del.icio.
us [35].
Cattuto et al. use a variation of set overlap in the spirit of TF-IDF to build an adjacency matrix of Web resources [9].
Wu et al. [47] modify HITS to look for relationships between Web resources.
Hotho et al. [23] convert a folksonomy into an undirected weighted network, used for computing a modi ed PageRank algorithm called FolkRank for ranking query results.
Semantic networks card s coef cient [18], also to reconstruct a concept hierarchy [19].
Relationships among users can also be extracted from tagging systems.
Diederich and Iofciu use a cosine variant to compute similarities between users [12].
Others have proposed alternative approaches for extracting taxonomic relations or inferring global semantics from a folksonomy [43, 42, 16, 49].
In the context of social network analysis, Liben-Nowell and Kleinberg [27] explore several notions of node similarity for link prediction.
Unlike all of the above literature, here we introduce a systematic analysis of a broad range of similarity measures that can be applied directly and symmetrically to build networks of users, tags, or resources.
Closely related to the task of measuring the relatedness of tags and resources is also the application domain of recommendations in folksonomies.
The literature is still sparse.
Existing work can be broadly divided into approaches that analyze the content of the tagged resources with information retrieval techniques (e.g.
[36, 7]), approaches that use collaborative  ltering methods based on the folksonomy structure (e.g.
[48, 24]), and combinations of the two [21].
Sarwar et al. built networks using variations of cosine and correlation based similarity measures.
Each type of network was exploited after assembly for investigating two collaborative  l-tering techniques [40].
Our approach differs in that we capture collaborative  ltering in the similarity measure during network assembly.
Several studies and algorithms consider social annotations as a means of improving Web search.
Examples include studies to compare the content of social networks with search engines [37, 20] and enhancing search through the use of tags and rankings from social bookmarking systems [45, 33, 2].
In prior work, we addressed scalability with collaborative  ltering when assembling a resource-by-resource similarity network in the social bookmarking system GiveALink.org [32].
This discussion extends our prior work.
The empirical evaluation in this paper leverages externally validated semantic similarity measures for Web resources and tags, each used as a grounding reference.
In the case of resources, semantic similarity refers to the degree of relatedness between two Web sites or documents, as perceived by human subjects.
Web directories such as the Open Directory Project (ODP, dmoz.org) provide user-compiled taxonomies of Web sites.
Measures of semantic similarity based on taxonomies are well studied [14].
Maguit-man et al. extended Lin s [28] information-theoretic measure to infer similarity from the structure of general ontologies, both hierarchical and non-hierarchical [31, 30].
Such a measure, validated by means of a user study, will serve as our grounding for resource similarity.
Jiang and Conrath [25] developed a notion of distance in WordNet (wordnet.princeton.edu) that combines the taxonomic path length with an information-theoretic similarity measure by Resnik [39].
The Jiang-Conrath distance was validated experimentally by means of user studies as well as by its superior performance in the context of a spellchecking application [8].
Therefore it will serve as our grounding for tag similarity.
Before diving into the details of the similarity measures that we propose to explore, let us  rst review the representation that we assume for the annotations to be mined.
Our approach is based on the triple representation widely adopted in the Semantic Web community [23], which is closely related to the triadic context in formal concept analysis [26].
A folksonomy F is a set of triples.
Each triple (u, r, t) represents user u annotating resource r with tag t. This is a highly  exible representation for which ef cient data store libraries exist.
Folksonomies are read-Figure 2: Example folksonomy.
Two users (alice and bob) annotate three resources (cnn.com, www2009.org, wired.com) using three tags (news, web, tech).
The triples (u, r, t) are represented as hyper-edges connecting a user, a resource and a tag.
The 7 triples correspond to the following 4 posts: (alice, cnn.com, {news}), (alice, www2009.org, {web, tech}), (bob, cnn.com, {news}), (bob, wired.com, {news, web, tech}).
ily represented via triples; a post (u, r, (t1, .
.
.
, tn)) is transformed into a set of triples {(u, r, t1), .
.
.
, (u, r, tn)}.
Note that hierarchical classi cations can also be represented by triples by equating categories (or folders) with tags and applying inheritance relationships in a straightforward way; a classi cation (u, r, t) implies {(u, r, t), (u, r, t1), .
.
.
, (u, r, tn)} for all ancestor classes ti of t. Therefore the triple representation subsumes hierarchical taxonomies and folk-sonomies.
As an example, Fig. 2 displays seven triples corresponding to a set of four posts by two users.
In the following we use this running example to illustrate different de nitions of similarity.
We will de ne similarity measures  (x, y) where x and y can be two resources (pages, media, etc.)
or tags (keywords, phrases, categories, etc.).
Since measures for similarity and relatedness are not well developed for three-mode data such as folksonomies, we consider various ways to obtain two-mode views of the data.
In particular, we consider two-mode views in which the two dimensions considered are dual   for example, resources and tags can be dual views if resources are represented as sets of tags and vice-versa, or if tags are represented as vectors of resources and vice-versa.
We focus on the development of information-theoretic similarity measures, which take into account the information/entropy associated with each item.
In reducing the dimensionality of the triple space, we necessarily lose correlation information.
Therefore the aggregation method is critical for the design of effective similarity measures; poor aggregation choices may negatively affect the quality of the similarity by discarding informative correlations.
As mentioned above, we can de ne similarity measures for each of the three dimensions (users, resources, tags) by  rst aggregating across one of the other dimensions to obtain a two-mode view of the annotation information.
For evaluation purposes, we focus here on resource-resource and tag-tag similarity, for which we have reference data as empirical grounding.
Therefore we aggregate across users, and obtain dual views of resources and tags, yielding dual de nitions for resource and tag similarity.
To keep the notation a bit simpler, let us make explicit the dimension of users along which we aggregate, even though the discussion can be extended in a straight-bobalicewired.comcnn.comwww2009.orgwebtechnewsWWW 2009 MADRID!Track: Semantic/Data Web / Session: Mining for Semantics643forward way to aggregate across tags or resources.
Below we consider four approaches to aggregate user information.
The simplest aggregation approach is to project across users, obtaining a unique set of (r, t) pairs.
If the triples are stored in a database relation F , this corresponds to the projection operator in relational algebra:  r,t(F ).
Another way to represent the result of aggregation by simple projection is a matrix with binary elements wrt   {0, 1} where rows correspond to resources (as binary vectors, or sets of tags) and columns corresponds to tags (as binary vectors, or sets of resources).
All similarity measures are then derived directly from this set information.
As an example, the projected binary matrix for the folksonomy of Fig. 2 is reported below.
Given a resource and a tag, a 0 in the corresponding matrix element means that no user associated that resource with that tag, whereas a 1 means that at least one user has performed the indicated association.
news web tech cnn.com www2009.org wired.com









 A more sophisticated form of aggregation stems from considering distributional information associated with the set membership relationships between resources and tags.
One way to achieve distributional aggregation is to make set membership fuzzy, i. e., weighted by the Shannon information (log-odds) extracted from the annotations.
Intuitively, a shared tag may signal a weak association if it is very common.
Thus we will use the information of a tag (resp.
resource) x de ned as   log p(x) where p(x) is the fraction of resources (resp.
tags) annotated with x.
Another approach is to count the users who agree on a certain resource-tag annotation while projecting across users.
This yields a set of frequency-weighted pairs (r, t, wrt) where the weight wrt is the number of users tagging r with t. Such a representation corresponds to a matrix with integer elements wrt, where rows are resources vectors and columns are tag vectors.
For the folksonomy of Fig. 2, such a matrix is reported below.
Similarity measures are then derived directly from the weighted representation.
news web tech cnn.com www2009.org wired.com








 We will use both of the above distributional aggregation schemes, as appropriate for different similarity measures.
The fuzzy set approach is appropriate when we want to perform row/column normalization of tag/resource probabilities to prevent very popular items from dominating the similarity.
Other measures such as the dot product depend naturally on weighted vector representations.
By analogy to micro-averaging in text mining, distributional aggregation can be viewed as  micro-aggregation  if we think of users as classes.
Each annotation is given the same weight, so that a more active user would have a larger impact on the weights and consequently on any derived similarity measure.
In contrast, macro-aggregation treats each user s annotation set independently  rst, and then aggregates across users.
In relational terms, we can select the triples involving each user u and then project, yielding a set of pairs for u: {(r, t)u} =  r,t( u(F )).
This results in per-user binary matrices of the form wu,rt   {0, 1}.
For the example folksonomy of Fig. 2, we report below the matrices for the user alice (top) and bob (bottom).
news web tech cnn.com www2009.org wired.com








 news web tech cnn.com www2009.org wired.com








 The per-user binary matrix representations wu,rt   {0, 1} are used to compute a  local  similarity  u(x, y) for each pair of objects (resources or tags) x and y.
Finally, we macro-aggregate by voting, i. e., by summing across users to obtain the  global  similarity
  (x, y) =  u(x, y).
(1) u Macro-aggregation does not have a bias toward users with many annotations.
However, in giving the same importance to each user, the derived similarity measures amplify the relative impact of annotations by less active users.
It is an empirical question which of these biases is more effective.
Macro-aggregation lends itself to explore the issue of collaborative  ltering in folksonomies.
Thus far, we have only considered feature-based representations.
That is, a resource is described in terms of its tag features and vice-versa.
If two objects share no feature, all of the measures de ned on the basis of the above aggregation schemes will yield a zero similarity.
In collaborative  ltering, on the other hand, the fact that one or more users vote for (or in our case annotate) two objects is seen as implicit evidence of an association between the two objects.
The more users share a pair of items, the stronger the association.
We want to consider the same idea in the context of folksonomies.
If many users annotate the same pair of resources, even with different tags, the two resources might be related.
Likewise, if many users employ the same pair of tags, the two tags might be related even if they share no resources.
Macro-aggregation incorporates the same idea by virtue of summing user votes, if we assign a nonzero local similarity  u(x, y) > 0 to every pair of objects (x, y) present in u s annotations, irrespec- tive of shared features.
This is accomplished by adding a feature-independent local similarity to every pair (x, y) of resources or tags.
In practice we can achieve this by adding a special  user tag  (resp.
 user resource ) to all resources (resp.
tags) of u.
This way all of u s items have at least one annotation in common.
Prior to macro-averaging, u s local similarity  u for each pair must be computed in such a way that the special annotations yield a small but nonzero contribution.
This requires a revision of the information-theoretic similarity measures.
For illustration, consider adding the special tag t  u to all resources annotated by u.
The probability of observing tag t  u associated with any of u s resources is one, therefore the fact that two resources share t  u carries no information value (Shannon s information is   log p(t  u|u) =   log 1 = 0).
Let us rede ne user u s odds of tag (resp.
resource) x as p(x|u) = N (u, x)/(N (u) + 1) (2) where N (u, x) is the number of resources (resp.
tags) annotated by u with x, while N (u) is the total number of resources (resp.
tags) annotated by u.
This way,   log p(t  u|u) =   log[N (u)/(N (u) +
 similarity measures with collaborative aggregation.
ods.
Entries refer to equation numbers.
Measure Matching Overlap Jaccard Dice Cosine
 Project.
Distrib.
Macro














 Collaborative









 We wish to evaluate several information-theoretic, statistical, and practical similarity measures.
Table 1 summarizes the measures de- ned below.
Each of the aggregation methods requires revisions and extensions of the de nitions for application to the folksonomy context, i. e., for computing resource and tag similarity from triple data.
Recalling that all measures are symmetric with respect to resources and tags, we simplify the notation as follows: x represents a tag or a resource and X is its vector representation.
For example, if x is a resource, X is a vector with tag elements wxy.
If x is a tag, X is a vector with resource elements wxy (note we do not switch the subscript order for generality).
For projection aggregation, the binary vector X can be interpreted as a set and we write y   X to y wxy.
Analogously for a single user y wu,xy.
We will use   to refer to all similarity measures, and  u to refer to all those similarity measures that are based on a single user u and are to be macro-aggregated (Equation 1).
The matching similarity measure is de ned, for the projection mean wxy = 1 and |X| =P u, y   X u means wu,xy = 1 and |X u| = P case, as  (x1, x2) = wx1ywx2y = |X1   X2|.
(3) y As an example, below we report the resulting similarity matrices for the resources and the tags of Fig. 2: cnn.com www2009.org wired.com cnn.com www2009.org wired.com -


-


-news web tech

 -


-news web tech -

 (x1, x2) =   X y X1 X2 The distributional version of the matching similarity is log p(y).
(4) This and the other measures use the p de nition of   3.2.2.
For the example case of Fig. 2, the resources and the tags have the following probabilities: p(cnn.com) = 1/3 (out of 3 tags, cnn.com is associated with 1 tag only, news), p(www2009.org) = 2/3, p(wired.com) = 1 (i.e., no information content about tags), p(news) = 2/3 (out of 3 resources, news is associated with 2 of them, cnn.com and wired.com), p(web) = 2/3, p(tech) =
 tags (numeric values were truncated at the second decimal place): wired.com www2009.org cnn.com cnn.com www2009.org wired.com -


-


-news web tech news web tech -


-


-Notice how the similarity of news with both web and tech is zero in the distributional case, whereas it is nonzero in the projection case above.
This is due to the fact that the tag news shares only one resource, wired.com, with both web and tech.
wired.com has zero information content for tags, as it is associated with all of them.
Thus it gives no contribution to tag similarities.
In the case of macro and collaborative aggregation, an analogous de nition applies to local (per-user) matching similarity:  u(x1, x2) =   X y Xu

 log p(y|u).
(5) For the case of Fig. 2, we need to compute the conditional probabilities for the two users.
For alice, we have: p(cnn.com|alice) = 1/3, p(www2009.org|alice) = 2/3, p(wired.com|alice) = 0, p(news|alice) = 1/2 (news is associated with one of the two resources alice has annotated), p(web|alice) = 1/2, p(tech|alice) = 1/2.
For bob: p(cnn.com|bob) = 1/3, p(www2009.org|bob) = 0, p(wired.com|bob) = 1, p(news|bob) = 1, p(web|bob) = 1/2, p(tech|bob) = 1/2.
We compute the similarity matrices as we did above, separately for users alice and bob, and then we sum them to obtain the aggregated similarity matrices below: cnn.com www2009.org wired.com cnn.com www2009.org wired.com -


-


-news web tech news web tech -


-


-Notice how computing per-user similarities and then aggregating over users produces more sparse similarity matrices than aggregating over users  rst.
In the example of Fig. 2, due to the tiny size of the folksonomy, the consequences are extreme: The contribution of user alice to both matrices is zero, and for tag similarities this is also true for user bob, so that all entries of the aggregated tag similarity matrix are zero.
Collaborative  ltering is able to extract more signal when aggregating similarities over users, as it exposes the similarity that is implicit in the user context.
In our example, when we modify the probabilities of tags and resources as described in   3.2.4, we  nd for alice: p(cnn.com|alice) = 1/4, p(www2009.org|alice) = 1/2, p(wired.com|alice) = 0, p(news|alice) = 1/3, p(web|alice) = 1/3, p(tech|alice) = 1/3.
For bob: p(cnn.com|bob) = 1/4, p(www2009.org|bob) = 0, p(wired.com|bob) = 3/4, p(news|bob) = 2/3, p(web|bob) =
 tag t  and dummy resource r  used in the construction of   3.2.4 are: alice|alice) = 2/3, p(r  bob|bob) = 2/3, p(t  bob|bob) = 3/4.
The resulting similarity matrices for collabora-p(r  tive aggregation are: alice|alice) = 3/4, p(t  cnn.com www2009.org wired.com cnn.com www2009.org wired.com -


-


-web tech news -

web
 -
tech

 Notice how collaborative  ltering recovers nonzero values for the tag similarities.
Projection-aggregated overlap similarity is de ned as The macro and collaborative aggregation versions are based on local cosine


 X u
 |X u p|X u



 (17)  u(x1, x2) = where in the collaborative case the construction of   3.2.4 is applied without need of log-odds computations.
The last measure we consider is mutual information.
With projection and distributional aggregation we de ne

 y1 X1 y2 X2 (6)  (x1, x2) = p(y1, y2) log p(y1, y2) p(y1)p(y2) (18) .
(7) log p(y)) where for the projection case the probabilities p(y) are de ned in the usual manner (  3.2.2), and the joint probabilities p(y1, y2) are also based on resource/tag (row/column) normalization:

 x 1 x wxy1 wxy2

 p(y1, y2) = .
(19) With distributional aggregation, the joint probabilities must be matrix rather than row/column normalized; we compute fuzzy joint probabilities from the weighted representation: p(y) = , p(y1, y2) = x min(wxy1 , wxy2 ) (20) r,t wrt where min is a fuzzy equivalent of the intersection operator.
Finally, macro and collaborative aggregation of local mutual information use
 x wxyP
 r,t wrt
  u(x1, x2) = y1 Xu
 y2 Xu
 p(y1, y2|u) log p(y1, y2|u) p(y1|u)p(y2|u) (21) where simple and joint probabilities are resource/tag (row/column) normalized for each user s binary representation, and collaborative mutual information uses the construction and probability de nition of   3.2.4.
For space reasons we omit discussion of other measures we experimented with.
These include distributional versions of matching, overlap, Dice, and Jaccard similarity with matrix-normalized probabilities based on the weighted representation.
They did not perform as well as the measures de ned above.
BibSonomy.org is a social bookmark and publication management system.
For our analysis, we used a benchmark dataset from December 2007, which is available on the BibSonomy site.1 We focused on the bookmark part of the system.
The BibSonomy snapshot that we used contains 128, 500 bookmarks annotated by
 larity and tag similarity, aggregating across users as the third dimension of our annotation data.
BibSonomy.org allows users to input directed relations such as tagging   web2.0 between pairs of tags.
These relationships are suitable for, but not limited to, de ning is-a relationships.
The semantics can thus be read as  tagging is a web2.0  or  tagging is a subtag of web2.0  [22].
The most straightforward evaluation of our similarity measures therefore consists in using them to predict user-de ned relations between tags.
Such a prediction task requires that we set some threshold on the similarity 1http://www.bibsonomy.org/faq#faq-dataset-1 while distributional overlap is given by  (x1, x2) = max(P max(P

 y X1 y Xu

 min(|X1|,|X2|) log p(y) y X2 y X1 X2 log p(y),P log p(y|u),P
 y Xu
 log p(y|u) y Xu
  (x1, x2) =  u(x1, x2) = Local overlap for macro and collaborative aggregation is
 Jaccard similarity aggregated by projection is

 Distributional Jaccard similarity is de ned by  (x1, x2) = log p(y|u)) .
(8) (9)



  (x1, x2) = y X1 X2 y X1 X2 log p(y) log p(y) (10) while the macro and collaborative versions are based on  u(x1, x2) = .
(11) y Xu y Xu



 log p(y|u) log p(y|u)
 The projected Dice coef cient is with its distributional version de ned as  (x1, x2) = and the macro and collaborative Dice built upon


  (x1, x2) =
 y X1 y X1 X2

 log p(y) +P

 log p(y|u) +P
 y Xu

 y Xu
 log p(y) y X2 log p(y) log p(y|u) y Xu
 log p(y|u)  u(x1, x2) =
 Cosine similarity with binary projection is given by  (x1, x2) =
 p|X1|   |X2| .
X1p|X1|   X2p|X2| =
 qP
 For the distributional version of the cosine, it is natural to use the frequency-weighted representation:  (x1, x2) =

 y wx1ywx2y qP y w2 x1y y w2 x2y .
(16) (12) (13) .
(14) (15) than to a computer.  Indeed in most applications we envision (e.g.
search, recommendation) ranking is key: Given a particular tag or resource we want to show the user a set of most similar objects.
We thus turn to Kendall s   correlation between the similarity vectors whose elements are pairs of objects.
We compute   ef ciently with Knight s O(N log N ) algorithm as implemented by Boldi et al. [5].
A higher correlation is to be interpreted as a better agreement with the grounding and thus as evidence of a better similarity measure.
Of course only a subset of the tags or resources in any social bookmarking system are found in a reference similarity dataset, so we cannot use the grounding to measure similarity in general.
We can however use the reference similarities to evaluate our proposed measures, which can in turn be applied to any pair of objects.
We use the WordNet term collection for the semantic grounding of the tag similarity measures.
In particular we rank tag pairs by their Jiang-Conrath distance [25], which combines taxonomic and information-theoretic knowledge.
This WordNet distance measure is an appropriate reference as it was validated experimentally [8, 10].
For our evaluation of tag similarity, we focus on the subset of the BibSonomy annotations whose tags overlap with the WordNet dataset.
This subset comprises 17, 041 tags, or about 29% of the total number of tags in the BibSonomy dataset.
Similarities are computed between all pairs of tags in this set, however it was not possible to use the full annotation data from the folksonomy due to the time complexity of the similarity computations in conjunction with the dimensionality of the underlying vector space.
The issues of time complexity and scalable computation of similarity are discussed below in   5.
Let us  rst evaluate the effectiveness of the measures by limiting the analysis to the most popular resources.
More specifically we select, among the tags in the overlap subset, those associated with the 2000 most frequent resources, i.e., those resources that appear in the largest number of triples across the entire folksonomy.
We then compute the similarities using all the folksonomy annotations relative to these top tags, disregarding less used, noisier tags.
As an illustration, let us consider the tags of Fig. 2 and the similarities among them as extracted from the WordNet grounding as well as two of our measures.
Below we show the ranked similarities and the resulting   values.
Rank


   WordNet tech-web news-web news-tech Distrib.
Jaccard news-tech tech-web news-web

 Distrib.
MI news-web tech-web news-tech

 Figure 4 plots Kendall s   correlation between each measure introduced in   3 and the WordNet reference.
As a baseline we computed   with a randomly generated ranking of the tag similarities.
Among micro-aggregated measures, distributional information does not have any positive impact on accuracy compared to the simpler binary representation stemming from projection.
Consistently with Fig. 3, mutual information is by far the most accurate measure of tag similarity.
Matching, overlap, Dice and Jaccard do not differ signi cantly from each other.
Macro-aggregation is the worst-performing aggregation method, with the exception of matching (which almost equals the micro-averaged version) and mutual information (which outperforms all of the micro-averaged measures except mutual information itself).
Figure 3: Areas under ROC curves (AUC) for tag relation predictions based on similarity measures with distributional and collaborative aggregation.
In an ROC curve, the true positive rate is plotted against the false positive rate as a function of similarity thresholds.
A good similarity measure can select many true positives with few false positives, yielding a higher AUC.
values, such that a similarity above threshold implies a prediction that two tags are related and vice-versa.
To determine which similarity measures are more effective predictors, we plot in Fig. 3 the areas under ROC curves for a couple of aggregation methods.
These results suggest that mutual information outperforms the other measures with distributional aggregation.
For collaborative aggregation it is dif cult to establish a clear ranking between the measures.
This evaluation approach has some important limitations:   While folksonomies contain many tags, available user data about tag relations is very sparse.
For example we considered 2000 tags (4 106 candidate relations) and found among these only 142 tag relations provided by BibSonomy users.
With such little labeled data, assessments are bound to be noisy.
  Similarity values are broadly distributed, spanning several orders of magnitude.
The tag relation prediction task forces us to turn this high resolution data into binary assessments, potentially losing precious information.
The results are very sensitive to small changes in the similarity threshold; for example increasing the threshold from 0 to 10 7 decreases the false positive rate from 1 to less then 0.1.
Such sensitivity suggests that  ne-grained information is critical, and negatively affects the reliability of the evaluation results.
  Although there is no such requirement, users  tag relations usually focus on hierarchical relationships and thus may miss many potentially strong non-hierarchical relations.
For example, we may have python   programming and perl   programming but no relation between python and perl.
This may unfairly penalize our measures.
  Finally, user data is only available for tag relations while we would like to also evaluate the resource similarity measures.
To address these limitations, we look to an alternative evaluation approach that, while still based (indirectly) on user data, allows us to access a much larger pool of high resolution similarity assessments for both tags and resources.
For each, we need a reliable external source of similarity data as a grounding reference to evaluate the effectiveness of the various proposed similarity measures.
Given a similarity measure to be evaluated, we want to assess how well it approximates the reference similarity measures.
Since different similarity measures have different distributional properties, we turn to a non-parametric analysis that only looks at the ranking of the pairs by similarity rather than the actual similarity values.
This re ects the intuition that while it is problematic for someone to quantify the similarity between two objects, it is natural to rank pairs on !"#$%!"&%!"&$%!" %!" $%!"(%)*+,-*./01234%51443.1-3067%!
"#$83,9:*2;%<67-43=%>3993-?%)*97%51+*27%8@%WWW 2009 MADRID!Track: Semantic/Data Web / Session: Mining for Semantics647Figure 4: Tag-tag similarity accuracy, according to Kendall s   correlations between the similarity vectors generated by the various measures and the reference similarity vector provided by the WordNet grounding measure.
All similarity measures perform signi cantly better than the randomly generated set of similarities (  = 10 4).
Figure 5: Resource-resource similarity accuracy, according to Kendall s   correlations between the similarity vectors generated by the various measures and the reference similarity vector provided by the ODP grounding measure.
All similarity measures perform signi cantly better than the randomly generated set of similarities (  = 8   10 5).
Collaborative aggregation provides a large boost to accuracy for tags.
Each of the collaborative measures outperforms all of the others, except mutual information.
These results underscore the critical semantic information contained in single-user annotations.
Combining these individually induced tag relations by collaborative aggregation yields globally meaningful semantic tag relations.
We use the URL collection of the Open Directory Project for the semantic grounding of the resource similarity measures.
In particular we rely on Maguitman et al. s graph-based similarity measure [31, 30], which extends Lin s hierarchical similarity [28] by taking non-hierarchical structure into account.
The ODP graph similarity is an appropriate reference because it was shown to be very accurate through a user study [30].
For our evaluation of resource similarity, we focus on the subset of the BibSonomy annotations whose resources overlap with the ODP.
This subset comprises 3, 323 resources, or about 2.6% of the total unique URLs in the BibSonomy dataset.
Similarities are computed between all pairs of resources in this set, using the full annotation data from the folksonomy.
Figure 5 plots the Kendall s   correlation between each measure introduced in   3 and the ODP reference.
The baseline was computed using a random ranking of resources similarities, as we did for tags.
Distributional aggregation yields the best performance.
However, with the exception of the matching similarity measure, the dis-Figure 6: Scalability of the mutual information computation of resource similarity for different aggregation methods.
We measured the CPU time necessary to update the similarities after a constant number of new annotations are received, as a function of system size n. Best polynomial  ts time   n  are also shown.
tributional information does not seem to have a very large impact.
Mutual information is again by far the most accurate measure.
Overlap, Dice and Jaccard do not differ signi cantly from each other.
While macro-aggregation is the worst-performing aggregation method, collaborative aggregation greatly improves accuracy.
In particular, cosine performs best in the collaborative setting.
These results again suggest that collaborative  ltering captures important semantic information in the folksonomy; the fact that two resources are annotated by the same users is telling about the relationship between these resources, beyond any tags they share.
These results are consistent with experiments performed on another data set for a small subset of the measures explained here [32].
The results outlined above for resource and tag similarity allow us to draw a few consistent observations: First, mutual information is the measure that best extracts semantic similarity information from a folksonomy.
Mutual information considers conditional probabilities between two objects extracting the most data among the evaluated measures from an information theory point of view.
We interpret this as the most  ne-grained approach because we are not projecting out any information on the graph.
Second, macro-aggregation is less effective than micro-aggregation.
One interpretation is that since user data is necessarily more sparse, macro-aggregation adds noise by giving equal importance to each user.
In other words, the user does not seem to be as good a  unit  of knowledge aggregation in a folksonomy as  ner-grained individual annotation.
In spite of macro-aggregation s shortcomings, collaborative  l-tering extracts so much useful information about folksonomy relationships that it cannot be ignored.
Especially for tag similarity, collaborative aggregation compensates for almost all the loss due to the noise of macro-aggregation.
It seems therefore important for folksonomy-derived similarity measures to capture this form of social information, which differs from the more obvious notions of similarity based on shared features.
Indeed we show there is useful information in annotation data even if we do away with tags when computing resource similarity and vice-versa (i.e., removing resources when computing tag similarity).
Another reason to consider macro-aggregation in general, and collaborative aggregation in particular, is related to the issue of scala-bility.
As mentioned above, the computations of micro-aggregated
 tion, the most effective measure, is also the most expensive.
Having a look at its de nition (Eq.
18), it is obvious that in its computation all possible combinations of attribute pairs for two given objects are involved.
This implies a quadratic complexity   while e.g.
the cosine similarity (Eq.
16) only runs in a linear fashion through the attribute overlap of two objects.
From a practical perspective, we consider as scalable those measures that can be updated to re ect new annotations at a pace that can keep up with the stream of incoming annotations.
Suppose that some constant number c of new annotations arrive per unit time.
The similarity of all pairs of tags/resources affected by each new annotation must therefore be updated in constant time 1/c.
The problem with distributional aggregation is that similarities must be recomputed from scratch as frequency weights are updated.
This is not scalable because its complexity clearly grows with the size of the system (e. g., number of triples).
On the other hand, macro and collaborative aggregation allow for incremental computation because each user s representation is maintained separately.
When a new annotation arrives from user u, only u s contribution  u need be updated.
Such updates may be scalable.
An average-case complexity analysis is problematic due to the long-tailed distributions typical of folksonomies; quantities like average densities and average overlap are not necessarily characteristic of the system, given the huge  uctuations associated with broad distributions.
Therefore we turn to an empirical analysis to examine how update complexity scales with system size.
Figure 6 compares the computation of mutual information between resources using two aggregation methods: distributional (micro) and macro (or collaborative) aggregation.
This is representative because mutual information is consistently the best measure with both micro and macro aggregation, and the second best with collaborative aggregation.
As the plot shows, micro-aggregation scales almost quadratically with system size, while macro-aggregated similarity can be updated in almost constant time.
Therefore macro and collaborative aggregation measures compensate a loss in accuracy with a huge scalability gain.
In summary, we have discussed a general and extensive foundation for the formulation of similarity measures in folksonomies, spanning critical design dimensions such as the symmetry between users, resources, and tags; aggregation schemes; exploitation of collaborative  ltering; and information-theoretic issues.
Experiments with resource and tag similarity alike have pointed to folksonomy-based mutual information measures as the best at extracting semantic associations from social annotation data.
The question of scalability has highlighted a critical trade-off between accuracy and complexity.
Although some social aggregation methods achieve good accuracy in a non-scalable way, measures based on collaborative aggregation of annotations achieve competitive quality while minimizing computation thanks to incremental updates.
This leads to the best performance/cost trade-off; we underscore the key role of scalability for the practical viability of similarity computations in existing social bookmarking systems.
Other similarity measures that we have not yet explored include matrix-normalized mutual information with binary projection aggregation and the integration of collaborative  ltering with distributional aggregation.
The similarity measures analyzed in this paper can readily be employed to support many Social and Semantic Web applications, such as tag clustering for ontology construction and learning, query expansion, and recommendation.
Our group has begun the use of these similarity measures for visualizing relationships among resources in search query results [13].
Another straightforward application of the socially induced similarity is to enrich Web navigation for knowledge exploration.
These techniques can lead to a possible synergy between traditional and socio-semantic Web technologies.
Acknowledgments We are grateful to Heather Roinestad for the ODP similarity network, Mark Meiss for his implementation of Kendall s  , and Luis Rocha for helpful comments on fuzzy notions of joint probability that contributed to our extension of mutual information.
This work was performed during FM s sabbatical at the ISI Foundation in Torino, Italy.
We acknowledge support from the ISI and CRT Foundations.
This work has been partly supported by the TAGora project (FP6-IST5-34721) funded by the European Commission s Future and Emerging Technologies program, and by NSF Grant No.
IIS-0811994.
