Similarity measures can be categorized broadly into two types: attributional similarity measures and relational similarity measures.
For attributional similarity measures, the objective is to compute the similarity between two given words by comparing the attributes of each word.
For example, the two words car and automobile share many attributes (e.g.
has wheels, is used for transportation).
Consequently, they are considered as synonyms.
On the other hand, relational similarity is the correspondence between semantic relations that exist between two word pairs.
Word pairs that show a high degree of relational similarity are considered as analogies.
For example, the two word pairs (ostrich, bird) and (lion, cat).
Ostrich is a large bird and lion is a large cat are illustrative of high relational similarity.
The semantic relation, is a large, pertains between the two words in each word pair.
The information available on the Web can be considered as a vast, hidden network of classes of objects (e.g.
named entities) that is interconnected by various semantic relations applying to those objects.
Measuring the similarity between semantic relations is an important intermediate step in various tasks in information retrieval and natural language processing such as relation extraction [7, 8, 40], in which the goal is to retrieve instances of a given relation.
For example, given the relation, ACQUIRER-ACQUIREE, a relation extraction system must extract the instance (Google, YouTube) from the sentence Google completed the acquisition of YouTube.
Bootstrapping methods [25, 6, 14], which require a few seeds (ca.
10 pairs of instances per relation) have extracted numerous candi- date instance pairs from a text corpus.
Given a set of candidate instance pairs, a relational similarity measure can be used to compute the similarity between the relations in the seeds and in the candidates.
Candidate instance pairs with high relational similarity with the seed pairs can then be selected as the correct instances of a relation.
Relational similarity measures have been used to  nd word analogies [10, 24, 31, 33, 38].
Word analogy questions have been used from the Scholastic Aptitude Test (SAT; Educational Testing Service) to benchmark relational similarity measures.
An SAT word analogy question consists of a stem word pair that acts as the question and  ve choice word pairs, out of which only one is analogous to the stem.
A relational similarity measure is used to compare the stem word pair with each choice word pair and to select the choice word pair with the highest relational similarity as the answer.
An interesting application of relational similarity in information retrieval is to search using implicitly stated analogies [21, 37].
For example, the query  Muslim Church  is expected to return  mosque , and the query  Hindu bible  is expected to return  the Vedas .
These queries can be formalized as word pairs: (Christian, We can then  nd the words X and Y that maximize the relational similarity in each case.
Despite the wide applications of relational similarity measures, accurately measuring the similarity between implicitly stated relations remains a challenging task for several reasons.
First, relational similarity is a dynamic phenomenon: it varies with time.
For example, two companies can be competitors initially; subsequently one company might acquire the other.
Second, there can be more than one relation between a given word pair.
For example, between the two words ostrich and bird, aside from the relation is a large, there is also the relation is a  ightless.
A relational similarity measure must  rst extract all relations between the two words in each word pair before it can compute the similarity between the word pairs.
Third, there can be more than one way to express a particular semantic relation in a text.
For example, the three patterns   X was acquired by Y, Y completed the acquisition of X, and Y buys X   all indicate an acquisition relation between X and Y.
In addition to the problems described above, measuring relational similarity between pairs in which one or both words are named entities (e.g., company names, personal names, locations, etc.)
is even more dif- cult because such words are not well covered by manually created dictionaries such as WordNet1[23].
As described herein, we propose a relational similarity measure that uses a Web search engine to measure the similarity between implicitly stated semantic relations in two word pairs.
Formally, given two word pairs, (a,b) and (c,d), we design a function, rel-sim((a, b), (c, d)), that returns a similarity score in the range [0, 1].
The proposed relational similarity measure  rst extracts implicitly stated relations that exist between the two words in each word pair.
The measure then compares the extracted relations between word pairs.
Our contributions are summarized as follows:   We propose a shallow, lexical-patterns-based approach to represent the various semantic relations that pertain between the two words in a given word pair.
The proposed pattern extraction algorithm requires no language dependent preprocessing steps such as part-of-speech tagging or dependency parsing, which can be time consuming or even infeasible at the Web scale.
We extract numerous lexical patterns that describe various semantic relations.
  We present an ef cient sequential clustering algorithm to cluster lexical patterns, to identify the different patterns that describe a particular semantic relation.
The proposed clustering algorithm requires only one pass through the set of extracted patterns.
For that reason, it scales linearly with the number of patterns.
We then use the clusters to de ne features for a supervised metric learning algorithm.
  We evaluate the proposed method in two tasks: classifying semantic relations between named entities, and solving SAT word-analogy questions.
In the relation classi cation task, the proposed method signi cantly outperforms all baselines, including the state-of-the art Latent Relational Analysis (LRA) [33].
Moreover, the proposed method achieves an SAT score of 51.1 and reduces the time taken to answer 374 questions by LRA from 9 days to less than 6 hours.
1http://wordnet.princeton.edu/

 The Structure Mapping Theory (SMT) [15] is based on the premise that an analogy is a mapping of knowledge from one domain (base) into another (target), which conveys that a system of relations known to hold in the base also holds in the target.
The target objects need not resemble their corresponding base objects.
This structural view of analogy is based on the intuition that analogies are about relations, rather than simple features.
Although this approach works best when the base and the target are rich in higher-order causal structures, it can fail when structures are missing or  at [39].
Turney et al. [35] combined 13 independent modules by considering the weighted sum of the outputs of each module to solve SAT analogy questions.
The best performing individual module was based on the Vector Space Model (VSM).
In the VSM approach [34], a vector is  rst created for a word pair (X,Y) by counting the frequencies of various lexical patterns containing X and Y.
In their experiments, they used 128 manually created patterns such as  X of Y ,  Y of X ,  X to Y , and  Y to X .
These patterns are then used as queries to a search engine.
The numbers of hits for respective queries are used as elements in a vector to represent the word pair.
Finally, the relational similarity is computed as the cosine of the angle between the two vectors that represent the two word pairs.
Turney et al. [35] introduced a dataset containing
 sures.
An SAT analogy question consists of a stem word pair that acts as the question, and  ve choice word pairs.
The choice word pair that has the highest relational similarity with the stem word pair is selected by the system as the correct answer.
The average SAT score reported by high school students for word-analogy questions is 57%.
The VSM approach achieves a score of 47% on this dataset.
Turney [31, 33] proposed Latent Relational Analysis (LRA) by extending the VSM approach in three ways: a) lexical patterns are automatically extracted from a corpus, b) the Singular Value Decomposition (SVD) is used to smooth the frequency data, and c) synonyms are used to explore variants of the word pairs.
Similarly, in the VSM approach, LRA represents a word pair as a vector of lexical pattern frequencies.
First, using a thesaurus, he  nds related words for the two words in a word pair and create additional word pairs that are related to the original word pairs in the dataset.
Second, n-grams of words are extracted from the contexts in which the two words in a word pair cooccur.
The most frequent n-grams are selected as lexical patterns to represent a word pair.
Then a matrix of word pairs vs. lexical patterns is created for all the word pairs in the original dataset and the additional word pairs.
Elements of this matrix correspond to the frequency of a word pair in a lexical pattern.
Singular value decomposition is performed on this matrix to reduce the number of columns (i.e. patterns).
Finally, the relational similarity between two word pairs is computed as the average cosine similarity over the original word pairs and the additional word pairs derived from them.
In fact, LRA achieves a score of 56.4% on SAT analogy questions.
Both VSM and LRA require numerous search engine queries to create a vector to represent a word pair.
For example, with 128 patterns, the VSM approach requires at least 256 queries to create two pattern-frequency vectors for two word pairs before it can compute the relational similarity.
In fact, LRA considers synonymous variants of the given word pairs.
For that reason, it requires even more search engine queries.
Methods that require numerous queries impose a heavy load on search engines.
Despite ef cient implementations, singular value decomposition of large matrices is time consuming.
In fact, LRA takes over 9 days to process the 374 SAT analogy questions [33].
This is problematic when computing of named entities, thesauri of related words are not usually available or are not complete, which becomes a problem when creating the additional word pairs required by LRA.
Veale [38] proposed a relational similarity measure based on the taxonomic similarity in WordNet.
The quality of a candidate analogy A:B::C:D (i.e. A to B as C to D) is evaluated through comparison of the paths in the WordNet, joining A to B and C to D. Relational similarity is de ned as the similarity between the A:B paths and C:D paths.
However, WordNet does not fully cover named entities such as personal names, organizations and locations, which becomes problematic when using this method to measure relational similarity between named entities.
Using a relational similarity measure, Turney [32] proposed an unsupervised learning algorithm to extract patterns that express implicit semantic relations from a corpus.
His method produces a ranked set of lexical patterns that unambiguously describes the relation between the two words in a given word pair.
Patterns are ranked according to their expected relational similarity (i.e. pertinence); they are computed using an algorithm similar to LRA.
To answer an SAT analogy question,  rst, ranked lists of patterns are generated for each of the six word pairs (one stem word pair and  ve choice word pairs).
Then each choice is evaluated by taking the intersection of its patterns with the stem s patterns.
The shared patterns are scored by the average of their rank in the stem s list and the choice s lists.
The algorithm picks the choice with the lowest scoring shared pattern as the correct answer.
This method reports an SAT score of 54.6%.
Relational similarity measures have been applied in natural language processing tasks such as generating word analogies [10], and classifying noun-modi er compounds based on the relation between the head and the modi er [33, 24, 9, 24].
Davidov and Rap-poport [10] proposed an unsupervised algorithm to discover general semantic relations that pertain between lexical items.
They represent a semantic relation with a cluster of patterns.
They use the pattern clusters to generate SAT-like word analogy questions for English and Russian languages.
The generated questions are then solved by human subjects.
They do not evaluate their method for relational similarity between named entities.
Relational similarity measures have been used to classify the relationships between the head and the modi er in noun-compounds [33, 24, 9].
For example, in the compound viral  u, the  u (head) is caused by a virus (modi er).
The Diverse dataset of Barker and Szpakowicz [1], which consists of 600 head-modi er pairs (noun-noun, adjective-noun and adverb-noun) is used as a benchmark dataset to evaluate relation classi cation of noun-compounds.
Each noun-modi er pair in this dataset is annotated with one of the following  ve relations: causal, temporal, spatial, participant, and quality.
Nakov and Hearst [24] proposed a linguistically motivated method that utilizes verbs, prepositions, and coordinate conjunctions that can help make explicit the hidden relations between the target nouns.
They report a classi cation accuracy of 40.5% on the Diverse dataset using a single nearest neighbor classi er.
Given two pairs of words (or named entities), (a,b) and (c,d), the problem of measuring the similarity of implicit semantic relations between the two pairs can be viewed as a two-stage process.
First, we must extract the semantic relations that pertain in each word pair.
We use a web search engine to retrieve the various contexts in which the two words in a word-pair cooccur.
We then ex-Google to acquire YouTube for $1.65 billion in stock.
Combination will create new opportunities for users and content owners everywhere...
Figure 1: A snippet returned for the query  Google * * * YouTube .
tract lexical patterns from the retrieved contexts to represent the various semantic relations that hold between two words.
However, not all patterns represent different semantic relations.
A single semantic relation can be expressed using more than one lexical pattern.
For example, both lexical patterns X acquired Y and Y was bought by X indicate an ACQUISITION relation between entities X and Y.
We present an ef cient clustering algorithm to identify the various lexical patterns that denote a particular semantic relation.
Second, we must compare the extracted semantic relations between the two word pairs to compute their relational similarity.
We model this problem as one of learning a distance metric between relationally similar and dissimilar word pairs.
Unlike previously proposed relational similarity measures, we do not assume semantic relations to be independent, and learn a non-Euclidean Maha-lanobis distance metric.
We must  rst identify the implicitly stated relations that hold between the two words in each word pair to compute the relational similarity between two given word pairs.
The context in which two words cooccur provides useful clues about the semantic relations that pertain between those words.
We propose the use of text snippets retrieved using a Web search engine as an approximation of the context of two words.
Snippets (also known as dynamic teasers) are brief summaries provided by most Web search engines along with the search results.
Typically, a snippet contains a window of text selected from a document that includes the queried words.
Snippets are useful for search because, most of the time, a user can read the snippet and decide whether a particular search result is relevant, without even opening the url.
Using snippets as contexts is also computationally ef cient because it obviates the need to download the source documents from the Web, which can be time consuming if a document is large.
A snippet for a query containing two words captures the local context in which they cooccur.
For example, consider the snippet shown in Figure 1, returned by Yahoo2 for the query  Google * * YouTube .
Here, the wildcard operator  *  matches one word or none in a document.
The snippet in Figure 1 is extracted from an online newspaper article about the acquisition of YouTube by Google.
To retrieve snippets for a word pair (A,B), we use the following seven types of queries:  A * B ,  B * A ,  A * * B ,  B * * A ,  A * * * B ,  B * * * A , and A B.
The queries containing the wildcard operator  *  returns snippets in which the two words, A and B appear within a window of speci ed length.
We designate such queries a wildcard queries.
We search for snippets in which the query words cooccur within a maximum window of three words (tokens).
This process is intended to approximate the local context of two words in a document.
The quotation marks around a query will ensure that the two words appear in the speci ed order (e.g.
A before B in snippets retrieved for the query  A * B ).
As a fallback in the case that all wildcard queries fail to return any snippets, we use the query A B (without wildcards or quotations) to retrieve snippets where A and B appear in any order.
2http://developer.yahoo.com/search/boss/ described above, we remove duplicate search results.
We consider two snippets to be duplicates if they contain the exact sequence of all words.
Duplicate snippets exist mainly for two reasons.
First, a web page can be mirrored in more than one location, and the default de-duplication mechanism of the search engine might fail to  lter out the duplicates.
Second, the queries we construct for a word pair are not independent.
For example, a query with two wildcards might return a snippet that can also be retrieved using a query with one wildcard.
However, we observed that the ranking of search results vary with the number of wildcards used.
A search engine usually returns only the top ranking results (in the case of Yahoo, only the top 1000 snippets can be downloaded).
We use multiple queries per word pair that induce different rankings, and aggregate search results to circumvent this limitation.
Lexical syntactic patterns have been used in various natural language processing tasks such as extracting hypernyms [17, 30], or meronyms [2], question answering [28], and paraphrase extraction [3].
Following these previous works, we present a shallow lexical pattern extraction algorithm to represent the semantic relations between two words.
The proposed method requires no language-dependent preprocessing such as part-of-speech tagging or dependency parsing, which can be both time consuming at Web scale, and likely to produce incorrect results because of the fragmented and ill-formed snippets.
The pattern extraction algorithm consists of the following three steps.
Step 1: Given a context S, retrieved for a word pair (A, B) according to the procedure described in section 3.2, we replace the two words A and B, respectively, with two variables X and Y .
Legal abbreviations such as Inc., Ltd., Corp., and titles such as Mr., Ms., Prof., Dr., Rev.
are considered as occurrences of the query terms.
For example, Google Inc. is considered as an occurrence of the entity Google.
We replace all numeric values by D, a marker for digits.
Punctuation marks are not removed.
Step 2: We generate all subsequences of the context S that satisfy all of the following conditions.
(i).
A subsequence must contain exactly one occurrence of each X and Y (i.e., exactly one X and one Y must exist in a subsequence).
(ii).
The maximum length of a subsequence is L words.
(iii).
A subsequence is allowed to have gaps.
However, we do not allow gaps of more than g number of words.
Moreover, the total length of all gaps in a subsequence should not exceed G words.
(iv).
We expand all negation contractions in a context.
For example, didn t is expanded to did not.
We do not skip the word not when generating subsequences.
For example, this condition ensures that from the snippet X is not a Y, we do not produce the subsequence X is a Y.
Step 3: We count the frequency of all generated subsequences for all word pairs in the dataset.
We select subsequences with frequency greater than N as lexical patterns to represent the semantic relations between words.
Our pattern extraction algorithm has four parameters (ca.
L, g, G and N).
We set the values of those parameters experimentally, as Figure 2: Distribution of four lexical patterns in word pairs.
explained later in section 4.
It is noteworthy that the proposed pattern extraction algorithm considers all the words in a snippet, and is not limited to extracting patterns only from the mid x (i.e., the portion of text in a snippet that appears between the queried words).
Moreover, the consideration of gaps enables us to capture relations between distant words in a snippet.
We use a modi ed version of the pre xspan algorithm [26] to generate subsequences.
The conditions in Step 2 are used to prune the search space, thereby reducing the number of generated subsequences in pre xspan.
For example, some patterns extracted form the snippet shown in Figure 1 are: X to acquire Y, X acquire Y, and X to acquire Y for.
Identifying Semantic Relations
 A semantic relation can be expressed using more than one pattern.
For example, consider the two distinct patterns, X acquired Y, and X completed the acquisition of Y.
Both these patterns indicate that there exists an acquisition relation between X and Y.
It is important to know whether any correspondence pertains between the sets of patterns extracted for each word pair when we compute the relational similarity between two word pairs.
We can expect a high relational similarity if there are many related patterns between two word pairs.
We use the distributional hypothesis [16] to  nd semantically related lexical patterns.
The distributional hypothesis states that words that occur in the same context have similar meanings.
The distributional hypothesis has been used in various related tasks, such as identifying related words[18], discovering inference rules[19], and extracting paraphrases[3].
If two lexical patterns are similarly distributed over a set of word pairs (i.e. occurs with the same set of word pairs), then from the distributional hypothesis it follows that the two patterns must be similar.
For example, consider the distributions shown in Figure 2 for four lexical patterns: X buys Y, X acquires Y, Y CEO X, and Y chief executive X, over a set of 100 word pairs.
Each distribution is normalized such that the sum of frequencies over all word pairs equals one.
Figure 2 shows that the distributions of patterns Y CEO X, and Y chief executive X have a high overlap (i.e., cosine similarity of 0.969).
Similarly, the distributions of patterns X buys Y, and X acquires Y show a high overlap (i.e. cosine similarity of 0.853).
However, almost no overlap is apparent between other combinations of distributions.
Consequently, to recognize semantically related patterns, we cluster lexical patterns using the similarity of their distributions over word pairs.
We designate p, the word-pair frequency vector of pattern p.
It is analogous to the document frequency vector of a word, as used in information retrieval.
The value of the element corresponding to a word pair (ai, bi) in p, is the frequency, f (ai, bi, p), that the pattern p occurs with the word pair (ai, bi).
As demonstrated later in the experiments of this study, the proposed pattern extraction algorithm typically extracts numerous lexical patterns (more than
 among all patterns are not feasible when the patterns are numerous.
Next, we present a sequential clustering algorithm to ef ciently cluster the extracted patterns.
(cid:80) Given a set P of patterns and a clustering similarity threshold  , Algorithm 1 returns clusters (of patterns) that express similar semantic relations.
First, in Algorithm 1, the function SORT sorts the patterns into descending order of their total occurrences in all word pairs.
The total occurrence of a pattern p is the sum of frequencies over all word pairs (i.e., i f (ai, bi, p)).
After sorting, the most common patterns appear at the beginning in P , whereas rare patterns (i.e., patterns that occur with only few word pairs) get shifted to the end.
Next, in line 2, we initialize the set of clusters, C, to the empty set.
The outer for-loop (starting at line 3), repeatedly takes a pattern pi from the ordered set P , and in the inner for-loop (starting at line 6),  nds the cluster, c  (  C) that is most similar to pi.
First, we represent a cluster by the centroid of all word pair frequency vectors corresponding to the patterns in that cluster to compute the similarity between a pattern and a cluster.
Next, we compute the cosine similarity between the cluster centroid (cj), and the word pair frequency vector of the pattern (pi).
If the similarity between a pattern pi, and its most similar cluster, c , is greater than the threshold  , we append pi to c  (line 14).
We use the operator   to denote the vector addition between c  and pi.
Then we form a new cluster {pi} and append it to the set of clusters, C, if pi is not similar to any of the existing clusters beyond the threshold  .
The only parameter in Algorithm 1, the similarity threshold,  , ranges in [0, 1].
It decides the purity of the formed clusters.
Setting   to a high value ensures that the patterns in each cluster are highly similar.
However, high   values also yield numerous clusters (increased model complexity).
In section 4, we investigate, experimentally, the effect of   on the overall performance of the proposed relational similarity measure.
The computational time complexity of Algorithm 1 is O(n|C|), where n is the number of patterns to be clustered and |C| is the number of clusters.
Usually, n is much larger than |C| (i.e. n (cid:192) |C|).
Therefore, the overall time complexity of Algorithm 1 linearly scales with the number of patterns.
The sequential nature of the algorithm avoids pairwise comparisons among all patterns.
Moreover, sorting the patterns by their total word-pair frequency prior to clustering ensures that the  nal set of clusters contains the most common relations in the dataset.
Evidence from psychological experiments suggest that similarity can be context-dependent and even asymmetric [36, 22].
Human subjects have reportedly assigned different similarity ratings to word pairs when the two words were presented in reverse order.
However, experimental results investigating the effects of asymmetry, report that the average difference in ratings for a word pair is less than 5 percent [22].
Consequently, we assume relational similarity to be symmetric and limit ourselves to symmetric similarity measures.
This assumption is in line with previous work on relational similarity described in section 2.
We model the problem of measuring relational similarity be-c    null for cluster cj   C do sim   cosine(pi, cj) if sim > max then Algorithm 1 Sequential pattern clustering algorithm.
Input: patterns P = {p1, .
.
.
, pn}, threshold   Output: clusters C




 4: max    











 end if
 18: end for
 end if end for if max >   then c    c    pi C   C   {pi} max   sim c    cj else tween word pairs as one of learning a Mahalanobis distance metric from a given set of relationally similar and dissimilar word pairs.
Given two points xi, xj, the (squared) Mahalanobis distance between them, dA(xi, xj), is parametrized using a positive de nite matrix A as follows, dA(xi, xj) = (xi   xj)T A(xi   xj).
(1) The Mahalanobis distance is a straightforward extension of the standard Euclidean distance.
In fact, if we let A be the identity matrix, then the Mahalanobis distance reduces to the Euclidean distance.
The motivation behind using Mahalanobis distance to measure relational similarity is twofold.
First, Mahalanobis distance can be learned from a few data points, and ef cient algorithms that can scale well to high-dimensional feature spaces are known [13, 12].
Second, unlike Euclidean distance, Mahalanobis distance does not assume that features are independent.
This is particularly important for relational similarity measures because semantic relations are not always independent.
A posterior analysis of the Mahalanobis matrix (A) can provide useful information related to the correlation between semantic relations.
p cj (cid:80) To learn a Mahalanobis distance metric, we  rst represent each word pair (ai, bi) as a feature vector xi.
The j-th element of xi is the total frequency of the word pair (ai, bi) in the j-th cluster; it is given as f (ai, bi, p).
Here, p is a pattern in the cluster cj, and f (ai, bi, p) is the number of times that the word pair (ai, bi) appears with the pattern p. We L2 normalize all feature vectors.
Given a set of relationally similar pairs S and dissimilar pairs D, the problem of learning a relational similarity measure becomes one of  nding a positive de nite matrix A, such that dA(xi, xj)   u for all (i, j)   S, and dA(xi, xj)   l for all (i, j)   D. Here u and l respectively signify upper and lower bounds of the decision threshold, and are set experimentally as described later in section 4.
Intuitively, word pairs that share identical semantic relations must have a higher relational similarity.
We set an additional constraint that the learned Mahalanobis matrix A must be  close  to the identity matrix I to incorporate this prior knowledge in the learning problem at hand.
This keeps the Mahalanobis distance similar to the Euclidean distance; it also helps to prevent over tting of the approach proposed by Davis et al. [13] to optimize the matrix A.
We observe the fact that there exists a simple bijection (up to a scaling function) between the set of Mahalanobis distances and the set of equal mean multivariate Gaussian distributions to quantify the  closeness  between A and I.
Assuming the equal mean to be  , for a Mahalanobis distance parameterized by A, the corresponding Gaussian is given by p(x; A) = 1
 Z is a normalizing constant and A 1 is the covariance of the distribution.
Then, the closeness between A and I is measurable using the Kullback-Liebler (KL) divergence between their corresponding multivariate Gaussians: Z exp(  1 (cid:90) KL(p(x; I) (cid:107) p(x; A)) = p(x; I) p(x; A) Using Formula 2, the learning problem can be stated as p(x; I) log dx.
KL(p(x; I) (cid:107) p(x; A)) (i, j)   S (i, j)   D.
min dA(xi, xj)   u dA(xi, xj)   l s.t Algorithm 2 Information-theoretic metric learning.
Input: X, (d  n matrix); S, set of similar pairs; D, set of dissimilar pairs; u, l: distance thresholds; I, identity matrix;  , slack parameter; c, constraint index function (cid:179) Output: A: Mahalanobis matrix

 3: repeat







 12: until convergence
 Pick a constraint (i, j)   S or (i, j)   D p   (xi   xj)T A(xi   xj)     1 if (i, j)   S,  1 otherwise     min p          /(1    c(i,j))  c(i,j)    c(i,j)/(  +  c(i,j))  ij    ij     (cid:180)(cid:180)  ij,  
 (cid:179)  c(i,j)
 (2) (3) The integral form of the KL divergence presented in Formula 2 is dif cult to numerically optimize directly.
However, it has been shown that the KL divergence between two multivariate Gaussians can be expressed as the convex combination of a Mahalanobis distance between mean vectors and the LogDet divergence between the covariance matrices [11].
Therefore, assuming that the means of the Gaussians are equal, we have KL(p(x; I) (cid:107) p(x; A)) = (4) Here, Dld(A, B) is the LogDet divergence of n n positive-de nite matrices A, B.
It is given as Dld(A, I).
Dld(A, B) = tr(AB  1)   log det(AB  1)   n.
(5) Finally, we incorporate slack variables into the formulation 3 to guarantee the existence of a feasible solution for A, and pose the following optimization problem: s.t.
Dld(A, I) +  Dld(diag( ), diag( 0)) min A(cid:186)0,  tr(A(xi   xj)(xi   xj)T )    c(i,j) tr(A(xi   xj)(xi   xj)T )    c(i,j) (i, j)   S (i, j)   D, (6) where c(i, j) is the index of the (i, j)-th constraint,   is a vector of slack variables, initialized to  0 (components of  0 are initialized to u and v, respectively, for similar and dissimilar constraints), and   is the parameter that controls the tradeoff between satisfying the constraints and minimizing Dld(A, I).
Algorithm 2 solves the optimization problem 6 by repeatedly projecting the current solution onto a single constraint.
Unlike Latent Relational Analysis [33], Algorithm 2 requires no eigen-decomposition, which is time consuming for large matrices.
In Algorithm 2, a single iteration of looping through all constraints costs O(cd2), where c signi es the number of constraints, and d represents the dimensionality of feature vectors.
Once we obtain a Mahalanobis matrix A from Algorithm 2, we can use Formula 1 to compute relational distances.
Distance and similarity are inversely related.
Therefore, it is possible to use Formula 1 directly to compare word pairs.
However, if one wants to convert distance values ranging in [0, + ) to similarity scores ranging in [0, 1], it can be done using sigmoid functions [27].
We use two different datasets to evaluate the proposed relational similarity measure in two tasks: classifying semantic relations between named entities, and solving SAT word-analogy questions.
Solving SAT word analogy questions was  rst proposed by Turney et al. [35] as a benchmark to evaluate relational similarity measures.
An SAT analogy question consists of a stem word pair that acts as the question, and  ve choice word pairs.
A relational similarity measure under evaluation will compare the stem word pair with each choice word pair separately, and select the choice word pair with the highest relational similarity as the correct answer.
The dataset contains 374 questions.
A limitation frequently associated with the SAT dataset is that it contains no named entities or relations that Web users are typically interested in, such as relations pertaining to companies or people.
Consequently, in addition to the SAT dataset, we created a dataset3 containing only entity pairs to evaluate the proposed relational similarity measure.
Hereinafter, we designate this as the ENT dataset.
The ENT dataset contains 100 instances (i.e. named-entity pairs) of the following  ve relation types.
ACQUIRER-ACQUIREE This relation holds between pairs of company names (A,B), where the company B (acquiree) is acquired by the company A (acquirer).
We only consider acquisitions that have already completed.
PERSON-BIRTHPLACE This relation holds between pairs (A,B), where A is the name of a person, and B is the location (place) where A was born.
We consider city names and countries as locations.
CEO-COMPANY This relation holds between pairs (A,B), where A is the chief executive of cer (CEO) of a company B.
We consider both current as well as past CEOs of companies.
COMPANY-HEADQUARTERS This relation holds between pairs A,B, where company A s headquarters is located in a place B.
We select names of cities as B.
PERSON-FIELD This relation holds between pairs (A,B), where a person A is an expert or is known for his or her abilities in a 3http://www.miv.t.u-tokyo.ac.jp/danushka/reldata.zip




 Total contexts Table 1: Overview of the relational similarity dataset.
Examples (20 in all for each relation type) (Google, YouTube), (Adobe Systems, Macromedia), (Yahoo, Inktomi) (Franz Kafka, Prague), (Charlie Chaplin, London), (Marie Antoinette, Vienna) (Terry Semel, Yahoo), (Eric Scmidt, Google), (Steve Jobs, Apple) (Microsoft, Redmond), (Yahoo, Sunnyvale), (Google, Mountain View) (Albert Einstein, Physics), (Roger Federer, Tennis), (Shane Warne, Cricket)




  eld B.
Instances of this relation contain scientists and their  eld of expertise, athletes and the sports they are associated with, and artists and the genre in which they perform.
We selected the relation types described above because previous studies of relation detection on the Web have frequently used those relations in evaluations [6].
We manually selected 20 instances for each of the  ve relation types.
Instances were selected from various information sources such as Wikipedia4, online newspapers, and company reviews5.
For word pairs in SAT and ENT datasets using the YahooBOSS API6, we download snippets as described in section 3.2.
For each relation type in ENT dataset, in Table 1, we show some instances and the total number of contexts.
We randomly split the ENT dataset into  ve equal-sized partitions to conduct  ve-fold cross validation.
Four partitions are used to extract patterns, clustering and training.
The remaining partition is used for testing.
For ENT data, positive training instances are generated by coupling word pairs that belong to the same relation type (i.e., 5  (20  19)/2 = 950 instances), and an equal number of negative training instances are generated by randomly coupling word pairs that belong to different relation types.
We run the pattern extraction algorithm described in section 3.3 on the contexts in our dataset to extract lexical patterns.
Experimentally, we set the values for the various parameters in the pattern extraction algorithm: L = 5, g = 2, and G = 4.
The proposed pattern extraction algorithm identi es numerous lexical patterns.
For example, for ENT training data, the algorithm extracts 473910 unique patterns.
However, of those, only 148655 (31.36% of the total) occur more than twice.
Patterns that only occur once contain misspellings or badly formatted text.
We only select the patterns that occur at least twice to  lter-out this noise.
The remaining experiments described in this paper are performed using those patterns.
We  rst compute the distribution of Euclidean distances over the training data to determine the values for distance thresholds u and l in Algorithm 2.
We then respectively select the 5-th and 95-th percentiles of distance distribution as u (1.96) and l (0.22).
Slack parameter   is set to 0.01 experimentally.
We evaluate the proposed relational similarity measure in a relation classi cation task.
Given an entity pair, the goal is to select a relation out of the  ve relation types in the ENT dataset that describes the relation between the two entities.
This is a multi-class classi cation problem.
We use k-nearest neighbor classi cation to assign a relation to a given entity pair.
Speci cally, given an entity pair (a, b), for which a relation R holds, we compute the relational similarity between (a, b) and the remaining entity pairs in the dataset.
We then sort the word pairs in the descending order of relational similarity with (a, b), and select the most similar k en-4http://wikipedia.org/ 5http://www.forbes.com/ 6http://developer.yahoo.com/search/boss/ tity pairs.
We then  nd the relation that is given to most of those k entity pairs and assign this relation to (a, b).
Ties are resolved randomly.
This procedure is repeated for each entity pair in the ENT dataset.
Overall accuracy of relation classi cation is computed as Accuracy = No.
of correctly classi ed entity pairs Total no.
of entity pairs .
(7) A good relational similarity measure must assign higher similarity scores to word pairs with similar implicit relations.
However, the classi cation accuracy does not evaluate the relative rankings of similarity scores.
We use average precision [29] to evaluate the top k most similar entity pairs to a given entity pair.
Average precision integrates the precision at different ranks.
It is frequently used as an evaluation measure in retrieval tasks.
The average precision for a particular relation type R is de ned as (cid:80)k r=1 Pre(r)   Rel(r) No of relevant word pairs .
AveragePrecision = (8) Here, Rel(r) is a binary valued function that returns 1 if the entity pair at rank r has the same relation (i.e., R) as in (a, b).
Otherwise, it returns zero.
Furthermore, Pre(r) is the precision at rank r, which is given as Pre(r) = no.
of entity pairs with relation R in top r pairs r .
(9) The number of relevant entity pairs is 20 for all  ve relation types in our dataset.
We consider the 10 most similar entity pairs (i.e., k = 10) for nearest neighbor classi cation.
The average precision is computed for those top 10 entity pairs.
We use ENT training data to investigate the effect of clustering threshold   (Algorithm 1) on relation classi cation performance.
Results are summarized in Figure 3.
Overall, in Figure 3, we see that performance increases with  .
This is because higher values of   result in highly similar pattern clusters that represent speci c semantic relations.
However, a slight drop of performance can be observed for high   values, because it produces a large number of pattern clusters (i.e., increased model complexity), which results in over  tting the data.
The best performance is reported for   =
 value of theta.
In Table 2, we show the top 10 clusters with the largest number of lexical patterns.
The number of patterns in each cluster is shown within brackets in the  rst column.
For each cluster in Table 2, we show the top four patterns that occur in the greatest number of entity pairs.
For explanatory purposes, we label the clusters with the  ve relation types as clusters 1 and 4 (acquirer-acquiree); clusters
 and 10 (company-headquarters); cluster 9 (person-birthplace).
Table 2 clari es that patterns representing various semantic relations are extracted by the proposed pattern extraction algorithm.
Moreover, we see that each cluster contains different lexical patterns that express a speci c semantic relation.
We can also  nd multiple clusters even among the top few clusters shown in Table 2 that represent X acquires Y Y legend X was Y champion X cluster 1 (2868) cluster 2 (2711) cluster 3 (2615) cluster 4 (2008) cluster 5 (2002) cluster 6 (1364) X revolutionized Y X and modern Y cluster 7 (845) cluster 8 (280) cluster 9 (144) cluster 10 (49) X headquarters in Y X s childhood in Y X headquarters in Y X to buy Y Y founder X X has acquired Y X s championship Y world Y champion X X and Y con rmed Y founder and CEO X X professor of Y X of ces in Y X s birth in Y X s Y headquarters genius: X and modern Y Y in DDDD, X was past X of ces in Y X s Y acquisition Y star X was X teaches Y X buy Y is X, founder of Y in Y since X Y born X Y - based X X, acquisition, Y X autographed Y ball X s greatest Y Y purchase to boost X X says Y on Y by X ago, X revolutionized Y the X conference in Y Y born X introduced the X works with the Y Y goes X Y star X robbed Y players like X X is buying Y X talks up Y X s contribution to Y X s lectures on Y X headquarters in Y on sobbing X left Y to Y of ce of X Table 3: Performance of the proposed method and baselines.
Relation acquirer-acquiree
 comp.-headquarters
 person eld
 CEO-comp.
person-birthplace
 Overall Average Precision
 Classi cation Accuracy
























 Figure 3: Performance of the proposed method against the clustering threshold ( ) a particular relation type.
For example, cluster 1 and 4 both represent an acquirer-acquiree relation, although the patterns in cluster 1 are derived from the verb acquire, whereas the patterns in cluster
 certain level of correlation among such clusters, which justi es the use of the Mahalanobis distance instead of Euclidean distance when computing relational similarity.
We compare the proposed relational similarity measure (PROP) to the Euclidean distance baseline (EUC), vector space model-based relational similarity [35] (VSM) and the state-of -the-art Latent Relational Analysis [33] (LRA).
Next, we explain each of those relational similarity measures in detail.
VSM: This is the vector space model-based approach proposed by Turney et al. [35].
First, each word pair is represented using a vector of pattern frequencies.
Then the relational similarity between two word pairs is computed as the cosine of the angle between the two vectors representing the two word pairs.
This approach is equivalent to computing relational similarity using Formula 1, if we de ne feature vectors as pattern frequency vectors and take the identity matrix as A.
represent word pairs and the columns represent lexical patterns.
An element of the matrix corresponds to the frequency of occurrence of a word pair in a particular lexical pattern.
Next, singular value decomposition (SVD) is performed on this matrix to reduce the number of columns.
Finally, the relational similarity between two word pairs is computed as the cosine of the angle between the corresponding row vectors.
We re-implemented LRA as described in the original paper.
However, we do not use related word thesauri to  nd additional word pairs, because such resources are not available for named entities.
Following, Turney s proposal, we used the most frequent 4000 lexical patterns in the matrix and reduced the number of columns to 300 via SVD (i.e., eigenvectors corresponding to the largest 300 eigenvalues are used to approximate the matrix).
We used Scienti c Python s SVD library7 for the computation of SVD.
LRA is the current state-of-the-art relational similarity measure.
EUC: We set A in Formula 1 to the identity matrix and compute relation similarity using pattern clusters.
This is equivalent to computing relational similarity between two word pairs as the Euclidean distance between the corresponding two feature vectors created using pattern clusters.
This baseline is a cut-down version of the proposed method, where all clusters are assumed to be independent.
This baseline is expected to show the decrease in the performance when we do not use Mahalanobis distance learning.
PROP: This is the proposed relational similarity measure, de ned in Formula 1.
For both EUC and PROP, we used the same set of clusters.
Therefore, any difference in performance can be attributable to using the Mahalanobis distance when computing relational similarity.
We used the 10447 clusters derived by setting the clustering threshold   to the value 0.905.
LRA: This is the Latent Relational Analysis (LRA) proposed by Turney [33].
First, a matrix is created, in which the rows 7www.scipy.org
 Algorithm Random guessing Jiang & Conrath [33] Lin [33] Leacock & Chodrow [33] Hirst & St.-Onge [33] Resnik [33]

 Algorithm score










 score







 The four methods described above presented for comparison in Table 3.
For each relation type, Table 3 shows the average precision scores computed using Formula 8.
Moreover, the overall performance is reported using both average precision and classi cation accuracy.
The proposed method (PROP) reports the highest overall average precision (0.7403) in Table 3.
In fact, PROP has the best average precision scores for four out of the  ve relation types.
Analysis of variance (ANOVA) reveals that the average precision scores in Table 3 are statistically signi cant.
Moreover, paired t-tests conducted between the proposed method (PROP) and each of the remaining three methods in Table 3, reveal that the improvement shown by PROP over VSM, EUC, and LRA is statistically signi cant (  = 0.01).
PROP has the highest classi cation accuracy (0.93), followed by EUC, LRA, and VSM, in that order.
It is noteworthy that the EUC baseline that does not consider inter-cluster correlation performs better than the VSM method.
This result shows that clustering similar patterns prior to computing relational similarity indeed improves performance.
Among the  ve relation types compared in Table 3, high average precision scores are reported for the following three relation types: acquirer-acquiree, company-headquarters, and CEO-company.
Lowest performance is reported for the person-birthplace relation.
A closer look into the snippets extracted for the person-birthplace pairs revealed that there were many snippets that convey information related to places that people associate with places other than their place of birth.
For example, regarding actors, the locations where they gave their  rst performance are incorrectly extracted as contexts for the person-birthplace relation.
Following the previous work on relational similarity measures, we use the proposed method to solve SAT word-analogy questions.
We split the SAT dataset (374 questions) randomly into  ve partitions and select four partitions as training data and the remainder as test data.
The procedure is repeated with different partitions.
Then the experimental results are reported for  ve-fold cross-validation.
For all word pairs in the SAT dataset, we download contexts from the Web (section 3.2), and extract lexical patterns (section 3.3).
We then cluster the extracted patterns using Algorithm 1.
Next, for each SAT question in the training dataset, we create a positive training instance by coupling the stem word pair with the correct answer.
Similarly, negative training instances are created by coupling the stem word pair with incorrect answers.
We then use Algorithm 2 to learn a Mahalanobis distance matrix from the training data.
To solve an SAT question in the test dataset, we compute the relational similarity (alternatively distance) between the stem word pair and each choice word pairs using Formula 1, and select the choice with the highest relational similarity (lowest distance) as the correct answer.
The SAT score is computed as the percentage of correctly answered questions to the total questions in the dataset.
As shown in Table 4 the proposed method reports an SAT score of 51.1%; it is ranked 3rd among 16 systems.
The average SAT score reported by high-school students is 57%.
Randomly guessing one out of  ve choices gives the lower bound of 20%.
The proposed method outperforms WordNet-based relational similarity measures (Veale [38]) as well as various corpus-based approaches.
The two systems that perform better than the proposed method (i.e., Pertinence and LRA) use a synonym dictionary to  nd similar word pairs.
However, the proposed method requires no external resources such as synonym dictionaries to compute relational similarity.
In fact, synonym dictionaries for named entities are either not available or incomplete.
Moreover, as stated in the original paper, LRA takes over 9 days to answer the 374 questions in the SAT dataset, whereas the proposed method requires less than 6 hours to answer the same set of questions.
The gain in processing time can be attributable to two factors.
First, unlike LRA and Pertinence, the proposed method requires no singular value decomposition (SVD).
Performing SVD on large matrices is time consuming.
For example, in LRA the data matrix consists of 2176 word pairs (rows) and
 method requires much fewer search engine queries.
In LRA, to compute the feature vector for a word pair we must issue a query for each pattern extracted.
For example, with 4000 patterns, LRA requires at least 8000 (4000 2 word pairs) search engine queries to compute the relational similarity between two word-pairs.
On the other hand, the proposed method searches for patterns only within the snippets downloaded for a word pair.
Because multiple snippets can be downloaded by issuing a single query, the proposed method requires only two search engine queries to compute the relational similarity between two word pairs.
Moreover, the number of search engine queries is independent of the number of patterns.
Therefore, the proposed method is more appropriate in an online setting (e.g., web search), in which we must quickly compute relational similarity for unseen word pairs.
The de nition of relational similarity, as given in Formula 1 can be viewed as a general framework into which all existing relational similarity measures can be integrated.
The existing approaches differ in their de nition of matrix A.
For example, in VSM, A is the identity matrix, and in LRA it is computed via SVD.
The proposed method learns a Mahalanobis distance matrix as A using training data.
The task of designing relational similarity measures can be modeled as searching for a matrix A that best re ects the notion of relational similarity possessed by humans.
We proposed a method to compute the similarity between implicit semantic relations in two word pairs.
Given two word pairs, the proposed relational similarity measure  rst  nds contexts in which the two words in each word pair cooccur on the Web.
We used text snippets returned by a Web search engine as contexts, and proposed a shallow lexical pattern extraction algorithm to represent the various semantic relations that exist between two words.
The proposed pattern extraction algorithm requires no language speci c preprocessing techniques such as part-of-speech taggers or dependency parsers.
We then cluster the extracted patterns to identify the different lexical patterns that convey a particular semantic relation.
We proposed a sequential clustering algorithm that scales linearly with the number of patterns to cluster a larger number of patterns ef ciently.
We create a feature vector using the formed pattern clusters, and compute the relational similarity between two word pairs as the Mahalanobis distance between the two feature vectors.
Experimental results on a relation classi cation task and SAT word-analogy task, showed that the proposed method markedly outperforms various baselines and reduces the processing time of previously proposed latent relational analysis.
In future studies, we trieve a set of word pairs for a given implicit relation from the Web.
