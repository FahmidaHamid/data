[1]  Aula, A. et al. How does search behaviour change as search

becomes more difficult? In Proc. 28th international conference
on Human factors in computing systems – HCI (Atlanta, GA,
USA 2010), 35-44.

[2]  Doan, A., Ramakrishnan R., and Halevy, A. Crowdsourcing
Systems on the World-Wide Web, Communications of the
ACM, April 2011.

[3]  Yan, T. and Kumar, V. and Ganesan, D. CrowdSearch:

exploiting crowds for accurate real-time image search. Proc. 8th
Int. Conference on Mobile Systems, Applications, and Services
– MOBISYS  (S. Francisco, CA, 2010), 77-90.

[4]  Franklin M.J. et al. CrowdDB: answering queries with

crowdsourcing. In Proceedings of the 2011 international
conference on Management of data (SIGMOD '11). ACM, New
York, NY, USA, 61-72.

[5]  Marcus, A. et al. Crowdsourced Databases: Query Processing

with People. Conference on Innovative Data Systems Research.
2011 (Asilomar, CA, 2011), 211-214

[6]  Parameswaran, A. and Polyzotis, N. Answering Queries using
Databases, Humans and Algorithms. Conference on Innovative
Data Systems Research 2011 (Asilomar, CA, 2011), 160-166.

[7]  Baeza-Yates, R. and Raghavan, P. Next Generation Web Search.
Search Computing Challenges and Directions, Springer-Verlag,
LNCS 5950, 2010, 11-23.

[8]  Marchionini, G. Exploratory Search: from Finding to

Understanding. Communications of the ACM, 2006. 41-46.

[9]  Bozzon, A., Brambilla, M., Ceri, S., Fraternali, P. Liquid Query:

Multi-Domain Exploratory Search on the Web. WWW 2010
(Raleigh, USA, 2010). ACM, New York, NY, USA, 161-170.

[10]  Bozzon, A. et al. Exploratory Search in Multi-Domain

Information Spaces with Liquid Query. Proc. WWW 2011 -
Demo (Hyderabad, India, 2011), ACM, New York, NY, USA,
189-192.

[11]  Marcus A., Wu E., Karger D., Madden S., and Miller R.

Humanpowered Sorts and Joins, PVLDB 5(1), 2011, 13-24.
[12]  Kumar, A. and Lease, M. Modeling Annotator Accuracies for

Supervised Learning, Proc. Crowdsourcing for Search and Data
Mining Workshop – CSDM (Hong-Kong, China, 2011).

[13]  Bernstein M.S. et al. Soylent: a word processor with a crowd

inside. In Proceedings of the 23nd annual ACM symposium on
User interface software and technology. ACM, New York, NY,
USA, 313-322.

[14]  Kulkarni, A. P., Can, M., and Hartmann, B. Turkomatic:

Automatic Recursive Task and Workflow Design for
Mechanical Turk. Proc. Extended Abstracts on Human Factors
in Computing Systems - CHI EA (Vancouver, CA, 2011), 2053-
2058.

[15]  Mason, W. A., and Watts, D. J. Financial Incentives and the

"Performance of Crowds". KDD Workshop on Human
Computation (Paris, France, 2009), 77-85.

[16]  Ariely, D. et al. Large Stakes and Big Mistakes, Review of

Economic Studies, 76(2), 2009, 451-469.

[17]  Chilton et al. Task search in a human computation market. ACM

SIGKDD Workshop on Human Computation (HCOMP '10).
ACM, New York, NY, USA, 1-9.

[18]  Morris, M. R. A survey of Collaborative Web Search practices.

Proc. SIGCHI Conference on Human Factors in Computing
Systems, (Florence, 2008) 1657–166.

WWW 2012 – Session: CrowdsourcingApril 16–20, 2012, Lyon, France1018
