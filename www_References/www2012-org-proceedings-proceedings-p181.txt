[1] D. Agarwal, B.-C. Chen, and B. Pang. Personalized

recommendation of user comments via factor models. In
EMNLP, 2011.

[2] M. Bilgic, L. Mihalkova, and L. Getoor. Active learning for

networked data. In ICML, 2010.

[3] A. Blum and S. Chawla. Learning from labeled and

unlabeled data using graph mincuts. In ICML, 2001.

[4] S. Brin and L. Page. The anatomy of a large-scale

hypertextual web search engine. Computer Networks,
30(1-7):107–117, 1998.

[5] N. Cesa-Bianchi, C. Gentile, F. Vitale, and G. Zappella.

Active learning on trees and graphs. In COLT, 2010.

[6] B.-C. Chen, J. Guo, B. Tseng, and J. Yang. User reputation

in a comment rating environment. In KDD, 2011.

[7] N. Diakopoulos and M. Naaman. Topicality, time and

sentiment in online news comments. In CHI EA ’11, 2011.
[8] N. Diakopoulos and M. Naaman. Towards quality discourse

in online news comments. In CSCW, 2011.

[9] A. Guillory and J. Bilmes. Label Selection on Graphs. In

NIPS. 2009.

[10] C.-F. Hsu, E. Khabiri, and J. Caverlee. Ranking comments

on the social web. In ICCSE, 2009.

Figure 3: Ratings histogram obtained for the algo-
rithm of [17].

scale (0 to 500), and was very sensitive to the initial choice
of seed values. This does not allow us to make a meaning-
ful comparison with our algorithm and the baseline mean
rating.

8. RELATED WORK

Comment quality in social media has been studied in great
detail (see [8] and references therein). There are diﬀerent as-
pects of quality [11, 24] such as relevance, validity, ﬂaming,
etc. It is important to hide or delete low quality content.
Since the volume of comments on the internet is huge, utiliz-
ing the knowledge of crowds appears to be a viable option.
Techniques to analyze and improve the quality of content
through moderation have been studied in [14, 15].

Going beyond moderation, there have been several re-
search eﬀorts aimed at ranking comments.
[10] proposes
to rank comments in the absence of explicit positive and
negative ratings. It uses a machine learning based approach
to train a regression model with features based on content,
message visibility, and user reputation.
[22] investigates
comment usefulness, another related quality measure, on
YouTube. It employs bag-of-word features to train classiﬁ-
cation models for deciding the usefulness of new comments.
User votes are not used as features, instead they are used
for deﬁning training data, i.e., comments that receive many
positive votes are assumed to be useful. Note that this prob-
lem is complementary to ours. Because of bias, comments
with many positive votes may still be abusive – our bias cor-
rection schemes help to address this. In [1], generalizations
of matrix factorization that leverage both features and past
ratings are used to recommend comments to users.

Author reputation in a comment rating environment is
studied in [6]. User bias is deﬁned as the propensity to
give excessive thumbs-ups/thumbs-downs, and is factored
in while computing reputation. As mentioned earlier in Sec-
tion 3.1, this deﬁnition of bias diﬀers from ours. Similar
deﬁnitions of bias as the average deviation from the unbi-
ased rating have been considered in [13, 16, 17]. Thus, if a
user gives adversarial ratings such as high ratings to poor
comments and low ratings to good comments, then it is pos-
sible to keep his/her bias artiﬁcially close to zero. However,
this is not possible with our formulation. Our work is also
related to the work on modeling trustworthiness of data [25,
26].

In our work, we require labels for a few comments. Our
algorithm combines these labeled and unlabeled comments
together to compute user bias and unbiased ratings for unla-
beled comments. Such an approach falls under semi-supervised
learning where both labeled and unlabeled data are utilized
together to come up with better models. Semi-supervised

WWW 2012 – Session: Fraud and Bias in User RatingsApril 16–20, 2012, Lyon, France189[11] S. Kiesler, J. Siegel, and W. McGuire, Timothy.

Computer-supported cooperative work: a book of readings.
chapter Social psychological aspects of computer-mediated
communication (Reprint), pages 657–682. Morgan
Kaufmann Publishers Inc., 1988.

[12] J. M. Kleinberg. Authoritative sources in a hyperlinked

environment. J. ACM, 46(5):604–632, 1999.

[13] Y. Koren. Factorization meets the neighborhood: a

multifaceted collaborative ﬁltering model. In KDD, 2008.

[14] C. Lampe and P. Resnick. Slash(dot) and burn: distributed

moderation in a large online conversation space. In CHI,
2004.

[15] C. A. Lampe, E. Johnston, and P. Resnick. Follow the
reader: ﬁltering comments on slashdot. In CHI, 2007.

[16] H. W. Lauw, E.-P. Lim, and K. Wang. Bias and

controversy: beyond the statistical deviation. In KDD,
2006.

[17] H. W. Lauw, E.-P. Lim, and K. Wang. Summarizing review

scores of ”unequal” reviewers. In SDM, 2007.

[18] S. A. Macskassy. Using graph-based metrics with empirical
risk minimization to speed up active learning on networked
data. In KDD, 2009.

[19] K. Purcell, L. Purcell, A. Mitchell, T. Rosenstiel, and

K. Olmstead. Understanding the participatory news
consumer. Pew Internet and American Life Project, 2010.
[20] N. Roy and A. McCallum. Toward optimal active learning
through sampling estimation of error reduction. In ICML,
2001.

[21] B. Settles. Active learning literature survey. Computer

Sciences Technical Report 1648, University of
Wisconsin–Madison, 2009.

[22] S. Siersdorfer, S. Chelaru, W. Nejdl, and J. S. Pedro. How

useful are your comments?: analyzing and predicting
youtube comments and comment ratings. In WWW, 2010.

[23] G. W. Stewart. Matrix Algorithms: Volume 1, Basic

Decompositions. Society for Industrial Mathematics, 1998.
[24] D. M. Strong, Y. W. Lee, and R. Y. Wang. Data quality in

context. Commun. ACM, 40:103–110, May 1997.

[25] V. G. V. Vydiswaran, C. Zhai, and D. Roth. Content-driven

trust propagation framework. In KDD, 2011.

[26] X. Yin, J. Han, and P. S. Yu. Truth discovery with multiple

conﬂicting information providers on the web. IEEE Trans.
Knowl. Data Eng., 20(6):796–808, 2008.

[27] A. X. Zheng, A. Y. Ng, and M. I. Jordan. Stable algorithms

for link analysis. In SIGIR, 2001.

[28] X. Zhu, Z. Ghahramani, and J. D. Laﬀerty.

Semi-supervised learning using gaussian ﬁelds and
harmonic functions. In ICML, 2003.

[29] X. Zhu, J. Laﬀerty, and Z. Ghahramani. Combining active
learning and semi-supervised learning using gaussian ﬁelds
and harmonic functions. In ICML 2003 workshop on The
Continuum from Labeled to Unlabeled Data in Machine
Learning and Data Mining, pages 58–65, 2003.

APPENDIX
A.

PROOF OF LEMMA 1

Lemma 1. The diﬀerence of ratings in two ratings, p and q is

at most 1.

|rp(i) − rq(i)| ≤ 1

Proof. If i ∈ L, then |rp(i)− rq(i)| = 0. We now prove where

comment i is not labeled.

wij (biasq−1(i) − biasp−1(i))

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2) 1

di(j)

(cid:3)
i:i→j

|rp(i) − rq(i)| =
(cid:3)
i:i→j

≤ 1
di(j)

|biasq−1(i) − biasp−1(i)| ≤ 1
di(j)

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

(cid:3)
i:i→j

1 = 1

Last inequality comes from the fact that bias∗
fore |bias∗

(i) − bias∗

(i)| ≤1.

(i) ∈ [0, 1], there-

B. PROOF OF THEOREM 1

We show the bound of Theorem 1 of Section 4.2.1. We prove

this using mathematical induction to prove the error bound.

Proof. Basis: We ﬁrst prove for t = 1.
|bias2(i) − bias1(i)|

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)
(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)
(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

=

≤

≤

=

⎛
⎝ (cid:3)
⎛
⎝ (cid:3)
⎛
⎝ (cid:3)

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

⎞
⎠
wij (r1(j) − r0(j))
⎞
⎠

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)
(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2) [using Lemma 1]

|r1(j) − r0(j)|
⎞
⎠

1

1

1

1

2 · (α · do

L(i) +d o

U L(i))

j:i→j,j∈U L

2 · (α · do

L(i) +d o

U L(i))

j:i→j,j∈U L

U L(i))

2 · (α · do
L(i) +d o
do
U L(i))
2 · (α · do
L(i) + do

U L(i))

j:i→j,j∈U L

≤ 1
2

2 · (α · do

L(i) + do

This conﬁrms the basis.
Induction step: We assume the bound to be true for bt(i), i.e.,
for the tth iteration. In the (t + 1)th iteration,
|biast+2(i) − bt+1(i)| =

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

1

1

U L(i))

j:i→j,j∈U L

⎛
⎝ (cid:3)
⎛
⎝ (cid:3)

⎞
⎠
wij (rt+1(j) − rt(j))
(cid:8)
|wkj||biast+1(k) − biast(k)|(cid:9)⎞
⎠
⎛
⎝ 1
di(j)

j:i→j,j∈U L

(cid:3)
k:k→j

U L(i))

⎞
⎠

(cid:11)t

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

(cid:10)

1
2

⎞
⎠

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

2 · (α · do
L(i) + do
(cid:3)
k:k→j

di(j)

1

1

2 · (α · do

L(i) + do

⎛
⎝ (cid:3)
(cid:11)t+1 ≤

j:i→j,j∈U L
(cid:10)

1
2

U L(i))
(cid:10)

[Induction Assumption]

(cid:11)t+1

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)
(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)

=

≤

≤

=

do
U L(i))
(α · do
L(i) +d o

U L(i))

·

1
2

2

D−1
i AT D−1

o A) (see Section 6).

C. PROOF OF EXISTENCE OF THE INVERSE
inverse of matrix (I − 1

In this section, we present a small proof of existence of the
For a matrix A, if ρ(A) < 1, then (I−A)
−1 exists (see Theorem
4.20 from matrix algorithms [23]), where ρ(A) denotes the spec-
tral radius of A. Let ||.||∞ denote the inﬁnity norm; it satisﬁes
||A||∞ ≥ ρ(A) and is submultiplicative, i.e., ||AB|| ≤ ||A|| ||B||.
o A|| < 1, then it will prove
If we can show that || 1
i AT D−1
D−1
ρ( 1
o A) < 1 and subsequently, the existence of the
2
inverse.
||D−1
i AT D−1
o A||∞. Ob-
Now, 1
2
serve that the maximum absolute sum of each row of D−1
i AT
and D−1
o A is 1, which shows that ||.||∞ of these two matrices is
at most 1. Therefore, ρ( 1
2

i AT ||∞||D−1

D−1
i AT D−1

i AT D−1
D−1

o A||∞ ≤ 1

o A) ≤ 1

||D−1

2

.

2

2

WWW 2012 – Session: Fraud and Bias in User RatingsApril 16–20, 2012, Lyon, France190
