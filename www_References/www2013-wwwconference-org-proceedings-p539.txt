[1] L. Addario-Berry and T. Lei. The mixing time of the

newman–watts small world. In SODA, pages
1661–1668, 2012.

[2] Y.-Y. Ahn, S. Han, H. Kwak, S. B. Moon, and

H. Jeong. Analysis of topological characteristics of
huge online social networking services. In WWW,
pages 835–844, 2007.

[3] N. Alon, R. Yuster, and U. Zwick. Finding and

counting given length cycles. Algorithmica,
17(3):209–223, 1997.

[4] H. Avron. Counting triangles in large graphs using
randomized matrix trace estimation. In Large-Scale
Data Mining: Theory and Applications (KDD
Workshop), 2010.

[5] L. Backstrom, D. P. Huttenlocher, J. M. Kleinberg,

and X. Lan. Group formation in large social networks:
membership, growth, and evolution. In KDD, pages
44–54, 2006.

[6] Z. Bar-Yossef and M. Gurevich. Random sampling
from a search engine’s index. J. ACM, 55(5), 2008.

[7] Z. Bar-Yossef and M. Gurevich. Estimating the

impressionrank of web pages. In WWW, pages 41–50,
2009.

[8] Z. Bar-Yossef and M. Gurevich. Eﬃcient search engine

measurements. TWEB, 5(4):18, 2011.

546e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

 3

 2.5

 2

 1.5

 1

 0.5

 2.5

 2

 1.5

 1

 0.5

 0

DBLP network

MH Ego network
RW Ego network
Random walk

 0

 0.2  0.4  0.6  0.8

 1

 1.2  1.4  1.6  1.8

 2

Percentage of mined nodes

Flickr network

RW Ego network
MH Ego network
Random walk

 0

 0.2  0.4  0.6  0.8

 1

 1.2  1.4  1.6  1.8

 2

Percentage of mined nodes

e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

 5

 4

 3

 2

 1

 0

 6

 5

 4

 3

 2

 1

 0

Orkut network

RW Ego network
MH Ego network
Random walk

 0

 0.2  0.4  0.6  0.8

 1

 1.2  1.4  1.6  1.8

 2

Percentage of mined nodes

LiveJournal network

RW Ego network
MH Ego network
Random walk

 0

 0.2  0.4  0.6  0.8

 1

 1.2  1.4  1.6  1.8

 2

Percentage of mined nodes

Figure 3: Estimation of the global clustering coeﬃcient conﬁdence interval vs. the percentage of mined nodes.

[9] L. Becchetti, P. Boldi, C. Castillo, and A. Gionis.

[16] J. Kunegis. KONECT – the Koblenz Network

Eﬃcient algorithms for large-scale local triangle
counting. TKDD, 4(3), 2010.

[10] L. S. Buriol, G. Frahling, S. Leonardi,

A. Marchetti-Spaccamela, and C. Sohler. Counting
triangles in data streams. In PODS, pages 253–262,
2006.

[11] K.-M. Chung, H. Lam, Z. Liu, and M. Mitzenmacher.

Chernoﬀ-hoeﬀding bounds for markov chains:
Generalized and simpliﬁed. In STACS, pages 124–135,
2012.

[12] L. F. Costa, F. A. Rodriguez, G. Travieso, and

P. R. V. Boas. Characterization of complex networks:
A survey of measurements. Advances in Physics,
56(1):167–242, Aug. 2006.

[13] M. Gjoka, M. Kurant, C. T. Butts, and

A. Markopoulou. Walking in facebook: A case study
of unbiased sampling of OSNs. Proceedings of IEEE
INFOCOM 2010, pages 1–9, 2010.

[14] S. J. Hardiman, P. Richmond, and S. Hutzler.

Calculating statistics of complex networks through
random walks with an application to the on-line social
network bebo. European Physics Journal B,
71(4):611–622, 2009.

[15] L. Katzir, E. Liberty, and O. Somekh. Estimating

sizes of social networks via biased sampling. In
WWW, pages 597–606, 2011.

Collection. http://konect.uni-koblenz.de/, 2012.

[17] D. A. Levin, Y. Peres, and E. L. Wilmer. Markov

Chains and Mixing Times. American Mathematical
Society, 2008.

[18] M. Ley. The DBLP computer science bibliography:

Evolution, research issues, perspectives. In Proc. Int.
Symp. on String Processing and Information Retrieval,
pages 1–10, 2002.

[19] L. Lov´asz and P. Winkler. Mixing times. microsurveys

in discrete. In DimacsWorkshop, 1998.

[20] A. Mislove, H. S. Koppula, K. P. Gummadi,

P. Druschel, and B. Bhattacharjee. Growth of the
ﬂickr social network. In Proceedings of the 1st ACM
SIGCOMM Workshop on Social Networks
(WOSN’08), August 2008.

[21] A. Mislove, M. Marcon, P. K. Gummadi, P. Druschel,

and B. Bhattacharjee. Measurement and analysis of
online social networks. In Internet Measurement
Comference, pages 29–42, 2007.

[22] A. Mohaisen, A. Yun, and Y. Kim. Measuring the

mixing time of social graphs. In Internet Measurement
Conference, pages 383–389, 2010.

[23] M. Newman and D. Watts. Renormalization group
analysis of the small-world network model. Physics
Letters A, 263:341–346, 1999.

547Orkut network

Node Collision
Neighbor Collision

 2.6
 2.4
 2.2
 2
 1.8
 1.6
 1.4
 1.2
 1
 0.8
 0.6
 0.4

e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

 2.2

 2

 1.8

 1.6

 1.4

 1.2

 1

 0.8

 0.6

 2.6
 2.4
 2.2
 2
 1.8
 1.6
 1.4
 1.2
 1
 0.8
 0.6
 0.4

DBLP network

Node Collision
Neighbor Collision

 0.5

 1

 1.5

 2

 2.5

Percentage of mined nodes

Flickr network

Node Collision
Neighbor Collision

 0

 0.2

 0.4

 0.6

 0.8

 1

 1.2

 1.4

 1.6

Percentage of mined nodes

e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

e
u
l
a
v



n
o
i
t
a
m

i
t
s
e

e
v
i
t
a
l
e
R

 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9

 1

Percentage of mined nodes

LiveJournal network

Node Collision
Neighbor Collision

 0.4

 0.6

 0.8

 1

 1.2

 1.4

 1.6

Percentage of mined nodes

 2.2

 2

 1.8

 1.6

 1.4

 1.2

 1

 0.8

 0.6

 0.2

Figure 4: Estimation of the network size conﬁdence interval vs. the percentage of mined nodes.

[24] M. Newman and D. Watts. Scaling and percolation in

the small-world network model. Physical Review E,
60:7332–7342, 1999.

[25] B. F. Ribeiro and D. F. Towsley. Estimating and

sampling graphs with multidimensional random walks.
In Internet Measurement Conference, pages 390–403,
2010.

[26] R. Y. Rubinstein and D. P. Kroese. Simulation and

the Monte Carlo Method. Wiley Series in Probability
and Statistics, 2 edition, 2007.

[27] T. Schank and D. Wagner. Approximating clustering

coeﬃcient and transitivity. J. Graph Algorithms Appl.,
9(2):265–275, 2005.

[28] S. Wasserman and K. Faust. Social Network Analysis:

Methods and Applications. Cambridge University
Press, 1994.

APPENDIX
A. CONCENTRATION OF ΨL AND ΦL

In the proof of Lemma 1 we required that the variables Ψl
and Φl give an /3 approximation to their expected values
with probability at least 1 − δ/2.

To prove both Ψl or Φl are concentrated we ﬁrst restate

a theorem from Chung et al. [11]:

Theorem 4

Let M be an er-
godic Markov chain with state space [n] and stationary dis-

(Theorem 3.1 [11]).

π =

(cid:2)

tribution π. Let τ = τ () be its -mixing time for  ≤ 1
8 . Let
(x1, x2, . . . , xr) denote an r-step random walk on M start-
ing from an initial distribution ϕ on [n], i.e., x1 ← ϕ. Let
(cid:11)ϕ(cid:11)
. For every k ∈ [r], let fk : [n] → [0, 1] be
a weight function at step k such that the expected weight
(cid:2)
Ev←π[fk(xk)] = μ for all k. Deﬁne the total weight of
the walk (x1, x2, . . . , xr) by Z (cid:2)
k=1 fk(xk). There ex-
ists some constant c (which is independent of μ, δ and )
such that for 0 < δ <1

n
i=1

2
ϕ
i
πi

r

Pr [|Z − μr| > μr] ≤ c(cid:11)ϕ(cid:11)

e−

2

μr/72τ ,

π

or equivalently

(cid:4)(cid:12)(cid:12)(cid:12)(cid:12) Z

r

Pr

(cid:12)(cid:12)(cid:12)(cid:12) > μ
(cid:5)

− μ

≤ c(cid:11)ϕ(cid:11)

π

e−

2

μr/72τ .

Lemma 5. There is a constant value, ξ, such that if r ≥

rΨl = ξ D

n

τ (), we have

(cid:4)
|Ψl − E [Ψl]| ≤ E [Ψl]

(cid:5)

Pr

≥ 1 − δ
2

. We assume that

(cid:13)

(cid:14)

1
dxk

= n
D .

3

(cid:14)

Proof. Let fk(xk) = f (xk) = 1
dxk

π = 1. We have, E [Ψl] = E

ϕ ≈ π, and thus (cid:11)ϕ(cid:11)
From Theorem 4,

(cid:13)
|Ψl − E [Ψl]| >

Pr



3

E [Ψl]

≤ ce−

2

nr/9·72·τ D

548≤
τ (). Since  and δ are constants, this ends the

nr/9·72·τ D, we have rΨl

2 = ce−

2

Extracting rΨl for which δ
˜ξ log(δ) 1
2
proof.

D
n

Lemma 6. There is a constant value, ξ, such that if r ≥

rΦl = ξ D
ncl

τ (), we have

(cid:4)

(cid:5)

Pr

|Φl − E [Φl]| ≤ E [Φl]

3

≥ 1 − δ
2

dxk

Axk ,xk+2
−1

Proof. For this bounds, we cannot apply Therorem 4
directly since fj depends on previously visited node. How-
ever, since
only depends on a 3-nodes history, we
observe a related Markov chain that remembers the last
three visited nodes. To this end, ˜M has ˜n = n × n × n
nodes, and (x1, x2, x3) ← (x2, x3, x4) with the same transi-
Axk−1,xk+1
tion probability of x3 to x4 in M . Let fk(˜xk) =
.
We assume that ϕ ≈ π, and thus (cid:11)ϕ(cid:11)
(cid:2)
π = 1. We have,
i=1 ci = n
cl. From Theo-
E [Φl] = E
(cid:14)
rem 4,

(cid:13)
φk

1
−1
dxk

= 1
D

dxk

−1

(cid:14)

D

n

(cid:13)
|Φl − E [Φl]| >

Pr

≤ ce−

2

ncl(r−2)/9·72·˜τ D

2

2

D
ncl

Extracting rΦl for which δ
rΦl
the proof.

ncl (r−2)/9·72·˜τ D, we have
≤ ˜ξ log(δ) 1
˜τ . Since  and δ are constants, this ends
Note that ˜τ () ≤ τ (). To see this, in the true station-
ary distribution the probability of drawing xk−1, xk, xk+1 is
dxk−1
. After τ () steps, the probability of drawing
xk−1 is at most  distance away. Therefore, probability of
drawing xk−1, xk, xk+1 is
, and thus
D
the diﬀerence is bounded by  1
dxk

(cid:16)
± 

≤ .

dxk−1

1
dxk

1
dxk

dxk+1

dxk+1

dxk+1

(cid:15)

D

1

1

1



3

E [Φl]
2 = ce−

To conclude we combine Lemma 5 and 6, and choose

rl = max {rΨl
B. CONCENTRATION OF ΨG AND ΦG

, rΦl

}.

In the proof of Lemma 2 we require that the variables Ψg
and Φg give an /3 approximation to their expected values
with probability at least 1 − δ/2.

Lemma 7. There is a constant value, ξ, such that if r ≥

n

(cid:2)

Pr

(cid:5)

Ddmax

rΨg = ξ

τ (), we have

i=1 di(di−1)

(cid:4)
|Ψg − E [Ψg]| ≤ E [Ψg]
−1
dxk
dmax (all values in [0, 1]).
We assume that ϕ ≈ π, and thus (cid:11)ϕ(cid:11)
(cid:2)
π = 1. We have,
i=1 di(di − 1). From
dmax E [Ψg] = E
Theorem 4,

Proof. Let fk(xk) = f (xk) =

≥ 1 − δ
2

−1
dxk
dmax

Ddmax

(cid:13)

=

3

n

1

1

(cid:14)
(cid:12)(cid:12)(cid:12)(cid:12) >

(cid:4)(cid:12)(cid:12)(cid:12)(cid:12) Ψg

dmax

Pr

− E [Ψg]
dmax

(cid:5)



E [Ψl]
dmax
3
2 = ce−
i=1 di(di−1)

Ddmax

2(cid:2)

n

≤ ce

− 

2(cid:2)

n
i=1 di
9·72·τ Ddmax

(di

−1)r

n

i=1 di(di−1)r/9·72·τ Ddmax,
τ (). Since  and δ are

Extracting rΨg for which δ
≤ ˜ξ log(δ) 1
we have rΨg
(cid:2)
constants, this ends the proof.

2

Lemma 8. There is a constant value, ξ, such that if r ≥

rΦg = ξ

(cid:2)

cg

Ddmax
n

τ (), we have
(cid:4)
i=1 di(di−1)
|Φg − E [Φg]| ≤ E [Φg]

Pr

(cid:5)

≥ 1 − δ
2

3

Proof. The proof combines the division by dmax of lemma 7

and the the 3-node history markov chain ˜M of lemma 6.

549
