[1] AOL search data.

http://www.gregsadetsky.com/aol-data/, 2006.

[2] D. Arroyuelo, R. C´anovas, G. Navarro, and

K. Sadakane. Succinct trees in practice. In ALENEX,
pages 84–97, 2010.

[3] D. Benoit, E. D. Demaine, J. I. Munro, R. Raman,

V. Raman, and S. S. Rao. Representing trees of higher
degree. Algorithmica, 43(4):275–292, 2005.

[4] I. Bialynicka-Birula and R. Grossi. Rank-sensitive data

structures. In SPIRE, pages 79–90, 2005.

[5] P. Boldi and S. Vigna. Codes for the World Wide Web.

Internet Mathematics, 2(4):407–429, 2005.

[6] N. R. Brisaboa, R. C´anovas, F. Claude, M. A.

Mart´ınez-Prieto, and G. Navarro. Compressed string
dictionaries. In SEA, pages 136–147, 2011.

[7] K. W. Church, B. Thiesson, and R. Ragno. K-best

suﬃx arrays. In HLT-NAACL (Short Papers), pages
17–20, 2007.

[8] D. R. Clark. Compact pat trees. PhD thesis, University

of Waterloo, Waterloo, Ont., Canada, Canada, 1998.
UMI Order No. GAXNQ-21335.

[9] P. Davoodi, R. Raman, and S. R. Satti. Succinct

representations of binary trees for range minimum
queries. In COCOON, pages 396–407, 2012.

[10] H. Duan and B.-J. P. Hsu. Online spelling correction

for query completion. In WWW, pages 117–126, 2011.
[11] P. Elias. Universal codeword sets and representations of

the integers. IEEE Transactions on Information
Theory, 21(2):194–203, Mar. 1975.

[12] P. Ferragina and G. Manzini. Indexing compressed text.

J. ACM, 52(4):552–581, 2005.

[13] J. Fischer and V. Heun. Space-eﬃcient preprocessing
schemes for range minimum queries on static arrays.
SIAM J. Comput., 40(2):465–492, 2011.

[14] E. Fredkin. Trie memory. Commun. ACM, 3:490–499,

September 1960.

[15] J. Goldstein, R. Ramakrishnan, and U. Shaft.

Compressing relations and indexes. In ICDE, pages
370–379, 1998.

[16] J. Grieves. The secrets of the Windows Phone 8
keyboard. http://blogs.windows.com/windows_
phone/b/windowsphone/archive/2012/12/06/the-
secrets-of-the-windows-phone-8-keyboard.aspx,
December 2012.

[17] R. Grossi and G. Ottaviano. Fast compressed tries
through path decompositions. In ALENEX, pages
65–74, 2012.

[18] R. Grossi and J. S. Vitter. Compressed suﬃx arrays

and suﬃx trees with applications to text indexing and
string matching. SIAM J. Comput., 35(2):378–407,
2005.

[19] W.-K. Hon, R. Shah, and J. S. Vitter. Space-eﬃcient

framework for top-k string retrieval problems. In FOCS,
pages 713–722, 2009.

[20] G. Jacobson. Space-eﬃcient static trees and graphs. In

FOCS, pages 549–554, 1989.

[21] D. E. Knuth. The Art of Computer Programming,
Volume 3: Sorting and Searching. Addison-Wesley,
Reading, USA, 2nd edition, 1998.

[22] N. J. Larsson and A. Moﬀat. Oﬄine dictionary-based
compression. In Data Compression Conference, pages
296–305, 1999.

[23] F. Li. Simpler search. http:

//blog.twitter.com/2012/07/simpler-search.html,
July 2012.

592[24] G. Li, S. Ji, C. Li, and J. Feng. Eﬃcient type-ahead
search on relational data: a TASTIER approach. In
SIGMOD, pages 695–706, 2009.

[25] G. Li, J. Wang, C. Li, and J. Feng. Supporting eﬃcient

top-k queries in type-ahead search. In SIGIR, pages
355–364, 2012.

[26] D. Matani. An O(k log n) algorithm for preﬁx based

ranked autocomplete.
http://www.dhruvbird.com/autocomplete.pdf, 2011.
Preprint.

[27] Microsoft Web N-gram Service.

http://web-ngram.research.microsoft.com/.

[28] J. I. Munro and V. Raman. Succinct representation of

balanced parentheses and static trees. SIAM Journal
on Computing, 31(3):762–776, June 2001.

[29] S. Muthukrishnan. Eﬃcient algorithms for document

retrieval problems. In SODA, pages 657–666, 2002.

[30] A. Nandi and H. V. Jagadish. Eﬀective phrase

prediction. In VLDB, pages 219–230, 2007.
[31] D. Okanohara and K. Sadakane. Practical

entropy-compressed rank/select dictionary. In
ALENEX, 2007.

[32] S. Russell and P. Norvig. Artiﬁcial Intelligence: A

Modern Approach. Prentice Hall, Upper Saddle River,
N.J., 3 edition, 2003.

[33] K. Sadakane and G. Navarro. Fully-functional succinct

trees. In SODA, pages 134–149, 2010.

[34] Succinct library. http://github.com/ot/succinct.
[35] D. Sullivan. How Google Instant’s autocomplete

suggestions work.
http://searchengineland.com/how-google-instant-
autocomplete-suggestions-work-62592, April 2011.

[36] R. Vernica and C. Li. Eﬃcient top-k algorithms for

fuzzy search in string collections. In KEYS, 2009.

[37] S. Vigna. Broadword implementation of rank/select

queries. In WEA, pages 154–168, 2008.

[38] H. E. Williams and J. Zobel. Compressing integers for

fast ﬁle access. Comput. J., 42(3):193–201, 1999.

APPENDIX
A. DATA STRUCTURE FOR RMQ

To perform Range Minimum Queries on a vector of scores,
we use the 2d-Min-Heap described by Fischer and Heun
[13], which, as noted by Davoodi et al. [9], is an alternative
representation of the Cartesian tree. As in [13], we build the
DFUDS representation of the 2d-Min-Heap in the bitvector
U . The RMQ of i and j can then be reduced to the RMQ
on the excess sequence E of U , denoted as ±1RMQE, with
the following algorithm. Note that the indices are slightly
diﬀerent from [13] because all our primitives are 0-based.

Lemma A.1

([13, Section 5.1]). If U is the DFUDS
representation of a 2d-Min-Heap, then RMQ(i, j) can be
computed by the following algorithm.

1 x ← Select)(U, i + 1)
2 y ← Select)(U, j + 1)
3 w ← ±1RMQE(x, y)
4 if Rank)(U, FindOpen(U, w − 1)) = i + 1 then

5
6 else
7

return i
return Rank)(U, w − 1)

Our implementation diﬀers from the one in [13] in two
ways. First, instead of using an ad-hoc data structure for
±1RMQE, we re-use the same Range-Min tree [17] that is
used for tree navigation. The Range-Min tree divides the
excess sequence E into blocks and builds a binary tree whose
nodes correspond to intervals in E: the leaves correspond to
individual blocks, while each internal node corresponds to the
union of the intervals corresponding to its children. In each
node, we store the excess minimum for the corresponding
interval. It is straightforward to ﬁnd the block with minimal
excess between the block containing x and the one containing
y in O(log n) time. Then, to ﬁnd the position of minimal
excess within a block, we perform a simple linear scan by
dividing the block into 8-bit chunks and using a lookup table
to ﬁnd the minimum inside each chunk.
Second, line 4 in Lemma A.1 checks whether the node at
position x is the parent of w − 1 (in which case the minimal
value is at position i). We replace it with the following line.
4 if Excess(U, Select)(i) + 1) ≤ Excess(U, w) then
Since, in our implementation, Select is signiﬁcantly faster
than FindOpen, the whole algorithm speeds up by 10 − 20%
with this change. The following lemma proves that the two
conditions are equivalent.

Lemma A.2. In the algorithm described in Lemma A.1,
Excess(U, Select)(i) + 1) ≤ Excess(U, w) if and only if the
node at w − 1 in U is a child of the node at Select)(i + 1).
Proof. Let t = Select)(i) and x = Select)(i + 1). If the
node at w − 1 is a child of the node at x, then its mate z is
between t and x as shown below:

(··· (
)
t

z

··· ()

x

········· )
w−1

If follows that Excess(t + 1) ≤ Excess(z). Since Excess(z) =
Excess(w), we obtain Excess(t + 1) ≤ Excess(w).
Conversely, suppose Excess(U, t + 1) ≤ Excess(U, w). Since
w = ±1RMQE(x, y), it holds Excess(U, w) < Excess(U, x).
Hence there must be a position z such that t + 1 ≤ z < x and
Excess(U, z) = Excess(U, w). To prove that z is the mate of
w − 1, it suﬃces to note that the excess between z + 1 and
w − 1 is strictly greater than Excess(w), again because w is
the leftmost excess minimum in the range [x, y].

593
