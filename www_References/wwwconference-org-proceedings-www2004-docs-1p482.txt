[1] J. Allan, V. Khandelwal, and R. Gupta. Temporal summaries

of news topics. In Proceedings of the 24th International
Conference on Research and Development in Information
Retrieval, pages 10–18, 2001.

[2] C. Burgess, K. Livesay, and L. Kevin. Explorations in
context space: Words, sentences, discourse. Discourse
Processes, 25(2&3):211–258, 1998.

[3] J. Carbonell and J. Goldstein. The use of MMR,

diversity-based reranking for reordering documents and
producing summaries. In Proceedings of the 21st
International Conference on Research and Development in
Information Retrieval, pages 335–336, 1998.

[4] K. Collins-Thompson, P. Ogilvie, Y. Zhang, and J. Callan.

Information ﬁltering, novelty detection, and named-page
ﬁnding. In Proceedings of the 11th Text REtrieval
Conference. National Institute of Standards and Technology,
2002.

[5] T. Cover and J. Thomas. Elements of Information Theory.

John Wiley & Sons, 1991.

[6] S. Cronen-Townsend and W. B. Croft. Quantifying query

ambiguity. In Proceedings of the Human Language
Technology Conference (HLT-2002), pages 94–98, March
2002.

[7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft. Predicting

query performance. In Proceedings of the 25th International
Conference on Research and Development in Information
Retrieval, pages 299–306, August 2002.

[8] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer,

and R. Harshman. Indexing by latent semantic analysis.
Journal of the American Society For Information Science,
41:391–407, 1990.

[9] F. Douglis, T. Ball, Y.-F. Chen, and E. Koutsoﬁos. The AT&T
internet difference engine: Tracking and viewing changes on
the web. World Wide Web, pages 27–44, January 1998.

[10] C. Fellbaum, editor. WordNet: An Electronic Lexical

Database. MIT Press, 1998.

[11] L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan,

G. Wolfman, and E. Ruppin. Placing search in context: The
concept revisited. ACM Transactions on Information
Systems, 20(1):116–131, January 2002.

[12] R. Gonzalez and P. Wintz. Digital Image Processing.

Addison-Wesley, second edition, 1987.

[13] D. Harman. Overview of the TREC 2002 novelty track. In
Proceedings of the 11th Text REtrieval Conference, pages

The x-axis shows contextual word windows ending at word i; the
y-axis plots the distance from each window to the seed story.
Figure 6: Examples of relationships of articles with a seed story.

extracted from the text, and use a variety of distance metrics to
estimate the dissimilarity between each news article and a collec-
tion of the previously read ones. The techniques underlying the
algorithms analyze inter- and intra-document dynamics by study-
ing how the delivery of information evolves over time from article
to article, as well as within each individual article at the level of
contextual word windows.

News browsers incorporating these algorithms can offer users a
personalized news experience, giving users the ability to tune both
the desired frequency of news updates and the degree to which
these updates should be similar to the seed story, via exercising
control over the novelty constraint.

To evaluate the algorithm for ranking news articles by novelty,
we propose a new evaluation scheme that asks users to read several
sets of articles ordered by different metrics, and rate them from
the most to least novel. Although at ﬁrst glance this task appears
very hard as it requires the users to keep in mind all the articles they
read, in practice the scheme was feasible. Debrieﬁng the users after
the experiments offered interesting insights into how people judge
novelty and relevance issues.

This research can be extended in several directions. We plan
to investigate more sophisticated distance metrics that incorporate
some of the basic metrics we described herein, as well as use com-
plex weighting windows that vary document weights over time.
We also plan to combine information-theoretic measures such as
KL and JS with a representation based solely on named entities,
to estimate the amount of novelty carried by the latter in a more
principled way. Of particular interest and practical use is the char-
acterization of which metrics are best for predicting the novelty of
articles for different types of topics. The notion of intra-story pat-
terns of novelty is a rich area for exploration. In this work we only
scratched the surface by modeling a few article types of particular
interest in the context of news. However, we believe a much richer
ontology would be necessary to capture the entire possible variety
of article types. We hope that further research in these directions
will provide additional insights into principles and applications for
personalizing news.

Finally, we observe that techniques similar to those we described
can also be applied to other types of content, such as blogs and
newsgroups, assessing the novelty of postings within threads or

 48946–55. ACM Press, 2002. NIST Special Publication
500-251.

[14] E. Horvitz, C. Kadie, T. Paek, and D. Hovel. Models of

attention in computing and communication: From principles
to applications. Communications of the ACM, 46(3):52–59,
March 2003. http://research.microsoft.com/
˜horvitz/cacm-attention.htm.

[15] A. Kilgarriff. Comparing corpora. International Journal of

Corpus Linguistics, 6(1):97–133, 2001.

[16] J. Kleinberg. Bursty and hierarchical structure in streams. In

Proceedings of the 8th International Conference on
Knowledge Discovery and Data Mining, 2002.

[22] G. Salton and C. Buckley. Term weighting approaches in

automatic text retrieval. Information Processing and
Management, 24(5):513–523, 1988.

[23] B. Schiffman, A. Nenkova, and K. McKeown. Experiments

in multidocument summarization. In Proceedings of the
Human Language Technology Conference (HLT-2002),
March 2002.

[24] R. Swan and D. Jensen. Timemines: Constructing timelines
with statistical models of word usage. In Proceedings of the
ACM SIGKDD 2000 Workshop on Text Mining, pages 73–80,
2000.

[25] F. Wilcoxon. Individual comparisons by ranking methods.

[17] L. Lee. Measures of distributional similarity. In Proceedings

Biometrics, 1:80–83, 1945.

of the 37th Annual Meeting of the ACL, 1999.

[26] Y. Yang, T. Ault, and T. Pierce. Combining multiple learning

[18] C. D. Manning and H. Schuetze. Foundations of Statistical

Natural Language Processing. The MIT Press, 2000.
[19] J. R. Quinlan. C4.5: Programs for Machine Learning.

Morgan Kaufmann, 1993.

[20] P. Resnik. Semantic similarity in a taxonomy: An

information-based measure and its application to problems
of ambiguity in natural language. Journal of Artiﬁcial
Intelligence Research, 11:95–130, 1999.

[21] E. Ristad. A natural law of succession. Technical Report

Technical Report CS-TR-495-95, Princeton University, 1995.

strategies for effective cross-validation. In Proceedings of
ICML-00, 17th International Conference on Machine
Learning, pages 1167–1182, 2000.

[27] Y. Yang, J. Zhang, J. Carbonell, and C. Jin.

Topic-conditioned novelty detection. In Proceedings of the
Internaltional Conference on Knowledge Discovery and
Data Mining, pages 688–693, 2002.

490
