
[1] E. Agichtein, E. Brill, and S. Dumais. Improving web search ranking by

incorporating user behavior information. In SIGIR ’06: Proceedings of the 29th
annual international ACM SIGIR conference on Research and development in
information retrieval, pages 19–26, 2006.

[2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules.

In Proceedings of the 20th International Conference on Very Large Databases
(VLDB’94), pages 487–499, 1994.

[3] H. Akaike. A new look at the statistical model identi↓cation. IEEE

Transactions on Automatic Control, 19:716– 723, Dec 1974.

[4] R. Andersen, C. Borgs, J. Chayes, J. Hopcroft, V. Mirrokni, and S.-H.

Teng. Local computation of pagerank contributions. Internet Mathematics,
5:23–45, Jan. 2009.

[5] Atlas. Engagement mapping. Thought Paper, Available at

http://www.atlassolutions.com/uploadedFiles/Atlas/Atlas\_Institute/Engagement\
_Mapping/eMapping- TP.pdf, 2008.

[6] S. Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik, S. Kumar,

D. Ravichandran, and M. Aly. Video suggestion and discovery for youtube:
taking random walks through the view graph. In Proceedings of the 17th
International Conference on World Wide Web, WWW, pages 895–904, 2008.
[7] H. Cao, D. Jiang, J. Pei, E. Chen, and H. Li. Towards context-aware

search by learning a very large variable length hidden markov model from
search logs. In WWW ’09: Proceedings of the 18th international conference on
World wide web, pages 191–200, 2009.

[8] comScore. Whither the click? comscore brand metrix norms prove

‘view-thru’ value of on-line advertising. Available at
http://www.comscore.com/press/release.asp?press=2587, 2008.

[9] G. Cormode, F. Korn, S. Muthukrishnan, and Y. Wu. On signatures for
communication graphs. In Proceedings of the 24th International Conference on
Data Engineering, ICDE, pages 189–198, 2008.

[10] E. E. Dar, Y. Mansour, V. Mirrokni, S. Muthukrishnan, and U. Nadav.
Budget optimization for broad-match ad auctions. In WWW, World Wide
Web Conference, 2009.

[11] J. Dean and S. Ghemawat. Mapreduce: simpli↓ed data processing on large

clusters. Communications of ACM, 51(1):107–113, 2008.

[12] T. Fawcett and F. J. Provost. Combining data mining and machine

learning for e↑ective user pro↓ling. In Proceedings of the Second International
Conference on Knowledge Discovery and Data Mining (KDD), pages 8–13, 1996.

[13] J. Feldman, S. Muthukrishnan, M. Pal, and C. Stein. Budget optimization

in search-based advertising auctions. In EC ’07: Proceedings of the 8th ACM
conference on Electronic commerce, pages 40–49, 2007.

[14] A. Hassan, R. Jones, and K. Klinkner. Beyond DCG: User behavior as a

predictor of a successful search. In WSDM ’10: Proceedings of the 3rd
international conference on web search and data mining, 2010. Forthcoming.

[15] T. H. Haveliwala. Topic-sensitive pagerank: A context-sensitive ranking

algorithm for web search. IEEE Transactions on Knowledge and Data
Engineering, 15(4):784–796, 2003.

[16] A. Inokuchi, T. Washio, and H. Motoda. An apriori-based algorithm for

mining frequent substructures from graph data. In Principles of Data Mining
and Knowledge Discovery, pages 13–23, 2000.

[17] G. Jeh and J. Widom. Scaling personalized web search. In WWW ’03:

Proceedings of the 12th international conference on World Wide Web, pages
271–279, 2003.

[18] K. Keller. Brand equity and integrated communication. In Integrated

Communication: Synergy of Persuasive Voices, 1996.

[19] R. Kohavi. A study of cross-validation and bootstrap for accuracy

estimation and model selection. In Proceedings of the Fourteenth International
Joint Conference on Artiﬁcial Intelligence, pages 1137–1145, 1995.

[20] R. Lewis and D. Reiley. Retail advertising works!: Measuring the e↑ects of
advertising on sales via a controlled experiment on yahoo! Working paper,
Yahoo! Research, 2009.

[21] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser,
and G. Czajkowski. Pregel: a system for large-scale graph processing. In
PODC ’09: Proceedings of the 28th ACM symposium on Principles of distributed
computing, pages 6–6, 2009.

[22] H. Mannila, H. Toivonen, and I. Verkamo. Discovery of frequent episodes

in event sequences. Data Mining and Knowledge Discovery, 1:259–289, Sept.
1997.

[23] S. Muthukrishnan, M. Pal, and Z. Svitkina. Stochastic models for budget

optimization in search-based advertising. In Lecture Notes in Computer
Science, Internet and Network Economics, pages 131–142, 2007.

[24] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation

ranking: Bringing order to the web. Technical Report. Stanford InfoLab.,
1999.

[25] K. Sugiyama, K. Hatano, and M. Yoshikawa. Adaptive web search based

on user pro↓le constructed without any e↑ort from users. In WWW ’04:
Proceedings of the 13th international conference on World Wide Web, pages
675–684, 2004.

10. APPENDIX

Proof of Proposition 1

Proof. From [4]

pprα(·, v) = αev

∞X

t=0

(1 − α)t(M

T )t

.

After taking the derivative

∂ pprα(·, c)

pprα(·, c)

=

∂α

α

+ αec

∞X

t=1

t(1 − α)t−1(M

T )t

.

It immediately follows that

‚‚‚‚‚ ∂ pprα(·, c)

∂α

− pprα(·, c)

α

‚‚‚‚‚∞

→ 0.

Next, we have h = ec + hM T and

pprα(·, c) = αec + (1 − α) pprα(·, c)M

T

,

which is equivalent to

pprα(·, c)

α

After substraction

or



h − pprα(·, c)
!

α

h − pprα(·, c)

α

as pprα(·, c) → 0.

Proof of Proposition 2

= ec +



=

T

.

1 − α

α

pprα(·, c)M
!
h − 1 − α
pprα(·, c)
T “

α

I − M

= pprα(·, c)M

T

,

M

T”−1 → 0,

Proof. We know that the ppr vector p with restart at node b solves the equa-
tion p = αeb + (1 − α)pM, where M is the transition matrix. Fix nodes i and j
and take a derivative with respect to wij :

∂p

∂wij

= (1 − α)p

∂M

∂wij

+ (1 − α)

∂p

∂wij

M.

Now, ∂M
∂wij

that

is a zero matrix with a single 1 at row i and column j. It follows

where p[i] is the i-th component of the vector p. This can be written as

∂p

∂wij

M,

∂p

∂wij

∂p

∂wij

=

= (1 − α)p[i]ej + (1 − α)
  1 − α

!

p[i]

αej + (1 − α)

α

and by linearity of the PPR we can see that this is just
PPR vector with restart at node j, i.e.,
1 − α

∂ pprα(b, c)

=

pprα(b, i) pprα(j, c).

∂wij

α

∂p

∂wij

M,

“ 1−α

α

”

p[i]

times the

Proofs of Propositions 3 and 5
Proof. For outgoing edges, we can use the equality pprα(i, c) = αI(i ==

c) + (1 − α) pprα(j, c)wij [4], as shown below:

0@X

1A

X

j

wij

∂ pprα(b, c)

∂wij

=

=

=

(1 − α) pprα(b, i)

wij pprα(j, c)

α

1 − α

α

pprα(b, i)

j

1

1 − α

pprα(i, c)

pprα(b, i) pprα(i, c)

.

α

For incoming edges, we can use similar trick with pprα(b, i) = αI(i == b) + (1−
α) pprα(b, j)wji.

Proof of Theorem 2
Proof. M Iα and REα can be approximated by Theorem 1 of [4]. For MI,
RE and Pass simply note that ˆM can be written as (1 − α(cid:48))M∗, where M∗ is
a valid random walk matrix (every row sums to at most 1.0, the rest goes to
“null”). One can therefore calculate hit and all derivative adfactors (MI, RE and
Pass) via a pushback algorithm for the PPR of a random walk with the restart
probability α(cid:48) so Theorem 1 of [4] works again.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA40
