[1] Hitwise 2009 press releases, 2009.
[2] Special issue on web as corpus. Computational

Linguistics, 29(3), September 2003.

[3] E. Agichtein, E. Brill, and S. Dumais. Improving web

search ranking by incorporating user behavior
information. In Proceedings of 29th international ACM
conference on Research and development in
information retrieval (SIGIR), pages 19–26, 2006.
[4] M. Banko and E. Brill. Scaling to very very large

corpora for natural language disambiguation. In
Proceedings of 39th Annual Meeting on Association for
Computational Linguistics (ACL), pages 26–33, 2001.

[5] C. Barr, R. Jones, and M. Regelson. The linguistic
structure of english web-search queries. In Proc. of
Conference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1021–1030, 2008.

[6] S. Bergsma, D. Lin, and R. Goebel. Web-scale n-gram

models for lexical disambiguation. In Proceedings of
the 21st International Joint Conference on Arti(cid:12)cial
Intelligence (IJCAI), pages 1507–1512, 2009.

[7] S. Bergsma and Q. I. Wang. Learning noun phrase

query segmentation. In Proceedings of the Joint
Conference on Empirical Methods in Natural Language
Processing (EMNLP) and Computational Natural
Language Learning (CoNLL), pages 819–826, 2007.

Figure 7: Tradeoﬀ between the exact match rate
and the violation rate for long query segmentation
using diﬀerent n-gram language models.

of keywords, most similar to the way long queries are
composed. The performance diﬀerence of the body and title
language models are not particularly clear cut in this case.

7. CONCLUSION

The vast world wide web oﬀers a tremendous amount of
treasure freely available in the wild. This work chooses
the n-gram language model, a representation that has
found many successful applications in IR and NLP, to
capture the web language information hidden in the massive
unlabeled and unﬁltered web data. Enabled by the recent
advances in web-scale language modeling techniques, we
built language models from web document sources including
the anchor texts, the titles and the document bodies, as
well as from search queries. We conduct a large-scale
information theoretical analysis on these language models
to quantitatively examine the language diﬀerences in these
data sources with diﬀerent orders and sizes. We ﬁnd that
web search queries are composed in a way most similar to
how authors summarize documents in anchor texts or titles.
In practice, web language models can be applied in a
variety of document and query processing tasks in a web
search engine. This work focuses on three Search Query
Processing (SQP) tasks. Through the lens of context-
sensitive query spelling correction, we observe how the
diﬀerence of language translates to that of the accuracy in
a real-world application. This suggests that the alternative
data sources can be even more eﬀective than the document
bodies that have been used in past work. We further analyze
the sub-query bracketing structure for three-word queries
and propose a novel hierarchical long query segmentation
method using web language models. The methods inves-
tigated in these SQP tasks are all unsupervised methods
driven by the unlabeled web data that are abundantly
available. As such, they can be readily and eﬃciently applied
in the real world.

Our exploration yields several guidances for practice. We
show that a theoretical measure – perplexity – to be a good
accuracy indicator for these tasks and hence can be used to
intelligently allocate engineering resources in practice. We

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA459[8] T. Brants and A. Franz. Web 1T 5-gram corpus

[24] P. Nakov and M. Hearst. Search engine statistics

version 1.1. Technical report, Google Research, 2006.

[9] T. Brants, A. C. Popat, P. Xu, F. J. Och, and

J. Dean. Large language models in machine
translation. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Processing
(EMNLP) and Computational Natural Language
Learning (CoNLL), pages 858–867, 2007.

[10] S. F. Chen and J. Goodman. An empirical study of

smoothing techniques for language modeling.
Computer Speech and Language, 13(10):359–394, 1999.
[11] K. Church, T. Hard, and J. Gao. Compressing trigram

language models with Golomb coding. In Proceedings
of EMNLP and CoNLL, pages 199–207, 2007.

[12] S. Cucerzan and E. Brill. Spelling correction as an

iterative process that exploits the collective knowledge
of web users. In EMNLP, pages 293–300, 2004.

[13] M. Gamon, J. Gao, C. Brockett, A. Klementiev,

W. Dolan, D. Belenko, and L. Vanderwende. Using
contextual speller techniques and language modeling
for ESL error correction. In Proc. of IJCNLP, 2008.

[14] J. Gao, J. Goodman, and J. Miao. The use of
clustering techniques for language modelling -
application to Asian languages. Computational
Linguistics and Chinese Language Processing,
6(1):27–60, 2001.

[15] J. Gao, W. Yuan, X. Li, K. Deng, and J.-Y. Nie.

Smoothing clickthrough data for web search ranking.
In Proceedings of the 32nd international SIGIR
conference on Research and development in
information retrieval (SIGIR), pages 355–362, 2009.

[16] A. R. Golding and Y. Schabes. Combining

trigram-based and feature-based methods for
context-sensitive spelling correction. In Proceedings of
the 34th ACL, pages 71–78, 1996.

[17] A. Halevy, P. Norvig, and F. Pereira. The

unreasonable eﬀectiveness of data. IEEE Intelligent
Systems, 24(2):8–12, 2009.

[18] X. Huang, A. Acero, and H.-W. Hon. Spoken

Language Processing: A Guide to Theory, Algorithm
and System Development. Prentice Hall PTR, 2001.

[19] R. Jones, B. Rey, O. Madani, and W. Greiner.

Generating query substitutions. In Proc. of 15th
World Wide Web (WWW), pages 387–396, 2006.

[20] R. Kneser and H. Ney. Improved backing-oﬀ for
M-gram language modeling. IEEE International
Conference on Acoustics, Speech, and Signal
Processing (ICASSP), 1:181–184, 1995.

[21] G. Kumaran and V. R. Carvalho. Reducing long

queries using query quality predictors. In Proc. of
32nd international conf. on Research and development
in information retrieval (SIGIR), pages 564–571, 2009.

[22] M. Lapata and F. Keller. The web as a baseline:

Evaluating the performance of unsupervised
web-based models for a range of NLP tasks. In Proc.
of Human Language Technologies - North American
Chapter of the Association for Computational
Linguistics (HLT-NAACL), pages 121–128, 2004.

[23] M. Lauer. Corpus statistics meet the noun compound:

some empirical results. In Proceedings of the 33rd
annual meeting on Association for Computational
Linguistics (ACL), pages 47–54, 1995.

beyond the n-gram: Application to noun compound
bracketing. In Proc. of 9th Conf. on Computational
Natural Language Learning, pages 17–24, 2005.

[25] P. Nguyen, J. Gao, and M. Mahajan. MSRLM: a

scalable language modeling toolkit. Technical report
TR-2007-144, Microsoft Research, 2007.

[26] A. Spink, D. Wolfram, M. B. J. Jansen, and

T. Saracevic. Searching the web: the public and their
queries. Journal of American Society for Information
Science and Technology, 52(3):226–234, 2001.

[27] K. Svore and C. Burges. A machine learning approach

for improved bm25 retrieval. In Proceedings of 18th
ACM Conference on Information and Knowledge
Management (CIKM), pages 1811–1814, 2009.

[28] B. Tan and F. Peng. Unsupervised query segmentation

using generative language models and Wikipedia. In
Proceeding of the 17th international conference on
World Wide Web (WWW), pages 347–356, 2008.

[29] D. Vadas and J. R. Curran. Corpus statistics meet the

noun compound: some empirical results. In
Proceedings of 10th Conference of the Paci(cid:12)c
Association for Computational Linguistics
(PACLING), pages 104–112, 2007.

[30] K. Wang and X. Li. Eﬃcacy of a constantly adaptive

language modeling technique for web-scale
applications. In Proceedings of IEEE International
Conference on Acoustics, Speech and Signal Processing
(ICASSP), pages 4733–4736, 2009.

[31] C. Zhai and J. Laﬀerty. A study of smoothing

methods for language models applied to information
retrieval. ACM Transactions on Information Systems,
22(2):179–214, 2004.

APPENDIX
A. DERIVATION OF THE SPMI METRIC
Using an order r n-gram LM with the Markov assumption,

P (q) = P (w1w2:::wk) =

i=1

P (wijwi(cid:0)r+1::wi(cid:0)1)

With a segmentation boundary t, the probability of the
left and right segments can be written similarly. Given the
following SPMI deﬁnition:

k∏

∏

SPMI(q; t) = log

P (qlqr)

P (ql)P (qr)

(10)

we can write out individual terms as below,

∏
i=1 P (wijwi(cid:0)r+1::wi(cid:0)1)
log
t(cid:0)1
Note that most terms cancel out and only at most r (cid:0) 2

∏
i=t P (wijwi(cid:0)r+1::wi(cid:0)1)

k

i=1 P (wijwi(cid:0)r+1::wi(cid:0)1)

k

terms behind the segmentation boundary remain, i.e.
log P (wtjwt(cid:0)r+1::wt(cid:0)1)P (wt+1jwt(cid:0)r+2::wt):::P (wt+r(cid:0)2jwt(cid:0)1::wt+r(cid:0)3)

P (wt)P (wt+1jwt):::P (wt+r(cid:0)2jwt::wt+r(cid:0)3)

Simplifying and noting the query’s right boundary, we get

the desired result:

minfr(cid:0)2;k(cid:0)(r(cid:0)2)g∑

SPMI(q; t) =

i=0

p(wt+ijwt+i(cid:0)r+1::wt+i(cid:0)1)

p(wt+ijwt::wt+i(cid:0)1)

log

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA460
