[1] N. Abe, A. W. Biermann, and P. M. Long. Reinforcement learning

with immediate rewards and linear hypotheses. Algorithmica,
37(4):263–293, 2003.

[2] D. Agarwal, B.-C. Chen, and P. Elango. Explore/exploit schemes for
web content optimization. In Proc. of the 9th International Conf. on
Data Mining, 2009.

[3] D. Agarwal, B.-C. Chen, P. Elango, N. Motgi, S.-T. Park,

R. Ramakrishnan, S. Roy, and J. Zachariah. Online models for
content optimization. In Advances in Neural Information Processing
Systems 21, pages 17–24, 2009.

[4] R. Agrawal. Sample mean based index policies with o(log n) regret

for the multi-armed bandit problem. Advances in Applied
Probability, 27(4):1054–1078, 1995.

[5] A. Anagnostopoulos, A. Z. Broder, E. Gabrilovich, V. Josifovski, and

L. Riedel. Just-in-time contextual advertising. In Proc. of the 16th

ACM Conf. on Information and Knowledge Management, pages
331–340, 2007.

[6] P. Auer. Using conﬁdence bounds for exploitation-exploration

trade-offs. Journal of Machine Learning Research, 3:397–422, 2002.

[7] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the
multiarmed bandit problem. Machine Learning, 47(2–3):235–256,
2002.

[8] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. The
nonstochastic multiarmed bandit problem. SIAM Journal on
Computing, 32(1):48–77, 2002.

[9] D. A. Berry and B. Fristedt. Bandit Problems: Sequential Allocation

of Experiments. Monographs on Statistics and Applied Probability.
Chapman and Hall, 1985.

[10] P. Brusilovsky, A. Kobsa, and W. Nejdl, editors. The Adaptive Web —

Methods and Strategies of Web Personalization, volume 4321 of
Lecture Notes in Computer Science. Springer Berlin / Heidelberg,
2007.

[11] R. Burke. Hybrid systems for personalized recommendations. In

B. Mobasher and S. S. Anand, editors, Intelligent Techniques for Web
Personalization. Springer-Verlag, 2005.

[12] W. Chu and S.-T. Park. Personalized recommendation on dynamic

content using predictive bilinear models. In Proc. of the 18th
International Conf. on World Wide Web, pages 691–700, 2009.

[13] W. Chu, S.-T. Park, T. Beaupre, N. Motgi, A. Phadke,

S. Chakraborty, and J. Zachariah. A case study of behavior-driven
conjoint analysis on Yahoo!: Front Page Today Module. In Proc. of
the 15th ACM SIGKDD International Conf. on Knowledge Discovery
and Data Mining, pages 1097–1104, 2009.

[14] A. Das, M. Datar, A. Garg, and S. Rajaram. Google news

personalization: scalable online collaborative ﬁltering. In Proc. of the
16th International World Wide Web Conf., 2007.

[15] J. Gittins. Bandit processes and dynamic allocation indices. Journal

of the Royal Statistical Society. Series B (Methodological),
41:148–177, 1979.

[16] S. M. Kakade, S. Shalev-Shwartz, and A. Tewari. Efﬁcient bandit

algorithms for online multiclass prediction. In Proc. of the 25th
International Conf. on Machine Learning, pages 440–447, 2008.

[17] T. L. Lai and H. Robbins. Asymptotically efﬁcient adaptive

allocation rules. Advances in Applied Mathematics, 6(1):4–22, 1985.
[18] J. Langford and T. Zhang. The epoch-greedy algorithm for contextual
multi-armed bandits. In Advances in Neural Information Processing
Systems 20, 2008.

[19] D. J. C. MacKay. Information Theory, Inference, and Learning

Algorithms. Cambridge University Press, 2003.

[20] D. Mladenic. Text-learning and related intelligent agents: A survey.

IEEE Intelligent Agents, pages 44–54, 1999.

[21] S.-T. Park, D. Pennock, O. Madani, N. Good, and D. DeCoste. Naïve
ﬁlterbots for robust cold-start recommendations. In Proc. of the 12th
ACM SIGKDD International Conf. on Knowledge Discovery and
Data Mining, pages 699–705, 2006.

[22] N. G. Pavlidis, D. K. Tasoulis, and D. J. Hand. Simulation studies of

multi-armed bandits with covariates. In Proceedings on the 10th
International Conf. on Computer Modeling and Simulation, pages
493–498, 2008.

[23] D. Precup, R. S. Sutton, and S. P. Singh. Eligibility traces for

off-policy policy evaluation. In Proc. of the 17th Interational Conf.
on Machine Learning, pages 759–766, 2000.

[24] H. Robbins. Some aspects of the sequential design of experiments.

Bulletin of the American Mathematical Society, 58(5):527–535,
1952.

[25] J. B. Schafer, J. Konstan, and J. Riedi. Recommender systems in

e-commerce. In Proc. of the 1st ACM Conf. on Electronic Commerce,
1999.

[26] W. R. Thompson. On the likelihood that one unknown probability

exceeds another in view of the evidence of two samples. Biometrika,
25(3–4):285–294, 1933.

[27] T. J. Walsh, I. Szita, C. Diuk, and M. L. Littman. Exploring compact

reinforcement-learning representations with linear regression. In
Proc. of the 25th Conf. on Uncertainty in Artiﬁcial Intelligence, 2009.

WWW 2010 • Full PaperApril 26-30 • Raleigh • NC • USA670
