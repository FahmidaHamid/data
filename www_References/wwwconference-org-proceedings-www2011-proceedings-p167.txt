[1] Chakrabarti, D., Agarwal, D., and Josifovski, V.

Contextual advertising by combining relevance with
click feedback. In WWW ’08: Proceedings of the 17th
International Conference on World Wide Web (2008),
pp. 417–426.

[2] Dean, B. C., Goemans, M. X., and Vondr´ak, J.
Approximating the stochastic knapsack problem: The
beneﬁt of adaptivity. Mathematics of Operations
Research 33, 4 (Nov 2008), 945–964.

WWW 2011 – Session: Monetization IIMarch 28–April 1, 2011, Hyderabad, India174(a) π1

(b) π3

Figure 4: Eﬃciency of π1 and π3 by diﬃculty levels, with k = 2, T = 300

[3] Derman, C., Lieberman, G. J., and Ross, S. M. A
renewal decision problem.l Management Science 24, 5
(1978), 554–561.

[4] Kan, A. H. G. R., and Stougie, L. On the relation

between complexity and uncertainty. Annals of
Operations Research 18 (1989), 17–24.

[5] Langford, J., and Zhang, T. The epoch-greedy

algorithm for multi-armed bandits with side
information. In Advances in Neural Information
Processing Systems 20, J. Platt, D. Koller, Y. Singer,
and S. Roweis, Eds. MIT Press, Cambridge, MA, 2008,
pp. 817–824.

[6] Li, L., Chu, W., Langford, J., and Schapire,

R. E. A contextual-bandit approach to personalized
news article recommendation. In WWW ’10:
Proceedings of the 19th International Conference on
World Wide Web (2010), pp. 661–670.

[7] Martello, S., and Toth, P. Knapsack Problems:

Algorithms and Computer Implementations. John
Wiley and Sons, Chichester, 1990.

WWW 2011 – Session: Monetization IIMarch 28–April 1, 2011, Hyderabad, India175(a) k = 2

(b) k = 3

(c) k = 4

(d) k = 5

Figure 5: Eﬃciency of greedy policies with 1 ≤ ni ≤ 20 and T = 1000, for (a) k = 2, (b) k = 3, (c) k = 4, and (d)
k = 5. Cases involving both diﬃculty levels M and E have been separated from the rest.

WWW 2011 – Session: Monetization IIMarch 28–April 1, 2011, Hyderabad, India176
