[1] E. Agichtein, E. Brill, and S. Dumais. Improving web

search ranking by incorporating user behavior

WWW 2011 – Session: RankingMarch 28–April 1, 2011, Hyderabad, India37563

62.5

62

61.5

61

60.5

1
@
G
C
D
N


t
s
e
T



60
1

2



62.5



66



3
@
G
C
D
N


t
s
e
T

62

61.5

61

60.5

60



59.5
1

2

Baseline (Newton)
Baseline (Gradient Descent)
λ(L)+λ(S),Exponential
λ(L)+λ(S),Linear

3

4

Percentage  of Train Data

5

6

0
1
@
G
C
D
N


t
s
e
T

65.5

65

64.5

64



63.5
1

2

Baseline (Newton)
Baseline (Gradient Descent)
λ(L)+λ(S),Exponential
λ(L)+λ(S),Linear

3

4

Percentage  of Train Data

5

6

Baseline (Newton)
Baseline (Gradient Descent)
λ(L)+λ(S),Exponential
λ(L)+λ(S),Linear

3

4

Percentage  of Train Data

5

6

(a)

(b)

(c)

Figure 7: NDCG results on the 13.5K test set for LambdaMART (baseline; both Newton and gradient
descent) versus LambdaMART using the iteration-dependent λ-gradient, denoted λ(L) + λ(S). Two methods of
weight adjustment are considered: exponential and linear. The x-axis indicates the percentage of the 108K
training data used for training, with {1 = 3.25%, 2 = 6.25%, 3 = 12.5%, 4 = 25%, 5 = 50%, 6 = 100%}. The validation
and test sets remain consistent across all experiments, each with 13.5K queries.

information. In Proceedings of international ACM
SIGIR conference on Research and development in
information retrieval, pages 19–26, 2006.

[11] J. H. Friedman. Greedy function approximation: A
gradient boosting machine. In Annals of Statistics,
pages 29(5):1189–1232, 2001.

[2] C. J. Burges, K. M. Svore, P. N. Benett, A. Pastusiak,

[12] F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor,

and Q. Wu. Learning to rank using an ensemble of
lambda-gradient models. to appear in Special Edition
of JMLR: Proceedings of the Yahoo! Learning to Rank
Challenge, 14:25–35, 2011.

Y.-M. Wang, , and C. Faloutsos. Click chain model in
web search. In Proceedings of the 18th International
World Wide Web Conference. Association for
Computing Machinery, Inc., 2009.

[3] C. J. C. Burges. From RankNet to LambdaRank to

[13] K. Jarvelin and J. Kekalainen. IR evaluation methods

LambdaMART: An Overview. Technical Report
MSR-TR-2010-82, Microsoft Research, 2010.

[4] C. J. C. Burges, R. Ragno, and Q. V. Le. Learning to
rank with nonsmooth cost functions. In Proceedings of
the Neural Information Processing Systems, pages
193–200, 2006.

[5] C. J. C. Burges, T. Shaked, E. Renshaw, A. Lazier,

M. Deeds, N. Hamilton, and G. Hullender. Learning to
rank using gradient descent. In Proceedings of the
International Conference on Machine learning, pages
89–96, 2005.

[6] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li.

Learning to rank: from pairwise approach to listwise
approach. In Proceedings of the International
Conference on Machine learning, pages 129–136, 2007.

[7] S. Chakrabarti, R. Khanna, U. Sawant, and

C. Bhattacharyya. Structured learning for non-smooth
ranking losses. In Proceedings of the ACM SIGKDD
Conference on Knowledge Discovery and Data Mining,
pages 88–96, 2008.

[8] O. Chapelle, Y. Chang, and T.-Y. Liu. The
Yahoo! Learning to Rank Challenge, 2010.

[9] P. Donmez, K. Svore, and C. Burges. On the local

optimality of lambdarank. In Special Interest Group
on Information Retrieval (SIGIR), 2009.

[10] Z. Dou, R. Song, X. Yuan, and J.-R. Wen. Are

click-through data adequate for learning web search
rankings? In Proceeding of the ACM Conference on
Information and Knowledge Management, 2008.

for retrieving highly relevant documents. In
Proceedings of the International ACM SIGIR
Conference on Research and Development in
Information Retrieval, pages 41–48, 2000.

[14] T. Joachims. Optimizing search engines using
clickthrough data. In Proceedings of the ACM
Conference on Knowledge Discovery and Data Mining,
pages 133–142, 2002.

[15] T. Joachims, L. Granka, B. Pan, H. Hembrooke,

F. Radlinski, and G. Gay. Evaluating the accuracy of
implicit feedback from clicks and query reformulations
in web search. ACM Transactions on Information
Science, 2007.

[16] O.Chapelle, D. Metzler, Y. Zhang, and P. Grinspan.

Expected reciprocal rank for graded relevance. In
Proceeding of the ACM Conference on Information
and Knowledge Management, 2009.

[17] M. Taylor, J. Guiver, S. Robertson, and T. Minka.
Softrank: optimizing non-smooth rank metrics. In
Proceedings of the International Conference on Web
Search and Web Data Mining, pages 77–86, 2008.

[18] M. N. Volkovs and R. S. Zemel. Boltzrank: Learning
to maximize expected ranking gain. In Proceedings of
the International Conference on Machine Learning,
pages 1089–1096, 2009.

[19] Q. Wu, C. Burges, K. M. Svore, and J. Gao. Adapting

Boosting for Information Retrieval Measures.
Information Retrieval, 2009.

WWW 2011 – Session: RankingMarch 28–April 1, 2011, Hyderabad, India376
