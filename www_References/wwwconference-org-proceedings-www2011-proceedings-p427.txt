[1] Google Sets: http://labs.google.com/sets.
[2] List of United Nations member states.

http://en.wikipedia.org/wiki/united_nations_member_states.

[3] Web colors. http://en.wikipedia.org/wiki/web_colors.
[4] E. Agichtein and L. Gravano. Snowball: extracting relations from

large plain-text collection. In JCDL, 2000.

[5] S. Baluja, R. Seth, D. Sivakumar, Y. Jing, J. Yagnik, S. Kumar,

D. Ravichandran, and M. Aly. Video suggestion and discovery for
youtube: Taking random walks through the view graph. In WWW,
2008.

[6] O. Etzioni, M. Cafarella, D. Downey, S. Kok, A. Popescu, T. Shaked,

S. Soderland, D. S. Weld, and A. Yates. Web-scale information
extraction in KnowItAll. In WWW, 2004.

[7] O. Etzioni, M. Cafarella, D. Downey, A.-M. Popescu, T. Shaked,

S. Soderland, D. S. Weld, and A. Yates. Unsupervised named-entity
extraction from the web: An experimental study. In Artiﬁcal
Intelligence, 2005.

[8] Z. Ghahramani and K. A. Heller. Bayesian sets. In NIPS, 2005.
[9] R. M. Karp. Reducibility among combinatorial problems. Complexity

of Computer Computations, 1972.

[10] N. Otsu. A threshold selection method from gray-level histograms.

IEEE Transactions on Systems, Man and Cybernetics, 1979.

[11] M. S. Pang-Ning Tan and V. Kumar. Introduction to Data Mining.

2005.

[12] T. Ridler and S. Calvard. Picture thresholding using an iterative

selection method. IEEE Transactions on Systems, Man and
Cybernetics, 1978.

[13] B. Settles. Biomedical named entity recognition using conditional

random ﬁelds and rich feature sets. In CoLING, 2004.

[14] P. P. Talukdar, T. Brants, M. Liberman, and F. Pereira. A context
pattern induction method for named entity extraction. In CoNLP,
2006.

[15] P. P. Talukdar, J. Reisinger, M. Pasca, D. Ravichandran, R. Bhagat,

and F. Pereira. Weakly-supervised acquisition of labeled class
instances using graph random walks. In EMNLP, 2008.
[16] R. Wang and W. Cohen. SEAL: http://rcwang.com/seal.
[17] R. Wang and W. Cohen. Language-independent set expansion of

named entities using the web. In ICDM, 2007.

[18] R. Wang and W. Cohen. Iterative set expansion of named entity using

the web. In ICDM, 2008.

[19] R. Wang and W. Cohen. Character-level analysis of semi-structured

documents for set expansion. In EMNLP, 2009.

[20] Y.-Y. Wang, R. Hoffmann, X. Li, and J. Szymanski. Semi-supervised
learning of semantic classes for query understanding. In CIKM, 2009.

8. APPENDIX
8.1 Proof of Theorem 1

We show that there exists a polynomial-time reduction from the
Maximum-Clique problem to the problem we stated in Section 3.4.
For any given graph 𝐺 = {𝑉, 𝐸} for which the Maximum-
Clique needs to be computed, we can build a corresponding simi-
larity matrix 𝑀 of size ∣𝑉 ∣×∣𝑉 ∣, where each row 𝑟𝑖 corresponds to
vertex 𝑣𝑖 ∈ 𝑉 , and each column 𝑐𝑗 corresponds to vertex 𝑣𝑗 ∈ 𝑉 .
The matrix entry 𝑀 (𝑟𝑖, 𝑐𝑗) is 1 if there is the edge (𝑣𝑖, 𝑣𝑗) ∈ 𝐸,
otherwise 𝑀 (𝑟𝑖, 𝑐𝑗) = 0.

Given this construction of this similarity matrix 𝑀, we prove
the claim by contradiction. Suppose there is an algorithm 𝐴 that
efﬁciently ﬁnds the optimal 𝑅 of size 𝐾 with maximum quality
𝑄(𝑅, 𝑆). If we assign 𝛼 to be 0, the decision problem of ﬁnding
Maximum-Clique of any graph 𝐺 can be solved using the corre-
sponding similarity matrix 𝑀 and algorithm 𝐴. This is because the
∣𝑅∣−1
optimal set 𝑅 computed by 𝐴 with maximum quality score (
2∣𝑅∣ )
must corresponds to a clique in the original graph. This contra-
dicts with the hardness of the Maximum-Clique problem, hence
the hardness of the problem we stated in Section 3.4.
8.2 Proof of Theorem 2

Let 𝑅 = {𝑟1, 𝑟2, ..., 𝑟𝐾−1, 𝑟𝐾} and 𝑅′ = {𝑟′

To prove that the Algorithm 1 will terminate and the computation
of 𝑅𝑖𝑡𝑒𝑟 converges, we show that the quality metric 𝑄(𝑅𝑖𝑡𝑒𝑟, 𝑆) is
monotonically increasing with the number of iteration 𝑖𝑡𝑒𝑟.
𝐾}
𝐾−1, 𝑟′
2, ..., 𝑟′
be the ESS of two subsequent iterations. Without loss of generality,
𝑖 for 1 ≤ 𝑖 ≤ 𝐾−1, and denote ˜𝑅 = {𝑟1, 𝑟2, ..., 𝑟𝐾−1} =
let 𝑟𝑖 = 𝑟′
{𝑟′
𝐾−1}, such that we have 𝑅 = ˜𝑅 ∪ {𝑟𝐾} and 𝑅′ =
2, ..., 𝑟′
1, 𝑟′
˜𝑅 ∪ {𝑟′
𝐾}. Let 𝑔(𝑟𝑗, 𝑅, 𝑆), and 𝑔(𝑟𝑗, 𝑅′, 𝑆) be the ranking func-
tion of 𝑟𝑗 against 𝑅 and 𝑅′
respectively. Observe that the quality
metric

1, 𝑟′

𝑄(𝑅, 𝑆) =

𝛼

∣𝑅∣ ⋅ ∣𝑆∣

∣𝑆∣∑

∣𝑅∣∑

𝑖=1

𝑗=1

𝑆𝑖𝑚(𝑠𝑖, 𝑟𝑗)

(1 − 𝛼)
∣𝑅∣ ⋅ ∣𝑅∣

+

∣𝑅∣∑

∣𝑅∣∑

𝑖=1

𝑗>𝑖

𝑆𝑖𝑚(𝑟𝑖, 𝑟𝑗)

and similarly

𝑄(𝑅′, 𝑆) =

𝛼

∣𝑅′∣ ⋅ ∣𝑆∣

∣𝑆∣∑

∣𝑅′∣∑

𝑖=1

𝑗=1

𝑆𝑖𝑚(𝑠𝑖, 𝑟′
𝑗)

(1 − 𝛼)
∣𝑅′∣ ⋅ ∣𝑅′∣

+

∣𝑅′∣∑

∣𝑅′∣∑

𝑖=1

𝑗>𝑖

𝑆𝑖𝑚(𝑟′

𝑖, 𝑟′
𝑗)

The difference of the quality function in two subsequent itera-

.

tions are thus

𝑄(𝑅′, 𝑆) − 𝑄(𝑅, 𝑆)

=

∣𝑆∣∑

𝛼

𝑖=1

∣𝑅∣ ⋅ ∣𝑆∣ (
(1 − 𝛼)
∣𝑅∣ ⋅ ∣𝑅∣ (
∣𝑆∣∑

+

𝑖=1

∣𝑅∣ ⋅ ∣𝑆∣ (
(1 − 𝛼)
∣𝑅∣ ⋅ ∣𝑅∣ (

+

≥ 𝛼

𝑆𝑖𝑚(𝑠𝑖, 𝑟′

𝐾−1∑

𝑆𝑖𝑚(𝑟′

∣𝑆∣∑

𝐾 ) −
𝐾 , 𝑟𝑖) − 𝐾−1∑

𝑖=1

𝑖=1

𝑖=1

𝑆𝑖𝑚(𝑠𝑖, 𝑟′

𝐾∑

𝑆𝑖𝑚(𝑟′

∣𝑆∣∑

𝐾 ) −
𝐾 , 𝑟𝑖) − 𝐾∑

𝑖=1

𝑖=1

𝑖=1

𝑆𝑖𝑚(𝑠𝑖, 𝑟𝐾 ))

𝑆𝑖𝑚(𝑟𝐾 , 𝑟𝑖))

𝑆𝑖𝑚(𝑠𝑖, 𝑟𝐾 ))

𝑆𝑖𝑚(𝑟𝐾 , 𝑟𝑖))

≥ 1
∣𝑅∣ (𝑔(𝑟′

𝐾 , 𝑅, 𝑆) − 𝑔(𝑟𝐾 , 𝑅, 𝑆))

>0.

In other words, after each iteration the quality of the new ESS
𝑄(𝑅′, 𝑆) is strictly greater than that of the previous iteration 𝑄(𝑅, 𝑆).
Since for each iteration 𝑖𝑡𝑒𝑟, 𝑅𝑖𝑡𝑒𝑟 ⊆ 𝑈, the number of different
𝑅𝑖𝑡𝑒𝑟 is ﬁnite. Thus we know the algorithm will terminate and the
computation of 𝑅𝑖𝑡𝑒𝑟 converges.

WWW 2011 – Session: Information ExtractionMarch 28–April 1, 2011, Hyderabad, India436
