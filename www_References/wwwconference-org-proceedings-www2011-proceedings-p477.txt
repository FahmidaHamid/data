[1] http://crowdflower.com/.
[2] http://www.smartsheet.com/.
[3] http://www.google.com/analytics/.
[4] http://requester.mturk.com/.
[5] http://s3.amazonaws.com/.
[6] http://www.maxmind.com/app/geolitecity.
[7] O. Alonso and S. Mizzaro. Can we get rid of TREC

Assessors? Using Mechanical Turk for Relevance
Assessment. In SIGIR ’09 Workshop on the Future of
IR Evaluation.

[8] D. Feng. Talk: Tackling ATTi Business Problems

Using Mechanical Turk. Palo Alto Mechanical Turk
Meetup, 2010.

[9] J. Galante. CrowdFlower’s Virtual Pay for Digital

Purchases. http://www.businessweek.com/magazine/
content/10_26/b4184041335224.htm.

[10] P. Heymann and H. Garcia-Molina. Human

Processing. Technical report, 2010.

[11] P. Ipeirotis. Mechanical Turk: The Demographics.
http://behind-the-enemy-lines.blogspot.com/
2008/03/mechanical-turk-demographics.html.

[12] P. Ipeirotis. The New Demographics of Mechanical

Turk. http:
//behind-the-enemy-lines.blogspot.com/2010/03/
new-demographics-of-mechanical-turk.html.

[13] A. Kittur, E. H. Chi, and B. Suh. Crowdsourcing User

Studies with Mechanical Turk. In CHI ’08.

[14] G. Little, L. Chilton, M. Goldman, and R. Miller.

TurKit: Tools for Iterative Tasks on Mechanical Turk.
In HCOMP ’09: SIGKDD Workshop on Human
Computation.

[15] J. Ross, L. Irani, M. Silberman, A. Zaldivar, and

B. Tomlinson. Who are the Crowdworkers?: Shifting
Demographics in Mechanical Turk. In CHI ’10.

[16] R. Snow, B. O’Connor, D. Jurafsky, and A. Ng. Cheap

and Fast—But is it Good?: Evaluating Non-expert
Annotations for Natural Language Tasks. In
EMNLP’08.

[17] A. Sorokin and D. Forsyth. Utility Data Annotation

with Amazon Mechanical Turk. In CVPRW’08.

Figure 7: Plot of average active and total seconds
for each worker who completed the NER task.

diiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii
.............. 300 inactive seconds .............
iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii
iaaaaaaiiiiaaaaaaaiaiaaaaaaaaaaaaaaaaiaaiaaaaaaaaa
aaaaaaaaaaaaaaaiiiiiiiiiaaaaaaaaaaaaaaaiaaaiiiaaaa
aaaaaiiiiiiiiaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
aaiaaaiaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
aaaaiiiiiiiiiiiiiiiaiaiiiiiiiaaiiaiaaaaaaaaiiaaaaa
aaiiaiiaaaaaaaaaiaaaaaaaiiiiaaiaaaaaaaasbu

(a) 688 Second Activity Signature

daaaaiaaaaaiaaaaaaaaaaaaiiiiiiaaaaaaaiiiaaaaaaaaaa
aaaaiiiiaaiiiaaaiiiiaaaaaiaaaaiaaaaaiiaaaaiiiasabu

(b) 96 Second Activity Signature

Figure 8: Two activity signatures showing dif-
ferent proﬁles
Key:
a=activity, i =inactivity, d =DOM load, s=submit,
b=beforeunload, u=unload.

for completing a task.

8. RELATED WORK

Our system, and the results presented, are related to four
main areas of work: human computation systems, analytics,
Mechanical Turk demographic research, and general Me-
chanical Turk work. With respect to human computation
systems, several were cited in the introduction [1], [2], [8],
[14]. Our intent is for our tool to improve such systems and
make building them easier. With respect to analytics, nu-
merous analytics tools (e.g., [3]) exist in industry, though
there does not appear to be a great deal of work in the aca-
demic literature about such tools. With respect to demo-
graphics, independent work by Ipeirotis [11], [12] and Ross
et al. [15] used worker surveys to illustrate the changing de-
mographics of Mechanical Turk over time. (Section 6 more
or less validates these previous results, as well as adding a
more recent data point.) With respect to general Mechanical
Turk research, the most common focuses to date have been
conducting controlled experiments [13] and performing data
annotation in areas like natural language processing [16],
information retrieval [7], and computer vision [17].

9. CONCLUSION

We presented Turkalytics, a tool for gathering data about
workers completing human computation tasks. We envi-
sion Turkalytics as part of a broader system, in particu-
lar a system implementing the Human Processing model.
However, one big advantage of our design for Turkalytics is

WWW 2011 – Session: Performance and SystemsMarch 28–April 1, 2011, Hyderabad, India486
