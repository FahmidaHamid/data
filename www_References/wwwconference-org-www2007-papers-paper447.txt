[1] OASIS eXtensible Access Control Markup Language

(XACML). http:
//www.oasis-open.org/committees/xacml/,
2005.

[2] Sun’s XACML implementation.

http://sunxacml.sourceforge.net/, 2005.

[3] A. T. Acree. On Mutation. PhD thesis, Georgia Institute of

Technology, 1980.

[4] T. A. Budd. Mutation Analysis of Program Test Data. PhD

thesis, Yale University, 1980.

[5] B. Choi and A. P. Mathur. High-performance mutation

testing. Journal of Systems and Software, 20:135–152, 1993.

[6] N. Damianou, N. Dulay, E. Lupu, and M. Sloman. The

Ponder policy speciﬁcation language. In Proc. International
Workshop on Policies for Distributed Systems and Networks,
pages 18–38, 2001.

[7] R. A. DeMillo, R. J. Lipton, and F. G. Sayward. Hints on test

data selection: Help for the practicing programmer. IEEE
Computer, 11(4):34–41, April 1978.

[8] R. A. DeMillo and A. J. Offutt. Constraint-based automatic

test data generation. IEEE Trans. Softw. Eng.,
17(9):900–910, 1991.

[9] K. Fisler, S. Krishnamurthi, L. A. Meyerovich, and M. C.

Tschantz. Veriﬁcation and change-impact analysis of

Figure 5: Mutant-killing ratios for all subjects by operators.

ﬁcial lowering of the mutant-killing ratio. Indeed this explanation
may be the case because policy and rule combining algorithms are
only relevant when there is a high degree of interaction between
rules within a policy or policies within a policy set. Conversely,
PSTT and PSTF have over 60% killing ratios, and PTT, PTF, RTF,
RCF, and CRE have at least 90% killing ratios. The similar mutant-
killing ratios across these mutation operators indicate that there is
no signiﬁcant difference between the fault types in terms of difﬁ-
culty of detection.

We provided the original policy and each mutant policy to Mar-
grave’s change-impact analysis feature to perform equivalent-mutant
detection.
If Margrave ﬁnds counterexamples that illustrate dif-
ferences between the policies, then they must not be equivalent.
Unfortunately, Margrave supports only a subset of XACML fea-
tures; therefore, the converse does not hold, resulting in potential
false positives. In other words, if Margrave does not ﬁnd counter-
examples for a particular mutant, then the mutant may or may not
be equivalent. In our experiment, Margrave identiﬁed less than 1%
of all mutants as potentially equivalent. Furthermore, these po-
tentially equivalent mutants occurred only for the CPC and CRC
mutation operators. Performing equivalent mutation detection is
costly, taking approximately 45 minutes for the whole experiment.
When considering the low percentage of detection, potential for
false positives, and high computational cost, we feel other means
of equivalent-mutant detection are needed.

In summary, the results indicate that although structural cov-
erage is indeed correlated to fault-detection capability, structural
coverage is not strong enough to achieve an acceptable level of
fault detection. Note that the structural coverage investigated in
this experiment is essentially equivalent to statement coverage in
general-purpose programming languages. In future work, we plan
to investigate stronger criteria that correspond to path coverage. We
expect these stronger criteria to be much more effective at achiev-
ing higher mutant-killing ratios. Similar to the ﬁndings in mutation
testing of general-purpose programming languages, we found that
equivalent-mutant detection is expensive.

7.4 Threats to Validity

The threats to external validity primarily include the degree to
which the policies, fault model, mutation operators, coverage met-
rics, and test sets are representative of true practice. These threats
could be reduced by further experimentation on a wider type and

WWW 2007 / Track: Security, Privacy, Reliability, and EthicsSession: Access Control and Trust on the Web675access-control policies. In Proc. 27th International
Conference on Software Engineering, pages 196–205, 2005.

[10] V. N. Fleyshgakker and s. N. Weiss. Efﬁcient mutation

analysis: A new approach. In Proc. International Symposium
on Software Testing and Analysis, pages 185–195, 1994.

[26] A. P. Mathur and E. W. Krauser. Mutant uniﬁcation for

improved vectorization. Technical Report SERC-TR-14-P,
Software Engineering Research Center - Purdue University,
1988.

[27] L. J. Morell. A theory of fault-based testing. IEEE Trans.

[11] R. Geist, A. J. Offutt, and F. Harris. Estimation and

Softw. Eng., 16(8):844–857, 1990.

enhancement of real-time software reliability through
mutation analysis. IEEE Transactions on Computers,
41(5):55–558, 1992.

[12] M. R. Girgis and M. R. Woddward. An integrated system for
program testing using weak mutation and data ﬂow analysis.
In Proc. 8th International Conference on Software
Engineering, pages 313–319, 1985.

[13] M. M. Greenberg, C. Marks, L. A. Meyerovich, and M. C.

[28] A. J. Offut, G. Rothermel, and C. Zapf. An experimental

evaluation of selective mutation. In Proc, 15th Internation
Conference on Software Engineering, pages 100–107, May
1993.

[29] A. J. Offutt, A. Lee, G. Rothermel, R. Untch, and C. Zapf.

An experimental determination of sufﬁcient mutation
operators. ACM Transactions on Software Engineering
Methodology, 5:99, April 1996.

Tschantz. The soundness and completeness of Margrave with
respect to a subset of XACML. Technical Report CS-05-05,
Department of Computer Science, Brown University, 2005.

[30] A. J. Offutt and S. D. Lee. How strong is weak mutation? In

Proc. 4th Symposium on Software Testing, Analysis, and
Veriﬁcation, pages 200–213, 1991.

[14] M. J. Harrold, R. Gupta, and M. L. Soffa. A methodology for

[31] A. J. Offutt, R. Pargas, S. V. Fichter, and P. Khambekar.

controlling the size of a test suite. ACM Trans. Softw. Eng.
Methodol., 2(3):270–285, 1993.

[15] M. Hennessy and J. F. Power. An analysis of rule coverage as

Mutation testing of software using a MIMD computer. In
Proc. International Conference on Parallel Processing,
pages 257–266, 1992.

a criterion in generating minimal test suites for
grammar-based software. In Proc. 20th IEEE/ACM
International Conference on Automated Software
Engineering, pages 104–113, November 2005.

[16] J. R. Horgan and A. P. Mathur. Weak mutation is probably

strong mutation. Technical Report SERC-TR-83-P, Software
Engineering Research Center - Purdue University, December
1990.

[17] W. E. Howden. Weak mutation testing and completeness of

test sets. IEEE Transactions on Software Engineering,
8(4):371–379, July 1982.

[18] G. Hughes and T. Bultan. Automated veriﬁcation of access
control policies. Technical Report 2004-22, Department of
Computer Science, University of California, Santa Barbara,
2004.

[19] D. S. Johnson. Approximation algorithms for combinatorial

problems. J. Comput. System Sci., 9:256–278, 1974.

[32] A. J. Offutt and s. D. Lee. An empirical evaluation of weak

mutation. IEEE Transactions on Software Engineering,
20:337–344, 1994.

[33] J. Offutt and R. H. Untch. Mutation 2000: Uniting the
orthogonal. In Mutation 2000: Mutation Testing in the
Twentieth and the Twenty First Centuries, pages 45–55,
October 2000.

[34] M. Sahinoglu and E. H. Spafford. A bayes sequential

statistical procedure for approving software products. In
Proc. IFIP Conference on Approving Software Products,
pages 43–56, 1990.

[35] W. E. Wong. On Mutation and Data Flow. PhD thesis,

Purdue University, 1993.

[36] W. E. Wong, M. E. Delamaro, J. Maldonado, and A. P.

Mathur. Constrained mutation in c programs. In Proc. 8th
Brazilian Symposium on Software Engineering, pages
439–452, October 1994.

[20] E. W. Krauser, A. P. Mathur, and V. J. Rego. High

[37] M. R. Woodward and K. Halewood. From weak to strong,

performance software testing on SIMD machines. IEEE
Trans. Softw. Eng., 17(5):403–423, 1991.

[21] Y.-S. Ma, Y.-R. Kwon, and J. Offutt. Inter-class mutation
operators for Java. In Proc. International Symposium on
Software Reliability Engineering, pages 352–363, 2002.
[22] B. Marick. The weak mutation hypothesis. In Proc. 4th

Symposium on Software Testing, Analysis, and Veriﬁcation,
pages 190–199, 1991.

[23] E. Martin and T. Xie. Inferring access-control policy

properties via machine learning. In Proc. International
Workshop on Policies for Distributed Systems and Networks,
pages 235–238, June 2006.

[24] E. Martin and T. Xie. Automated test generation for access

control policies via change-impact analysis. In Proc. 3rd
International Workshop on Software Engineering for Secure
Systems, May 2007.

[25] E. Martin, T. Xie, and T. Yu. Deﬁning and measuring policy

coverage in testing access control policies. In Proc. 8th
International Conference on Information and
Communications Security, pages 139–158, December 2006.

dead or alive? an analysis of some mutation testing issues. In
Proc. 2nd Workshop on Software Testing, Veriﬁcation, and
Analysis, pages 152–158, 1988.

[38] N. Zhang, M. Ryan, and D. P. Guelev. Synthesising veriﬁed

access control systems in XACML. In Proc. 2004 ACM
Workshop on Formal Methods in Security Engineering,
pages 56–65, 2004.

[39] N. Zhang, M. Ryan, and D. P. Guelev. Evaluating access

control policies through model checking. In Proc. 8th
International Conference on Information Security, pages
446–460, September 2005.

[40] H. Zhu, P. A. V. Hall, and J. H. R. May. Software unit test

coverage and adequacy. ACM Comput. Surv., 29(4):366–427,
1997.

WWW 2007 / Track: Security, Privacy, Reliability, and EthicsSession: Access Control and Trust on the Web676
