[1] G. Aggarwal, A. Goel, and R. Motwani. Truthful

auctions for pricing search keywords. Proceedings of
ACM conference on Electronic Commerce, 2006.

[2] S. Athey, and I. Segal. An Eﬃcient Dynamic

Mechanism. manuscript, 2007.

[3] P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time
Analysis of the Multiarmed Bandit Problem. Machine
Learning archive, Volume 47 , Issue 2-3, 235-256, 2002.
[4] A. Bapna, and T. Weber. Eﬃcient Dynamic Allocation

with Uncertain Valuations. Working Paper, 2006.

[5] M. Balcan, A. Blum, J. Hartline, and Y. Mansour.

Mechanism Design via Machine Learning. Proceedings
of 46th Annual IEEE Symposium on Foundations of
Computer Science, 2005.

[6] D. Bergemann, and J. V¨alim¨aki. Eﬃcient Dynamic

Auctions. Proceedings of Third Workshop on
Sponsored Search Auctions, 2007.

[7] A. Borodin, and P. Salminen. Handbook of Brownian

Motion: Facts and Formulae. Springer, 2002.

[8] A. Blum, V. Kumar, A. Rudra, and F. Wu. Online

Learning in Online Auctions. Proceedings of the
fourteenth annual ACM-SIAM symposium on Discrete
Algorithms, 2003.

[9] R. Cavallo, D. Parkes, and S. Singh, Eﬃcient Online

Mechanism for Persistent, Periodically Inaccessible
Self-Interested Agents. Working Paper, 2007.

[10] K. Crawford. Google CFO: Fraud A Big Threat.

CNN/Money, December 2, 2004.

[11] J. Gittins. Multi-Armed Bandit Allocation Indices.

Wiley, New York, NY, 1989.

[12] R. Gonen, and E. Pavlov. An Incentive-Compatible
Multi-Armed Bandit Mechanism. Proceedings of the
Twenty-Sixth Annual ACM Symposium on Principles
of Distributed Computing, 2007.

[13] B. Grow, B. Elgin, and M. Herbst. Click Fraud: The
dark side of online advertising. BusinessWeek. Cover
Story, October 2, 2006.

[14] N. Immorlica, K. Jain, M. Mahdian, and K. Talwar.

Click Fraud Resistant Methods for Learning
Click-Through Rates. Proceedings of the 1st Workshop
on Internet and Network Economics, 2005.

[15] B. Kitts, P. Laxminarayan, B. LeBlanc, and R. Meech.

A Formal Analysis of Search Auctions Including
Predictions on Click Fraud and Bidding Tactics.
Workshop on Sponsored Search Auctions, 2005.

[16] R. Kleinberg. Online Decision Problems With Large

Strategy Sets. Ph.D. Thesis, MIT, 2005.

[17] S. Lahaie, and D. Parkes. Applying Learning

Algorithms to Preference Elicitation. Proceedings of
the 5th ACM conference on Electronic Commerce,
2004.

[18] M. Mahdian, and K. Tomak. Pay-per-action model for
online advertising. Proceedings of the 3rd International
Workshop on Internet and Network Economics,
549-557, 2007.

[19] P. Milgrom, Putting Auction Theory to Work.

Cambridge University Press, 2004.

[20] D. Mitchell. Click Fraud and Halli-bloggers. New York

Times, July 16, 2005.

[21] N. Nisan, T. Roughgarden, E. Tardos, and

V. Vazirani, editors. Algorithmic Game Theory,
Cambridge University Press, 2007.

[22] D. Parkes. Online Mechanisms Algorithmic Game

Theory (Nisan et al. eds.), 2007.

186WWW 2008 / Refereed Track: Internet Monetization - Online AdvertisingApril 21-25, 2008 · Beijing, China[23] B. Stone. When Mice Attack: Internet Scammers

Steal Money with “Click Fraud”. Newsweek, January
24, 2005.

[24] R. Wilson. Game-Theoretic Approaches to Trading
Processes. Economic Theory: Fifth World Congress,
ed. by T. Bewley, chap. 2, pp. 33-77, Cambridge
University Press, Cambridge, 1987.

[25] J. Wortman, Y. Vorobeychik, L. Li, and J. Langford.

Maintaining Equilibria During Exploration in
Sponsored Search Auctions. Proceedings of the 3rd
International Workshop on Internet and Network
Economics, 2007.

APPENDIX

A. PROOF OF LEMMA 4

Proof. We prove the lemma by showing that for any

agent i,

Pr[|µi −bµit(t)| ≥

that:

1

√t1−

µi] = o(

1
tc ),∀c > 0.

First, we estimate E[nit]. There exists a constant d such

E[nit] ≥

t−1Xk=1

η(k)

n

=

t−1Xk=1

min{

1
n

, k− ln1+ k} >

1
d

t1− ln1+ t

By the Chernoﬀ-Hoeﬀding bound:

Pr[nit ≤

E[nit]

2

] ≤ e

−t1− ln1+ t

8d

.

Inequality (1) and the Chernoﬀ-Hoeﬀding bound imply:

Pr[|µi −bµit(t)| ≥

1

√t1−

µi] =

= Pr[|µi −bµit(t)| ≥
+ Pr[|µi −bµit(t)| ≥

t1− ln1+ t µi

t1−

1

−

2d

√t1−
1
√t1−

≤ 2e
= o(

1
tc ),∀c > 0

1

µi ∧ nit ≥

E[nit]

]

2
E[nit]

µi ∧ nit <

]

2

−t1− ln1+ t

8d

+ e

Therefore, with probability 1 − o( 1
t ), for all agents, ∆t ≤
1√t1− . Since the maximum value of uit is 1, E[∆t] =
O(

1√t1− ).

B. PROOF OF LEMMA 8



2 ] = o( 1

Proof. Deﬁne Xit = |µi,T − µi,T−t|. We ﬁrst prove
T c ),∀c > 0. There exists a constant
Pr[Xit > T
Td such that for any time T ≥ Td, the probability that i has
not been randomly allocated the item in the last t < Td step
is at most:
Pr[T − li,T−1 > t] < (1 − T − ln2+2 T )t ≤ e
ln1+ T T . By equation (14) and (16),
Let t = 1

−t ln2+2 T

. (16)

T 

Pr[Xit > T



2 ] = Pr[Xit > T



2 ∧ T − li,T−1 ≤ t]



2 ∧ T − li,T−1 > t]

+ Pr[Xit > T

= o(

1
T c ),∀c > 0.



Hence, with high probability, for all the n agents, Xit ≤

T
2 , then, by Corol-
2 . If for some of the agents Xit ≥ T
lary 7, the expected value of the maximum of µit over these
agents is θ(√T ). Therefore, E[maxi{Xit}] = O(T

2 ). The
lemma follows because E[∆T ] ≤ E[maxi{Xit}].

187WWW 2008 / Refereed Track: Internet Monetization - Online AdvertisingApril 21-25, 2008 · Beijing, China
