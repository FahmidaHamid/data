[1] V. Anh and A. Moffat. Index compression using ﬁxed binary codewords. In

Proc. of the 15th Int. Australasian Database Conference, pages 61–67, 2004.

[2] V. Anh and A. Moffat. Improved word-aligned binary compression for text
indexing. IEEE Trans. on Knowledge and Data Engineering, 18(6), 2006.
[3] R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Plachouras, and
F. Silvestri. The impact of caching on search engines. In Proc. of the 30th
Annual SIGIR Conf. on Research and Development in Inf. Retrieval, 2007.
[4] R. Baeza-Yates, F. Junqueira, V. Plachouras, and H. Witschel. Admission

policies for caches of search engine results. In Proc. of the 14th String
Processing and Information Retrieval Symposium, September 2007.

[5] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addision

Wesley, 1999.

[6] R. Baeza-Yates and F. Saint-Jean. A three-level search-engine index based in
query log distribution. In Proc. of the 10th String Processing and Information
Retrieval Symposium, September 2003.

[7] P. Boldi and S. Vigna. Compressed perfect embedded skip lists for quick

inverted-index lookups. In Proc. of the Int. Symp. on String Processing and
Information Retrieval, pages 25–28, 2005.

[8] St. Büttcher and C. Clarke. Index compression is good, especially for random
access. In Proc. of the 16th ACM Conf. on Inf. and Knowledge Manag., 2007.

[9] P. Cao and S. Irani. Cost-aware WWW proxy caching algorithms. In Proc. of the

USENIX Symp. on Internet Technologies and Systems, 1997.

[10] T. Fagni, R. Perego, F. Silvestri, and S. Orlando. Boosting the performance of

web search engines: Caching and prefetching query results by exploiting
historical usage data. ACM Trans. on Information Systems, 24, 2006.

[11] S. Heman. Super-scalar database compression between RAM and CPU-cache.
MS Thesis, Centrum voor Wiskunde en Informatica (CWI), Amsterdam, 2005.
[12] B. Jonsson, M. Franklin, and D. Srivastava. Interaction of query evaluation and
buffer management for information retrieval. In Proc. of the ACM SIGMOD Int.
Conf. on Management of Data, pages 118–129, June 1998.

[13] R. Lempel and S. Moran. Predictive caching and prefetching of query results in

search engines. In Proc. of the 12th Int. World-Wide Web Conference, 2003.

[14] X. Long and T. Suel. Three-level caching for efﬁcient query processing in large
web search engines. In Proc. of the 14th Int. World Wide Web Conference, 2005.

[15] E. Markatos. On caching search engine query results. In 5th International Web

Caching and Content Delivery Workshop, May 2000.

[16] N. Megiddo and D. Modha. ARC: A self-tuning, low overhead replacement

cache. In Proc. of the USENIX Conf. on File and Storage Technologies, 2003.
[17] N. Megiddo and D. Modha. Outperforming LRU with an adaptive replacement

cache algorithm. IEEE Computer, 37(4), 2004.

[18] A. Moffat and J. Zobel. Self-indexing inverted ﬁles for fast text retrieval. ACM

Trans. on Information Systems, 14(4):349–379, 1996.

[19] G. Navarro, E. de Moura, M. Neubert, N. Ziviani, and R. Baeza-Yates. Adding

compression to block addressing inverted indexes. Inf. Retrieval, 3(1), 2000.

[20] P. Saraiva, E. de Moura, N. Ziviani, W. Meira, R. Fonseca, and B. Ribeiro-Neto.

Rank-preserving two-level caching for scalable search engines. In Proc. of the
24th Annual SIGIR Conf. on Research and Development in Inf. Retrieval, 2001.

[21] F. Scholer, H. Williams, J. Yiannis, and J. Zobel. Compression of inverted

indexes for fast query evaluation. In Proc. of the 25th Annual SIGIR Conf. on
Research and Development in Information Retrieval, August 2002.

[22] V. Shkapenyuk and T. Suel. Design and implementation of a high-performance
distributed web crawler. In Proc. of the Int. Conf. on Data Engineering, 2002.

[23] Y. Xie and D. O’Hallaron. Locality in search engine queries and its implications

for caching. In Proc. of the Infocom Conference, 2002.

[24] N. Young. On-line ﬁle caching. In Proc. of the 9th Annual ACM-SIAM Symp. on

Discrete algorithms, 1998.

[25] Y. Zhou, J. Philbin, and K. Li. The multi-queue replacement algorithm for

second level buffer caches. In Proc. of the USENIX Annual Techn. Conf., 2001.
[26] J. Zobel and A. Moffat. Inverted ﬁles for text search engines. ACM Computing

Surveys, 38(2), 2006.

[27] M. Zukowski, S. Heman, N. Nes, and P. Boncz. Super-scalar RAM-CPU cache

compression. In Proc. of the Int. Conf. on Data Engineering, 2006.

Figure 14: Comparison of PForDelta, S16, and Rice coding, using
LFU caching and assuming 50MB/s disk speed.

of cache sizes, followed by S16 and then by Rice coding. The rea-
son is that the slightly higher cache hit rates for S16 and Rice do
not make up for the much slower decompression.

Figure 15: Comparison of query processing costs for different disk
speeds, using LFU and a 128MB cache.

Finally, we look at the impact of disk speed for a ﬁxed cache size.
In Figure 15, we show results for a cache size of 128 MB and disk
speeds between 10 to 100 MB/s. We see that when the disk has a
transfer rate up to 20 MB/s, Rice is faster than the other compres-
sion algorithms, but otherwise PForDelta is best. (To be precise,
S16 is brieﬂy the champion around 20 MB/s, by a very slim mar-
gin.) Looking at disk speeds of 20 MB/s or less may seem like
a useless exercise given that current cheap disks already achieve
transfer rates of about 60 MB/s, but we note that our results are
really based on the ratio between disk transfer rate and decompres-
sion speed: If CPUs increase in speed by a factor of 2 this would
have the same effect in relative terms as disk speeds being reduced
by a factor of 2. Thus, architectural trends in the future may make
techniques such as Rice coding relevant again. For current archi-
tectures, PForDelta plus LFU appears to be the best choice.

7. CONCLUDING REMARKS

In this paper, we studied techniques for inverted index compres-
sion and index caching in search engines. We provided a detailed
evaluation of several state-of-the-art compression methods and of
different list caching policies. Finally, we looked at the perfor-
mance beneﬁts of combining compression and caching, and ex-
plored how this beneﬁt depends on machine parameters such as disk
transfer rate, main memory, and CPU speed.

There are several interesting remaining open problems. First, the
recent work on PForDelta in [11, 27] shows that decompression
speed depends not so much on questions of bit versus byte align-
ment, but on the amount of obliviousness in the control and data
ﬂow of the algorithm. Any approach that requires a decision to be
made for each decoded integer will be at a severe disadvantage in
terms of speed. We have shown here that ideas similar to PForDelta
can also be used to increase the speed of Rice decoding, implying a
trade-off between speed and compression. An interesting challenge

396WWW 2008 / Refereed Track: Search - Corpus Characterization & Search PerformanceBeijing, China
