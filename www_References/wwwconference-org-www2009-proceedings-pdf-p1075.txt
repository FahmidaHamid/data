[1]  Borthwick, A. "Survey Paper on Statistical Language

Modeling", Technical Report, Proteus project, New York
University Computer Science Department, 1997

[2]  Gauch, S., Wang, G. and Gomez, M. Profusion: intelligent
fusion from multiple, distributed search engines. J. Univers.
Comput. Sci. 2(9), (1996), 637-649.

[3]  Järvelin, K. and Kekalainen, J. IR evaluation methods for

retrieving highly relevant documents. In Proceedings of the
23rd annual international ACM SIGIR conference (Athens,
Greece, July, 2000) SIGIR'00, ACM Press, New York, NY,
41-48.

p R S q

(

|

ij

,

i

=

)

(
Score

R
ij

|

, )
S q

i

⋅

e

−

λ

N

j

∑

l

(
Score

R
ij

|

, )
S q

i

⋅

e

−

λ

N

l

               (3.2)

[4]  Meng, W., Yu, C., and Liu, K. Building efficient and

effective metasearch engines. ACM Comput. 34(1) 48-89.

Table 1. Vertical intention of generic Web-search queries



3

2
1
0

Image

12.3%
26.1%
36.3%
25.7%

Video
8.5%

15%
46.6%
29.7%

News
13.1%

28%
49.5%
9.3%

Blog
0.9%

8.6%
70.7%
19.7%

Book
7.2%

11.9%
29.9%
50.9%

3.  TYPESET TEXT
In  this  paper,  search  engines  (SEs)  is  noted  as  both  VSEs  and
general purpose search engine. Let Λ = {Si , i=1,2,…m} stands for
the  set  of  all  SEs.  Given  the  user  query  q,  the  search  results  are
represented by R ={Rij, i=1,2,…m and j=1,2,…n}, where Rij is the
jth  search  result  of  query  q  in  the  ith  search  engines  Si.  Our
problem is to rank the results come from various SEs for generic
Web search. Thus we aim to learn the probability p(Rij|q) and then
the search results of q can be ranked according to the probabilities
in  a  decreasing  order.  To  learn  p(Rij|q),  we  firstly  analyze  the
dependencies between queries, SEs and search results. Since Rij is
retrieved from Si by query q, it depends on both Si and q. On the
i≠ .
other  hand,  we  assume  that  Rij  is  independent  of  Vl  if l
Intuitively, we assume that each result can only be retrieved from
one  search  engine.  Note  the  fact  that  different  queries  will  have
different  vertical  search  intentions.  The  importance  of  SEs  is not
uniformly  distributed.  It  will  highly  depend  on  the  user  query.
Motivated by these clear dependencies, we modeled our problem,
i.e. the problem of learning probability p(Rij|q), by a probabilistic
graphical model, which is described by Figure 1.

Figure 1. The proposed model for blended search.

According  to  the  conditional  independency  assumptions,  we  can
get the probability distribution p(Rij |q) through,



  (
p R

ij

|   )
q

=

∑

l



=

∑

l

p R S

(

,

ij

|

q

)

l

p R

(

ij

|

S q p S q

) (

,

l

l

)



    (3.1)



=

p R

(

ij

|

S q p S

)

(

,

i

|

q

)

i

The  remaining  problem  is  to  estimate

p

(R | S ,

ij

i

q and (S |

ip

)

q .

)

q ∝ (
)

i

i

|

|

)

(

)

(
ip S

Through  Bayesian

p q S p S ,  where  p(Si)  is  our
prior belief that Si relates to any arbitrary query q and p(q | Si) is
known  as  the  query  likelihood.  Without  loss  of  generality,
suppose  query  q  consists  of  k  terms  {t1,  t2,  …tk}.  We  utilize  the
unigram  language  model,  which  is  a  multinomial  model,  to
estimate  the  probability  p(q  |  Si)  [1].  On  the  other  hand,  we
propose to estimate the probability distributions

q by,

(R | S ,

p

)

ij

i

λ−

jN

e

is a factor for punishing the vertical search results and

where
Nj  is  the  position  of ij
punishing  factor  is  that  we  embed  the  vertical  search  results  into

I in  the  result  list.  The  intuition  for  the

WWW 2009 MADRID!Poster Sessions: Wednesday, April 22, 20091076
