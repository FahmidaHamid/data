[1] G. Aggarwal, J. Feldman, S. Muthukrishnan, and

M. P´al. Sponsored search auctions with markovian
users. In WINE ’08, pages 621–628, 2008.

[2] E. Agichtein, E. Brill, and S. Dumais. Improving web

search ranking by incorporating user behavior
information. In SIGIR ’06, pages 19–26, 2006.

[3] O. Chapelle and Y. Zhang. A dynamic bayesian

network click model for web search ranking. In WWW
’09, 2009.

[4] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An
experimental comparison of click position-bias models.
In WSDM ’08, pages 87–94, 2008.

[5] G. E. Dupret and B. Piwowarski. A user browsing

model to predict search engine click data from past
observations. In SIGIR ’08, pages 331–338, 2008.

[6] F. Guo, L. Li, and C. Faloutsos. Tailoring click models

to user goals. In WSDM ’09 workshop on Web search
click data, pages 88–92, 2009.

[7] F. Guo, C. Liu, and Y.-M. Wang. Eﬃcient

multiple-click models in web search. In WSDM ’09,
pages 124–131, 2009.

WWW 2009 MADRID!Track: Data Mining / Session: Click Models19[8] T. Joachims. Optimizing search engines using

clickthrough data. In KDD ’02, pages 133–142, 2002.
[9] T. Joachims, L. Granka, B. Pan, H. Hembrooke, and
G. Gay. Accurately interpreting clickthrough data as
implicit feedback. In SIGIR ’05, pages 154–161, 2005.

[10] T. Joachims, L. Granka, B. Pan, H. Hembrooke,

F. Radlinski, and G. Gay. Evaluating the accuracy of
implicit feedback from clicks and query reformulations
in web search. ACM Trans. Inf. Syst., 25(2):7, 2007.

[11] D. Kempe and M. Mahdian. A cascade model for

externalities in sponsored search. In WINE ’08, pages
585–596, 2008.

[12] U. Lee, Z. Liu, and J. Cho. Automatic identiﬁcation of

user goals in web search. In WWW ’05, pages
391–400, 2005.

[13] T. Minka. Expectation propagation for approximate
bayesian inference. In UAI ’01, pages 362–369, 2001.
[14] B. Piwowarski, G. Dupret, and R. Jones. Mining user
web search activity with layered bayesian networks or
how to capture a click in its context. In WSDM ’09,
pages 162–171, 2009.

[15] F. Radlinski and T. Joachims. Query chains: learning

to rank from implicit feedback. In KDD ’05, pages
239–248, 2005.

[16] M. Richardson, E. Dominowska, and R. Ragno.

Predicting clicks: estimating the click-through rate for
new ads. In WWW ’07, pages 521–530, 2007.

[17] G.-R. Xue, H.-J. Zeng, Z. Chen, Y. Yu, W.-Y. Ma,

W. Xi, and W. Fan. Optimizing web search using web
click-through data. In CIKM ’04, pages 118–126, 2004.

APPENDIX
A. Algorithms for Learning UBM
For UBM, the log-likelihood for each query session is

(cid:7) =

Ci(log rdi + log γli,i−li ) + (1− Ci) log(1− rdi γli,i−li )

M(cid:7)

i=1

The coupling of relevance r and parameter γ introduced in
the second term makes exact computation intractable. The
algorithm could alternative be carried out in an iterative,
coordinate-ascent fashion. However, we found that the ﬁx-
point equation update proposed in [5] does not have conver-
gence guarantee and is sub-optimal in certain cases. Instead,
we designed the following update scheme which usually leads
to very fast convergence.
Given a query for each document d, we keep its count of
click Kd and non-click Ld,j where 1 ≤ j ≤ M (M + 1)/2,
and they map one-to-one with all possible γ indices, and
1 ≤ d ≤ D maps one-to-one to all query-document pair.
Similarly, for each γj, we keep its count of click Kj. Then
given the initial value of γ = γ0, optimization of relevance
can be carried out iteratively,

(cid:13)
(cid:13)

Kd log r +

rt+1
d = arg max
0<r<1

γt+1
j = arg max
0<γ<1

(cid:14)

Ld,j log(1 − rγt
j)
(cid:14)

M (M +1)/2(cid:7)
D(cid:7)

j=1

d=1

Kj log γ +

Ld,j log(1 − rt+1

d γ)

for all possible d and j respectively. The “arg-max” opera-
tion can be carried out by evaluating the objective function
for a sequential scan of r or γ values. And we suggest a
granularity of 0.01 for both scans.
B. LL and Other Statistics of CCM
Given a query session in test data, let ri and si denote the
ﬁrst and second moment of the document relevance poste-
rior for the web document at position i, and α1, α2, α3 de-
note the user behavior parameter. These values are obtained
during model training. We iteratively deﬁne the following
constants:

ζ0 = 1
ζi+1 = (1 − rM−i)(1 − α1 + α1ζi)

Let C i denote the actual click event at test data, then de-
pending on the value of last clicked position l, we have the
following two cases:
• l = 0 (no click),

(cid:8)

LL =

S

p(S1)P (C1 = 0|E1 = 1, S1)

(cid:7)

(cid:4)

E

j>1

P (Ej|Ej−1, Cj−1 = 0)p(Sj)P (Cj = 0|Ej, Sj) = ζM
(cid:22)
(cid:23)
• 1 ≤ l ≤ M
l−1(cid:4)
(cid:5)

(α1(1 − ri))1−Ci (α2ri + (α3 − α2)si)

(1 − α2(1 − ζM−l))rl + (α2 − α3)(1 − ζM−l)sl

LL =

(cid:6)

i=1

Ci

·

We also deﬁne the following constants:

ϕi = (1 − ri)α1 + (ri − si)α2 + siα3
ξM = 0
ξi−1 = φi−1ξi + ri

Then we have

Examination Probability P (Ei = 1) =

i−1(cid:4)

ϕj

j=1

i−1(cid:4)

Examination Depth P (LEP = i) = (1 − ϕi)P (Ei = 1)

Click Probability P (Ci = 1) = riP (Ei = 1)

α1(1 − rj)
First Clicked Position P (F CP = i) = ri
(cid:6)
(cid:18)
Last Clicked Position P (LCP = i) = P (Ei = 1)·
ξi

ri −(cid:17)

ϕi−α1(1 − ri)

(cid:5)

j=1

To draw sample from CCM for performance test:
Initialize C1:M = 0,E1 = 1, i = 1
while (i ≤ M ) and (Ei (cid:11)= 0)

Ci ∼ Bernoulli(ri)
Ei+1 ∼ Bernoulli(α1(1 − Ci) + (α2ri + (α3 − α2)si)Ci)
i = i + 1

Detailed derivations for this subsection will be available at
the author’s web site and included in an extended version
of this work.

WWW 2009 MADRID!Track: Data Mining / Session: Click Models20
