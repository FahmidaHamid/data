[1] E. Adar. User 4xxxxx9: Anonymizing query logs. In Query Log Analysis:

Social And Technological Challenges Workshop at WWW, 2007.

[2] M. Arrington. AOL proudly releases massive amounts of private data. August

2006.

[3] R. Baeza-Yates and A. Tiberi. Extracting semantic relations from query logs.

In KDD, pages 76–85, 2007.

[4] J. Bar-Ilan. Access to query logs - an academic researcher’s point of view. In

Query Log Analysis: Social And Technological Challenges Workshop at
WWW, 2007.

[5] M. Barbaro and T. Zeller. A face is exposed for AOL searcher No. 4417749.

New York Times, Aug 2006.

[6] A. Blum, K. Ligett, and A. Roth. A learning theory approach to

non-interactive database privacy. In STOC, pages 609–618, 2008.

[7] K. Chaudhuri and N. Mishra. When random sampling preserves privacy. In

CRYPTO, volume 4117, pages 198–213, 2006.

[8] N. Craswell and M. Szummer. Random walks on the click graph. In SIGIR,

pages 239–246, 2007.

[9] C. Dwork. An ad omnia approach to deﬁning and achieving private data

analysis. In Lecture Notes in Computer Science, volume 4890, pages 1–13.
Springer, 2008.

[10] C. Dwork, K. . Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data,
ourselves: Privacy via distributed noise generation. In EUROCRYPT, volume
4004, pages 486–503, 2006.

[11] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to

sensitivity in private data analysis. In Theory of Cryptography, pages 265–284,
2006.

[12] D. Fallows. Search engine users. Pew Internet and American Life Project,

2005.

[13] A. Fuxman, P. Tsaparas, K. Achan, and R. Agrawal. Using the wisdom of the

crowds for keyword generation. In WWW, pages 61–70, 2008.

[14] A. Horowitz, D. Jacobson, T. McNichol, and O. Thomas. 101 dumbest

moments in business, the year’s biggest boors, buffoons, and blunderers. In
CNN Money, 2007.

[15] T. Joachims, L. Granka, B. Pang, H. Hembrooke, and G. Gay. Accurately

interpreting clickthrough data as implicit feedback. In SIGIR, pages 154–161,
2005.

[16] R. Jones, R. Kumar, B. Pang, and A.Tomkins. “I know what you did last
summer”: query logs and user privacy. In CIKM, pages 909–914, 2007.

[17] R. Jones, R. Kumar, B. Pang, and A. Tomkins. Vanity fair: Privacy in querylog

bundles. In CIKM, pages 853–862, 2008.

[18] R. Kessler, M. Stein, and P. Berglund. Social Phobia Subtypes in the National

Comorbidity Survey. Am J Psychiatry, 155(5):613–619, 1998.

[19] R. Kumar, J. Novak, B. Pang, and A. Tomkins. On anonymizing query logs via

token-based hashing. In WWW, pages 629–638, 2007.

[20] F. McSherry and K. Talwar. Mechanism design via differential privacy. In

FOCS, pages 94–103, 2007.

[21] F. McSherry and K. Talwar. Private communication. 2008.
[22] A. Narayanan and V. Shmatikov. Robust de-anonymization of large sparse

datasets. In IEEE Symposium on Security and Privacy, pages 111–125, 2008.

[23] K. Nissim. Private data analysis via output perturbation. In Privacy-Preserving

Data Mining: Models and Algorithms, pages 383–414. Springer, 2008.
[24] B. Tancer. Click: What Millions of People Are Doing Online and Why it

Matters. Hyperion, 2008.

[25] L. Xiong and E. Agichtein. Towards privacy-preserving query log publishing.

In Query Log Analysis: Social And Technological Challenges Workshop in
WWW, 2007.

11. APPENDIX

Observation 2. [Properties of Laplace distribution] For Laplace

distribution with location parameter 0, and scale parameter b > 0,
and a random variable X, the cdf F (x) = P r[X ≤ x] satisﬁes:

F (x) = 1/2 · exp(x/b), if x < 0

= 1 − 1/2 · exp(−x/b), if x ≥ 0

In this notation, increasing b ﬂattens out the Lap(b) curve, yielding
larger expected noise magnitude and therefore, eventually, better
privacy guarantees.

Observation 3. [Properties of Laplace ratios] Let r be a ran-

dom Lap(b) noise. Then,
1 ≤ P r[r<c+1]

≤ e1/b and e

P r[r<c]

−1/b ≤ P r[r>c+1]

P r[r>c]

≤ 1.

Observation 4. [Properties of ratios] For a, b ≥ 0 and c, d >

0 : a+b
c+d

≤ max( a

c , b

d ).

WWW 2009 MADRID!Track: Data Mining / Session: Web Mining180
